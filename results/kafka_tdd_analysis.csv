Commit Hash,Commit Message,Commit Date,Author,Commit Type
642da2f28c9bc6e373603d6d9119ce33684090f5,"Initial checkin of Kafka to Apache SVN. This corresponds to https://github.com/kafka-dev/kafka/commit/709afe4ec75489bc00a44335de8821fa726bb97e except that git specific files have been removed and code has been put into trunk/branches/site/etc. This is just a copy of master, branches and history are not being converted since we can't find a good tool for it.



git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1152970 13f79535-47bb-0310-9956-ffa450edef68",2011-08-01 23:41:24,Edward Jay Kreps,Mixed
96b8e03dd1ee23a550ca87803777b4d7bec05d5a,"commit offset before consumer shutdown KAFKA-84; rename util.StringSerializer to ZKStringSerializer to avoid confusion with producer.StringSerializer

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1154719 13f79535-47bb-0310-9956-ffa450edef68",2011-08-07 16:29:55,Jun Rao,Mixed
462dfda513d98a0017564f5070f678d57f834872,"KAFKA-93 | Change and add ASF source header to follow standard ASF source header (http://www.apache.org/legal/src-headers.html).

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1156232 13f79535-47bb-0310-9956-ffa450edef68",2011-08-10 15:33:21,Henry Saputra,Mixed
d0c980dab278627286e9a2be649de0f6c8ce8b53,"KAFKA-93 | add license to missed files and remove LinkedIn copyright line per ASF guideline. Thanks to Joel Koshy for pointing it out

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1156299 13f79535-47bb-0310-9956-ffa450edef68",2011-08-10 18:32:09,Henry Saputra,Not TDD
49f3b4017918c4e254e9bc09e2ef5178d62e0248,"auto-discovery of topics for mirroring; patched by Joel; reviewed by Jun; KAFKA-74

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1156393 13f79535-47bb-0310-9956-ffa450edef68",2011-08-10 22:32:23,Jun Rao,Not TDD
82b42163a55440eee6508ff4a721906bc40704e8,"change whitelist config for mirroring; patched by Joel; KAFKA-103

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1158969 13f79535-47bb-0310-9956-ffa450edef68",2011-08-17 23:34:08,Jun Rao,Not TDD
8a07bdb71e74377d7b8ae3c53fe1e59f46bbe2a8,"Bug in serialize and collate logic in the DefaultEventHandler KAFKA-107; patched by Neha; reviewed by Jun

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1159452 13f79535-47bb-0310-9956-ffa450edef68",2011-08-19 00:29:09,Neha Narkhede,Not TDD
900496eedabd7acfdeaaf077239228f4d94312e8,"CompressionUtils introduces a GZIP header while compressing empty message sets KAFKA-109; patched by Neha; reviewed by Jun

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1159459 13f79535-47bb-0310-9956-ffa450edef68",2011-08-19 00:47:34,Neha Narkhede,Not TDD
4a688c5d6c87aa8dfffdb2154ef880107176573f,"KAFKA-99 Enforce a max request size in socket server to avoid running out of memory with very large requests.



git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1159837 13f79535-47bb-0310-9956-ffa450edef68",2011-08-20 04:08:06,Edward Jay Kreps,Mixed
4cdc982e22870f0e4d993d479036a3571ad3a2bc,"Producer performance tool should use the new blocking async producer instead of the sleep timeout hack; KAFKA-118; patched by nehanarkhede; reviewed by junrao

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1160947 13f79535-47bb-0310-9956-ffa450edef68",2011-08-24 00:50:28,Neha Narkhede,Not TDD
bf30ae996f2ec08ae97f61a0eff0c50bb8ce8067,"The FetcherRunnable busy waits on empty fetch requests; KAFKA-117; patched by nehanarkhede; reviewed by junrao

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1160952 13f79535-47bb-0310-9956-ffa450edef68",2011-08-24 01:27:42,Neha Narkhede,Mixed
54f49314afbc1e13ff511f152e9b292ffaf9104d,"KAFKA-70 Patch from Prashanth Menon to add space-based retention setting.



git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1171886 13f79535-47bb-0310-9956-ffa450edef68",2011-09-17 03:21:06,Edward Jay Kreps,Mixed
dc66fd9a4b6e77cacb5c15dee18a404a0bb89408,"enhancements to .Net; patched by Eric Hauser; KAFKA-85

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1173797 13f79535-47bb-0310-9956-ffa450edef68",2011-09-21 19:17:19,Jun Rao,Mixed
d772600c7b79d84d332aa2b7d37512b47fd7d7ae,"Fix ASF license headers for C# client; patched by Eric Hauser; #KAFKA-137

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1174493 13f79535-47bb-0310-9956-ffa450edef68",2011-09-23 01:44:40,Jun Rao,Mixed
4092ceeb5ae5c5e2546c824ccab7478a8ab19c68,"Consumer needs a pluggable decoder; patched by Joel Koshy; reviewed by Jun Rao; KAFKA-3

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1176671 13f79535-47bb-0310-9956-ffa450edef68",2011-09-28 00:42:30,Jun Rao,Mixed
a7b4731947b605d8433c91e967aaecacd5340aa4,"obsessive compulsive tag team: Replace tabs with spaces
patch by jkreps; reviewed by cburroughs for KAFKA-114

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1178670 13f79535-47bb-0310-9956-ffa450edef68",2011-10-04 01:41:25,Chris Burroughs,Not TDD
dd62e77f90f5f6fb9050627a9cfa40b35dae67b1,"KAFKA-129 ZK-based producer can throw an unexpceted exception when sending a message; patched by nehanarkhede; reviewed by junrao

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1178997 13f79535-47bb-0310-9956-ffa450edef68",2011-10-04 22:43:00,Neha Narkhede,Mixed
101af58f6c0dc007d53819eb5f3281c60d1fa7bc,"KAFKA-141; Added the ASF header to the kafka source and test files where it was missing, deleted the CONTRIBUTORS file to match the convention of other Apache projects; patched by nehanarkhede; reviewed by junrao

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1179788 13f79535-47bb-0310-9956-ffa450edef68",2011-10-06 19:45:38,Neha Narkhede,Not TDD
472723f1cccb8cb1e74ef52e47ccb2fbdc6c3e3d,"KAFKA-149: Current perf directory has buggy perf tests; patched by nehanarkhede; reviewed by junrao

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1179791 13f79535-47bb-0310-9956-ffa450edef68",2011-10-06 19:48:03,Neha Narkhede,Mixed
a99becbe491680346c47b0bf8af738e1729de348,"Minor patch, removing the .gitigore file

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1180110 13f79535-47bb-0310-9956-ffa450edef68",2011-10-07 17:18:56,Neha Narkhede,Mixed
f34dfc002d7e1aa6b57eb7fa28ee3c928a96e968,"Reverting accidental commit 1180110, which is pending review for KAFKA-141

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1180117 13f79535-47bb-0310-9956-ffa450edef68",2011-10-07 17:33:43,Neha Narkhede,Mixed
fa09aacdbdf0cd325edd28eb80cbd0f4b232ffc3,"KAFKA-141 Check and make sure that the files that have been donated have been updated to reflect the new ASF copyright;patched by nehanarkhede; reviewd by jjkoshy

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1180185 13f79535-47bb-0310-9956-ffa450edef68",2011-10-07 19:51:28,Neha Narkhede,Mixed
e27136d81a47a5601e0a85069140a0a7854d3d65,"KAFKA-141 Follow up patch to fix the cpp files; patched by Lorenzo, nehanarkhede; reviewed by junrao, jjkoshy

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1182158 13f79535-47bb-0310-9956-ffa450edef68",2011-10-12 01:05:28,Neha Narkhede,Not TDD
e39c11abbc24223344b5ee8f7c8c03f126da5750,"Add compression to C# client; patched by Eric Hauser; KAFKA-153

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1185772 13f79535-47bb-0310-9956-ffa450edef68",2011-10-18 17:52:13,Jun Rao,Mixed
81f8d0dd83a25e075cc6a08c6105b01459980c5f,"ZK consumer gets into infinite loop if a message is larger than fetch size; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-160

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1186570 13f79535-47bb-0310-9956-ffa450edef68",2011-10-19 23:52:58,Jun Rao,Mixed
d9a8af778275fda2057d49f244e61456dfcf2f96,"KAFKA-161 Producer using broker list does not load balance requests across multiple partitions on a broker; patched by nehanarkhede; reviewed by junrao

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1188333 13f79535-47bb-0310-9956-ffa450edef68",2011-10-24 19:41:35,Neha Narkhede,Mixed
14a1f0dcd6af28bc710e108e6f7a5c10f825a40a,"KAFKA 158 Support for compression in go clients; patched by jeffregydamick; reviewed by nehanarkhede

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1189773 13f79535-47bb-0310-9956-ffa450edef68",2011-10-27 14:24:27,Neha Narkhede,Mixed
12572102c695058264af1599112f0660325e7189,"KAFKA-177 Remove the clojure clients until correctly implemented and refactored; patched by nehanarkhede; reviewd by jefferydamick

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1195249 13f79535-47bb-0310-9956-ffa450edef68",2011-10-30 21:17:13,Neha Narkhede,Mixed
5c3d5d815ca4f74611ffdd0fbd9da05cd5943d83,"KAFKA-177 Remove the clojure clients until correctly implemented and refactored; patched by nehanarkhede; reviewd by jefferydamick

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1195281 13f79535-47bb-0310-9956-ffa450edef68",2011-10-30 23:46:41,Neha Narkhede,Mixed
c51b940179e2a5719021ea253b38ec4a2beed41f,"Add Snappy Compression as a Codec; patched by Joe Stein; reviewed by Neha Narkhede and Jun Rao; KAFKA-187

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1202045 13f79535-47bb-0310-9956-ffa450edef68",2011-11-15 05:02:08,Jun Rao,Mixed
af923c3018f8ddee6703e577eadf9227d826806e,"Avoid creating a new topic by the consumer; patched by Taylor Gautier; reviewed by Jun Rao; KAFKA-101

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1204764 13f79535-47bb-0310-9956-ffa450edef68",2011-11-22 00:35:09,Jun Rao,Mixed
1280b71a35f0868de427a22271fa9f38384d9f2f,"KAFKA-193 Add a logging helper trait and use it where logging is used. Patch from Joe Stein.



git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1205311 13f79535-47bb-0310-9956-ffa450edef68",2011-11-23 07:21:16,Edward Jay Kreps,Mixed
336410a7774b0ee20758358a1bf03461ce4b98e1,"KAFKA-227 Broker failure system test; patched by johnfung; reviewed by nehanarkhede

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1227916 13f79535-47bb-0310-9956-ffa450edef68",2012-01-06 00:43:46,Neha Narkhede,Mixed
66be5eedf3e758ad53b966272f9228f54a96e648,"Support configurable send / receive socket buffer size in server; patched by John Fung; reviewed by Jun Rao; KAFKA-200

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1228480 13f79535-47bb-0310-9956-ffa450edef68",2012-01-06 22:50:29,Jun Rao,Mixed
b0484eccf3e72ff856c4e1c63949ac036c92d932,"KAFKA-228 Reduce duplicate messages served by the kafka consumer for uncompressed topics; patched by nehanarkhede; reviewed by junrao

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1228504 13f79535-47bb-0310-9956-ffa450edef68",2012-01-07 00:01:25,Neha Narkhede,Mixed
60d88a3ac95bee3b54a3d732d1ada22258054a33,"KAFKA-202 Make request processing in kafka asynchronous; patched by jaykreps; reviewed by junrao and nehanarkhede

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1230845 13f79535-47bb-0310-9956-ffa450edef68",2012-01-13 00:03:02,Neha Narkhede,Mixed
1021ea9002dc7250c000512db7a8dec92f462404,"KAFKA 244 Improve log4j appender to use kafka.producer.Producer; patched by vtkstef; reviewed by nehanarkhede

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1231276 13f79535-47bb-0310-9956-ffa450edef68",2012-01-13 19:53:32,Neha Narkhede,Mixed
ff668f4fc9a07137c92cc9259f8116d9ec2d2e1f,"create/delete ZK path for a topic in an admin tool; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-237

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1231400 13f79535-47bb-0310-9956-ffa450edef68",2012-01-13 23:48:27,Jun Rao,Mixed
fe2f0557130b21aca203ced11bd6990322847b97,"ConsumerIterator throws a IllegalStateException after a ConsumerTimeout occurs; patched by Jun Rao; reviewed by Joel Koshy; KAFKA-241

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1233501 13f79535-47bb-0310-9956-ffa450edef68",2012-01-19 17:53:32,Jun Rao,Not TDD
af0ceff79b3f1902bf9d005136ace81549332902,"KAFKA-238 getTopicMetadata API; patched by nehanarkhede; reviewed by junrao

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1235492 13f79535-47bb-0310-9956-ffa450edef68",2012-01-24 20:54:11,Neha Narkhede,Mixed
afd4b0d772f35f902a7acf81039abcc47b983d1f,"KAFKA 256 Bug in the consumer rebalancing logic leads to the consumer not pulling data from some partitions; patched by nehanarkhede; reviewed by joelkoshy

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1239766 13f79535-47bb-0310-9956-ffa450edef68",2012-02-02 19:07:48,Neha Narkhede,Not TDD
e3b529df80bfbc8d5ae3f86ef29efaf25e2edfb7,"Merging commits 1230840:1239902 from trunk

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1239937 13f79535-47bb-0310-9956-ffa450edef68",2012-02-02 23:40:39,Neha Narkhede,Mixed
345bc7bad594af43df5fc264ad0b5904d1126257,"KAFKA-263 Enhance single host broker failure test to have 2 topics with uneven distribution on the source brokers; patched by John Fung; reviewed by Neha Narkhede

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1241528 13f79535-47bb-0310-9956-ffa450edef68",2012-02-07 17:38:15,Neha Narkhede,Not TDD
21da30456f4c23aae1f40b3446f74565d5b6d917,"refactor the async producer; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-253

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1241754 13f79535-47bb-0310-9956-ffa450edef68",2012-02-08 02:59:54,Jun Rao,Mixed
a888a9d09e4fc219ab9d8536034ac043093f17df,"KAFKA-262 Bug in the consumer rebalancing logic causes one consumer to release partitions that it does not own; patched by Neha Narkhede; reviewed by Jun Rao

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1242552 13f79535-47bb-0310-9956-ffa450edef68",2012-02-09 22:04:32,Neha Narkhede,Mixed
a5fb217293e5124ef7f47e0d45c7400bd9286077,"new consumer request format; patched by Prashanth Menon; reviewed by Jun Rao and Jay Kreps; KAFKA-240

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1243407 13f79535-47bb-0310-9956-ffa450edef68",2012-02-13 03:58:37,Jun Rao,Not TDD
6e36047fae3338b425a63c0d1e4a5acb499e5207,"disable dup topic in consumer request; patched by Prashanth Menon; reviewed by Jun Rao; KAFKA-240

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1244650 13f79535-47bb-0310-9956-ffa450edef68",2012-02-15 19:08:08,Jun Rao,Not TDD
333966f50ea42ba41ff243d1ba5571a2fa8b9a60,"Add a shallow iterator to the ByteBufferMessageSet; patched by Yang Ye; reviewed by Jun Rao; KAFKA-277

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1293010 13f79535-47bb-0310-9956-ffa450edef68",2012-02-23 22:57:40,Jun Rao,Mixed
d8286aad107dbec34faae9e4e29c65bde20eb6f8,"Increase maximum value of log.retention.size; patched by Elben Shira; reviewed by Jun Rao; KAFKA-285

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1294441 13f79535-47bb-0310-9956-ffa450edef68",2012-02-28 01:50:38,Jun Rao,Not TDD
6c34cf2dcc5961703001ab484a1ca6e662eee362,"use propertyExists to test if both broker.list and zk.connect are present; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-290

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1294959 13f79535-47bb-0310-9956-ffa450edef68",2012-02-29 03:22:14,Jun Rao,Mixed
9fd2d4ffdba4b45df7807c1a70ff17496b51afa8,"KAFKA-239 Refactoring code to wire new ZK data structures and making partitions logical; patched by Neha Narkhede; reviewed by Jun Rao

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1295861 13f79535-47bb-0310-9956-ffa450edef68",2012-03-01 21:15:26,Neha Narkhede,Mixed
f8042d5b3932a0114c33cad6388eba9c41d77809,"KAFKA-240 ProducerRequest wire format protocol update and related changes

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1296577 13f79535-47bb-0310-9956-ffa450edef68",2012-03-03 05:46:43,Joe Stein,Mixed
0443e2dd737cada1fed3964dd1cb2b687944f9c6,"broker deletes all file segments when cleaning up an empty log segment; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-292

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1297324 13f79535-47bb-0310-9956-ffa450edef68",2012-03-06 02:21:54,Jun Rao,Mixed
4dd7f95569d3af60c73484e7969080ac0d755085,"Add acknowledgement to the produce request; patched by Prashanth Menon; reviewed by Jun Rao; KAFKA-49

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1300435 13f79535-47bb-0310-9956-ffa450edef68",2012-03-14 01:35:46,Jun Rao,Mixed
854fb29c26ed55926956e858b0465b85f80ef738,"KAFKA-300 Leader election; patched by nehanarkhede; reviewed by junrao

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1303473 13f79535-47bb-0310-9956-ffa450edef68",2012-03-21 17:29:32,Neha Narkhede,Mixed
fedb9d6c19903651e5b27412374aad84994f1320,"KAFKA-307 Refactor server code to reduce interdependencies; patched by nehanarkhede; reviewed by junrao

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1304473 13f79535-47bb-0310-9956-ffa450edef68",2012-03-23 16:46:03,Neha Narkhede,Mixed
a260bfacaee251b4f23236a71651cfb87ce3f6d7,"SyncProducer does not correctly timeout; patched by Prashanth Menon; reviewed by Jun Rao, Neha Narkhede; KAFKA-305

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1305454 13f79535-47bb-0310-9956-ffa450edef68",2012-03-26 17:12:30,Jun Rao,Mixed
d9441f0066604534a8226ce1809eaf68e5a4ada2,"enable shallow iterator in ByteBufferMessageSet to allow mirroing data without decompression; patched by Jun Rao; reviewed by Joel Koshy; KAFKA-315

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1310595 13f79535-47bb-0310-9956-ffa450edef68",2012-04-06 21:18:56,Jun Rao,Mixed
c0e190cdefabc7c59b11bbe0de843baec78efe3f,"Separate out Kafka mirroring into a stand-alone app; patched by Joel Koshy; reviewed by Jun Rao and Neha Narkhede; KAFKA-249

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1310645 13f79535-47bb-0310-9956-ffa450edef68",2012-04-07 00:04:51,Jun Rao,Mixed
79a3b31f267921dedbe8b6ca6af648609bb11dc0,"KAFKA-320 testZKSendWithDeadBroker fails intermittently due to ZKNodeExistsException; patched by nehanarkhede; reviewed by junrao and prashanth menon

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1310661 13f79535-47bb-0310-9956-ffa450edef68",2012-04-07 02:12:26,Neha Narkhede,Mixed
d97c557202e7f20001d2597d09bcbf0bfc123fa9,"KAFKA-320 testZKSendWithDeadBroker fails intermittently due to ZKNodeExistsException; patched by nehanarkhede; reviewed by junrao and prashanth menon

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1310937 13f79535-47bb-0310-9956-ffa450edef68",2012-04-08 02:00:19,Neha Narkhede,Not TDD
d73355017a66fbcdf0a6ad1bafbf3d60fa004b92,"KAFKA-301 Implement broker startup procedure; patched by Neha Narkhede; reviewed by Jun Rao and Jay Kreps

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1329509 13f79535-47bb-0310-9956-ffa450edef68",2012-04-23 23:32:59,Neha Narkhede,Mixed
d6b1de35f6b9cd5370c7812790fea8e61618f461,"Mirroring should use multiple producers; add producer retries to DefaultEventHandler; patched by Joel Koshy; reviewed by Jun Rao; KAFKA-332

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1330083 13f79535-47bb-0310-9956-ffa450edef68",2012-04-25 02:24:47,Jun Rao,Mixed
1bedde76c280181fe5114cd262389f599d8542fb,"KAFKA-48 Patch to add ""long poll"" support to fetch requests. 



git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1332413 13f79535-47bb-0310-9956-ffa450edef68",2012-04-30 21:34:49,Edward Jay Kreps,Mixed
904708fae892417f248b74130da14a165747abcc,"Fix retry logic for producers; patched by Prashanth Menon; reviewed by Jun Rao, Neha Narkhede; KAFKA-49

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1343255 13f79535-47bb-0310-9956-ffa450edef68",2012-05-28 13:45:51,Prashanth Menon,Not TDD
822963bb9dab9c948ecf850ab25b311e9d9fa7ae,"KAFKA-348 merge trunk to branch 1239902:1310937 patch by Joe Stein reviewed by Jun Rao

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1344526 13f79535-47bb-0310-9956-ffa450edef68",2012-05-31 01:51:23,Joe Stein,Mixed
045f4fdca4f8305a537d0e382f88aed3da0965a7,"KAFKA-46: Message replication feature without failures; patched by Neha Narkhede; reviewed by Jun Rao, Jay Kreps, Prashanth Menon

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1344964 13f79535-47bb-0310-9956-ffa450edef68",2012-06-01 01:53:19,Neha Narkhede,Mixed
f99177766aff632831598a1e2e2c929a015b7c68,"Add admin RPC requests; clean up Response objects; patched by Yang Ye; reviewed by Jun Rao; KAFKA-349; KAFKA-336

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1346697 13f79535-47bb-0310-9956-ffa450edef68",2012-06-06 01:28:46,Jun Rao,Mixed
83c82a3ecc734138ed561a69f18ca3ac02a41ddb,"embedded controller; patched by Yang Ye; reviewed by Jun Rao; KAFKA-335

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1350291 13f79535-47bb-0310-9956-ffa450edef68",2012-06-14 15:17:35,Jun Rao,Mixed
965edbbcd8149abe4d9ecd87dcf813fb13874e83,"system test to validate consistency of replicas; patched by John Fung; reviewed by Jun Rao; KAFKA-341

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1350316 13f79535-47bb-0310-9956-ffa450edef68",2012-06-14 16:23:30,Jun Rao,Mixed
efdc57bc58c2812cc01e627b64eaace9a5f92cb4,"KAFKA-348 rebase branch from trunk patch by Jun Rao reviewed by Joe Stein

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1351112 13f79535-47bb-0310-9956-ffa450edef68",2012-06-17 15:32:29,Joe Stein,Mixed
eff68ce1d0ef59e27a49edea4759ad0cd4096b7a,"Create topic support (revisit based on v3 design); patched by Prashanth Menon; reviewed by Jun Rao; KAFKA-329

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1351188 13f79535-47bb-0310-9956-ffa450edef68",2012-06-18 01:17:44,Prashanth Menon,Mixed
505cf9d618c24f532e7b800d8b34a20a40c45feb,"using MultiFetch in the follower; patched by Jun Rao; reviewed by Joel Koshy and Neha Narkhede; KAFKA-339

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1353086 13f79535-47bb-0310-9956-ffa450edef68",2012-06-23 07:14:24,Jun Rao,Mixed
e7efee02c10e2def27d6b301e2f926202dabb9ce,"KAFKA-353 Tie producer-side ack with high watermark and progress of replicas; patched by Joel Koshy; reviewed by Jun Rao, Jay Kreps

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1355578 13f79535-47bb-0310-9956-ffa450edef68",2012-06-29 22:05:57,Joel Jacob Koshy,Mixed
489b09c120992d624fe95ed970b80ec8157131a9,"KAFKA-373 Fix trunk broker failure test to work with mirror maker; patched by John Fung; reviewed by Joel Koshy

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1358407 13f79535-47bb-0310-9956-ffa450edef68",2012-07-06 20:44:51,Joel Jacob Koshy,Not TDD
d79919d82748429589da9907a560e5a5071a4229,"broker failure system test broken on replication branch; patched by John Fung; reviewed by Joel Koshy and Jun Rao; KAFKA-306

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1359812 13f79535-47bb-0310-9956-ffa450edef68",2012-07-10 18:05:54,Jun Rao,Not TDD
3bade0b5c86c1313f52d4488964d9773344542d9,"broker failure system test broken on replication branch; patched by John Fung; reviewed by Joel Koshy and Jun Rao; KAFKA-306

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1359813 13f79535-47bb-0310-9956-ffa450edef68",2012-07-10 18:08:07,Jun Rao,Not TDD
89661d3b678974fe5574fb3e6b85f7cd2e5b2c2c,"ZookeeperConsumerConnector needs to connect to new leader after leadership change; patched by Jun Rao; reviewed by Joel Koshy; KAFKA-362

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1360261 13f79535-47bb-0310-9956-ffa450edef68",2012-07-11 16:16:26,Jun Rao,Mixed
9e44db6af0a91a6071a046eb8b94f042ca223ec9,"KAFKA-352 Unknown topic error code handling for all requests; patched by Neha Narkhede; reviewed by Jay Kreps

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1363507 13f79535-47bb-0310-9956-ffa450edef68",2012-07-19 19:51:12,Neha Narkhede,Not TDD
16b0f44559de969f1fd4387dceda881e6aabdc1c,"KAFKA-371 Refactoring of LogManager. Reviewed by Neha.



git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1363542 13f79535-47bb-0310-9956-ffa450edef68",2012-07-19 21:02:15,Edward Jay Kreps,Not TDD
842da7bfcddb322266ee27bab279c6f4e05b79cb,"KAFKA-350 Enable message replication in the presence of failures; patched by Neha Narkhede; reviewed by Jun Rao and Jay Kreps

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1365199 13f79535-47bb-0310-9956-ffa450edef68",2012-07-24 18:13:01,Neha Narkhede,Mixed
b49de724f12549354836c34aea6f2e0640994e07,"KAFKA-405 Improve high watermark maintenance to store high watermarks for all partitions in a single .highwatermark file; patched by Neha Narkhede; reviewed by Jay Kreps and Jun Rao

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1365841 13f79535-47bb-0310-9956-ffa450edef68",2012-07-25 23:42:07,Neha Narkhede,Mixed
19fbdb30998f6dead6cc788a41617c55bcb20d8e,"deal with empty TopicData list in producer and fetch request; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-412

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1366244 13f79535-47bb-0310-9956-ffa450edef68",2012-07-27 00:16:08,Jun Rao,Not TDD
2a9d42c243397142f80d3f0f96c8d7a6b74d1b02,"revisit the become leader and become follower state change operations using V3 design; patched by Yang Ye; reviewed by Neha Narkhede and Jun Rao; kafka-343

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1367619 13f79535-47bb-0310-9956-ffa450edef68",2012-07-31 15:33:29,Jun Rao,Mixed
c21a7979c18c93336bd1dda5f82627c9ae537b62,"revert commit to KAFKA-343 due to unit test failures

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1367811 13f79535-47bb-0310-9956-ffa450edef68",2012-07-31 22:50:59,Jun Rao,Mixed
96ed9af6201e7ce7bc3cf44c5d5153ffbb95f7fd,"KAFKA-384 Fix intermittent unit test failures and remove Thread.sleep statements; patched by Neha Narkhede; reviewed by Joel Koshy, Jun Rao and Jay Kreps

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1367821 13f79535-47bb-0310-9956-ffa450edef68",2012-07-31 23:27:11,Neha Narkhede,Mixed
0223fd827003b94babdf6cb6624d0f97e936d00a,"recommit: revisit the become leader and become follower state change operations using V3 design; patched by Yang Ye; reviewed by Neha Narkhede and Jun Rao; kafka-343

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1368092 13f79535-47bb-0310-9956-ffa450edef68",2012-08-01 16:13:59,Jun Rao,Mixed
b995133387881222cf3947f5b333a623a6d8407b,"Minor checkin to fix replication system test and jmx tool

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1370941 13f79535-47bb-0310-9956-ffa450edef68",2012-08-08 20:17:31,Neha Narkhede,Not TDD
ee855fe1aa4a4f549c9d91c81ee53f448828d81a,"remove ZK dependency on producer; patched by Yang Ye; reviewed by Jun Rao; KAFKA-369

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1372724 13f79535-47bb-0310-9956-ffa450edef68",2012-08-14 04:17:27,Jun Rao,Mixed
190bd3ff71d85b8e3831e1dbedcce3098f50960f,"KAFKA-385 Fix race condition between checkSatisfied and expire in RequestPurgatory; fixed constant expiration of follower fetch requests as checkSatisfied was not getting called; add metrics to the RequestPurgatory; add a KafkaTimer convenience class; patched by Joel Koshy; reviewed by Jun Rao and Jay Kreps.

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1374069 13f79535-47bb-0310-9956-ffa450edef68",2012-08-16 21:26:40,Joel Jacob Koshy,Mixed
60735b7ad6ef15f25ae9e432c2fc566bec535e31,"enforce broker.id to be a non-negative integer; patched by Swapnil Ghike; reviewed by Jun Rao, Neha Narkhede; KAFKA-424

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1374440 13f79535-47bb-0310-9956-ffa450edef68",2012-08-17 21:09:15,Jun Rao,Not TDD
12a3ccafa1cbc333539b98d83d7d6d572700f05b,"KafkaController NPE in SessionExpireListener; patched by Yang Ye; reviewed by Jun Rao, Neha Narkhede; KAFKA-464

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1374467 13f79535-47bb-0310-9956-ffa450edef68",2012-08-17 23:09:05,Jun Rao,Not TDD
7baccc6c331467335954d32558c68511223d8c7c,"remove support for format for magic byte 0 in 0.8; patched by Swapnil Ghike; reviewed by Jun Rao; KAFKA-461

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1375367 13f79535-47bb-0310-9956-ffa450edef68",2012-08-21 01:52:50,Jun Rao,Not TDD
663d25443359763b2d0fb8adcbdd96cc82dcbda7,"refactor ReplicaManager; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-351

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1375670 13f79535-47bb-0310-9956-ffa450edef68",2012-08-21 17:17:29,Jun Rao,Mixed
5861046d09e82b2bd187177c227bdd1be792d60b,"KAFKA-440 Regression/system test framework; patched by John Fung; reviewed by Neha Narkhede

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1376147 13f79535-47bb-0310-9956-ffa450edef68",2012-08-22 17:16:26,Neha Narkhede,Not TDD
0d6a4dff097d5e46d659db7f7ef922c91ede24e0,"TopicCount.constructTopicCount isn't thread-safe; patched by Jun Rao; reviewed by Joel Koshy and Neha Narkhede; kafka-379

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1376598 13f79535-47bb-0310-9956-ffa450edef68",2012-08-23 17:15:17,Jun Rao,Not TDD
9a84e408c1dff1f32ea030190987501701a1903f,"message size not checked at the server; patched by Swapnil Ghike; reviewed by Jun Rao, Neha Narkhede; KAFKA-469

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1376943 13f79535-47bb-0310-9956-ffa450edef68",2012-08-24 14:32:10,Jun Rao,Mixed
21326cb9f29c3514b9533a741b69b90ef6d45038,"Time based log segment rollout; patched by Swapnil Ghike; reviewed by Jun Rao, Neha Narkhede; KAFKA-475

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1377093 13f79535-47bb-0310-9956-ffa450edef68",2012-08-24 20:38:27,Jun Rao,Mixed
17283a377dc9b2026b3eecdf1d9a32908b3bfc90,"Controller tests throw several zookeeper errors; patched by Yang Ye; reviewed by Jun Rao; KAFKA-416

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1377161 13f79535-47bb-0310-9956-ffa450edef68",2012-08-25 00:24:49,Jun Rao,Not TDD
2756b424a73785be49a4bcfc2d5dae704e64d2d5,"Time based log segment rollout (0.8 branch); patched by Swapnil Ghike; reviewed by Jun Rao, Neha Narkhede; KAFKA-475

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1377165 13f79535-47bb-0310-9956-ffa450edef68",2012-08-25 00:34:27,Jun Rao,Mixed
31b9d124d609b1494cd6f79cdc2a022c7fae8a4f,"maintain HW correctly with only 1 replica in ISR; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-420

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1377166 13f79535-47bb-0310-9956-ffa450edef68",2012-08-25 00:46:08,Jun Rao,Not TDD
d4f3eff171f97c45c977191999f1f03f7b343fd3,"KAFKA-489 Add metrics collection and graphs to the system test framework; patched by Neha Narkhede; reviewed by Jun Rao and John Fung

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1378666 13f79535-47bb-0310-9956-ffa450edef68",2012-08-29 18:07:58,Neha Narkhede,Mixed
4cea1de21a8f1638e9908560de08072e5782ff68,"KAFKA-483 Improvements to the system testing framework; patched by John Fung; reviewed by Neha Narkhede

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1379232 13f79535-47bb-0310-9956-ffa450edef68",2012-08-30 23:47:55,Neha Narkhede,Not TDD
9e54dadf4bffbd0401d4b92fb82b1044c87cccc8,"Handle topic names with / on Kafka server; patched by Swapnil Ghike; reviewed by Jay Kreps and Jun Rao; kafka-495

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1381853 13f79535-47bb-0310-9956-ffa450edef68",2012-09-07 03:48:50,Jun Rao,Mixed
87fa96e29186a9b874caed820cf25d3d6f91b9f3,"Expose different data to fetch requests from the follower replicas and consumer clients; patched by Prashanth Menon; reviewed by Jun Rao; KAFKA-376

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1382828 13f79535-47bb-0310-9956-ffa450edef68",2012-09-10 13:28:44,Prashanth Menon,Not TDD
22e4341ba9f7744314ae0363529333a276bd325d,"KAFKA-498: Controller has race conditions and synchronization bugs; patched by Neha Narkhede; reviewed by Jun Rao

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1382988 13f79535-47bb-0310-9956-ffa450edef68",2012-09-10 17:09:52,Neha Narkhede,Mixed
ba58c9a7040e778b6c8cf9dc59d97858c2617afe,"remove errorcode from ByteBufferMessageSet; patched by Swapnil Ghike; reviewed by Jay Kreps and Jun Rao; KAFKA-458

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1383105 13f79535-47bb-0310-9956-ffa450edef68",2012-09-10 20:47:23,Jun Rao,Mixed
ea14ae8b7fe12b0c1dbb05c89d3d3eb4d7c882f9,"Check max message size on server; patched by Swapnil Ghike; reviewed by Joel Koshy and Jun Rao; KAFKA-490

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1383730 13f79535-47bb-0310-9956-ffa450edef68",2012-09-12 01:30:09,Jun Rao,Mixed
de927e29482f066cc919817e260356ca9248d42f,"Handle topic names with / on Kafka server (0.8 branch); patched by Swapnil Ghike; reviewed by Jay Kreps, Joel Koshy and Jun Rao; KAFKA-495

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1383739 13f79535-47bb-0310-9956-ffa450edef68",2012-09-12 02:14:37,Jun Rao,Mixed
2bc65dab67933e9f9cdade59bd0e45ff99afd338,"Improve Kafka internal metrics; patched by Jun Rao; reviewed by Joel Koshy and Neha Narkhede; KAFKA-203

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1384202 13f79535-47bb-0310-9956-ffa450edef68",2012-09-13 04:27:13,Jun Rao,Mixed
e42c8d5f4e54d3661cb15c7231f9ad306d807790,"revisit broker config in 0.8; patched by Swapnil Ghike; reviewed by Jun Rao; KAFKA-325

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1384624 13f79535-47bb-0310-9956-ffa450edef68",2012-09-14 01:29:07,Jun Rao,Mixed
fb0f176131b1d075e08cc110bbb9b58ce10dccf9,"KAFKA-449: Leader election test

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1384854 13f79535-47bb-0310-9956-ffa450edef68",2012-09-14 17:20:04,Neha Narkhede,Not TDD
c8f75870721ac99286272d1b85d09ce41fad444c,"log.truncateTo needs to handle targetOffset smaller than the lowest offset in the log ; patched by Swapnil Ghike; reviewed by Jun Rao; KAFKA-463

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1386641 13f79535-47bb-0310-9956-ffa450edef68",2012-09-17 14:52:18,Jun Rao,Mixed
b688c3ba045df340bc32caa40ba1909eddbcbec5,"KAFKA-391 Refactor fetch/producer requests to use maps instead of several arrays; patched by Joel Koshy; reviewed by Jun Rao.

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1386806 13f79535-47bb-0310-9956-ffa450edef68",2012-09-17 20:15:59,Joel Jacob Koshy,Mixed
3889a3b34fd358ce512efe8c44c44befc19e3273,"KAFKA-499 Refactor controller; patched by Neha Narkhede; reviewed by Jun Rao

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1387270 13f79535-47bb-0310-9956-ffa450edef68",2012-09-18 17:21:15,Neha Narkhede,Not TDD
0f06136aa87393f3c3ac8be3ab9e0c601a13fd63,"javaapi support for getTopoicMetaData; patched by Swapnil Ghike; reviewed by Jun Rao; KAFKA-500

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1387796 13f79535-47bb-0310-9956-ffa450edef68",2012-09-19 22:15:52,Jun Rao,Mixed
e9d07d72fa3bd29d61b4995abff07ea287853f6b,"KAFKA-534 remove client library directory

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/trunk@1390784 13f79535-47bb-0310-9956-ffa450edef68",2012-09-27 00:21:45,Joe Stein,Mixed
9a4ef48ef145e2fecf3b6f4154e5086c5e00e848,"KAFKA-534 remove client library directory

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1390786 13f79535-47bb-0310-9956-ffa450edef68",2012-09-27 00:22:12,Joe Stein,Mixed
3310531d8752c9d19bf3083f9b0c062c2578ba52,"restrict topic names (reopened); patched by Swapnil Ghike; reviewed by Jun Rao; KAFKA-495

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1390800 13f79535-47bb-0310-9956-ffa450edef68",2012-09-27 01:33:54,Jun Rao,Mixed
14b42f795641e13f9703286a527015cbf99a7788,"getOffset Api should return different latest offset to non-follower and follower consumers. Also, implement a batched version of the getOffset Api. patched by Joel Koshy; reviewed by Jun Rao; KAFKA-501

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1391168 13f79535-47bb-0310-9956-ffa450edef68",2012-09-27 19:20:08,Joel Jacob Koshy,Not TDD
3f1fbb1d077a63d49f2d0dbdca5eb95af1d987f1,"KAFKA-508 split out partiondata from fetchresponse and producerrequest

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1394587 13f79535-47bb-0310-9956-ffa450edef68",2012-10-05 15:27:05,Joe Stein,Not TDD
f64fd3dcbaace1dba7bbd72398bb3e7d28b41d61,"KAFKA-506 Move to logical offsets. Reviewed by Jun and Neha.



git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1395729 13f79535-47bb-0310-9956-ffa450edef68",2012-10-08 19:13:24,Edward Jay Kreps,Mixed
452be9080ea00327834386014657c01f057aaaca,"KAFKA-551 Remove the concept of immutable log segments--now all indexes and message sets are mutable. This allows truncating old segments. Review by Jun and Neha.



git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396102 13f79535-47bb-0310-9956-ffa450edef68",2012-10-09 16:40:56,Edward Jay Kreps,Mixed
542ac86313916b7903a50c1d4f2a4ce5ee2d4ebd,"Upgrade to metrics jar to 3.x to pick up csv reporter fixes; KAFKA-542; patched by Joel Koshy; reviewed by Neha Narkhede.

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396336 13f79535-47bb-0310-9956-ffa450edef68",2012-10-09 21:28:20,Joel Jacob Koshy,Not TDD
5a33bfa9d42b1158273ec24ac9633bd149162488,"KAFKA-543 Avoid sending duplicate topic names in TopicMetadataRequest. Reviewed by Neha.



git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396465 13f79535-47bb-0310-9956-ffa450edef68",2012-10-10 04:24:27,Edward Jay Kreps,Mixed
6ccdc40ae8767138be01f7dab5db1ece771f7c99,"broker needs to know the replication factor per partition; patched by Yang Ye; reviewed by Jun Rao; kafka-510

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396673 13f79535-47bb-0310-9956-ffa450edef68",2012-10-10 16:25:42,Jun Rao,Not TDD
1b4d3c3061d030ce5ebf67c15803fff7f9bca4ac,"KAFKA-502 Adding 30 more system tests, reviewed by Jun and Neha; patched by John Fung

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396687 13f79535-47bb-0310-9956-ffa450edef68",2012-10-10 16:56:57,Neha Narkhede,Not TDD
01a8b8d12377eae66a1924d2e26ed4e94d3f52bc,"Reverting KAFKA-510, to be reapplied after addressing review comments and after KAFKA-42 is checked in

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396704 13f79535-47bb-0310-9956-ffa450edef68",2012-10-10 17:32:10,Neha Narkhede,Not TDD
6d0042b4f4125b3731d3b85a0e741f1dde1413fe,"KAFKA-42 Cluster expansion feature; patched by Neha Narkhede; reviewed by Jun Rao

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396713 13f79535-47bb-0310-9956-ffa450edef68",2012-10-10 18:03:07,Neha Narkhede,Mixed
a1698e2b70341cae20c53fb6b2e890df34b29a3e,"Reverting KAFKA-42 since it accidentally contained changes to metrics package. Didn't catch it due to a stale sbt cache. It is better to redo the patch and then commit

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396726 13f79535-47bb-0310-9956-ffa450edef68",2012-10-10 18:42:57,Neha Narkhede,Mixed
23d7620442df299f43d147a2ad924b2759f7efbd,"KAFKA-42 Cluster expansion feature; patched by Neha; reviewed by Jun

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1396808 13f79535-47bb-0310-9956-ffa450edef68",2012-10-10 21:27:11,Neha Narkhede,Mixed
432423518310a5ed9e8f6fbcf238767b25d63f35,"KAFKA-557 Patch to avoid assigning offsets to Log.appends as part of replication. Reviewed by Neha.



git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1397190 13f79535-47bb-0310-9956-ffa450edef68",2012-10-11 17:40:00,Edward Jay Kreps,Mixed
eb06b93f97808a7071df43621bd09a4f168864f8,"KAFKA-510 Broker needs to know replication factor per partition; patched by Yang Ye; reviewed by Neha Narkhede, Jun Rao and Joel Koshy

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1397372 13f79535-47bb-0310-9956-ffa450edef68",2012-10-11 23:30:23,Neha Narkhede,Not TDD
dd44ec672a95a414972747a23c76cbe74efb37ea,"KAFKA-432 allow consumer to read from followers; patched by Yang Ye; reviewed by Neha and Jun

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1397422 13f79535-47bb-0310-9956-ffa450edef68",2012-10-12 02:56:28,Neha Narkhede,Not TDD
669ae397f8846d8ddc5af350b44bd7c0e442d3aa,"KAFKA-548 remove partition from ProducerRequestPartitionData and FetchResponsePartitionData; patched by Yang Ye; reviewed by Neha and Joel

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1397744 13f79535-47bb-0310-9956-ffa450edef68",2012-10-13 00:21:45,Neha Narkhede,Not TDD
3015d0a447a72fd571e71123bae0e541c46a1830,"KAFKA-43 Move leader to preferred replica; patched by Neha Narkhede; reviewed by Joel Koshy and Jun Rao

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1397747 13f79535-47bb-0310-9956-ffa450edef68",2012-10-13 00:39:41,Neha Narkhede,Not TDD
d1a22b2e3b59c2cf00adabd75d29ddd53938bacb,"KAFKA-569 Split up utils package and do some cleanup. Patch reviewed by Neha.



git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1397765 13f79535-47bb-0310-9956-ffa450edef68",2012-10-13 03:35:02,Edward Jay Kreps,Mixed
98f64070891a34e3a8b3f0483a7f5397b8a6933b,"KAFKA-537 Expose clientId in ConsumerConfig and fix correlation id; patched by Yang Ye; reviewed by Neha Narkhede

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1398893 13f79535-47bb-0310-9956-ffa450edef68",2012-10-16 17:30:46,Neha Narkhede,Not TDD
1b7b43c6e1387baea50fb7c1225411342db5b62b,"KAFKA-541 Move to metrics csv reporter for system tests; patched by Yang Ye; reviewed by Neha, Jun and Joel

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1401138 13f79535-47bb-0310-9956-ffa450edef68",2012-10-23 01:26:08,Neha Narkhede,Mixed
23bce10e779a8be03a3f1883e60c9a5e85cf6fe0,"Change MessageSet.sizeInBytes to Int; patched by Swapnil Ghike; reviewed by Jun Rao; kafka-556

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1401760 13f79535-47bb-0310-9956-ffa450edef68",2012-10-24 16:19:26,Jun Rao,Mixed
adebb7d78a52fc7c5cca1e2368c7e54d64f6a626,"Add more test cases to System Test ; patched by John Fung; reviewed by Jun Rao; KAFKA-571

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1401875 13f79535-47bb-0310-9956-ffa450edef68",2012-10-24 20:56:16,Jun Rao,Not TDD
947ad072af00cb16b818836041be1d48e1e142f4,"Implement clean shutdown in replication; patched by Joel Koshy; reviewed by Jun Rao and Neha Narkhede; KAFKA-340

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1402395 13f79535-47bb-0310-9956-ffa450edef68",2012-10-26 05:23:55,Joel Jacob Koshy,Not TDD
743ac37382113f526d706a7cb65340d1f8880897,"extend DumpLogSegments to verify consistency btw data and index; patched by Yang Ye; reviewed by Neha Narkhede and Jun Rao; KAFKA-577

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1403553 13f79535-47bb-0310-9956-ffa450edef68",2012-10-29 22:09:43,Jun Rao,Not TDD
ddabfa7da5580fc633a184ba6a031a93863d5415,"Partition.makeFollower() reads broker info from ZK; patched by Swapnil Ghike; reviewed by Jun Rao; KAFKA-575

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1403598 13f79535-47bb-0310-9956-ffa450edef68",2012-10-30 01:28:01,Jun Rao,Not TDD
414e9faf9badd67bdfd4f0d055a771a41775165e,"KAFKA-588 Fix bug in OffsetIndex.truncateTo. Reviewed by Neha.



git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1403859 13f79535-47bb-0310-9956-ffa450edef68",2012-10-30 20:18:45,Edward Jay Kreps,Mixed
75fc5eab35aa33cffd9c09a2070dfe287db0ef4e,"KAFKA-188 Support multiple data directories. 
Patch reviewed by Neha and Jun.



git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1405102 13f79535-47bb-0310-9956-ffa450edef68",2012-11-02 19:01:38,Edward Jay Kreps,Mixed
ed6243852af125c0399b9ceae817f863043b2373,"KAFKA-593 Empty log index file created when it shouldn't be empty; Patched by Yang Ye; reviewed by Jun and Jay

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1406036 13f79535-47bb-0310-9956-ffa450edef68",2012-11-06 03:43:15,Neha Narkhede,Mixed
6800b0ed3b2519952c3253023c4fda06627bc1e0,"Fix commit() in zk consumer for compressed messages; patched by Swapnil Ghike; reviewed by Jun Rao; KAFKA-546

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1406940 13f79535-47bb-0310-9956-ffa450edef68",2012-11-08 06:19:55,Jun Rao,Mixed
1cc8c3beab1cf42d8f6d3216af081b767761693c,"Add test cases to test log size retention and more; patched by John Fung; reviewed by Jun Rao; KAFKA-591

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1407680 13f79535-47bb-0310-9956-ffa450edef68",2012-11-09 22:58:23,Jun Rao,Not TDD
6c97767b88de625ea5101999ace7fb78744b75b5,"Remove custom metrics jar and replace with latest from metrics HEAD; patched by Joel Koshy; reviewed by Jun Rao; KAFKA-585.

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1409296 13f79535-47bb-0310-9956-ffa450edef68",2012-11-14 18:57:48,Joel Jacob Koshy,Not TDD
f4ccf21d5d65ae313b2a400eb831df6d2d3daa67,"KAFKA-544 Store the key given to the producer in the message. Expose this key in the consumer. Patch reviewed by Jun.



git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1410055 13f79535-47bb-0310-9956-ffa450edef68",2012-11-15 22:15:14,Edward Jay Kreps,Mixed
60d0587e8fca7197683b55e00537c32ddee4795d,"KAFKA-545 Add some log performance tests.



git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1410088 13f79535-47bb-0310-9956-ffa450edef68",2012-11-15 22:54:45,Edward Jay Kreps,Not TDD
e13ecfc1df8966c91384e9c7787f9026b0c500ab,"System Test - Log Retention Cases should wait longer before getting the common starting offset in replica log segments; patched by John Fung; reviewed by Jun Rao; KAFKA-605

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1410547 13f79535-47bb-0310-9956-ffa450edef68",2012-11-16 19:38:14,Jun Rao,Not TDD
8e7b0d40169f93710d08ee36e53b4a16c1d3a344,"KAFKA-532 Multiple controllers can co-exist during soft failures; patched by Neha Narkhede; reviewed by Jun Rao

git-svn-id: https://svn.apache.org/repos/asf/incubator/kafka/branches/0.8@1411010 13f79535-47bb-0310-9956-ffa450edef68",2012-11-18 22:48:20,Neha Narkhede,Mixed
bdb04bba67326bdf1451df3ec4a855ed3c109869,"ProducerRequest should take ByteBufferMessageSet instead of MessageSet; patched by Jun Rao; reviewed by Neha Narkhede; KAFKA-632

git-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1414917 13f79535-47bb-0310-9956-ffa450edef68",2012-11-28 21:05:17,Jun Rao,Not TDD
d7c71c0949e0cbae8963ca76bc69d64bee8f10af,"KAFKA-622 Create mbeans per client; patched by Swapnil; reviewed by Neha Narkhede

git-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1415021 13f79535-47bb-0310-9956-ffa450edef68",2012-11-29 01:31:18,Neha Narkhede,Mixed
6486fd1a9f503af24c83d16a014a6405ae07cf9b,"KAFKA-640 kafka.common.InvalidClientIdException in broker log4j messages; patched by Swapnil; reviewed by Neha Narkhede

git-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1415765 13f79535-47bb-0310-9956-ffa450edef68",2012-11-30 17:49:49,Neha Narkhede,Not TDD
6ca7b3acfdfe34752c42a0a1a26ea991b8e4c3b1,"KAFKA-608 and KAFKA-630 getTopicMetadata does not respect producer config settings and fix auto-create topic; patched by Neha Narkhede; reviewed by Jun Rao

git-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1415909 13f79535-47bb-0310-9956-ffa450edef68",2012-12-01 02:04:19,Neha Narkhede,Mixed
4be0b1be29e301500515b6c5e00655b06e829045,"KAFKA-521 Refactor the log subsystem. Patch reviewed by Neha.



git-svn-id: https://svn.apache.org/repos/asf/kafka/trunk@1416253 13f79535-47bb-0310-9956-ffa450edef68",2012-12-02 20:50:01,Edward Jay Kreps,Mixed
494706999c43003f1f16ce3558bebe39421ff3eb,"KAFKA-521 Missing files on last commit.



git-svn-id: https://svn.apache.org/repos/asf/kafka/trunk@1416254 13f79535-47bb-0310-9956-ffa450edef68",2012-12-02 20:55:27,Edward Jay Kreps,Mixed
e11447650a9a9fbaebff0e5c6a369375e087f1ae,"KAFKA-642 Fixes to protocol. Patch reviewed by Neha and Joel.



git-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1417734 13f79535-47bb-0310-9956-ffa450edef68",2012-12-06 04:23:44,Edward Jay Kreps,Mixed
f5a48b06e31ebe925dc99abfb6518f6057871318,"KAFKA-642 Remove the response version and baseline all versions/magic bytes etc to 0.


git-svn-id: https://svn.apache.org/repos/asf/kafka/branches/0.8@1418181 13f79535-47bb-0310-9956-ffa450edef68",2012-12-07 04:01:29,Edward Jay Kreps,Not TDD
a10be4b69c904a596af198feaac4cef4c391bf4c,"KAFKA-597 Refactor scheduler. Fixes a couple of bugs, and adds the ability to mock scheduled tasks.



git-svn-id: https://svn.apache.org/repos/asf/kafka/trunk@1419692 13f79535-47bb-0310-9956-ffa450edef68",2012-12-10 19:31:29,Edward Jay Kreps,Mixed
ac35ae1fef0294cc5a33908209598f938dc7d84c,"KAFKA-636 Make log segment delete an asynchronous background action done by the scheduler. Patch reviewed by Jun and Neha.


git-svn-id: https://svn.apache.org/repos/asf/kafka/trunk@1420361 13f79535-47bb-0310-9956-ffa450edef68",2012-12-11 19:47:13,Edward Jay Kreps,Mixed
3244bcafe4233611fc0366f9df53ec98b44ca571,KAFKA-670 Clean spurious .index files; reviewed by Neha Narkhede,2012-12-13 10:15:32,Edward Jay Kreps,Mixed
739b2df6806c10b934f69e6181555fccb85cd9b8,KAFKA-374 Move off the default java crc implementation to the crc code borrowed from Hadoop. Patch reviewed by Joe.,2012-12-16 11:28:16,Jay Kreps,Not TDD
8ad9018ea197676bdc4e57ccf985dc752e54e5c7,KAFKA-646 Provide aggregate stats at the high level Producer and ZookeeperConsumerConnector level; reviewed by Neha Narkhede,2012-12-17 14:05:17,Swapnil Ghike,Mixed
9001d74839772d148443d3d86aca48f5dbbc890b,KAFKA-647 Provide a property in System Test for no. of topics and topics string will be generated automatically; reviewed by Neha Narkhede,2012-12-17 14:12:27,John Fung,Not TDD
994fe081b6e429ba1cfd5c09d464015c41e64cf7,KAFKA-646 Missing files from previous commit,2012-12-17 15:53:12,Swapnil Ghike,Mixed
04b52743f8eaa9057b0b5687fb3681e1bd1e2d49,"KAFKA-664 RequestPurgatory should clean up satisfied requests from watchers map. Also, simplify the purge logic - purge based on an incoming request interval.",2012-12-17 16:35:32,Joel Koshy,Not TDD
c6d41102d81ac48b345d3f42d669e6a6bbfbe062,"KAFKA-675 Allow the user to override the host that we bind to. Patch from Matan Amir<matan.amir@voxer.com> with slight changes
to improve error messages for a bad host or port.",2012-12-20 14:13:22,Jay Kreps,Mixed
25d77cc69c5f12394f55e22516fc90fd3c272166,KAFKA-668 Store jmx port in broker zk string - controlled shutdown admin tool should not require controller JMX url/port to be supplied. Reviewed by Jun Rao.,2013-01-02 14:08:46,Joel Koshy,Mixed
2f4bfc645a597892c3b0a8dfe722158f3b993874,ApiUtils#writeShortString uses String length instead of byte length; kafka-680; patched by David Arthur; reviewed by Jun Rao,2013-01-04 13:39:07,Jun Rao,Mixed
222c0e46ab78a12e1f58e3fb526667a4f73d344a,KAFKA-657 Add APIs for the consumer to commit and fetch offsets on the broker.,2013-01-04 14:30:03,David Arthur,Mixed
e0b3b6316342271d798af10494c0ceab13e1eb02,"KAFKA-690 TopicMetadataRequest throws exception when no topics are specified, reviewed by Jay Kreps and Neha Narkhede",2013-01-09 08:49:11,Neha Narkhede,Mixed
03eb903ce223ab55c5acbcf4243ce805aaaf4fad,KAFKA-683 Fix correlation id in all requests sent to kafka; reviewed by Jun Rao,2013-01-11 14:06:00,Neha Narkhede,Mixed
a40953196e1ef558eb61b78219a20c20a4bd63df,Use uniform convention for naming properties keys; kafka-648; patched by Sriram Subramanian; reviewed by Jun Rao,2013-01-11 16:12:57,Jun Rao,Mixed
b2eec991d35e7d17b3cfc05438d81637a056aa83,ConsoleConsumer throws InvalidConfigException; kafka-697; patched by Swapnil Ghike; reviewed by Jun Rao,2013-01-15 09:45:28,Jun Rao,Mixed
eeb817ac23f4aa756ebe404a85eeb618a7cb5a08,"KAFKA-697 ConsoleConsumer throws InvalidConfigException for . in client id; reviewed by Jun Rao, Neha Narkhede, John Fung",2013-01-15 09:45:46,Swapnil Ghike,Mixed
214a0af46b98aa9eaf54d0fbe982bc8ba2ae0a74,Consumer rebalance fails if no leader available for a partition and stops all fetchers; patched by Maxime Brugidou; reviewed by Jun Rao; kafka-693,2013-01-17 09:36:01,Jun Rao,Mixed
eb0d5a7f815ac51e3bdcf7bb2c1d3af9f33f2d83,KAFKA-708 ISR becomes empty while marking a partition offline; reviewed by Jun Rao,2013-01-23 13:47:27,Neha Narkhede,Mixed
311a5d81d8a8b34e18e1ad2fdc491661477de83c,KAFKA-727 broker can still expose uncommitted data to a consumer; reviewed by Neha Narkhede,2013-01-23 14:07:26,Edward Jay Kreps,Not TDD
e7edb5e1e933f5535378d546bcf4d8b178d2e69c,KAFKA-631 Implement a log cleaner for Kafka. Reviewed by Neha.,2013-01-28 19:31:17,Jay Kreps,Mixed
2ae069024120a7c9775ac53966f0af08435f2e5b,System Test : Disable shallow.iterator in Mirror Maker test cases to make compression work correctly; patched by John Fung; reviewed by Jun Rao; kafka-737,2013-01-29 18:01:28,Jun Rao,Not TDD
790a1504c3437b84ce2d910b9769a2b4ae481ed3,KAFKA-748 Maintain mmap position after resizing index. Also add a few more assertions.,2013-02-08 10:50:38,Jay Kreps,Mixed
828ce83dcb442d1cc6c0dbc538d12bbb04a0884d,standardizing json values stored in ZK; patched by Swapnil Ghike; reviewed by Jun Rao; kafka-755,2013-02-22 16:43:54,Jun Rao,Mixed
4d8fb1eebc043fab11c58d3309e93cc83ef24a89,KAFKA-736 Add an option to the 0.8 producer to mimic 0.7 producer behavior; reviewed by Jun Rao and Sriram Subramanian,2013-02-22 17:48:10,Neha Narkhede,Mixed
d925b157f42b13cb410a86e8850c23a11de3d2f1,"KAFKA-734 Migration tool needs a revamp, it was poorly written and has many performance bugs; reviewed by Jun Rao",2013-02-24 14:27:21,Neha Narkhede,Mixed
218e6a53c1385be897d9f8a3a39baa38b68d7992,KAFKA-771 NPE in handleOffsetCommitRequest; reviewed by Neha Narkhede,2013-02-24 18:10:29,David Arthur,Not TDD
89622c8e88ddddeddb8c3449ef1782c1d399c2b0,"KAFKA-671 DelayedProduce requests should not hold full producer request data; reviewed by Neha Narkhede, Jun Rao and Jay Kreps",2013-02-26 17:36:15,Sriram Subramanian,Not TDD
2457bc49ef39c70622816250025eefc3bfcc7640,KAFKA-513 Add state change log to Kafka brokers; reviewed by Neha Narkhede,2013-03-06 09:35:35,Swapnil Ghike,Not TDD
eae1bd52ef1d991834151898e768e57de8bb07bf,Standardize Zk data structures for Re-assign partitions and Preferred replication election; patched by Swapnil Ghike; reviewed by Jun Rao; kafka-779,2013-03-06 12:54:39,Swapnil Ghike,Mixed
771760ce23f00ba86b916420d8e209b2611b23c0,MirrorMaker with shallow.iterator.enable=true produces unreadble messages; patched by Jun Rao; reviewed by Neha Narkhede; kafka-732,2013-03-06 16:08:56,Jun Rao,Mixed
19ae1959b091df44475243e3b199d6121ddedc72,Include controllerId in all requests sent by controller; patched by Swapnil Ghike; reviewed by Jun Rao; kafka-793,2013-03-07 18:20:33,Swapnil Ghike,Not TDD
c1ed12e44ddebe41dc464683e3d7eeb4e6d39a45,KAFKA-554 Dynamic per-topic configuration. This patch adds a mechanism for storing per-topic configurations in zookeeper and dynamically making config changes across the cluster. Reviewed by Neha and Jun.,2013-03-08 15:07:39,Jay Kreps,Mixed
9ff4e8eb10e0ddd86f257e99d55971a132426605,KAFKA-739 Handle null message payloads in messages and in the log cleaner. Reviewed by Jun and Neha.,2013-03-12 11:17:12,Jay Kreps,Mixed
46ebdc16e99c4bb9236a6c25c47ff2c97fdc0f53,Incorrect index in the log of a follower; patched by Jun Rao; reviewed by Neha Narkhede and Jay Kreps; kafka-804,2013-03-18 15:53:03,Jun Rao,Mixed
28ee7855360b8e6ea690fc802dac4eaa60ad81e2,kafka-813; Minor cleanup in Controller; patched by Swapnil Ghike; reviewed by Neha Narkhede and Jun Rao,2013-03-25 09:31:57,Swapnil Ghike,Not TDD
26c50fac47802e4aa03793c60cb8316995bb37f1,kafka-791; Fix validation bugs in System Test; patched by John Fung; reviewed by Jun Rao,2013-03-25 14:08:24,John Fung,Not TDD
2fe3f9fef6e641ed64aca654b607c4d398e11d25,KAFKA-828 Preferred Replica Election does not delete the admin path on controller failover; reviewed by Neha Narkhede and Jun Rao,2013-03-28 08:51:00,Swapnil Ghike,Not TDD
6e05d7da865898c1c44f552c735484dfe2603b60,kafka-832; 0.8 Consumer prevents rebalance if consumer thread is blocked or slow; patched by Jun Rao; reviewed by Neha Narkhede,2013-03-28 16:34:47,Jun Rao,Mixed
afecc9f23108b100b27017974b132331d6bab8e6,KAFKA-844 System Test - Mirror Maker cases enhancements; reviewed by Neha Narkhede,2013-04-04 16:19:00,John Fung,Not TDD
6dbf9212ae4dc6ed7f91fc99135b8a3b35ab5edb,"KAFKA-826 Make Kafka 0.8 depend on metrics 2.2.0 instead of 3.x; reviewed by Swapnil Ghike, Neha Narkhede, Matt Christiansen, Scott Carey",2013-04-09 16:07:58,Neha Narkhede,Not TDD
ede85875a3aea5723baf82736cc71bb1a04a6102,KAFKA-872; Socket server should set send/recv socket buffer sizes; reviewed by Jun Rao.,2013-04-23 10:40:47,Joel Koshy,Mixed
2d7403174f8fd6d35fce05585a7ee6edb8af7dd4,kafka-871; Rename ZkConfig properties; patched by Swapnil Ghike; reviewed by Jun Rao,2013-04-25 18:57:31,Swapnil Ghike,Mixed
a61e7381382ada885debef15379675fea6974ec1,"change to standardize on [%s,%d] for partition",2013-04-29 11:09:19,Neha Narkhede,Mixed
cfdc403e1780882f62df6e9a092cda6bea017fbe,KAFKA-901 Kafka server can become unavailable if clients send several metadata requests; reviewed by Jun Rao,2013-05-17 15:45:33,Neha Narkhede,Mixed
eff59330f2ce19e7074d74f4d268774dd260bca7,KAFKA-901: Follow up minor changes,2013-05-17 16:59:40,Neha Narkhede,Not TDD
4f387ae43544c422b1845b3da5ab09aee8e4acd0,kafka-927; Integrate controlled shutdown into kafka shutdown hook; patched by Sriram Subramanian; reviewed by Neha Narkhede and Jun Rao,2013-06-03 16:08:37,Sriram Subramanian,Not TDD
fb37ea8c749c41b1e34158debc7e9221b4db8f31,"KAFKA-905 Logs can have same offsets causing recovery failure; reviewed by Jun, Neha and Jay",2013-06-03 17:05:17,Neha Narkhede,Mixed
9bd2a11486420a313f800d734cab8a858fac6d0e,kafka-931; make zookeeper.connect a required property; patched by Jun Rao; reviewed by Neha Narkhede,2013-06-03 18:40:16,Jun Rao,Mixed
23acbd309f5e17de71db46cb6f1a60c8d38ea4e4,KAFKA-941 Add Apache 2.0 license to missing code source files,2013-06-13 16:05:56,Joe Stein,Mixed
3817857b15f9ce03f10a9730f0ff4619d728b06f,"kafka-347; change number of partitions of a topic online; patched by Sriram Subramanian; reviewed by Neha Narkehede, Guozhang Wang, Joel Koshy and Jun Rao",2013-07-22 21:33:28,Sriram Subramanian,Mixed
ce7d588055e7d3aacebcc696665b1260fa2e9063,kafka-883; System Test - update migration tool testsuite after 0.7 ProducerPerformance sends seq MessageID; patched by John Fung; reviewed by Jun Rao,2013-07-23 10:32:30,John Fung,Not TDD
d285e263bf403f3db27f5d138594c395643a2284,KAFKA-925 Add a partition key that overrides the message's stored key. Patch reviewed by Joel.,2013-07-29 15:32:36,Jay Kreps,Not TDD
14af713252f016929f8150f2f6c2df9d0d447ddb,"Misc. minor house-keeping fixes: add reasonable GC settings, fix up README, fix up example configs, fix the logging for tools, use a log directory for logs instead of the root directory.",2013-08-05 10:10:18,Jay Kreps,Not TDD
df18fe13ad50bba3dbc7d1db0ecd8b698169ade2,KAFKA-615 fsync asynchronous from log roll. Patch reviewed by Jun and Sriram.,2013-08-05 21:31:52,Jay Kreps,Mixed
81c49bbdae5e490f9d5dc7b042ee60e617fbb22b,KAFKA-992 follow up: Fix the zookeeper de-registration issue for controller and consumer; reviewed by Neha Narkhede,2013-08-08 22:06:12,Guozhang Wang,Not TDD
1d75e09313b5b3f1cde6c39fdda20bc7185cfdf6,"Revert ""KAFKA-992 follow up: Fix the zookeeper de-registration issue for controller and consumer; reviewed by Neha Narkhede""

This reverts commit 81c49bbdae5e490f9d5dc7b042ee60e617fbb22b.",2013-08-09 15:29:08,Neha Narkhede,Not TDD
1db824ed2fcdaa45c3b1d0dcbf9101299fded09c,KAFKA-992 followup: Fix zookeeper de-registration bug for controller and consumer; reviewed by Neha Narkhede,2013-08-09 15:44:11,Guozhang Wang,Not TDD
f89ddced1ba058f0c51697957cde8bb2e2b05c4d,"KAFKA-955 After a leader change, messages sent with ack=0 are lost; reviewed by Jay Kreps, Neha Narkhede and Jun Rao",2013-08-28 10:16:59,Guozhang Wang,Not TDD
c12d2ea9e5b4bdcf9aeb07c89c69553a9f270c82,KAFKA-1046 Added support for Scala 2.10 builds while maintaining compatibility with 2.8.x; reviewed by Neha and Jun,2013-09-09 15:21:05,Christopher Freeman,Mixed
8e554c4d2acf5108805905b9f06198f20398ee3a,KAFKA-1046 Added support for Scala 2.10 builds while maintaining compatibility with 2.8.x; reviewed by Neha and Jun,2013-09-13 12:55:53,Christopher Freeman,Mixed
40efe0a972e8a1673b51b05f3937265d97acb01c,trivial follow-up patch for kafka-1073 to fix unit tests; patched by Jun Rao,2013-10-07 14:00:14,Jun Rao,Not TDD
c304a92a1ce39cc7b7e329fde0b97f93cb8caee3,Move AddPartitions into TopicCommand,2013-10-08 23:42:34,Sriram Subramanian,Mixed
8d4dbe60f188c48a7f0d552b7b1109fb8e126521,kafka-1052; integrate add-partitions command into topicCommand; patched by Sriram Subramanian; reviewed by Jun Rao,2013-10-09 20:44:49,Sriram Subramanian,Mixed
3e7c9c6abfed90b4e6e0e1bb3c806adf1c6bbbe9,KAFKA-1081 Clean up shell scripts. Removed re-run of failed command. Use exec instead of subprocess execution.,2013-10-14 09:39:10,Jay Kreps,Not TDD
c98b6de15db9a2ce72f44a5b2736f74de5066113,KAFKA-1008 Lock around unmap on windows.,2013-10-15 14:06:48,Jay Kreps,Mixed
d5dfa28596857d5564c14b598901653714717bdc,KAFKA-1089; Fix run-class and log4j for migration tool system test; reviewed by Jun Rao,2013-10-16 09:36:40,Joel Koshy,Not TDD
d030778861e6d274281adf7e0311dc4d51448c84,"KAFKA-1042 logSegments(from, to) Misses first segment.

I think this patch also fixes the continual timing problems we have had in log tests. The root cause
was that we weren't passing through the clock instance so we were mixing instances of MockTime and SystemTime.
This worked only because MockTime initializes to SystemTime.milliseconds so as long as the test took less than 1 ms it worked!",2013-10-18 11:33:50,Jay Kreps,Mixed
274b12f3351e007f76e8ef64ba9baf5b0824e690,kafka-918; Change log.retention.hours to be log.retention.mins; patched by Alin Vasile; reviewed by Jun Rao,2013-10-25 08:12:36,Alan Vasile,Mixed
a55ec0620f6ce805fafe2e1d4035ec3e0ab4e0d0,kafka-1092; Add server config parameter to separate bind address and ZK hostname; patched by Roger Hoover; reviewed by Jun Rao,2013-10-30 21:06:23,Roger Hoover,Mixed
ec547737de730cddb29200eba62c0165f901447b,KAFKA-1107 Broker unnecessarily recovers all logs when upgrading from 0.8 to 0.8.1; reviewed by Jay Kreps and Guozhang Wang,2013-10-31 21:14:17,Neha Narkhede,Mixed
a4fafefdb3a2701d30f14feed3be11f1c0905c31,KAFKA-1107 Follow up review cleanup comments,2013-10-31 21:27:38,Neha Narkhede,Mixed
7c54e39bd48c9908c220ee68cee608a0d0cf5d9d,"KAFKA-1112; broker can not start itself after kafka is killed with -9; patched by Jay Kreps and Jun Rao; reviewed by Jay Kreps, Neha Narkhede and Guozhang Wang",2013-11-18 18:31:32,Jun Rao,Mixed
9b0776d157afd9eacddb84a99f2420fa9c0d505b,"kafka-1135; Code cleanup - use Json.encode() to write json data to zk; patched by Swapnil Ghike; reviewed by Neha Narkhede, Guozhang Wang and Jun Rao",2013-11-20 10:05:40,Swapnil Ghike,Mixed
cd81d37ac872654c0cc68fab830ee457c56b7c6a,fix for scala 2.10.1 compilation issued introduced in kafka-1117,2013-11-20 21:42:46,Jun Rao,Not TDD
87efda7f818218e0868be7032c73c994d75931fd,kafka-1103; Consumer uses two zkclients; patched by Guozhang Wang; reviewed by Joel Koshy and Jun Rao,2013-11-22 09:16:39,Guozhang Wang,Mixed
583044cd5109cd060bdfc9e516f4c85d1d4e73a0,recommit kafka-1112 since it's inadvently reverted in the commit of kafka-1135,2013-11-25 15:34:04,Jun Rao,Mixed
df288b75a0c6685deeda99ce4db3e17fff39b0ad,kafka-1140; Move the decoding logic from ConsumerIterator.makeNext to next; patched by Guozhang Wang; reviewed by Jun Rao,2013-11-27 21:56:55,Guozhang Wang,Mixed
32aae7202ce041128fb1f6d2ea43580ee7864d74,KAFKA-1170 ISR can be inconsistent during partition reassignment for low throughput partitions; reviewed by Jun Rao and Guozhang Wang,2013-12-06 16:26:53,Neha Narkhede,Not TDD
6bc290f66d738a9133afe93e2a6ac64f1344c111,KAFKA-1178 Replica fetcher thread dies while becoming follower; reviewed by Jun Rao and Guozhang Wang,2013-12-11 11:18:24,Neha Narkhede,Not TDD
f63e3f730673f60ca179030cf0d64380689c2a40,"kafka-1074; Reassign partitions should delete the old replicas from disk; patched by Jun Rao; reviewed by Jay Kreps, Neha Narkhede and Guozhang Wang",2014-01-07 22:36:00,Jun Rao,Mixed
269d16d3c915d09f650ae32aa81542bd8522ca68,KAFKA-1227 New producer!,2014-01-28 11:15:05,Jay Kreps,Mixed
9c1d8e35c5913d22098cf80ae69035131cfee87f,KAFKA-1184 High-Level Consumer: expose fetcher threads number as a parameter; reviewed by Neha Narkhede,2014-01-30 08:37:28,Evelina Stepanova,Not TDD
253f86e31062fb86401abdc13835c251eef47417,Implement a few of the API suggestions from the mailing list.,2014-02-04 08:39:56,Jay Kreps,Mixed
3220af1fe2fad8da1f5bcc101ab9d3e8919b03bd,TRIVIAL: Fix misc. numerical issues in histogram.,2014-02-06 10:49:37,Jay Kreps,Mixed
fa6339c19cd06880d32ec9a5ee6b66e7f1488dcf,Rename client package from kafka.* to org.apache.kafka.*,2014-02-06 16:25:11,Jay Kreps,Mixed
167acb832d7f104eb2c344dcfd7b914c763d881d,"KAFKA-330 Delete topic; reviewed by Jun Rao, Guozhang Wang and Joel Koshy",2014-02-06 20:18:24,Neha Narkhede,Mixed
36eae8f63c81f8d38c2351054c15bf7d5eb612d9,trivial fix to add missing license header using .gradlew licenseFormatMain and ./gradlew licenseFormatTest; patched by Jun Rao,2014-02-07 14:19:06,Jun Rao,Mixed
1a7048d41bb56118d4f31ff972618ebe13007857,KAFKA-330 Delete topic followup - more tests and Joel's review comments,2014-02-08 11:09:39,Neha Narkhede,Not TDD
6b80dbb97b3d9b533f60d5c09639ea6c7c5f2be5,KAFKA-1236 Fix various breakages in the perf tests. Make the producer test use either the old or the new producer.,2014-02-10 20:49:08,Jay Kreps,Not TDD
a0939f412d7c5c0e294f7d1c2779ae9321338155,KAFKA-1233 Integration test for the new producer; reviewed by Jay Kreps and Neha Narkhede,2014-02-11 14:25:40,Guozhang Wang,Not TDD
3f0b67b6ac864befccfdd4bb5dee08c0b33c3b43,KAFKA-1252 Implement retries in new producer.,2014-02-18 17:18:13,Jay Kreps,Mixed
6ab9b1ecd89c74a42233fc792684e7a8757e9460,kafka-1235; Enable server to indefinitely retry on controlled shutdown; patched by Guozhang Wang; reviewed by Jun Rao,2014-02-20 17:44:41,Guozhang Wang,Not TDD
3955915a5f8a0daa7b96be69a87b3fbd013c9501,KAFKA-1279 Socket server should close all connections when it is shutdown.,2014-02-24 14:44:32,Jay Kreps,Mixed
edbed2823fc3e4948bb56ec3bee02fe4ad1bbdca,kafka-1278; More flexible helper scripts; patched by Nathan Brown; reviewed by Jun Rao,2014-02-25 09:37:15,Nathan Brown,Not TDD
5e2a9a560d847bd0cf364d86bd6784f70d99c71a,"KAFKA-1260 Integration Test for New Producer Part II: Broker Failure Handling; reviewed by Jay Kreps, Neha Narkhede and Jun Rao",2014-02-27 10:50:26,Guozhang Wang,Not TDD
77118a935ee28da80c67d4050f41a1e7e838ebaa,"KAFKA-1289 Misc. nitpicks in log cleaner for new 0.8.1 features patch by Jay Kreps, reviewed by Sriram Subramanian and Jun Rao",2014-03-04 15:30:59,Joe Stein,Mixed
5ba48348b3abb8f84fda0798d992ff2e0a04051d,"KAFKA-1286 Retry can block. Patch from Guozhang, reviewed by jay.",2014-03-04 20:07:00,Jay Kreps,Mixed
74c54c7eeb236cbf66710751165ea9f632cf3f52,KAFKA-1281 add the new producer to existing tools; reviewed by Jun Rao and Guozhang Wang,2014-03-06 18:08:55,Neha Narkhede,Not TDD
c765d7bd4e30e0b952fc4bc00d142f7939b498a6,kafka-1240; Add ability to existing system tests to use the new producer client; patched by Jun Rao; reviewed by Neha Narkhede,2014-03-06 19:06:25,Jun Rao,Not TDD
a670537aa33732b15b56644d8ccc1681e16395f5,"KAFKA-1012; Consumer offset management in Kafka; patched by Tejas Patil and Joel Koshy; feedback and reviews from Neha Narkhede, Jun Rao, Guozhang Wang, Sriram Subramanian, Joe Stein, Chris Riccomini",2014-03-14 15:14:33,Joel Koshy,Mixed
616086b909252eeee2cb05f379659a2de2c7bd83,KAFKA-1028 per topic configuration of preference for consistency over availability; reviewed by Neha Narkhede and Jay Kreps,2014-03-17 18:40:59,Andrew Olson,Mixed
423d9d5af9481b782c7655dc2410e61e1b48a0bb,KAFKA-1309; Fix cross-compilation issue (due to use of deprecated JavaConversions API in javaapi.OffsetCommitRequest; reviewed by Neha Narkhede,2014-03-18 10:38:03,Joel Koshy,Mixed
cc859dcca791dc8e1e6eeabe8b88387a11241b24,"kafka-1307; potential socket leak in new producer and clean up; reviewed by Jay Kreps, Guozhang Wang and Neha Narkhede",2014-03-18 10:52:34,Jun Rao,Mixed
4484916d656243384d91e172a8e0b7ca240785f0,KAFKA-1311 Add a flag to turn off delete topic until it is stable; reviewed by Joel Koshy and Guozhang Wang,2014-03-18 17:31:35,Neha Narkhede,Not TDD
d9be502bcc6b9d7e5716c01d2273189c00506f53,KAFKA-1315 log.dirs property in KafkaServer intolerant of trailing slash; reviewed by Neha Narkhede and Guozhang Wang,2014-03-20 17:34:38,Timothy Chen,Mixed
466a83b78c2bfcb9ac3116748394e7845a99bf7a,KAFKA-1253 Compression in the new producer; reviewed by Jay Kreps and Jun Rao,2014-03-26 21:49:06,Guozhang Wang,Mixed
9bc47bc1365d17c34f8d43239846de28219a663c,KAFKA-1253 Compression in the new producer: follow up patch to push new files,2014-03-26 21:50:30,Neha Narkhede,Not TDD
23d7fc470638c4dffa5ca005ef2e3d34c14dc92e,KAFKA-1251: Add metrics to the producer.,2014-03-27 20:52:42,Jay Kreps,Mixed
fb92b3a2cdf571715b948f81f1f8bb4bc363d497,"KAFKA-1317 KafkaServer 0.8.1 not responding to .shutdown() cleanly, possibly related to TopicDeletionManager or MetricsMeter state; reviewed by Neha Narkhede",2014-03-28 18:13:19,Timothy Chen,Not TDD
083b6265c93619dd8b672c59fc31f0ed3d5da29b,KAFKA-1341 Client Selector doesn't check connection id properly; reviewed by Jay Kreps and Neha Narkhede,2014-03-31 22:36:42,Timothy Chen,Mixed
bd784aeb20b6a4252675c681116b47ea86402130,"kafka-1318; waiting for producer to stop is not reliable in system tests; patched by Jun Rao; reviewed by Guozhang Wang, Timothy Chen and Neha Narkhede",2014-04-01 11:40:03,Jun Rao,Not TDD
640f3b05efd00d5e1d7bfc8fe9c90c7aadc3d087,KAFKA-1337 Rationalize the producer configs.,2014-04-04 13:55:47,Jay Kreps,Mixed
8f94bc3315e7d469489da55f94e08a51235c01f3,KAFKA-1366 Multiple Unit Test failures with new producer; reviewed by Neha Narkhede,2014-04-08 10:15:08,Guozhang Wang,Mixed
0e1d853c04cb2fe86cf98f0b1006a96e1bb1e177,"KAFKA-1356 Topic metadata requests takes too long to process; reviewed by Neha Narkhede, Joel Koshy and Guozhang Wang",2014-04-08 10:44:07,Timothy Chen,Not TDD
8d15de85114da6012530f0dd837f131bd1e367cd,"KAFKA-1373; Set first dirty (uncompacted) offset to first offset of the
log if no checkpoint exists. Reviewed by Neha Narkhede and Timothy Chen.",2014-04-09 10:45:10,Joel Koshy,Not TDD
9a6f7113ed630d8e6bb50f4a58846d976a2d5f97,kafka-1390; TestUtils.waitUntilLeaderIsElectedOrChanged may wait longer than it needs; patched by Jun Rao; reviewed by Guozhang Wang,2014-04-15 13:46:54,Jun Rao,Mixed
97f13ec73255f3978c1cbb80ea26f446cf756515,"KAFKA-1323; Fix regression due to KAFKA-1315 (support for relative
directories in log.dirs property broke). Patched by Timothy Chen and
Guozhang Wang; reviewed by Joel Koshy, Neha Narkhede and Jun Rao.",2014-04-16 10:31:36,Joel Koshy,Mixed
b9351e04f0a26f2f9e4abc7ec526ed802495f991,KAFKA-1398 dynamic config changes are broken.,2014-04-17 20:31:07,Jay Kreps,Not TDD
8b052150f55fb9a6f8c4aedc6b3fa0528719671e,KAFKA-1337: Fix incorrect producer configs after config renaming.,2014-04-18 13:05:13,Jay Kreps,Not TDD
89f040c8c9807fc4f9e219f0b57279b692b6e45d,KAFKA-1398 Dynamic config follow-on-comments.,2014-04-18 15:02:06,Jay Kreps,Not TDD
caafc9d614dcb8584fbaf01902fbeaf2d5ea6786,"kafka-1410; MetadataCache cleanup; patched by Jun Rao; reviewed by Timothy Chen, Joel Koshy",2014-04-22 17:22:27,Jun Rao,Not TDD
93af67cd4f75d2f4cc3a25ad999fe6349925504e,"kafka-1359; Followup on K1359: change nanoTime to currentTimeMillis in metrics; patched by Guozhang Wang; reviewed by Neha Narkhede, Jun Rao",2014-04-22 17:47:55,Guozhang Wang,Not TDD
0efdfa6f7b6be688d5c531e801c9d37882e55f7f,kafka-1389; transient unit test failure in ProducerFailureHandlingTest; patched by Jun Rao; reviewed by Guozhang Wang and Neha Narkhede,2014-04-23 17:26:46,Jun Rao,Not TDD
631536327e3aad866d7c797984794a8800fa9fc3,kafka-1424; (followup patch) transient unit test failure in testSendWithDeadBroker; patched by Jun Rao; reviewed by Guozhang Wang and Neha Narkhede,2014-04-28 14:59:35,Jun Rao,Not TDD
3f7a9061b4d1b9ef9e0f4dae3117fd985f84e072,"KAFKA-1432 Make num.producerThreads configurable on new MirrrorMaker; reviewed by Neha Narkhede, Jun Rao",2014-05-05 16:56:50,Guozhang Wang,Not TDD
44c39c4ea48f365445b8c08ce57d0f16b15f0d0b,kafka-1397; delete topic is not working; patched by Timothy Chen; reviewed by Neha Narkhede and Jun Rao,2014-05-06 10:37:49,Timothy Chen,Mixed
9b6bf407874ef0fda12d8b2cc7f8331ce4aebeea,kafka-1384; Log Broker state; patched by Timothy Chen; reviewed by Joel Koshy and Jun Rao,2014-05-06 16:36:09,Timothy Chen,Mixed
c179c45f2375cb1253e519d0be8c8e9e6ff679f6,KAFKA-1437; Consumer metadata response should include (empty) coordinator information if the coordinator is unavailable; reviewed by Neha Narkhede and Guozhang Wang.,2014-05-15 14:41:29,Joel Koshy,Not TDD
99f10739b5921534dddc6e3773e4f8a05b8909b0,"KAFKA-1445 Send all partitions, regardless of how full, whenever we are sending a request to a broker. Patch from Guozhang.",2014-05-15 16:56:45,Jay Kreps,Mixed
8d454f374b4f879b50825b192617167070749b4f,KAFKA-1179 createMessageStreams() in javaapi.ZookeeperConsumerConnector does not throw; reviewed by Neha Narkhede,2014-05-15 17:36:14,Sriharsha Chintalapani,Mixed
c24740c7b0f6a6e7c66659da786a346650b76766,KAFKA-1328 New consumer APIs; reviewed by Jun Rao and Guozhang Wang,2014-05-20 16:49:31,Neha Narkhede,Not TDD
bf83131dffbdb6c39de0135e0426701ca141f150,KAFKA-1328 follow up: Updated javadoc,2014-05-20 22:11:19,Neha Narkhede,Not TDD
547ccedcfa081de2679f9607e4e868041c2cc55f,KAFKA-1456 Add LZ4 and LZ4C as a compression codec patch by James Oliver reviewed by Joe Stein,2014-05-26 11:34:50,Joe Stein,Not TDD
02311c0642b3358e8180191ea0542e985ed0f6dc,KAFKA-1468 Misc. improvements from benchmarking.,2014-05-31 15:05:45,Jay Kreps,Mixed
1363ed7c5268546e657d2d8d9e9e3aeac2df04d8,KAFKA-1438 Migrate client tools out of perf; reviewed by Neha Narkhede,2014-06-04 22:20:55,Sriharsha Chintalapani,Mixed
d3007171102a95cd2979fad6dec5d0bbefb57d7a,KAFKA-1469 Util.abs function does not return correct absolute values for negative values; patched by Guozhang Wang and Neha Narkhede,2014-06-06 10:03:28,Sebastian Geller,Mixed
b04a3be54e872599a1e3a0fda488de5f19ce7c24,KAFKA-1298 (followup); Controlled shutdown tool doesn't seem to work out of the box;  patched by Sriharsha Chintalapani; reviewed by Jun Rao,2014-06-10 10:35:32,Sriharsha Chintalapani,Not TDD
dee16451e04a4bb905a0479e08fa1f0848fea4fb,KAFKA-1382. Update zkVersion on partition state update failures; reviewed by Neha Narkhede,2014-06-10 14:54:58,Neha Narkhede,Mixed
dcc88408c98a07cb9a816ab55cd81e55f1d2217d,KAFKA-1488; new metrics for measuring the ratio when the new producer is block for space allocation; patched by Jun Rao; reviewed by Guozhang Wang and Joel Koshy,2014-06-10 17:14:45,Jun Rao,Mixed
548d1ba0939c43fff14531510140e2c641b1caa5,KAFKA-1326 Refactor Sender to support consumer.,2014-06-10 17:41:29,Jay Kreps,Mixed
dd048d8fee60db7282076a71eeeb8a1d0a4381d9,KAFKA-1382 follow up patch; reviewed by Neha Narkhede,2014-06-18 21:13:48,Sriharsha Chintalapani,Mixed
6b0ae4bba0d0f8e4c8da19de65a8f03f162bec39,KAFKA-1291 Add wrapper scripts and usage information to each command.,2014-06-19 14:04:06,Jay Kreps,Not TDD
f1c6e97d718581566d037a48640ac3d869d1f15a,KAFKA-1498 Misc. producer performance enhancements. Patch from Guozhang.,2014-07-01 13:21:36,Jay Kreps,Mixed
6de56b30b0f9aee19bf110431bcb4511d9b748f2,KAFKA-1519 Make it possible to disable the line seperator in the console consumer. Patch from Gwen Shapira.,2014-07-03 21:15:01,Jay Kreps,Mixed
cd3ce27d4baf5434676ec040d64663ad3ce09817,KAFKA-1515 Fix a bug that could result in blocking for a long period of time in the producer. Patch from Guozhang Wang.,2014-07-08 13:16:56,Jay Kreps,Mixed
420628d695cc675711b94af5cfd14653147bf7f7,kafka-1325; Fix inconsistent per topic log configs; patched by Manikumar Reddy; reviewed by Jun Rao,2014-07-10 08:27:33,Manikumar Reddy,Mixed
8e444a3562d6723b9f33cbdaa6a461409c84c98b,KAFKA-1512 Add per-ip connection limits.,2014-07-16 09:53:15,Jay Kreps,Mixed
4ebcdfd51f1e9e4c3d684204e6a785fae6c0e549,KAFKA-1535 Have the metadata response contain all alive brokers rather than just the ones needed for the given topics.,2014-07-17 15:53:52,Jay Kreps,Not TDD
fc0e03f79131746da81c05c12e056862c08d79d4,kafka-1462; Add new request and response formats for the new consumer and coordinator communication; patched by Jun Rao; reviewed by Guozhang Wang and Jay Kreps,2014-07-17 18:20:01,Jun Rao,Mixed
592678e4d72151940002ffb1a367ec433b27f2ef,"KAFKA-1180 WhiteList topic filter gets a NullPointerException on complex Regex patch by Joe Stein, reviewed by Joel Koshy",2014-07-19 21:00:22,Joe Stein,Not TDD
014b700f0323b4dc00d3aa0e1b598f7e2ed07957,kafka-1462 (followup patch); Add new request and response formats for the new consumer and coordinator communication; patched by Jun Rao; reviewed by Jay Kreps,2014-07-22 10:53:34,Jun Rao,Not TDD
ff05e9b3616a222e29a42f6e8fdf41945a417f41,kafka-1533; transient unit test failure in ProducerFailureHandlingTest; reviewed by Guozhang Wang; reviewed by Jun Rao,2014-07-22 14:14:19,Guozhang Wang,Not TDD
f489493c385e3266c3bc17db2e8ebc215a6e54e2,kafka-1414; Speedup broker startup after hard reset; patched by Anton Karamanov; reviewed by Jay Kreps and Jun Rao,2014-07-27 21:13:20,Anton Karamanov,Mixed
f8d521a9616134d78966419e5cf2aa73e8d6a5c5,kafka-1562; kafka-topics.sh alter add partitions resets cleanup.policy; patched by Jonathan Natkins; reviewed by Jun Rao,2014-08-04 07:21:25,Jonathan Natkins,Mixed
0dc243b92a6ae1683795caf8222edc1b2bb49565,kafka-1430; Purgatory redesign; patched by Guozhang Wang; reviewed by Jun Rao,2014-08-05 21:27:57,Guozhang Wang,Mixed
4d0759713fb2722bac8ce7dcbbb047d7af99280a,kafka-1419; cross build for scala 2.11; patched by Ivan Lyutov; reviewed by Joe Stein and Jun Rao,2014-08-10 21:20:30,Ivan Lyutov,Not TDD
c6f08b6094924ff3560a8e16090c85ed1a415b03,KAFKA-1580; Reject producer requests to internal topics; reviewed by Joel Koshy and Neha Narkhede,2014-08-15 15:49:54,Jonathan Natkins,Not TDD
2cdc83e85b56c946eed51da6143fbe9d2d0c9d08,KAFKA-1485 Upgrade to Zookeeper 3.4.6 and create shim for ZKCLI so system tests can run patch by Gwen Shapira reviewed by Joe Stein and Jun Rao,2014-08-28 21:15:10,Joe Stein,Not TDD
953e35b5c591559a600b4e6bd01d1dd1f2e979db,KAFKA-687; Provide a roundrobin partition assignment strategy that considers partitions from all topics; reviewed by Jun Rao and Guozhang Wang.,2014-08-29 17:55:14,Joel Koshy,Mixed
ffb81a581b6cbd3bd7338ec88022aa745a05b1c9,kafka-1616; Purgatory Size and Num.Delayed.Request metrics are incorrect; patched by Guozhang Wang; reviewed by Jun Rao,2014-09-04 22:23:25,Guozhang Wang,Mixed
cb6a1597b768404d758540e3ed53f5918c28c31b,KAFKA-1611 Improve system test configuration; reviewed by Neha Narkhede and Guozhang Wang,2014-09-14 20:14:07,Gwen Shapira,Not TDD
d677701b93b3b792fac6191588984f7a5323eecd,KAFKA-1496 Using batch message in sync producer only sends the first message if we use a Scala Stream as the argument; reviewed by Neha Narkhede,2014-09-14 20:40:35,Guan Liao,Not TDD
be5edd2f8d0c0355cb33feb2ac7482b7df7dccbc,kafka-1123; Broker IPv6 addresses parsed incorrectly; patched by Krzysztof Szafrański; reviewed by Jun Rao,2014-09-18 15:53:48,Krzysztof Szafrański,Mixed
8eac7d789f588b48ad278f4db620402c426c65bc,KAFKA-1282 Disconnect idle socket connection in Selector; reviewed by Neha Narkhede and Jun Rao,2014-09-20 13:51:22,nicu marasoiu,Mixed
084566b837ee2204b6898b82156e811d0601085f,kafka-1645; some more jars in our src release; patched by Joe Stein; reviewed by Jun Rao,2014-09-24 21:13:21,Joe Stein,Not TDD
f750dba65f9d9552a61a0754c46fa6e294785b31,"KAFKA-404 When using chroot path, create chroot on startup if it doesn't exist; reviewed by Neha Narkhede",2014-09-25 17:49:29,Jonathan Creasy,Not TDD
9c17747baab829adb268da28b4d943bbd6ef4e9f,KAFKA-589 Clean shutdown after startup connection failure; reviewed by Neha Narkhede,2014-09-25 21:23:10,Ewen Cheslack-Postava,Not TDD
c940470e32916e2dbbe8f95bd295950a3681c5b7,kafka-1670; Corrupt log files for segment.bytes values close to Int.MaxInt; patched by Sriharsha Chintalapani; reviewed by Jay Kreps and Jun Rao,2014-10-09 08:05:32,Sriharsha Chintalapani,Mixed
58e58529b350a3da860b1f51fdfa356dfc42761f,KAFKA-1648; Robin consumer balance throws an NPE when there are no topics,2014-10-09 16:34:40,Mayuresh Gharat,Mixed
043190c601f37e42c32189f3df5ddd986e57da95,kafka-1555; provide strong consistency with reasonable availability; patched by Gwen Shapira; reviewed by Joel Koshy and Jun Rao,2014-10-09 18:26:03,Gwen Shapira,Mixed
0d65f043fed14c482a788d403c6a05544c0dd01b,KAFKA-1471 Add producer unit tests for LZ4 and LZ4HC compression codecs; patched by James Oliver; reviewed by Neha Narkhede,2014-10-12 16:15:54,Ewen Cheslack-Postava,Not TDD
22643bfc2b683b426eb41d4b66cf90c3b7ec7f0d,KAFKA-979 Add jitter for time based rolling; reviewed by Neha Narkhede and Joel Koshy,2014-10-14 21:17:01,Ewen Cheslack-Postava,Mixed
de432a09e632f78df9e580b51277f81582c3f026,KAFKA-1637 SimpleConsumer.fetchOffset returns wrong error code when no offset exists for topic/partition/consumer group; reviewed by Neha Narkhede,2014-10-14 21:47:02,Ewen Cheslack-Postava,Not TDD
841387b23ac30707dd7f24a79de441c3302458d4,"Revert ""KAFKA-1637 SimpleConsumer.fetchOffset returns wrong error code when no offset exists for topic/partition/consumer group; reviewed by Neha Narkhede""

This reverts commit de432a09e632f78df9e580b51277f81582c3f026.",2014-10-14 22:31:50,Joel Koshy,Not TDD
4271ecbf06d0ffe16db3222b4e75247641a4c35f,KAFKA-1637 SimpleConsumer.fetchOffset returns wrong error code when no offset exists for topic/partition/consumer group; reviewed by Neha Narkhede and Joel Koshy,2014-10-15 17:07:30,Neha Narkhede,Not TDD
37356bfee09bf0dffc93d85270c342e03c36ca44,kafka-1493; Use a well-documented LZ4 compression format and remove redundant LZ4HC option; patched by James Oliver; reviewed by Jun Rao,2014-10-17 10:07:34,James Oliver,Not TDD
4b095760cb38c726c49e6f245ffd7dc8ccf49863,kafka-1698; Validator.ensureValid() only validates default config value; patched by Ewen Cheslack-Postava; reviewed by Jun Rao,2014-10-20 18:02:00,Ewen Cheslack-Postava,Mixed
12ce4b1e1e0e6ec7fd3585baf3ed531ecc16a5d9,KAFKA-1725 Configuration file bugs in system tests add noise to output and break a few tests; reviewed by Neha Narkhede,2014-10-24 09:04:23,Ewen Cheslack-Postava,Not TDD
89831204c092f3a417bf41945925a2e9a0ec828e,"KAFKA-1583; Encapsulate replicated log implementation details into
ReplicaManager and refactor KafkaApis; reviewed by Joel Koshy and Jun
Rao",2014-10-29 18:56:23,Guozhang Wang,Mixed
4bb020212aa0260a750b69dc18856cf25c1e7011,KAFKA-1706; Add a byte bounded blocking queue utility; reviewed by Joel Koshy,2014-11-04 10:09:22,Jiangjie Qin,Mixed
ca2cf97a6b151566f091a5dd016b93dfdaf87628,KAFKA-1764; ZookeeperConsumerConnector should not put multiple shutdown commands to the same data chunk queue; reviewed by Joel Koshy and Guozhang Wang,2014-11-14 10:02:45,Jiangjie Qin,Mixed
7d89867c05a7cca6e76cc48c47f8e703d68a9a43,kafka-1642; [Java New Producer Kafka Trunk] CPU Usage Spike to 100% when network connection is lost; patched by Ewen Cheslack-Postava; reviewed by Guozhang Wang and Jun Rao,2014-11-14 14:30:04,Ewen Cheslack-Postava,Mixed
1c7d783dd648d0e691ad80cb1357c52d3f0af11a,kafka-1743; ConsumerConnector.commitOffsets in 0.8.2 is not backward compatible; patched by Manikumar Reddy; reviewed by Jun Rao,2014-11-18 19:03:51,Manikumar Reddy,Mixed
457744a820d806e546edebbd8ffd33f6772e519f,kafka-1481; Stop using dashes AND underscores as separators in MBean names; patched by Vladimir Tretyakov; reviewed by Joel Koshy and Jun Rao,2014-11-19 17:57:41,Vladimir Tretyakov,Mixed
409c367ceb5f9eae395cb346dd3fa02b8ee8ee70,KAFKA-1654 Provide a way to override server configuration from command line; reviewed by Neha Narkhede,2014-11-23 16:41:24,Jarek Jarcec Cecho,Not TDD
9f8b8dad2b7ad31c9595f559f6d9e7d07d2f696d,KAFKA-1580; disallow non-admin clients to produce to internal (e.g. offsets) topics; reviewed by Joel Koshy,2014-11-24 14:38:49,Guozhang Wang,Not TDD
834b6419806750ff555e8ffd104caa420004e84e,kafka-1667; topic-level configuration not validated; patched by Dmytro Kostiuchenko; reviewed by Jun Rao,2014-11-25 14:36:31,Dmytro Kostiuchenko,Mixed
b24f9c0890302a5149aaaf26dc933bd0a842f1be,kafka-1798; ConfigDef.parseType() should throw exception on invalid boolean value; patched by dokovan; reviewed by Jun Rao,2014-12-01 16:24:31,dokovan,Mixed
3cc10d5ff9bf73cff2045685f89d71fee92a41f4,KAFKA-1720; Renamed Delayed Operations after KAFKA-1583; reviewed by Gwen Shapira and Joel Koshy,2014-12-04 13:51:44,Guozhang Wang,Mixed
2801629964882015a9148e1c0ade22da46376faa,KAFKA-1650; avoid data loss when mirror maker shutdown uncleanly; reviewed by Guozhang Wang,2014-12-05 15:18:25,Jiangjie Qin,Mixed
e8ffbd0fee0bc715ad0fe6c9afe85715f84d8e51,KAFKA-1812 Allow IpV6 in configuration with parseCsvMap patch by Jeff Holoman reviewed by Gwen Shapira and Joe Stein,2014-12-12 03:46:29,Joe Stein,Mixed
ae0bb84fa7e599774cd984196dc62b3dc84b13ca,KAFKA-742: Existing directories under the Kafka data directory without any data cause process to not start; reviewed by Neha Narkhede,2014-12-16 20:33:28,Ashish Singh,Mixed
92d1d4cd31e1045f0e000e8d2d777c73f7529743,kafka-1797; add the serializer/deserializer api to the new java client; patched by Jun Rao; reviewed by Neha Narkhede,2014-12-17 16:29:09,Jun Rao,Mixed
10c6dec34dae8820bf7ce24839c938135f9a9189,KAFKA-1650; (Follow-up patch) to support no data loss in mirror maker; reviewed by Joel Koshy,2014-12-23 17:04:45,Jiangjie Qin,Not TDD
50b734690a93e58030f69cede8d0a84d1e3f5461,kafka-1797; (follow-up patch) add the serializer/deserializer api to the new java client; patched by Jun Rao; reviewed by Jay Kreps,2015-01-06 11:40:26,Jun Rao,Not TDD
f82518a85001307334132056fe32c28b452cf48b,KAFKA-1512 Fixes for limit the maximum number of connections per ip address patch by Jeff Holoman reviewed by Jay Krepps and Gwen Shapira,2015-01-06 22:40:27,Joe Stein,Mixed
a93ef199b2375c422e35d82ac7aa3a2fdacc1e74,kafka-1797; (addressing Manikumar Reddy's comment) add the serializer/deserializer api to the new java client; patched by Jun Rao; reviewed by Manikumar Reddy and Neha Narkhede,2015-01-09 11:27:00,Jun Rao,Not TDD
e52a6181bf0969f315ac0f0d325eac34d2b4a6ee,kafka-1851; OffsetFetchRequest returns extra partitions when input only contains unknown partitions; patched by Jun Rao; reviewed by Neha Narkhede,2015-01-09 11:33:48,Jun Rao,Not TDD
b1b80860a01cc378cfada3549a3480f0773c3ff8,KAFKA-1070 Auto assign broker id; reviewed by Neha Narkhede,2015-01-12 15:45:29,Sriharsha Chintalapani,Mixed
ad4883a0cd5afc4219e28cdafbd98576eeaee2d1,KAFKA-1836 metadata.fetch.timeout.ms set to zero blocks forever; reviewed by Neha Narkhede and Ewen Cheslack-Postava,2015-01-12 15:59:16,Jaikiran Pai,Mixed
14779dddb6a9bb3aefbaa825a62874f89bb47d2c,KAFKA-1819 Cleaner gets confused about deleted and re-created topics; reviewed by Neha Narkhede,2015-01-12 21:12:34,Gwen Shapira,Not TDD
6f4dea9dbce5cc9f69a917182981b41a56a98a85,kafka-1797; (missed parametric in a few files) add the serializer/deserializer api to the new java client; patched by Jun Rao,2015-01-12 21:29:40,Jun Rao,Not TDD
688e38ce45a7358a1e0bb359aa9b1a698a841619,KAFKA-1723; make the metrics name in new producer more standard; patched by Manikumar Reddy; reviewed by Jay Kreps and Jun Rao,2015-01-12 22:02:02,Manikumar Reddy,Mixed
1c8f89bc73ec1844371c812215b255db037e24a5,KAFKA-1499; Broker-side compression configuration; reviewed by Joel Koshy,2015-01-14 18:46:38,Manikumar Reddy,Mixed
45697ed6c6132475b5dd4dd0069a2a192a75d329,KAFKA-1499; Trivial follow-up (fix comments and whitespace),2015-01-15 08:04:29,Joel Koshy,Mixed
5174df53778cb5cb2d6d86e4cec9f3185a2c85db,"kafka-1864; Revisit defaults for the internal offsets topic; patched by Jun Rao; reviewed by Jeol Koshy, Neha Narkhede, and Gwen Shapira",2015-01-16 18:56:32,Jun Rao,Not TDD
0f6cc0a058bbd2736f1e638448fc64b58a9f6b41,KAFKA-1818 KAFKA-1818 clean up code to more idiomatic scala usage; reviewed by Neha Narkhede and Gwen Shapira,2015-01-25 19:28:14,Eric Olander,Mixed
0699ff2ce60abb466cab5315977a224f1a70a4da,KAFKA-1760: New consumer.,2015-01-29 02:55:35,Jay Kreps,Mixed
1c6d5bbac672cbf49591aed0889510b10e3285fa,KAFKA-1915: Add checkstyle for java code.,2015-02-03 09:16:55,Jay Kreps,Mixed
0839def4bdbfd9f5939e463f42cfbc81a98a8eff,KAFKA-1925; Fix coordinator broker id stuck with INT_MIN; reviewed by Jay Kreps,2015-02-09 09:33:16,Guozhang Wang,Not TDD
39cd48de321585ac55c94ec407fede5858f38962,KAFKA-1333; Add the consumer coordinator to server; reviewed by Onur Karaman and Jay Kreps,2015-02-09 15:13:10,Guozhang Wang,Not TDD
9fe9913e95e1d3e114c74620d8da40f804f71b18,KAFKA-1476 Added a ConsumerCommand tool that will replace other consumer related tools in the future; reviewed by Neha Narkhede,2015-02-10 11:59:01,Onur Karaman,Mixed
a3d6dcaf1bcc6189c3ef17b63719ae4d12dcb789,KAFKA-1948; Fix ConsumerTest.testPartitionReassignmentCallback handling issue; reviewed by Gwen Shapira,2015-02-12 17:09:42,Guozhang Wang,Not TDD
eab4f4c9f43e20b3d91bf0e2e9be6b6fd72f0acf,KAFKA-1697; Remove support for producer ack > 1 on the broker; reviewed by Joel Koshy,2015-02-13 13:08:10,Gwen Shapira,Mixed
5b949c7b1ad5ab3f71cae6024eea10b59a7ad9b6,KAFKA-1805; ProducerRecord should implement equals and hashCode; reviewed by Guozhang Wang,2015-02-17 16:18:35,Parth Brahmbhatt,Mixed
cb40ec2e7a73bdecdfea6c88ffd8e8717b630d0f,KAFKA-1914; Include total produce/fetch stats in broker topic metrics.,2015-02-17 17:36:12,Aditya Auradkar,Not TDD
8c1b9325be4adc5065c6dbe3dcdbdccb1887d604,KAFKA-1867 liveBroker list not updated on a cluster with no topics; reviewed by Neha Narkhede,2015-02-20 16:22:23,Sriharsha Chintalapani,Not TDD
41189ea5601837bdb697ade31f55e244abbe6d1c,kafka-1971; starting a broker with a conflicting id will delete the previous broker registration; patched by Jun Rao; reviewed by Neha Narkhede,2015-02-23 11:51:32,Jun Rao,Not TDD
10311c138923dcded5d8f57f587c7f7ef1119dac,"kafka-1984; java producer may miss an available partition; patched by Jun Rao; reviewed by Ewen Cheslack-Postava, Jay Kreps, and Guozhang Wang",2015-02-24 14:07:27,Jun Rao,Mixed
b8904e9614b4c1f11b8487e7a4b88b1e37e1f20b,KAFKA-1953; KAFKA-1962; Disambiguate purgatory metrics; restore delayed request metrics; reviewed by Guozhang Wang,2015-02-25 10:59:28,Joel Koshy,Mixed
b56f5973c739072350f3f6bf6efa4eb05bc692bf,KAFKA-1664 Kafka does not properly parse multiple ZK nodes with non-root chroot; reviewed by Neha Narkhede and Jun Rao,2015-02-27 15:10:01,Ashish Singh,Not TDD
687abc98a4600bf90ed7a7acb6fb2a5e6eac2055,KAFKA-1866 LogStartOffset gauge throws exceptions after log.delete(); reviewed by Neha Narkhede,2015-02-27 16:10:47,Sriharsha Chintalapani,Not TDD
22ff9e943a960a73d2f007b2c52b90e675a61299,KAFKA-1824 ConsoleProducer - properties key.separator and parse.key no longer work; reviewed by Neha Narkhede,2015-02-28 07:41:37,Gwen Shapira,Mixed
0636928d961a6ceaab46d908f9372d913c3e5faf,KAFKA-1865 Add a flush() method to the producer.,2015-02-28 14:11:59,Jay Kreps,Mixed
1cd6ed9e2c07a63474ed80a8224bd431d5d4243c,"KAFKA-1755; Reject compressed and unkeyed messages sent to compacted topics; reviewed by Mayuresh Gharat, Neha Narkhede and Guozhang Wang",2015-03-03 10:44:04,Joel Koshy,Mixed
616987d196b654486a1261f4eed50e48560e3041,KAFKA-1852; Reject offset commits to unknown topics; reviewed by Joel Koshy,2015-03-03 11:16:38,Sriharsha Chintalapani,Not TDD
3a9f4b833bb7e86dc759361c33f4321ab043db05,KAFKA-1988; Fix org.apache.kafka.common.utils.Utils.abs and add Partitioner.toPositive; reviewed by Jun Rao and Guozhang Wang,2015-03-03 17:15:30,Tong Li,Mixed
8f0003f9b694b4da5fbd2f86db872d77a43eb63f,KAFKA-1845 KafkaConfig should use ConfigDef patch by Andrii Biletskyi reviewed by Gwen Shapira,2015-03-05 09:53:27,Joe Stein,Mixed
0b92cec1e07a1f2d9aa70f3ecd7d0fb12290d2e2,KAFKA-1910; Refactor new consumer and fixed a bunch of corner cases / unit tests; reviewed by Onur Karaman and Jay Kreps,2015-03-10 11:19:48,Guozhang Wang,Mixed
01d2a25235841feb01eac55f6ea5141750225a21,KAFKA-1910; follow-up on fixing buffer.flip on produce requests,2015-03-10 16:18:00,Guozhang Wang,Mixed
1eb5f53aa4f5c5c0f67ce62d86e8d9b4e5bbc500,KAFKA-1910; missed follow-up changes,2015-03-10 17:31:17,Guozhang Wang,Not TDD
01f20e029fbd068a8493492a2c4a1364a5668579,KAFKA-1910 Follow-up again; fix ListOffsetResponse handling for the expected error codes,2015-03-11 16:25:21,Guozhang Wang,Not TDD
b7439c8081465f8764e88326b3fa7b320f99f130,kafka-1461; Replica fetcher thread does not implement any back-off behavior; patched by Sriharsha Chintalapani; reviewed by Jun Rao,2015-03-12 13:56:52,Sriharsha Chintalapani,Not TDD
c41c7b40b63ecd668c727a897f29e276a1c5adf7,KAFKA-1997; Refactor MirrorMaker based on KIP-3; reviewed by Joel Koshy and Guozhang Wang,2015-03-13 15:07:48,Jiangjie Qin,Mixed
a74688de46c23dd34ad964372fbed05c1f7f4b3e,kafka-527; Compression support does numerous byte copies; patched by Yasuhiro Matsuda; reviewed by Guozhang Wang and Jun Rao,2015-03-25 13:08:38,Yasuhiro Matsuda,Mixed
d2f50fc3886896bc569fea7fb308036008b89f94,KAFKA-527; Use in-place decompression enabled inner iterator to replace old decompress function; reviewed by Joel Koshy and Jun Rao,2015-03-26 15:43:18,Guozhang Wang,Mixed
c5df2a8e3acca1e2c905fa6b78e73e09b1dd0cd7,KAFKA-1634; Bump up Offset Commit Request to v2 to add global retention and remove per-partition commit timestamp; reviewed by Joel Koshy and Jun Rao,2015-03-26 17:16:33,Guozhang Wang,Mixed
d8fe98efee5a44ae12c1e3484fa20f89b0f30054,kafka-2044; Support requests and responses from o.a.k.common in KafkaApis; patched by Gwen Shapira; reviewed by Jun Rao,2015-03-28 08:39:48,Gwen Shapira,Not TDD
48f997047228c327f91e8f848142b4607366fc3e,"KAFKA-1961 Prevent deletion of _consumer_offsets topic; reviewed by Neha Narkhede, Gwen Shapira and Jun Rao",2015-04-03 11:43:59,Ted Malaska,Mixed
15b93a410a8e988e09dc147c6d5250cbbe328b26,"KAFKA-1546; Automate replica lag tuning; reviewed by Joel Koshy, Neha
Narkhede, Jun Rao and Guozhang Wang",2015-04-03 18:40:17,Aditya Auradkar,Not TDD
6adaffd8ea4bc1f40bd5cf5268c30eb2df1868ab,"KAFKA-1501 Let the OS choose the port in unit tests to avoid collisions. Patch by Ewen CP, reviewed by Guozhang and me.",2015-04-04 14:26:38,Ewen Cheslack-Postava,Mixed
7acfa92c09bbfeb6d28a0771c09d36c9c89fc31f,KAFKA-2024 Log compaction can generate unindexable segments.,2015-04-04 15:56:17,Rajini Sivaram,Mixed
53f31432a0e1da78abf31ad42297790445083072,kafka-1809; Refactor brokers to allow listening on multiple ports and IPs; patched by Gwen Shapira; reviewed by Joel Koshy and Jun Rao,2015-04-05 17:21:37,Gwen Shapira,Mixed
9c23d93553a33c5d85231193614d192a9945796e,kafka-1926; Replace kafka.utils.Utils with o.a.k.common.utils.Utils; patched by Tong Li; reviewed by Jun Rao,2015-04-05 21:46:11,Tong Li,Mixed
75e1cc8bc497e6aaa0dd05454d6c817ed0fb5e23,kafka-2043; CompressionType is passed in each RecordAccumulator append; patched by Grant Henke; reviewed by Jun Rao,2015-04-06 13:34:31,Grant Henke,Mixed
04fce48e1af183d5133be1044d27e0f526e94f2a,"kafka-2099; BrokerEndPoint file, methods and object names should match; patched by Gwen Shapira; reviewed by Sriharsha Chintalapani and Jun Rao",2015-04-06 18:20:45,Gwen Shapira,Mixed
013cda2d79e1b82755cf948b668f4fb40b4efe62,KAFKA-1910 Follow-up; Revert the no-offset-committed error code; reviewed by Joel Koshy,2015-04-07 15:38:36,Guozhang Wang,Mixed
6880f66c97f63b2d1f3750f1753ec8b6094cb8a5,kafka-1989; New purgatory design; patched by Yasuhiro Matsuda; reviewed by Guozhang Wang and Jun Rao,2015-04-08 15:19:59,Yasuhiro Matsuda,Mixed
185eb9b59a9676f641af8bac8e8373ad4dfd5dc6,kafka-1994; Evaluate performance effect of chroot check on Topic creation; patched by Ashish Singh; reviewed by Gwen Shapira and Jun Rao,2015-04-18 09:26:50,Ashish Singh,Not TDD
5408931a2955adf8cb9d604d17dc9b5bd47b4d57,"kafka-1982; change kafka.examples.Producer to use the new java producer; patched by Ashish Singh; reviewed by Gwen Shapira, Mayuresh Gharat and Jun Rao",2015-04-19 07:46:58,Ashish Singh,Not TDD
3139cc31f6cab26f3dfd429c36280d1567dbf61a,kafka-1990; Add unlimited time-based log retention; patched by Jeff Holoman; reviewed by Jun Rao,2015-04-19 11:46:18,Jeff Holoman,Mixed
01e94e2b4a22eb0dd9ec4c3bbc353d054b1904b1,KAFKA-2121; Close internnal modules upon client shutdown; reviewed by Ewen Cheslack-Postava and Guozhang Wang,2015-04-22 10:14:44,Steven Wu,Mixed
2166104aff174e2ceb45638ca7be34f1db37e3e1,KAFKA-2138; Fix producer to honor retry backoff; reviewed by Joel Koshy and Guozhang Wang,2015-04-24 12:41:32,Jiangjie Qin,Mixed
ed1a548c503f041c025e00e75d338b4fc4a51f47,KAFKA-2140 Improve code readability; reviewed by Neha Narkhede,2015-04-26 08:40:58,Ismael Juma,Mixed
ae797467eb36d75083c87520d8ccaa759dafc7bb,"KAFKA-2122 Remove controller.message.queue.size Config; reviewed by Neha Narkhede, Jun Rao, Onur",2015-04-26 09:37:23,Sriharsha Chintalapani,Not TDD
ba3e089582d46b0193a734b6d1c5ebdd41da4dcc,KAFKA-2114 Unable to change min.insync.replicas default; reviewed by Neha,2015-04-26 13:09:09,Gwen Shapira,Not TDD
dbfe8c0a7dfea65e9f32e6157da1c9a3ce256171,kafka-2118; Cleaner cannot clean after shutdown during replaceSegments; patched by Rajini Sivaram; reviewed by Jun Rao,2015-04-26 19:17:15,Rajini Sivaram,Not TDD
161b1aa16ef0821c15fc7283d87cd83336b28d1a,KAFKA-2068 Phase 1; Merge in KAFKA-1841; reviewed by Jun Rao,2015-05-03 17:26:20,Guozhang Wang,Mixed
944628b0f5b5a7873c2bfd3d52c445b7ab0eaff3,"KAFKA-2153 kafka-patch-review tool uploads a patch even if it is empty; reviewed by Neha Narkhede, Gwen Shapira",2015-05-04 11:58:53,Ashish Singh,Mixed
5a47ef8ecbdf574bb18bd9ee5397188097924558,KAFKA-2121; Fix Closeable backward-compatibility; reviewed by Guozhang Wang,2015-05-07 17:04:51,Steven Wu,Not TDD
33af0cba3bff87874ae6cef61900cd065edad064,KAFKA-1660; Add API to the producer to support close with a timeout; reviewed by Joel Koshy and Jay Kreps.,2015-05-12 15:31:07,Jiangjie Qin,Mixed
49026f11781181c38e9d5edb634be9d27245c961,KAFKA-1334; Add the heartbeat logic to consumer coordinator; reviewed by Guozhang Wang,2015-05-14 14:54:59,Onur Karaman,Mixed
0ad646620614f257a0485ef3ff69ad8b83eeaf8d,KAFKA-2160; remove watcher list if empty in purgatory; remove join-group purgatory in coordinator; reviewed by Jun Rao,2015-05-19 18:43:18,Guozhang Wang,Mixed
29419581f5b28b66c7de7d5eb49b3bd6b62c9aba,KAFKA-2196; Remove identical topic constraint in round-robin assignor; reviewed by Guozhang Wang,2015-05-19 21:39:32,Onur Karaman,Mixed
bb133c63b0645c22f2d9b76393886fb506b14a93,KAFKA-1374; Log cleaner should be able to handle compressed messages; reviewed by Guozhang Wang,2015-05-20 10:27:39,Joel Koshy,Mixed
43b92f8b1ce8140c432edf11b0c842f5fbe04120,KAFKA-1737; Enforce ZKSerializer while creating ZkClient; reviewed by Guozhang Wang,2015-05-24 12:02:32,Vivek Madani,Mixed
d6c45c70fb9773043766446e88370db9709e7995,"KAFKA-2091; Expose a partitioner interface in the new producer
(https://cwiki.apache.org/confluence/display/KAFKA/KIP-+22+-+Expose+a+Partitioner+interface+in+the+new+producer);
reviewed by Joel Koshy and Jay Kreps",2015-05-28 13:27:12,Sriharsha Chintalapani,Mixed
d22987f01d50549d855ae092b69f520d75bfeb7b,KAFKA-2208; add consumer side error handling upon coordinator failure; reviewed by Onur Karaman,2015-06-03 13:47:08,Guozhang Wang,Mixed
78ba492e3e70fd9db61bc82469371d04a8d6b762,"kafka-1928; Move kafka.network over to using the network classes in org.apache.kafka.common.network; patched by Gwen Shapira; reviewed by Joel Koshy, Jay Kreps, Jiangjie Qin, Guozhang Wang and Jun Rao",2015-06-03 21:40:35,Gwen Shapira,Mixed
017c00caf44aaad3418cb99d3ef42c4d1b066ddd,kafka-2266; Client Selector can drop idle connections without notifying NetworkClient; patched by Jason Gustafson; reviewed by Jun Rao,2015-06-12 10:24:54,Jason Gustafson,Mixed
d31a2c2381bebc9c4b27e36fdf986183732e13eb,kafka-2232; make MockProducer generic; patched by Alexander Pakulov; reviewed by Jun Rao,2015-06-12 14:16:03,Alexander Pakulov,Mixed
20a31a29f7aa6ce6687a13aa0cf60b92c5ac4d1e,kafka-2101; Metric metadata-age is reset on a failed update; patched by Tim Brooks; reviewed by Jun Rao,2015-06-15 17:43:56,Tim Brooks,Mixed
54e54f08077c9d71a5121e640b55836e6f7f2c9b,kafka-2195; Add versionId to AbstractRequest.getErrorResponse and AbstractRequest.getRequest; patched by Andrii Biletskyi; reviewed by Jun Rao,2015-06-16 14:46:48,Andrii Biletskyi,Not TDD
28ecea421794d0c9a1c4f95375ccd1a6dfd8f365,kafka-2272; listeners endpoint parsing fails if the hostname has capital letter; patched by Sriharsha Chintalapani; reviewed by Jun Rao,2015-06-16 15:25:16,Sriharsha Chintalapani,Not TDD
7009f1d6fffe3866723d1d33a28a4572053eb4e5,kafka-2264; SESSION_TIMEOUT_MS_CONFIG in ConsumerConfig should be int; patched by Manikumar Reddy; reviewed by Jun Rao,2015-06-16 15:30:52,Manikumar Reddy,Mixed
5c9040745466945a04ea0315de583ccdab0614ac,kafka-2249; KafkaConfig does not preserve original Properties; patched by Gwen Shapira; reviewed by Jun Rao,2015-06-18 14:07:33,Gwen Shapira,Mixed
ca758252c5a524fe6135a585282dd4bf747afef2,kafka-1646; Improve consumer read performance for Windows; patched by Honghai Chen; reviewed by Jay Kreps and Jun Rao,2015-06-19 07:52:37,Honghai Chen,Mixed
16ecf9806b286d9510103a4426bf0901d7dc8778,kafka-2012; Broker should automatically handle corrupt index files;  patched by Manikumar Reddy; reviewed by Jun Rao,2015-06-19 09:34:22,Manikumar Reddy,Mixed
1eac3ceaf94b3e7583c7b6de2cfe13539ab06dd6,KAFKA-2245; Add response tests for consumer coordinator; reviewed by Joel Koshy,2015-06-22 10:14:14,Onur Karaman,Not TDD
b6d326b0893e60b350608260fd1bd2542337cb5a,"kafka-2168; New consumer poll() can block other calls like position(), commit(), and close() indefinitely; patched by Jason Gustafson; reviewed by Jay Kreps, Ewen Cheslack-Postava, Guozhang Wang and Jun Rao",2015-06-23 00:09:06,Jason Gustafson,Mixed
14e0ce0a47fb7f6ae6dab085b2ea9d5a1f644433,KAFKA-2168: minor follow-up patch; reviewed by Guozhang Wang,2015-07-01 15:28:11,Jason Gustafson,Not TDD
3f8480ccfb011eb43da774737597c597f703e11b,KAFKA-1740: merge offset manager into consumer coordinator; reviewed by Onur Karaman and Jason Gustafson,2015-07-02 11:41:51,Guozhang Wang,Mixed
fd612a2d50f1ee13009395f082357403c4277164,"kafka-2248; Use Apache Rat to enforce copyright headers; patched by Ewen Cheslack-Postava; reviewed by Gwen Shapira, Joel Joshy and Jun Rao",2015-07-06 15:47:40,Ewen Cheslack-Postava,Not TDD
2d96da05a0af7847aca5edc6d003a18be7f5216a,"kafka-2132; Move Log4J appender to a separate module; patched by Ashish Singh; reviewed by Gwen Shapira, Aditya Auradkar and Jun Rao",2015-07-06 16:36:20,Ashish Singh,Mixed
f77dc386c099da5ff0bac4d2a12b04f7f17f07d3,kafka-1367; Broker topic metadata not kept in sync with ZooKeeper; patched by Ashish Singh; reviewed by Jun Rao,2015-07-07 09:45:45,Ashish Singh,Mixed
ee88dbb67f19b787e12ccef37982c9459b78c7b6,"KAFKA-2327; broker doesn't start if config defines advertised.host but not advertised.port

Added unit tests as well. These fail without the fix, but pass with the fix.

Author: Geoff Anderson <geoff@confluent.io>

Closes #73 from granders/KAFKA-2327 and squashes the following commits:

52a2085 [Geoff Anderson] Cleaned up unecessary toString calls
23b3340 [Geoff Anderson] Fixes KAFKA-2327",2015-07-09 14:58:01,Geoff Anderson,Mixed
9ca61d17915f09b8010fa1da5ad0285b076a96e1,"KAFKA-1740 follow-up: add state checking in handling heartbeat request; reviewed by Onur Karaman, Ewen Cheslack-Postavam and Guozhang Wang",2015-07-09 18:15:45,Jason Gustafson,Not TDD
bdbb9672f5e035fd00801037e2affe64811ec6ab,kafka-972; MetadataRequest returns stale list of brokers; patched by Ashish Singh; reviewed by Jun Rao,2015-07-13 17:16:34,Ashish Singh,Not TDD
99c0686be2141a0fffe1c55e279370a87ef8c1ea,KAFKA-2123: add callback in commit api and use a delayed queue for async requests; reviewed by Ewen Cheslack-Postava and Guozhang Wang,2015-07-15 12:38:45,Jason Gustafson,Mixed
1e0ed7a592cd80cfca727b27ba01f6faa511531f,kafka-2174; Wrong TopicMetadata deserialization; patched by Alexey Ozeritskiy; reviewed by Jun Rao,2015-07-16 17:13:12,Alexey Ozeritskiy,Not TDD
1d2bd6284b06b579c901e6be8919a8a27dbe11ee,"KAFKA-2337;  Verify that metric names will not collide when creating new topics; patched by Grant Henke; reviewed by Edward Ribeiro, Ashish Singh and Gwen Shapira",2015-07-20 16:15:42,Grant Henke,Mixed
fd3b4cc41e9249ec6848cde8137691d32b2e79e5,"KAFKA-2342; KafkaConsumer rebalance with in-flight fetch can cause invalid position

Author: Jason Gustafson <jason@confluent.io>

Closes #88 from hachikuji/KAFKA-2342 and squashes the following commits:

cabb017 [Jason Gustafson] KAFKA-2342; KafkaConsumer rebalance with in-flight fetch can cause invalid position",2015-07-22 13:00:03,Jason Gustafson,Mixed
269c2407d4e6e38b3b6be00566c480121b5dc51a,"KAFKA-2381: Fix concurrent modification on assigned partition while looping over it; reviewed by Jason Gustafson, Aditya Auradkar, Ewen Cheslack-Postava, Ismael Juma and Guozhang Wang",2015-07-28 14:23:44,Ashish Singh,Mixed
594b963930c2054199ed54203415d1cb7917df27,"KAFKA-2275: Add ListTopics() API to the Java consumer; reviewed by Jason Gustafson, Edward Ribeiro and Guozhang Wang",2015-07-28 15:49:22,Ashish Singh,Mixed
e43c9aff92c57da6abb0c1d0af3431a550110a89,"KAFKA-2276; KIP-25 initial patch

Initial patch for KIP-25

Note that to install ducktape, do *not* use pip to install ducktape. Instead:

```
$ git clone gitgithub.com:confluentinc/ducktape.git
$ cd ducktape
$ python setup.py install
```

Author: Geoff Anderson <geoff@confluent.io>
Author: Geoff <granders@gmail.com>
Author: Liquan Pei <liquanpei@gmail.com>

Reviewers: Ewen, Gwen, Jun, Guozhang

Closes #70 from granders/KAFKA-2276 and squashes the following commits:

a62fb6c [Geoff Anderson] fixed checkstyle errors
a70f0f8 [Geoff Anderson] Merged in upstream trunk.
8b62019 [Geoff Anderson] Merged in upstream trunk.
47b7b64 [Geoff Anderson] Created separate tools jar so that the clients package does not pull in dependencies on the Jackson JSON tools or argparse4j.
a9e6a14 [Geoff Anderson] Merged in upstream changes
d18db7b [Geoff Anderson] fixed :rat errors (needed to add licenses)
321fdf8 [Geoff Anderson] Ignore tests/ and vagrant/ directories when running rat build task
795fc75 [Geoff Anderson] Merged in changes from upstream trunk.
1d93f06 [Geoff Anderson] Updated provisioning to use java 7 in light of KAFKA-2316
2ea4e29 [Geoff Anderson] Tweaked README, changed default log collection behavior on VerifiableProducer
0eb6fdc [Geoff Anderson] Merged in system-tests
69dd7be [Geoff Anderson] Merged in trunk
4034dd6 [Geoff Anderson] Merged in upstream trunk
ede6450 [Geoff] Merge pull request #4 from confluentinc/move_muckrake
7751545 [Geoff Anderson] Corrected license headers
e6d532f [Geoff Anderson] java 7 -> java 6
8c61e2d [Geoff Anderson] Reverted jdk back to 6
f14c507 [Geoff Anderson] Removed mode = ""test"" from Vagrantfile and Vagrantfile.local examples. Updated testing README to clarify aws setup.
98b7253 [Geoff Anderson] Updated consumer tests to pre-populate kafka logs
e6a41f1 [Geoff Anderson] removed stray println
b15b24f [Geoff Anderson] leftover KafkaBenchmark in super call
0f75187 [Geoff Anderson] Rmoved stray allow_fail. kafka_benchmark_test -> benchmark_test
f469f84 [Geoff Anderson] Tweaked readme, added example Vagrantfile.local
3d73857 [Geoff Anderson] Merged downstream changes
42dcdb1 [Geoff Anderson] Tweaked behavior of stop_node, clean_node to generally fail fast
7f7c3e0 [Geoff Anderson] Updated setup.py for kafkatest
c60125c [Geoff Anderson] TestEndToEndLatency -> EndToEndLatency
4f476fe [Geoff Anderson] Moved aws scripts to vagrant directory
5af88fc [Geoff Anderson] Updated README to include aws quickstart
e5edf03 [Geoff Anderson] Updated example aws Vagrantfile.local
96533c3 [Geoff] Update aws-access-keys-commands
25a413d [Geoff] Update aws-example-Vagrantfile.local
884b20e [Geoff Anderson] Moved a bunch of files to kafkatest directory
fc7c81c [Geoff Anderson] added setup.py
632be12 [Geoff] Merge pull request #3 from confluentinc/verbose-client
51a94fd [Geoff Anderson] Use argparse4j instead of joptsimple. ThroughputThrottler now has more intuitive behavior when targetThroughput is 0.
a80a428 [Geoff Anderson] Added shell program for VerifiableProducer.
d586fb0 [Geoff Anderson] Updated comments to reflect that throttler is not message-specific
6842ed1 [Geoff Anderson] left out a file from last commit
1228eef [Geoff Anderson] Renamed throttler
9100417 [Geoff Anderson] Updated command-line options for VerifiableProducer. Extracted throughput logic to make it reusable.
0a5de8e [Geoff Anderson] Fixed checkstyle errors. Changed name to VerifiableProducer. Added synchronization for thread safety on println statements.
475423b [Geoff Anderson] Convert class to string before adding to json object.
bc009f2 [Geoff Anderson] Got rid of VerboseProducer in core (moved to clients)
c0526fe [Geoff Anderson] Updates per review comments.
8b4b1f2 [Geoff Anderson] Minor updates to VerboseProducer
2777712 [Geoff Anderson] Added some metadata to producer output.
da94b8c [Geoff Anderson] Added number of messages option.
07cd1c6 [Geoff Anderson] Added simple producer which prints status of produced messages to stdout.
a278988 [Geoff Anderson] fixed typos
f1914c3 [Liquan Pei] Merge pull request #2 from confluentinc/system_tests
81e4156 [Liquan Pei] Bootstrap Kafka system tests",2015-07-28 17:22:14,Geoff Anderson,Mixed
be82a2afc9e38adc0109dc694834ca5947128877,"KAFKA-2350; KafkaConsumer pause/resume API

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael, Ashish, Guozhang

Closes #100 from hachikuji/KAFKA-2350 and squashes the following commits:

250e823 [Jason Gustafson] KAFKA-2350; KafkaConsumer pause/resume API",2015-07-30 14:23:43,Jason Gustafson,Mixed
a56a79055dfba4687f476b0a4d20aeec1c4ebff7,kafka-2205; Generalize TopicConfigManager to handle multiple entity configs; patched by Aditya Auradkar; reviewed Jun Rao,2015-08-04 15:11:27,Aditya Auradkar,Mixed
9cefb2a0fb7852d35cfe0f051bc6eadb8e9c4c80,KAFKA-2288; Follow-up to KAFKA-2249 - reduce logging and testing; Reviewd by Jun Rao,2015-08-04 19:04:58,Gwen Shapira,Mixed
27d499fe66fc034669a1852ca33ee2f486e1b83c,"KAFKA-2393: Correctly Handle InvalidTopicException in KafkaApis.getTo…

…picMetadata()

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #117 from granthenke/invalid-topic and squashes the following commits:

0abda5f [Grant Henke] KAFKA-2393: Correctly Handle InvalidTopicException in KafkaApis.getTopicMetadata()",2015-08-05 15:55:48,Grant Henke,Not TDD
006b45c7e5b94e70b3a4200f4646042f3557c48e,"KAFKA-2400: Expose heartbeat interval in KafkaConsumer configuration

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang

Closes #116 from hachikuji/KAFKA-2400 and squashes the following commits:

3c1b1dd [Jason Gustafson] KAFKA-2400; expose heartbeat interval in KafkaConsumer configuration",2015-08-06 14:17:30,Jason Gustafson,Mixed
f6373e4d9929d123a8474ab7673ee701f63ac593,"KAFKA-2340: Improve KafkaConsumer Fetcher test coverage

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang

Closes #112 from hachikuji/KAFKA-2340 and squashes the following commits:

cc49ca2 [Jason Gustafson] KAFKA-2340; improve KafkaConsumer Fetcher test coverage",2015-08-06 15:52:43,Jason Gustafson,Mixed
63b820c592aba3ec6f26cc99c0c470795029b10c,"KAFKA-2413; New consumer's subscribe(Topic...) api fails if called more than once

Author: Onur Karaman <okaraman@linkedin.com>

Reviewers: Ashish Singh, Ismael Juma, Jason Gustafson

Closes #122 from onurkaraman/KAFKA-2413 and squashes the following commits:

cc340fc [Onur Karaman] fix ConsumerCoordinator updateConsumer",2015-08-07 15:20:09,Onur Karaman,Mixed
be633a713e311c90ebfafc650eb3dcfb94ce372d,"KAFKA-2408: ConsoleConsumerService direct log output to file

console consumer writes to System.out, while (some) log4j loggers operate in other threads.

This occasionally led to funky interleaved output which disrupted parsing of consumed messages by ConsoleConsumerService, leading to spurious test failures.

This fix directs log output to a separate file.

Author: Geoff Anderson <geoff@confluent.io>

Reviewers: Ewen Cheslack-Postava

Closes #123 from granders/KAFKA-2408 and squashes the following commits:

247b0e0 [Geoff Anderson] Updated line counting to use wc -l
66d6f4f [Geoff Anderson] lower -> uperrcase constants
e67f554 [Geoff Anderson] Changed incorrect license header
af67e01 [Geoff Anderson] Merged in upstream trunk
8f89044 [Geoff Anderson] Added another lifecycle check. Wait for log file to exist before exmaning contents.
521a84b [Geoff Anderson] Updated console consumer to directo log output directly to file rather than stdout",2015-08-11 15:24:52,Geoff Anderson,Mixed
a62d63007c89c0c6f7ad62fe4643f7adc7fbc661,"KAFKA-2300: Error in controller log when broker tries to rejoin cluster

Author: flavio junqueira <fpj@apache.org>

Reviewers: Ismael Juma, Guozhang Wang

Closes #102 from fpj/2300 and squashes the following commits:

7bd2edb [flavio junqueira] KAFKA-2300: Removed unnecessary s"" occurrences.
aa6ec90 [flavio junqueira] KAFKA-2300: Wrapped all occurences of sendRequestToBrokers with try/catch and fixed string typo.
f1261b1 [flavio junqueira] Fixed some style issues.
9b6390a [flavio junqueira] Updated package name and removed unnecessary imports.
dbd1bf3 [flavio junqueira] KAFKA-2300: Error in controller log when broker tries to rejoin cluster",2015-08-12 14:31:39,flavio junqueira,Not TDD
2c55bd8aa2666ea11ee2814b04f782eef8fa52c6,"KAFKA-2406: Throttle ISR propagation

This is a follow up patch for KAFKA-2406. Further test to verify if this change alone is enough to solve the problem or not.

Author: Jiangjie Qin <becket.qin@gmail.com>
Author: Jiangjie Qin <jqin@jqin-ld1.linkedin.biz>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #114 from becketqin/KAFKA-2406",2015-08-13 17:54:36,Jiangjie Qin,Not TDD
f6acfb08917946f15cb8de2fee786019124af212,"KAFKA-2366; Initial patch for Copycat

This is an initial patch implementing the basics of Copycat for KIP-26.

The intent here is to start a review of the key pieces of the core API and get a reasonably functional, baseline, non-distributed implementation of Copycat in place to get things rolling. The current patch has a number of known issues that need to be addressed before a final version:

* Some build-related issues. Specifically, requires some locally-installed dependencies (see below), ignores checkstyle for the runtime data library because it's lifted from Avro currently and likely won't last in its current form, and some Gradle task dependencies aren't quite right because I haven't gotten rid of the dependency on `core` (which should now be an easy patch since new consumer groups are in a much better state).
* This patch currently depends on some Confluent trunk code because I prototyped with our Avro serializers w/ schema-registry support. We need to figure out what we want to provide as an example built-in set of serializers. Unlike core Kafka where we could ignore the issue, providing only ByteArray or String serializers, this is pretty central to how Copycat works.
* This patch uses a hacked up version of Avro as its runtime data format. Not sure if we want to go through the entire API discussion just to get some basic code committed, so I filed KAFKA-2367 to handle that separately. The core connector APIs and the runtime data APIs are entirely orthogonal.
* This patch needs some updates to get aligned with recent new consumer changes (specifically, I'm aware of the ConcurrentModificationException issue on exit). More generally, the new consumer is in flux but Copycat depends on it, so there are likely to be some negative interactions.
* The layout feels a bit awkward to me right now because I ported it from a Maven layout. We don't have nearly the same level of granularity in Kafka currently (core and clients, plus the mostly ignored examples, log4j-appender, and a couple of contribs). We might want to reorganize, although keeping data+api separate from runtime and connector plugins is useful for minimizing dependencies.
* There are a variety of other things (e.g., I'm not happy with the exception hierarchy/how they are currently handled, TopicPartition doesn't really need to be duplicated unless we want Copycat entirely isolated from the Kafka APIs, etc), but I expect those we'll cover in the review.

Before commenting on the patch, it's probably worth reviewing https://issues.apache.org/jira/browse/KAFKA-2365 and https://issues.apache.org/jira/browse/KAFKA-2366 to get an idea of what I had in mind for a) what we ultimately want with all the Copycat patches and b) what we aim to cover in this initial patch. My hope is that we can use a WIP patch (after the current obvious deficiencies are addressed) while recognizing that we want to make iterative progress with a bunch of subsequent PRs.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Ismael Juma, Gwen Shapira

Closes #99 from ewencp/copycat and squashes the following commits:

a3a47a6 [Ewen Cheslack-Postava] Simplify Copycat exceptions, make them a subclass of KafkaException.
8c108b0 [Ewen Cheslack-Postava] Rename Coordinator to Herder to avoid confusion with the consumer coordinator.
7bf8075 [Ewen Cheslack-Postava] Make Copycat CLI speific to standalone mode, clean up some config and get rid of config storage in standalone mode.
656a003 [Ewen Cheslack-Postava] Clarify and expand the explanation of the Copycat Coordinator interface.
c0e5fdc [Ewen Cheslack-Postava] Merge remote-tracking branch 'origin/trunk' into copycat
0fa7a36 [Ewen Cheslack-Postava] Mark Copycat classes as unstable and reduce visibility of some classes where possible.
d55d31e [Ewen Cheslack-Postava] Reorganize Copycat code to put it all under one top-level directory.
b29cb2c [Ewen Cheslack-Postava] Merge remote-tracking branch 'origin/trunk' into copycat
d713a21 [Ewen Cheslack-Postava] Address Gwen's review comments.
6787a85 [Ewen Cheslack-Postava] Make Converter generic to match serializers since some serialization formats do not require a base class of Object; update many other classes to have generic key and value class type parameters to match this change.
b194c73 [Ewen Cheslack-Postava] Split Copycat converter option into two options for key and value.
0b5a1a0 [Ewen Cheslack-Postava] Normalize naming to use partition for both source and Kafka, adjusting naming in CopycatRecord classes to clearly differentiate.
e345142 [Ewen Cheslack-Postava] Remove Copycat reflection utils, use existing Utils and ConfigDef functionality from clients package.
be5c387 [Ewen Cheslack-Postava] Minor cleanup
122423e [Ewen Cheslack-Postava] Style cleanup
6ba87de [Ewen Cheslack-Postava] Remove most of the Avro-based mock runtime data API, only preserving enough schema functionality to support basic primitive types for an initial patch.
4674d13 [Ewen Cheslack-Postava] Address review comments, clean up some code styling.
25b5739 [Ewen Cheslack-Postava] Fix sink task offset commit concurrency issue by moving it to the worker thread and waking up the consumer to ensure it exits promptly.
0aefe21 [Ewen Cheslack-Postava] Add log4j settings for Copycat.
220e42d [Ewen Cheslack-Postava] Replace Avro serializer with JSON serializer.
1243a7c [Ewen Cheslack-Postava] Merge remote-tracking branch 'origin/trunk' into copycat
5a618c6 [Ewen Cheslack-Postava] Remove offset serializers, instead reusing the existing serializers and removing schema projection support.
e849e10 [Ewen Cheslack-Postava] Remove duplicated TopicPartition implementation.
dec1379 [Ewen Cheslack-Postava] Switch to using new consumer coordinator instead of manually assigning partitions. Remove dependency of copycat-runtime on core.
4a9b4f3 [Ewen Cheslack-Postava] Add some helpful Copycat-specific build and test targets that cover all Copycat packages.
31cd1ca [Ewen Cheslack-Postava] Add CLI tools for Copycat.
e14942c [Ewen Cheslack-Postava] Add Copycat file connector.
0233456 [Ewen Cheslack-Postava] Add copycat-avro and copycat-runtime
11981d2 [Ewen Cheslack-Postava] Add copycat-data and copycat-api",2015-08-14 16:00:51,Ewen Cheslack-Postava,Mixed
bbb7d97adefe5826f2e02a8e55423ea215c9f749,"KAFKA-2084; Add per-client-id byte-rate metrics and quota manager; reviewed by Joel Koshy, Dong Lin, Jun Rao and Edward Ribeiro",2015-08-14 18:51:48,Aditya Auradkar,Mixed
503bd36647695e8cc91893ffb80346dd03eb0bc5,"KAFKA-2436; log.retention.hours should be honored by LogManager

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Joel Koshy, Gwen Shapira

Closes #142 from lindong28/KAFKA-2436",2015-08-18 13:03:11,Dong Lin,Mixed
9e2c683f550b7ae58008d0bcb62238b7a2d89a65,"kafka-1690; Add SSL support to Kafka Broker, Producer and Consumer; patched by Sriharsha Chintalapani; reviewed Rajini Sivaram, Joel Koshy, Michael Herstine, Ismael Juma, Dong Lin, Jiangjie Qin and Jun Rao",2015-08-18 21:51:15,Sriharsha Chintalapani,Mixed
0b04f9f34b37dd43c68c572dfae6bb75144f066c,"KAFKA-2246; Fix incorrect config ZK path.

This bug was introduced while committing KAFKA-2205. Basically, the path for topic overrides was renamed to ""topic"" from ""topics"". However, this causes existing topic config overrides to break because they will not be read from ZK anymore since the path is different.

https://reviews.apache.org/r/34554/

Author: Aditya Auradkar <aauradkar@linkedin.com>

Reviewers: Joel Koshy

Closes #152 from auradkar/2446",2015-08-19 18:16:59,Aditya Auradkar,Mixed
767a8a7628bd936ee3da1f03c27639657cd0dd5e,"KAFKA-2015: Enable ConsoleConsumer to use new consumer

This extends the original patch done by GZ to provide Console access to both the new and old consumer API's. The code follows a pattern similar to that already used in ConsoleProducer.

Author: Ben Stopford <benstopford@gmail.com>

Reviewers: Jason Gustafson, Ismael Juma, Guozhang Wang

Closes #144 from benstopford/KAFKA-2015 and squashes the following commits:

5058a7b [Ben Stopford] Patch for KAFKA-2015: removed unused imports
6e08bf4 [Ben Stopford] Patch for KAFKA-2015: fixed formatting error
739457c [Ben Stopford] Patch for KAFKA-2015: switched to blocking poll + typo + fixed to match style guide
883a626 [Ben Stopford] Patch for KAFKA-2015: incorporating comments to date.
0660629 [Ben Stopford] Merge remote-tracking branch 'upstream/trunk' into KAFKA-2015
e102ff6 [Ben Stopford] KAFKA-2015 - ported patch from jira in and altered to match exising ConsoleProducer template",2015-08-20 13:00:58,Ben Stopford,Mixed
1d2ae89c5a1dc5d18b8188bf737a8e1d195be325,"KAFKA-2439; Add MirrorMaker service class for system tests

Added MirrorMaker service and a few corresponding sanity checks, as well as necessary config template files. A few additional updates to accomodate the change in wait_until from ducktape0.2.0->0.3.0

Author: Geoff Anderson <geoff@confluent.io>

Reviewers: Ewen Cheslack-Postava, Gwen Shapira

Closes #148 from granders/KAFKA-2439 and squashes the following commits:

c7c3ebd [Geoff Anderson] MirrorMaker now can run as multi-node service. Added kill -9 to various clean_node methods.
1e806f2 [Geoff Anderson] Various cleanups per review.
1b4b049 [Geoff Anderson] Added MirrorMaker service and a few corresponding sanity checks, as well as necessary config template files. A few additional updates to accomodate the change in wait_until from ducktape0.2.0->0.3.0",2015-08-22 19:23:36,Geoff Anderson,Mixed
436b7ddc386eb688ba0f12836710f5e4bcaa06c8,"KAFKA-2136; Add throttle time (on quota violation) in fetch/produce
responses; reviewed by Joel Koshy, Dong Lin and Jun Rao",2015-08-25 18:33:10,Aditya Auradkar,Mixed
8b538d62bd7ddcefd177bfed01b10b39fc971bb1,"KAFKA-1683; persisting session information in Requests

Author: Gwen Shapira <cshapi@gmail.com>

Reviewers: Sriharsha Chintalapa, Ismael Juma, Edward Ribeiro, Parth Brahmbhatt, Jun Rao

Closes #155 from gwenshap/KAFKA-1683",2015-08-26 13:49:33,Gwen Shapira,Mixed
03f850f671ba3035eb150fa243dca0a2aed28302,"KAFKA-2072: Add StopReplica request/response to o.a.k.common.requests

This PR adds StopReplica request and response as it is required by ijuma for KAFKA-2411. Migration of core module is addressed a separate PR (#141).

ijuma Could you review it? gwenshap Could you take a look as well?

Author: David Jacot <david.jacot@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #170 from dajac/KAFKA-2072-part-1",2015-08-26 17:16:30,David Jacot,Not TDD
35eaef7bb4ebcf6b209312db774564451b052ca9,"KAFKA-2388: refactor KafkaConsumer subscribe API

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Edward Ribeiro, Onur Karaman, Ismael Juma, Guozhang Wang

Closes #139 from hachikuji/KAFKA-2388 and squashes the following commits:

377c67e [Jason Gustafson] KAFKA-2388; refactor KafkaConsumer subscribe API",2015-08-26 17:20:51,Jason Gustafson,Mixed
8c88d198a0bcd0292a6b7ec3b08ae138e41fcc6e,"KAFKA-2467: Fix changes to behavior in ConsoleConsumer: properly parse consumer.config option, handle exceptions during message processing, and print number of processed messages to stderr.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Guozhang Wang

Closes #166 from ewencp/kafka-2467-fix-console-consumer-behavior-regressions and squashes the following commits:

8b5e30c [Ewen Cheslack-Postava] KAFKA-2466: Fix ConsoleConsumer exit process for new consumer to avoid ConcurrentModificationException.
c6abe38 [Ewen Cheslack-Postava] Fix missing parameter in test.
a6961ee [Ewen Cheslack-Postava] KAFKA-2467: Fix changes to behavior in ConsoleConsumer: properly parse consumer.config option, handle exceptions during message processing, and print number of processed messages to stderr.",2015-08-26 18:38:43,Ewen Cheslack-Postava,Mixed
492bfdfa873db649049382b9785cefef2d6d1eca,"KAFKA-2367; Add Copycat runtime data API.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Gwen Shapira, Jay Kreps

Closes #163 from ewencp/kafka-2367-copycat-runtime-data-api",2015-08-27 11:58:42,Ewen Cheslack-Postava,Mixed
2fa8c748537a86a8b81b43ab7df060b6e61f5085,"KAFKA-2377: Add basic system test for copycat using source and sink file connectors.

Tests standalone mode by running separate source and sink connectors, catting
data into the source file, and validating the output in the sink file. Restarts
the service to verify that clean restarts will result in tasks resuming where
they left off.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Geoff Andreson, Gwen Shapira

Closes #150 from ewencp/kafka-2377-copycat-system-test",2015-08-27 13:53:00,Ewen Cheslack-Postava,Mixed
3803e5cb37cb602ff9eab5562ff8db3a2dd79b45,"KAFKA-2475: Make Copycat only have a Converter class instead of Serializer, Deserializer, and Converter.

The Converter class now translates directly between byte[] and Copycat's data
API instead of requiring an intermediate runtime type like Avro's GenericRecord
or Jackson's JsonNode.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Gwen Shapira

Closes #172 from ewencp/kafka-2475-unified-serializer-converter and squashes the following commits:

566c52f [Ewen Cheslack-Postava] Checkstyle fixes
320d0df [Ewen Cheslack-Postava] Restrict offset format.
85797e7 [Ewen Cheslack-Postava] Add StringConverter for using Copycat with raw strings.
698d65c [Ewen Cheslack-Postava] Move and update outdated comment about handing of types for BYTES type in Copycat.
4bed051 [Ewen Cheslack-Postava] KAFKA-2475: Make Copycat only have a Converter class instead of Serializer, Deserializer, and Converter.",2015-08-31 12:26:16,Ewen Cheslack-Postava,Mixed
d02ca36ca1cccdb6962191b97f54ce96b9d75abc,"KAFKA-2411; remove usage of blocking channel

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>, Gwen Shapira <cshapi@gmail.com>

Closes #151 from ijuma/kafka-2411-remove-usage-of-blocking-channel",2015-09-02 11:55:08,Ismael Juma,Mixed
689d170ac32ed15af9098faa03a97609af14bf05,"kafka-2210; KafkaAuthorizer: Add all public entities, config changes and changes to KafkaAPI and kafkaServer to allow pluggable authorizer implementation; patched by Parth Brahmbhatt; reviewed Ismael Juma and Jun Rao",2015-09-02 18:09:13,Parth Brahmbhatt,Mixed
f25731265ef63e5440a188b3e5553c31fb9a397b,"KAFKA-2519; NetworkClient.close should remove node from inFlightRequests

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #193 from ijuma/kafka-2519-network-client-close-remove-in-flight",2015-09-04 09:30:13,Ismael Juma,Mixed
b8b1bca44095df0481fc6bb0d7ea5c06686b9337,"KAFKA-2489: add benchmark for new consumer

ewencp
The changes here are smaller than they look - mostly refactoring/cleanup.

- ConsumerPerformanceService: added new_consumer flag, and exposed more command-line settings
- benchmark.py: refactored to use `parametrize` and `matrix` - this reduced some amount of repeated code
- benchmark.py: added consumer performance tests with new consumer (using `parametrize`)
- benchmark.py: added more detailed test descriptions
- performance.py: broke into separate files

Author: Geoff Anderson <geoff@confluent.io>

Reviewers: Ewen Cheslack-Postava, Jason Gustafson, Gwen Shapira

Closes #179 from granders/KAFKA-2489-benchmark-new-consumer",2015-09-08 17:59:49,Geoff Anderson,Not TDD
fd123965802f900fa474a8d5b1539e62d28bff73,"KAFKA-1893: Allow regex subscriptions in the new consumer

Author: Ashish Singh <asingh@cloudera.com>

Reviewers: Jason Gustafson, Guozhang Wang, Edward Ribeiro, Ismael Juma

Closes #128 from SinghAsDev/KAFKA-1893",2015-09-10 13:14:24,Ashish Singh,Mixed
845514d62329be8382e6d02b8041fc858718d534,"KAFKA-2389: remove commit type from new consumer.

A shot to remove commit type from new consumer. The coordinator constructor takes a default offset commit callback mainly for testing purpose.

Author: Jiangjie Qin <becket.qin@gmail.com>

Reviewers: Ewen Cheslack-Postava, Jason Gustafson, Guohang Wang

Closes #134 from becketqin/KAFKA-2389",2015-09-11 15:49:51,Jiangjie Qin,Mixed
65bf3afe86ef883136fcd6bc857724b25e750bd7,"KAFKA-2440; Use `NetworkClient` instead of `SimpleConsumer` to fetch data from replica

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Aditya Auradkar <aauradkar@linkedin.com>, Jun Rao <junrao@gmail.com>

Closes #194 from ijuma/kafka-2440-use-network-client-in-fetcher",2015-09-11 16:08:00,Ismael Juma,Mixed
7199c87c32b94daec612bc022607bb86103bd8b2,"MINOR: Added scripts to automate Vagrant setup for system tests

Updated testing README accordingly.

Author: Geoff Anderson <geoff@confluent.io>

Reviewers: Ewen Cheslack-Postava, Gwen Shapira

Closes #201 from granders/minor-vagrant-package-script",2015-09-14 15:00:04,Geoff Anderson,Not TDD
da39931afad8008bc2b385a75a462777be051435,"KAFKA-2120; Add a request timeout to NetworkClient (KIP-19); reviewed by Jason Gustafson, Ismael Juma, Joel Koshy, Jun Rao, and Edward Ribeiro",2015-09-16 10:31:57,Mayuresh Gharat,Mixed
9dbeb71ab258955e04b46991c1baf880b07633f4,"Revert ""KAFKA-2120; Add a request timeout to NetworkClient (KIP-19); reviewed by Jason Gustafson, Ismael Juma, Joel Koshy, Jun Rao, and Edward Ribeiro""

This reverts commit da39931afad8008bc2b385a75a462777be051435.",2015-09-17 14:36:01,Joel Koshy,Mixed
6ec88f7f8a18be7aff12fb0c73fc8abd00ef62d2,"KAFKA-2532; Remove Consumer reference from rebalance callback

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ewen Cheslack-Postava, Onur Karaman, Guozhang Wang

Closes #203 from hachikuji/KAFKA-2532",2015-09-21 13:14:17,Jason Gustafson,Mixed
0990b6ba6a28276f79a1a8bfaf48455c6eddfa1f,"KAFKA-2211: Adding simpleAclAuthorizer implementation and test cases.

Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #195 from Parth-Brahmbhatt/KAFKA-2211",2015-09-21 17:47:18,Parth Brahmbhatt,Mixed
4833d8a8c34b2fb86a5cf605ea5483d0b9eadc4f,"KAFKA-2558: ServerShutdownTest is failing intermittently

See jira for a description.

Author: fpj <fpj@apache.org>

Reviewers: Onur Karaman, Ismael Juma, Guozhang Wang

Closes #224 from fpj/KAFKA-2558",2015-09-21 18:25:42,Flavio Junqueira,Mixed
2837fa5a34420ea1ede90901ded6e9f3c94a3e7b,"KAFKA-2557: separate REBALANCE_IN_PROGRESS and ILLEGAL_GENERATION error codes

Author: Onur Karaman <okaraman@linkedin.com>

Reviewers: Jiangjie Qin, Jason Gustafson, Guozhang Wang

Closes #222 from onurkaraman/KAFKA-2557",2015-09-22 14:32:28,Onur Karaman,Not TDD
d1dd1e902685178a990861f9948fe07f820cf4ef,"KAFKA-2403; Add support for commit metadata in KafkaConsumer

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma, Guozhang Wang

Closes #119 from hachikuji/KAFKA-2403",2015-09-23 14:10:06,Jason Gustafson,Mixed
1daf6ac510602ee27210f069bbe7415d4610fbea,"KAFKA-1387: Kafka getting stuck creating ephemeral node it has already created when two zookeeper sessions are established in a very short period of time

This is a patch to get around the problem discussed in the KAFKA-1387 jira. The tests are not passing in my box when I run them all, but they do pass when I run them individually, which indicates that there is something leaking from a test to the next. I still need to work this out and also work on further testing this. I wanted to open this PR now so that it can start getting reviewed.

Author: flavio junqueira <fpj@apache.org>
Author: fpj <fpj@apache.org>
Author: Flavio Junqueira <fpj@apache.org>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>, Jun Rao <junrao@gmail.com>

Closes #178 from fpj/1387",2015-09-24 10:14:23,flavio junqueira,Mixed
bcf374da9e0d9ec8d13ecdaf4a1a15691549442b,"KAFKA-2390; followup; add unit test for OffsetOutOfRange exception

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Jason Gustafson, Guozhang Wang

Closes #239 from lindong28/KAFKA-2390-followup",2015-09-24 14:40:03,Dong Lin,Mixed
48b4d6938dfb9dc72c941e979ff0d0c4d921f743,"KAFKA-2373: Add Kafka-backed offset storage for Copycat.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Gwen Shapira, James Cheng

Closes #202 from ewencp/kafka-2373-copycat-distributed-offset",2015-09-24 19:01:11,Ewen Cheslack-Postava,Mixed
7e453df3179efed92d5bbe4ce9ee1d90a07cd503,"KAFKA-2409; have KafkaConsumer.committed return null when there is no commit

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Onur Karaman, Guozhang Wang

Closes #243 from hachikuji/KAFKA-2409",2015-09-25 11:08:24,Jason Gustafson,Mixed
263c10ab7c8e8fde9d3566bf59dccaa454ee2605,"KIP-28: Add a processor client for Kafka Streaming

This work has been contributed by Jesse Anderson, Randall Hauch, Yasuhiro Matsuda and Guozhang Wang. The detailed design can be found in https://cwiki.apache.org/confluence/display/KAFKA/KIP-28+-+Add+a+processor+client.

Author: Guozhang Wang <wangguoz@gmail.com>
Author: Yasuhiro Matsuda <yasuhiro.matsuda@gmail.com>
Author: Yasuhiro Matsuda <yasuhiro@confluent.io>
Author: ymatsuda <yasuhiro.matsuda@gmail.com>
Author: Randall Hauch <rhauch@gmail.com>
Author: Jesse Anderson <jesse@smokinghand.com>
Author: Ismael Juma <ismael@juma.me.uk>
Author: Jesse Anderson <eljefe6a@gmail.com>

Reviewers: Ismael Juma, Randall Hauch, Edward Ribeiro, Gwen Shapira, Jun Rao, Jay Kreps, Yasuhiro Matsuda, Guozhang Wang

Closes #130 from guozhangwang/streaming",2015-09-25 17:27:58,Guozhang Wang,Mixed
b62f8ea43b6d5307f7274fbe8b7984dd5ee22239,"KAFKA-2531: Add Ducktape based tests for KafkaLog4jAppender

Author: Ashish Singh <asingh@cloudera.com>

Reviewers: Geoff Anderson, Edwerd Ribeiro, Ewen Cheslack-Postava, Gwen Shapira

Closes #235 from SinghAsDev/KAFKA-2531",2015-09-26 18:32:49,Ashish Singh,Mixed
2c4e63a899c6cf832fba4be35773218a9ba5239f,"KAFKA-2120; Add a request timeout to NetworkClient (KIP-19); reviewed by Jason Gustafson, Ismael Juma, Joel Koshy, Jun Rao, and Edward Ribeiro",2015-09-29 10:30:03,Mayuresh Gharat,Mixed
73720113b97ccfcd796a844f87438546ed2e09e4,"MINOR: fix Quota's equal() function

It compares upper bound with itself.

Author: Edward Ribeiro <edward.ribeiro@gmail.com>

Reviewers: Aditya Auradkar, Ismael Juma, Guozhang Wang

Closes #182 from eribeiro/equals-bug",2015-09-29 10:54:45,Edward Ribeiro,Not TDD
5e769ccd5bf81f82c90069d4b0e79182a1cfe3c0,"KAFKA-2570: commit offsets on rebalance/close when auto-commit is enabled

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang

Closes #257 from hachikuji/KAFKA-2570",2015-09-29 17:49:06,Jason Gustafson,Mixed
5764e54de147af81aac85acc00687c23e9646a5c,"KAFKA-2212: Authorizer CLI implementation.

Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>
Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #230 from Parth-Brahmbhatt/KAFKA-2212",2015-10-01 18:04:09,Parth Brahmbhatt,Mixed
a3bd99811c6ed7b30611ff0592e4ce7bc8537260,"MINOR: remove no longer needed CommitType

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma, Guozhang Wang

Closes #258 from hachikuji/delete-committype",2015-10-02 15:09:28,Jason Gustafson,Not TDD
37f7d75e3d55c600902cd15c3cb219ddd221d23c,"KAFKA-2591: Fix StreamingMetrics

Remove state storage upon unclean shutdown and fix streaming metrics used for local state.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Edward Ribeiro, Yasuhiro Matsuda, Jun Rao

Closes #265 from guozhangwang/K2591",2015-10-02 20:12:34,Guozhang Wang,Mixed
b46cb3b2975afd8a3e82a0265c57760d8b9910da,"KAFKA-2599: Fix Metadata.getClusterForCurrentTopics throws NPE

…h null checking

Author: Edward Ribeiro <edward.ribeiro@gmail.com>

Reviewers: Ismael Juma, Guozhang Wang

Closes #262 from eribeiro/KAFKA-2599",2015-10-06 13:39:17,Edward Ribeiro,Mixed
23f9afb70bc5cdbf66550a1e69161e2fe06a909a,"KAFKA-2482: Allow sink tasks to get their current assignment, as well as pause and resume topic partitions.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Guozhang Wang

Closes #249 from ewencp/kafka-2482-sink-tasks-pause-consumption",2015-10-06 14:26:08,Ewen Cheslack-Postava,Mixed
174a43cd09d3a2a2785daf0cfa5ada1646d8bfcc,"KAFKA-2474: Add caching of JSON schema conversions to JsonConverter

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Ismael Juma, Guozhang Wang

Closes #250 from ewencp/kafka-2474-cache-json-schema-conversions",2015-10-06 15:31:28,Ewen Cheslack-Postava,Mixed
02e103b75aa6161c27358e83ab2828515c876701,"KAFKA-2476: Add Decimal, Date, and Timestamp logical types.

To support Decimal, this also adds support for schema parameters, which is an
extra set of String key value pairs which provide extra information about the
schema. For Decimal, this is used to encode the scale parameter, which is part
of the schema instead of being passed with every value.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Guozhang Wang

Closes #281 from ewencp/kafka-2476-copycat-logical-types",2015-10-06 22:02:46,Ewen Cheslack-Postava,Mixed
2047a9afe1ef9cf81e6347fe27f0051c8758d226,"KAFKA-2534: Fixes and unit tests for SSLTransportLayer buffer overflow

Unit tests which mock buffer overflow and underflow in the SSL transport layer and fixes for the couple of issues in buffer overflow handling described in the JIRA.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Sriharsha Chintalapani <schintalapani@hortonworks.com>, Jun Rao <junrao@gmail.com>

Closes #205 from rajinisivaram/KAFKA-2534",2015-10-07 09:28:22,Rajini Sivaram,Mixed
118912e76e5c867a8727f90d40bb969e0e6b65c5,"KAFKA-2419; Garbage collect unused sensors

As discussed in KAFKA-2419 - I've added a time based sensor retention config to Sensor. Sensors that have not been ""recorded"" for 'n' seconds are eligible for expiration.

In addition to the time based retention, I've also altered several tests to close the Metrics and scheduler objects since they can cause leaks while running tests. This causes TestUtils.verifyNonDaemonThreadStatus to fail.

Author: Aditya Auradkar <aauradka@aauradka-mn1.linkedin.biz>
Author: Aditya Auradkar <aauradka@aauradka-mn1.(none)>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Joel Koshy <jjkoshy.w@gmail.com>

Closes #233 from auradkar/K-2419",2015-10-07 13:08:07,Aditya Auradkar,Mixed
2254f2bfaf5a6a2332ec390471ff3a7c34b8b890,"Kafka-2587:  Only notification handler will update the cache and all verifications will use waitUntilTrue.

Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #277 from Parth-Brahmbhatt/KAFKA-2587",2015-10-07 18:13:58,Parth Brahmbhatt,Mixed
6a06e22ef81aae3335ca59c94cb0fc33e9f4ceff,"KAFKA-2596: reject commits from unknown groups with positive generations

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Onur Karaman, Guozhang Wang

Closes #267 from hachikuji/KAFKA-2596",2015-10-08 23:39:17,Jason Gustafson,Mixed
49822ff836e0fcd2a30bdf994d7b881a9de95cdf,"KAFKA-2622: Add Time logical type for Copycat.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Guozhang Wang

Closes #285 from ewencp/kafka-2622-time-logical-type",2015-10-09 11:59:38,Ewen Cheslack-Postava,Mixed
7233858bea1c548153ed00b7edffd55299db7cf2,"KAFKA-2600: Align Kafka Streams' interfaces with Java 8 functional interfaces

A few of Kafka Stream's interfaces and classes are not as well-aligned with Java 8's functional interfaces. By making these changes, when Kafka moves to Java 8 these classes can extend standard Java 8 functional interfaces while remaining backward compatible. This will make it easier for developers to use Kafka Streams, and may allow us to eventually remove these custom interfaces and just use the standard Java 8 interfaces.

The changes include:

1. The 'apply' method of KStream's `Predicate` functional interface was renamed to `test` to match the method name on `java.util.function.BiPredicate`. This will allow KStream's `Predicate` to extend `BiPredicate` when Kafka moves to Java 8, and for the `KStream.filter` and `filterOut` methods to accept `BiPredicate`.
2. Renamed the `ProcessorDef` and `WindowDef` interfaces to `ProcessorSupplier` and `WindowSupplier`, respectively. Also the `SlidingWindowDef` class was renamed to `SlidingWindowSupplier`, and the `MockProcessorDef` test class was renamed to `MockProcessorSupplier`. The `instance()` method in all were renamed to `get()`, so that all of these can extend/implement Java 8's `java.util.function.Supplier<T>` interface in the future with no other changes and while remaining backward compatible. Variable names that used some form of ""def"" were changed to use ""supplier"".

These two sets of changes were made in separate commits.

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Ismael Juma, Guozhang Wang

Closes #270 from rhauch/kafka-2600",2015-10-09 12:19:07,Randall Hauch,Mixed
c67ca65889721e3af7527ab26df49a9fb4db87ef,"MINOR: putting back kstream stateful transform methods

guozhangwang

* added back type safe stateful transform methods (kstream.transform() and kstream.transformValues())
* changed kstream.process() to void

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang

Closes #292 from ymatsuda/transform_method",2015-10-09 16:28:40,Yasuhiro Matsuda,Mixed
1265d7cb7f56b5f5aad940250dc705a9a060a6f0,"KAFKA-2614; No more clients can connect after `TooManyConnectionsException` threshold (max.connections.per.ip) is reached

* Call `ConnectionQuotas.decr` when calling `Selector.close` and when disconnections happen.
* Expand `SocketServerTest` to test for this and to close sockets.
* Refactor and clean-up `SocketServer` and `Acceptor` to make the code easier to understand.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #288 from ijuma/kafka-2614-connection-count-not-updated",2015-10-10 15:24:36,Ismael Juma,Mixed
9fde92f9f1f1e40ceb6b3d5ff9676ba590385825,"KAFKA-2443 KAFKA-2567; Expose windowSize on Rate; - Throttle time should not return NaN

This is a followup ticket from KAFKA-2084 to improve the windowSize calculation in Quotas. I've made the following changes:

1. Added a windowSize function on Rate
2. Calling Rate.windowSize in ClientQuotaManager to return the exact window size to use when computing the delay time.
3. Changed the window size calculation subtly. The current calculation had a bug wherein, it used the number of elapsed seconds from the ""lastWindowSeconds"" of the most recent Sample object. However, the lastWindowSeconds is the time when the sample is created.. this causes an issue because it implies that the current window elapsed time is always ""0"" when the sample is created. This is incorrect as demonstrated in a testcase I added in MetricsTest. I've fixed the calculation to count the elapsed time from the ""oldest"" sample in the set since that gives us an accurate value of the exact amount of time elapsed

Author: Aditya Auradkar <aauradkar@linkedin.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Joel Koshy <jjkoshy.w@gmail.com>

Closes #213 from auradkar/K-2443",2015-10-12 12:22:39,Aditya Auradkar,Mixed
dd514b2bb8c476642952bf923de8d4c81bbeca7d,"KAFKA-2581: Run some existing ducktape tests with SSL

Parametrize console consumer sanity test, replication tests and benchmarks tests to run with both PLAINTEXT and SSL.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Geoff Anderson, Ewen Cheslack-Postava, Guozhang Wang

Closes #271 from rajinisivaram/KAFKA-2581",2015-10-12 17:19:45,Rajini Sivaram,Mixed
e2ec02e1d1580e73c06f1acbf3a53a1b8ee52930,"KAFKA-2637; Cipher suite setting should be configurable for SSL

Enables Cipher suite setting. Code was previously reviewed by ijuma, harshach. Moving to an independent PR.

Author: benstopford <benstopford@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Sriharsha Chintalapani <harsha@hortonworks.com>

Closes #301 from benstopford/cipher-switch",2015-10-13 06:59:25,benstopford,Mixed
36d4469326fe20c3f0657315321e6ad515530a3e,"KAFKA-2372: Add Kafka-backed storage of Copycat configs.

This also adds some other needed infrastructure for distributed Copycat, most
importantly the DistributedHerder, and refactors some code for handling
Kafka-backed logs into KafkaBasedLog since this is shared betweeen offset and
config storage.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Gwen Shapira, James Cheng

Closes #241 from ewencp/kafka-2372-copycat-distributed-config",2015-10-13 10:23:21,Ewen Cheslack-Postava,Mixed
123d27e4d005a384611671133fbecde7e390d24f,"KAFKA-2527; System Test for Quotas in Ducktape

granders Can you take a look at this quota system test?

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Geoff Anderson, Ewen Cheslack-Postava

Closes #275 from lindong28/KAFKA-2527",2015-10-13 13:54:40,Dong Lin,Not TDD
27c099b043704d16a22c33e0602f0ae7295cab25,"MINOR: ignore wakeups when committing offsets on consumer close

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Gwen Shapira

Closes #306 from hachikuji/handle-wakeup-in-consumer-close",2015-10-13 18:50:32,Jason Gustafson,Not TDD
6e571225d51f5d71ffcfc4d22d108e89ae2f46ec,"KAFKA-2593: Key value stores can use specified serializers and deserializers

Add support for the key value stores to use specified serializers and deserializers (aka, ""serdes""). Prior to this change, the stores were limited to only the default serdes specified in the topology's configuration and exposed to the processors via the ProcessorContext.

Now, using InMemoryKeyValueStore and RocksDBKeyValueStore are similar: both are parameterized on the key and value types, and both have similar multiple static factory methods. The static factory methods either take explicit key and value serdes, take key and value class types so the serdes can be inferred (only for the built-in serdes for string, integer, long, and byte array types), or use the default serdes on the ProcessorContext.

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Guozhang Wang

Closes #255 from rhauch/kafka-2593",2015-10-14 13:59:10,Randall Hauch,Mixed
5013a41a514973e9612012413832e063ab062aef,"KAFKA-2650: Change ConfigCommand --deleted-config option to align wit…

…h TopicCommand

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Gwen Shapira

Closes #308 from granthenke/configcommand",2015-10-14 14:06:14,Grant Henke,Mixed
a4dbf9010754183965772066a9cd2c5c4a49d44a,"KAFKA-2295; Support dynamically loaded classes from context class loader

Rebased code..

Author: Manikumar reddy O <manikumar.reddy@gmail.com>

Reviewers: Guozhang Wang

Closes #314 from omkreddy/KAFKA-2295",2015-10-15 11:11:32,Manikumar reddy O,Mixed
aa66b42daca0791840da3c77d47c96cf98f19ef2,"KAFKA-2419 - Fix to prevent background thread from getting created when not required

See here for more discussion: https://issues.apache.org/jira/browse/KAFKA-2419
Basically, the fix involves adding a param to Metrics to indicate if it is capable of metric cleanup or not.

Author: Aditya Auradkar <aauradka@aauradka-mn1.linkedin.biz>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #323 from auradkar/KAFKA-2419-fix",2015-10-16 09:47:04,Aditya Auradkar,Mixed
c553249b4e6d7d385821061f9742f15f90e94def,"KAFKA-2594: Add InMemoryLRUCacheStore as a preliminary method for bounding in-memory stores

Added a new `KeyValueStore` implementation called `InMemoryLRUCacheStore` that keeps a maximum number of entries in-memory, and as the size exceeds the capacity the least-recently used entry is removed from the store and the backing topic. Also added unit tests for this new store and the existing `InMemoryKeyValueStore` and `RocksDBKeyValueStore` implementations. A new `KeyValueStoreTestDriver` class simplifies all of the other tests, and can be used by other libraries to help test their own custom implementations.

This PR depends upon [KAFKA-2593](https://issues.apache.org/jira/browse/KAFKA-2593) and its PR at https://github.com/apache/kafka/pull/255. Once that PR is merged, I can rebase this PR if desired.

Two issues were uncovered when creating these new unit tests, and both are also addressed as separate (small) commits in this PR:
* The `RocksDBKeyValueStore` initialization was not creating the file system directory if missing.
* `MeteredKeyValueStore` was casting to `ProcessorContextImpl` to access the `RecordCollector`, which prevent using `MeteredKeyValueStore` implementations in tests where something other than `ProcessorContextImpl` was used. The fix was to introduce a `RecordCollector.Supplier` interface to define this `recordCollector()` method, and change `ProcessorContextImpl` and `MockProcessorContext` to both implement this interface. Now, `MeteredKeyValueStore` can cast to the new interface to access the record collector rather than to a single concrete implementation, making it possible to use any and all current stores inside unit tests.

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Edward Ribeiro, Guozhang Wang

Closes #256 from rhauch/kafka-2594",2015-10-16 14:46:26,Randall Hauch,Mixed
ef65d0a360ed65180ddd84d17679f24671c66e14,"KAFKA-2484: Add schema projection utilities

This PR adds schema projection utilities to copycat.

Author: Liquan Pei <liquanpei@gmail.com>

Reviewers: Ewen Cheslack-Postava

Closes #307 from Ishiihara/schema-projection",2015-10-16 15:44:31,Liquan Pei,Mixed
e2e5c891428e5f1288b6f4674983d924f8bdb779,"KAFKA-2515: Handle oversized messages properly in new consumer

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Dong Lin, Jun Rao

Closes #318 from guozhangwang/K2515",2015-10-16 17:39:39,Guozhang Wang,Mixed
636e14a99191eeededfb933aacfe2459c7c7bb6f,"KAFKA-2397: add leave group request to force coordinator trigger rebalance

Let's say every consumer in a group has session timeout s. Currently, if a consumer leaves the group, the worst case time to stabilize the group is 2s (s to detect the consumer failure + s for the rebalance window). If a consumer instead can declare they are leaving the group, the worst case time to stabilize the group would just be the s associated with the rebalance window.

This is a low priority optimization!

Author: Onur Karaman <okaraman@linkedin.com>

Reviewers: Jason Gustafson, Guozhang Wang

Closes #103 from onurkaraman/leave-group",2015-10-16 17:46:17,Onur Karaman,Not TDD
ce306ba4ebc77464bf8ff4d656e1f1f44979182e,"KAFKA-2639: Refactoring of ZkUtils

I've split the work of KAFKA-1695 because this refactoring touches a large number of files. Most of the changes are trivial, but I feel it will be easier to review this way.

This pull request includes the one Parth-Brahmbhatt started to address KAFKA-1695.

Author: flavio junqueira <fpj@apache.org>
Author: Flavio Junqueira <fpj@apache.org>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #303 from fpj/KAFKA-2639",2015-10-18 15:23:52,flavio junqueira,Mixed
343db8a7f4d22a593f0aecc79d55869350803889,"KAFKA-2669; Fix LogCleaner.awaitCleaned for LogCleanerIntegrationTest

LogCleanerIntegrationTest calls LogCleaner.awaitCleaned() to wait until cleaner has processed up to given offset. However, existing awaitCleaned() implementation doesn't wait for this. This patch fix the problem.

Author: Dong Lin <lindong@cis.upenn.edu>
Author: Dong Lin <lindong28@gmail.com>

Reviewers: Ismael Juma, Guozhang Wang

Closes #327 from lindong28/KAFKA-2669",2015-10-19 14:50:18,Dong Lin,Not TDD
403158b54b18cabf93eb15d4c4dd8ab66604bf9f,"KAFKA-1686; Implement SASL/Kerberos

This PR implements SASL/Kerberos which was originally submitted by harshach as https://github.com/apache/kafka/pull/191.

I've been submitting PRs to Harsha's branch with fixes and improvements and he has integrated all, but the most recent one. I'm creating this PR so that the Jenkins can run the tests on the branch (they pass locally).

Author: Ismael Juma <ismael@juma.me.uk>
Author: Sriharsha Chintalapani <harsha@hortonworks.com>
Author: Harsha <harshach@users.noreply.github.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>, Parth Brahmbhatt <brahmbhatt.parth@gmail.com>, Jun Rao <junrao@gmail.com>

Closes #334 from ijuma/KAFKA-1686-V1",2015-10-20 14:13:34,Sriharsha Chintalapani,Mixed
0785feeb0fae2a4f75a59147197c5138109b1b39,"KAFKA-2459: Mark last committed timestamp to fix connection backoff

This fix applies to three JIRAs, since they are all connected.

KAFKA-2459Connection backoff/blackout period should start when a connection is disconnected, not when the connection attempt was initiated
Backoff when connection is disconnected

KAFKA-2615Poll() method is broken wrt time
Added Time through the NetworkClient API. Minimal change.

KAFKA-1843Metadata fetch/refresh in new producer should handle all node connection states gracefully
I’ve partially addressed this for a specific failure case in the JIRA.

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Ewen Cheslack-Postava, Jason Gustafson, Ismael Juma, Guozhang Wang

Closes #290 from enothereska/trunk",2015-10-21 10:04:49,Eno Thereska,Mixed
1d4a0b8811d82a6465015a71194a712679d63efe,"KAFKA-2667: Fix transient error in KafkaBasedLogTest.

The test required a specific sequence of events for each Consumer.poll() call,
but the MockConsumer.waitForPollThen() method could not guarantee that,
resulting in race conditions. Add support for scheduling sequences of events
even when running in multi-threaded environments.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Guozhang Wang

Closes #333 from ewencp/kafka-2667-kafka-based-log-transient-error",2015-10-21 11:20:29,Ewen Cheslack-Postava,Not TDD
86eb74d9236c586af5889fe79f4b9e066c9c2af3,"KAFKA-2464: client-side assignment for new consumer

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Jiangjie Qin, Onur Karaman, Ewen Cheslack-Postava, Guozhang Wang

Closes #165 from hachikuji/KAFKA-2464",2015-10-21 12:13:42,Jason Gustafson,Mixed
361686d4a999298b6e5b63cacda72168172eb936,"KAFKA-2618; Disable SSL renegotiation for 0.9.0.0

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Sriharsha Chintalapani <schintalapani@hortonworks.com>, Rajini Sivaram <rajinisivaram@googlemail.com>, Jun Rao <junrao@gmail.com>

Closes #339 from ijuma/kafka-2618-disable-renegotiation",2015-10-21 14:39:39,Ismael Juma,Mixed
d9b1dc70817de9366513b0cbed0b6e0702d473fa,"KAFKA-2209; Change quotas dynamically using DynamicConfigManager

Changes in this patch are:
1. ClientIdConfigHandler now passes through the config changes to the quota manager.
2. Removed static KafkaConfigs for quota overrides. These are no longer needed since we can override configs through ZooKeeper.
3. Added testcases to verify that the config changes are propogated from ZK (written using AdminTools) to the actual Metric objects.

Author: Aditya Auradkar <aauradka@aauradka-mn1.(none)>
Author: Aditya Auradkar <aauradka@aauradka-mn1.linkedin.biz>

Reviewers: Dong Lin <lindong28@gmail.com>, Jun Rao <junrao@gmail.com>

Closes #298 from auradkar/K-2209",2015-10-21 16:07:39,Aditya Auradkar,Mixed
65922b5388561e3ab830fd1f367faa289d205e2a,"KAFKA-2456 KAFKA-2472; SSL clean-ups

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #342 from ijuma/kafka-2472-fix-kafka-ssl-config-warnings",2015-10-21 17:10:36,Ismael Juma,Mixed
aa56dfb9e7cea19faa545a13d42d499a6958cbef,"KAFKA-2686: Reset needsPartitionAssignment in SubscriptionState.assign()

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Jason Gustafson, Jun Rao

Closes #352 from guozhangwang/K2686",2015-10-22 21:06:10,Guozhang Wang,Mixed
21443f214fc6f1f51037e27f8ece155cf1eb288c,"KAFKA-2641; Upgrade path for ZK authentication

This pull request adds a configuration parameter and a migration tool. It is also based on pull request #303, which should go in first.

Author: flavio junqueira <fpj@apache.org>
Author: Flavio Junqueira <fpj@apache.org>
Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #313 from fpj/KAFKA-2641",2015-10-23 15:11:07,flavio junqueira,Mixed
2e61773590c0ba86cb8813e6ba17bf6ee33f4461,"KAFKA-2371: Add distributed support for Copycat.

This adds coordination between DistributedHerders using the generalized consumer
support, allowing automatic balancing of connectors and tasks across workers. A
few pieces that require interaction between workers (resolving config
inconsistencies, forwarding of configuration changes to the leader worker) are
incomplete because they require REST API support to implement properly.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Jason Gustafson, Gwen Shapira

Closes #321 from ewencp/kafka-2371-distributed-herder",2015-10-23 16:37:30,Ewen Cheslack-Postava,Mixed
6f2f1f9843f537b9bda3aa3951a867fdee661761,"KAFKA-2626: Handle null keys and value validation properly in OffsetStorageWriter.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Gwen Shapira

Closes #345 from ewencp/kafka-2626-offset-storage-writer-null-values",2015-10-23 17:01:33,Ewen Cheslack-Postava,Not TDD
16f194b20ad9795188f1d7781e7cbca1cd2a6a2d,"KAFKA-2460; Fix capitalisation in SSL classes

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>

Closes #355 from ijuma/kafka-2460-fix-capitalisation-in-ssl-classes",2015-10-24 09:42:19,Ismael Juma,Mixed
71399ffe4c52e2539a5794a17852c8c5b3d5fe72,"KAFKA-2652: integrate new group protocol into partition grouping

guozhangwang

* added ```PartitionGrouper``` (abstract class)
 * This class is responsible for grouping partitions. Each group forms a task.
 * Users may implement this class for custom grouping.
* added ```DefaultPartitionGrouper```
 * our default implementation of ```PartitionGrouper```
* added ```KafkaStreamingPartitionAssignor```
 * We always use this as ```PartitionAssignor``` of stream consumers.
 * Actual grouping is delegated to ```PartitionGrouper```.
* ```TopologyBuilder```
 * added ```topicGroups()```
   * This returns groups of related topics according to the topology
 * added ```copartitionSources(sourceNodes...)```
   * This is used by DSL layer. It asserts the specified source nodes must be copartitioned.
 * added ```copartitionGroups()```
   * This returns groups of copartitioned topics
* KStream layer
 * keep track of source nodes to determine copartition sources when steams are joined
 * source nodes are set to null when partitioning property is not preserved (ex. ```map()```, ```transform()```), and this indicates the stream is no longer joinable

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang

Closes #353 from ymatsuda/grouping",2015-10-26 13:33:51,Yasuhiro Matsuda,Mixed
b251bebbcc3074f0491fce988f1d46ccdc97f1fa,"MINOR: follow-up to KAFKA-2464 for renaming/cleanup

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ewen Cheslack-Postava, Jiangjie Qin, Guozhang Wang

Closes #354 from hachikuji/KAFKA-2464",2015-10-26 18:30:41,Jason Gustafson,Mixed
e6f9b9e473f0396743cdfc5236bfd551316fc6f7,"KAFKA-2694: Reformat task id as group id and partition id

guozhangwang

* A task id is now a class, ```TaskId```, that has a topic group id and a partition id fields.
* ```TopologyBuilder``` assigns a topic group id to a topic group. Related methods are changed accordingly.
* A state store uses the partition id part of the task id as the change log partition id.

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang

Closes #365 from ymatsuda/task_id",2015-10-26 20:14:19,Yasuhiro Matsuda,Mixed
c6c4f50703ff250b737080aaf239969473af99f0,"HOTFIX: group rebalance can throw illegal generation or rebalance in progress

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang

Closes #370 from hachikuji/hotfix-rebalance-error",2015-10-27 13:44:59,Jason Gustafson,Not TDD
e6b343302f3208f7f6e0099fe2a7132ef9eaaafb,"KAFKA-1888: rolling upgrade test

ewencp gwenshap
This needs some refactoring to avoid the duplicated code between replication test and upgrade test, but in shape for initial feedback.

I'm interested in feedback on the added `KafkaConfig` class and `kafka_props` file. This addition makes it:
- easier to attach different configs to different nodes (e.g. during broker upgrade process)
- easier to reason about the configuration of a particular node

Notes:
- in the default values in the KafkaConfig class, I removed many properties which were in kafka.properties before. This is because most of those properties were set to what is already the default value.
- when running non-trunk VerifiableProducer, I append the trunk tools jar to the classpath, and run it with the non-trunk kafka-run-class.sh script

Author: Geoff Anderson <geoff@confluent.io>

Reviewers: Dong Lin, Ewen Cheslack-Postava

Closes #229 from granders/KAFKA-1888-upgrade-test",2015-10-27 15:23:47,Geoff Anderson,Mixed
1ac2640f8095262f423c770060b737f81652e211,"KAFKA-2683: ensure wakeup exceptions raised to user

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ewen Cheslack-Postava, Guozhang Wang

Closes #366 from hachikuji/KAFKA-2683",2015-10-27 17:39:19,Jason Gustafson,Mixed
b6fe164dd6f9483469c0b0661c24467e33e91cd9,"MINOR: Clean-up MemoryRecords variables and APIs

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Jun Rao

Closes #348 from guozhangwang/MemoryRecordsCapacity",2015-10-28 10:11:05,Guozhang Wang,Mixed
9855bb9c655ebad0ed5586175452056466189b8a,"KAFKA-2675; SASL/Kerberos follow up

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Sriharsha Chintalapani <schintalapani@hortonworks.com>, Jun Rao <junrao@gmail.com>

Closes #376 from ijuma/KAFKA-2675-sasl-kerberos-follow-up",2015-10-28 10:48:39,Ismael Juma,Mixed
8838fa8010c146af6aab014a41bc7e68318b4eb0,"MINOR: KAFKA-2371 follow-up, DistributedHerder should wakeup WorkerGroupMember after assignment to ensure work is started immediately

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Gwen Shapira

Closes #360 from ewencp/minor-kafka-2371-follow-up-wakeup-after-rebalance",2015-10-28 12:42:03,Ewen Cheslack-Postava,Mixed
983b1f9e17a0f392cfb7785f572c767540a12e2b,"KAFKA-2640; Add tests for ZK authentication

I've added a couple of initial tests to verify the functionality. I've tested that the JAAS config file loads properly and SASL with DIGEST-MD5 works with ZooKeeper.

Author: Flavio Junqueira <fpj@apache.org>
Author: flavio junqueira <fpj@apache.org>
Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #324 from fpj/KAFKA-2640",2015-10-28 13:20:26,Flavio Junqueira,Not TDD
443cd9ab0db5223b7c85ac8333f2fc1a0e554870,"KAFKA-2648: enforce non-empty group-ids in join-group request

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang

Closes #362 from hachikuji/KAFKA-2648",2015-10-28 14:14:11,Jason Gustafson,Not TDD
1b5687b9e4cd10e0f91fb921d3569fdd44be163d,"KAFKA-2598; Adding integration test for the authorizer at API level. …

…Some bug fixes that I encountered while running the tests.

Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #300 from Parth-Brahmbhatt/KAFKA-2598",2015-10-29 08:30:06,Parth Brahmbhatt,Not TDD
42bcc4339f41bed320edde8bf141d0702798c021,"KAFKA-2705; Remove static JAAS config file for ZK auth tests

Remove static login config file.

Author: Flavio Junqueira <fpj@apache.org>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #380 from fpj/KAFKA-2705",2015-10-29 12:00:50,Flavio Junqueira,Not TDD
d9ae33d4c0473ef53a9ea560536467333136c0a0,"KAFKA-2711; SaslClientAuthenticator no longer needs KerberosNameParser in constructor

Also refactor `KerberosNameParser` and `KerberosName` to make the code
clearer and easier to use when `shortName` is not needed.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #390 from ijuma/kafka-2711",2015-10-30 08:53:16,Ismael Juma,Mixed
c001b2040cb7bf3a24aa77ec8de1312d4f780620,"KAFKA-2369: Add REST API for Copycat.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Gwen Shapira, James Cheng

Closes #378 from ewencp/kafka-2369-copycat-rest-api",2015-10-30 15:00:00,Ewen Cheslack-Postava,Mixed
d50499a0e08586d61445df6e287762333dc22d0a,"KAFKA-2715: Removed previous system_test folder

ewencp Nothing too complicated here

Author: Geoff Anderson <geoff@confluent.io>

Reviewers: Ewen Cheslack-Postava, Gwen Shapira

Closes #392 from granders/minor-remove-system-test",2015-10-30 15:13:16,Geoff Anderson,Mixed
1cc44830b90688f1a2034243b8ee03b97101f75c,"KAFKA-2562: update kafka scripts to use new tools/code

Updated  kafka-producer-perf-test.sh to use org.apache.kafka.clients.tools.ProducerPerformance.
Updated build.gradle to add kafka-tools-0.9.0.0-SNAPSHOT.jar to kafka/libs  folder.

Author: Manikumar reddy O <manikumar.reddy@gmail.com>

Reviewers: Gwen Shapira, Ismael Juma

Closes #242 from omkreddy/KAFKA-2562",2015-10-30 15:30:34,Manikumar reddy O,Not TDD
eec222e9828b36064827f206b398655aa2d4cd29,"KAFKA-2574: Add ducktape based ssl test for KafkaLog4jAppender

Author: Ashish Singh <asingh@cloudera.com>

Reviewers: Gwen Shapira, Geoff Anderson

Closes #319 from SinghAsDev/KAFKA-2574",2015-10-30 17:50:11,Ashish Singh,Mixed
b944356990d97401721a5752f8dcdd1ac5b8d4d4,"KAFKA-2660; Correct cleanableRatio calculation

onurkaraman Could you have a look? This is the patch I discussed with you.

Author: Dong Lin <lindong28@gmail.com>
Author: Dong Lin <lindong@cis.upenn.edu>

Reviewers: Onur Karaman <okaraman@linkedin.com>, Joel Koshy <jjkoshy@gmail.com>, Jun Rao <junrao@gmail.com>

Closes #316 from lindong28/KAFKA-2660",2015-10-30 18:14:20,Dong Lin,Mixed
9d8dd9f104aef3a9db9005d85bc55a15f851d258,"KAFKA-2680; Use IBM ConfigFile class to load jaas config if IBM JDK

Use IBM ConfigFile class with IBM JDK since JavaLoginConfig provided by SUN provider is not included with IBM JDK.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Flavio Junqueira <fpj@apache.org>, Jun Rao <junrao@gmail.com>

Closes #357 from rajinisivaram/KAFKA-2680",2015-10-31 09:01:59,Rajini Sivaram,Not TDD
758272267c811bf559336ea45571bc420a62a478,"KAFKA-2706: make state stores first class citizens in the processor topology

* Added StateStoreSupplier
* StateStore
  * Added init(ProcessorContext context) method
* TopologyBuilder
  * Added addStateStore(StateStoreSupplier supplier, String... processNames)
  * Added connectProessorAndStateStores(String processorName, String... stateStoreNames)
    * This is for the case processors are not created when a store is added to the topology. (used by KStream)
* KStream
  * add stateStoreNames to process(), transform(), transformValues().
* Refactored existing state stores to implement StateStoreSupplier

guozhangwang

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang

Closes #387 from ymatsuda/state_store_supplier",2015-11-02 13:24:48,Yasuhiro Matsuda,Mixed
e466ccd711ae00c5bb046c18aacf353b1a460dcd,"KAFKA-2707: make KStream processor names deterministic

guozhangwang

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang

Closes #408 from ymatsuda/kstream_processor_name",2015-11-02 14:40:52,Yasuhiro Matsuda,Mixed
7c33475274cb6e65a8e8d907e7fef6e56bc8c8e6,"KAFKA-2017: Persist Group Metadata and Assignment before Responding

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Onur Karaman, Jason Gustafson, Jun Rao

Closes #386 from guozhangwang/K2017",2015-11-02 23:41:58,Guozhang Wang,Mixed
5aa5f19d38eda33f32e170e14bcd4fd0d2835fc0,"KAFKA-2480: Add backoff timeout and support rewinds

Author: Liquan Pei <liquanpei@gmail.com>

Reviewers: Ewen Cheslack-Postava, Gwen Shapira

Closes #340 from Ishiihara/backoff",2015-11-03 13:17:20,Liquan Pei,Mixed
596c203af1f33360c04f4be7c466310d11343f78,"KAFKA-2687: Add support for ListGroups and DescribeGroup APIs

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang, Jun Rao

Closes #388 from hachikuji/K2687",2015-11-03 14:46:04,Jason Gustafson,Mixed
98db5ea94fcf7600137b5072453705c2a62e1f54,"KAFKA-2644; Run relevant ducktape tests with SASL_PLAINTEXT and SASL_SSL

Run sanity check, replication tests and benchmarks with SASL/Kerberos using MiniKdc.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Geoff Anderson <geoff@confluent.io>, Jun Rao <junrao@gmail.com>

Closes #358 from rajinisivaram/KAFKA-2644",2015-11-03 21:25:15,Rajini Sivaram,Mixed
70a7d5786cc3f04b5f3d964eb1fd1d826e9b9e0f,"KAFKA-2722; Improve ISR change propagation.

The patch has two changes:
1. fixed a bug in controller that it sends UpdateMetadataRequest of all the partitions in the cluster.
2. Uses the following rules to propagate ISR change: 1) if there are ISR changes pending propagation and the last ISR change is more than five seconds ago, propagate the changes. 2) if there is ISR change at T in the recent five seconds, delay the propagation until T + 5s. 3) if the last propagation is more than 1 min ago, ignore rule No.2 and propagate ISR change if there are changes pending propagation.

This algorithm avoids a fixed configuration of ISR propagation interval as we discussed about in KIP-29.

Author: Jiangjie Qin <becket.qin@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #402 from becketqin/KAFKA-2722",2015-11-04 05:52:16,Jiangjie Qin,Not TDD
421de0a3f93f8d21f7ca0f1287a4305c00edaa08,"KAFKA-2727: Topology partial construction

guozhangwang

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang

Closes #411 from ymatsuda/topology_partial_construction",2015-11-04 09:57:50,Yasuhiro Matsuda,Mixed
c39e79bb5af5b4e56bec358f8ec3758e6822dbcf,"KAFKA-2691: Improve handling of authorization failure during metadata refresh

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Jun Rao

Closes #394 from hachikuji/KAFKA-2691",2015-11-04 11:02:30,Jason Gustafson,Mixed
ef5d168cc8f10ad4f0efe9df4cbe849a4b35496e,"KAFKA-2697: client-side support for leave group

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ewen Cheslack-Postava, Guozhang Wang

Closes #414 from hachikuji/KAFKA-2697",2015-11-04 15:04:03,Jason Gustafson,Mixed
7d6515fb8f6141f5c34fe8434e97ea6ebd65941f,"KAFKA-2741: Make SourceTaskContext and SinkTaskContext interfaces and keep implementations in runtime jar.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Guozhang Wang

Closes #420 from ewencp/task-context-interfaces",2015-11-05 08:44:44,Ewen Cheslack-Postava,Mixed
b30d68a4e31cb49c2e664bb2e3263e056a27db40,"KAFKA-2743: Make forwarded task reconfiguration requests asynchronous on backoff on retrying.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Guozhang Wang

Closes #422 from ewencp/task-reconfiguration-async-with-backoff",2015-11-05 08:49:58,Ewen Cheslack-Postava,Mixed
a4551773ca8cb3c1b75cea873715f30053d88f47,"KAFKA-2748: Ensure sink tasks commit offsets upon rebalance and rewind if the SinkTask flush fails.

Also fix the incorrect consumer group ID setting which was giving each task its
own group instead of one for the entire sink connector.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Guozhang

Closes #431 from ewencp/kafka-2748-sink-task-rebalance-commit",2015-11-05 10:13:23,Ewen Cheslack-Postava,Mixed
7eee11451e1f0d17efa27775becfb370a9894d56,"KAFKA-2753: improve SyncGroup error handling in client

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang

Closes #433 from hachikuji/KAFKA-2753",2015-11-05 10:22:21,Jason Gustafson,Not TDD
490bbc91183d1468a164d80f826317f137026684,"KAFKA-2755: Suspicious reference forwarding cause NPE on handleDescribeGroup.

…xistent consumer group

Author: Ashish Singh <asingh@cloudera.com>

Reviewers: Guozhang Wang

Closes #435 from SinghAsDev/KAFKA-2755",2015-11-05 13:16:58,Ashish Singh,Not TDD
bf2563e2f73881491ea94e83013e0ff319a25016,"KAFKA-2735: BrokerEndPoint should support uppercase hostnames.

Added support for uppercase hostnames in BrokerEndPoint. Added unit test
to cover this scenario.

Author: jholoman <jeff.holoman@gmail.com>

Reviewers: Grant Henke, Guozhang Wang

Closes #415 from jholoman/KAFKA-2735",2015-11-05 13:31:01,Jeff Holoman,Mixed
33e879a389aeaff3576064b10a0f5dea5ad391ed,"KAFKA-2702: ConfigDef toHtmlTable() sorts in a way that is a bit conf…

…using

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Gwen Shapira

Closes #379 from granthenke/config-html",2015-11-05 18:17:30,Grant Henke,Mixed
c3c0c04e62253f2a9f78b383bbf0d1a04d9b3b25,"KAFKA-2490: support new consumer in ConsumerGroupCommand

Author: Ashish Singh <asingh@cloudera.com>

Reviewers: Guozhang Wang, Jason Gustafson

Closes #299 from SinghAsDev/KAFKA-2490",2015-11-05 18:56:26,Ashish Singh,Mixed
b1eaa46a512295abb4b4eb8b98402fc60a2c911a,"HOTFIX: unsubscribe does not clear user assignment properly

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Gwen Shapira

Closes #439 from hachikuji/unsubscribe-hotfix",2015-11-05 20:32:10,Jason Gustafson,Mixed
a76660ac811eb6e2cdf36a110ed4afb5bf3a617a,"KAFKA-2713: Run task start and stop methods in worker threads so they execute in parallel and cannot block the herder thread.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Gwen Shapira

Closes #443 from ewencp/kafka-2713-task-start-stop-threaded",2015-11-06 10:27:18,Ewen Cheslack-Postava,Mixed
c006c5916ef7a8048ed55db64db27c7b64a3af59,"KAFKA-2764: Change use of Properties in Copycat to Maps.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Gwen Shapira, Guozhang Wang

Closes #444 from ewencp/kafka-2764-maps-not-properties",2015-11-06 13:27:45,Ewen Cheslack-Postava,Mixed
a423316d388c386aa905b3d195487370f8703787,"KAFKA-2760: Clean up interface of AdminClient.describeConsumerGroup.

…roupId)

Author: Ashish Singh <asingh@cloudera.com>

Reviewers: Jason Gustafson, Guozhang Wang

Closes #442 from SinghAsDev/KAFKA-2760",2015-11-06 13:31:38,Ashish Singh,Mixed
d297b3af265a5be5a83ee11a990060231ea4cc25,"KAFKA-2765: Add versions to Copycat Connector and Task interfaces and log versions when instantiating connectors and tasks.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Gwen Shapira

Closes #446 from ewencp/connector-versions",2015-11-06 17:50:46,Ewen Cheslack-Postava,Mixed
15524d0970868d2dd9bc16b9d5de4519fc469e11,"KAFKA-2766: use new producer by default in tooling

Also update the API docs for new consumer.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Gwen Shapira

Closes #448 from guozhangwang/K2766",2015-11-06 17:55:32,Guozhang Wang,Mixed
23cc9c77b27889bb7d71d7ea74b80ab96c4529ae,"KAFKA-2723: new consumer exception cleanup

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang

Closes #441 from hachikuji/K2723",2015-11-08 11:32:17,Jason Gustafson,Mixed
f4b87deefecf4902992a84d4a3fe3b99a94ff72b,"KAFKA-2480: Handle retriable and non-retriable exceptions thrown by sink tasks.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Gwen Shapira

Closes #450 from ewencp/kafka-2480-unrecoverable-task-errors",2015-11-08 20:41:35,Ewen Cheslack-Postava,Mixed
f2031d40639ef34c1591c22971394ef41c87652c,"KAFKA-2774: Rename Copycat to Kafka Connect

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Gwen Shapira

Closes #456 from ewencp/kafka-2774-rename-copycat",2015-11-08 22:11:03,Ewen Cheslack-Postava,Mixed
7073fa7efea4acd6615f9dad4f649f6094be6332,"KAFKA-2258: add failover to mirrormaker test

This PR adds failover to simple end to end mirror maker test

Marked as WIP for 2 reasons:
- We may want to add a couple more test cases where kafka is being used to store offsets
- There appears to be a test failure in the hard failover case

Author: Geoff Anderson <geoff@confluent.io>

Reviewers: Ewen Cheslack-Postava

Closes #427 from granders/KAFKA-2258-mirrormaker-test",2015-11-09 10:45:51,Geoff Anderson,Mixed
69af573b35f04657e31f60e636aba19ffa0b2c84,"KAFKA-2783; Drop outdated hadoop contrib modules

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Gwen Shapira

Closes #466 from granthenke/drop-contrib",2015-11-09 11:02:46,Grant Henke,Not TDD
c9264b4c8904bf330b70cd84b433a7a141ec9d0e,"KAFKA-2769; Multi-consumer integration tests for consumer assignment incl. session timeouts and corresponding fixes

-- Refactored multi-consumer integration group assignment validation tests for round-robin assignment
-- Added multi-consumer integration tests for session timeout expiration:
   1. When a consumer stops polling
   2. When a consumer calls close()

-- Fixes to issues found with session timeout expiration tests woth help from Jason Gustafson: Try to avoid  SendFailedException exception by cancelling the scheduled tasks and ensuring metadata update before sending group leave requests + send leave group request with retries.

Author: Anna Povzner <anna@confluent.io>

Reviewers: Jason Gustafson, Guozhang Wang

Closes #472 from apovzner/cpkafka-81",2015-11-09 17:07:40,Anna Povzner,Not TDD
bce664b42a0c414dc19e2c07406cf6f14890cbd1,"KAFKA-2274: verifiable consumer and integration testing

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang, Geoff Anderson

Closes #465 from hachikuji/KAFKA-2274",2015-11-09 18:38:22,Jason Gustafson,Mixed
ae5a5d7c08bb634576a414f6f2864c5b8a7e58a3,"KAFKA-2792: Don't wait for a response to the leave group message when closing the new consumer.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Onur Karaman, Gwen Shapira

Closes #480 from ewencp/kafka-2792-fix-blocking-consumer-close",2015-11-10 10:26:51,Ewen Cheslack-Postava,Not TDD
60c06734b345bbf292773e5b9206282ff3995968,"KAFKA-2788; Allow specifying principals with comman in ACL CLI.

Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #489 from Parth-Brahmbhatt/KAFKA-2788",2015-11-10 14:27:55,Parth Brahmbhatt,Mixed
8db55618d5d5d5de97feab2bf8da4dc45387a76a,"KAFKA-2752: Add VerifiableSource/Sink connectors and rolling bounce Copycat system tests.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Ben Stopford, Geoff Anderson, Guozhang Wang

Closes #432 from ewencp/kafka-2752-copycat-clean-bounce-test",2015-11-10 14:54:15,Ewen Cheslack-Postava,Not TDD
e0098b4567541d1c0cefc6f57ce38f67a9133b5e,"KAFKA-2770: Catch and ignore WakeupException for commit upon closing

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Gwen Shapira, Geoff Anderson, Jason Gustafson

Closes #470 from guozhangwang/K2770",2015-11-10 19:24:15,Guozhang Wang,Not TDD
124f73b1747a574982e9ca491712e6758ddbacea,"KAFKA-2763: better stream task assignment

guozhangwang

When the rebalance happens each consumer reports the following information to the coordinator.
* Client UUID (a unique id assigned to an instance of KafkaStreaming)
* Task ids of previously running tasks
* Task ids of valid local states on the client's state directory

TaskAssignor does the following
* Assign a task to a client which was running it previously. If there is no such client, assign a task to a client which has its valid local state.
* Try to balance the load among stream threads.
  * A client may have more than one stream threads. The assignor tries to assign tasks to a client proportionally to the number of threads.

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang

Closes #497 from ymatsuda/task_assignment",2015-11-11 16:14:27,Yasuhiro Matsuda,Mixed
ab5ac264a71d7f895b21b4acfd93d9581dabd7c1,"KAFKA-2690: Hide passwords while logging the config.

Added PASSWORD_STRING in ConfigDef that returns ""[hidden]"" when method toString is invoked.

Author: Jakub Nowak <jakub.nowak94@interia.pl>

Reviewers: Ismael Juma, Gwen Shapira, Jun Rao

Closes #371 from Mszak/ssl-password-protection",2015-11-12 10:07:04,Jakub Nowak,Mixed
8e6bae21c64699245cf24dbaac3942f32a2a241b,"KAFKA-2838; Allow comma in super users, allow comma in CLI authz prop…

…erties.

Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>

Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Jun Rao <junrao@gmail.com>

Closes #529 from Parth-Brahmbhatt/KAFKA-2838",2015-11-13 17:36:09,Parth Brahmbhatt,Mixed
45e7f71309f9a3e30d25a6ddd3171c67e3e79286,"KAFKA-2811: add standby tasks

guozhangwang
* added a new config param ""num.standby.replicas"" (the default value is 0).
* added a new abstract class AbstractTask
* added StandbyTask as a subclass of AbstractTask
* modified StreamTask to a subclass of AbstractTask
* StreamThread
  * standby tasks are created by calling StreamThread.addStandbyTask() from onPartitionsAssigned()
  * standby tasks are destroyed by calling StreamThread.removeStandbyTasks() from onPartitionRevoked()
  * In addStandbyTasks(), change log partitions are assigned to restoreConsumer.
  * In removeStandByTasks(), change log partitions are removed from restoreConsumer.
  * StreamThread polls change log records using restoreConsumer in the runLoop with timeout=0.
  * If records are returned, StreamThread calls StandbyTask.update and pass records to each standby tasks.

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang

Closes #526 from ymatsuda/standby_task",2015-11-16 13:34:42,Yasuhiro Matsuda,Mixed
52d5e88393630ce6f817bd003c7c787e36e31277,"KAFKA-2847; Remove principal builder class from client configs

Also mark `PrincipalBuilder` as `Unstable` and  tweak docs.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #542 from ijuma/kafka-2847-remove-principal-builder-class-from-client-configs",2015-11-17 08:36:43,Ismael Juma,Not TDD
1a36af80b79a634a652e594d8240924ac32376ae,"MINOR: add KStream merge operator

guozhangwang

Added KStreamBuilder.merge(KStream...).

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang

Closes #536 from ymatsuda/kstream_merge_operator",2015-11-17 17:34:54,Yasuhiro Matsuda,Mixed
dacd21ec4e9028593faedeb7d2a4484394367612,"KAFKA-2852; Updating the Authorizer CLI to use a consistent way to specify a list of values for a config options.

…ecify a list of values for a config options.

Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #545 from Parth-Brahmbhatt/KAFKA-2852",2015-11-17 17:46:59,Parth Brahmbhatt,Mixed
dbdec927b9badcdbe4a4b4b6ccebf5044ca32747,"KAFKA-2841; safe group metadata cache loading/unloading

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jun Rao <junrao@gmail.com>

Closes #530 from hachikuji/KAFKA-2841",2015-11-17 18:34:51,Jason Gustafson,Not TDD
0f00ec97ae328d04c29cb1cb3eabad3f17e31582,"KAFKA-2859: Fix deadlock in WorkerSourceTask.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Gwen Shapira

Closes #554 from ewencp/kafka-2859-deadlock-worker-source-task",2015-11-18 14:19:37,Ewen Cheslack-Postava,Mixed
f154956a76790220a9ecb84d88644076c6885683,"KAFKA-2845: new client old broker compatibility

Author: Geoff Anderson <geoff@confluent.io>

Reviewers: Ismael Juma, Guozhang Wang

Closes #537 from granders/KAFKA-2845-new-client-old-broker-compatibility",2015-11-18 17:13:21,Geoff Anderson,Not TDD
d0614f97bc1c45734631770c46ab6a79fc8c8547,"KAFKA-2869; Host used by Authorizer should be IP address not hostname/IP

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #567 from ijuma/kafka-2869-host-used-by-authorizer-should-be-ip",2015-11-20 08:28:20,Ismael Juma,Mixed
b1d17e7ef0e901234d95d7825f6862d2aaead76f,"KAFKA-2863; Add a `close()` method to `Authorizer`

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #568 from ijuma/kafka-2863-authorizer-close",2015-11-20 10:43:25,Ismael Juma,Mixed
b16817a54c592eefc5a462132f45c5b4f786d5f1,"KAFKA-2812: improve consumer integration tests

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Geoff Anderson

Closes #500 from hachikuji/KAFKA-2812",2015-11-20 15:46:42,Jason Gustafson,Mixed
84c8d2bb86dc2794a3d6a86ae28b3cb51cea5c4b,"KAFKA-2872: unite sink nodes with parent nodes in addSink

Starting a KafkaStream was getting an error due to the fact that the TopologyBuilder.addSink method was not connecting the sink with it parent(s) processor/sources.  Just needed to wire up the sink with it parent(s) in TopologyBuilder.addSink .

Author: bbejeck <bbejeck@gmail.com>

Reviewers: Guozhang Wang

Closes #572 from bbejeck/KAFKA-2872_kafka_stream_sink_not_connected_to_parent",2015-11-21 18:46:15,Bill Bejeck,Mixed
d1053915f64aec7ea717bbeac9570b1f75e9a2b0,"KAFKA-2803: Add hard bounce system test for Kafka Connect.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Gwen Shapira

Closes #494 from ewencp/kafka-2803-connect-hard-bounce-system-test",2015-11-24 17:39:14,Ewen Cheslack-Postava,Not TDD
87b894d682a5f10b2e1d32dd028ddb258f2f1bbf,"KAFKA-2878; Guard against OutOfMemory in Kafka broker

Sanity check array size in requests before allocation

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Ashish Singh <asingh@cloudera.com>, Jun Rao <junrao@gmail.com>

Closes #577 from rajinisivaram/KAFKA-2878",2015-11-25 08:53:13,Rajini Sivaram,Not TDD
69a1cced49d7d0c805adeb1dfd327f8bb5c7ce9a,"KAFKA-2643: Run mirror maker ducktape tests with SSL and SASL

Run tests with SSL, SASL_PLAINTEXT and SASL_SSL. Same security protocol is used for source and target Kafka.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Geoff Andreson, Ben Stopford

Closes #559 from rajinisivaram/KAFKA-2643",2015-11-25 15:05:31,Rajini Sivaram,Mixed
5e8958a856a5b4ccbdcb610473cab4c2eeddbac5,"MINOR: initialize Serdes with ProcessorContext

guozhangwang

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang

Closes #589 from ymatsuda/init_serdes_with_procctx",2015-11-25 15:21:17,Yasuhiro Matsuda,Mixed
d07bb1814010ca4d822e44330d1e8ea4b2839c80,"MINOR: comments on KStream methods, and fix generics

guozhangwang

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang

Closes #591 from ymatsuda/comments",2015-11-25 16:44:43,Yasuhiro Matsuda,Mixed
4a8acdf9d7135a50b751a0bea9e205ea4a071e5c,"KAFKA-2732; Add class for ZK Auth.

Author: Flavio Junqueira <fpj@apache.org>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Ben Stopford <benstopford@gmail.com>, Jun Rao <junrao@gmail.com>

Closes #410 from fpj/KAFKA-2732",2015-11-28 08:23:35,Flavio Junqueira,Not TDD
6b4cc2ea2b141b25852e2110ac4a400905154b92,"KAFKA-2771: Added rolling upgrade system test (ducktape) for Secured Cluster

Tests rolling upgrade from PLAINTEXT to SSL

Author: Ben Stopford <benstopford@gmail.com>

Reviewers: Geoff Anderson, Ismael Juma

Closes #496 from benstopford/security-upgrade-test",2015-11-30 14:13:50,Ben Stopford,Not TDD
69269e76a43adf85a478240280c6ab3c7eef4d8e,"KAFKA-2421: Upgrade LZ4 to version 1.3

A few notes on the added test:
 * I verified this test fails when changing between snappy 1.1.1.2 and 1.1.1.7 (per KAFKA-2189)
 * The hard coded numbers are passing before and after lzo change

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Ismael Juma, Guozhang Wang

Closes #552 from granthenke/lz4",2015-12-01 11:57:34,Grant Henke,Not TDD
9fb1e25738f89b75a36ef69f730b0e138ccd55b1,"KAFKA-2880: consumer should handle disconnect/timeout for metadata requests

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma, Guozhang Wang

Closes #581 from hachikuji/KAFKA-2880",2015-12-02 11:27:36,Jason Gustafson,Mixed
a5382a333ebb51a10c1a1cab46d66f10abff128a,"KAFKA-2902: streaming config use get base consumer configs.

Changes made for using getBaseConsumerConfigs from StreamingConfig.getConsumerConfigs.

Author: bbejeck <bbejeck@gmail.com>
Author: Bill Bejeck <bbejeck@gmail.com>

Reviewers: Guozhang Wang

Closes #596 from bbejeck/KAFKA-2902-StreamingConfig-use-getBaseConsumerConfigs",2015-12-02 18:40:07,bbejeck,Mixed
5b5f6bbe68a82ce5eae946e0a1a199e9713a6ff7,"KAFKA-2825: Add controller failover to existing replication tests

Author: Anna Povzner <anna@confluent.io>

Reviewers: Geoff Anderson

Closes #618 from apovzner/kafka_2825_01",2015-12-03 10:43:44,Anna Povzner,Not TDD
80df43500141d6bf710b19f342c8ab172587c128,"KAFKA-2905: System test for rolling upgrade to enable ZooKeeper ACLs with SASL

Author: flavio junqueira <fpj@apache.org>

Reviewers: Ismael Juma, Geoff Anderson

Closes #598 from fpj/KAFKA-2905",2015-12-03 17:47:44,Flavio Junqueira,Not TDD
cd54fc8816964f5a56469075c75c567e777b9656,"KAFKA-2931: add system test for consumer rolling upgrades

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma, Guozhang Wang

Closes #619 from hachikuji/KAFKA-2931",2015-12-03 21:17:51,Jason Gustafson,Mixed
39c3512eceedebcb6e50f8c6c4ef66601ff7dbc4,"KAFKA-2856: Add KTable non-stateful APIs along with standby task support

guozhangwang
* added KTable API and impl
* added standby support for KTable

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang

Closes #604 from ymatsuda/add_ktable",2015-12-04 14:59:24,Yasuhiro Matsuda,Mixed
d05fa0a03bc9bcfcff8d73cbf1b22832ebdb75a2,"KAFKA-2804: manage changelog topics through ZK in PartitionAssignor

Author: Guozhang Wang <wangguoz@gmail.com>
Author: wangguoz@gmail.com <guozhang@Guozhang-Macbook.local>
Author: Guozhang Wang <guozhang@Guozhang-Macbook.local>

Reviewers: Yasuhiro Matsuda

Closes #579 from guozhangwang/K2804",2015-12-07 15:12:09,Guozhang Wang,Mixed
b390b15cdbf89f7ffce16dad2a20ee9330f82731,"MINOR: Remove unused DoublyLinkedList

It used to be used by MirrorMaker but its usage was removed in KAFKA-1997.

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Jiangjie Qin

Closes #638 from granthenke/remove-dll",2015-12-07 23:15:04,Grant Henke,Not TDD
268392f5e99dc3eab9d89e921bafde782a1d10a6,"HOTFIX: fix ProcessorStateManager to use correct ktable partitions

guozhangwang

* fix ProcessorStateManager to use correct ktable partitions
* more ktable tests

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang

Closes #635 from ymatsuda/more_ktable_test",2015-12-07 23:16:19,Yasuhiro Matsuda,Mixed
5bc90d4542ca9d6cea3eac1e0a7e1bfa1fed15e7,"KAFKA-2958: Remove duplicate API key mapping functionality

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Gwen Shapira

Closes #637 from granthenke/api-keys",2015-12-08 09:55:46,Grant Henke,Not TDD
ef92a8ae7479560b26edecfa8db79934065f13cf,"KAFKA-2668; Add a metric that records the total number of metrics

onurkaraman becketqin Do you have time to review this patch? It addresses the ticket that jjkoshy filed in KAFKA-2668.

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Onur Karaman <okaraman@linkedin.com>, Joel Koshy <jjkoshy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Jun Rao <junrao@gmail.com>

Closes #328 from lindong28/KAFKA-2668",2015-12-08 19:43:05,Dong Lin,Mixed
977ebbe9bafb6c1a6e1be69620f745712118fe80,"KAFKA-2973; Fix leak of child sensors on remove

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Gwen Shapira, Guozhang Wang

Closes #650 from ijuma/kafka-2973-fix-leak-child-sensors-on-remove",2015-12-09 09:52:17,Ismael Juma,Mixed
7bb7e415a371909757a6099a911587047d4c4b69,"KAFKA-2972; Add missing `partitionsRemaingList.add` in `ControlledShutdownResponse` constructor

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Grant Henke, Guozhang Wang

Closes #649 from ijuma/KAFKA-2972-controlled-shutdown-response-bug",2015-12-09 11:57:20,Ismael Juma,Not TDD
6e5bd2497af2b6bb67a47e4f3defa50da3cad4c7,"KAFKA-2974; `==` is used incorrectly in a few places in Java code

A few issues found via static analysis.

Author: Edward Ribeiro <edward.ribeiro@gmail.com>
Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Gwen Shapira, Sriharsha Chintalapani, Guozhang Wang

Closes #652 from ijuma/use-equals-instead-of-==",2015-12-09 20:34:09,Edward Ribeiro,Not TDD
3b350cdff795ec08dc77e60f127f2790149d8d52,"HOTFIX: fix table-table outer join and left join. more tests

guozhangwang

* fixed bugs in table-table outer/left joins
* added more tests

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang

Closes #653 from ymatsuda/join_tests",2015-12-09 23:02:44,Yasuhiro Matsuda,Mixed
9d23b512ccb95940782f51c93bd6cdbed3e938db,"KAFKA-2893: Add a simple non-negative partition seek check

Author: jinxing <jinxing@fenbi.com>
Author: ZoneMayor <jinxing6042@126.com>

Reviewers: Guozhang Wang

Closes #628 from ZoneMayor/trunk-KAFKA-2893",2015-12-10 10:49:02,Jin Xing,Mixed
a5f1537f8762f4787b2af106c5d93c156f906074,"KAFKA-2896; Added system test for partition re-assignment

Partition re-assignment tests with and without broker failure.

Author: Anna Povzner <anna@confluent.io>

Reviewers: Ben Stopford <ben@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>, Geoff Anderson <geoff@confluent.io>

Closes #655 from apovzner/kafka_2896",2015-12-10 17:06:47,Anna Povzner,Not TDD
1dcafadefc09aece9037bc930aa0de7617f655b2,"MINOR: test ktable state store creation

guozhangwang
* a test for ktable state store creation

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang

Closes #661 from ymatsuda/more_ktable_test",2015-12-10 21:48:27,Yasuhiro Matsuda,Not TDD
01f3e59ef91b348a5fab805bc6915591dd490a16,"KAFKA-2070; Replace Offset{Request,Response} with o.a.k.c requests equivalent

…uivalent

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #663 from granthenke/offset-list",2015-12-11 09:37:09,Grant Henke,Not TDD
e08b922aad485a96fceb51d5c27877729156ddab,"KAFKA-2978: consumer stops fetching when consumed and fetch positions get out of sync

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Michal Turek, Ismael Juma, Guozhang Wang

Closes #666 from hachikuji/KAFKA-2978",2015-12-14 14:54:22,Jason Gustafson,Mixed
3f3358b6d4374662f5ca57c6e93e009b58a6b2a2,"MINOR: Fix typos in code comments

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Gwen Shapira

Closes #673 from vahidhashemian/typo02/fix_typos_in_code_comments",2015-12-15 13:46:57,Vahid Hashemian,Mixed
3432e85f664c5e3d8300171c314ea52b2f4b88fd,"KAFKA-2509: Replace LeaderAndIsr{Request,Response} with o.a.k.c reque…

…sts equivalent

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Gwen Shapira

Closes #647 from granthenke/isr-request",2015-12-15 13:48:34,Grant Henke,Not TDD
587a2f4efd7994d4d3af82ed91304f939514294a,"KAFKA-2984: KTable should send old values when required

guozhangwang

At DAG level, `KTable<K,V>` sends (key, (new value, old value)) to down stream.  This is done by wrapping the new value and the old value in an instance of `Change<V>` class and sending it as a ""value"" part of the stream. The old value is omitted (set to null) by default for optimization. When any downstream processor needs to use the old value, the framework should enable it (see `KTableImpl.enableSendingOldValues()` and implementations of `KTableProcessorSupplier.enableSensingOldValues()`).

NOTE: This is meant to be used by aggregation. But, if there is a use case like a SQL database trigger, we can add a new KTable method to expose this.

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang

Closes #672 from ymatsuda/trigger",2015-12-16 15:37:53,Yasuhiro Matsuda,Mixed
9220df9f8b58870a2282d3e4ceb2e003667d854b,"KAFKA-2964: Split Security Rolling Upgrade Test by Client and Broker Protocols

The core of this PR is to ensure we evaluate enabling security in a running cluster where we have different broker and client protocols.
Also in this PR are some improvements to the validation process in produce_consume_validate.py which make it easier to work out where missing messages have been lost:
- Fail fast if producer or consumer stop running.
- If messages go missing, check in the data files to see if the cause was data loss or the consumer missing messages.
- Make it possible for the ConsoleConsumer to log both what it consumed and when it consumed it (and enable this feature in produce_consume_validate tests)

Author: Ben Stopford <benstopford@gmail.com>

Reviewers: Gwen Shapira, Geoff Anderson

Closes #667 from benstopford/security-rolling_upgrade-additions",2015-12-17 18:02:38,Ben Stopford,Not TDD
a0d21407cbdd3b7cb73f52c986aa2f60804618e7,"KAFKA-3009; Disallow star imports

Summary of code changes
------------------------------------
1) Added a new Checkstyle rule to flag any code using star imports
2) Fixed ALL existing code violations using star imports

Testing
-----------
Local build was successful
ALL JUnits ran successfully on local.

ewencp - Request you to please review changes. Thank you !

I state that the contribution is my original work and I license the work to the project under the project's open source license.

Author: manasvigupta <manasvigupta@yahoo.co.in>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #700 from manasvigupta/KAFKA-3009",2015-12-21 13:30:59,manasvigupta,Mixed
976fa192d45243d2da3eb7e1d6fa1ce0fdda1fd2,"KAFKA-2989; System tests should verify partitions consumed after rebalancing

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #702 from hachikuji/KAFKA-2989",2015-12-22 16:15:37,Jason Gustafson,Mixed
07ee17fd05900101ad2ebc7210f94b05e230bf83,"KAFKA-3024: Remove old patch review tools

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Gwen Shapira, Ismael Juma

Closes #705 from granthenke/review-tools-cleanup",2015-12-22 18:28:48,Grant Henke,Mixed
ea73356905ff4663d0d085c46b348fa4e9b9568d,"KAFKA-3002; Allow uppercase letters in hostnames

Make available to specify hostname with Uppercase at broker list

Author: Sasaki Toru <sasakitoa@nttdata.co.jp>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #685 from sasakitoa/hostname_uppercase",2015-12-23 20:55:01,Sasaki Toru,Mixed
2679524604b611046e9826b2a1fba461d42f06f4,"KAFKA-3055; Fix JsonConverter mangling the Schema in Connect

Author: ksenji <ksenji@ebay.com>

Reviewers: Dong Lin <lindong28@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #722 from ksenji/trunk",2016-01-04 11:47:31,Kishore Senji,Mixed
f9642e2a9878faff81366dbc885a206727bd7c7b,"KAFKA-3052; Broker properties get logged twice if acl enabled

Fix it by making it possible to pass the `doLog` parameter to `AbstractConfig`. As explained in the code comments, this means that we can continue to benefit from ZK default settings as specified in `KafkaConfig` without having to duplicate code.

Also:
* Removed unused private methods from `KafkaConfig`
* Removed `case` modifier from `KafkaConfig` so that `hashCode`, `equals`
and `toString` from `AbstractConfig` are used.
* Made `props` a `val` and added `apply` method to `KafkaConfig` to
remain binary compatible.
* Call authorizer.close even if an exception is thrown during `configure`.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Guozhang Wang

Closes #725 from ijuma/kafka-3052-broker-properties-get-logged-twice-if-acl-enabled",2016-01-04 08:51:30,Ismael Juma,Mixed
b93f48f7494e1db4d564b6c28772712ee7681620,"KAFKA-2422: Allow copycat connector plugins to be aliased to simpler names

…names

Author: Gwen Shapira <cshapi@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #687 from gwenshap/KAFKA-2422",2016-01-04 15:01:58,Gwen Shapira,Mixed
57df460f8d7b225509dd8c061a5b6efa65c8ac9c,"KAFKA-3051 KAFKA-3048; Security config docs improvements

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #724 from ijuma/minor-security-fixes",2016-01-04 12:49:23,Ismael Juma,Not TDD
b0b3e5aebf381faf81bd9454ef7b448e2ad922c7,"KAFKA-3016: phase-1. A local store for join window

guozhangwang
An implementation of local store for join window. This implementation uses ""rolling"" of RocksDB instances for timestamp based truncation.

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang

Closes #726 from ymatsuda/windowed_join",2016-01-04 16:47:17,Yasuhiro Matsuda,Mixed
5aad4999d1a1d35d61365ff57a9b79a6af3e70d2,"KAFKA-3016: phase-2. stream join implementations

guozhangwang

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang

Closes #737 from ymatsuda/windowed_join2",2016-01-06 14:34:40,Yasuhiro Matsuda,Mixed
00114dae7a0ecb361aa5b843d5c7a95381294bd2,"KAFKA-2072; Replace StopReplica Request/Response with their org.apache.kafka.common.requests equivalents

Author: David Jacot <david.jacot@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Grant Henke <granthenke@gmail.com>, Jun Rao <junrao@gmail.com>

Closes #196 from dajac/KAFKA-2072-part-2",2016-01-06 16:08:16,David Jacot,Not TDD
a9ff3f2eced76a0aa13804439101c2897916e250,"KAFKA-2929: Migrate duplicate error mapping functionality

Deprecates ErrorMapping.scala in core in favor or Errors.java in common.
Duplicated exceptions in core are deprecated as well, to ensure the mapping is correct.

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #616 from granthenke/error-mapping",2016-01-06 21:24:19,Grant Henke,Mixed
ee1770e00e841ba68dc25f03a8d3f2ac647b0eb3,"KAFKA-2988; Change default configuration of the log cleaner

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #686 from granthenke/compaction",2016-01-07 09:57:35,Grant Henke,Not TDD
4836e525c851640e0da9d8d11321621a2c70e8f0,"KAFKA-2649: Add support for custom partitioning in topology sinks

Added option to use custom partitioning logic within each topology sink.

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Guozhang Wang

Closes #309 from rhauch/kafka-2649",2016-01-07 14:46:02,Randall Hauch,Not TDD
40d731b8712950122915795acca43886851a73b6,"KAFKA-2653: Add KStream/KTable Aggregation and KTable Join APIs

ping ymatsuda for reviews.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Yasuhiro Matsuda

Closes #730 from guozhangwang/K2653r",2016-01-07 17:18:33,Guozhang Wang,Mixed
49778b18446d691321026415aeaac1b265057ece,"KAFKA-2979: Enable authorizer and ACLs in ducktape tests

Patch by fpj and benstopford.

Author: flavio junqueira <fpj@apache.org>
Author: Flavio Junqueira <fpj@apache.org>
Author: Ben Stopford <benstopford@gmail.com>

Reviewers: Ben Stopford <benstopford@gmail.com>, Geoff Anderson <geoff@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #683 from fpj/KAFKA-2979",2016-01-07 20:04:24,Flavio Junqueira,Not TDD
3a0fc125f4337a670ea52009afb1a254179ac07b,"KAFKA-3084: Topic existence checks in topic commands (create, alter, delete)

…delete)

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #744 from granthenke/exists-checks",2016-01-11 10:08:45,Grant Henke,Mixed
3e5afbfa0dd4ddfca65fae1f3b2a268ae1ed2025,"KAFKA-3078: Add ducktape tests for KafkaLog4jAppender producing to SASL enabled Kafka cluster

Note that KAFKA-3077 will be required to run these tests.

Author: Ashish Singh <asingh@cloudera.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #747 from SinghAsDev/KAFKA-3078",2016-01-11 23:15:42,Ashish Singh,Mixed
72eebad43d5aaf4bbd29532eedc2a793fc3ee9d5,"KAFKA-3069: Fix recursion in ZkSecurityMigrator

I'm also fixing a bug in the testChroot test case.

Author: Flavio Junqueira <fpj@apache.org>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #736 from fpj/KAFKA-3069",2016-01-12 09:48:47,Flavio Junqueira,Not TDD
836cb1963330a9e342379899e0fe52b72347736e,"KAFKA-3063; LogRecoveryTest causes JVM to exit occasionally

Remove deletion of tmp file in `OffsetCheckpoint`'s constructor. This delete causes unintuitive behaviour like `LogRecoveryTest` causing a `System.exit` because the test creates an instance of `OffsetCheckpoint` in order to call `read()` on it (while unexpectedly deleting a file being written by another instance of `OffsetCheckpoint`).

Also:
* Improve error-handling in `OffsetCheckpoint`
* Also include minor performance improvements in `read()`
* Minor clean-ups to `ReplicaManager` and `LogRecoveryTest`

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #759 from ijuma/kafka-3063-log-recovery-test-exits-jvm",2016-01-12 16:16:10,Ismael Juma,Not TDD
4f22705c7d0c8e8cab68883e76f554439341e34a,"KAFKA-3081: KTable Aggregation

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Yasuhiro Matsuda

Closes #761 from guozhangwang/K3081",2016-01-13 17:15:57,Guozhang Wang,Mixed
a3d3d5379df71e7a2c653d06ebf1b30923dde738,"MINOR: add internal source topic for tracking

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Yasuhiro Mastuda

Closes #775 from guozhangwang/KRepartTopic",2016-01-14 17:09:33,Guozhang Wang,Mixed
37be6d98da842512367ab0b31d8f0244afafda92,"KAFKA-3108: custom StreamParitioner for Windowed key

guozhangwang

When ```WindowedSerializer``` is specified in ```to(...)``` or ```through(...)``` for a key, we use ```WindowedStreamPartitioner```.

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang

Closes #779 from ymatsuda/partitioner",2016-01-14 17:20:08,Yasuhiro Matsuda,Mixed
6dc974312590f089c9e0ac27e8eb9b848caf32b5,"KAFKA-2886: Handle sink task rebalance failures by stopping worker task

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Liquan Pei <liquanpei@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #767 from hachikuji/KAFKA-2886",2016-01-15 09:28:43,Jason Gustafson,Mixed
0c32bc99265c4645fad2e3244dc2c697bfd9a229,"KAFKA-3105: Use `Utils.atomicMoveWithFallback` instead of `File.rename`

It behaves better on Windows and provides more useful error messages.

Also:
* Minor inconsistency fix in `kafka.server.OffsetCheckpoint`.
* Remove delete from `streams.state.OffsetCheckpoint` constructor (similar to the change in `kafka.server.OffsetCheckpoint` in https://github.com/apache/kafka/commit/836cb1963330a9e342379899e0fe52b72347736e#diff-2503b32f29cbbd61ed8316f127829455L29).

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #771 from ijuma/kafka-3105-use-atomic-move-with-fallback-instead-of-rename",2016-01-18 09:47:32,Ismael Juma,Not TDD
747dc930ff710ec890b5f054b4ec4bf7bbb7c960,"KAFKA-2695: limited support for nullable byte arrays

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang

Closes #780 from hachikuji/KAFKA-2695",2016-01-18 09:54:02,Jason Gustafson,Mixed
cc3570d1a28354acd082c41a15d9c9efde540b16,"KAFKA-2999: Errors enum should be a 1 to 1 mapping of error codes and…

… exceptions

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Gwen Shapira

Closes #766 from granthenke/errors-map",2016-01-18 10:09:17,Grant Henke,Mixed
a62eb5993f5517a64dd1020b0a9bbd1012f7ee67,"KAFKA-3104: add windowed aggregation to KStream

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Yasuhiro Mastuda

Closes #781 from guozhangwang/K3104",2016-01-18 12:14:43,Guozhang Wang,Mixed
5c337d759892ae6d46d6901a24e9b97cebd2a4da,"KAFKA-3012: Avoid reserved.broker.max.id collisions on upgrade

Provides a configuration to opt out of broker id generation.

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Gwen Shapira

Closes #762 from granthenke/id-generation",2016-01-18 18:39:55,Grant Henke,Mixed
b1d325b3c09cd95d69a66fac4a3760f57d3062c9,"KAFKA-3091: Broker persists generated ID even when the ID can't be used due to duplicates

…updated to a new valid one

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Gwen Shapira

Closes #763 from granthenke/id-start-failure",2016-01-18 18:55:50,Grant Henke,Not TDD
959cf09e8653f4b8255f49c6f4c258ed1a5ec38e,"KAFKA-3121: Remove aggregatorSupplier and add Reduce functions

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Yasuhiro Matsuda

Closes #795 from guozhangwang/K3121s1",2016-01-20 16:10:43,Guozhang Wang,Mixed
79cda0472b8e3af915c45daca9cce82d7c964182,"KAFKA-2071: Replace Producer Request/Response with their org.apache.kafka.common.requests equivalents

This PR replaces all occurrences of kafka.api.ProducerRequest/ProducerResponse by their common equivalents.

Author: David Jacot <david.jacot@gmail.com>

Reviewers: Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #110 from dajac/KAFKA-2071",2016-01-20 16:27:34,David Jacot,Mixed
21c6cfe50dbe818a392c28f48ce8891f7f99aaf6,"KAFKA-3136: Rename KafkaStreaming to KafkaStreams

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Gwen Shapira

Closes #800 from guozhangwang/KRename",2016-01-22 13:00:00,Guozhang Wang,Mixed
a19729fe61b23178c6f91135cb81901f76f982f0,"MINOR: Fixes version lookup exception.

Given a schema with 2 versions (0 and 1), if you pass in a version of `2` you will get an `OutOfBoundsException` instead of an `IllegalArgumentException`.

This fixes the problem by changing the check from `>` to `>=`, which will now return true in the given scenario.

Author: Micah Zoltu <micah@zoltu.net>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #748 from Zoltu/patch-1",2016-01-22 14:18:30,Micah Zoltu,Mixed
c197113a9c04e2f6c2d1a72161c0d40d5804490e,"KAFKA-3066: Demo Examples for Kafka Streams

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #797 from guozhangwang/K3066",2016-01-22 15:25:24,Guozhang Wang,Mixed
4f39b5bc5b2104fb39ab5b0c087fe84a71205a74,"KAFKA-2846: Add Ducktape test for kafka-consumer-groups

Author: Ashish Singh <asingh@cloudera.com>

Reviewers: Geoff Anderson <geoff@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #555 from SinghAsDev/KAFKA-2846",2016-01-23 16:59:28,Ashish Singh,Not TDD
5e8a084834ad35506ee74e1da15a3964642a512e,"KAFKA-3134: Fix missing value.deserializer error during KafkaConsumer initialization

… initialization

Author: Yifan Ying <yying@fitbit.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #803 from happymap/KAFKA-3134",2016-01-24 01:55:30,Yifan Ying,Mixed
30d3cc6314bf896ea37d01c5a1d6b21d69a7053f,"KAFKA-3100; Broker.createBroker should work if json is version > 2 and still compatible

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Grant Henke <granthenke@gmail.com>, Jun Rao <junrao@gmail.com>

Closes #773 from ijuma/kafka-3100-create-broker-version-check",2016-01-25 15:12:37,Ismael Juma,Not TDD
5ae97196ae149e58f6cfa3c5b6d968cbd7cb6787,"KAFKA-3125: Add Kafka Streams Exceptions

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #809 from guozhangwang/K3125",2016-01-26 09:19:28,Guozhang Wang,Mixed
e9a72ceab6e0ceaf4d2125756f07154cd15a7178,"KAFKA-3132: URI scheme in ""listeners"" property should not be case-sen…

…sitive

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Ismael Juma

Closes #811 from granthenke/listeners-case",2016-01-26 16:47:26,Grant Henke,Mixed
9ffa907d704b424ad05c18d834cfefdc1c7ad22a,"MINOR: remove FilteredIterator

guozhangwang
removing an unused class, FilteredIterator, and its test.

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Gwen Shapira

Closes #816 from ymatsuda/remove_obsolete_class",2016-01-26 20:03:50,Yasuhiro Matsuda,Mixed
22de0a8ab5d0e84fa40016754f9a8eff8193aa89,"MINOR: join test for windowed keys

guozhangwang

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang

Closes #814 from ymatsuda/windowed_key_join_test",2016-01-26 23:03:42,Yasuhiro Matsuda,Mixed
523562c109b29cc5a5e56313f16f1b1ff6c5dd9c,"KAFKA-3152; kafka-acl doesn't allow space in principal name

* Add quotes to `$` in shell scripts
This is necessary for correct processing of quotes in the
user command.

* Minor improvements to AclCommand messages

* Use a principal with a space in `SslEndToEndAuthorizationTest`
This passed without any other changes, but good avoid regressions.

* Clean-up `TestSslUtils`:
Remove unused methods, fix unnecessary verbosity and don't set security.protocol (it should be done at a higher-level).

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Grant Henke <granthenke@gmail.com>, Jun Rao <junrao@gmail.com

Closes #818 from ijuma/kafka-3152-kafka-acl-space-in-principal",2016-01-27 08:23:25,Ismael Juma,Not TDD
91491986c0a4c9c4cde2ab33be822852b76759e6,"KAFKA-3166; Disable SSL client authentication for SASL_SSL security protocol

Also:

* Fixed a bug in `createSslConfig` where we were always generating a
keystore even if `useClientCert` was false and `mode` was `Mode.CLIENT`.
* Pass `numRecords` to `consumerRecords` and other clean-ups (formatting and scaladoc).

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #827 from ijuma/kafka-3166-disable-ssl-auth-sasl-ssl and squashes the following commits:

8265221 [Ismael Juma] Pass `numRecords` to `consumerRecords` and clean-ups.
a73db89 [Ismael Juma] SSL client authentication should be disabled for SASL_SSL security protocol",2016-01-29 16:03:10,Ismael Juma,Not TDD
e1d32bdffd0979596058788ffa3b1130cc7d93b8,"KAFKA-3029: Mark TopicPartition and OffsetAndMetadata as Serializable

Patch for issue KAFKA-3029

Given that the fix is trivial no new test case is needed. I have run the test suite using gradle (as mentioned  https://github.com/apache/kafka/blob/trunk/README.md) and suite runs clean.

Author: Praveen Devarao <praveendrl@in.ibm.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Gwen Shapira <cshapi@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #711 from praveend/tp_serializable_branch",2016-01-29 09:23:55,Praveen Devarao,Not TDD
57da044a991ebf8913d44dfcfa6a27729f54a4d5,"KAFKA-3060: Refactor MeteredStore and RockDBStore Impl

Changes include:

1) Move logging logic from MeteredXXXStore to internal stores, and leave WindowedStore API clean by removed all internalPut/Get functions.

2) Wrap common logging behavior of InMemory and LRUCache stores into one class.

3) Fix a bug for StoreChangeLogger where byte arrays are not comparable in HashSet by using a specified RawStoreChangeLogger.

4) Add a caching layer on top of RocksDBStore with object caching, it relies on the object's equals and hashCode function to be consistent with serdes.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Yasuhiro Matsuda <yasuhiro@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #826 from guozhangwang/K3060",2016-02-01 16:11:13,Guozhang Wang,Mixed
95174337c2f6cda90e213e5c3a73fc89854f42a7,"KAFKA-3121: Refactor KStream Aggregate to be Lambda-able.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Yasuhiro Matsuda <yasuhiro@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #839 from guozhangwang/K3121s2",2016-02-02 12:01:47,Guozhang Wang,Mixed
1d80f563bcd043cd464003782802906b60a0ade8,"KAFKA-3092: Replace SinkTask onPartitionsAssigned/onPartitionsRevoked with open/close

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Liquan Pei <liquanpei@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #815 from hachikuji/KAFKA-3092",2016-02-03 11:28:58,Jason Gustafson,Mixed
79eacf6c95506d5d6819add5a1256681b13170b1,"MINOR: Some more Kafka Streams Javadocs

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Yasuhiro Matsuda <yasuhiro@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #853 from guozhangwang/KJavaDoc",2016-02-03 11:31:32,Guozhang Wang,Not TDD
5b5869383832512d78e20183c855f83d30a5ab37,"KAFKA-3194: Validate security.inter.broker.protocol against the adver…

…tised.listeners protocols

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Ismael Juma

Closes #851 from granthenke/verify-protocol",2016-02-03 15:42:22,Grant Henke,Mixed
d3ff902d6023eff257653a5dfb31f4e482204c44,"MINOR: Fix restoring for source KTable

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Yasuhiro Matsuda

Closes #860 from guozhangwang/KRestoreChangelog",2016-02-03 20:42:43,Guozhang Wang,Not TDD
287e45ab40ad744405ee2008b51caa7922f1b7b2,"MINOR: Removed unnecessary Vagrantfile hack

The hack here is no longer necessary with up-to-date versions of Vagrant, vagrant-hostmanager, and vagrant-aws. What's more, the change in c8b60b63 caused a chain of infinite recursion on OSX, preventing bringup of VMs on a typical laptop.

Author: Geoff Anderson <geoff@confluent.io>

Reviewers: Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #867 from granders/remove-vagrantfile-hack and squashes the following commits:

14f4395 [Geoff Anderson] Removed uneccessary references to version 1.5.0 of vagrant-hostmanager
8799afe [Geoff Anderson] Removed Vagrantfile hack which is no longer necessary with up-to-date versions of Vagrant, vagrant-hostmanager, and vagrant-aws",2016-02-04 13:49:01,Geoff Anderson,Not TDD
7802a90ed98ea5b9a2b2dcf2e04db1a50e34a2f8,"KAFKA-3207: Fix StateChangeLogger to use the right topic name

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Yasuhiro Matsuda

Closes #865 from guozhangwang/K3207",2016-02-04 14:51:10,Guozhang Wang,Not TDD
db8d6f02c092c42f2402b7e2587c1b28d330bf83,"KAFKA-3179; Fix seek on compressed messages

The fix itself is simple.

Some explanation on unit tests. Currently we the vast majority of unit test is running with uncompressed messages.  I was initially thinking about run all the tests using compressed messages. But it seems uncompressed messages are necessary in a many test cases because we need the bytes sent and appended to the log to be predictable. In most of other cases, it does not matter whether the message is compressed or not, and compression will slow down the unit test. So I just added one method in the BaseConsumerTest to send compressed messages whenever we need it.

Author: Jiangjie Qin <becket.qin@gmail.com>

Reviewers: Aditya Auradkar <aauradkar@linkedin.com>, Ismael Juma <ismael@juma.me.uk>, Joel Koshy <jjkoshy.w@gmail.com>

Closes #842 from becketqin/KAFKA-3179",2016-02-04 16:08:21,Jiangjie Qin,Mixed
dc662776cde8e980a3f978041adaf961edf0fe7d,"KAFKA-3211: Handle WorkerTask stop before start correctly

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #874 from hachikuji/KAFKA-3211",2016-02-04 18:00:45,Jason Gustafson,Mixed
f7ad3d1b1fe24f3d33caf5f168d1292d4ae0b979,"HOTFIX: RecordCollector should send a record to the specified partition

guozhangwang

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #887 from ymatsuda/hotfix4",2016-02-08 16:35:05,Yasuhiro Matsuda,Mixed
feda3f68e98b5269431db9f2a5f131c03a16f651,"HOTFIX: open window segments on init

guozhangwang

A window store should open all existing segments. This is important for segment cleanup, and it also ensures that the first fetch() call returns the hits, the values in the search range. (previously, it missed the hits in fetch() immediately after initialization).

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #886 from ymatsuda/hotfix3",2016-02-08 16:48:06,Yasuhiro Matsuda,Mixed
cd15321e0d250253abb990af53e1f5624cf46b42,"KAFKA-3189: Kafka server returns UnknownServerException for inherited exceptions

… exceptions

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #856 from granthenke/inherited-errors",2016-02-09 10:16:57,Grant Henke,Mixed
b5e6b8671a5b6d97d5026261ae8d62b54f068e53,"HOTFIX: open window segments in order, add segment id check in getSegment

* During window store initialization, we have to open segments in the segment id order and update ```currentSegmentId```, otherwise cleanup won't work.
* ```getSegment()``` should not create a segment and clean up old segments if the segment id is greater than ```currentSegmentId```. Segment maintenance should be driven not by query but only by data insertion.

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #891 from ymatsuda/hotfix2",2016-02-09 13:22:46,Yasuhiro Matsuda,Mixed
fe3b7492b73bf21ecb1a49e730dd30efd1e66693,"KAFKA-3141: Add checks to catch invalid authorizer porperties

Skip misformed properties instead of throwing ArrayIndexOutOfBoundsException

Author: Ashish Singh <asingh@cloudera.com>

Reviewers: Ismael Juma, Gwen Shapira

Closes #806 from SinghAsDev/KAFKA-3141",2016-02-09 21:48:56,Ashish Singh,Mixed
d5b43b19bb06e9cdc606312c8bcf87ed267daf44,"KAFKA-3162: Added producer and consumer interceptors

This is the most of the KIP-42: Producer and consumer interceptor. (Except exposing CRC and record sizes to the interceptor, which is coming as a separate PR; tracked by KAFKA-3196).

This PR includes:
1. Add ProducerInterceptor interface and call its callbacks from appropriate places in Kafka Producer.
2. Add ConsumerInterceptor interface and call its callbacks from appropriate places in Kafka Consumer.
3. Add unit tests for interceptor changes
4. Add integration test for both mutable consumer and producer interceptors.

Author: Anna Povzner <anna@confluent.io>

Reviewers: Jason Gustavson, Ismael Juma, Gwen Shapira

Closes #854 from apovzner/kip42",2016-02-09 22:10:06,Anna Povzner,Mixed
330274ed1c8efd2b1aa9907860429d9d20f72c3c,"KAFKA-3229 ensure that root statestore is registered with ProcessorStateManager

Pass through the root StateStore in the init method so the inner StateStore can register that object.

Author: tomdearman <tom.dearman@gmail.com>

Reviewers: Yasuhiro Matsuda

Closes #904 from tomdearman/KAFKA-3229",2016-02-11 11:35:55,tomdearman,Mixed
d7fc7cf6154592b7fea494a092e42ad9d45b98a0,"KAFKA-3088; Make client-id a nullable string and fix handling of invalid requests.""

…ent ID

- Adds  NULLABLE_STRING Type to the protocol
- Changes client_id in the REQUEST_HEADER to NULLABLE_STRING with a default of """"
- Fixes server handling of invalid ApiKey request and other invalid requests

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Joel Koshy <jjkoshy.w@gmail.com>

Closes #866 from granthenke/null-clientid",2016-02-12 18:49:19,Grant Henke,Not TDD
5df56145a51c78e8808046254ad4771d60957ac5,"KAFKA-2508; Replace UpdateMetadata{Request,Response} with o.a.k.c.req…

…uests equivalent

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Sriharsha Chintalapani <mail@harsha.io>

Closes #896 from granthenke/update-metadata and squashes the following commits:

2eb5d59 [Grant Henke] Address reviews
497258d [Grant Henke] KAFKA-2508: Replace UpdateMetadata{Request,Response} with o.a.k.c.requests equivalent",2016-02-16 18:25:00,Grant Henke,Not TDD
2faf9f60c81023b4c061c4b8067c8b23cf73516e,"KAFKA-2547; Make DynamicConfigManager to use the ZkNodeChangeNotifica…

…tionListener introduced as part of KAFKA-2211

Author: Parth Brahmbhatt <brahmbhatt.parth@gmail.com>

Reviewers: Flavio Junqueira <fpj@apache.org>, Ismael Juma <ismael@juma.me.uk>, Sriharsha Chintalapani <mail@harsha.io>

Closes #679 from Parth-Brahmbhatt/KAFKA-2547 and squashes the following commits:

1722c76 [Parth Brahmbhatt] Addressing review comments.
376f77d [Parth Brahmbhatt] Merge branch 'trunk' of http://git-wip-us.apache.org/repos/asf/kafka into KAFKA-2547
a13b963 [Parth Brahmbhatt] Addressing comments from Reviewers.
1007137 [Parth Brahmbhatt] KAFKA-2547: Make DynamicConfigManager to use the ZkNodeChangeNotificationListener introduced as part of KAFKA-2211",2016-02-16 20:34:59,Parth Brahmbhatt,Not TDD
3382b6db7b2b9c17a4ccfd9ebe840741bcf44670,"KAFKA-2757; Consolidate BrokerEndPoint and EndPoint

Author: zhuchen1018 <amandazhu19620701@gmail.com>

Reviewers: Dong Lin <lindong28@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #911 from zhuchen1018/KAFKA-2757",2016-02-17 18:48:00,Chen Zhu,Not TDD
8c90b1a98acb1222a0e907153bf52a85af0fe443,"KAFKA-3225: Method commit() of class SourceTask never invoked

1. Added a test case to prove commit() on SourceTask was not being called.
2. Added commitSourceTask() which logs potential exceptions.
3. Added after call to finishSuccessfulFlush().

Author: Jeremy Custenborder <jeremy@scarcemedia.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #909 from jcustenborder/KAFKA-3225",2016-02-17 11:12:41,Jeremy Custenborder,Mixed
45c8195fa14c766b200c720f316836dbb84e9d8b,"KAFKA-3025; Added timetamp to Message and use relative offset.

See KIP-31 and KIP-32 for details.

A few notes on the patch:
1. This patch implements KIP-31 and KIP-32. The patch includes features in both KAFKA-3025,  KAFKA-3026 and KAFKA-3036
2. All unit tests passed.
3. The unit tests were run with new and old message format.
4. When message format conversion occurs during consumption, the consumer will not be able to detect the message size too large situation. I did not try to fix this because the situation seems rare and only happen during migration phase.

Author: Jiangjie Qin <becket.qin@gmail.com>
Author: Ismael Juma <ismael@juma.me.uk>
Author: Jiangjie (Becket) Qin <becket.qin@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Anna Povzner <anna@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>, Jun Rao <junrao@gmail.com>

Closes #764 from becketqin/KAFKA-3025",2016-02-19 07:56:40,Jiangjie Qin,Mixed
d2527af99a9bb1007f7fe63a0cd7d27a55182857,"KAFKA-3255: Added unit tests for NetworkClient.connectionDelay(Node node, long now)

Author: Frank Scholten <frank@frankscholten.nl>

Reviewers: Eno Thereska <eno.thereska@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #941 from frankscholten/tests/cluster-connection-states",2016-02-22 10:13:11,Frank Scholten,Not TDD
982ab09a790c6dbc2e1a5c52311103fd14ab5233,"HOTFIX: check offset limits in streamtask when recovering KTable store

guozhangwang

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #947 from ymatsuda/hotfix2",2016-02-22 21:37:27,Yasuhiro Matsuda,Not TDD
3358e1682f034a82afd670be95505b2f620c78c6,"KAFKA-2802: kafka streams system tests

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Geoff Anderson <geoff@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #930 from ymatsuda/streams_systest",2016-02-23 12:14:26,Yasuhiro Matsuda,Not TDD
14b688e00ddb54a5c8451411d269721484be875f,"KAFKA-3046: Add ByteBuffer Serializer and Deserializer

https://issues.apache.org/jira/browse/KAFKA-3046

Author: Xin Wang <best.wangxin@163.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #718 from vesense/patch-3",2016-02-23 15:03:55,Xin Wang,Not TDD
0ce9163989cb9898df7e74245cbc2ee37d729670,"MINOR: KTable.count() to only take a selector for key

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Gwen Shapira, Yashiru Matsuda, Michael Noll

Closes #872 from guozhangwang/KCount",2016-02-23 15:10:56,Guozhang Wang,Not TDD
73ecd7a1797a023039fea365a08dbdba4171d10b,"KAFKA-3007: implement max.poll.records (KIP-41)

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #931 from hachikuji/KAFKA-3007",2016-02-23 15:46:32,Jason Gustafson,Mixed
f7d019ed408fa988129be9af3689bfa4878bc627,"KAFKA-3093: Add Connect status tracking API

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #920 from hachikuji/KAFKA-3093",2016-02-23 22:47:31,Jason Gustafson,Mixed
01aeea7c7bca34f1edce40116b7721335938b13b,"KAFKA-3259 KAFKA-3253; KIP-31/KIP-32 Follow-up

This PR includes a number of clean-ups:
* Code style
* Documentation wording improvements
* Efficiency improvements

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #943 from ijuma/kafka-3259-kip-31-32-clean-ups",2016-02-24 11:28:53,Ismael Juma,Mixed
13b8fb295c3becc27e7954af623fe90b3062409e,"MINOR: enhance streams system test

guozhangwang

* add table aggregate to the system test
* actually create change log partition replica

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #966 from ymatsuda/enh_systest",2016-02-24 18:11:36,Yasuhiro Matsuda,Not TDD
5db2c99e15a4467489b495144815ac8334c2c5d4,"KAFKA-2698: Add paused() method to o.a.k.c.c.Consumer

Author: Tom Lee <github@tomlee.co>

Reviewers: Onur Karaman <okaraman@linkedin.com>, Jiangjie Qin <jiangjie@linkedin.com>, Grant Henke <ghenke@cloudera.com>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #962 from hachikuji/KAFKA-2698",2016-02-24 19:41:57,Tom Lee,Mixed
4e0ae79d5c9aec04c014aca55cd4823f89b933c8,"KAFKA-3214: Added system tests for compressed topics

Added CompressionTest that tests 4 producers, each using a different compression type and one not using compression.

Enabled VerifiableProducer to run producers with different compression types (passed in the constructor). This includes enabling each producer to output unique values, so that the verification process in ProduceConsumeValidateTest is correct (counts acks from all producers).

Also a fix for console consumer to raise an exception if it sees the incorrect consumer output (before we swallowed an exception, so was hard to debug the issue).

Author: Anna Povzner <anna@confluent.io>

Reviewers: Geoff Anderson, Jason Gustafson

Closes #958 from apovzner/kafka-3214",2016-02-26 13:40:39,Anna Povzner,Not TDD
d501cc62ddcbbddcb114a40527d3e4f71f501286,"KAFKA-3133: Add putIfAbsent function to KeyValueStore

guozhangwang

Author: Kim Christensen <kich@mvno.dk>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>

Closes #912 from kichristensen/KAFKA-3133",2016-02-29 12:46:03,Kim Christensen,Not TDD
845c6eae1f6c6bcf117f5baa53bb19b4611c0528,"KAFKA-3192: Add unwindowed aggregations for KStream; and make all example code executable

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Yasuhiro Matsuda, Michael G. Noll, Jun Rao

Closes #870 from guozhangwang/K3192",2016-02-29 14:03:32,Guozhang Wang,Mixed
695fdc69db6e080419bb05d624e91fa88d5c0a02,"KAFKA-3273; MessageFormatter and MessageReader interfaces should be resilient to changes

* Change `MessageFormat.writeTo` to take a `ConsumerRecord`
* Change `MessageReader.readMessage()` to use `ProducerRecord`

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #972 from ijuma/kafka-3273-message-formatter-and-reader-resilient",2016-02-29 18:52:54,Ismael Juma,Mixed
002b377dad9c956cd0ae0597981f29698883b6d5,"KAFKA-3196; Added checksum and size to RecordMetadata and ConsumerRecord

This is the second (remaining) part of KIP-42. See https://cwiki.apache.org/confluence/display/KAFKA/KIP-42%3A+Add+Producer+and+Consumer+Interceptors

Author: Anna Povzner <anna@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>, Jun Rao <junrao@gmail.com>

Closes #951 from apovzner/kafka-3196",2016-03-02 09:40:34,Anna Povzner,Mixed
2a58ba9fd893979f89aec251579b10f5cda41d10,"KAFKA-3311; Prepare internal source topics before calling partition grouper

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Yasuhiro Matsuda <yasuhiro.matsuda@gmail.com>, Jun Rao <junrao@gmail.com>

Closes #990 from guozhangwang/K3311",2016-03-02 13:43:48,Guozhang Wang,Mixed
cfc324333fa13e06ec7ac5ef3a09d8a6b6b54485,"KAFKA-3290: fix transient test failures in WorkerSourceTaskTest

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Gwen Shapira

Closes #998 from hachikuji/KAFKA-3290",2016-03-02 17:22:14,Jason Gustafson,Not TDD
079c88178dff4b3a4c9de55629e7d15b60e5f562,"KAFKA-2934; Offset storage file configuration in Connect standalone mode is not included in StandaloneConfig

Added offsetBackingStore config to StandaloneConfig and DistributedConfig;
Added config for offset.storage.topic and config.storage.topic into DistributedConfig;

Author: jinxing <jinxing@fenbi.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #734 from ZoneMayor/trunk-KAFKA-2934",2016-03-03 08:54:37,jinxing,Mixed
7079f57f70dfb5e731baf0a19bbf16e7364c15bb,"KAFKA-3290: fix race condition with worker task shutdown and mock validation

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Gwen Shapira

Closes #1008 from hachikuji/KAFKA-3290-REVISITED",2016-03-03 14:58:43,Jason Gustafson,Not TDD
5d893654489647e8be65c4d54864ab63b7285faa,"KAFKA-3310; Fix for NPEs observed when throttling clients.

The fix basically ensures that the throttleTimeSensor is non-null before handing off to record the metric value. We also record the throttle time to 0 so that we don't recreate the sensor always.

Author: Aditya Auradkar <aauradkar@linkedin.com>

Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Jun Rao <junrao@gmail.com>

Closes #989 from auradkar/KAFKA-3310",2016-03-03 16:16:56,Aditya Auradkar,Mixed
b7d6fae59ed782833981675efa0304ce2b12a59e,"KAFKA-3299: Ensure that reading config log on rebalance doesn't hang the herder

Author: Gwen Shapira <cshapi@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #981 from gwenshap/KAFKA-3299",2016-03-04 14:21:22,Gwen Shapira,Mixed
94c234341907b705ec34dd2b390899435286e242,"KAFKA-3341: Improve error handling on invalid requests

* Include request id when parsing of request header fails
* Don't mute selector on a connection that was closed due to an error (otherwise a second exception is thrown)
* Throw appropriate exception from `ApiKeys.fromId` if invalid id is passed
* Fail fast in `AbstractRequest.getRequest` if we fail to handle an instance of `ApiKeys` (if this happens, it's a programmer error and the code in `getRequest` needs to be updated)

I ran into the top two issues while trying to figure out why a connection from a producer to a broker was failing (and it made things harder than necessary). While fixing them, I noticed the third and fourth issues.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Gwen Shapira

Closes #1017 from ijuma/kafka-3341-improve-error-handling-invalid-requests",2016-03-07 11:34:12,Ismael Juma,Mixed
8d0c298c8c3283a7f8cffc4f68b3af87b0588e07,"KAFKA-2068; KAFKA-2069; Replace OffsetCommit and OffsetFetch Request/…

…Response with o.a.k.c.requests equivalent

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Ismael Juma

Closes #927 from granthenke/offset-refactor",2016-03-07 18:33:52,Grant Henke,Not TDD
f6e35dec9bf330c3531fd95c6566070d4ddf0457,"KAFKA-3201: Added rolling upgrade system tests from 0.8 and 0.9 to 0.10

Three main tests:
1. Setup: Producer (0.8) → Kafka Cluster → Consumer (0.8)
First rolling bounce: Set inter.broker.protocol.version = 0.8 and message.format.version = 0.8
Second rolling bonus, use latest (default) inter.broker.protocol.version and message.format.version
2. Setup: Producer (0.9) → Kafka Cluster → Consumer (0.9)
First rolling bounce: Set inter.broker.protocol.version = 0.9 and message.format.version = 0.9
Second rolling bonus, use latest (default) inter.broker.protocol.version and message.format.version
3. Setup: Producer (0.9) → Kafka Cluster → Consumer (0.9)
First rolling bounce: Set inter.broker.protocol.version = 0.9 and message.format.version = 0.9
Second rolling bonus: use inter.broker.protocol.version = 0.10 and message.format.version = 0.9

Plus couple of variations of these tests using old/new consumer and no compression / snappy compression.

Author: Anna Povzner <anna@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #980 from apovzner/kafka-3201-02",2016-03-07 23:18:17,Anna Povzner,Not TDD
5afa1660103df8aecbf7558e761418944fb5905a,"KAFKA-3197; Fix producer sending records out of order

This patch reuse max.in.flight.request.per.connection. When it equals to one, we take it as user wants order protection. The current approach is make sure there is only one batch per partition on the fly.

Author: Jiangjie Qin <becket.qin@gmail.com>

Reviewers: Aditya Auradkar <aauradkar@linkedin.com>, Jason Gustafson <jason@confluent.io>, Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Joel Koshy <jjkoshy.w@gmail.com>, Jun Rao <junrao@gmail.com>

Closes #857 from becketqin/KAFKA-3197",2016-03-08 14:06:53,Jiangjie Qin,Mixed
090d7220e2c0c4c8a39c388043c6032386ea024f,"KAFKA-3237: Allow ConfigDef options with no default and validator

Remove test cases testInvalidDefaultRange() and testInvalidDefaultString(). Defaults if not overridden will get checked on parse. Testing the defaults is unnecessary. This allows you to set that a parameter is required while setting a validator for that parameter. Added a test case testNullDefaultWithValidator that allows a null default with a validator for certain strings.

Author: Jeremy Custenborder <jcustenborder@gmail.com>

Reviewers: Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #936 from jcustenborder/KAFKA-3237",2016-03-08 21:56:33,Jeremy Custenborder,Mixed
324b0c85f603005dceee69033b8fbffc7ef95281,"KAFKA-3279: Remove checks for JAAS system property

JAAS configuration may be set using other methods and hence the check for System property doesn't  always match where the actual configuration used by Kafka is loaded from.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Sriharsha Chintalapani <harsha@hortonworks.com>, Flavio Junqueira <fpj@apache.org>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #967 from rajinisivaram/KAFKA-3279",2016-03-08 23:40:09,Rajini Sivaram,Not TDD
818080312364940e4a6e964c22ec54e133b8ec02,"KAFKA-3352: Avoid DNS reverse lookups

By using `getHostString` (introduced in Java 7) instead of `getHostName`.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson, Grant Henke

Closes #1030 from ijuma/kafka-3352-avoid-dns-reverse-look-ups",2016-03-09 14:19:57,Ismael Juma,Mixed
6eb061fa85de1b5346eb2652622c9c60f7f3baf1,"MINOR: Fix system test broken by change of consumer group tool output format

… format

Author: Gwen Shapira <cshapi@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1039 from gwenshap/minor-consumer-groups",2016-03-10 11:12:07,Gwen Shapira,Not TDD
9c4c5ae1cd15aa0afe3156e572362fbb40130573,"MINOR: Add unit test for internal topics

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Yasuhiro Matsuda <yasuhiro@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1047 from guozhangwang/KInternal",2016-03-10 14:54:47,Guozhang Wang,Mixed
764d8ca9eb0aba6099ba289a10f437e72b53ffec,"KAFKA-2073: migrate to client-side topic metadata request/response

Author: Jason Gustafson <jason@confluent.io>
Author: Ismael Juma <ismael@juma.me.uk>
Author: hachikuji <jason@confluent.io>

Reviewers: Grant Henke, Ismael Juma, Gwen Shapira, Flavio Junquiera

Closes #988 from hachikuji/KAFKA-2073",2016-03-11 11:11:59,Jason Gustafson,Mixed
02d4da5f64989b41358cdfd94d95b94fb4e20198,"KAFKA-2960 KAFKA-1148; Clear purgatory for partitions before becoming follower

Author: Jiangjie Qin <becket.qin@gmail.com>

Reviewers: Aditya Auradkar <aauradkar@linkedin.com>, Ismael Juma <ismael@juma.me.uk>, Joel Koshy <jjkoshy.w@gmail.com>, Jun Rao <junrao@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #1018 from becketqin/KAFKA-2960",2016-03-11 11:22:15,Jiangjie Qin,Mixed
a162f6bf66d0d21505c8d11942f84be446616491,"KAFKA-3380; Add system test for GetOffsetShell tool

Author: Ashish Singh <asingh@cloudera.com>

Reviewers: Gwen Shapira

Closes #1048 from SinghAsDev/KAFKA-3380",2016-03-11 12:17:45,Ashish Singh,Not TDD
c1a56c6839e77f3de5266315a92b236a379ec857,"KAFKA-3395: prefix job id to internal topic names

guozhangwang

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1062 from ymatsuda/k3395",2016-03-14 14:50:24,Yasuhiro Matsuda,Mixed
ffbe624e6f4906c55080508fab19ac60dc93761e,"KAFKA-3373; add 'log' prefix to configurations in KIP-31/32

Author: Jiangjie Qin <becket.qin@gmail.com>

Reviewers: Gwen Shapira

Closes #1049 from becketqin/KAFKA-3373",2016-03-14 19:13:26,Jiangjie Qin,Mixed
241c3ebb2803f1e09306fb06f20a66e7a60ca3c8,"KAFKA-3375; Suppress deprecated warnings where reasonable and tweak compiler settings

* Fix and suppress number of unchecked warnings (except for Kafka Streams)
* Add `SafeVarargs` annotation to fix warnings
* Suppress unfixable deprecation warnings
* Replace deprecated by non-deprecated usage where possible
* Avoid reflective calls via structural types in Scala
* Tweak compiler settings for scalac and javac

Once we drop Java 7 and Scala 2.10, we can tweak the compiler settings further so that they warn us about more things.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Grant Henke, Gwen Shapira, Guozhang Wang

Closes #1042 from ijuma/kafka-3375-suppress-depreccated-tweak-compiler",2016-03-14 19:14:36,Ismael Juma,Mixed
951e30adc6d4a0ed37dcc3fde0050ca5faff146d,"KAFKA-1215; Rack-Aware replica assignment option

Please see https://cwiki.apache.org/confluence/display/KAFKA/KIP-36+Rack+aware+replica+assignment for the overall design.

The update to TopicMetadataRequest/TopicMetadataResponse will be done in a different PR.

Author: Allen Wang <awang@netflix.com>
Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>, 	Grant Henke <granthenke@gmail.com>, Jun Rao <junrao@gmail.com>

Closes #132 from allenxwang/KAFKA-1215",2016-03-15 10:03:03,Allen Wang,Mixed
355076cd262dd071287a1c8586ae0f9635e218e3,"MINOR: kstream/ktable counting method with default long serdes

guozhangwang miguno

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Michael G. Noll, Guozhang Wang

Closes #1065 from ymatsuda/count_serdes",2016-03-15 12:08:26,Yasuhiro Matsuda,Not TDD
6eacc0de303e4d29e083b89c1f53615c1dfa291e,"KAFKA-3260 - Added SourceTask.commitRecord

Added commitRecord(SourceRecord record) to SourceTask. This method is called during the callback from producer.send() when the message has been sent successfully. Added commitTaskRecord(SourceRecord record) to WorkerSourceTask to handle calling commitRecord on the SourceTask. Updated tests for calls to commitRecord.

Author: Jeremy Custenborder <jcustenborder@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #950 from jcustenborder/KAFKA-3260",2016-03-15 14:32:22,Jeremy Custenborder,Mixed
858047a12ba3a7d426178c63226dd2c7509f20dd,"KAFKA-3402; Restore behaviour of MetadataCache.getTopicMetadata when unsupported security protocol is received

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson, Grant Henke

Closes #1073 from ijuma/kafka-3402-restore-get-topic-metadata-behaviour",2016-03-16 16:15:55,Ismael Juma,Mixed
9a836d0154efe6ea1effc688567186cb56265bf4,"KAFKA-3303; Pass partial record metadata to ProducerInterceptor.onAcknowledgement on error

This is a KIP-42 followup.

Currently, If sending the record fails before it gets to the server, ProducerInterceptor.onAcknowledgement() is called with metadata == null, and non-null exception. However, it is useful to pass topic and partition, if known, to ProducerInterceptor.onAcknowledgement() as well. This patch ensures that  ProducerInterceptor.onAcknowledgement()  gets record metadata with topic and maybe partition. If partition is not set in 'record' and KafkaProducer.send() fails before partition gets assigned, then ProducerInterceptor.onAcknowledgement() gets RecordMetadata with partition == -1. Only time when  ProducerInterceptor.onAcknowledgement() gets null record metadata is when the client passes null record to KafkaProducer.send().

Author: Anna Povzner <anna@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Ashish Singh <asingh@cloudera.com>, Jun Rao <junrao@gmail.com>

Closes #1015 from apovzner/kip42-3",2016-03-16 17:29:29,Anna Povzner,Mixed
958e10c87ce293c3bf59bb9840eaaae915eff25e,"KAFKA-3411: Streams: stop using ""job"" terminology, rename job.id to application.id

guozhangwang ymatsuda : please review.

Author: Michael G. Noll <michael@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1081 from miguno/KAFKA-3411",2016-03-17 10:41:48,Michael G. Noll,Mixed
dce06766da245ca95951c9c7e82d6a113db7cb13,"KAFKA-3392: ConsumerRecords iterator throws NoSuchElementException when a TopicPartition is empty

This contribution is my original work, and I license it under the project's open source license.

CC jkreps

Author: Drausin Wulsin <daedalus2718@gmail.com>
Author: John Doe <daedalus2718@gmail.com>

Reviewers: Jason Gustafson

Closes #1055 from drausin/bugfix/consumer-records-iterator",2016-03-17 10:52:33,Drausin Wulsin,Mixed
30e78fa00650b258f3ab5ef6c9bdf5ca137289c0,"KAFKA-2832: Add a consumer config option to exclude internal topics

A new consumer config option 'exclude.internal.topics' was added to
allow excluding internal topics when wildcards are used to specify
consumers.
The new option takes a boolean value, with a default 'false' value (i.e.
no exclusion).

This patch is co-authored with rajinisivaram edoardocomar mimaison

Author: edoardo <ecomar@uk.ibm.com>
Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Ismael Juma, Jun Rao, Gwen Shapira

Closes #1082 from edoardocomar/KAFKA-2832",2016-03-17 12:33:47,edoardo,Mixed
a1eb12d7c6ad9422b9cf24b670d1b4c11227b03e,"KAFKA-3188: Compatibility test for old and new clients with 0.10 broker

apovzner becketqin please have a look if you can. Thanks.

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Anna Povzner, Gwen Shapira

Closes #1059 from enothereska/kafka-3188-compatibility",2016-03-17 13:17:01,Eno Thereska,Not TDD
c07d017227f319250e5c373f8a6f504874ecfbf2,"KAFKA-3315: Add REST and Connector API to expose connector configuration

Author: Liquan Pei <liquanpei@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #964 from Ishiihara/expose-connector-config",2016-03-17 13:26:02,Liquan Pei,Mixed
8ef804dc194bb562b6dbe48855e81965cacd1114,"KAFKA-3414; Return of MetadataCache.getAliveBrokers should not be mutated by cache updates

`Map.values` returns `DefaultValuesIterable` where the default implementation of `toSeq` is (sadly) `toStream`. `Stream` is a lazy collection and it can reflect changes to the underlying map before it's `forced`.

I verified that the test failed before my change.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Gwen Shapira

Closes #1088 from ijuma/kafka-3414-get-alive-brokers-no-mutation",2016-03-17 13:56:27,Ismael Juma,Mixed
dea0719e99211684775780f5da8b93835d7a5dac,"KAFKA-3336: Unify Serializer and Deserializer into Serialization

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Michael G. Noll, Ismael Juma

Closes #1066 from guozhangwang/K3336",2016-03-17 15:41:59,Guozhang Wang,Mixed
e89a9ce1a4383af32435c7f4ee04361b1b65797d,"KAFKA-2982; Mark the old Scala producer and related classes as deprecated

Also update server tests to always use new producer.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Gwen Shapira

Closes #1092 from ijuma/kafka-2982-deprecate-old-producers",2016-03-17 18:12:40,Ismael Juma,Mixed
5d0cd7667f7e584f05ab4e76ed139fbafa81e042,"KAFKA-3422: Add overloading functions without serdes in Streams DSL

Also include:

1) remove streams specific configs before passing to producer and consumer to avoid warning message;
2) add `ConsumerRecord` timestamp extractor and set as the default extractor.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Michael G. Noll, Ewen Cheslack-Postava

Closes #1093 from guozhangwang/KConfigWarn",2016-03-18 12:39:41,Guozhang Wang,Mixed
d9bf55171ba41962edc05cdf106f540cf94a2c3e,"KAFKA-3394; allow null offset metadata in commit API

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <me@ewencp.org>, Jun Rao <junrao@gmail.com>

Closes #1064 from hachikuji/KAFKA-3394",2016-03-18 13:37:33,Jason Gustafson,Not TDD
4332175c11dda5deb491f27a6ecf66661676ca47,"KAFKA-3006: standardize KafkaConsumer API to use Collection

Author: Pierre-Yves Ritschard <pyr@spootnik.org>

Reviewers: Jason Gustafson, Gwen Shapira

Closes #1098 from hachikuji/KAFKA-3006",2016-03-18 16:07:20,Pierre-Yves Ritschard,Mixed
eb823281a52f3b27c3a889e7412bc07b3024e688,"KAFKA-3424: Add CORS support to Connect REST API

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Gwen Shapira

Closes #1099 from ewencp/cors-rest-support",2016-03-19 18:39:52,Ewen Cheslack-Postava,Mixed
bfac36ad0e378b5f39e3889e40a75c5c1fc48fa7,"KAFKA-3328: SimpleAclAuthorizer can lose ACLs with frequent add/remov…

…e calls

Changes the SimpleAclAuthorizer to:
- Track and utilize the zookeeper version when updating zookeeper to prevent data loss in the case of stale reads and race conditions
- Update local cache when modifying ACLs
- Add debug logging

Author: Grant Henke <granthenke@gmail.com>
Author: Grant Henke <granthenke@users.noreply.github.com>
Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Flavio Junqueira, Jun Rao, Ismael Juma, Gwen Shapira

Closes #1006 from granthenke/simple-authorizer-fix",2016-03-20 00:46:12,Grant Henke,Mixed
4f048c4f194a90ded5f0df35e4e23379272d5bc6,"MINOR: Fix FetchRequest.getErrorResponse for version 1

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #1091 from granthenke/fetch-error",2016-03-20 20:19:54,Grant Henke,Not TDD
8d8e3aaa6172d314230a8d61e6892e9c09dc45b6,"KAFKA-3412: multiple asynchronous commits causes send failures

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1108 from hachikuji/KAFKA-3412",2016-03-21 20:47:25,Jason Gustafson,Mixed
73c79000edddd929cd0af25f4a29fcc682a1c9c0,"KAFKA-3426; Improve protocol type errors when invalid sizes are received

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Grant Henke, Gwen Shapira

Closes #1100 from ijuma/kafka-3426-invalid-protocol-type-errors-invalid-sizes",2016-03-22 12:39:04,Ismael Juma,Not TDD
ad3dfc6ab25c3f80d2425e24e72ae732b850dc60,"KAFKA-3219: Fix long topic name validation

This fixes an issue with long topic names by considering, during topic
validation, the '-' and the partition id that is appended to the log
folder created for each topic partition.

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Gwen Shapira, Grant Henke

Closes #898 from vahidhashemian/KAFKA-3219",2016-03-22 13:10:07,Vahid Hashemian,Mixed
255b5e13863a95cfc327236856db2df188f04d49,"KAFKA-3431: Remove `o.a.k.common.BrokerEndPoint` in favour of `Node`

Also included a minor efficiency improvement in kafka.cluster.EndPoint.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Gwen Shapira

Closes #1105 from ijuma/kafka-3431-replace-broker-end-point-with-node",2016-03-22 19:13:26,Ismael Juma,Not TDD
7af67ce22aa02121d6b82dc54dad42358282e524,"KAFKA-3442; Fix FileMessageSet iterator.

Author: Jiangjie Qin <becket.qin@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #1112 from becketqin/KAFKA-3442",2016-03-23 07:15:59,Jiangjie Qin,Mixed
de062443381df84ee0d65acc20e44ffca2b2552b,"MINOR: remove streams-smoke-test.sh

guozhangwang

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1125 from ymatsuda/remove_smoketest_shell_script",2016-03-23 14:57:03,Yasuhiro Matsuda,Not TDD
cb78223bf90aca4f75699f36c1a82db7661a62f3,"KAFKA-3434; add old constructor to ConsumerRecord

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1123 from hachikuji/KAFKA-3434",2016-03-23 22:36:19,Jason Gustafson,Mixed
c1d8c38345e0a1e04ced143ed07e63fe02ceb8b0,"KAFKA-3449: Rename filterOut() to filterNot() to achieve better terminology

…nology

Hi all,

This is my first contribution and I hope it will be good.

The PR is related to this issue:
https://issues.apache.org/jira/browse/KAFKA-3449

Thanks a lot,

Andrea

Author: Andrea Cosentino <ancosen@gmail.com>

Reviewers: Yasuhiro Matsuda, Guozhang Wang

Closes #1134 from oscerd/KAFKA-3449",2016-03-25 15:00:45,Andrea Cosentino,Mixed
78fa20eb58a948abd9ad4e44acfed606400a47f3,"KAFKA-3316: Add REST API for listing connector plugins

Author: Liquan Pei <liquanpei@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1090 from Ishiihara/kafka-3316",2016-03-25 16:46:53,Liquan Pei,Mixed
1fbe445dde71df0023a978c5e54dd229d3d23e1b,"KAFKA-3388; Fix expiration of batches sitting in the accumulator

Author: Jiangjie Qin <becket.qin@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #1056 from becketqin/KAFKA-3388",2016-03-26 09:22:59,Jiangjie Qin,Mixed
43d5078e981bbb25fd81cdc8ba4c339cd2d3f3d2,"MINOR: Remove a couple of redundant `CoreUtils.rm` methods

Also:
* Rename remaining `CoreUtils.rm` to `delete` for consistency
* Use `try with resources` in `Utils` to simplify code
* Silence compiler warning due to exception catch clause in `TestUtils`

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1153 from ijuma/remove-redundant-core-utils-rm",2016-03-28 14:35:31,Ismael Juma,Mixed
78d91dcd8805d850038df52718380a6f956abad7,"KAFKA-3475; Introduce our own `MiniKdc`

This also fixes KAFKA-3453 and KAFKA-2866.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Gwen Shapira

Closes #1155 from ijuma/kafka-3475-introduce-our-minikdc",2016-03-30 19:30:34,Ismael Juma,Not TDD
9f6a6f97134a1d4969c91c4b4e9037b376e03440,"KAFKA-3381: Add system test for SimpleConsumerShell

Author: Ashish Singh <asingh@cloudera.com>

Reviewers: Geoff Anderson

Closes #1053 from SinghAsDev/KAFKA-3381",2016-03-30 19:33:37,Ashish Singh,Mixed
89fd97f8c934b99b1ad994e36435e0686ef7b85a,"KAFKA-2844; Separate keytabs for sasl tests

Use a different keytab for server and client in SASL tests

Also:
* Improve approach used to build the JAAS files programmatically
* Delete stale `kafka_jaas.conf` file
* Move `FourLetterWords` to its own file, add `Zk` prefix and clean-up its usage

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Harsha Chintalapani, Gwen Shapira

Closes #533 from ijuma/separate-keytabs-for-sasl-tests",2016-04-01 15:25:35,Ismael Juma,Not TDD
dd5480a47eb0f45214c179b7f14ffaf493164222,"KAFKA-3486: fix autocommit when partitions assigned manually

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1169 from hachikuji/KAFKA-3486",2016-04-02 23:02:19,Jason Gustafson,Mixed
45c585b4f7e3d5e5dd5297b4d121badbd2052922,"KAFKA-3483: Restructure ducktape tests to simplify running subsets of tests

… tests

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Geoff Anderson <geoff@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1162 from granthenke/ducktape-structure",2016-04-03 20:04:36,Grant Henke,Mixed
31e263e8294e94de3d2c44d2ab3a827ab904e247,"HOTFIX: set timestamp in SinkNode

guozhangwang
Setting the timestamp in produced records in SinkNode. This forces the producer record's timestamp same as the context's timestamp.

Author: Yasuhiro Matsuda <yasuhiro@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1137 from ymatsuda/set_timestamp_in_sinknode",2016-04-04 14:57:15,Yasuhiro Matsuda,Not TDD
c3c9289c12342065d6c671098aaace23a328c7ff,"KAFKA-3464: Add system tests for Connect with Kafka security enabled

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Ismael Juma, Gwen Shapira

Closes #1141 from ewencp/kafka-3464-connect-security-system-tests",2016-04-04 18:49:29,Ewen Cheslack-Postava,Mixed
aee8ebb46cd9393a0886c42cb88b080d065da397,"KAFKA-3510; OffsetIndex thread safety

* Make all fields accessed outside of a lock `volatile`
* Only allow mutation within the class
* Remove unnecessary `AtomicInteger` since mutation always happens inside a lock

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1188 from ijuma/kafka-3510-offset-index-thread-safety",2016-04-05 11:46:04,Ismael Juma,Mixed
893e79af88016f1d8659e72d48a25d4a825b8867,"KAFKA-3489; Update request metrics if a client closes a connection while the broker response is in flight

I also fixed a few issues in `SocketServerTest` and included a few clean-ups.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #1172 from ijuma/kafka-3489-update-request-metrics-if-client-closes",2016-04-05 18:16:48,Ismael Juma,Mixed
8218a4a153d9138f29486e74cf77c88d1786997a,"KAFKA-3508: Fix transient SimpleACLAuthorizerTest failures

Allows the the maximum retires when writing to zookeeper to be overridden in tests and sets the value to Int.MaxValue to avoid transient failure.

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1156 from granthenke/transient-acl-test",2016-04-05 15:17:46,Grant Henke,Mixed
8dbd688b1617968329087317fa6bde8b8df0392e,"KAFKA-3497: Streams ProcessorContext should support forward() based on child name

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Yuto Kawamura, Michael G. Noll, Guozhang Wang

Closes #1194 from enothereska/kafka-3497-forward",2016-04-07 10:20:17,Eno Thereska,Not TDD
9c34df1511a769b272893b75ec1ed90d38cc9576,"KAFKA-3488; Avoid failing of unsent requests in consumer where possible

Fail unsent requests only when returning from KafkaConsumer.poll().

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1183 from rajinisivaram/KAFKA-3488",2016-04-07 15:48:50,Rajini Sivaram,Mixed
3a58407e2e0aee0bb2c5e343fbe98c7f28fc6f3e,"KAFKA-3505: Fix punctuate generated record metadata

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Anna Povzner <anna@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1190 from guozhangwang/K3505",2016-04-08 08:59:50,Guozhang Wang,Mixed
9beafae23a83774fc1d9ea811d449eac34240363,"KAFKA-3512: Added foreach operator

miguno guozhangwang please have a look if you can.

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Michael G. Noll <michael@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #1193 from enothereska/kafka-3512-ForEach",2016-04-08 09:17:05,Eno Thereska,Mixed
4d467c2ec275b5659c2da0ca196409dffaa3caf3,"KAFKA-725: Return OffsetOutOfRange error from ReplicaManager when non-follower attempts reading an offset that's above high watermark.

This should make Log.read act the same when startOffset is larger than maxOffset as it would if startOffset was larger than logEndOffset. The current behavior can result in an IllegalArgumentException from LogSegment if a consumer attempts to fetch an offset above the high watermark which is present in the leader's log. It seems more correct if Log.read presents the view of the log to consumers as if it simply ended at maxOffset (high watermark).

I've tried to describe an example scenario of this happening here https://issues.apache.org/jira/browse/KAFKA-725?focusedCommentId=15221673&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15221673

I'm not sure I understand why ReplicaManager sets maxOffset to the high watermark, and not high watermark + 1. Isn't the high watermark the last committed message, and readable by consumers?

Tests passed for me locally on second try, seems like it just hit a flaky test.

Author: Stig Rohde Døssing <sdo@it-minds.dk>

Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #1178 from srdo/KAFKA-725",2016-04-08 09:44:51,Stig Rohde Døssing,Mixed
cbdd70ec0de4b4d6d04b62580a5a67ea69311c4a,"MINOR: improve logging of consumer system tests

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1199 from hachikuji/improve-consumer-systests",2016-04-08 10:04:46,Jason Gustafson,Not TDD
2a8fa287862912491d1e118c52a2d194d8480075,"KAFKA-3528: handle wakeups while rebalancing more gracefully

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1201 from hachikuji/KAFKA-3528",2016-04-08 12:55:21,Jason Gustafson,Not TDD
7c27989860e7e063bfec3c679cb6bc8fd52abc84,"KAFKA-3338: Add print and writeAsText to KStream/KTable in Kafka Streams

    Addresses comments from previous PR [#1187]
    Changed print and writeAsText method return signature to void
    Flush System.out on close
    Changed IllegalStateException to TopologyBuilderException
    Updated MockProcessorContext.topic method to return a String
    Renamed KStreamPrinter to KeyValuePrinter
    Updated the printing of null keys to 'null' to match ConsoleConsumer
    Updated JavaDoc stating need to override toString

Author: bbejeck <bbejeck@gmail.com>

Reviewers: Dan Norwood, Guozhang Wang

Closes #1209 from bbejeck/KAFKA-3338_Adding_print/writeAsText_to_Streams_DSL",2016-04-10 17:43:47,bbejeck,Not TDD
c76b6e6d9bad2278076054f5175a2b053383388f,"HOTFIX: special handling first ever triggered punctuate

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Anna Povzner <anna@confluent.io>

Closes #1208 from guozhangwang/KPunctuate",2016-04-10 23:09:43,Guozhang Wang,Not TDD
40fd456649b5df29d030da46865b5e7e0ca6db15,"KAFKA-3519: Refactor Transformer's transform / punctuate to return nullable values

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Dan Norwood, Anna Povzner

Closes #1204 from guozhangwang/KTransformR",2016-04-11 12:33:48,Guozhang Wang,Mixed
667ff7ef737612773c50908d2b3cc829bb5132c7,"KAFKA-3504; Log compaction for changelog partition

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>

Closes #1203 from enothereska/KAFKA-3504-logcompaction",2016-04-12 17:38:20,Eno Thereska,Mixed
c1694833d5c095e47e5767f38c3e85bbe927a0a7,"KAFKA-3490; Multiple version support for ducktape performance tests

Author: Ismael Juma <ismael@juma.me.uk>
Author: Geoff Anderson <geoff@confluent.io>

Reviewers: Geoff Anderson <geoff@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1173 from ijuma/kafka-3490-multiple-version-support-perf-tests",2016-04-13 13:50:49,Ismael Juma,Not TDD
f4d3d2865894f1a1ade9d92ac27931fd35d16cae,"KAFKA-3470: treat commits as member heartbeats

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>

Closes #1206 from hachikuji/KAFKA-3470",2016-04-13 18:09:08,Jason Gustafson,Mixed
065ddf90195e09689512b55d0718a5ebdb3d42ad,"KAFKA-3549: Close consumers instantiated in consumer tests

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1217 from granthenke/close-consumers",2016-04-14 22:02:19,Grant Henke,Not TDD
5236bf60debbb0c08010315a92dd3fbfa482e871,"KAFKA-3526: Return string instead of object in ConfigKeyInfo and ConfigValueInfo

Author: Liquan Pei <liquanpei@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1200 from Ishiihara/config-string",2016-04-15 15:51:31,Liquan Pei,Mixed
b1691cf49e9de850ac8a2675c487af9fb60bfdaa,"KAFKA-3430: Allow users to set key in KTable.toStream and in KStream.

… With KStream the method selectKey was added to enable getting a key from values before perfoming aggregation-by-key operations on original streams that have null keys.

Author: bbejeck <bbejeck@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1222 from bbejeck/KAFKA-3430_allow_users_to_set_key_KTable_toStream",2016-04-16 20:18:27,Bill Bejeck,Not TDD
89c67727c2793bf56b0b005a7d758beebedb5aed,"KAFKA-3506: Kafka Connect restart APIs

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1189 from hachikuji/KAFKA-3506",2016-04-18 10:50:58,Jason Gustafson,Mixed
a5f1158c317e22a79c4186d1acb04fb25ce6e56a,"KAFKA-3558; Add compression_type parameter to benchmarks in benchmark_test.py

* Use a fixed `Random` seed in `EndToEndLatency.scala` for determinism
* Add `compression_type` to and remove `consumer_fetch_max_wait` from `end_to_end_latency.py`. The latter was never used.
* Tweak logging of `end_to_end_latency.py` to be similar to `consumer_performance.py`.
* Add `compression_type` to `benchmark_test.py` methods and add `snappy` to `matrix` annotation
* Use randomly generated bytes from a restricted range for `ProducerPerformance` payload. This is a simple fix for now. It can be improved in the PR for KAFKA-3554.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1225 from ijuma/kafka-3558-add-compression_type-benchmark_test.py",2016-04-18 14:23:46,Ismael Juma,Not TDD
0bf61039c858af17260878d4815dbe7fb1645f90,"MINOR: Fix typos in code comments

This patch fixes all occurances of two consecutive 'the's in the code comments.

Author: Ishita Mandhan (imandhaus.ibm.com)

Author: Ishita Mandhan <imandha@us.ibm.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1240 from imandhan/typofixes",2016-04-19 17:39:04,Ishita Mandhan,Mixed
c9485b78a6e43747daf1314ae9532839fb7bc810,"KAFKA-2370: kafka connect pause/resume API

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Liquan Pei <liquanpei@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1087 from hachikuji/KAFKA-2370",2016-04-20 14:09:59,Jason Gustafson,Mixed
8a863ecee7e5dcdaf66a55b91040a7893ffdbf66,"KAFKA-3117: handle metadata updates during consumer rebalance

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1247 from hachikuji/KAFKA-3117",2016-04-20 17:08:00,Jason Gustafson,Mixed
9d71489ff0e62fd1897c7a6f54671673db7b37b8,"KAFKA-3548: Use root locale for case transformation of constant strings

For enums and other constant strings, use locale independent case conversions to enable comparisons to work regardless of the default locale.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Manikumar Reddy, Ismael Juma, Guozhang Wang, Gwen Shapira

Closes #1220 from rajinisivaram/KAFKA-3548",2016-04-20 18:54:30,Rajini Sivaram,Not TDD
5c547475d86aa336f8b3c4bb69faff39759d5df5,"KAFKA-3337: Extract selector as a separate groupBy operator for KTable aggregations

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1231 from mjsax/kafka-3337-extact-key-selector-from-agg",2016-04-21 13:42:17,Matthias J. Sax,Not TDD
74e6dc842559d344241c70cb6607a69291e3a20d,"KAFKA-3589: set inner serializer for ChangedSerde upon initialization

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Eno Thereska <eno.thereska@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1246 from guozhangwang/K3589",2016-04-21 14:51:21,Guozhang Wang,Not TDD
32740044972ad3bfc9539b5d76128dceddedc2ba,"KAFKA-3594; After calling MemoryRecords.close() method, hasRoomFor() method should return false

This exception is occurring when producer is trying to append a record to a Re-enqueued record batch in the accumulator. We should not allow to add a record to Re-enqueued record batch. This is due a bug in MemoryRecords.java/hasRoomFor() method. After calling MemoryRecords.close() method, hasRoomFor() method should return false.

Author: Manikumar reddy O <manikumar.reddy@gmail.com>

Reviewers: Ismael Juma, Grant Henke, Guozhang Wang

Closes #1249 from omkreddy/KAFKA-3594",2016-04-21 15:13:25,Manikumar reddy O,Mixed
bc5051565171cf65b4ed7dd4d9ef269d66a1021a,"KAFKA-3605: Return error if connector config includes mismatching connector name.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Jason Gustafson

Closes #1253 from ewencp/kafka-3605-connector-name-mismatch",2016-04-22 07:09:14,Ewen Cheslack-Postava,Mixed
996e29cfe8a9e5a45d4b778a84fb20479eeba469,"KAFKA-3619: File handles are leaked on .lock files of ProcessorStateManager

Kafka Streams seems to hold file handles on the `.lock` files for the state dirs, resulting in an explosion of filehandles over time. Running `lsof` shows the number of open filehandles on the `.lock` file increasing rapidly over time. In a separate test project, I reproduced the issue and determined that in order for the filehandle to be relinquished the `FileChannel` instance must be properly closed. Applying this patch seems to resolve the issue in my job.

Author: Greg Fodor <gfodor@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1267 from gfodor/bug/state-lock-filehandle-leak",2016-04-25 13:45:51,Greg Fodor,Mixed
b3847f76b571deac5c7da7287a642c8b354a2a8c,"KAFKA-3270; Added some Happy Path Tests for the Reassign Partitions Command

with help from enothereska  :)

Author: Ben Stopford <benstopford@gmail.com>

Reviewers: Jun Rao <junrao@apache.org>, Eno Thereska <eno.thereska@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #956 from benstopford/KAFKA-3270-ReassignPartitionsCommand-Tests",2016-04-26 06:31:00,Ben Stopford,Not TDD
e7d04c2515be158d9a7f0ff0d7571bd41287d91a,"KAFKA-3602; Rename RecordAccumulator dequeFor() and fix usage

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Grant Henke <granthenke@gmail.com>, Ashish Singh <asingh@cloudera.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1254 from hachikuji/KAFKA-3602",2016-04-26 06:37:08,Jason Gustafson,Mixed
a02c8aaecfbd13838c2a062bac1455da352028fe,"KAFKA-3499: prevent array typed keys in KeyValueStore

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Ismael Juma, Josh Gruenberg, Michael G. Noll, Ewen Cheslack-Postava

Closes #1229 from guozhangwang/K3499",2016-04-26 07:32:21,Guozhang Wang,Mixed
9d37b9f4b6ba228ff7f7b99c8a0921a971fc03a6,"KAKFA-3599: Move WindowStoreUtils to package ""internals""

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Ismael Juma, Michael G. Noll, Guozhang Wang

Closes #1266 from mjsax/kafka-3599-minorCodeCleanup",2016-04-26 10:53:49,Matthias J. Sax,Mixed
1a73629bb43bbc781e5a968a61f6079365bc75b7,"KAFKA-3607: Close KStreamTestDriver upon completing; follow-up fixes to be tracked in KAFKA-3623

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Eno Thereska, Michael G. Noll, Ismael Juma

Closes #1258 from guozhangwang/K3607",2016-04-26 11:39:49,Guozhang Wang,Not TDD
5b375d7bf9b26aaeed06bac2dc5de3f8214cbad4,"KAFKA-3149; Extend SASL implementation to support more mechanisms

Code changes corresponding to KIP-43 to enable review of the KIP.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Jun Rao <junrao@apache.org>, Ismael Juma <ismael@juma.me.uk>

Closes #812 from rajinisivaram/KAFKA-3149",2016-04-26 16:56:42,Rajini Sivaram,Mixed
33d745e2dcfa7a9cac90af5594903330ad774cd2,"KAFKA-3306: Change metadata response to include required additional fi…

…elds

- Adds boolean type to the protocol
- Allows protocol arrays to be null (optionally)
- Adds support to ask for no topics in the metadata request
- Adds new fields to the Metadata response protocol
- Adds server code to handle new fields
   - Support no-topic metadata requests
   - Track controller id in the metadata cache
   - Check if a topic is considered internal
   - Included rack information if present
   - Include all replicas and ISRs, even if node is down
- Adds test code to test new functionality independent of the client

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Gwen Shapira, Ismael Juma, Ashish Singh

Closes #1095 from granthenke/metadata-changes",2016-04-26 17:03:18,Grant Henke,Mixed
4c76b5fa6a72412efa5936c284800148c2c69c24,"KAFKA-3629; KStreamImpl.to(...) throws NPE when the value SerDe is null

guozhangwang

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax, Guozhang Wang

Closes #1272 from dguy/kstreamimpl-to-npe and squashes the following commits:

49d48fb [Damian Guy] actually commit the fix
07ce589 [Damian Guy] fix npe in KStreamImpl.to(..)
74d396d [Damian Guy] fix npe in KStreamImpl.to(..)",2016-04-27 10:50:20,Damian Guy,Mixed
8407dac6ee409d832c95533e6f1d5578511232ae,"KAFKA-3307; Add ApiVersions Request/Response and server side handling.

The patch does the following.
1. Adds ApiVersionsRequest/Response.
2. Adds UNSUPPORTED_VERSION error and UnsupportedVersionException.
3. Adds broker side handling of ApiVersionsRequest.

Author: Ashish Singh <asingh@cloudera.com>

Reviewers: Gwen Shapira, Ismael Juma, Magnus Edenhill

Closes #986 from SinghAsDev/KAFKA-3307",2016-04-27 11:28:32,Ashish Singh,Mixed
94aee2143ed5290d27cdd4072c6ae9bb70a6ba30,"KAFKA-3612: Added structure for integration tests

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Ismael Juma, Damian Guy, Michael G. Noll, Guozhang Wang

Closes #1260 from enothereska/KAFKA-3612-integration-tests",2016-04-27 16:55:51,Eno Thereska,Not TDD
669be7fadc808a8436ba28d033b70d24641c75ea,"KAFKA-3631; Fix Struct.toString for nullable arrayOf

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #1279 from granthenke/struct-fix",2016-04-27 17:15:37,Grant Henke,Not TDD
316389d6adfb1398e30ca2ce5d586ea94d3f3110,"KAFKA-3611: Remove warnings when using reflections

ewencp granders Can you take a look? Thanks!

Author: Liquan Pei <liquanpei@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1259 from Ishiihara/fix-warning",2016-04-28 11:59:02,Liquan Pei,Not TDD
3a496f480d002a4512273477eda9d92731e600c3,"KAFKA-3617; Unit tests for SASL authenticator

Unit tests for SASL authenticator, tests for SASL/PLAIN and multiple mechanisms, authorization test for SASL/PLAIN

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #1273 from rajinisivaram/KAFKA-3617",2016-04-28 13:39:22,Rajini Sivaram,Not TDD
0ada3b1fc215bb8efdf5c7ae27eb52b29e0fbbdc,"KAFKA-3382: Add system test for ReplicationVerificationTool

Author: Ashish Singh <asingh@cloudera.com>

Reviewers: Geoff Anderson <geoff@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1160 from SinghAsDev/KAFKA-3382",2016-04-28 15:49:01,Ashish Singh,Mixed
68433dcfdc0ae078ee4e7d278c286a9b7c1b3e76,"KAFKA-3613: Consolidate TumblingWindows and HoppingWindows into TimeWindows

This PR includes the same code as https://github.com/apache/kafka/pull/1261 but is rebased on latest trunk.

Author: Michael G. Noll <michael@confluent.io>

Reviewers: Matthias J. Sax, Guozhang Wang

Closes #1277 from miguno/KAFKA-3613-v2",2016-04-29 07:44:03,Michael G. Noll,Mixed
4ab4e4af814fb791fe6e8c2bd3381da8ca80b0b5,"KAFKA-3598: Improve JavaDoc of public API

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Michael G. Noll, Guozhang Wang

Closes #1250 from mjsax/JavaDoc-publicAPI",2016-04-29 08:49:16,Matthias J. Sax,Not TDD
cea01af125a33b81f973a96501fe41ca9d698197,"KAFKA-2693: Ducktape tests for SASL/PLAIN and multiple mechanisms

Run a sanity test with SASL/PLAIN and a couple of replication tests with SASL/PLAIN and multiple mechanisms.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1282 from rajinisivaram/KAFKA-2693",2016-04-29 09:41:12,Rajini Sivaram,Not TDD
e50327331d7d4e2854297a377f6701d737599672,"KAFKA-3578: Allow cross origin HTTP requests on all HTTP methods

Author: Liquan Pei <liquanpei@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1288 from Ishiihara/kip-56",2016-04-29 10:52:42,Liquan Pei,Mixed
69d9a669d7bbfec1e33dd6177c5687ef7f9977df,"KAFKA-3618; Handle ApiVersionsRequest before SASL authentication

Server-side implementation and tests for handling ApiVersionsRequest before SaslHandshakeRequest.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Gwen Shapira, Ismael Juma

Closes #1286 from rajinisivaram/KAFKA-3618",2016-04-29 11:15:20,Rajini Sivaram,Mixed
3414d56121d8d2f66f8dd613453af71d5b3f0c5f,"KAFKA-3440: Update streams javadocs

- add class doc for KTable, KStream, JoinWindows
- add missing return tags

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Michael G. Noll <michael@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1287 from mjsax/kafka-3440-JavaDoc",2016-04-29 12:50:02,Matthias J. Sax,Not TDD
d0dedc6314bfd83d9b2b9a9557e3168e715981da,"KAFKA-3459: Returning zero task configurations from a connector does not properly clean up existing tasks

hachikuji ewencp Can you take a look when you have time?

Author: Liquan Pei <liquanpei@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1248 from Ishiihara/kafka-3459",2016-04-29 14:49:22,Liquan Pei,Mixed
60380e31d4bf6688d8d26ec44cf514a3c32731cb,"HOTFIX: Fix equality semantics of KeyValue

Fixes wrong KeyValue equals logic when keys not equal but values equal.

Original hotfix PR at https://github.com/apache/kafka/pull/1293 (/cc enothereska)

Please review: ewencp ijuma guozhangwang

Author: Eno Thereska <eno.thereska@gmail.com>
Author: Michael G. Noll <michael@confluent.io>

Reviewers: Michael G. Noll <michael@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1294 from miguno/KeyValue-equality-hotfix",2016-04-29 15:14:36,Eno Thereska,Mixed
94d1878a9b7aaf57c7520fb5bdcd2f05aeec5853,"MINOR: change initial value of Min stat to Double.MAX_VALUE (not MIN)

this is consistent with the Max stat implementation.

Author: Zack Dever <zdever@pandora.com>

Reviewers: Aditya Auradkar, Gwen Shapira

Closes #1143 from zackdever/min-stat-fix",2016-04-29 15:49:48,Zack Dever,Not TDD
9eaf529ffb168e44a461be24b666eee00fdaf497,"KAFKA-3644; Use Boolean protocol type for StopReplicaRequest delete_p…

…artitions

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Gwen Shapira

Closes #1296 from granthenke/stop-boolean",2016-04-29 17:27:02,Grant Henke,Not TDD
1f528815de8d0e094ee5446794ab7325629ca7ed,"KAFKA-3642: Fix NPE from ProcessorStateManager when the changelog topic not exists

Issue: https://issues.apache.org/jira/browse/KAFKA-3642

Author: Yuto Kawamura <kawamuray.dadada@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1289 from kawamuray/KAFKA-3642-streams-NPE",2016-05-03 10:47:23,Yuto Kawamura,Mixed
c7425be5be8d0c2786155fbc697d83f80827d084,"KAFKA-3128; Add metrics for ZooKeeper events zookeeper metrics

Also:
* Remove redundant `time.milliseconds` call in `Sensor.record`
* Clean-up a number of tests and remove a manual test that is no longer required

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Liquan Pei <liquanpei@gmail.com>, Jun Rao <junrao@gmail.com>

Closes #1265 from ijuma/kafka-3128-zookeeper-metrics",2016-05-03 10:55:54,Ismael Juma,Mixed
88e5d5a9a16f4831b8a178355d38d203febe85f9,"KAFKA-3448; Support zone index in IPv6 regex

When an address is written textually, the zone index is appended to the address, separated by a percent sign (%). The actual syntax of zone indices depends on the operating system.

Author: Som Sahu <sosahu@microsoft.com>
Author: Soumyajit Sahu <soumyajit-sahu@users.noreply.github.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #1305 from soumyajit-sahu/fixIPV6RegexPattern_trunk",2016-05-03 19:24:14,Som Sahu,Mixed
b3d2c0dabbcfc8e5d286e181450029adefc9fee8,"MINOR: Added more integration tests

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Ismael Juma, Michael G. Noll, Guozhang Wang

Closes #1285 from enothereska/more-integration-tests",2016-05-03 13:26:22,Eno Thereska,Not TDD
94e12a2e1fbd2f43821643d67a0d91f03b3f94e5,"KAFKA-3648; maxTimeToBlock in BufferPool.allocate should be enforced

 `maxTimeToBlock` needs to be updated in each loop iteration. Also record waitTime before throwing `TimeoutException`

Author: Chen Zhu <amandazhu19620701@gmail.com>

Reviewers: Dong Lin <lindong28@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1304 from zhuchen1018/KAFKA-3648",2016-05-03 23:59:12,Chen Zhu,Mixed
50aacd660d4c4212ffa4a9dca7d45bcfe50af833,"KAFKA-3654: Config validation should validate both common and connector specific configurations

Author: Liquan Pei <liquanpei@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1313 from Ishiihara/config-short-circuit",2016-05-03 18:05:04,Liquan Pei,Not TDD
03a1f7d39c553835022987826df4762cfd39a639,"MINOR: Handle null values in validators

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #1316 from ewencp/minor-handle-null-values-validators",2016-05-04 02:14:35,Ewen Cheslack-Postava,Mixed
7a0821d653c6c99a26ded6046ea24722c8d8ad85,"KAFKA-3632; remove fetcher metrics on shutdown and leader migration

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #1312 from hachikuji/KAFKA-3632",2016-05-04 20:10:41,Jason Gustafson,Mixed
c46cc480214080844ef0ca04d96f1db61b1f2ea3,"KAFKA-2236; Offset request reply racing with segment rolling

Author: William Thurston <wthurston@linkedin.com>
Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Ismael Juma, Guozhang Wang

Closes #1318 from ijuma/KAFKA-2236-offset-request-reply-segment-rolling-race",2016-05-04 14:26:30,William Thurston,Not TDD
c8c6ac3f6d2d590261acb35fabbf7418ae102d4e,"KAFKA-3639; Configure default serdes upon construction

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Michael G. Noll <michael@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #1311 from guozhangwang/K3639",2016-05-05 00:23:34,Guozhang Wang,Mixed
64451af9e08de428064dc232cd6dea0ea0b2a81d,"KAFKA-3652; Return error response for unsupported version of ApiVersionsRequest

Handle unsupported version of ApiVersionsRequest during SASL auth as well as normal operation by returning an error response.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #1310 from rajinisivaram/KAFKA-3652",2016-05-04 18:16:08,Rajini Sivaram,Not TDD
ad316509787787afeed6e2a24a62fd22cadd09c7,"KAFKA-3527: Consumer commitAsync should not expose internal exceptions

Author: Liquan Pei <liquanpei@gmail.com>

Reviewers: Grant Henke <granthenke@gmail.com>, Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1300 from Ishiihara/kafka-3527",2016-05-04 19:20:54,Liquan Pei,Mixed
32bf83e5a792c5ee9eb88660da71b73aad5bbc02,"KAFKA-3659: Handle coordinator disconnects more gracefully in client

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1322 from hachikuji/KAFKA-3659",2016-05-05 12:03:28,Jason Gustafson,Mixed
b6cd0e2791e0e6a6ef02d069b3001ffb477f7c6c,"KAFKA-3581: add timeouts to joins in background thread services

This actually removes joins altogether, as well as references to self.worker_threads, which is best left as an implementation detail in BackgroundThreadService.

This makes use of hachikuji 's recent ducktape patch, and updates ducktape dependency to 0.5.0.

Author: Geoff Anderson <geoff@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1297 from granders/KAFKA-3581-systest-add-join-timeout",2016-05-05 13:12:11,Geoff Anderson,Mixed
8429db937e2134d9935d9dccd2ed0febc474fd66,"KAFKA-3661; fix NPE in o.a.k.c.c.RoundRobinAssignor when topic metadata not found

AbstractPartitionAssignor.assign has an ambiguous line in its documentation:
> param partitionsPerTopic The number of partitions for each subscribed topic (may be empty for some topics)

Does empty mean the topic has an entry with value zero, or that the entry is excluded from the map altogether? The current implementation in AbstractPartitionAssignor excludes the entry from partitionsPerTopic if the topic isn't in the metadata.

RoundRobinAssignorTest.testOneConsumerNonexistentTopic interprets emptiness as providing the topic with a zero value.
RangeAssignor interprets emptiness as excluding the entry from the map.
RangeAssignorTest.testOneConsumerNonexistentTopic interprets emptiness as providing the topic with a zero value.

This implementation chooses to solve the NPE by deciding to exclude topics from partitionsPerTopic when the topic is not in the metadata.

Author: Onur Karaman <okaraman@linkedin.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #1326 from onurkaraman/KAFKA-3661",2016-05-05 23:25:03,Onur Karaman,Mixed
6856c5c214fb0a40b18cfb25db3dadae320c4142,"KAFKA-3651; Remove the condition variable waiting on memory availability in Bufferpool when a TimeoutException is thrown

Whenever the BufferPool throws a ""Failed to allocate memory within the configured max blocking time"" exception, it should also remove the condition object from the waiters deque

Author: MayureshGharat <gharatmayuresh15@gmail.com>

Reviewers: Chen Zhu <amandazhu19620701@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1314 from MayureshGharat/kafka-3651",2016-05-05 23:31:46,Mayuresh Gharat,Mixed
4a076a03bee376853713f4b5784b66b18ad5535c,"HOTFIX: follow-up on KAFKA-725 to remove the check and return empty response instead of throw exceptions

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Stig Døssing, Ismael Juma, Jun Rao

Closes #1327 from guozhangwang/K725r",2016-05-05 16:55:23,Guozhang Wang,Mixed
2ff955044aa875176aaa58a9be4a79c494a3fb27,"KAFKA-3627: consumer fails to execute delayed tasks in poll when records are available

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Liquan Pei <liquanpei@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1295 from hachikuji/KAFKA-3627",2016-05-05 22:24:03,Jason Gustafson,Mixed
fec2d41bc2bed9f4effbd9922ca487bb02e5eeae,"KAFKA-3616: Make kafka producers/consumers injectable for KafkaStreams

Ticket: https://issues.apache.org/jira/browse/KAFKA-3616

Author: Yuto Kawamura <kawamuray.dadada@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1264 from kawamuray/kafka-3616-inject-clients",2016-05-06 08:49:44,Yuto Kawamura,Mixed
54092c12ed276b4bf91741e3c7fd315443f3c0b1,"KAFKA-3592: System test - configurable paths

This patch adds logic for the following:
- remove hard-coded paths to various scripts and jars in kafkatest service classes
- provide a mechanism for overriding path resolution logic with a ""pluggable"" path resolver class

Author: Geoff Anderson <geoff@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1245 from granders/configurable-install-path",2016-05-06 11:10:27,Geoff Anderson,Mixed
717eea8350feb670e8ba3dd3505c708a8a52de71,"KAFKA-3655; awaitFlushCompletion() in RecordAccumulator should always decrement flushesInProgress count

Author: Chen Zhu <amandazhu19620701@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #1315 from zhuchen1018/KAFKA-3655",2016-05-06 21:57:53,Chen Zhu,Mixed
c4bbf342432291220242ad4177fd72a959ddcb94,"KAFKA-3112; Warn instead of error on unresolvable bootstrap server

so that unresolvable DNS names are ignored and only throw an error if no other bootstrap servers are resolvable.

Author: Jonathan Bond <jbond@netflix.com>

Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #792 from bondj/KAFKA-3112",2016-05-07 09:05:55,Jonathan Bond,Mixed
8fe2552239863f3a01d01708d55edf3c7082ff92,"KAFKA-3160; Fix LZ4 Framing

This contribution is my original work and I license the work under Apache 2.0.

Author: Dana Powers <dana.powers@gmail.com>
Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1212 from dpkp/KAFKA-3160",2016-05-07 19:35:55,Dana Powers,Mixed
51f7a35c929d9aa04d821098a2266902f9178d7c,"KAFKA-3670; ControlledShutdownLeaderSelector should pick the preferred replica as the new leader, if possible

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #1338 from ijuma/kafka-3670-controlled-shutdown-leader-selector-preferred-replica",2016-05-08 10:45:47,Ismael Juma,Not TDD
62b9fa22545a8e254b4ffd07ddc5bd3315542548,"KAFKA-3579; Reference both old and new consumer properties in `TopicCommand`

Add references to the new consumer property 'max.partition.fetch.bytes' along with the old consumer property 'fetch.message.max.bytes' in the corresponding warning messages of TopicCommand.
Also, create and leverage a static variable for the default value of the new consumer property.
Also, use 'DEFAULT_...' for default propoerty constant names in the code instead of '..._DEFAULT'.

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Manikumar reddy O <manikumar.reddy@gmail.com>, Ashish Singh <asingh@cloudera.com>, Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1239 from vahidhashemian/KAFKA-3579",2016-05-08 22:27:58,Vahid Hashemian,Not TDD
d1bb2b9df105169c47f16d057c887acb7f8fe818,"KAFKA 3671: Move topics to SinkConnectorConfig

Author: Liquan Pei <liquanpei@gmail.com>

Reviewers: Dan Norwood <norwood@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1335 from Ishiihara/sink-connector-config",2016-05-08 22:26:26,Liquan Pei,Mixed
dbafc631ad78c96f85361a3d5e1c4d203cedb26f,"KAFKA-3673: Connect tests don't handle concurrent config changes

Author: Liquan Pei <liquanpei@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1340 from Ishiihara/connect-test-failure",2016-05-08 23:50:43,Liquan Pei,Not TDD
8911660e2e7d9553502974393ad1aa04852c2da2,"KAFKA-3674: Ensure connector target state changes propagated to worker

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1341 from hachikuji/KAFKA-3674",2016-05-09 00:12:30,Jason Gustafson,Mixed
2caf872c2e51d689c6ac20240c4a306e36d98b15,"KAFKA-3587; LogCleaner fails due to incorrect offset map computation

Removed the over pessimistic require and instead attempt to fill the dedup buffer. Use the (only) map until full;
this may allow to process all dirty segment (optimism) or may happen in the middle of a dirt segment.
In either case, do compaction using the map loaded that way.

This patch was developed with edoardocomar

Author: Mickael Maison <mickael.maison@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #1332 from mimaison/KAFKA-3587",2016-05-09 18:10:40,Mickael Maison,Mixed
4331bf4ff2d0e7ab1a24ea29382897162c1ed91c,"HOTFIX: KAFKA-3160 follow-up, catch decompression errors in constructor

After testing KAFKA-3160 a bit more, I found that the error code was not being set properly in ProduceResponse. This happened because the validation error is raised in the CompressionFactory constructor, which was not wrapped in a try / catch.

ijuma junrao

(This contribution is my original work and I license the work under Apache 2.0.)

Author: Dana Powers <dana.powers@gmail.com>
Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>, Gwen Shapira <cshapi@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1344 from dpkp/decompress_error_code",2016-05-09 18:40:54,Dana Powers,Not TDD
f96da638ee9a4e1e47ece1ea337ee071d911c3da,"KAFKA-3676: system tests for connector pause/resume

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1345 from hachikuji/KAFKA-3676",2016-05-09 16:56:32,Jason Gustafson,Not TDD
3e89d2bc59b1bf6c73b262a36019df01af7a958c,"KAFKA-3525; getSequenceId should return 1 for first data node creation

ZkUtils.getSequenceId() method is used to generate broker id sequence numbers. During startup, each broker updates the data at /brokers/seqid zk path and returns stat.getVersion as next sequence id.

stat.getVersion returns ""1"" for first data update. So ZkUtils.getSequenceId() should return ""1"" on first data update.

Author: Manikumar reddy O <manikumar.reddy@gmail.com>

Reviewers: Flavio Junqueira <fpj@apache.org>, Ismael Juma <ismael@juma.me.uk>

Closes #1224 from omkreddy/KAFKA-3525",2016-05-11 01:52:43,Manikumar reddy O,Not TDD
bd8681cdd51d2878ea917941abe335f68a373716,"KAFKA-3690: Avoid to pass null to UnmodifiableMap

Author: Liquan Pei <liquanpei@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1360 from Ishiihara/avoid-to-pass-null",2016-05-11 13:06:20,Liquan Pei,Mixed
b28bc57a1fdb9b56c89c3cb9c3df60afbeda521c,"MINOR: Improve handling of channel close exception

Propagate IOException in SslTransportLayer channel.close to be consistent with PlaintextTransportLayer,  close authenticator on channel close even if transport layer close fails.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #1370 from rajinisivaram/minor-channelclose2",2016-05-11 21:11:17,Rajini Sivaram,Mixed
f892f0ca6d38cb21a93c2c05dd8b9a23c4165181,"KAFKA-3694; Ensure broker Zk deregistration prior to restart in ReplicationTest

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Geoff Anderson <geoff@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #1365 from hachikuji/KAFKA-3694",2016-05-11 23:48:46,Jason Gustafson,Not TDD
5aedde5b29cc5a1adea4c65d5c44fb657f162eab,"MINOR: Change type of StreamsConfig.BOOTSTRAP_SERVERS_CONFIG to List

This is an improved version of https://github.com/apache/kafka/pull/1374, where we include a unit test.

/cc ijuma and guozhangwang

Author: Guozhang Wang <wangguoz@gmail.com>
Author: Michael G. Noll <michael@confluent.io>

Reviewers: Michael G. Noll <michael@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #1377 from miguno/streamsconfig-multiple-bootstrap-servers",2016-05-12 11:12:17,Guozhang Wang,Mixed
81f76bde8565eaffd67e5adaa69ddfdb4f5cebaa,"KAFKA-3520: Add system tests for REST APIs of list connector plugins and config validation

ewen granders Ready for review.

Author: Liquan Pei <liquanpei@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1195 from Ishiihara/system-test",2016-05-12 18:19:00,Liquan Pei,Mixed
f34164eed53d791768f05df21f4dfeca89859b2e,"MINOR: Fix bugs in KafkaStreams.close()

Initially proposed by ijuma in https://github.com/apache/kafka/pull/1362#issuecomment-218293662

mjsax commented:

> StreamThread.close() should be extended to call metrics.close() (the class need a private member to reference the Metrics object, too)

The `Metrics` instance is created in the `KafkaStreams` constructor and shared between all threads, so closing it within the threads doesn't seem like the right approach. This PR calls `Metrics.close()` in `KafkaStreams.close()` instead.

cc guozhangwang

Author: Jeff Klukas <jeff@klukas.net>

Reviewers: Ismael Juma, Guozhang Wang

Closes #1379 from jklukas/close-streams-metrics",2016-05-12 21:14:51,Jeff Klukas,Mixed
1c4b943f2d9cc90101026519769f142c07bc1785,"KAFKA-3584; Fix synchronization issue between deleteOldSegments() and delete() methods

This PR is to fix synchronization issue between deleteOldSegments() and delete() method calls. log.deleteOldSegments() call throws NullPointerException after log.delete() method call.

cc ijuma junrao

Author: Manikumar reddy O <manikumar.reddy@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1367 from omkreddy/KAFKA-3584",2016-05-13 12:57:09,Manikumar reddy O,Mixed
6a5d3e65c6ba9faa0f6cf4ec2871a83beb28c6c4,"KAFKA-3258; Delete broker topic metrics of deleted topics

Delete per-topic metrics when there are no replicas of any partitions of the topic on a broker.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Joel Koshy <jjkoshy.w@gmail.com>, Manikumar reddy O <manikumar.reddy@gmail.com>, Ashish Singh <asingh@cloudera.com, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #944 from rajinisivaram/KAFKA-3258",2016-05-16 14:37:09,Rajini Sivaram,Not TDD
177b2d0bea76f270ec087ebe73431307c1aef5a1,"KAFKA-3735: Dispose all RocksObejcts upon completeness

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Roger Hoover, Eno Thereska, Ismael Juma

Closes #1411 from guozhangwang/K3735-dispose-rocksobject",2016-05-20 11:52:36,Guozhang Wang,Not TDD
fe27d8f787f38428e0add36edeac9d694f16af53,"KAFKA-3747; Close `RecordBatch.records` when append to batch fails

With this change, `test_producer_throughput` with message_size=10000, compression_type=snappy and a snappy buffer size of 32k can be executed in a heap of 192m in a local environment (768m is needed without this change).

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1418 from ijuma/kafka-3747-close-record-batch-when-append-fails",2016-05-24 09:13:40,Ismael Juma,Mixed
5653249e08b1050f0e2081bf1dcc50324b3ec409,"KAFKA-3732: Add an auto accept option to kafka-acls.sh

Added a new argument to AclCommand: --yes. When set, automatically answer yes to prompts

Author: Mickael Maison <mickael.maison@gmail.com>

Reviewers: Gwen Shapira

Closes #1406 from mimaison/KAFKA-3732",2016-05-25 11:25:04,Mickael Maison,Mixed
62dc1afb69369c64207991ba59bcd203505d37ea,"KAFKA-3718; propagate all KafkaConfig __consumer_offsets configs to OffsetConfig instantiation

Kafka has two configurable compression codecs: the one used by the client (source codec) and the one finally used when storing into the log (target codec). The target codec defaults to KafkaConfig.compressionType and can be dynamically configured through zookeeper.

The GroupCoordinator appends group membership information into the __consumer_offsets topic by:
1. making a message with group membership information
2. making a MessageSet with the single message compressed with the source codec
3. doing a log.append on the MessageSet

Without this patch, KafkaConfig.offsetsTopicCompressionCodec doesn't get propagated to OffsetConfig instantiation, so GroupMetadataManager uses a source codec of NoCompressionCodec when making the MessageSet. Let's say we have enough group information such that the message formed exceeds KafkaConfig.messageMaxBytes before compression but would fall below the threshold after compression using our source codec. Even if we had dynamically configured __consumer_offsets with our favorite compression codec, the log.append will throw RecordTooLargeException during analyzeAndValidateMessageSet since the message was unexpectedly uncompressed instead of having been compressed with the source codec defined by KafkaConfig.offsetsTopicCompressionCodec.

Author: Onur Karaman <okaraman@linkedin.com>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #1394 from onurkaraman/KAFKA-3718",2016-05-26 09:17:31,Onur Karaman,Not TDD
be0f3502da1f703b27d7a3fae5a01325dff44957,"Setting broker state as running after publishing to ZK

junrao

Currently, the broker state is set to running before it registers itself in ZooKeeper.  This is too early in the broker lifecycle.  If clients use the broker state as an indicator that the broker is ready to accept requests, they will get errors.  This change is to delay setting the broker state to running until it's registered in ZK.

Author: Roger Hoover <roger.hoover@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #1426 from theduderog/broker-running-after-zk",2016-05-26 09:50:49,Roger Hoover,Not TDD
c699b1a914260b7d6fd84596f78128369d2bf2bf,"MINOR: Use `--force` instead of `--yes` in `AclCommand`

To be consistent with `ConfigCommand` and `TopicCommand`.

No release includes this option yet, so we can simply change it.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Mickael Maison, Grant Henke

Closes #1430 from ijuma/use-force-instead-of-yes-in-acl-command and squashes the following commits:

bdf3a57 [Ismael Juma] Update `AclCommandTest`
78b8467 [Ismael Juma] Change variable name to `forceOpt`
0bb27af [Ismael Juma] Use `--force` instead of `--yes` in `AclCommand`",2016-05-26 09:58:59,Ismael Juma,Mixed
3cf2de0694cf0e276d25d8c7048a9928b41969a3,"KAFKA-3723: Cannot change size of schema cache for JSON converter

Author: Christian Posta <christian.posta@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1401 from christian-posta/ceposta-connect-class-cast-error",2016-05-26 14:13:54,Christian Posta,Mixed
756ec494da75c49e6b537bd094b941c0492ec46e,"KAFKA-3682; ArrayIndexOutOfBoundsException thrown by

SkimpyOffsetMap.get() when full

Limited number of attempts to number of map slots after the internal
positionOf() goes into linear search mode.
Added unit test

Co-developed with mimaison

Author: edoardo <ecomar@uk.ibm.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #1352 from edoardocomar/KAFKA-3682",2016-05-27 15:39:07,edoardo,Mixed
0aff450961a8dd14cc7820ee8d1c9eea855439b0,"KAFKA-3158; ConsumerGroupCommand should tell whether group is actually dead

This patch fix differentiates between when a consumer group is rebalancing or dead and reports the appropriate error message.

Author: Ishita Mandhan <imandha@us.ibm.com>

Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #1429 from imandhan/KAFKA-3158",2016-05-28 23:30:10,Ishita Mandhan,Mixed
1029030466f01937d416e11f93562bcaaecce253,"MINOR: Fix setting of ACLs and ZK shutdown in test harnesses

I found both issues while investigating the issue described in PR #1425.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Sriharsha Chintalapani <schintalapani@hortonworks.com>, Jun Rao <junrao@gmail.com>

Closes #1455 from ijuma/fix-integration-test-harness-and-zk-test-harness",2016-06-03 01:19:46,Ismael Juma,Not TDD
234fa5a6949c9a5bfb4f543989c2ece84fcce033,"KAFKA-3784: TimeWindows#windowsFor calculation is incorrect

- Fixed the logic calculating the windows that are affected by a new …event in the case of hopping windows and a small overlap.
- Added a unit test that tests for the issue

Author: Tom Rybak <trybak@gmail.com>

Reviewers: Michael G. Noll, Matthias J. Sax, Guozhang Wang

Closes #1462 from trybak/bugfix/KAFKA-3784-TimeWindows#windowsFor-false-positives",2016-06-03 13:21:40,Tom Rybak,Mixed
ab356060665b3b6502c7d531366b26e1e0f48f9c,"KAFKA-3768; Replace all pattern match on boolean value by if/else block.

Author: Satendra kumar <satendra@knoldus.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #1445 from satendrakumar06/remove_boolean_pattern_match",2016-06-04 21:24:45,Satendra kumar,Not TDD
f4a263b5a89e028ad3b658dca2259b6da0197214,"KAFKA-3787; Preserve the message timestamp in mirror maker

The timestamp of messages consumed by mirror maker is not preserved after sending to target cluster. The correct behavior is to keep create timestamp the same in both source and target clusters.

Author: Tao Xiao <xiaotao183@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1466 from xiaotao183/KAFKA-3787",2016-06-05 08:42:42,Tao Xiao,Mixed
79aaf19f24bb48f90404a3e3896d115107991f4c,"KAFKA-3771; Improving Kafka core code

- Used flatMap instead of map and flatten
- Use isEmpty, NonEmpty, isDefined as appropriate
- Used head, keys and keySet where appropriate
- Used contains, diff and find where appropriate
- Removed redundant val modifier for case class constructor
- toString has no parameters, no side effect hence without () consistent usage
- Removed unnecessary return , parentheses and semi colons.

Author: Joshi <rekhajoshm@gmail.com>
Author: Rekha Joshi <rekhajoshm@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #1451 from rekhajoshm/KAFKA-3771",2016-06-06 08:08:47,Rekha Joshi,Mixed
0cee0c321897b4fca4409651fdf28188870cb2f0,"KAFKA-2948; Remove unused topics from producer metadata set

If no messages are sent to a topic during the last refresh interval or if UNKNOWN_TOPIC_OR_PARTITION error is received, remove the topic from the metadata list. Topics are added to the list on the next attempt to send a message to the topic.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>
Author: rsivaram <rsivaram@uk.ibm.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #645 from rajinisivaram/KAFKA-2948",2016-06-06 19:55:50,Rajini Sivaram,Mixed
f643d1b75d17bb27a378c7e66fcc49607454e445,"KAFKA-3783; Catch proper exception on path delete

- ZkClient is used for conditional path deletion and wraps `KeeperException.BadVersionException` into `ZkBadVersionException`
- add unit test to `SimpleAclAuthorizerTest` to reproduce the issue and catch potential future regression

Author: Sebastien Launay <sebastien@opendns.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #1461 from slaunay/bugfix/KAFKA-3783-zk-conditional-delete-path",2016-06-07 01:22:58,Sebastien Launay,Mixed
feab5a374a33a7b7b8e96c6a88b872c4db33dcf1,"KAFKA-3781; Errors.exceptionName() can throw NPE

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Grant Henke <granthenke@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1476 from ijuma/kafka-3781-exception-name-npe",2016-06-06 20:28:31,Ismael Juma,Mixed
d9f052acc396871801edee13ef0a6042a9af6626,"KAFKA-3501: Console consumer process hangs on exit

- replace `System.exit(1)` with a regular `return` in order to release the latch blocking the shutdown hook thread from shutting down the JVM
- provide `PrintStream` to the `process` method in order to ease unit testing

Author: Sebastien Launay <sebastien@opendns.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1185 from slaunay/bugfix/KAFKA-3501-console-consumer-hangs",2016-06-06 21:34:33,Sebastien Launay,Mixed
eb6f04a8b12194b9e13e2a28d8ffdfa971516d68,"KAFKA-3711: Ensure a RecordingMap is passed to configured instances

See https://issues.apache.org/jira/browse/KAFKA-3711

I've tested locally that this change does indeed resolve the warning I mention in the ticket:
```
org.apache.kafka.clients.consumer.ConsumerConfig: The configuration metric.dropwizard.registry = kafka-metrics was supplied but isn't a known config.
```
where `metric.dropwizard.registry` is a configuration value defined in a custom `MetricReporter` (https://github.com/SimpleFinance/kafka-dropwizard-reporter).

With this change, the above warning no longer appears, as ewencp predicted.

This contribution is my original work and I license the work to the project under the project's open source license.

Author: Jeff Klukas <jeff@klukas.net>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1479 from jklukas/abstractconfig-originals",2016-06-08 09:33:45,Jeff Klukas,Mixed
da8517182d2f30c4e03b33b38d41d2fa33621e24,"KAFKA-3817: handle null keys in KTableRepartitionMap

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Jeff Klukas <jeff@klukas.net>

Closes #1488 from guozhangwang/K3817-handle-null-groupedkey",2016-06-10 13:14:05,Guozhang Wang,Not TDD
b8ea094b427768bb360d87fc0a07f670cb667e1e,"KAFKA-3786: Let ConfigDef filter property key value pairs

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #1465 from guozhangwang/K3786-config-parsing",2016-06-13 14:15:28,Guozhang Wang,Mixed
9ff54cb5dd99fab83533ddfdf0ed89508e5525fb,"MINOR: Catch Throwable in commitSourceTask()

Author: Liquan Pei <liquanpei@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1402 from Ishiihara/source-task-commit-record",2016-06-14 13:21:30,Liquan Pei,Mixed
17668e81c95d89f6543657351abc0a18004ecde5,"MINOR: Expose window store sequence number

guozhangwang mjsax enothereska

Currently, Kafka Streams does not have a util to get access to the sequence number added to the key of windows state store changelogs.  I'm interested in exposing it so the the contents of a changelog topic can be 1) inspected for debugging purposes and 2) saved to text file and loaded from text file

Author: Roger Hoover <roger.hoover@gmail.com>

Reviewers: Eno Thereska <eno.thereska@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1501 from theduderog/expose-seq-num",2016-06-15 12:09:03,Roger Hoover,Mixed
1ef7b494bbd937205ecd14dd30e625c2efdb3aa9,"KAFKA-3753: Add approximateNumEntries() method to KeyValueStore interface

See https://issues.apache.org/jira/browse/KAFKA-3753

This contribution is my original work and I license the work to the project under the project's open source license.

cc guozhangwang kichristensen ijuma

Author: Jeff Klukas <jeff@klukas.net>

Reviewers: Ismael Juma, Guozhang Wang

Closes #1486 from jklukas/kvstore-size",2016-06-15 17:08:33,Jeff Klukas,Not TDD
fb42558e2500835722a4e5028896ddae4f407d6f,"KAFKA-3443: support for adding sources to KafkaStreams via Pattern.

This PR is the follow on to the closed PR #1410.

Author: bbejeck <bbejeck@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1477 from bbejeck/KAFKA-3443_streams_support_for_regex_sources",2016-06-15 19:20:43,bbejeck,Mixed
8c551675adb11947e9f27b20a9195c9c4a20b432,"KAFKA-2720: expire group metadata when all offsets have expired

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Liquan Pei, Onur Karaman, Guozhang Wang

Closes #1427 from hachikuji/KAFKA-2720",2016-06-15 19:46:42,Jason Gustafson,Mixed
54ba2280f0c42b0bd3d74c197f97d8a12617a847,"KAFKA-3840; Allow clients default OS buffer sizes

Follow up on KAFKA-724 (#1469) to allow OS socket buffer sizes auto tuning for both the broker and the clients.

Author: Sebastien Launay <sebastien@opendns.com>

Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1507 from slaunay/enhancement/os-socket-buffer-size-tuning-for-clients",2016-06-16 14:34:58,Sebastien Launay,Not TDD
7d9d1cb2355e33270703280ed6bb712033b03d26,"KAFKA-3561: Auto create through topic for KStream aggregation and join

guozhangwang enothereska mjsax miguno

If you get a chance can you please take a look at this. I've done the repartitioning in the join, but it results in 2 internal topics for each join. This seems like overkill as sometimes we wouldn't need to repartition at all, others just 1 topic, and then sometimes both, but I'm not sure how we can know that.

I'd also need to implement something similar for leftJoin, but again, i'd like to see if i'm heading down the right path or if anyone has any other bright ideas.

For reference - https://github.com/apache/kafka/pull/1453 - the previous PR

Thanks for taking the time and looking forward to getting some welcome advice :-)

Author: Damian Guy <damian.guy@gmail.com>
Author: Damian Guy <damian@continuum.local>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1472 from dguy/KAFKA-3561",2016-06-16 11:56:32,Damian Guy,Mixed
751fe9309011b99f60c1cb03c23a47d0444dce05,"KAFKA-3805: Check if DB is null.

- Check if DB is null before flushing or closing. In some cases, a state store is closed twice. This happens in `StreamTask.close()` where both `node.close()` and `super.close` (in `ProcessorManager`) are called in a sequence. If the user's processor defines a `close` that closes the underlying state store, then the second close will be redundant.

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Andrés Gómez, Ismael Juma, Guozhang Wang

Closes #1485 from enothereska/KAFKA-3805-locks",2016-06-16 16:18:02,Eno Thereska,Not TDD
2c9796114d0a9638be79b4165d0096c7a63babe7,"KAFKA-3850: WorkerSinkTask commit prior to rebalance should be retried on wakeup

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Liquan Pei <liquanpei@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1511 from hachikuji/retry-commit-on-wakeup-in-sinks",2016-06-19 15:31:04,Jason Gustafson,Mixed
4544ee448703b8c1900adcb7a605380eb99a00a2,"KAFKA-3864: make field.get return field's default value when needed

And not the containing struct's default value.

The contribution is my original work and that I license the work to the project under the project's open source license.

ewencp

Author: Rollulus <roelboel@xs4all.nl>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1528 from rollulus/kafka-3864",2016-06-20 12:30:27,Rollulus,Mixed
9716768810635b75b7668730962c399048ca883e,"KAFKA-3176: Add partition/offset options to the new consumer

With this pull request the new console consumer can be provided with optional --partition and --offset arguments so only messages from a particular partition and starting from a particular offset are consumed.

The following rules are also implemented to avoid invalid combinations of arguments:
- If --partition or --offset is provided --new-consumer has to be provided too.
- If --partition is provided --topic has to be provided too.
- If --offset is provided --partition has to be provided too.
- --offset and --from-beginning cannot be used at the same time.

This patch is co-authored with rajinisivaram.

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #922 from vahidhashemian/KAFKA-3176",2016-06-20 22:28:27,Vahid Hashemian,Mixed
36cab7dbdff6981d0df4b355dadee3fac35508a6,"KAFKA-3863: System tests covering connector/task failure and restart

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1519 from hachikuji/KAFKA-3863",2016-06-22 17:06:49,Jason Gustafson,Not TDD
8ec4e4b7a37164a1189a74815decb1d6f6410963,"Kafka-3880: Disallow Join Window with size zero

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Michael G. Noll, Damian Guy, Eno Thereska, Guozhang Wang

Closes #1529 from mjsax/kafka-3880-join-windows",2016-06-23 14:16:42,Matthias J. Sax,Mixed
7e9f5a7ee6dfe22107c8cc3c9f57daa288d6c392,"HOTFIX: Check JoinWindow boundaries

guozhangwang

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1575 from mjsax/hotfix2",2016-06-30 10:50:51,Matthias J. Sax,Mixed
7d6b416f9e75f1d9f886b9b43637c488667222e1,"KAFKA-3740: Part I: expose StreamConfig properties in ProcessorContext

This is the part I of the work to add the StreamsConfig to ProcessorContext.

We need to access StreamsConfig in the ProcessorContext so other components (e.g. RocksDBWindowStore or LRUCache can retrieve config parameter from application)

Author: Henry Cai <hcai@pinterest.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1553 from HenryCaiHaiying/config",2016-06-30 11:10:16,Henry Cai,Not TDD
44ad7b574e376f958cf1d3893156d666f904cdd3,"KAFKA-3846: KIP-65: include timestamp in Connect record types

https://cwiki.apache.org/confluence/display/KAFKA/KIP-65%3A+Expose+timestamps+to+Connect

Author: Shikhar Bhushan <shikhar@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1537 from shikhar/kafka-3846",2016-06-30 13:59:31,Shikhar Bhushan,Mixed
7edaa3dd89d1a7300a12e101e23f66459a9cc33d,"MINOR: bug fixes to ducktape services

Here's a (mostly successful) run with these changes:

http://testing.confluent.io/confluent-kafka-branch-builder-system-test-results/?prefix=2016-06-27--001.1467080884--alexlod--ducktape-fixes--ad85493/

At least one of the failed tests is failing in trunk, too:

http://testing.confluent.io/confluent-kafka-branch-builder-system-test-results/?prefix=2016-06-28--001.1467090978--alexlod--ducktape-fixes--ad85493/

The contribution is my original work and I license the work to the project under the project's open source license.

Author: Alex Loddengaard <alexloddengaard@gmail.com>

Reviewers: Geoff Anderson <geoff@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1566 from alexlod/ducktape-fixes",2016-06-30 21:16:13,Alex Loddengaard,Not TDD
2098529b44cad78731e478aa8af2b49e9c94db7d,"KAFKA-3902: Optimize KTable.filter in Streams DSL to avoid forwarding if both old and new values are null

The contribution is my original work and that I license the work to the project under the project's open source license.

Contributors: Guozhang Wang, Phil Derome
guozhangwang

Added checkEmpty to validate processor does nothing  and added a inhibit check for filter to fix issue.

Author: Philippe Derome <phderome@gmail.com>
Author: Phil Derome <phderome@gmail.com>
Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1556 from phderome/DEROME-3902",2016-07-01 16:47:10,Philippe Derome,Mixed
d7de59a579af5ba4ecb1aec8fed84054f8b86443,"KAFKA-3854: Fix issues with new consumer's subsequent regex (pattern) subscriptions

This patch fixes two issues:
1. Subsequent regex subscriptions fail with the new consumer.
2. Subsequent regex subscriptions would not immediately refresh metadata to change the subscription of the new consumer and trigger a rebalance.

The final note on the JIRA stating that a later created topic that matches a consumer's subscription pattern would not be assigned to the consumer upon creation seems to be as designed. A repeat
`subscribe()` to the same pattern or some wait time until the next automatic metadata refresh would handle that case.

An integration test was also added to verify these issues are fixed with this PR.

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1572 from vahidhashemian/KAFKA-3854",2016-07-04 14:09:30,Vahid Hashemian,Not TDD
15e008783cf73dcaed851fe6cc587767031886e5,"KAFKA-3802; log mtimes reset on broker restart / shutdown

There seems to be a bug in the JDK that on some versions the mtime of
the file is modified on FileChannel.truncate() even if the javadoc states
`If the given size is greater than or equal to the file's current size then
 the file is not modified.`.

This causes problems with log retention, as all the files then look like
they contain recent data to Kafka. Therefore this is only done if the channel size is different to the target size.

Author: Moritz Siuts <m.siuts@emetriq.com>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1497 from msiuts/KAFKA-3802-log_mtimes_reset_on_broker_shutdown",2016-07-06 14:33:07,Moritz Siuts,Mixed
b64302f9cea0e3e95d740cbe7bbd4c64e147301c,"KAFKA-3794: added stream / table names as prefix to print / writeAsText

…int to the console.

Author: bbejeck <bbejeck@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #1577 from bbejeck/KAFKA-3794-add-prefix-to-print-functions",2016-07-06 10:46:36,Bill Bejeck,Not TDD
730bf9a37a08b2ca41dcda52d2c70e92e85980f7,"KAFKA-3887: KAFKA-3817 follow-up to avoid forwarding value if it is null in KTableRepartition

Also handle Null value in SmokeTestUtil.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>

Closes #1597 from guozhangwang/KHotfix-check-null",2016-07-08 08:36:20,Guozhang Wang,Not TDD
542350d616e4638958d133d1d5599acf8546ed06,"KAFKA-3920: Add Schema source connector to Kafka Connect

Author: Liquan Pei <liquanpei@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1574 from Ishiihara/schema-source",2016-07-08 10:56:58,Liquan Pei,Not TDD
a5da2a4f4c3b9d1917cbafc0e79d8e8318f7cbff,"MINOR: Typo fix in comments

Author: Nafer Sanabria <nafr.snabr@gmail.com>

Reviewers: Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1595 from naferx/minor-typo",2016-07-09 02:09:14,Nafer Sanabria,Not TDD
c439268224e3178002bfa28bc048722870f992e3,"KAFKA-3562; Handle topic deletion during a send

Fix timing window in producer by holding onto cluster object while processing send requests so that changes to cluster during metadata refresh don't cause NPE if a topic is deleted.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #1478 from rajinisivaram/KAFKA-3562",2016-07-11 17:06:59,Rajini Sivaram,Mixed
136a8fabca8e266f67897cf5471b2e41c0a341be,"KAFKA-3887 Follow-up: add unit test for null checking in KTable aggregates

Also made a pass over the streams unit tests, with the following changes:

1. Removed three integration tests as they are already covered by other integration tests.
2. Merged `KGroupedTableImplTest` into `KTableAggregateTest`.
3. Use mocks whenever possible to reduce code duplicates.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1604 from guozhangwang/Kminor-unit-tests-consolidation",2016-07-11 13:57:02,Guozhang Wang,Not TDD
fc47b9fa6b89a612cd0f79dfc689ee3813fd405a,"KAFKA-2945; CreateTopic - protocol and server side implementation

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #1489 from granthenke/create-wire-new",2016-07-12 08:21:19,Grant Henke,Mixed
f17790cd9952aecef67fbec58122c55c72e5c2b2,"KAFKA-3941: Delay eviction listener in InMemoryKeyValueLoggedStore after restoration

Also move the initialization that restores from changelog to inner stores.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Eno Thereska, Dan Norwood

Closes #1610 from guozhangwang/K3941-avoid-eviction-listener",2016-07-13 18:11:25,Guozhang Wang,Not TDD
9f94a7752a590c36186a7eb1eee16e992ec68c97,"KAFKA-3905: Handling null/empty topics and collections, patterns when subscription with list of topics or with patterns, and with assignments.

- Added validity checks for input parameters on subscribe, assign to avoid NPE, and provide an argument exception instead
- Updated behavior for subscription with null collection to be same as when subscription with emptyList.i.e., unsubscribes.
- Added tests on subscription, assign

Author: Rekha Joshi <rekhajoshm@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #1601 from rekhajoshm/KAFKA-3905-1",2016-07-14 10:44:58,Rekha Joshi,Mixed
fbc5185543fd4895c7c81ff55b3c8b4c25ac7600,"KAFKA-3870: Expose state store names in DSL

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Damian Guy, Matthias J. Sax, Michael G. Noll, Guozhang Wang

Closes #1526 from enothereska/expose-names-dsl",2016-07-18 12:12:51,Eno Thereska,Mixed
61c568d8391de6fceb6c8d6a33d349def8d2ada8,"MINOR: Added simple streams benchmark to system tests

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Geoff Anderson, Guozhang Wang, Ismael Juma

Closes #1621 from enothereska/simple-benchmark-streams-system-tests",2016-07-18 12:16:58,Eno Thereska,Not TDD
f1dd0d272313deceaf7021e54c09a63043acf4af,"KAFKA-3912: Query local state stores

guozhangwang enothereska please review

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska, Matthias J. Sax, Michael G. Noll, Guozhang Wang

Closes #1565 from dguy/kafka-3912",2016-07-19 14:02:21,Damian Guy,Mixed
14934157df7aaf5e9c37a302ef9fd9317b95efa4,"KAFKA-3812: fix state store directory locking in Kafka Streams

Move all state directory creation/locking/unlocking/cleaning to a single class. Don't release the channel until the lock is released. Refactor code to make use of new class

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska, Ismael Juma, Guozhang Wang

Closes #1628 from dguy/kafka-3812",2016-07-19 16:00:48,Damian Guy,Mixed
9cad9dbdac273e8fe893b0cbe4f0f22d4271fb7b,"MINOR: Remove unused parameter in `checkIfPartitionReassignmentSucceeded` and clean-ups

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Gwen Shapira

Closes #1635 from ijuma/remove-unused-parameter-in-check-if-partition-reassignment-succeeded and squashes the following commits:

f9ed930 [Ismael Juma] Code style improvements in `ReassignPartitionsCommand`
66c7541 [Ismael Juma] Fix comment in `KafkaController.onPartitionReassignment`
85288f3 [Ismael Juma] Remove unused parameter from `checkIfPartitionReassignmentSucceeded`",2016-07-19 19:04:24,Ismael Juma,Not TDD
0d19f58850282d16c14fd4abd04663eae817d012,"KAFKA-3915; Don't convert messages from v0 to v1 during log compaction

The conversion is unsafe as the converted message size may be greater
than the message size limit. Updated `LogCleanerIntegrationTest` to test the max message size case for both V0 and the current version.

Also include a few minor clean-ups:
* Remove unused code branch in `LogCleaner.compressMessages`
* Avoid unintentional usage of `scala.collection.immutable.Stream` (`toSeq` on an `Iterator`)
* Add explicit result type in `FileMessageSet.iterator`

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Ewen Cheslack-Postava, Guozhang Wang

Closes #1643 from ijuma/kafka-3915-log-cleaner-io-buffers-message-conversion",2016-07-20 12:49:29,Ismael Juma,Not TDD
e5a0d139861b58589233e2bcd3a10e9fb032ddbc,"MINOR: MetadataCache brokerId is not set on first run with generated broker id

…broker id

This is because the id passed into the MetadataCache is the value from the config before the real broker id is generated.

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #1632 from granthenke/metadata-id",2016-07-21 00:49:24,Grant Henke,Not TDD
0e5700fb68671f3fb75bfdeceda40e84330aca69,"MINOR: Improve PartitionState logging and remove duplication of code

Currently, logs involving PartitionState are not very helpful.

```
	Broker 449 cached leader info org.apache.kafka.common.requests.UpdateMetadataRequest$PartitionState3285d64a for partition <topic>-<partition> in response to UpdateMetadata request sent by controller 356 epoch 138 with correlation id 0

	TRACE state.change.logger: Broker 449 received LeaderAndIsr request org.apache.kafka.common.requests.LeaderAndIsrRequest$PartitionState66d6a8eb correlation id 3 from controller 356 epoch 138 for partition [<topic>,<partition>]
```

Author: Ashish Singh <asingh@cloudera.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #1609 from SinghAsDev/partitionState",2016-07-21 01:00:33,Ashish Singh,Mixed
9991086671b0a74bc5fd5698ba81aaf9a2985404,"KAFKA-3740: Enable configuration of RocksDBStores

Add new config StreamsConfig.ROCKSDB_CONFIG_SETTER_CLASS_CONFIG to enable advanced
RocksDB users to override default RocksDB configuration

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Roger Hoover, Dan Norwood, Eno Thereska, Guozhang Wang

Closes #1640 from dguy/kafka-3740-listener",2016-07-21 11:04:08,Damian Guy,Not TDD
933a7506efb57add31a1e9dbd984c1230128b855,"KAFKA-3858: Add functions to print stream topologies

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Roger Hoover, Matthias J. Sax, Guozhang Wang

Closes #1619 from enothereska/KAFKA-3858-print-topology",2016-07-21 13:11:53,Eno Thereska,Mixed
1ccab26a325e6ee23396049a24a5b6eb4b7a1c8e,"KAFKA-3911: KTable source materialization

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Damian Guy, Guozhang Wang

Closes #1638 from enothereska/KAFKA-3911-ktable-materialization",2016-07-21 14:44:59,Eno Thereska,Mixed
932bb84c837807eeca3600007ae3030561fdcb37,"KAFKA-3960; Committed offset not set after first assign

Author: Alexey Romanchuk <al.romanchuk@2gis.ru>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #1629 from 13h3r/kafka-3960",2016-07-23 09:31:16,Alexey Romanchuk,Mixed
d1546960de0aa43989680a59c8f6b1ae7cb333e9,"KAFKA-3935; Fix test_restart_failed_task system test for SinkTasks

Fix the test by using a more liberal timeout and forcing more frequent SinkTask.put() calls. Also add some logging to aid future debugging.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #1663 from ewencp/kafka-3935-fix-restart-system-test",2016-07-26 03:02:02,Ewen Cheslack-Postava,Not TDD
801fee89d801e6d222c7b1b76a97847ecc9f10ff,"MINOR: cleanup apache license in python files

ijuma
As discussed in https://github.com/apache/kafka/pull/1645, this patch removes an extraneous line from several __init__.py files, and a few others as well

Author: Geoff Anderson <geoff@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #1659 from granders/minor-cleanup-init-files",2016-07-26 03:04:13,Geoff Anderson,Not TDD
4059f07216a07db0cdd88b46db40914069171838,"KAFKA-3500: Handle null keys and values in KafkaOffsetBackingStore.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Ismael Juma, Jason Gustafson, Gwen Shapira

Closes #1662 from ewencp/kafka-3500-kafka-offset-backing-store-null",2016-07-26 19:43:32,Ewen Cheslack-Postava,Mixed
64842f47f8ad21c942be2e2dd1edb56e3bc76cb8,"KAFKA-3996; ByteBufferMessageSet.writeTo() should be non-blocking

Also:
* Introduce a blocking variant to be used by `FileMessageSet.append`
* Add tests
* Minor clean-ups

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #1669 from ijuma/kafka-3996-byte-buffer-message-set-write-to-non-blocking",2016-07-27 07:51:40,Ismael Juma,Mixed
8deedcacb68ff8ebae802e086ff706ad7e5f38e9,"KAFKA-3185: Allow users to cleanup internal Kafka Streams data

- added Kafka Stream Application Reset Tool

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Guozhang Wang, Michael G. Noll

Closes #1636 from mjsax/kafka-3185",2016-07-27 14:11:40,Matthias J. Sax,Mixed
ff557f02ac628edbe220ea69888d39de834527d3,"KAFKA-3977; Defer fetch parsing for space efficiency and to ensure exceptions are raised to the user

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Ismael Juma <ismael@juma.me.uk>

Closes #1656 from hachikuji/KAFKA-3977",2016-07-28 11:18:25,Jason Gustafson,Mixed
131f96868aa24f38f69ee2ab769ea3f289e5c1fc,"MINOR: Consumer should throw KafkaException on invalid checksum

InvalidRecordException is not part of the public API so go back
to the behaviour before ff557f02 for now.

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #1676 from hachikuji/raise-kafka-exception-on-invalid-crc",2016-07-28 21:36:30,Jason Gustafson,Mixed
f7976d2fc1793d0f635b42eb4dca3810e40c4cc8,"KAFKA-4008: Module ""tools"" should not be dependent on ""core""

moved streams application reset tool from tools to core

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1685 from mjsax/moveResetTool

(cherry picked from commit f2405a73ea2dd4b636832b7f8729fb06a04de1d5)
Signed-off-by: Ewen Cheslack-Postava <me@ewencp.org>",2016-08-01 20:12:38,Matthias J. Sax,Not TDD
bb629f2243c4462db2a863793c190d734f11f3c6,"KAFKA-3929: Add prefix for underlying clients configs in StreamConfig

Add prefixes for consumer and producer configs to StreamsConfig, but be backward compatible.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska, Guozhang Wang

Closes #1649 from dguy/kafka-3929",2016-08-02 14:14:52,Damian Guy,Mixed
27fc11d1c9b1ec8c63a991cb8c481f95eddb850b,"MINOR: rename StateStoreProvider.getStores() -> StateStoreProvider.stores()

Rename StateStoreProvider.getStores(...) to StateStoreProvider.stores(...) as this is consistent with the naming of other 'getters' in the public API.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1699 from dguy/minor-method-rename",2016-08-03 15:24:36,Damian Guy,Mixed
6fb33afff976e467bfa8e0b29eb82770a2a3aaec,"KAFKA-3875; Transient test failure: kafka.api.SslProducerSendTest.testSendNonCompressedMessageWithCreateTime

1. The IllegalStateException is actually thrown from testCloseWithZeroTimeoutFromSenderThread() due to a bug. We call producer.close() in the callback. Once the first callback is called, producing records in the callback will hit the IllegalStateException. This only pollutes the output, but doesn't fail the test. I fixed this by only calling producer.send() in the first callback.
2. It's not clear which test throws TimeoutException and it's not reproducible locally. One thing is that the error message in TimeoutException is mis-leading since the timeout is not necessarily due to metadata. Improved this by making the error message in TimeoutException clearer.
3. It's not clear what actually failed testSendNonCompressedMessageWithCreateTime(). One thing I found is that since we set the linger time to MAX_LONG and are sending small messages, those produced messages won't be drained until we call producer.close(10000L, TimeUnit.MILLISECONDS). Normally, 10 secs should be enough for the records to be sent. My only hypothesis is that since SSL is more expensive, occasionally, 10 secs is still not enough. So, I bumped up the timeout from 10 secs to 20 secs.

Author: Jun Rao <junrao@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1703 from junrao/kafka-3875",2016-08-04 12:30:24,Jun Rao,Not TDD
3dafb81da788294d4c2e9811f49437608e5b9ce8,"KAFKA-3817: KTableRepartitionMap publish old Change first, for non-count aggregates

I affirm that the contribution is my original work and that I license the work to the project under the project's open source license.

This cleans up misbehaviour that was introduce while fixing KAFKA-3817. It is impossible for a non-count aggregate to be build, when the addition happens before the removal. IMHO making sure that these details are correct is very important.

This PR has local test errors. It somehow fails the ResetIntegrationTest. It doesn't quite appear to me why but it looks like this PR breaks it, especially because the error appears with the ordering of the events. Still I am unable to find where I could have broken it. Maybe not seems to fail on trunk aswell.

Author: jfilipiak <Jan.Filipiak@trivago.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1705 from Kaiserchen/KAFKA-3817-preserve-order-for-aggreagators",2016-08-05 10:03:22,Jan Filipiak,Not TDD
fb65ff40a8d89bc7ad9b079cf1f2a8b902abd182,"KAFKA-3954; Consumer should use internal topics information returned by the broker

It previously hardcoded it.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Grant Henke <granthenke@gmail.com>, Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1613 from ijuma/kafka-3954-consumer-internal-topics-from-broker",2016-08-08 20:33:59,Ismael Juma,Mixed
caa9bd0fcd2fab4758791408e2b145532153910e,"KAFKA-3936: Validate parameters as early as possible

Added non null checks to parameters supplied via the DSL and `TopologyBuilder`

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Edward Ribeiro <edward.ribeiro@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #1711 from dguy/kafka-3936",2016-08-09 11:31:04,Damian Guy,Mixed
68b5d014fa3bf2e18da253ded2bbcd4f5d4a9d8d,"KAFKA-3914: Global discovery of state stores

guozhangwang enothereska mjsax miguno  please take a look. A few things that need to be clarified

1. I've added StreamsConfig.USER_ENDPOINT_CONFIG, but should we have separate configs for host and port or is this one config ok?
2. `HostState` in the KIP has a byte[] field - not sure why and what it would be populated with
3. I've changed the API to return `List<KafkaStreamsInstance>` as opposed to `Map<HostInfo, Set<TaskMetadata>>` as i find this far more intuitive to work with.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax, Michael G. Noll, Eno Thereska, Guozhang Wang

Closes #1576 from dguy/kafka-3914v2",2016-08-10 14:25:23,Damian Guy,Mixed
208ecae23994812d2a707b776de6b95d9f591bb7,"KAFKA-3847: Use a separate producer per source task

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Jason Gustafson, Gwen Shapira

Closes #1727 from ewencp/kafka-3847-per-task-producers and squashes the following commits:

7d39724 [Ewen Cheslack-Postava] Add timeout for closing producers.
98ec7f6 [Ewen Cheslack-Postava] KAFKA-3847: Use a separate producer per source task",2016-08-12 14:06:37,Ewen Cheslack-Postava,Mixed
539633ba0eba452960a4d2a3bf07abd79020b329,"KAFKA-2946; DeleteTopic - protocol and server side implementation

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <me@ewencp.org>, Jun Rao <junrao@gmail.com>

Closes #1616 from granthenke/delete-wire-new",2016-08-12 14:26:46,Grant Henke,Mixed
be36b322749003581474e2c84a3ec9ba2aaec53c,"KAFKA-4034; Avoid unnecessary consumer coordinator lookup

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1720 from hachikuji/KAFKA-4034",2016-08-12 23:26:41,Jason Gustafson,Mixed
e49b3aee6b25b9b26275849c693d5dec41d6cf68,"KAFKA-4035; AclCommand should allow Describe operation on groups

Author: Manikumar Reddy O <manikumar.reddy@gmail.com>

Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Jun Rao <junrao@gmail.com>

Closes #1723 from omkreddy/KAFKA-4035",2016-08-14 10:00:08,Manikumar Reddy O,Mixed
ae237be1bbfd7d1b84a5095491a6131cd3cc9346,"KAFKA-3769: Create new sensors per-thread in KafkaStreams

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Michael G. Noll <michael@confluent.io>, Greg Fodor <gfodor@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1530 from guozhangwang/K3769-per-thread-metrics",2016-08-16 10:43:12,Guozhang Wang,Mixed
40b1dd3f495a59abef8a0cba5450526994c92c04,"KAFKA-3888: send consumer heartbeats from a background thread (KIP-62)

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>

Closes #1627 from hachikuji/KAFKA-3888",2016-08-17 11:50:04,Jason Gustafson,Mixed
59cfa84801c67de9729385a8f9b536721e0c37b9,"KAFKA-4037: Make Connect REST API retries aware of 409 CONFLICT errors

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #1733 from ewencp/rest-api-retries",2016-08-18 15:29:56,Ewen Cheslack-Postava,Not TDD
05ed54bf2b80691d413dbfa05065eb3afe33972f,"KAFKA-3845: KIP-75: Add per-connector converters

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Shikhar Bhushan, Gwen Shapira

Closes #1721 from ewencp/kafka-3845-per-connector-converters",2016-08-18 20:56:31,Ewen Cheslack-Postava,Mixed
79d3fd2bf0e5c89ff74a2988c403882ae8a9852e,"KAFKA-3163; Add time based index to Kafka.

This patch is for KIP-33.
https://cwiki.apache.org/confluence/display/KAFKA/KIP-33+-+Add+a+time+based+log+index

Author: Jiangjie Qin <becket.qin@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>, Liquan Pei <liquanpei@gmail.com>

Closes #1215 from becketqin/KAFKA-3163",2016-08-19 10:07:07,Jiangjie Qin,Mixed
104d2154b635c50efc80331ee2a4779cc3658414,"KAFKA-4050; Allow configuration of the PRNG used for SSL

Add an optional configuration for the SecureRandom PRNG implementation, with the default behavior being the same (use the default implementation in the JDK/JRE).

Author: Todd Palino <Todd Palino>

Reviewers: Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Joel Koshy <jjkoshy@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #1747 from toddpalino/trunk",2016-08-19 11:05:39,Todd Palino,Mixed
c5d26c4829583c95af7ca9e961a4d3954f8e09eb,"KAFKA-4016: Added join benchmarks

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Ismael Juma, Damian Guy, Guozhang Wang

Closes #1700 from enothereska/join-benchmarks",2016-08-19 15:23:30,Eno Thereska,Not TDD
317c4fdede41f2026b34f473af1ad69f8ee62a1d,"KAFKA-3949: Fix race condition when metadata update arrives during rebalance

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Vahid Hashemian, Guozhang Wang

Closes #1762 from hachikuji/KAFKA-3949",2016-08-19 21:59:55,Jason Gustafson,Mixed
6ed3e6b1cb8a73b1f5f78926ccb247a8953a554c,"KAFKA-3894; log cleaner can partially clean a segment

As discussed in https://issues.apache.org/jira/browse/KAFKA-3894, this PR makes the log cleaner do a ""partial"" clean on a segment, whereby it builds a partial offset map up to a particular offset in a segment. Once cleaning resumes again, we will continue from the next dirty offset, which can now be located in the middle of a segment.

Prior to this PR, segments with overly numerous keys could crash the log cleaner thread, as it was required that the log cleaner had to fit at least a single segment in the offset map.

Author: Tom Crayford <tcrayford@googlemail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #1725 from tcrayford/dont_crash_log_cleaner_thread_if_segment_overflows_buffer",2016-08-22 10:58:40,Tom Crayford,Mixed
05d00b5aca2e1e59ad685a3f051d2ab022f75acc,"KAFKA-4032; Uncaught exceptions when autocreating topics

handled by adding a catch all for any unhandled exception. Because the jira specifically mentions the InvalidReplicationFactor exception, a test was added for that specific case.

Author: Grant Henke <granthenke@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #1739 from granthenke/create-errors",2016-08-23 00:14:44,Grant Henke,Not TDD
a2bac70a6634e9a78734d23158fb7e45f290ea26,"MINOR: Refactor TopologyBuilder with ApplicationID Prefix

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1736 from guozhangwang/Kminor-topology-applicationID",2016-08-22 21:33:47,Guozhang Wang,Mixed
a1e0b2240dba0740135621d959441eefa6fd3124,"KAFKA-4073; MirrorMaker should handle messages without timestamp correctly

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #1773 from ijuma/kafka-4073-mirror-maker-timestamps",2016-08-22 21:49:40,Ismael Juma,Mixed
313aad423cb19618b8693af6f04b68138059c585,"KAFKA-3680; Enable Kafka clients to run in any classloader env

Configure default classes using class objects instead of class names, enable configurable lists of classes to be specified as class objects, add tests for different classloader configurations.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1421 from rajinisivaram/KAFKA-3680",2016-08-23 10:31:29,Rajini Sivaram,Mixed
cec2769e2281ac731e8cfd12b5d8e34e0ebe38cd,"KAFKA-2894: WorkerSinkTask should rewind offsets on rebalance

Author: Konstantine Karantasis <k.karantasis@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1771 from kkonstantine/KAFKA-2894-rewind-offsets-on-rebalance",2016-08-23 10:19:07,Konstantine Karantasis,Not TDD
36044fdc544f1b6b4829558691e0e7d280abce99,"KAFKA-4015; Change cleanup.policy config to accept a list of valid policies

Change cleanup.policy to accept a comma separated list of valid policies.
Updated LogCleaner.CleanerThread to also run deletion for any topics configured with compact,delete.
Ensure Log.deleteSegments only runs when delete is enabled.
Additional Integration and unit tests to cover new option

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #1742 from dguy/kafka-4015",2016-08-25 08:15:55,Damian Guy,Mixed
32feed25aefdda3a9f2b780d0709a3002777c9df,"MINOR: Move a few methods from the `ZKUtils` class to the companion object

They don't require access to `ZkClient`.

Also include a few obvious clean-ups in `ZKUtils`:
* Remove redundant rethrows and braces
* Use named arguments for booleans

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Gwen Shapira <cshapi@gmail.com>

Closes #1775 from ijuma/move-some-zk-utils-methods-to-companion-object",2016-08-26 00:41:23,Ismael Juma,Not TDD
71f7e7c3a29e8f7339430837065126256907bd2a,"KAFKA-4042: Contain connector & task start/stop failures within the Worker

Invoke the statusListener.onFailure() callback on start failures so that the statusBackingStore is updated. This involved a fix to the putSafe() functionality which prevented any update that was not preceded by a (non-safe) put() from completing, so here when a connector or task is transitioning directly to FAILED.

Worker start methods can still throw if the same connector name or task ID is already registered with the worker, as this condition should not happen.

Author: Shikhar Bhushan <shikhar@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1778 from shikhar/distherder-stayup-take4",2016-08-26 14:00:42,Shikhar Bhushan,Mixed
9aaeb33c16d4a319967560215e2ea72082367f92,"KAFKA-4098: NetworkClient should not intercept user metdata requests on disconnect

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1798 from hachikuji/KAFKA-4098",2016-08-29 13:13:08,Jason Gustafson,Mixed
b91eeac9438b8718c410045b0e9191296ebb536d,"KAFKA-4100: Ensure 'fields' and 'fieldsByName' are not null for Struct schemas

Author: Shikhar Bhushan <shikhar@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1800 from shikhar/kafka-4100",2016-08-29 19:08:52,Shikhar Bhushan,Mixed
2e731a9ee002298b4b90f97e9c876b330b005539,"KAFKA-3799: Enable SSL endpoint validation in system tests

Generate certificates with hostname in SubjectAlternativeName and enable hostname validation.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1483 from rajinisivaram/KAFKA-3799",2016-08-31 09:14:59,Rajini Sivaram,Mixed
8f3462552fa4d6a6d70a837c2ef7439bba512657,"KAFKA-4104: Queryable state metadata is sometimes invalid

If the thread or process is not the coordinator the Cluster instance in StreamPartitionAssignor will always be null. This builds an instance of the Cluster with the metadata associated with the Assignment

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1804 from dguy/kafka-4104",2016-09-01 21:21:42,Damian Guy,Mixed
af9fc503dea5058df890fbd79249abb7634e06bc,"KAFKA-4099; Fix the potential frequent log rolling

Author: Jiangjie Qin <becket.qin@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #1809 from becketqin/KAFKA-4099",2016-09-02 12:49:34,Jiangjie Qin,Mixed
a960faf5f48025548de71a84b16e0ccf2a1837ca,"KAFKA-4105: Queryable state tests

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Damian Guy, Guozhang Wang

Closes #1806 from enothereska/queryable-state-tests",2016-09-04 21:49:48,Eno Thereska,Not TDD
ed639e8263d9409a9836a55938174122d6ff3ffa,"KAFKA-4023: Add thread id and task id for logging prefix in Streams

Author: bbejeck <bbejeck@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1803 from bbejeck/KAFKA-4023_add_thread_id_prefix_for_logging",2016-09-06 11:38:53,Bill Bejeck,Mixed
de1b853c3ed326cf296a56538ca9570b0ecc0636,"MINOR: changes embedded broker time to MockTime

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy, Ismael Juma, Guozhang Wang

Closes #1808 from mjsax/mockTime",2016-09-06 15:35:12,Matthias J. Sax,Not TDD
d2acd676c3eb0c11d0042bc3b9ae314165c68443,"MINOR: More graceful handling of buffers that are too small in Record's `isValid` and `ensureValid`

Also add tests and make `Crc32.update` perform the same argument checks as
`java.util.zip.CRC32`.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Gwen Shapira

Closes #1672 from ijuma/record-is-valid-should-be-more-robust",2016-09-06 17:34:46,Ismael Juma,Not TDD
2586226a9a5300fea427ca001608ad86d393df1b,"KAFKA-4058: Failure in org.apache.kafka.streams.integration.ResetIntegrationTest.testReprocessingFromScratchAfterReset

 - use AdminTool to check for active consumer group

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1767 from mjsax/kafka-4058-trunk",2016-09-06 23:02:41,Matthias J. Sax,Not TDD
eba0ede878bd9c42431cc702bc58f56354c595a6,"KAFKA-4123: Queryable State returning null for key before all stores in instance have been initialized

Mark the store as open after the DB has been restored from the changelog.
Only add the store to the map in ProcessorStateManager post restore.
Make RocksDBWindowStore.Segment override openDB(..) as it needs to mark the Segment as open.
Throw InvalidStateStoreException if any stores in a KafkaStreams instance are not available.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska, Guozhang Wang

Closes #1824 from dguy/kafka-4123",2016-09-07 17:42:35,Damian Guy,Mixed
69ebf6f7be2fc0e471ebd5b7a166468017ff2651,"KAFKA-3595: window stores use compact,delete config for changelogs

changelogs of window stores now configure cleanup.policy=compact,delete with retention.ms set to window maintainMs + StreamsConfig.WINDOW_STORE_CHANGE_LOG_ADDITIONAL_RETENTION_MS_CONFIG
StoreChangeLogger produces messages with context.timestamp().

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska, Guozhang Wang

Closes #1792 from dguy/kafka-3595",2016-09-07 18:02:24,Damian Guy,Mixed
6cf2cb6f294d0d4766f57e9da660fb4efac7d258,"KAFKA-4139; Reset findCoordinatorFuture when brokers are unavailable

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma, Jason Gustafson

Closes #1831 from rajinisivaram/KAFKA-4139",2016-09-08 09:42:22,Rajini Sivaram,Mixed
54767bbba5bf18c01f50bb40c339433bfed09627,"KAFKA-4033; Revise partition assignment semantics on consumer subscription changes (KIP-70)

This PR changes topic subscription semantics so a change in subscription does not immediately cause a rebalance.
Instead, the next poll or the next scheduled metadata refresh will update the assigned partitions.

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Jason Gustafson

Closes #1726 from vahidhashemian/KAFKA-4033",2016-09-08 19:56:53,Vahid Hashemian,Mixed
4af50bb8600c37ee2e3597fba9a54a29cef94afa,"KAFKA-3807; Fix transient test failure caused by race on future completion

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Dan Norwood <norwood@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #1821 from hachikuji/KAFKA-3807",2016-09-09 21:47:03,Jason Gustafson,Mixed
1933f12a5368f1f60816d986a2777fa324754f80,"KAFKA-4147; Fix transient failure in ConsumerCoordinatorTest.testAutoCommitDynamicAssignment

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #1841 from hachikuji/KAFKA-4147",2016-09-11 08:46:20,Jason Gustafson,Not TDD
5f040cd77f4b8fbe12b3e3389fab1fc2565dda82,"KAFKA-1981; Make log compaction point configurable

Now uses LogSegment.largestTimestamp to determine age of segment's messages.

Author: Eric Wasserman <eric.wasserman@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #1794 from ewasserman/feat-1981",2016-09-11 20:45:05,Eric Wasserman,Mixed
41e676d29587042994a72baa5000a8861a075c8c,"KAFKA-4158; Reset quota to default value if quota override is deleted

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Joel Koshy <jjkoshy.w@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>

Closes #1851 from lindong28/KAFKA-4158",2016-09-13 17:33:54,Dong Lin,Not TDD
084a19e9acb43666cfcaa2ca155a775d47cd8b39,"KAFKA-4172; Ensure fetch responses contain the requested partitions

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #1857 from hachikuji/KAFKA-4172",2016-09-14 18:04:58,Jason Gustafson,Not TDD
f197ad4997032a848540a7d577b5846f76a26bfb,"KAFKA-4160: Ensure rebalance listener not called with coordinator lock

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1855 from hachikuji/KAFKA-4160",2016-09-14 22:31:52,Jason Gustafson,Not TDD
d4366610241321a58d62c0b919d60ccfe3c3d698,"KAFKA-4131; Multiple Regex KStream-Consumers cause Null pointer exception

Fix for bug outlined in KAFKA-4131

Author: bbejeck <bbejeck@gmail.com>

Reviewers: Damian Guy, Guozhang Wang

Closes #1843 from bbejeck/KAFKA-4131_mulitple_regex_consumers_cause_npe",2016-09-15 17:08:00,Bill Bejeck,Not TDD
143a33bc506c703ea02fe5daa61f90b7094da13c,"KAFKA-1464; Add a throttling option to the Kafka replication

This applies to Replication Quotas
based on KIP-73 [(link)](https://cwiki.apache.org/confluence/display/KAFKA/KIP-73+Replication+Quotas) originally motivated by KAFKA-1464.

System Tests Run: https://jenkins.confluent.io/job/system-test-kafka-branch-builder/544/

**This first PR demonstrates the approach**.

**_Overview of Change_**
The guts of this change are relatively small. Throttling occurs on both leader and follower sides. A single class tracks the throttled throughput in and out of each broker (**_ReplicationQuotaManager_**).

On the follower side, the Follower Throttled Rate is calculated as fetch responses arrive. Then, before the next fetch request is sent, we check to see if the quota is violated, removing throttled partitions from the request if it is. This is all encapsulated in a few lines of code in the **_ReplicaFetcherThread_**. There is existing code to handle temporal back off, if the request ends up being empty.

On the leader side it's a little more complex. When a fetch request arrives in the leader, it is built, partition by partition, in **_ReplicaManager.readFromLocalLog_**. As we put each partition into the fetch response, we check if the total size fits in the current quota. If the quota is exceeded, the partition will not be added to the fetch response. Importantly, we don't increase the quota at this point, we just check to see if the bytes will fit.

Now, if there aren't enough bytes to send the response immediately, which is common if we're catching up and throttled, then the request will be put in purgatory. I've added some simple code to **_DelayedFetch_** to handle throttled partitions (throttled partitions are checked against the quota, rather than the messages available in the log).

When the delayed fetch completes, and exits purgatory, _**ReplicaManager.readFromLocalLog**_ will be called again. This is why _**ReplicaManager.readFromLocalLog**_ does not actually increase the quota, it just checks whether enough bytes are available for a partition.

Finally, when there are enough bytes to be sent, or the delayed fetch times out, the response will be sent. Before it is sent the throttled-outbound-rate is increased, based on the size of throttled partitions being sent. This is at the end of _**KafkaApis.handleFetchRequest**_, exactly where client quotas are recorded.

There is an acceptance test which asserts the whole throttling process stabilises on the desired value. This covers a number of use cases including many-to-many replication. See **_ReplicationQuotaTest_**.

Note:
It should be noted that this protocol can over-request. The request is built, based on the quota at time t1 (_ReplicaManager.readFromLocalLog_). The bytes in the response are recorded at time t2 (end of _KafkaApis.handleFetchRequest_), where t2 > t1. For this reason I originally included an OverRequestedRate as a JMX metric, but testing has not seen revealed any obvious issue. Over-requesting is quickly compensated by subsequent requests, stabilising close to the quota value.

_**Main stuff left to do:**_
- The fetch size is currently unbounded. This will be addressed in KIP-74, but we need to ensure this ensures requests don’t go beyond the throttle window.
- There are two failures showing up in the system tests on this branch:  StreamsSmokeTest.test_streams (which looks like it fails regularly) and OffsetValidationTest.test_broker_rolling_bounce (which I need to look into)

_**Stuff left to do that could be deferred:**_
- Add the extra metrics specified in the KIP.
- There are no system tests.
- There is no validation for the cluster size / throttle combination that could lead to ISR dropouts

Author: Ben Stopford <benstopford@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Apurva Mehta <apurva@confluent.io>, Jun Rao <junrao@gmail.com>

Closes #1776 from benstopford/rep-quotas-v2",2016-09-15 22:25:56,Ben Stopford,Mixed
86aa0eb0f274c6e44eb190ce250433419e011a67,"KAFKA-3776: Unify store and downstream caching in streams

This is joint work between dguy and enothereska. The work implements KIP-63. Overview of main changes:

- New byte-based cache that acts as a buffer for any persistent store and for forwarding changes downstream.
- Forwarding record path changes: previously a record in a task completed end-to-end. Now it may be buffered in a processor node while other records complete in the task.
- Cleanup and state stores and decoupling of cache from state store and forwarding.
- More than 80 new unit and integration tests.

Author: Damian Guy <damian.guy@gmail.com>
Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Matthias J. Sax, Guozhang Wang

Closes #1752 from enothereska/KAFKA-3776-poc",2016-09-16 09:58:36,Damian Guy,Mixed
567cc3d78746391a3b050d4eea76571e4bf20e89,"KAFKA-4183; Corrected Kafka Connect's JSON Converter to properly convert from null to logical values

The `JsonConverter` class has `LogicalTypeConverter` implementations for Date, Time, Timestamp, and Decimal, but these implementations fail when the input literal value (deserialized from the message) is null.

Test cases were added to check for these cases, and these failed before the `LogicalTypeConverter` implementations were fixed to consider whether the schema has a default value or is optional, similarly to how the `JsonToConnectTypeConverter` implementations do this. Once the fixes were made, the new tests pass.

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Shikhar Bhushan <shikhar@confluent.io>, Jason Gustafson <jason@confluent.io>

Closes #1867 from rhauch/kafka-4183",2016-09-16 14:55:46,Randall Hauch,Mixed
d7bffebca05aa91a69da03fe29add4f29b964fd9,"KAFKA-4173; SchemaProjector should successfully project missing Struct field when target field is optional

Author: Shikhar Bhushan <shikhar@confluent.io>

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Jason Gustafson <jason@confluent.io>

Closes #1865 from shikhar/kafka-4173",2016-09-16 15:54:33,Shikhar Bhushan,Mixed
ecc1fb10fad39c2da82731a36552cb5dd9ac2858,"KAFKA-4093; Cluster Id (KIP-78)

This PR implements  KIP-78:Cluster Identifiers [(link)](https://cwiki.apache.org/confluence/display/KAFKA/KIP-78%3A+Cluster+Id#KIP-78:ClusterId-Overview) and includes the following changes:

1. Changes to broker code
	- generate cluster id and store it in Zookeeper
	- update protocol to add cluster id to metadata request and response
	- add ClusterResourceListener interface, ClusterResource class and ClusterMetadataListeners utility class
	- send ClusterResource events to the metric reporters
2. Changes to client code
	- update Cluster and Metadata code to support cluster id
	- update clients for sending ClusterResource events to interceptors, (de)serializers and metric reporters
3. Integration tests for interceptors, (de)serializers and metric reporters for clients and for protocol changes and metric reporters for broker.
4. System tests for upgrading from previous versions.

Author: Sumit Arrawatia <sumit.arrawatia@gmail.com>
Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1830 from arrawatia/kip-78",2016-09-17 07:53:25,Sumit Arrawatia,Mixed
69356fbc6e76ab4291ff4957f0d6ea04e7245909,"KAFKA-3492; Secure quotas for authenticated users

Implementation and tests for secure quotas at <user> and <user, client-id> levels as described in KIP-55. Also adds dynamic default quotas for <client-id>, <user> and <user-client-id>. For each client connection, the most specific quota matching the connection is used, with user quota taking precedence over client-id quota.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #1753 from rajinisivaram/KAFKA-3492",2016-09-17 10:06:05,Rajini Sivaram,Mixed
d04b0998c043a6a430921585ffd4c42572a3bf5a,"KAFKA-2063; Bound fetch response size (KIP-74)

This PR is implementation of [KIP-74](https://cwiki.apache.org/confluence/display/KAFKA/KIP-74%3A+Add+Fetch+Response+Size+Limit+in+Bytes) which is originally motivated by [KAFKA-2063](https://issues.apache.org/jira/browse/KAFKA-2063).

Author: Andrey Neporada <neporada@gmail.com>
Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #1812 from nepal/kip-74",2016-09-18 09:15:16,Andrey Neporada,Mixed
70afd5f9dd2eddc784a24fa2518992ef3371f0a4,"KAFKA-4175: Can't have StandbyTasks in KafkaStreams where NUM_STREAM_THREADS_CONFIG > 1

standby tasks should be assigned per consumer not per process

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska, Guozhang Wang

Closes #1862 from dguy/kafka-4175",2016-09-19 10:30:58,Damian Guy,Mixed
3d74196f205c53946b6fc3dd0501aa2095f0031a,"KAFKA-4163: NPE in StreamsMetadataState during re-balance operations

During rebalance operations the Cluster object gets set to Cluster.empty(). This can result in NPEs when doing certain operation on StreamsMetadataState. This should throw a StreamsException if the Cluster is empty as it is not yet (re-)initialized

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska, Guozhang Wang

Closes #1845 from dguy/streams-meta-hotfix",2016-09-19 11:00:53,Damian Guy,Mixed
431c3b0937da103b6e79e9f970c0862898205909,"KAFKA-4183; Centralize checking for optional and default values in JsonConverter

Cleaner to just check once for optional & default value from the `convertToConnect()` function.

It also helps address an issue with conversions for logical type schemas that have default values and null as the included value. That test case is _probably_ not an issue in practice, since when using the `JsonConverter` to serialize a missing field with a default value, it will serialize the default value for the field. But in the face of JSON data streaming in from a topic being [generous on input, strict on output](http://tedwise.com/2009/05/27/generous-on-input-strict-on-output) seems best.

Author: Shikhar Bhushan <shikhar@confluent.io>

Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #1872 from shikhar/kafka-4183",2016-09-19 12:49:38,Shikhar Bhushan,Mixed
4e1c7d844f743e5b439447e645fa41d2f92b8b5f,"KAFKA-4135; Consumer poll with no subscription or assignment should raise an error

When the consumer is not subscribed to any topic or, in the case of manual assignment, is not assigned any partition, calling `poll()` should raise an exception.

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #1839 from vahidhashemian/KAFKA-4135",2016-09-19 16:42:43,Vahid Hashemian,Mixed
cf8f4a713b64f010c15a4a7b8dae616edb8a1b74,"KAFKA-4153: Fix incorrect KStream-KStream join behavior with asymmetric time window

The contribution is my original work and I license the work to the project under the project's open source license.

guozhangwang

Author: Elias Levy <fearsome.lucidity@gmail.com>

Reviewers: Damian Guy, Matthias J. Sax, Guozhang Wang

Closes #1846 from eliaslevy/KAFKA-4153",2016-09-19 17:13:47,Elias Levy,Not TDD
eaaa433fc97b86450833d8fcc8c9289ea35d47c0,"KAFKA-4148; Support ListOffsetRequest v1 and search offsets by timestamp in consumer (KIP-79)

Author: Jiangjie Qin <becket.qin@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #1852 from becketqin/KAFKA-4148",2016-09-19 18:38:27,Jiangjie Qin,Mixed
732fabf94ebc9631d31f2feb2116ee8b63beabef,"KAFKA-3782: Ensure heartbeat thread restarted after rebalance woken up

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang

Closes #1898 from hachikuji/KAFKA-3782",2016-09-22 10:07:50,Jason Gustafson,Mixed
6a13a3dbaddf99850b2583007577fa2a6e1e6d3a,"KAFKA-3590; Handle not-enough-replicas errors when writing to offsets topic

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>

Closes #1859 from hachikuji/KAFKA-3590",2016-09-23 13:13:29,Jason Gustafson,Mixed
0de807357be4d776747e960b5fd17ddeae9a6cad,"KAFKA-3719; Allow underscores in hostname

Technically this does not strictly adhere to RFC-952 however it is valid for domain names, urls and uris so we should loosen the requirements a tad.

Author: Ryan Pridgeon <ryan.n.pridgeon@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #1856 from rnpridgeon/KAFKA-3719",2016-09-23 22:20:56,Ryan Pridgeon,Mixed
1d055f7551d138324d2540095a1cfc1c8f74d76f,"KAFKA-3282; Change tools to use new consumer if zookeeper is not specified

Author: Arun Mahadevan <aiyer@hortonworks.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #1376 from arunmahadevan/cons-consumer-fix",2016-09-25 09:12:02,Arun Mahadevan,Mixed
c0a62b70a8eadc550c937bb18e0203ab691618f5,"KAFKA-4055; System tests for secure quotas

Fix existing client-id quota test which currently don't configure quota overrides correctly. Add new tests for user and (user, client-id) quota overrides and default quotas.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #1860 from rajinisivaram/KAFKA-4055",2016-09-25 17:01:45,Rajini Sivaram,Not TDD
b75245cfbbefc712103b9329da0f27a205baa6aa,"MINOR: Wakeups propagated from commitOffsets in WorkerSinkTask should be caught

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1907 from hachikuji/catch-wakeup-worker-sink-task",2016-09-26 14:54:01,Jason Gustafson,Mixed
5d6408f6cfda3f8ab366195f69e90de048cde25d,"KAFKA-4200; Fix throttle argument in kafka-reassign-partitions.sh

Simple jira which alters two things:

1. kafka-reassign-partitions --verify prints Throttle was removed regardless of whether a throttle was applied. It should only print this if the value was actually changed.

2. --verify should exception if the —throttle argument. (check generate too)

To test this I extracted all validation logic into a separate method and added a test which covers the majority of combinations. The validation logic was retained as is, other than implementing (2) and adding validation to the --broker-list option which you can currently apply to any of hte main actions (where it is ignored). Requirement 1 was tested manually (as it's just println).

Testing:
- Build passes locally.
- System test reassign_partitions_test.py also passes.

Author: Ben Stopford <benstopford@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #1896 from benstopford/KAFKA-4200",2016-09-27 14:00:44,Ben Stopford,Not TDD
b8ed4a51134ca8b98d1445871a55ed33b6ad5b92,"KAFKA-4177; Remove ThrottledReplicationRateLimit from Server Config

This small PR pulls ThrottledReplicationRateLimit out of KafkaConfig and puts it in a class that defines Dynamic Configs. Client configs are also placed in this class and validation added.

Author: Ben Stopford <benstopford@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1864 from benstopford/KAFKA-4177",2016-09-27 20:37:49,Ben Stopford,Mixed
0c25c73782e6e70b8f37e3dda2fa2a5b0b1c8c65,"HOTFIX: fix npe in StreamsMetadataState when onChange has not been called

If some StreamsMetadataState methods are called before the onChange method is called a NullPointerException was being thrown. Added null check for cluster in isInitialized method

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1920 from dguy/fix-npe-streamsmetadata",2016-09-27 17:35:24,Damian Guy,Mixed
d83cde7cabe4e86951c6760e68e65b99752cfe0e,"KAFKA-3708: Better exception handling in Kafka Streams

KafkaExceptions currently thrown from within StreamThread/StreamTask currently bubble up without any additional context. This makes it hard to figure out where something went wrong, i.e, which topic had the serialization exception etc

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1819 from dguy/kafka-3708 and squashes the following commits:

d6feaa8 [Damian Guy] address comments
15b89e7 [Damian Guy] merge trunk
6b8a8af [Damian Guy] catch exceptions in various places and throw more informative versions
c86eeda [Damian Guy] fix conflicts
8f37e2c [Damian Guy] add some context to exceptions",2016-09-28 11:07:44,Damian Guy,Mixed
aa506a6919e8ec0381657db2c2f15dc1f62b00f6,"KAFKA-4194; Follow-up improvements/testing for ListOffsets v1 (KIP-79)

Author: Jiangjie Qin <becket.qin@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #1897 from becketqin/KAFKA-4194",2016-09-28 17:58:08,Jiangjie Qin,Mixed
2ca9177f499a07262db0072bbbb252d3ca2dfb58,"KAFKA-4216; Control Leader & Follower Throttled Replicas Separately

Splits the throttled replica configuration (the list of which replicas should be throttled for each topic) into two. One for the leader throttle, one for the follower throttle.

So:
 quota.replication.throttled.replicas
=>
quota.leader.replication.throttled.replicas & quota.follower.replication.throttled.replicas

Author: Ben Stopford <benstopford@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1906 from benstopford/KAFKA-4216-seperate-leader-and-follower-throttled-replica-lists",2016-09-29 08:57:17,Ben Stopford,Mixed
9edc71230ee7b77fd512f6d923e76469508c3280,"KAFKA-4223; RocksDBStore should close all open iterators on close

Keep track of open Rocks DB iterators. When a store is closed, close all open iterators.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1917 from dguy/kafka-4223",2016-09-30 09:41:28,Damian Guy,Not TDD
0bc1f41fc02062ff224f12ffac053ea3753ecb98,"KAFKA-4225; Replication Quotas: Control Leader & Follower Limit Separately

Author: Ben Stopford <benstopford@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1932 from benstopford/KAFKA-4225-over-KAFKA-4216",2016-09-30 11:02:08,Ben Stopford,Mixed
43c30b8c3970d6a6252490c42b3300c445d80d37,"HOTFIX: turn off auto topic creation in embedded kafka cluster

Turning off auto topic creation in the EmbeddedKafkaCluster used by Streams as it can cause race conditions that lead to build hangs.
Fixed the couple of tests that needed to have some topics manually created

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska <eno.thereska@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1941 from dguy/disable-auto-topic-create",2016-09-30 11:26:17,Damian Guy,Not TDD
4292243009c066c9ab5477ce886d8eb00534587e,"HOTFIX: do not call partitioner if num partitions is non-positive

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Eno Thereska, Damian Guy

Closes #1929 from guozhangwang/KMinor-check-zero-num-partitions and squashes the following commits:

c8edc2d [Guozhang Wang] fix unit test
3127f9c [Guozhang Wang] do not call partitioner if num partitions is non-positive",2016-09-30 09:36:46,Guozhang Wang,Not TDD
5f3746d135697f364aaacf877ce288267d00b9a2,"KAFKA-4233: StateDirectory fails to create directory if any parent directory does not exist

Change the creation of the directories, in the StateDirectory constructor, to use mkdirs so any parents get created. Throw an exception if the directory doesn't exist and couldn't be created

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Michael G. Noll, Eno Thereska, Guozhang Wang

Closes #1942 from dguy/kafka-4233",2016-09-30 11:55:32,Damian Guy,Mixed
5a989d1748426004212d44abad4567f9034a04ef,"KAFKA-4213; System tests for replication throttling (KIP-73)

In this patch, we test `kafka-reassign-partitions` when throttling is active.

This patch also fixes the following:

  1. KafkaService.verify_reassign_partitions did not check whether
partition reassignment actually completed successfully (KAFKA-4204).
This patch works around those shortcomings so that we get the right
signal from this method.

  2. ProduceConsumeValidateTest.annotate_missing_messages would call
`pop' on the list of missing messages, causing downstream methods to get
incomplete data. We fix that in this patch as well.

Author: Apurva Mehta <apurva.1618@gmail.com>

Reviewers: Geoff Anderson <geoff@confluent.io>, Ben Stopford <benstopford@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1904 from apurvam/throttling-tests",2016-09-30 19:58:58,Apurva Mehta,Not TDD
20322446aa261dec8b51e6e4514307e926a29ba5,"KAFKA-4234; Revert automatic offset commit behavior in consumer's `unsubscribe()`

Temporarily disable the offset commit (when auto commit is enabled) in the new consumer's `unsubscribe()` method towards a workaround for the issue reported in [KAFKA-3491](https://issues.apache.org/jira/browse/KAFKA-3491).
For now, a call to `unsubscribe()` can be made to reset the offsets in case processing the batch received from the most recent `poll()` is interrupted (due to some exception).

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #1944 from vahidhashemian/KAFKA-4234",2016-09-30 13:13:24,Vahid Hashemian,Mixed
8124f6e0996cb673760750b3aba004ae11e34c6a,"KAFKA-3396; Ensure Describe access is required to detect topic existence

Reopening of https://github.com/apache/kafka/pull/1428

Author: Edoardo Comar <ecomar@uk.ibm.com>
Author: Mickael Maison <mickael.maison@gmail.com>

Reviewers: Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #1908 from edoardocomar/KAFKA-3396",2016-09-30 23:07:51,Edoardo Comar,Not TDD
c78a3b173d019e8bb58f4e31c94bf4dd3f7ab614,"KAFKA-4241: StreamsConfig doesn't pass through custom consumer and producer properties to ConsumerConfig and ProducerConfig

pass through user-defined consumer and producer properties from StreamsConfig to ConsumerConfig and ProducerConfig.
For example, consumer interceptor support, i.e, consumer.interceptor.classes=SomeClass

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1943 from dguy/interceptor",2016-10-01 21:57:49,Damian Guy,Mixed
496594a12c67d468c5ab58d83bf31caea3154e56,"MINOR: Rename Throttling config variables to match config name

ThrottledLeaderReplicationRate* => LeaderReplicationThrottledRate*
ThrottledFollowerReplicationRate* => FollowerReplicationThrottledRate* LeaderThrottledReplicasList* => LeaderReplicationThrottledReplicas*
FollowerThrottledReplicasList* => FollowerReplicationThrottledReplicas*

Author: Ben Stopford <benstopford@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #1951 from benstopford/rename-ThrottledLeaderReplicationRateProp",2016-10-03 18:21:57,Ben Stopford,Mixed
a23859e5686bf93ed7e0d310f949757694d47a1b,"KAFKA-4248; Consumer should rematch regex immediately in subscribe

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1954 from hachikuji/rematch-regex-on-subscribe",2016-10-03 16:19:41,Jason Gustafson,Mixed
7115c66aefb11efa802e61a42bcc13fadf92598d,"MINOR: Follow-up minor improvements/cleanup for KAFKA-3396

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #1946 from hachikuji/followup-for-kafka-3396",2016-10-03 16:49:50,Jason Gustafson,Mixed
cf0bf7c7a24aa5a19069b6e8456353c9b498dffc,"MINOR: Tweak implementation of `FetchRequest.shuffle` and upgrade.html improvements

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #1955 from ijuma/kip-74-follow-up",2016-10-04 02:18:19,Ismael Juma,Mixed
672dfaa243850a835c1b01da4fb20311ba6455bc,"KAFKA-4019; Update log cleaner to handle max message size of topics

Grow read and write buffers of cleaner up to the maximum message size of the log being cleaned if the topic has larger max message size than the default config of the broker.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #1758 from rajinisivaram/KAFKA-4019",2016-10-03 20:22:52,Rajini Sivaram,Mixed
c9da62794547ee75a7e2ade1aa8bbf4a1443c49c,"KAFKA-4253: Fix Kafka Stream thread shutting down process ordering

Changed the ordering in `StreamThread.shutdown`
1. commitAll (we need to commit so that any cached data is flushed through the topology)
2. close all tasks
3. producer.flush() - so any records produced during close are flushed and we have offsets for them
4. close all state managers
5. close producers/consumers
6. remove the tasks

Also in `onPartitionsRevoked`
1. commitAll
2. close all tasks
3. producer.flush
4. close all state managers

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska, Guozhang Wang

Closes #1970 from dguy/kafka-4253",2016-10-06 09:43:39,Damian Guy,Mixed
8b75a016db16e20c5d5180deb6859bf0ad4c48fd,"KAFKA-4267; Quota initialization for <user, clientId> uses incorrect ZK path

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #1987 from rajinisivaram/quota-init-test",2016-10-07 12:10:53,Rajini Sivaram,Not TDD
e876df8b37fc6ea54b0a0571306c4a833c919cda,"HOTFIX: recreate state.dir after cleanup

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #1940 from mjsax/hotfix-resetTool",2016-10-07 13:13:27,Matthias J. Sax,Mixed
6b91f83fbaef26fefb9ec221529c29872a04c004,"KAFKA-4274; Consumer `offsetForTimes` times out on empty map

Author: Jiangjie Qin <becket.qin@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #1993 from becketqin/KAFKA-4274",2016-10-07 18:43:24,Jiangjie Qin,Mixed
1bce0d1b5120743a9a0559a6c9a98249d463fe02,"KAFKA-3175; Topic not accessible after deletion even when delete.topic.enable is disabled

Remove topics under /admin/delete_topics path in zk if deleteTopic is disabled. The topic should never be enqueued for deletion.

Author: MayureshGharat <gharatmayuresh15@gmail.com>

Reviewers: Joel Koshy <jjkoshy.w@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>, Jun Rao <junrao@gmail.com>

Closes #846 from MayureshGharat/kafka-3175",2016-10-10 14:06:12,MayureshGharat,Not TDD
72d5675a7cfc64a5547b921672856ea4afc4f4c2,"KAFKA-4010: add ConfigDef toEnrichedRst() for additional fields in output

followup on https://github.com/apache/kafka/pull/1696

cc rekhajoshm

Author: Shikhar Bhushan <shikhar@confluent.io>
Author: Joshi <rekhajoshm@gmail.com>

Reviewers: Shikhar Bhushan <shikhar@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1964 from shikhar/kafka-4010",2016-10-10 20:02:04,Joshi,Mixed
93b940016348fcf64034f36e4b4f3fc53a966f74,"KAFKA-4283: records deleted from CachingKeyValueStore still appear in range and all queries

Records that are deleted/removed from the CachingKeyValueStore shouldn't appear in range and all queries.
Modified the iterator such that it skips over the deleted records.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska, Matthias J. Sax, Guozhang Wang

Closes #2001 from dguy/kafka-4283",2016-10-11 13:57:30,Damian Guy,Mixed
65f6a7964f5e59e789eae3cdd4d301bb6a649064,"KAFKA-4300: NamedCache throws an NPE when evict is called and the cache is empty

If evict is called on a NamedCache and the cache is empty an NPE is thrown. This was reported on the user list from a developer running 0.10.1.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska, Matthias J. Sax, Guozhang Wang

Closes #2024 from dguy/cache-bug",2016-10-13 13:15:26,Damian Guy,Mixed
1a67739c2f3d0418a8f2d8f7b15d5af2ed3a324a,"KAFKA-4254; Update producer's metadata before failing on non-existent partitions

Author: Konstantine Karantasis <konstantine@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #1995 from kkonstantine/KAFKA-4254-Update-producers-metadata-before-failing-on-non-existent-partition",2016-10-13 20:17:57,Konstantine Karantasis,Mixed
d09043637d5ea4094e3ee9808f29d037e8afaba6,"KAFKA-4298; Ensure compressed message sets are not converted when log cleaning

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #2019 from hachikuji/KAFKA-4298",2016-10-13 21:08:28,Jason Gustafson,Mixed
6199c62776bf3ce9467703ca651a0119b261e60e,"KAFKA-4303; Ensure commitSync does not block unnecessarily in poll without in-flight requests

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2031 from hachikuji/KAFKA-4303",2016-10-14 15:36:43,Jason Gustafson,Mixed
925310aac0b6a0fb32e3e2d614198ffc78f34f96,"KAFKA-4275: Check of State-Store-assignment to Processor-Nodes is not enabled

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy, Guozhang Wang

Closes #1992 from mjsax/kafka-4275-stateStoreCheck",2016-10-17 21:48:40,Matthias J. Sax,Not TDD
179d4dc0f2a23d7e67caf4875a0563e74027933a,"HOTFIX: Fix putAll and putIfAbsent logic for correct eviction behavior

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Damian Guy, Guozhang Wang

Closes #2038 from enothereska/hotfix-put-cache",2016-10-19 14:01:23,Eno Thereska,Mixed
b51002c576ea9758132d75a8a0fe454e1bc270a2,"KAFKA-4312: If filePath is empty string writeAsText should have more meaningful error message

…eaningful error message

Author: bbejeck <bbejeck@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #2042 from bbejeck/KAFKA-4312_write_as_text_throws_NPE_empty_string",2016-10-19 14:29:53,Bill Bejeck,Mixed
17cb4fe52f74fcc1b7c43baa4649e0a4aba80fa3,"HOTFIX: follow up on KAFKA-4275

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #2039 from mjsax/hotfix-ktableLeftJoin",2016-10-19 20:58:18,Matthias J. Sax,Not TDD
4c295a78446be6eba24ca4a9b7e506657e55c875,"KAFKA-4269: Update topic subscription when regex pattern specified out of topicGroups method

…d out of topicGroups method. The topicGroups method only called from StreamPartitionAssignor when KafkaStreams object  is the leader, needs to be executed for clients.

Author: bbejeck <bbejeck@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #2005 from bbejeck/KAFKA-4269_multiple_kstream_instances_mult_consumers_npe",2016-10-19 21:04:28,Bill Bejeck,Mixed
24067e40764d91e1a6b2d80be45407841bbb72a2,"KAFKA-4313; ISRs may thrash when replication quota is enabled

Author: Jun Rao <junrao@gmail.com>

Reviewers: Ben Stopford <benstopford@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2043 from junrao/kafka-4313",2016-10-20 10:45:31,Jun Rao,Not TDD
62c0972efc525cc0677bd3fd470bd9fbbd70b004,"KAFKA-4001: Improve Kafka Streams Join Semantics (KIP-77)

 - fixed leftJoin -> outerJoin test bug
 - simplified to only use values
 - fixed inner KTable-KTable join
 - fixed left KTable-KTable join
 - fixed outer KTable-KTable join
 - fixed inner, left, and outer left KStream-KStream joins
 - added inner KStream-KTable join
 - fixed left KStream-KTable join

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #1777 from mjsax/kafka-4001-joins",2016-10-20 13:06:25,Matthias J. Sax,Mixed
302a246c72677b1045696f4d6dda51da8c6a1da0,"KAFKA-4296; Fix LogCleaner statistics rolling

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2016 from hachikuji/KAFKA-4296",2016-10-21 14:41:04,Jason Gustafson,Mixed
7afdad8c37cde4a32ad7ce66ca7a878cf730495e,"KAFKA-3144; Report members with no assigned partitions in ConsumerGroupCommand

This PR makes a couple of enhancements to the `--describe` option of `ConsumerGroupCommand`:
1. Listing members with no assigned partitions.
2. Showing the member id along with the owner of each partition (owner is supposed to be the logical application id and all members in the same group are supposed to set the same owner).
3. Printing a warning indicating whether ZooKeeper based or new consumer API based information is being reported.

It also adds unit tests to verify the added functionality.

Note: The third request on the corresponding JIRA (listing active offsets for empty groups of new consumers) is not implemented as part of this PR, and has been moved to its own JIRA (KAFKA-3853).

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #1336 from vahidhashemian/KAFKA-3144",2016-10-21 19:19:04,Vahid Hashemian,Mixed
63da487213765cb543a4255a83acb876a57d3634,"KAFAK-4058: Failure in org.apache.kafka.streams.integration.ResetIntegrationTest.testReprocessingFromScratchAfterReset

 - fixed consumer group dead condition
 - disabled state store cache

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #2056 from mjsax/KAFKA-4058-instableResetToolTest",2016-10-23 21:31:34,Matthias J. Sax,Not TDD
d092673838173d9dedbf5acf3f4e2cd8c736294f,"MINOR: A bunch of clean-ups related to usage of unused variables

There should be only one cases where these clean-ups have a functional impact: replaced repeated identical logs with a single log for the stale controller epoch case.

The rest should just make the code easier to read and make it a bit less wasteful. I did this exercise because unused variables sometimes mask bugs.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #1985 from ijuma/remove-unused",2016-10-25 02:55:55,Ismael Juma,Mixed
2ac332e9c9015964d993692c99c5ad19c9e2d56b,"KAFKA-4339; Update system tests to accommodate the new consumer group describe output

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2061 from vahidhashemian/KAFKA-4339",2016-10-25 13:07:50,Vahid Hashemian,Not TDD
0dd9607f9ca50a385e78af06b66e0e90c1f37076,"KAFKA-4326; Refactor LogCleaner for better reuse of common copy/compress logic

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2053 from hachikuji/KAFKA-4326",2016-10-28 06:31:29,Jason Gustafson,Not TDD
a4ab9d02a22e77f0ebca0450e608898d83d4fe18,"KAFKA-4117: Stream partitionassignro cleanup

1. Create a new `ClientMetadata` to collapse `Set<String> consumerMemberIds`, `ClientState<TaskId> state`, and `HostInfo hostInfo`.

2. Stop reusing `stateChangelogTopicToTaskIds` and `internalSourceTopicToTaskIds` to access the (sub-)topology's internal repartition and changelog topics for clarity; also use the source topics num.partitions to set the num.partitions for repartition topics, and clarify to NOT have cycles since otherwise the while loop will fail.

3. `ensure-copartition` at the end to modify the number of partitions for repartition topics if necessary to be equal to other co-partition topics.

4. Refactor `ClientState` as well and update the logic of `TaskAssignor` for clarity as well.

5. Change default `clientId` from `applicationId-suffix` to `applicationId-processId` where `processId` is an UUID to avoid conflicts of clientIds that are from different JVMs, and hence conflicts in metrics.

6. Enforce `assignment` partitions to have the same size, and hence 1-1 mapping to `activeTask` taskIds.

7. Remove the `AssignmentSupplier` class by always construct the `partitionsByHostState` before assigning tasks to consumers within a client.

8. Remove all unnecessary member variables in `StreamPartitionAssignor`.

9. Some other minor fixes on unit tests, e.g. remove `test only` functions with java field reflection.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Xavier Léauté, Matthias J. Sax, Eno Thereska, Jason Gustafson

Closes #2012 from guozhangwang/K4117-stream-partitionassignro-cleanup",2016-10-29 10:48:17,Guozhang Wang,Mixed
29ea4b0f1481aa2ee29694f2b469c16059f9c17e,"KAFKA-3559: Recycle old tasks when possible

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Damian Guy, Guozhang Wang

Closes #2032 from enothereska/KAFKA-3559-onPartitionAssigned",2016-10-30 11:21:44,Eno Thereska,Mixed
76b070284142635d2be78e8f86e779dfdbb0a2e0,"HOTFIX: improve error message on invalid input record timestamp

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Guozhang Wang, Ismael Juma, Michael G. Noll, Eno Thereska

Closes #2076 from mjsax/hotfixTSExtractor",2016-10-30 11:37:38,Matthias J. Sax,Mixed
ba322e54203ffec5779944753f264d70b87a24fd,"KAFKA-4361: Streams does not respect user configs for ""default"" params

Enable user provided consumer and producer configs to override the streams default configs.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska, Matthias J. Sax, Guozhang Wang

Closes #2084 from dguy/kafka-4361",2016-11-01 10:07:58,Damian Guy,Mixed
94909a8f83bfe214726f85130ad04d867e022894,"KAFKA-4357; Fix consumer group describe output when there is no active member (old consumer)

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Jason Gustafson <jason@confluent.io>

Closes #2075 from vahidhashemian/KAFKA-4357",2016-11-01 11:36:12,Vahid Hashemian,Not TDD
e795ad96ca9f26cdef01d063b79483a6c9221f27,"KAFKA-4024; Override client metadata backoff on topic changes and avoid unnecessary connections

Fixes a bug that inappropriately applies backoff as interval between metadata updates even though the current one is outdated.

Author: Yuto Kawamura <kawamuray.dadada@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #1707 from kawamuray/KAFKA-4024-metadata-backoff",2016-11-03 23:19:01,Yuto Kawamura,Mixed
0a659e50f7d98c0a195a7dca4ef9f117ab2aa257,"KAFKA-4372: Kafka Connect REST API does not handle DELETE of connector with slashes in their names

Kafka Connect REST API does not handle in many places connectors with slashes in their names because it expects PathParams, this PR intends to :
* Reject as bad requests API calls trying to create connectors with slashes in their names
* Add support for connector with slashes in their names in the DELETE part of the API to allow users to cleanup their connectors without dropping everything.

This PR adds as well the Unit Test needed for the creation part and was tested manually for the DELETE part.

Author: Olivier Girardot <o.girardot@lateral-thoughts.com>

Reviewers: Shikhar Bhushan <shikhar@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2096 from ogirardot/fix/connectors-with-slashes-cannot-be-deleted",2016-11-04 10:44:05,Olivier Girardot,Mixed
471a2ab17df66c52e0a98afa81e0b360560a5e9a,"KAFKA-4284: Make Partitioner a Closeable and close it when closing the producer

[KAFKA-4284](https://issues.apache.org/jira/browse/KAFKA-4284)

Even though Partitioner has a close method it is not closed when the producer is closed. Serializers, interceptors and metrics are all closed, so partitioners should be closed to.

To be able to use the same mechanism to close the partitioner as the serializers, etc. I had to make the `Partitioner` interface extend `Closeable`. Since this doesn't change the interface that feels ok and should be backwards compatible.

Looking at [KAFKA-2091](https://issues.apache.org/jira/browse/KAFKA-2091) (d6c45c70fb9773043766446e88370db9709e7995) that introduced the `Partitioner` interface it looks like the intention was that the producer should close the partitioner.

This contribution is my original work and I license the work to the project under the project's open source license.

Author: Theo <theo@iconara.net>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2000 from iconara/kafka-4284",2016-11-08 09:27:11,Theo,Mixed
7c36fc377650dac8a9d6e5f2d0049a78cd93d2e5,"KAFKA-4311: Multi layer cache eviction causes forwarding to incorrect ProcessorNode

Given a topology like the one below. If a record arriving in `tableOne` causes a cache eviction, it will trigger the `leftJoin` that will do a `get` from `reducer-store`. If the key is not currently cached in `reducer-store`, but is in the backing store, it will be put into the cache, and it may also trigger an eviction. If it does trigger an eviction and the eldest entry is dirty it will flush the dirty keys. It is at this point that a ClassCastException is thrown. This occurs because the ProcessorContext is still set to the context of the `leftJoin` and the next child in the topology is `mapValues`.
We need to set the correct `ProcessorNode`, on the context, in the `ForwardingCacheFlushListener` prior to calling `context.forward`. We also need to  remember to reset the `ProcessorNode` to the previous node once `context.forward` has completed.

```
       final KTable<String, String> one = builder.table(Serdes.String(), Serdes.String(), tableOne, tableOne);
        final KTable<Long, String> two = builder.table(Serdes.Long(), Serdes.String(), tableTwo, tableTwo);
        final KTable<String, Long> reduce = two.groupBy(new KeyValueMapper<Long, String, KeyValue<String, Long>>() {
            Override
            public KeyValue<String, Long> apply(final Long key, final String value) {
                return new KeyValue<>(value, key);
            }
        }, Serdes.String(), Serdes.Long())
                .reduce(new Reducer<Long>() {..}, new Reducer<Long>() {..}, ""reducer-store"");

    one.leftJoin(reduce, new ValueJoiner<String, Long, String>() {..})
        .mapValues(new ValueMapper<String, String>() {..});

```

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska, Guozhang Wang

Closes #2051 from dguy/kafka-4311",2016-11-09 10:43:27,Damian Guy,Mixed
d8fa4006cb824aa2a8ab890b6754c920ac17182c,"MINOR: improve exception message for incompatible Serdes to actual key/value data types

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Michael G. Noll, Guozhang Wang

Closes #2118 from mjsax/hotfixImproveSerdeTypeMissmatchError",2016-11-10 17:06:36,Matthias J. Sax,Mixed
64a860c5853e21ff91109d0acb74b42f2dc20c7c,"KAFKA-4379: Remove caching of dirty and removed keys from StoreChangeLogger

The `StoreChangeLogger` currently keeps a cache of dirty and removed keys and will batch the changelog records such that we don't send a record for each update. However, with KIP-63 this is unnecessary as the batching and de-duping is done by the caching layer. Further, the `StoreChangeLogger` relies on `context.timestamp()` which is likely to be incorrect when caching is enabled

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax, Eno Thereska, Guozhang Wang

Closes #2103 from dguy/store-change-logger",2016-11-11 10:21:03,Damian Guy,Mixed
7282de39f7b7cef1ca85f21771f2401a4a67eaec,"KAFKA-4081; KafkaConsumer should not allow negative offsets to be committed

Author: Mickael Maison <mickael.maison@gmail.com>

Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #1827 from mimaison/KAFKA-4081",2016-11-11 10:21:59,Mickael Maison,Mixed
b7d36b7261ddefea68667a65cc5e2ee0734ed4a1,"KAFKA-3829: Ensure valid configuration prior to creating connector

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Shikhar Bhushan <shikhar@schmizz.net>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1911 from hachikuji/KAFKA-3829",2016-11-12 16:11:28,Jason Gustafson,Mixed
3b4c347949c02b1e2b1dd473deda0f8d2304d027,"KAFKA-2066; Use client-side FetchRequest/FetchResponse on server

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #2069 from hachikuji/KAFKA-2066",2016-11-14 16:31:04,Jason Gustafson,Mixed
b902ef985a8d4ce304950fcb2c02499054fe6d24,"MINOR: Remove unused `ByteBoundedBlockingQueue` class and `zkSessionTimeout` parameter

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #2136 from ijuma/remove-unused-code",2016-11-16 09:38:42,Ismael Juma,Mixed
249e4136852be49579eef53b2bce0b2506797666,"KAFKA-4211; Update system test services to use the new consumer by default

Update system test method signatures and method calls to use the new consumer by default.

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #2060 from vahidhashemian/KAFKA-4211",2016-11-16 16:30:48,Vahid Hashemian,Mixed
2daa10d77f8f177a8db6ff5de5c511165fedc2f5,"KAFKA-4366: KafkaStreams.close() blocks indefinitely

Added `timeout` and `timeUnit` to `KafkaStreams.close(..)`. Now do close on a thread and `join` that thread with the provided `timeout`.
Changed `state` in `KafkaStreams` to use an enum.
Added system test to ensure we don't deadlock on close when an uncaught exception handler that calls `System.exit(..)` is used and there is also a shutdown hook that calls `KafkaStreams.close(...)`

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax, Eno Thereska, Guozhang Wang

Closes #2097 from dguy/kafka-4366",2016-11-17 12:49:20,Damian Guy,Mixed
eaf0e4af341818b335d17400b0a02be87a7fff9b,"KAFKA-3825: Allow users to specify different types of state stores in Streams DSL

Author: Jeyhun Karimov <je.karimov@gmail.com>

Reviewers: Damian Guy, Guozhang Wang

Closes #1588 from jeyhunkarimov/KAFKA-3825",2016-11-17 12:52:50,Jeyhun Karimov,Mixed
0e7ba70008fa8961ae55861a4dd3a5370d1d5a69,"KAFKA-4377; remove deprecated scala.collection.JavaConversions calls

JavaConversions are deprecated in 2.12 in favour of JavaConverters.

Author: Bernard Leach <leachbj@bouncycastle.org>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2101 from leachbj/4377-java-converters",2016-11-18 04:29:55,Bernard Leach,Mixed
e53babab9cada20cc54a18c0fd63aa5ab84fd012,"KAFKA-3703; Graceful close for consumers and producer with acks=0

Process requests received from channels before they were closed. For consumers, wait for coordinator requests to complete before returning from close.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1836 from rajinisivaram/KAFKA-3703",2016-11-19 09:33:48,Rajini Sivaram,Mixed
dcea5f83888bb346c8ae20887b57904e046463a7,"KAFKA-4355: Skip topics that have no partitions

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Damian Guy, Matthias J. Sax, Guozhang Wang

Closes #2133 from enothereska/KAFKA-4355-topic-not-found",2016-11-22 09:54:54,Eno Thereska,Mixed
4b003d8bcfffded55a00b8ecc9eed8eb373fb6c7,"KAFKA-4362; Consumer can fail after reassignment of the offsets topic partition

Author: MayureshGharat <gharatmayuresh15@gmail.com>

Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #2116 from MayureshGharat/KAFKA-4362",2016-11-22 20:32:42,MayureshGharat,Mixed
0ea540552a52b3265c48aacbb9790ea6e71431a5,"KAFKA-4395; Break static initialization order dependency between KafkaConfig and Logconfig

Fixes static initialization order dependency between KafkaConfig and LogConfig. jjkoshy please take a look.

Author: Sumant Tambe <sutambe@yahoo.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2120 from sutambe/logconfig-static-init",2016-11-23 10:06:10,Sumant Tambe,Mixed
724cddbc56fec227727db4caf75c77adb62438e6,"KAFKA-4331: Kafka Streams resetter is slow because it joins the same group for each topic

  - bug-fix follow up
  - Resetter fails if no intermediate topic is used because seekToEnd() commit ALL partitions to EOL

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Michael G. Noll, Roger Hoover, Guozhang Wang

Closes #2138 from mjsax/kafka-4331-streams-resetter-bugfix",2016-11-23 17:31:34,Matthias J. Sax,Not TDD
e035fc039598127e88f31739458f705290b1fdba,"KAFKA-4345; Run decktape test for each pull request

As of now the ducktape tests that we have for kafka are not run for pull request. We can run these test using travis-ci. Here is a sample run:
https://travis-ci.org/raghavgautam/kafka/builds/170574293

Author: Raghav Kumar Gautam <raghav@apache.org>

Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>

Closes #2064 from raghavgautam/trunk",2016-11-23 20:48:58,Raghav Kumar Gautam,Mixed
3e3b7a010be9959ac6f205a0ea66a2595bb62ae6,"KAFKA-4384; ReplicaFetcherThread stops after ReplicaFetcherThread receives a corrupted message

Author: Jun He <jun.he@airbnb.com>

Reviewers: Jiangjie (Becket) Qin <becket.qin@gmail.com>, Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2127 from jun-he/KAFKA-4384",2016-11-24 14:44:54,Jun He,Mixed
a5d28149fb67ab68d9de7d8de63c0de93b80a82c,"Revert ""KAFKA-4345; Run decktape test for each pull request""

This reverts commit e035fc039598127e88f31739458f705290b1fdba for the
following reasons:

1. License files are missing causing local builds to fail during the
rat task (rat is not being run in Jenkins for some reason, filed
KAFKA-4459 for that)
2. It renames a number of system test files when there's a better
way to achieve the goal of running a subset of system tests to stay
under the Travis limit.
3. It adds the gradle wrapper binary even though this was removed
intentionally a while back.

A new PR will be submitted for KAFKA-4345 without the undesired
changes.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2187 from ijuma/kafka-4345-revert",2016-11-29 09:11:21,Ismael Juma,Mixed
7d0f3e75ad2934b8ad5b84f81707b01285022523,"KAFKA-4427: Skip topic groups with no tasks

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #2171 from enothereska/KAFKA-4427-topicgroups-with-no-tasks",2016-11-29 11:07:39,Eno Thereska,Mixed
d98ca230a14b0aedae752fa97f5d55b3a0c49b9c,"KAFKA-4397: Refactor Connect backing stores for thread safety

Author: Konstantine Karantasis <konstantine@confluent.io>

Reviewers: Shikhar Bhushan <shikhar@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2123 from kkonstantine/KAFKA-4397-Refactor-connect-backing-stores-for-thread-safety",2016-11-29 15:31:14,Konstantine Karantasis,Mixed
5819b06fafd8a1a32276018560e0ff731191caf5,"KAFKA-4403; Update KafkaBasedLog to use new endOffsets consumer API

ewencp plz review

Author: Balint Molnar <balintmolnar91@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #2176 from baluchicken/KAFKA-4403",2016-11-29 19:04:24,Balint Molnar,Mixed
1503f7603c1d5e0511bf71175d84bde555c80e9a,"KAFKA-4387; KafkaConsumer should properly handle interrupts

See https://issues.apache.org/jira/browse/KAFKA-4387

Author: Stig Rohde Døssing <sdo@it-minds.dk>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #2110 from srdo/KAFKA-4387",2016-11-29 19:57:13,Stig Rohde Døssing,Mixed
ea42d65354b5905668d45dedae1cd1f7f39c888c,"KAFKA-3637: Added initial states

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Ismael Juma, Dan Norwood, Xavier Léauté, Damian Guy, Michael G. Noll, Matthias J. Sax, Guozhang Wang

Closes #2135 from enothereska/KAFKA-3637-streams-state",2016-11-30 22:23:31,Eno Thereska,Mixed
b65f9a777d46fbe4edfed8a4c7216dd1e741be53,"KAFKA-3008: Parallel start and stop of connectors and tasks in Connect

Author: Konstantine Karantasis <konstantine@confluent.io>
Author: Konstantine Karantasis <k.karantasis@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Shikhar Bhushan <shikhar@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1788 from kkonstantine/KAFKA-3008-Parallel-start-and-stop-of-connectors-and-tasks",2016-12-01 14:42:15,Konstantine Karantasis,Mixed
b45a67ede9021985c8df87c633b225231092c0c9,"KAFKA-4161: KIP-89: Allow sink connectors to decouple flush and offset commit

Author: Shikhar Bhushan <shikhar@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2139 from shikhar/kafka-4161-deux",2016-12-01 15:01:09,Shikhar Bhushan,Mixed
128d0ff91d84a3a1f5a5237133f9ec01caf18d66,"KAFKA-2247; Merge kafka.utils.Time and kafka.common.utils.Time

Also:
* Make all implementations of `Time` thread-safe as they are accessed from multiple threads in some cases.
* Change default implementation of `MockTime` to use two separate variables for `nanoTime` and `currentTimeMillis` as they have different `origins`.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Shikhar Bhushan <shikhar@confluent.io>, Jason Gustafson <jason@confluent.io>, Eno Thereska <eno.thereska@gmail.com>, Damian Guy <damian.guy@gmail.com>

Closes #2095 from ijuma/kafka-2247-consolidate-time-interfaces",2016-12-02 14:00:58,Ismael Juma,Mixed
b06fc322bf008f55bb8b14c5b02c9af5a90a92ed,"MINOR: Improvements in group metadata cleanup and test coverage

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma, Guozhang Wang

Closes #2202 from hachikuji/group-expiration-cleanup",2016-12-02 11:02:04,Jason Gustafson,Mixed
2d19ad4bb07b4f10f2a314e86bbf4171cdcd7765,"KAFKA-4205; KafkaApis: fix NPE caused by conversion to array

NPE was caused by `log.logSegments.toArray` resulting in array containing `null` values. The exact reason still remains somewhat a mystery to me, but it seems that the culprit is `JavaConverters` in combination with concurrent data structure access.

Here's a simple code example to prove that:
```scala
import java.util.concurrent.ConcurrentSkipListMap
// Same as `JavaConversions`, but allows explicit conversions via `asScala`/`asJava` methods.
import scala.collection.JavaConverters._

case object Value
val m = new ConcurrentSkipListMap[Int, Value.type]
new Thread { override def run() = { while (true) m.put(9000, Value) } }.start()
new Thread { override def run() = { while (true) m.remove(9000) } }.start()
new Thread { override def run() = { while (true) { println(m.values.asScala.toArray.headOption) } } }.start()
```

Running the example will occasionally print `Some(null)` indicating that there's something shady going on during `toArray` conversion.

`null`s magically disappear by making the following change:
```diff
- println(m.values.asScala.toArray.headOption)
+ println(m.values.asScala.toSeq.headOption)
```

Author: Anton Karamanov <ataraxer@yandex-team.ru>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>

Closes #2204 from ataraxer/KAFKA-4205",2016-12-04 10:51:16,Anton Karamanov,Not TDD
a55e2963116eb11252b957304b4f399eff3df9c2,"KAFKA-3994: Fix deadlock in Watchers by calling tryComplete without any locks

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma, Jun Rao, Jiangjie Qin, Guozhang Wang

Closes #2195 from hachikuji/KAFKA-3994-linked-queue",2016-12-05 11:12:03,Jason Gustafson,Mixed
34aa538bf3e0a38fe61de66a4536dfe48a6cdc57,"HOTFIX: Fix bug in readToLogEnd in KafkaBasedLog.

Author: Konstantine Karantasis <konstantine@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2211 from kkonstantine/HOTFIX-Correctly-read-to-end-of-offsets-log-in-Connect-KafkaBasedLog",2016-12-05 14:34:14,Konstantine Karantasis,Mixed
f4f0f8222276b630b61355b30827bf1b50160712,"KAFKA-4472; offsetRetentionMs miscalculated in GroupCoordinator

Fix possible integer overflow.

Author: Kim Christensen <kich@mvno.dk>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2200 from kichristensen/MiscalculatedOffsetRetention",2016-12-06 11:26:12,Kim Christensen,Mixed
a4592a18641f84a1983c5fe7e697a8b0ab43eb25,"KAFKA-4488: UnsupportedOperationException during initialization of StandbyTask

Instead of throwing `UnsupportedOperationException` from `StandbyTask.recordCollector()` return a No-op implementation of `RecordCollector`.
Refactored `RecordCollector` to have an interface and impl.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska, Guozhang Wang

Closes #2212 from dguy/standby-task",2016-12-06 11:49:54,Damian Guy,Mixed
e9a67a8daaf4be35f292dd06ae3c7797200658fa,"KAFKA-4492: Make the streams cache eviction policy tolerable to reentrant puts

The NamedCache wasn't correctly dealing with its re-entrant nature. This would result in the LRU becoming corrupted, and the above exception occurring during eviction. For example:
Cache A: dirty key 1
eviction runs on Cache A
Node for key 1 gets marked as clean
Entry for key 1 gets flushed downstream
Downstream there is a processor that also refers to the table fronted by Cache A
Downstream processor puts key 2 into Cache A
This triggers an eviction of key 1 again ( it is still the oldest node as hasn't been removed from the LRU)
As the Node for key 1 is clean flush doesn't run and it is immediately removed from the cache.
So now we have dirtyKey set with key =1, but the value doesn't exist in the cache.
Downstream processor tries to put key = 1 into the cache, it fails as key =1 is in the dirtyKeySet.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska, Guozhang Wang

Closes #2226 from dguy/cache-bug",2016-12-07 12:08:34,Damian Guy,Mixed
006630fd93d8efb823e5b5f7d61584138df984a6,"MINOR: Fix metric collection NPE during shutdown

Collecting socket server metrics during shutdown may throw NullPointerException

Author: Xavier Léauté <xavier@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2221 from xvrl/fix-metrics-npe-on-shutdown",2016-12-08 23:42:48,Xavier Léauté,Mixed
9bed8fbcfc52ced719f2dcafa3f30cbfd5e6bd57,"KAFKA-4393: Improve invalid/negative TS handling

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Michael G. Noll, Eno Thereska, Damian Guy, Guozhang Wang

Closes #2117 from mjsax/kafka-4393-improveInvalidTsHandling",2016-12-09 16:17:36,Matthias J. Sax,Mixed
8e9e1776790abb0a9b103f75d0231dd66d09e68f,"HOTFIX: Fix HerderRequest.compareTo()

With KAFKA-3008 (#1788), the implementation does not respect the contract that 'sgn(x.compareTo(y)) == -sgn(y.compareTo(x))'

This fix addresses the hang with JDK8 in DistributedHerderTest.compareTo()

Author: Shikhar Bhushan <shikhar@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2232 from shikhar/herderreq-compareto",2016-12-10 12:48:51,Shikhar Bhushan,Mixed
1d586cb50a94540f6b931a8d525ba75273f314f0,"KAFKA-4476: Kafka Streams gets stuck if metadata is missing

 - break loop in StreamPartitionAssigner.assign() in case partition metadata is missing
 - fit state transition issue (follow up to KAFKA-3637: Add method that checks if streams are initialised)
 - some test improvements

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Eno Thereska, Ismael Juma, Guozhang Wang

Closes #2209 from mjsax/kafka-4476-stuck-on-missing-metadata",2016-12-10 21:48:44,Matthias J. Sax,Mixed
62e043a86565cc9bc485658d6c6d176e9aff620f,"KAFKA-4140: Upgrade to ducktape 0.6.0 and make system tests parallel friendly

Updates to take advantage of soon-to-be-released ducktape features.

Author: Geoff Anderson <geoff@confluent.io>
Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1834 from granders/systest-parallel-friendly",2016-12-11 18:43:23,Geoff Anderson,Mixed
efeaf129890c2195b4753d5b9eece4f1b7cdf756,"KAFKA-4405; Avoid unnecessary network poll in consumer if no fetches sent

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #2193 from enothereska/KAFKA-4405-prefetch",2016-12-12 09:38:25,Eno Thereska,Mixed
21d7e6f19bd36a7ad16291294fc933f9abfac9b7,"KAFKA-4516: When a CachingStateStore is closed it should clear its associated NamedCache

Clear and remove the NamedCache from the ThreadCache when a CachingKeyValueStore or CachingWindowStore is closed.
Validate that the store is open when doing any queries or writes to Caching State Stores.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska, Guozhang Wang

Closes #2235 from dguy/kafka-4516",2016-12-12 18:00:00,Damian Guy,Mixed
67f1e5b91bf073151ff57d5d656693e385726697,"KAFKA-4390; Replace MessageSet usage with client-side alternatives

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>, Jun Rao <junrao@gmail.com>

Closes #2140 from hachikuji/KAFKA4390",2016-12-13 10:26:25,Jason Gustafson,Mixed
859113786957a36381222f21287a940767e92f1c,"KAFKA-4509: Task reusage on rebalance fails for threads on same host

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy, Guozhang Wang

Closes #2233 from mjsax/kafka-4509-task-reusage-fix",2016-12-13 12:11:09,Matthias J. Sax,Mixed
448f194c70e7a66ae2f1a7e89c822032359b14c9,"KAFKA-4532: StateStores can be connected to the wrong source topic resulting in incorrect metadata returned from Interactive Queries

When building a topology with tables and StateStores, the StateStores are mapped to the source topic names. This map is retrieved via TopologyBuilder.stateStoreNameToSourceTopics() and is used in Interactive Queries to find the source topics and partitions when resolving the partitions that particular keys will be in.
There is an issue where by this mapping for a table that is originally created with builder.table(""topic"", ""table"");, and then is subsequently used in a join, is changed to the internal repartition topic. This is because the mapping is updated during the call to topology.connectProcessorAndStateStores(..).
In the case that the stateStoreNameToSourceTopics Map already has a value for the state store name it should not update the Map.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax, Guozhang Wang

Closes #2250 from dguy/kafka-4532",2016-12-13 12:34:46,Damian Guy,Not TDD
ea724497a85e922af6acccd02d7e7466871fb339,"HOTFIX: Streams fix state transition stuck on rebalance

This fixes a problem where the Kafka instance state transition gets stuck on rebalance (Thanks to dguy for pointing out). Also adjusts the test in QueryableStateIntegration test.

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Damian Guy, Matthias J. Sax, Guozhang Wang

Closes #2252 from enothereska/hotfix_state_never_running",2016-12-15 09:44:09,Eno Thereska,Mixed
a9687bc0d8ddab27c83f7e6f3e87d9e74e32c8df,"KAFKA-4529; LogCleaner should not delete the tombstone too early.

cc junrao

Author: Jiangjie Qin <becket.qin@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #2260 from becketqin/KAFKA-4529-trunk",2016-12-15 11:14:41,Jiangjie Qin,Mixed
e36e8079d8a005550c5281ecebb4b7b622cc41b1,"KAFKA-4451; Fix OffsetIndex overflow when replicating a highly compacted topic. OffsetIndex provides checks for overflow, used when deciding to roll a LogSegment

Fix OffsetIndex overflow when replicating a highly compacted topic.
https://issues.apache.org/jira/browse/KAFKA-4451

Author: Michael Schiff <schiff.michael@gmail.com>
Author: Michael Schiff <michael.schiff@tubemogul.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #2210 from michaelschiff/bug/4451",2016-12-15 15:46:26,Michael Schiff,Mixed
233cd4b18af83e9f9eadfaf048cdaa1888faf546,"KAFKA-4537: StreamPartitionAssignor incorrectly adds standby partitions to the partitionsByHostState map

If a KafkaStreams app is using Standby Tasks then `StreamPartitionAssignor` will add the standby partitions to the partitionsByHostState map for each host. This is incorrect as the partitionHostState map is used to resolve which host is hosting a particular store for a key.
The result is that doing metadata lookups for interactive queries can return an incorrect host

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska, Matthias J. Sax, Guozhang Wang

Closes #2254 from dguy/KAFKA-4537",2016-12-15 16:49:35,Damian Guy,Mixed
056ed86600ebf884057ea24daafc9e3b1ab85b81,"KAFKA-4539: StreamThread is not correctly creating StandbyTasks

Tasks that don't have any `StateStore`s wont have a `StandbyTask`, so `createStandbyTask` can return `null`. We need to check for this in `StandbyTaskCreator.createTask(...)`

Also, the checkpointed offsets for `StandbyTask`s are never loaded.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska, Matthias J. Sax, Guozhang Wang

Closes #2255 from dguy/kafka-4539",2016-12-15 17:22:41,Damian Guy,Mixed
b58b6a1bef0ecdc2107a415e222af099fcd9bce3,"MINOR: Replace deepIterator/shallowIterator with deepEntries/shallowEntries

The latter return `Iterable` instead of `Iterator` so that enhanced foreach can be used
in Java.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #2261 from ijuma/deepEntries-shallowEntries",2016-12-16 10:41:27,Ismael Juma,Mixed
d6b0b520fc0755fa560af84f5fc4c9f86699739c,"KAFKA-3600; Use ApiVersions to check if broker supports required api versions

Author: Ashish Singh <asingh@cloudera.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Colin P. Mccabe <cmccabe@confluent.io>, Dana Powers <dana.powers@gmail.com>, Gwen Shapira <cshapi@gmail.com>, Grant Henke <granthenke@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1251 from SinghAsDev/KAFKA-3600",2016-12-17 04:24:15,Ashish Singh,Mixed
65acff32d195a2ac6e3d7ca4542702065417ba66,"KAFKA-4534: StreamPartitionAssignor only ever updates the partitionsByHostState and metadataWithInternalTopics on first assignment

partitionsByHostState and metadataWithInternalTopics need to be updated on each call to onAssignment() otherwise they contain invalid/stale metadata.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax, Guozhang Wang

Closes #2256 from dguy/4534",2016-12-19 12:22:37,Damian Guy,Mixed
bc9ef716af8ac387d63b22ee973a9fc6f864bebb,"KAFKA-4553; Improve round robin assignment in Connect to avoid uneven distributions of connectors and tasks

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Jason Gustafson <jason@confluent.io>

Closes #2272 from ewencp/kafka-4553-better-connect-round-robin",2016-12-19 12:37:58,Ewen Cheslack-Postava,Mixed
a786be94788816bbce32a6cd6ffcf8949ed95556,"KAFKA-4447; Controller resigned but it also acts as a controller for a long time

Author: Ismael Juma <ismael@juma.me.uk>
Author: xiguantiaozhan <kafkausr@126.com>
Author: tuyang <tuyang@meituan.com>

Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Onur Karaman <okaraman@linkedin.com>

Closes #2191 from xiguantiaozhan/avoid_swamp_controllerLog",2016-12-19 18:35:30,Json Tu,Not TDD
a5c15ba0374acbb43f69b1a556077e4ad53332e8,"KAFKA-4500; Code quality improvements

- Removed redundant modifiers, not needed String.format()
- Removed unnecessary semicolon, additional assignment, inlined return
- Using StringBuilder for consistency across codebase
- Using try-with-resources

Author: Rekha Joshi <rekhajoshm@gmail.com>
Author: Joshi <rekhajoshm@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2222 from rekhajoshm/KAFKA-4500",2016-12-20 12:40:07,Rekha Joshi,Not TDD
0321bf5aa67b52d7fab82a326b15ca8e058faee6,"KAFKA-4473: RecordCollector should handle retriable exceptions more strictly

The `RecordCollectorImpl` currently drops messages on the floor if an exception is non-null in the producer callback. This will result in message loss and violates at-least-once processing.
Rather than just log an error in the callback, save the exception in a field. On subsequent calls to `send`, `flush`, `close`, first check for the existence of an exception and throw a `StreamsException` if it is non-null. Also, in the callback, if an exception has already occurred, the `offsets` map should not be updated.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #2249 from dguy/kafka-4473",2016-12-20 09:59:25,Damian Guy,Mixed
56c61745deeadd299e5ef24577c1bdf5d9d231a0,"KAFKA-4540: Suspended tasks that are not assigned to the StreamThread need to be closed before new active and standby tasks are created

During `onPartitionsAssigned` first close, and remove, any suspended `StandbyTasks` that are no longer assigned to this consumer.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #2266 from dguy/kafka-4540",2016-12-20 10:30:33,Damian Guy,Mixed
3930dd7e7502ab94a7594a0ca41f27638663ae7c,"KAFKA-4554; Fix ReplicaBuffer.verifyChecksum to use iterators instead of iterables

This was changed in b58b6a1bef0 and caused the `ReplicaVerificationToolTest.test_replica_lags`
system test to start failing.

I also added a unit test and a couple of other minor clean-ups.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #2280 from ijuma/kafka-4554-fix-replica-buffer-verify-checksum",2016-12-20 11:01:46,Ismael Juma,Mixed
0f86dbe89da19ed1cc9142a5362cfa2fe3bc48ee,"MINOR: Support auto-incrementing offsets in MemoryRecordsBuilder

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2282 from hachikuji/builder-autoincrement-offsets",2016-12-21 00:07:10,Jason Gustafson,Mixed
68f204e01bb6fd8b9b6c56dff7a2b0daa448764d,"MINOR: Replace TopicAndPartition with TopicPartition in `Log` and `ReplicaManager`

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #2268 from ijuma/topicpartition-vs-topicandpartition",2016-12-20 16:36:32,Ismael Juma,Mixed
fc88bac66686ef963b5aec53a3eba717336e4ba7,"KAFKA-4485; Follower should be in the isr if its FetchRequest has fetched up to the logEndOffset of leader

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #2208 from lindong28/KAFKA-4485",2016-12-20 21:31:50,Dong Lin,Not TDD
9eb665c39af1950548f903ad959449f2e69d7671,"KAFKA-4259; Dynamic JAAS configuration for Kafka clients (KIP-85)

Implementation of KIP-85: https://cwiki.apache.org/confluence/display/KAFKA/KIP-85%3A+Dynamic+JAAS+configuration+for+Kafka+clients

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1979 from rajinisivaram/KAFKA-4259",2016-12-24 09:21:53,Rajini Sivaram,Mixed
d092146247f3b3de061ecdb4ddfeac9321d8cf73,"KAFKA-4527: task status was being updated before actual pause/resume

h/t ewencp for pointing out the issue

Author: Shikhar Bhushan <shikhar@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2277 from shikhar/kafka-4527",2016-12-24 17:25:01,Shikhar Bhushan,Mixed
4ca5abe8ee7578f602fb7653cb8a09640607ea85,"KAFKA-4092: retention.bytes should not be allowed to be less than segment.bytes

adding a LogConfig value validator.  gwenshap or junrao would you mind taking a look?

Author: Dustin Cote <dustin@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1796 from cotedm/retentionbytesvalidation",2016-12-27 15:02:22,Dustin Cote,Mixed
88a439ed8e78803ae47783c3e5a75d4e4cad2a77,"KAFKA-4549; Call writeBlock before writeEndMark in KafkaLZ4BlockOutputStream.close()

Author: MURAKAMI Masahiko <fossamagna2@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2265 from fossamagna/fix-lz4outputstream-close",2016-12-28 12:49:00,MURAKAMI Masahiko,Mixed
dc550259ea04011b22501c82dd6510a29b5a9b0f,"KAFKA-4428; Kafka does not exit if port is already bound

During Acceptor initialization, if ""Address already in use"" error is encountered,
the shutdown latch in each Processor is never counted down. Consequently,
the Kafka server hangs when `Processor.shutdown` is called.

Author: huxi <huxi@zhenrongbao.com>
Author: amethystic <huxi_2b@hotmail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2156 from amethystic/kafka-4428_Kafka_noexit_for_port_already_use",2016-12-28 17:34:31,huxi,Not TDD
29d456cd21d8f3430d52db50a8fd17cc8d700f36,"KAFKA-4351; MirrorMaker with new consumer should support comma-separated regex

This makes it consistent with MirrorMaker with the old consumer.

Author: huxi <huxi@zhenrongbao.com>
Author: amethystic <huxi_2b@hotmail.com>

Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2072 from amethystic/kafka-4351_Regex_behavior_change_for_new_consumer",2016-12-31 12:22:23,huxi,Not TDD
252e7e958a2fabfa680d23a00e7f0ce7c74f6ad8,"MINOR: Scala code readability improvements

Author: Himani Arora <1himani.arora@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2297 from himani1/refactored_code",2017-01-03 11:07:57,Himani Arora,Not TDD
cea2a669b34b2f94d445aace2b6e95e70af7e2f6,"KAFKA-4561; Ordering of operations in StreamThread.shutdownTasksAndState may void at-least-once guarantees

In `shutdownTasksAndState` and `suspendTasksAndState` we commit offsets BEFORE we flush any state. This is wrong as if an exception occurs during a flush, we may violate the at-least-once guarantees, that is we would have committed some offsets but NOT sent the processed data on to other Sinks.
Also during suspend and shutdown, we should try and complete all tasks even when exceptions occur. We should just keep track of the exception and rethrow it at the end if necessary. This helps with ensuring that StateStores etc are closed.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #2281 from dguy/kafka-4561",2017-01-03 08:34:15,Damian Guy,Mixed
9e9e6d8752646436cb836af03a8906605fa76471,"KAFKA-2434: Remove identical topic subscription constraint for roundrobin strategy in old consumer API

Author: Andrew Olson <aolson1@cerner.com>

Reviewers: Onur Karaman

Closes #145 from noslowerdna/KAFKA-2434",2017-01-03 08:57:30,Andrew Olson,Mixed
b565dd7eb184da5ef3b08c88a8acc3df221aaa08,"KAFKA-4429; Consumer lag metric should be zero if FetchResponse is empty

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Jason Gustafson <jason@confluent.io>

Closes #2155 from lindong28/KAFKA-4429",2017-01-03 13:54:40,Dong Lin,Mixed
6d6c77a7a9c102f7508e4bc48e0d6eba1fcbc9c6,"MINOR: Improvements to Record related classes (part 1)

Jason recently cleaned things up significantly by consolidating the Message/Record classes
into the common Java code in the clients module. While reviewing that, I noticed a few things
that could be improved a little more. To make reviewing easier, there will be multiple PRs.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Jason Gustafson <jason@confluent.io>

Closes #2271 from ijuma/records-minor-fixes",2017-01-03 19:53:20,Ismael Juma,Mixed
d62ef55252594bbfa1c26fab19207a9632f7bdd3,"KAFKA-4584: Fail the 'kafka-configs' command if the config to be removed does not exist

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #2300 from vahidhashemian/KAFKA-4584",2017-01-03 21:41:14,Vahid Hashemian,Mixed
0cd5afdb611d6d35009b9806be6bdf9874999bb3,"KAFKA-4508; System test that runs client against older versions of the broker

In reality, we’ll only test older brokers after KAFKA-4462 is fully implemented.

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Apurva Mehta <apurva.1618@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2263 from cmccabe/KAFKA-4508",2017-01-04 13:55:36,Colin P. Mccabe,Not TDD
d3572648b6c3524784fc3f60964a7f28817cbd55,"MINOR: Remove stray comma from PartitionInfo.toString

Removed the extra ',' character while printing the replicas / in-sync replicas
array.

Author: Kamal <kamal@nmsworks.co.in>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2306 from Kamal15/trunk",2017-01-05 10:26:02,Kamal,Mixed
2e1bcf661df8f22ee05f5bd883a8b501588fc4e2,"KAFKA-4575: ensure topic created before starting sink for ConnectDistributedTest.test_pause_resume_sink

Otherwise in this test the sink task goes through the pause/resume cycle with 0 assigned partitions, since the default metadata refresh interval is quite long

Author: Shikhar Bhushan <shikhar@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2313 from shikhar/kafka-4575",2017-01-05 15:25:00,Shikhar Bhushan,Not TDD
b7da847f6ae5786925d65a673b7e80f2de8fe389,"MINOR: Add unit tests to the ReassignPartitionsCommand

Adds a bunch of tests to unit tests to the assignment command.
Moves the Rack aware test into its own class as it makes use of ZooKeeperTestHarness and slows everything else down.

Author: Ben Stopford <benstopford@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #1950 from benstopford/os-rebalance-extra-unit-testing",2017-01-06 11:23:03,Ben Stopford,Mixed
e0de3a4211a3701c98230b115fadfb67b655e3cf,"KAFKA-3452: Support session windows

Add support for SessionWindows based on design detailed in https://cwiki.apache.org/confluence/display/KAFKA/KIP-94+Session+Windows.
This includes refactoring of the RocksDBWindowStore such that functionality common with the RocksDBSessionStore isn't duplicated.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska <eno.thereska@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #2166 from dguy/kafka-3452-session-merge",2017-01-06 10:12:30,Damian Guy,Mixed
10b330cf057a90038407a89fdb59d096da01bc55,"MINOR: cleanup Kafka Streams exception classes

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy, Guozhang Wang

Closes #2314 from mjsax/javaDocImprovements",2017-01-06 11:48:11,Matthias J. Sax,Not TDD
fa80093c067e6684e005bfd548770541b5b2778b,"KAFKA-4465: Create docker image and scripts for running tests locally

Author: Raghav Kumar Gautam <raghav@apache.org>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Sriharsha Chintalapani <harsha@hortonworks.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2197 from raghavgautam/trunk",2017-01-08 16:15:05,Raghav Kumar Gautam,Not TDD
42a6b7166348455482934f7845160d10cd435eaa,"KAFKA-4402: make the KafkaProducer true round robin per topic

Author: yaojuncn <yaojuncn@users.noreply.github.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Vahid Hashemian <vahidhashemian@us.ibm.com>, Konstantin <konstantin@tubemogul.com>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2128 from yaojuncn/KAFKA-4402-client-producer-round-robin-fix",2017-01-08 20:08:07,yaojuncn,Mixed
52e397962b624f3c881b6f99e71c94da32cf6a33,"KAFKA-4551: StreamsSmokeTest.test_streams intermittent failure

Remove use of TestTimestampExtractor as it causes the logs to roll and segments get deleted.
Remove the wcnt example as it is dependent on the TestTimestampExtractor - windowed counting is covered elsewhere.
Change all aggregate operations to use TimeWindow as use of UnlimitedWindow was causing logs to roll and segments being deleted.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax, Guozhang Wang, Eno Thereska

Closes #2319 from dguy/smoke-test",2017-01-09 11:13:09,Damian Guy,Not TDD
044b56b8b5106f5115de7054ac95e199f1b621ea,"MINOR: Add Replication Quotas Test Rig

This test rig lives in the other.kafka package so isn't part of our standard tests. It provides a convenient mechanism for measuring throttling performance over time. Measurements for each experiment are charted and presented to the user in an html file. The output looks like this:

**Experiment4**
- BrokerCount: 25
- PartitionCount: 100
- Throttle: 4,000,000 B/s
- MsgCount: 1,000
- MsgSize: 100,000
- TargetBytesPerBrokerMB: 400

![image](https://cloud.githubusercontent.com/assets/1297498/19070450/3251bc52-8a23-11e6-88fe-94de6b9147c2.png)
![image](https://cloud.githubusercontent.com/assets/1297498/19070467/4c19f38e-8a23-11e6-986a-ba19d16819ca.png)

Author: Ben Stopford <benstopford@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #1957 from benstopford/throttling-test-rig",2017-01-10 00:42:41,Ben Stopford,Not TDD
1fea1c390846673fd39452100e949be61c21b9ce,"MINOR: Remove unnecessary semi-colons

Author: Mickael Maison <mickael.maison@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2326 from mimaison/minor-fixes",2017-01-10 11:41:04,Mickael Maison,Not TDD
275c5e1df237808fe72b8d9933f826949d4b5781,"KAFKA-3751; SASL/SCRAM implementation

Implementation of KIP-84: https://cwiki.apache.org/confluence/display/KAFKA/KIP-84%3A+Support+SASL+SCRAM+mechanisms

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2086 from rajinisivaram/KAFKA-3751",2017-01-10 08:05:07,Rajini Sivaram,Mixed
fe82330f0be1d478b134732a9d29c229b37afe3b,"MINOR: rename SessionStore.findSessionsToMerge to findSessions

Rename `SessionStore.findSessionsToMerge` to `findSessions`

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #2339 from dguy/minor-findsession-rename",2017-01-10 09:38:30,Damian Guy,Mixed
a95170f822227c50414c57860e8547dc2e9d84cb,"KAFKA-4481: relax streams api type contraints

Make appropriate methods contravariant in key and value types.

Author: Xavier Léauté <xavier@confluent.io>

Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #2205 from xvrl/streams-contravariance",2017-01-11 09:11:18,Xavier Léauté,Mixed
4b71c0bdc1acf244e3c96fa809a1a0e48471d586,"KAFKA-4060: Remove zk client dependency in kafka streams

dguy guozhangwang This is a new PR for KAFKA-4060.

Author: Hojjat Jafarpour <hojjat@Hojjat-Jafarpours-MBP.local>
Author: Hojjat Jafarpour <hojjat@HojjatJpoursMBP.attlocal.net>

Reviewers: Damian Guy, Matthias J. Sax, Isamel Juma, Guozhang Wang

Closes #1884 from hjafarpour/KAFKA-4060-Remove-ZkClient-dependency-in-Kafka-Streams-new",2017-01-11 09:15:26,Hojjat Jafarpour,Mixed
3d60f1e64350710a5fd2a6036da353cc83195741,"KAFKA-4507; Clients should support older brokers (KIP-97)

The client should send older versions of requests to the broker if necessary.

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>, Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2264 from cmccabe/KAFKA-4507",2017-01-11 19:25:58,Colin P. Mccabe,Mixed
ecff8544dd45e8cf0fcf04f5e0e716d3e21c9f20,"KAFKA-3715: Add granular metrics to Kafka Streams and add hierarhical logging levels to Metrics

Kafka Streams: add granular metrics per node and per task, also expose ability to register non latency metrics in StreamsMetrics
Also added different recording levels to Metrics.

This is joint contribution from Eno Thereska and Aarti Gupta.

from https://github.com/apache/kafka/pull/1362#issuecomment-218326690-------
We can consider adding metrics for process / punctuate / commit rate at the granularity of each processor node in addition to the global rate mentioned above. This is very helpful in debugging.

We can consider adding rate / total cumulated metrics for context.forward indicating how many records were forwarded downstream from this processor node as well. This is helpful in debugging.

We can consider adding metrics for each stream partition timestamp.
This is helpful in debugging.
## Besides the latency metrics, we can also add throughput latency in terms of source records consumed.

More discussions here https://issues.apache.org/jira/browse/KAFKA-3715, KIP-104, KIP-105

Author: Eno Thereska <eno@confluent.io>
Author: Aarti Gupta <aartiguptaa@gmail.com>

Reviewers: Greg Fodor, Ismael Juma, Damian Guy, Guozhang Wang

Closes #1446 from aartigupta/trunk",2017-01-11 12:06:18,Eno Thereska,Mixed
f72203ee9223d3b724ee67bdad9912612dd72f63,"KAFKA-4426; Add close with timeout for KafkaConsumer (KIP-102)

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Apurva Mehta <apurva.1618@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #2285 from rajinisivaram/KAFKA-4426",2017-01-11 15:56:56,Rajini Sivaram,Mixed
6508e63c7ab1fbabb322754fabf41eb75bbbcec2,"KAFKA-4180; Support clients with different authentication credentials in the same JVM

Changed caching in LoginManager to allow one LoginManager per client
JAAS configuration.

Added test to End2EndAuthorization for SASL Plain and GSSAPI with two
consumers with different credentials.

Developed with mimaison.

Author: Edoardo Comar <ecomar@uk.ibm.com>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2293 from edoardocomar/KAFKA-4180d",2017-01-12 01:36:31,Edoardo Comar,Not TDD
23dff4b04a4c4cd338b5f39c9bb7d384857c482c,"KAFKA-4114: Allow different offset reset strategies

mjsax

Here's my first pass at finer grained auto offset reset strategies.

I've left TODO comments about whether we want to consider adding this to `KGroupedTable.aggregate` and `KStreamImpl` when re-partitioning a source.

Author: bbejeck <bbejeck@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #2007 from bbejeck/KAFKA-4114_allow_different_offset_reset_strategies",2017-01-11 20:30:47,Bill Bejeck,Mixed
3c60511655df3349323e394bdc3836300991352f,"KAFKA-3452; Follow-up: Add SessionWindows

 - TimeWindows represent half-open time intervals while SessionWindows represent closed time intervals

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #2342 from mjsax/kafka-3452-session-window-follow-up",2017-01-11 20:33:42,Matthias J. Sax,Mixed
8079c980ac5c9c00d7577fa05857b4de6864dbb5,"KAFKA-4490: Add Global Table support to Kafka Streams

Add Global Tables to KafkaStreams. Global Tables are fully replicated once-per instance of KafkaStreams. A single thread is used to update them. They can be used to join with KStreams, KTables, and other GlobalKTables. When participating in a join a GlobalKTable is only ever used to perform a lookup, i.e., it will never cause data to be forwarded to downstream processor nodes.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax, Eno Thereska, Guozhang Wang

Closes #2244 from dguy/global-tables",2017-01-12 11:46:02,Damian Guy,Mixed
2f904883237c476fd82a202f7ddda93fe56eef36,"KAFKA-3209: KIP-66: single message transforms

Besides API and runtime changes, this PR also includes 2 data transformations (`InsertField`, `HoistToStruct`) and 1 routing transformation (`TimestampRouter`).

There is some gnarliness in `ConnectorConfig` / `ConfigDef` around creating, parsing and validating a dynamic `ConfigDef`.

Author: Shikhar Bhushan <shikhar@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2299 from shikhar/smt-2017",2017-01-12 16:14:53,Shikhar Bhushan,Mixed
2eb32d6a70bcdef86bf87f9afd56b70de9df505e,"MINOR: Minor improvements in consumer close timeout handling

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2348 from hachikuji/minor-cleanup-for-kip-102",2017-01-13 02:31:19,Jason Gustafson,Mixed
8d9d847904e28759b44ffc87752802e8e6f1f659,"KAFKA-4581; Fail early if multiple client login modules in sasl.jaas.config

Validate and fail client connection if multiple login modules are specified in sasl.jaas.config to avoid harder-to-debug authentication failures later on.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2356 from rajinisivaram/KAFKA-4581",2017-01-13 10:34:15,Rajini Sivaram,Mixed
d25671884bbbdf7843ada3e7797573a00ac7cd56,"KAFKA-4565; Separation of Internal and External traffic (KIP-103)

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Gwen Shapira <cshapi@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #2354 from ijuma/kafka-4565-separation-of-internal-and-external-traffic",2017-01-13 10:00:06,Ismael Juma,Mixed
f6fee34a2d6315cd25855b9805e2f4129e24e5c3,"KAFKA-4627; Fix timing issue in consumer close tests

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Apurva Mehta <apurva.1618@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #2367 from rajinisivaram/KAFKA-4627",2017-01-13 11:09:26,Rajini Sivaram,Mixed
d1956d4b6c3ab30cba78bc6f6034ec20303e4801,"HOTFIX: Added another broker to smoke test

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #2362 from enothereska/hotfix-smoke-test-2-brokers",2017-01-13 11:11:17,Eno Thereska,Not TDD
fc0d612b0806032675b433a48f56ccd04f7e52cf,"KAFKA-3739: Add no-arg constructor for WindowedSerdes in Streams

Add default constructor for library provided serdes

Author: huxi <huxi@zhenrongbao.com>
Author: amethystic <huxi_2b@hotmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #2308 from amethystic/kafka3739_add_noarg_constructor_for_streaming_serdes",2017-01-13 11:13:16,Xi Hu,Not TDD
e90db3e3af0718a80d729809186d45076e71a241,"MINOR: Remove unnecessary store info from TopologyBuilder

This PR is extracted from https://github.com/apache/kafka/pull/2333 as an incremental fix to ease the reviewing:

1. Removed `storeToProcessorNodeMap` from ProcessorTopology since it was previously used to set the context current record, and can now be replaced with the dirty entry in the named cache.

2. Replaced `sourceStoreToSourceTopic` from ProcessorTopology with `storeToChangelogTopic` map, which includes the corresponding changelog topic name for all stores that are changelog enabled.

3. Modified `ProcessorStateManager` to rely on `sourceStoreToSourceTopic` when retrieving the changelog topic; this makes the second parameter `loggingEnabled` in `register` not needed any more, and we can deprecate the old API with a new one.

4. Also fixed a minor issue in `KStreamBuilder`: if the storeName is not provided in the `table(..)` function, do not create the underlying materialized store. Modified the unit tests to cover this case.

5. Fixed a bunch of other unit tests failures that are exposed by this refactoring, in which we are not setting the applicationId correctly when constructing the mocking processor topology.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Damian Guy, Matthias J. Sax, Ewen Cheslack-Postava

Closes #2338 from guozhangwang/KMinor-refactor-state-to-changelogtopic",2017-01-13 11:28:40,Guozhang Wang,Mixed
88fdca26a0881d12e9f3ba942cd580c8e8154025,"KAFKA-4381: Add per partition lag metrics to the consumer

Author: Jiangjie Qin <becket.qin@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2329 from becketqin/KAFKA-4381",2017-01-13 11:38:25,Jiangjie Qin,Mixed
c2d9b95f36a9bb853bb3851696161d7f7f790bec,"KAFKA-3853; Extend OffsetFetch API to allow fetching all offsets for a consumer group (KIP-88)

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>, Jason Gustafson <jason@confluent.io>

Closes #2074 from vahidhashemian/KAFKA-3853",2017-01-13 17:16:28,Vahid Hashemian,Mixed
da57bc27e7cb52cb1e817010ed5101188cbeb68e,"KAFKA-4591; Create Topic Policy (KIP-108)

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Apurva Mehta <apurva.1618@gmail.com>, Gwen Shapira <cshapi@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #2361 from ijuma/kafka-4591-create-topic-policy",2017-01-13 19:46:02,Ismael Juma,Mixed
b712b8675d6977a9171edc6569cf382ffcd91354,"KAFKA-4622; Consumer should handle group authorization errors in offset fetch

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #2384 from hachikuji/KAFKA-4622",2017-01-16 10:56:03,Jason Gustafson,Mixed
a8eb1d13e0d962ca3bb3f7708cbf92bd97b54ffd,"KAFKA-4619: Dissallow to output records with unknown keys in TransformValues

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy, Guozhang Wang

Closes #2346 from mjsax/kafka-4619-fixTransformValues",2017-01-16 11:24:20,Matthias J. Sax,Mixed
b62804a252b96932952006a483b3afd7da7363ab,"MINOR: Remove unused constructor param from ProcessorStateManager

Remove applicationId parameter as it is no longer used.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #2385 from dguy/minor-remove-unused-param",2017-01-16 11:40:47,Damian Guy,Mixed
55abe65e0996008d54bd5bb8440906ac4a359937,"KAFKA-4590; SASL/SCRAM system tests

Runs sanity test and one replication test using SASL/SCRAM.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #2355 from rajinisivaram/KAFKA-4590",2017-01-17 12:55:07,Rajini Sivaram,Not TDD
7a84b241eeb8cb63400a9512b066c3f733f94b8c,"MINOR: Some cleanups and additional testing for KIP-88

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2383 from hachikuji/minor-cleanup-kip-88",2017-01-17 10:42:05,Jason Gustafson,Not TDD
825f225bc5706b16af8ec44ca47ee1452c11e6f3,"KAFKA-4588: Wait for topics to be created in QueryableStateIntegrationTest.shouldNotMakeStoreAvailableUntilAllStoresAvailable

After debugging this i can see the times that it fails there is a race between when the topic is actually created/ready on the broker and when the assignment happens. When it fails `StreamPartitionAssignor.assign(..)` gets called with a `Cluster` with no topics. Hence the test hangs as no tasks get assigned. To fix this I added a `waitForTopics` method to `EmbeddedKafkaCluster`. This will wait until the topics have been created.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax, Guozhang Wang

Closes #2371 from dguy/integration-test-fix",2017-01-17 12:33:11,Damian Guy,Not TDD
73b7ae0019d387407375f3865e263225c986a6ce,"KAFKA-3452 Follow-up: Refactoring StateStore hierarchies

This is a follow up of https://github.com/apache/kafka/pull/2166 - refactoring the store hierarchies as requested

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #2360 from dguy/state-store-refactor",2017-01-17 14:13:46,Damian Guy,Mixed
e3bdc84d864a5ca655f985473770f7b7cb24b79b,"MINOR: remove ZK from system tests

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #2391 from mjsax/kafka-4060-zk-follow-up-system-tests",2017-01-17 18:14:43,Matthias J. Sax,Not TDD
fd6d7bcf335166a524dc9a29a50c96af8f1c1c02,"KAFKA-4591; Create Topic Policy follow-up

1. Added javadoc to public classes
2. Removed `s` from config name for consistency with interface name
3. The policy interface now implements Configurable and AutoCloseable as per the KIP
4. Use `null` instead of `-1` in `RequestMetadata`
5. Perform all broker validation before invoking the policy
6. Add tests

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #2388 from ijuma/create-topic-policy-docs-and-config-name-change",2017-01-18 02:43:10,Ismael Juma,Mixed
1974e1b0e54abe5fdebd8ff3338df864b7ab60f3,"KAFKA-3502; move RocksDB options construction to init()

In RocksDBStore, options / wOptions / fOptions are constructed in the constructor, which needs to be dismissed in the close() call; however in some tests, the generated topology is not initialized at all, and hence the corresponding state stores are supposed to not be able to be closed as well since their `init` function is not called. This could cause the above option objects to be not released.

This is fixed in this patch to move the logic out of constructor and inside `init` functions, so that no RocksDB objects will be created in the constructor only. Also some minor cleanups:

1. In KStreamTestDriver.close(), we lost the logic to close the state stores but only call `flush`; it is now changed back to call both.
2. Moved the forwarding logic from KStreamTestDriver to MockProcessorContext to remove the mutual dependency: these functions should really be in ProcessorContext, not the test driver.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Jason Gustafson <jason@confluent.io>

Closes #2381 from guozhangwang/K3502-pure-virtual-function-unit-tests",2017-01-17 20:31:31,Guozhang Wang,Not TDD
4c492975a05e4a646f7140c560ed403c48925331,"KAFKA-4568; Simplify test code for multiple SASL mechanisms

Remove workaround for testing multiple SASL mechanisms using
sasl.jaas.config and the new support for multiple client
modules within a JVM.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Sriharsha Chintalapani <harsha@hortonworks.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2373 from rajinisivaram/KAFKA-4568",2017-01-18 11:06:14,Rajini Sivaram,Not TDD
961ebca57fdd4f8f84df8cf26a835f07ea1718c9,"HOTFIX: ChangeLoggingKeyValueStore.name() returns null

This class doesn't need to override this method as it is handled appropriately by the super class

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #2397 from dguy/hotfix-npe-state-store",2017-01-18 09:19:06,Damian Guy,Mixed
d8a77560c2fa2c209353e3ba2366ad3d4cfdf22c,"MINOR: refactor streams system test class hierachy

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Eno Thereska, Guozhang Wang

Closes #2392 from mjsax/minor-system-test-rework",2017-01-18 11:55:23,Matthias J. Sax,Not TDD
4a6f2c6cc0647a08f016a2d712a01ec02630cf87,"KAFKA-4457; Add BrokerApiVersionsCommand

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Apurva Mehta <apurva.1618@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2184 from cmccabe/KAFKA-4457",2017-01-18 23:44:11,Colin P. Mccabe,Mixed
8e2cbae8b12cd71f99f13953b744163f68021323,"KAFKA-4060; Follow-up: Throw exceptions when internal topics to create already exist with unexpected number of partitions

Re-branched the trunk and applied the changes to the new branch to simplify commit log.

Author: Hojjat Jafarpour <hojjat@Hojjat-Jafarpours-MBP.local>

Reviewers: Ismael Juma, Damian Guy, Eno Thereska, Guozhang Wang

Closes #2389 from hjafarpour/KAFKA-4060-Remove-ZkClient-dependency-in-Kafka-Streams-followup-from-trunk

Address Ismael's comments upon merging",2017-01-18 15:54:15,Hojjat Jafarpour,Mixed
813897a00653351710d37acbbb598235e86db824,"KAFKA-4547; Avoid incorrect reset of paused partitions to the committed offsets

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #2341 from vahidhashemian/KAFKA-4547",2017-01-19 16:35:12,Vahid Hashemian,Mixed
a8aa75616602363847848f004fd0b1a36d0de78c,"KAFKA-3209: KIP-66: more single message transforms

Renames `HoistToStruct` SMT to `HoistField`.

Adds the following SMTs:
`ExtractField`
`MaskField`
`RegexRouter`
`ReplaceField`
`SetSchemaMetadata`
`ValueToKey`

Adds HTML doc generation and updates to `connect.html`.

Author: Shikhar Bhushan <shikhar@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2374 from shikhar/more-smt",2017-01-20 16:15:15,Shikhar Bhushan,Mixed
0b99bea590842018e8e97e7fd1c71b1471db4d08,"KAFKA-4060 and KAFKA-4476 follow up: remove unnecessary InternalTopicManager branch and fixed one copartitioning bug

ZK removed reveal a bug in `StreamPartitionAssigner` but did not fix it properly. This is a follow up bug fix.

Issue:
 - If topic metadata is missing, `StreamPartitionAssigner` should not create any affected tasks that consume topics with missing metadata.
 - Depending downstream tasks should not be create either.
 - For tasks that are not created, no store changelog topics (if any) should get created
 - For tasks that write output to not-yet existing internal repartitioning topics, those repartitioning topics should not get created

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy, Guozhang Wang

Closes #2404 from mjsax/kafka-4060-zk-test-follow-up",2017-01-21 13:18:39,Matthias J. Sax,Mixed
1eb1e2f60ae006144757fc9fc10ab423c58970bb,"MINOR: Pass RecordingLevel to MetricConfig in the broker

This is a KIP-104/105 follow-up. Thanks to ijuma for pointing out.

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2350 from enothereska/minor-broker-level-config",2017-01-23 15:16:57,Eno Thereska,Mixed
dd897bdb2e9cc8790d1e0494fb7867a5cd09ecc6,"HOTFIX: KAFKA-4060 and KAFKA-4476 follow up

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy, Guozhang Wang

Closes #2418 from mjsax/kafka-4060-zk-test-follow-up",2017-01-23 09:34:52,Matthias J. Sax,Mixed
3400d0c3cc07d5d3136bf9a19142b36cca93f92d,"KAFKA-4633; Always using regex pattern subscription in StreamThread

1. In StreamThread, always use subscribe(Pattern, ..) function in order to avoid sending MetadataRequest with specific topic names and cause brokers to possibly auto-create subscribed topics; the pattern is generated as ""topic-1|topic-2..|topic-n"".

2. In ConsumerCoordinator, let the leader to refresh its metadata if the generated assignment contains some topics that is not contained in the subscribed topics; also in SubscriptionState, modified the verification for regex subscription to against the regex pattern instead of the matched topics since the returned assignment may contain some topics not yet created when joining the group but existed after the rebalance; also modified some unit tests in `KafkaConsumerTest` to accommodate the above changes.

3. Minor cleanup: changed String[] to List<String> to avoid overloaded functions.

4. Minor cleanup: enforced strong typing in SinkNodeFactory and removed unnecessary unchecked tags.

5. Minor cleanup: augmented unit test error message and fixed a potential transient failure in KafkaStreamTest.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Jason Gustafson <jason@confluent.io>

Closes #2379 from guozhangwang/K4633-regex-pattern",2017-01-23 10:45:45,Guozhang Wang,Mixed
79987590e3e96351ff75ce86718801ec605b2419,"KAFKA-4671: Fix Streams window retention policy

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy, Eno Thereska, Guozhang Wang

Closes #2401 from mjsax/kafka-4671-window-retention-policy",2017-01-23 16:31:36,Matthias J. Sax,Mixed
337f576f5979bf8924c5707b338cf4d3c76a53fd,"KAFKA-4576; Log segments close to max size break on fetch

`FileChannel.read` may not fill the destination buffer even if there
are enough bytes in the channel to do so. Add a couple of utility
methods that ensure this and use them from all the relevant places.

Author: huxi <huxi@zhenrongbao.com>
Author: amethystic <huxi_2b@hotmail.com>
Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #2304 from amethystic/kafka4576_FileChannel_read",2017-01-24 11:02:20,huxi,Mixed
7837d3e54850fc6ecd16f9bc4dd28a02779572c2,"KAFKA-3896: Fix KStreamRepartitionJoinTest

The root cause of this issue is that in InternalTopicManager we are creating topics one-at-a-time, and for this test, there are 31 topics to be created, as a result it is possible that the consumer could time out during the assignment in rebalance, and the next leader has to do the same again because of ""makeReady"" calls are one-at-a-time.

This patch batches the topics into a single create request and also use the StreamsKafkaClient directly to fetch metadata for validating the created topics. Also optimized a bunch of inefficient code in InternalTopicManager and StreamsKafkaClient.

Minor cleanup: make the exception message more informative in integration tests.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Damian Guy, Matthias J. Sax, Jason Gustafson

Closes #2405 from guozhangwang/K3896-fix-kstream-repartition-join-test",2017-01-24 12:00:35,Guozhang Wang,Mixed
8dfb8afb93f3f1026f868466edb66a4cc63b4455,"KAFKA-4687; Fix InvalidTopicException due to topic creation race condition

We now throw the correct TopicExistsException instead.

Author: Andrew Olson <aolson1@cerner.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #2425 from noslowerdna/KAFKA-4687",2017-01-24 20:24:18,Andrew Olson,Mixed
abe19fe693d81ea65a018041f157c58ebecd014d,"KAFKA-3835; Streams is creating two ProducerRecords for each send via RecordCollector

Author: Jeyhun Karimov <je.karimov@gmail.com>

Reviewers: Matthias J. Sax, Guozhang Wang

Closes #2417 from jeyhunkarimov/KAFKA-3835",2017-01-24 16:36:31,Jeyhun Karimov,Mixed
448c1a4114798892bef60d44199a07a86fc4505a,"HOTIFX: streams system test do not start up correctly

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Guozhang Wang, Damian Guy, Eno Thereska

Closes #2428 from mjsax/hotfixSystemTests",2017-01-24 19:36:08,Matthias J. Sax,Not TDD
b8c3b7c964c6167be7f8ad72c96733dfa0d648a2,"KAFKA-4596; Throttled reassignment should support partial JSON file

Fixes a logic error in the Reassignment process which throws an exception
if you don't rebalance all partitions.

Author: Ben Stopford <benstopford@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2399 from benstopford/KAFKA-4596",2017-01-25 12:38:47,Ben Stopford,Mixed
b22a4f0782d0f4d3e07075403e8e5dc318d8d387,"KAFKA-2000; Delete topic should also delete consumer offsets.

Author: Manikumar Reddy O <manikumar.reddy@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Sriharsha Chintalapani <harsha@hortonworks.com>

Closes #1850 from omkreddy/KAFKA-2700-DELETE",2017-01-25 08:17:50,Manikumar Reddy O,Not TDD
2ca3e59bb6054cc8ecf6926a74859efe3df000ba,"KAFKA-3502: KStreamTestDriver needs to be closed after the test case

Found a few recently added unit tests did not close KStreamTestDriver after the test itself is closed; this can cause RocksDB virtual function called if the contained topology has some persistent store since they will be initialized but not closed in time.

MINOR fix: found that when closing KStreamTestDriver, we need to first flushing all stores before closing any of them; this is triggered from the `KTableKTableLeftJoin.shouldNotThrowIllegalStateExceptionWhenMultiCacheEvictions`.

MINOR fix: in CachingXXXStore, the `name` field is actually used as the cache's namespace, not really the store name or its corresponding topic name. Fixed it by renaming it to `cacheName` and use `this.name()` elsewhere which will call the underlying store's name.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Ewen Cheslack-Postava, Eno Thereska, Damian Guy

Closes #2432 from guozhangwang/K3502-kstream-builder-test",2017-01-25 11:11:21,Guozhang Wang,Not TDD
0971e62e50b94a74aae170fb49d1e532e39b2136,"HOTFIX: KIP-104 follow-up: remove duplicated per-processor-node throughput metrics, and also rename some other sensors

This is the HOTFIX PR for any issues detected with KIP-104 until code freeze. Note: do not merge until close to code freeze.

The name changes reflect feedback received while writing the documentation.

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Dan Norwood, Guozhang Wang

Closes #2398 from enothereska/hotfix-streams-metrics",2017-01-25 11:40:17,Eno Thereska,Mixed
8b3c6c0a1c1bb8f098a7013dbf9c2cb97720e106,"KAFKA-4597; RecordMetadata should return log append time when appropriate

There is a slight change of behaviour: we now complete the `Future` returned from `send`
before the callbacks are invoked. This seems OK and perhaps a little better as the `Future`
can make progress sooner (as it would typically be blocked on a different thread than the
I/O thread that invokes the callbacks).

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Jason Gustafson <jason@confluent.io>

Closes #2318 from ijuma/kafka-4597-record-metadata-log-append-time",2017-01-25 17:25:10,Ismael Juma,Mixed
135488352cbe646334a274418d7014a91e92057f,"MINOR: Refactor partition lag metric for cleaner encapsulation

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2416 from hachikuji/refactor-partition-lag-cleanup",2017-01-26 02:53:59,Jason Gustafson,Mixed
5b4e299a46a8ee92e450c54880408713606e4f52,"KAFKA-4630; Implement RecordTooLargeException when communicating with pre-KIP-74 brokers

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #2390 from cmccabe/KAFKA-4630",2017-01-26 11:19:32,Colin P. Mccabe,Mixed
254e3b77d656a610f19efd1124802e073dfda4b8,"KAFKA-4699; Invoke producer callbacks before completing the future

This behaviour was changed in 8b3c6c0, but it caused interceptor
test failures (which rely on callbacks) and since we’re so close to
code freeze, it’s better to be conservative.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #2440 from ijuma/kafka-4699-callbacks-invoked-before-future-is-completed",2017-01-26 09:50:25,Ismael Juma,Not TDD
8301cc608e0e3c334da96b546bf6d943a1704024,"HOTFIX: Consumer offsets not properly loaded on coordinator failover

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2436 from hachikuji/hotfix-offset-deletion",2017-01-26 20:52:54,Jason Gustafson,Not TDD
31716590454e1bdd53a65836741f316bf4715c9d,"KAFKA-4700: Don't drop security configs in `StreamsKafkaClient`

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Eno Thereska, Damian Guy, Guozhang Wang

Closes #2441 from ijuma/streams-kafka-client-drops-security-configs",2017-01-26 14:18:54,Ismael Juma,Mixed
ca0c071c108c9fd31a759e1cd1c4f89bdc5ac47e,"KAFKA-4636; Per listener security settings overrides (KIP-103)

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #2406 from ijuma/kafka-4636-per-listener-security-settings",2017-01-27 01:24:56,Ismael Juma,Mixed
2f9e9195abada7c2bcbd41147cb9d4c00f3a712d,"MINOR: Close create topics policy during shutdown and more tests

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #2443 from ijuma/close-create-topics-policy-during-shutdown",2017-01-26 21:27:44,Ismael Juma,Not TDD
89fb02aa81fe67f5a506f579e463f30f3020dee5,"MINOR: Add Streams system test for broker backwards compatibility

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy, Eno Thereska, Guozhang Wang

Closes #2403 from mjsax/addStreamsClientCompatibilityTest",2017-01-26 21:46:37,Matthias J. Sax,Not TDD
662c2f893c95128a9d5033f730f1538d368fd151,"KAFKA-4644: Improve test coverage of StreamsPartitionAssignor

Some exception paths not previously covered. Extracted `ensureCopartitioning` into a static class.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #2448 from dguy/KAFKA-4644",2017-01-27 08:47:19,Damian Guy,Mixed
9213de8f14dfd2754d913667ae9a703f76277022,"MINOR: Replace for within for each; replace if-elseif with match

In some Places for the loop was used but it can be replaced by the for each.
In One file if else if else was used so I replaced the same with match.

Author: Akash Sethi <akash.sethi@knoldus.in>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #2435 from akashsethi24/trunk",2017-01-27 09:45:01,Akash Sethi,Not TDD
57f0cb29973bb40e76ed6deb64b934b4b2e0592a,"KAFKA-4704; Coordinator cache loading fails if groupId is reused for offset storage after group is removed

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2455 from hachikuji/KAFKA-4704",2017-01-27 20:30:00,Jason Gustafson,Mixed
aef6927a42cde193dd6acc36cd4d9f32167da622,"KAFKA-4557; Handle Producer.send correctly in expiry callbacks

When iterating deque for expiring record batches, delay the
invocation of the callback and deallocation until iteration is
complete since callbacks invoked during expiry may send more
records, modifying the deque, resulting in a
ConcurrentModificationException in the iterator.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #2449 from rajinisivaram/KAFKA-4557",2017-01-27 23:26:24,Rajini Sivaram,Mixed
4c42654b1eecebae272dfe5ce018b85ad4db7709,"MINOR: update JavaDocs for Kafka Streams DSL helpers

 - also deprecate ZK config for Streams

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Ismael Juma, Guozhang Wang

Closes #2459 from mjsax/javaDocImprovements8",2017-01-27 16:48:44,Matthias J. Sax,Not TDD
8827a5b34ed2a2a570219fb8f29d955918867796,"KAFKA-4635; Client Compatibility follow-ups

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #2414 from cmccabe/KAFKA-4635",2017-01-28 01:08:46,Colin P. Mccabe,Mixed
6264cc155757216c878bcce48e02099a9f5a7d6f,"KAFKA-4450; Add upgrade tests for 0.10.1 and rename TRUNK to DEV_BRANCH to reduce confusion

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2457 from ewencp/kafka-4450-upgrade-tests",2017-01-28 01:40:34,Ewen Cheslack-Postava,Mixed
b559846f2f8151e41a6259e8a570b9422932c836,"KAFKA-4613: Treat null-key records the same way for joins and aggreations

Author: Jeyhun Karimov <je.karimov@gmail.com>

Reviewers: Matthias J. Sax, Eno Thereska, Damian Guy, Guozhang Wang

Closes #2420 from jeyhunkarimov/KAFKA-4613",2017-01-30 15:14:49,Jeyhun Karimov,Mixed
5afe959647fcad9d01365427f4b455e1586b1fd5,"MINOR: Logging improvements in consumer internals

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Manikumar reddy O <manikumar.reddy@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #2469 from hachikuji/improve-consumer-logging",2017-01-31 12:27:00,Jason Gustafson,Mixed
0b48ea1c81f22465cf32a19c012e0fb3c849afcc,"KAFKA-4677: Avoid unnecessary task movement across threads during rebalance

Makes task assignment more sticky by preferring to assign tasks to clients that had previously had the task as active task. If there are no clients with the task previously active, then search for a standby. Finally falling back to the least loaded client.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax, Guozhang Wang

Closes #2429 from dguy/kafka-4677",2017-01-31 20:16:47,Damian Guy,Mixed
063d534c5160316cdf22e476d128e872a1412783,"KAFKA-3959: enforce offsets.topic.replication.factor upon __consumer_offsets auto topic creation (KIP-115)

Kafka brokers have a config called ""offsets.topic.replication.factor"" that specify the replication factor for the ""__consumer_offsets"" topic. The problem is that this config isn't being enforced. If an attempt to create the internal topic is made when there are fewer brokers than ""offsets.topic.replication.factor"", the topic ends up getting created anyway with the current number of live brokers. The current behavior is pretty surprising when you have clients or tooling running as the cluster is getting setup. Even if your cluster ends up being huge, you'll find out much later that __consumer_offsets was setup with no replication.

The cluster not meeting the ""offsets.topic.replication.factor"" requirement on the internal topic is another way of saying the cluster isn't fully setup yet.

The right behavior should be for ""offsets.topic.replication.factor"" to be enforced. Topic creation of the internal topic should fail with GROUP_COORDINATOR_NOT_AVAILABLE until the ""offsets.topic.replication.factor"" requirement is met. This closely resembles the behavior of regular topic creation when the requested replication factor exceeds the current size of the cluster, as the request fails with error INVALID_REPLICATION_FACTOR.

Author: Onur Karaman <okaraman@linkedin.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2177 from onurkaraman/KAFKA-3959",2017-02-01 19:55:06,Onur Karaman,Not TDD
76550dd8956b07f24713f10992fc15aeedabe2c9,"KAFKA-4719: Consumption timeout should take into account producer request timeout

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2479 from hachikuji/KAFKA-4719",2017-02-02 10:49:11,Jason Gustafson,Mixed
cb674e5487f3f56647546b323dfe4fd45ccf0186,"KAFKA-4039; Fix deadlock during shutdown due to log truncation not allowed

Author: Maysam Yabandeh <myabandeh@dropbox.com>
Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #2474 from ijuma/kafka-4039-deadlock-during-shutdown",2017-02-02 22:23:49,Maysam Yabandeh,Mixed
ea70a9bcfc8a9ce317e8fa9b8cc4f7cb1aba26a9,"MINOR: Ensure timestamp type is provided when up-converting messages

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2483 from hachikuji/minor-upconvert-timestamp-safety",2017-02-02 22:34:53,Jason Gustafson,Mixed
d95f22c12c36a92f9c71a78cabf897d65ddef65f,"KAFKA-4646: Improve test coverage AbstractProcessorContext

Exception paths in `register()`, `topic()`, `partition()`, `offset()`, and `timestamp()`, were not covered by any existing tests

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska, Matthias J. Sax

Closes #2447 from dguy/KAFKA-4646",2017-02-03 09:15:56,Damian Guy,Mixed
7ebc5da606fb806bde8b7176fed0e60243e0f7f3,"KAFKA-3452 Follow-up: Optimize ByteStore Scenarios

This is a refactoring follow-up of https://github.com/apache/kafka/pull/2166. Main refactoring changes:

1. Extract `InMemoryKeyValueStore` out of `InMemoryKeyValueStoreSupplier` and remove its duplicates in test package.

2. Add two abstract classes `AbstractKeyValueIterator` and `AbstractKeyValueStore` to collapse common functional logics.

3. Added specialized `BytesXXStore` to accommodate cases where key value types are Bytes / byte[] so that we can save calling the dummy serdes.

4. Make the key type in `ThreadCache` from byte[] to Bytes, as SessionStore / WindowStore's result serialized bytes are in the form of Bytes anyways, so that we can save unnecessary `Bytes.get()` and `Bytes.wrap(bytes)`.

Each of these should arguably be a separate PR and I apologize for the mess, this is because this branch was extracted from a rather large diff that has multiple refactoring mingled together and dguy and myself have already put lots of efforts to break it down to a few separate PRs, and this is the only left-over work. Such PR won't happen in the future.

Ping dguy enothereska mjsax for reviews

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Damian Guy, Matthias J. Sax, Jun Rao

Closes #2333 from guozhangwang/K3452-followup-state-store-refactor",2017-02-03 11:12:49,Guozhang Wang,Mixed
d0932b0286d8e69a704211aeaba9fa9503c0fb42,"KAFKA-4558; throttling_test fails if the producer starts too fast

With this change, the consumer will be considered initialized in the
ProduceConsumeValidate tests once its partitions have been assigned.

Author: Apurva Mehta <apurva.1618@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2347 from apurvam/KAFKA-4588-fix-race-between-producer-consumer-start",2017-02-05 10:29:44,Apurva Mehta,Not TDD
7de22453bbd05a7ac629543e09626ac6987ce306,"KAFKA-4724: Clean up of state directories can possibly remove stores that are about to be used by another thread

Delay the cleanup of state directories that are not locked and not owned by the current thread such that we only remove the directory if its last modified is < now - cleanupDelayMs.
This also helps to avoid a race between threads on the same instance, where during rebalance, one thread releases the lock on the state directory, and before another thread can take the lock, the cleanup runs and removes the data.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax, Guozhang Wang

Closes #2486 from dguy/KAFKA-4724",2017-02-06 11:03:26,Damian Guy,Mixed
48aec6ef1e8065bd14e54172d6443144fb80738b,"KAFKA-4441; Monitoring incorrect during topic creation and deletion

OfflinePartitionsCount PreferredReplicaImbalanceCount metrics check for
topic being deleted

Added integration test which polls the metrics while topics are being
created and deleted

Developed with mimaison

Author: Edoardo Comar <ecomar@uk.ibm.com>

Reviewers: Dong Lin <lindong28@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #2325 from edoardocomar/KAFKA-4441",2017-02-06 12:23:24,Edoardo Comar,Not TDD
6cef4f5e4c3a73911a43378caf5cfc2736814333,"KAFKA-4734; Trim the time index on old segments

Author: Jiangjie Qin <becket.qin@gmail.com>

Reviewers: Dong Lin <lindong28@gmail.com>, Jun Rao <junrao@gmail.com>

Closes #2501 from becketqin/KAFKA-4734",2017-02-07 08:43:02,Jiangjie Qin,Mixed
b621703706118b383153da60937c1d31d518d5b8,"KAFKA-4648: Improve test coverage StreamTask

Provide test coverage for exception paths in: `schedule()`, `closeTopology()`, and `punctuate()`

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax, Guozhang Wang

Closes #2451 from dguy/kafka-4640",2017-02-08 11:26:45,Damian Guy,Mixed
13a82b48cab5f13feeb9d3597b24d26416eb4033,"KAFKA-4702: Parametrize streams benchmarks to run at scale

Author: Eno Thereska <eno.thereska@gmail.com>
Author: Eno Thereska <eno@confluent.io>
Author: Ubuntu <ubuntu@ip-172-31-22-146.us-west-2.compute.internal>

Reviewers: Matthias J. Sax, Guozhang Wang

Closes #2478 from enothereska/minor-benchmark-args",2017-02-08 13:06:09,Eno Thereska,Not TDD
b865a8b1dcae642b80280b8a7b5e23e82666061b,"KAFKA-4716: send create topics to controller in internaltopicmanager

This PR fixes a blocker issue, where the streams client code cannot talk to the controller. It also enables a system test that was previously failing.

This PR is for trunk only. A separate PR with just the fix (but not the tests) will be created for 0.10.2.

Author: Eno Thereska <eno@confluent.io>
Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Damian Guy, Ismael Juma, Matthias J. Sax, Guozhang Wang

Closes #2522 from enothereska/KAFKA-4716-metadata",2017-02-09 14:01:13,Eno Thereska,Mixed
b5dd39dda68e8bab555eea1b80de8f969f8641ea,"KAFKA-4525; Kafka should not require SSL truststore password

Author: Grant Henke <ghenke@cloudera.com>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2246 from granthenke/truststore-password",2017-02-10 02:57:35,Grant Henke,Mixed
9898d665d1ab201405d66c70e3ea9710d9dcecd7,"MINOR: Use an explicit `Errors` object when possible instead of a numeric error code

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #2475 from vahidhashemian/minor/use_explicit_Errors_type_when_possible",2017-02-09 21:03:46,Vahid Hashemian,Mixed
8bc9d583930110cf209f8ab20f9ff640ace3ed35,"KAFKA-4340; Change default message.timestamp.difference.max.ms to the same as log.retention.ms

Author: Jiangjie Qin <becket.qin@gmail.com>
Author: Jiangjie (Becket) Qin <becket.qin@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2071 from becketqin/KAFKA-4340",2017-02-11 21:33:55,Jiangjie Qin,Not TDD
5dabca02594e4b71fb6ff275283a3851f1c62d60,"KAFKA-4758; Connect missing checks for NO_TIMESTAMP

Author: rnpridgeon <ryan.n.pridgeon@gmail.com>

Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Jason Gustafson <jason@confluent.io>

Closes #2533 from rnpridgeon/no_timestamp",2017-02-12 16:06:33,rnpridgeon,Mixed
ed91af512fcb5c0ea3032ed259451817c96b5ee1,"KAFKA-4756; The auto-generated broker id should be passed to MetricRe…

…porter.configure

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #2540 from cmccabe/KAFKA-4756",2017-02-13 13:46:37,Colin P. Mccabe,Not TDD
3b36d5cff0b7a51e737a97144d6d479af708b2d7,"KAFKA-4761; Fix producer regression handling small or zero batch size

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva.1618@gmail.com>, Vahid Hashemian <vahidhashemian@us.ibm.com>, Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>

Closes #2545 from hachikuji/KAFKA-4761",2017-02-13 14:07:19,Jason Gustafson,Mixed
cb725c6a2d21651fe8b2e50225635209aa949bb5,"KAFKA-4720: Add a KStream#peek(ForeachAction<K, V>) in DSL

https://issues.apache.org/jira/browse/KAFKA-4720

Peek is a handy method to have to insert diagnostics that do not affect the stream itself, but some external state such as logging or metrics collection.

Author: Steven Schlansker <sschlansker@opentable.com>

Reviewers: Damian Guy, Matthias J. Sax, Eno Thereska, Guozhang Wang

Closes #2493 from stevenschlansker/kafka-4720-peek",2017-02-15 21:20:49,Steven Schlansker,Mixed
6c839395b7b43d8e9c0dfbb3c12470fc9284a94a,"KAFKA-4709：Error message from Struct.validate() should include the name of the offending field.

https://issues.apache.org/jira/browse/KAFKA-4709

Author: Aegeaner <xihuke@gmail.com>

Reviewers: Dong Lin, Guozhang Wang

Closes #2521 from Aegeaner/KAFKA-4709",2017-02-16 13:44:08,Aegeaner,Mixed
022d2017a781286d223d80d8eae505fbc3fb369c,"MINOR: Move compression stream construction into CompressionType

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2536 from hachikuji/minor-move-compression-io-construction",2017-02-16 15:22:55,Jason Gustafson,Not TDD
a88737929e880d5c6892a306d3c9b1358853b76b,"KAFKA-4775; Fix findbugs warnings in kafka-tools

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2559 from cmccabe/KAFKA-4775",2017-02-17 01:46:14,Colin P. Mccabe,Not TDD
1f2ee5f0a9dfc33e34362f7cd4ac45edaabe421b,"KAFKA-4340; Follow-up fixing system test failures and handling non default log.retention.ms

Author: Jiangjie Qin <becket.qin@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2544 from becketqin/KAFKA-4340_follow_up",2017-02-17 02:40:34,Jiangjie Qin,Mixed
fc1cfe475e8ae8458d8ddf119ce18d0c64653a70,"MINOR: Remove Struct from Request/Response classes

More details:
* Replaced `struct` field in Request/Response with a `toStruct` method. This
makes the performance model (including memory usage) easier to understand.
Note that requests have `toStruct()` while responses have `toStruct(version)`.
* Replaced mutable `version` field in `Request.Builder` with an immutable
field `desiredVersion` and a `version` parameter passed to the `build` method.
* Optimised `handleFetchRequest` to avoid unnecessary creation of `Struct`
instances (from 4 to 2 in the worst case and 2 to 1 in the best case).
* Various clean-ups in request/response classes and their test. In particular,
it is now clear what we are testing. Previously, it looked like we were testing
more than we really were.

With this in place, we could remove `AbstractRequest.Builder` in the future by
doing the following:
* Change `AbstractRequest.toStruct` to accept a version (like responses).
* Change `AbstractRequest.version` to be `desiredVersion` (like `Builder`).
* Change `ClientRequest` to take `AbstractRequest`.
* Move validation from the `build` methods to the request constructors or
static factory methods.
* Anything else required for the code to compile again.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Apurva Mehta <apurva.1618@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #2513 from ijuma/separate-struct",2017-02-17 14:19:01,Ismael Juma,Mixed
1f1e794ad0025bb2a33b7d8378a481f224b3bccc,"KAFKA-4317: Regularly checkpoint StateStore changelog offsets

Currently the checkpoint file is deleted at state store initialization and it is only ever written again during a clean shutdown. This can result in significant delays during restarts as the entire store needs to be loaded from the changelog.
We can mitigate against this by frequently checkpointing the offsets. The checkpointing happens only during the commit phase, i.e, after we have manually flushed the store and the producer. So we guarantee that the checkpointed offsets are never greater than what has been flushed.
In the event of hard failure we can recover by reading the checkpoints and consuming from the stored offsets.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska, Matthias J. Sax, Guozhang Wang

Closes #2471 from dguy/kafka-4317",2017-02-17 14:41:28,Damian Guy,Mixed
e41e782006d807a1ca8098dbfb95b8ab2295d6af,"KAFKA-4776; Implement graceful handling for improperly formed compressed message sets

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Jiangjie Qin <becket.qin@gmail.com>

Closes #2572 from hachikuji/KAFKA-4776",2017-02-19 20:53:19,Jason Gustafson,Mixed
3b8b7a4be39cb4a3f7257f8a17f74a887572e627,"MINOR: Fix NPE handling unknown APIs in NodeApiVersions.toString

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #2561 from hachikuji/fix-npe-api-version-tostring",2017-02-21 13:52:18,Jason Gustafson,Mixed
8bd06482d0562a518bce67dd06c590da4391d12a,"MINOR: Remove unused MessageWriter and CompressionFactory

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #2543 from hachikuji/remove-message-writer",2017-02-21 14:02:17,Jason Gustafson,Mixed
913c09e4a94447a953cb55ccd702d7131d1764a8,"KAFKA-4708; Fix transient failure in BrokerApiVersionsCommandTest.checkBrokerApiVersionCommandOutput

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>, Dong Lin <lindong28@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2489 from cmccabe/KAFKA-4708",2017-02-22 11:05:04,Colin P. Mccabe,Mixed
015f1d73811e52b3b7a578cf4c1ca4c48b6c2f5c,"MINOR: Move ProtoUtils methods to ApiKeys

Also move `requireTimestamp` to `minVersion` logic from `Fetcher` to
`ListOffsetRequest.Builder.forConsumer()`.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Jason Gustafson <jason@confluent.io>

Closes #2580 from ijuma/move-proto-utils-to-api-keys",2017-02-22 15:11:12,Ismael Juma,Mixed
5a2abc51821fab4d3834b615e577d97e0f0e6494,"KAFKA-4788: Revert ""KAFKA-4092: retention.bytes should not be allowed to be less than segment.bytes""

The intent is good, but it needs to take into account broker configs as well.
See KAFKA-4788 for more details.

This reverts commit 4ca5abe8ee7578f602fb7653cb8a09640607ea85.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #2588 from ijuma/kafka-4788",2017-02-23 16:28:38,Ismael Juma,Mixed
1ed4b48d5a43af743229fafc22f78846c9c3134d,"KAFKA-4198; Fix race condition in KafkaServer.shutdown()

It contained this step:

      val canShutdown = isShuttingDown.compareAndSet(false, true)
      if (canShutdown && shutdownLatch.getCount > 0) {

without any fallback for the case of `shutdownLatch.getCount == 0`. So in the case
of `shutdownLatch.getCount == 0` (when a previous call to the shutdown method
was right about to finish) you would set `isShuttingDown` to true again without any
possibility of ever getting the server started (since `startup` will check
`isShuttingDown` before setting up a new latch with count 1).

Long story short: concurrent calls to shutdown can get the server locked in a broken state.

This fixes the reported error:

java.lang.IllegalStateException: Kafka server is still shutting down, cannot re-start!
	at kafka.server.KafkaServer.startup(KafkaServer.scala:184)
	at kafka.integration.KafkaServerTestHarness$$anonfun$restartDeadBrokers$2.apply$mcVI$sp(KafkaServerTestHarness.scala:117)
	at kafka.integration.KafkaServerTestHarness$$anonfun$restartDeadBrokers$2.apply(KafkaServerTestHarness.scala:116)
	at kafka.integration.KafkaServerTestHarness$$anonfun$restartDeadBrokers$2.apply(KafkaServerTestHarness.scala:116)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.immutable.Range.foreach(Range.scala:160)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.integration.KafkaServerTestHarness$class.restartDeadBrokers(KafkaServerTestHarness.scala:116)
	at kafka.api.ConsumerBounceTest.restartDeadBrokers(ConsumerBounceTest.scala:34)
	at kafka.api.ConsumerBounceTest$BounceBrokerScheduler.doWork(ConsumerBounceTest.scala:158)

Author: Armin Braun <me@obrown.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2568 from original-brownbear/KAFKA-4198",2017-02-24 12:02:53,Armin Braun,Not TDD
2a7b18a2ac1213b189df8585671b713373dae383,"KAFKA-4779; Fix security upgrade system test to be non-disruptive

The phase_two security upgrade test verifies upgrading inter-broker and client protocols to the same value as well as different values. The second case currently changes inter-broker protocol without first enabling the protocol, disrupting produce/consume until the whole cluster is updated. This commit changes the test to be a non-disruptive upgrade test that enables protocols first (simulating phase one of upgrade).

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Apurva Mehta <apurva.1618@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2589 from rajinisivaram/KAFKA-4779",2017-02-24 17:24:07,Rajini Sivaram,Not TDD
151b23689ea1c2e13a1d38f403bf5839eddbe377,"KAFKA-4494: Reduce startup and rebalance time by batching restoration of stores

Replace one-by-one initialization of state stores with bulk initialization.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska, Guozhang Wang

Closes #2560 from dguy/kafka-4494",2017-02-24 10:34:21,Damian Guy,Mixed
5b22b53f0e581e3239ca6bbeceec6c01ce0f8ce0,"MINOR: Fix potential integer overflow and String.format issue

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Apurva Mehta <apurva.1618@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #2585 from ijuma/overflow-and-format-fixes",2017-02-24 16:41:51,Ismael Juma,Mixed
f3fab2e476cf5101ba6ae68e4d61ae9ab957b26c,"KAFKA-4809: docker/run_tests.sh should set up /opt/kafka-dev to be the source directory

…0.x and not 0.8

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2602 from cmccabe/KAFKA-4809",2017-02-28 12:21:46,Colin P. Mccabe,Not TDD
d0e436c471ba4122ddcc0f7a1624546f97c4a517,"MINOR: improve license header check by providing head file instead of (prefix) header regex

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2303 from mjsax/licenseHeader",2017-02-28 12:35:04,Matthias J. Sax,Mixed
de05c9d3a0d79a555088afe9344b52e002d287f2,"MINOR: Add code quality checks (and suppressions) to checkstyle.xml

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ewen Cheslack-Postava <me@ewencp.org>, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #2594 from dguy/checkstyle",2017-02-28 22:57:57,Damian Guy,Not TDD
0fba529608a5eb829feb66a499c89ead40b79694,"KAFKA-4677 Follow Up: add optimization to StickyTaskAssignor for rolling rebounce

Detect when a rebalance has happened due to one or more existing nodes bouncing. Keep assignment of previous active tasks the same and only assign the tasks that were not active to the new clients.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #2609 from dguy/kstreams-575",2017-03-01 11:21:41,Damian Guy,Mixed
b380a82d5be7c68141590467911ecb61db45ed1e,"MINOR: improve MinTimestampTrackerTest and fix NPE when null element removed

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax, Guozhang Wang

Closes #2611 from dguy/testing",2017-03-01 12:07:46,Damian Guy,Mixed
ef92bb4e00da10728cf74c2d81f8f2bbec4c9c02,"MINOR: Minor reduce unnecessary calls to time.millisecond (part 2)

Avoid calling time.milliseconds more often than necessary. Cleaning and committing logic can use the timestamp at the start of the loop with minimal consequences. 5-10% improvements noticed with request rates of 450K records/second.

Also tidy up benchmark code a bit more.

Author: Eno Thereska <eno.thereska@gmail.com>
Author: Eno Thereska <eno@confluent.io>

Reviewers: Matthias J. Sax, Damian Guy, Guozhang Wang

Closes #2603 from enothereska/minor-reduce-milliseconds2",2017-03-01 14:36:08,Eno Thereska,Mixed
ca06862a7005ca476f900bd9c2373021422d695b,"KAFKA-2358: Cluster collection returning methods never return null

See https://issues.apache.org/jira/browse/KAFKA-2358

Author: Stevo Slavic <sslavic@gmail.com>

Reviewers: Jason Gustafson, Guozhang Wang

Closes #96 from sslavic/feature/KAFKA-2358",2017-03-02 13:12:59,Stevo Slavic,Mixed
a3c45b0c9263ca4481b1af7af3f7d8ae8cb5d5cd,"KAFKA-4631; Request metadata in consumer if topic/partitions unavailable

If leader node of one more more partitions in a consumer subscription are temporarily unavailable, request metadata refresh so that partitions skipped for assignment dont have to wait for metadata expiry before reassignment. Metadata refresh is also requested if a subscribe topic or assigned partition doesn't exist.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #2622 from rajinisivaram/KAFKA-4631",2017-03-02 17:49:10,Rajini Sivaram,Mixed
573a6f39863061a6f38a0aca35f11470c3e8538e,"KAFKA-2857; Retry querying the consumer group while initializing

This applies to new-consumer based groups and would avoid scenarios in which user issues a `--describe` query while the group is initializing.
Example: The following could occur for a newly created group.
```
kafkakafka:~/workspace/kafka$ bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group g
Note: This will only show information about consumers that use the Java consumer API (non-ZooKeeper-based consumers).

Error: Executing consumer group command failed due to The group coordinator is not available.
```

With this PR the group is queried repeatedly at specific intervals within a preset (and configurable) timeout `group-init-timeout` to circumvent unfortunate situations like above.

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #2538 from vahidhashemian/KAFKA-2857",2017-03-03 12:01:38,Vahid Hashemian,Not TDD
4b1415c109fa75a01a11460aa80f0404baecac51,"MINOR: Fix tests/docker/Dockerfile

Fix tests/docker/Dockerfile to put the old Kafka distributions in the
correct spot for tests.  Also, run_tests.sh should exit with an error
code if image rebuilding fails, rather than silently falling back to an
older image.

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2613 from cmccabe/dockerfix",2017-03-03 16:40:25,Colin P. Mccabe,Not TDD
d9b784e1470714c8b04e7c3d74f626a96ca1591e,"KAFKA-4796; Fix some findbugs warnings in Kafka Java client

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2593 from cmccabe/KAFKA-4796",2017-03-04 00:52:26,Colin P. Mccabe,Mixed
b7378d567fffd06395f5babc36cebd64bdf539d1,"MINOR: Standardised benchmark params for consumer and streams

There were some minor differences in the basic consumer config and streams config that are now rectified. In addition, in AWS environments the socket size makes a big difference to performance and I've tuned it up accordingly. I've also increased the number of records now that perf is higher.

Author: Eno Thereska <eno@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #2634 from enothereska/minor-standardize-params",2017-03-04 20:55:16,Eno Thereska,Not TDD
580bebe09798b8f0062a2a1566a1d5836ecad4bb,"KAFKA-4826: Fix some findbugs warnings in Kafka Streams

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Matthias J. Sax, Guozhang Wang

Closes #2623 from cmccabe/KAFKA-4826",2017-03-05 10:01:30,Colin P. Mccabe,Mixed
f111f2a7167f3abcb0b0e53ac22f9f7bb367766e,"MINOR: additional refactoring around the use of Errors

A couple of updates were missed in the [PR](https://github.com/apache/kafka/pull/2475) that replaced the use of error codes with Errors objects.

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2635 from vahidhashemian/minor/Errors_refactoring_leftover",2017-03-06 10:46:04,Vahid Hashemian,Not TDD
63010cbfe5d07df5db060888afd348fab5cbe62c,"KAFKA-4266; ReassignPartitionsClusterTest: ensure ZK publication is completed before start

Increase the reliability of the one temporal comparison in ReassignPartitionsClusterTest by imposing a delay after ZK is updated. This should be more reliable than just increasing the amount of data.

This relates to a previous PR: https://github.com/apache/kafka/pull/1982

Author: Ben Stopford <benstopford@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #1997 from benstopford/KAFKA-4266",2017-03-06 13:12:28,Ben Stopford,Mixed
5cf491c2765b4912ff5f7f69f0b992a67005b983,"KAFKA-3155; Avoid long overflow in RecordBatch#maybeExpire

`Long.MaxValue` for the linger overflows in `RecordBatch#maybeExpire` when added to
the current timestamp.

Then causes an error to be set for the batch by `Sender` (not happening every time since
it depends on the timing of `Sender`):

That error then causes a call to `ProduceRequestResult#done` on the batch, which then
makes the check for ""not done"" fail.

Author: Armin Braun <me@obrown.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2639 from original-brownbear/KAFKA-3155",2017-03-06 20:29:37,Armin Braun,Mixed
81f9e1376cefed57022de62cd3abf5641c46e4aa,"MINOR: Rename RecordBatch to ProducerBatch to free the name for KIP-98

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva.1618@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2646 from hachikuji/rename-record-batch",2017-03-07 01:30:01,Jason Gustafson,Mixed
f7354e779cb058985dd385b2b1209db71eb7a5e8,"MINOR: Add varint serde utilities for new message format

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2647 from hachikuji/add-varint-serdes",2017-03-08 22:25:58,Jason Gustafson,Mixed
294018a578cbbc187ac123a6b99990468186e349,"KAFKA-4864; added correct zookeeper nodes for security migrator

Author: simplesteph <stephane.maarek@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #2655 from simplesteph/fix-security-migrator-tool",2017-03-08 21:41:38,simplesteph,Not TDD
65650ba4dcba8a9729cb9cb6477a62a7b7c3714e,"MINOR: Introduce NetworkClient.hasInFlightRequests

It’s a minor optimisation, but simple enough.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Apurva Mehta <apurva.1618@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #2658 from ijuma/has-in-flight-requests",2017-03-09 09:27:33,Ismael Juma,Mixed
7565dcd8b0547f91a5d9d19771d9cd6693079d01,"KAFKA-4861; GroupMetadataManager record is rejected if broker configured with LogAppendTime

The record should be created with CreateTime (like in the producer). The conversion to
LogAppendTime happens automatically (if necessary).

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #2657 from ijuma/kafka-4861-log-append-time-breaks-group-data-manager",2017-03-09 16:45:41,Ismael Juma,Mixed
dfa2ef4837259cd127b013e63ce26acdec8b94c5,"KAFKA-4738: Remove generic type of class ClientState

Remove generic type of class ClientState and generic T inTaskAssignor.

Author: sharad.develop <sharad.develop@gmail.com>

Reviewers: Matthias J. Sax, Guozhang Wang

Closes #2616 from sharad-develop/KAFKA-4738",2017-03-10 11:28:06,sharad.develop,Mixed
cd69daa4150631e9cea4e299c5ea08e12359118d,"KAFKA-4769: Add Float serializer, deserializer, serde

Author: Michael G. Noll <michael@confluent.io>

Reviewers: Dongjin Lee, Eno Thereska, Damian Guy, Colin P. McCabe, Matthas J. Sax, Guozhang Wang

Closes #2554 from miguno/KAFKA-4769",2017-03-13 11:49:49,Michael G. Noll,Not TDD
9e4548df30d50a56ae99cb3383f1a3f97bbe77bb,"KAFKA-4863; Querying window store may return unwanted keys

Make sure that the iterator returned from `WindowStore.fetch(..)` only returns matching keys, rather than all keys that are a prefix match.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska, Guozhang Wang

Closes #2662 from dguy/kafka-4863",2017-03-14 14:21:03,Damian Guy,Mixed
52a15d7c0b88da11409954321463b8b57b133a23,"KAFKA-4783: Add ByteArrayConverter (KIP-128)

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #2599 from ewencp/kafka-4783-byte-array-converter",2017-03-14 17:20:49,Ewen Cheslack-Postava,Mixed
962c378cc6cdb178541155af419c24e463516a5d,"HOTFIX: Fix header in ByteArrayConverter

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Manikumar reddy O <manikumar.reddy@gmail.com>

Closes #2690 from ijuma/fix-header-in-byte-array-converter",2017-03-15 14:46:32,Ismael Juma,Mixed
1659ca1773596b5889fe8b2f163196f7b32ea70a,"KAFKA-4901; Make ProduceRequest thread-safe

If request logging is enabled, `ProduceRequest` can be accessed
and mutated concurrently from a network thread (which calls
`toString`) and a request handler thread (which calls
`clearPartitionRecords()`).

That can lead to a `ConcurrentModificationException` when iterating
the `partitionRecords` map.

The underlying thread-safety issue has existed since the server
started using the Java implementation of ProduceRequest in 0.10.0.
However, we were incorrectly not clearing the underlying struct until
0.10.2, so `toString` itself was thread-safe until that change. In 0.10.2,
`toString` is no longer thread-safe and we could potentially see a
`NullPointerException` given the right set of interleavings between
`toString` and `clearPartitionRecords` although we haven't seen that
happen yet.

In trunk, we changed the requests to have a `toStruct` method
instead of creating a struct in the constructor and `toString` was
no longer printing the contents of the `Struct`. This accidentally
fixed the race condition, but it meant that request logging was less
useful.

A couple of days ago, `AbstractRequest.toString` was changed to
print the contents of the request by calling `toStruct().toString()`
and reintroduced the race condition. The impact is more visible
because we iterate over a `HashMap`, which proactively
checks for concurrent modification (unlike arrays).

We will need a separate PR for 0.10.2.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Onur Karaman <okaraman@linkedin.com>, Jun Rao <junrao@gmail.com>

Closes #2689 from ijuma/produce-request-thread-safety",2017-03-16 09:13:58,Ismael Juma,Not TDD
b8fe2bb56c25715de1602c1f00ab720af085f2e5,"KAFKA-4885: Add client.close as exception handler in streams system tests

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Eno Thereska, Damian Guy, Jason Gustafson

Closes #2693 from guozhangwang/K4885-system-test-unexpected-exception-handler",2017-03-16 22:33:50,Guozhang Wang,Not TDD
ec8feb766f0fc560200a326941632033600c141e,"KAFKA-4895; Fix findbugs ""format string should use %n rather than \n"" in tools

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #2684 from cmccabe/KAFKA-4895",2017-03-17 13:59:40,Colin P. Mccabe,Not TDD
9e787716b013595851b4a6c1ddf8b8af1ec0f42e,"KAFKA-4607: Validate the names of auto-generated internal topics

I considered catching errors to add further information about naming internal state stores. However, Topic.validate() will throw an error that prints the offending name, so I decided not to add too much complexity.

Author: Nikki Thean <nthean@etsy.com>

Reviewers: Matthias J. Sax, Guozhang Wang, Eno Thereska, Damian Guy, Ismael Juma

Closes #2331 from nixsticks/internal-topics",2017-03-17 12:03:02,Nikki Thean,Mixed
783900c259511f86f5af03cbd96f2e74833447b9,"MINOR: Guard against NPE when throwing StreamsException on serializer mismatch

Author: Michael G. Noll <michael@confluent.io>

Reviewers: Damian Guy, Guozhang Wang

Closes #2696 from miguno/trunk-sinknode-NPE",2017-03-17 15:18:06,Michael G. Noll,Mixed
5a2fcdd6d480e9f003cc49a59d5952ba4c515a71,"KAFKA-4894; Fix findbugs ""default character set in use"" warnings

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #2683 from cmccabe/KAFKA-4894",2017-03-20 13:52:35,Colin P. Mccabe,Not TDD
fef7fca2af7fd00bc6b0889062da3f8b56b2224e,"KAFKA-4594; Annotate integration tests and provide gradle build targets to run subsets of tests

This uses JUnit Categories to identify integration tests. Adds 2 new build targets:
`integrationTest` and `unitTest`.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska <eno@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #2695 from dguy/junit-categories",2017-03-21 10:12:36,Damian Guy,Not TDD
c74eec96c5e8828a88df67f6eb21d2369b340a22,"KAFKA-4863 Follow-up: Querying window store may return unwanted keys

iterate over all keys returned from the rocksdb iterator so we don't miss any results

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Xavier Léauté, Guozhang Wang

Closes #2713 from dguy/window-iter",2017-03-21 16:11:50,Damian Guy,Mixed
d5cec01f2aeb37823d1a158683da0809a0c54818,"MINOR: Pluggable verifiable clients

This adds support for pluggable VerifiableConsumer and VerifiableProducers test client implementations
allowing third-party clients to be used in-place of the Java client in kafkatests.

A new VerifiableClientMixin class is added and the standard Java Verifiable{Producer,Consumer}
classes have been changed to use it.

While third-party client drivers may be implemented with a complete class based on the Mixin, a simpler
alternative which requries no kafkatest class implementation is available through the VerifiableClientApp class that uses ducktape's global param to specify the client app to use (passed to ducktape through the `--globals <json>` command line argument).

Some existing kafkatest clients for reference:
Go: https://github.com/confluentinc/confluent-kafka-go/tree/master/kafkatest
Python: https://github.com/confluentinc/confluent-kafka-python/tree/master/confluent_kafka/kafkatest
C++: https://github.com/edenhill/librdkafka/blob/0.9.2.x/examples/kafkatest_verifiable_client.cpp
C#/.NET: https://github.com/confluentinc/confluent-kafka-dotnet/tree/master/test/Confluent.Kafka.VerifiableClient

This PR also contains documentation for the simplex JSON-based verifiable\* client protocol.

There are also some minor improvements that makes troubleshooting failing client tests easier.

Author: Magnus Edenhill <magnus@edenhill.se>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2048 from edenhill/pluggable_verifiable_clients",2017-03-21 22:24:17,Magnus Edenhill,Mixed
57278aa82da5dc9d040eb3dcf4a182e0731a621b,"MINOR: Improvements on Streams log4j

1. add thread id as prefix in state directory classes; also added logs for lock activities.
2. add logging for task creation / suspension.
3. add more information in rebalance listener logging.
4. add restored number of records into changlog reader.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Eno Thereska, Damian Guy, Ewen Cheslack-Postava

Closes #2702 from guozhangwang/KMinor-streams-task-creation-log4j-improvements",2017-03-22 14:33:34,Guozhang Wang,Mixed
2269eed242d9ccd4cc3e9ae3211d01f166f6e234,"KAFKA-4919: Document that stores must not be closed when Processors are closed

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Michael G. Noll, Eno Thereska, Matthias J. Sax, Elias Levy, Guozhang Wang

Closes #2725 from dguy/minor-processor-java-doc",2017-03-23 09:47:45,Damian Guy,Not TDD
5bd06f1d542e6b588a1d402d059bc24690017d32,"KAFKA-4816; Message format changes for idempotent/transactional producer (KIP-98)

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Jun Rao <junrao@gmail.com>, Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2614 from hachikuji/exactly-once-message-format",2017-03-24 19:38:43,Jason Gustafson,Mixed
d348ac92c80b6426864e3ed68b89bad341b3bda5,"MINOR: Fix deserialization of abortedTransactions and lastStableOffset in FetchResponse

Thanks to Dong Lin for finding the lastStableOffset issue.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Dong Lin <lindong28@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #2737 from ijuma/fix-fetch-response-lso",2017-03-25 14:03:40,Ismael Juma,Not TDD
1abed91bd2915226cf6320395e1a5877ea0705d7,"KAFKA-4881: add internal leave.group.on.close config to consumer

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Ismael Juma, Guozhang Wang

Closes #2650 from dguy/consumer-leave-group-config",2017-03-27 10:30:38,Damian Guy,Mixed
f3f9a9eafb9aee9d87dd188521a4fd72466abfeb,"KAFKA-4569; Check for wakeup on every call to KafkaConsumer.poll

Author: Armin Braun <me@obrown.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #2699 from original-brownbear/KAFKA-4569",2017-03-27 16:05:15,Armin Braun,Mixed
8b05ad406d4cba6a75d1683b6d8699c3ab28f9d6,"KAFKA-4586; Add purgeDataBefore() API (KIP-107)

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jiangjie Qin <becket.qin@gmail.com>

Closes #2476 from lindong28/KAFKA-4586",2017-03-28 09:59:44,Dong Lin,Mixed
a0b8e435c9419a9402d08408260bea0c1d95cff0,"MINOR: Support streaming decompression of fetched records for new format

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #2738 from hachikuji/streaming-compressed-iterator",2017-03-28 17:47:10,Jason Gustafson,Mixed
42284960dab4724445a4a3a7831b3b48f0ddcb48,"KAFKA-4903; Remove dead code in Shell

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2692 from cmccabe/KAFKA-4903",2017-03-29 16:10:19,Colin P. Mccabe,Mixed
6feaa8a581daaa76ff7c85e4a0b9c9aa4284fe99,"KAFKA-1449; Use CRC32C for checksum of V2 message format

I manually tested that Crc32CTest and AbstractChecksums pass with JDK 9. I also verified that `Java9ChecksumFactory` is used in that case.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #2739 from ijuma/kafka-1449-crc32c",2017-03-29 11:10:43,Ismael Juma,Mixed
84a14fec299749a208251bce1a0eb9c1a8241d08,"KAFKA-4843: More efficient round-robin scheduler

- Improves streams efficiency by more than 200K requests/second (small 100 byte requests)
- Gets streams efficiency very close to pure consumer (see results in https://jenkins.confluent.io/job/system-test-kafka-branch-builder/746/console)

- Maintains same fairness across tasks
- Schedules all records in the queue in-between poll() calls, not just one per task.

Author: Eno Thereska <eno@confluent.io>
Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Damian Guy, Matthias J. Sax, Guozhang Wang

Closes #2643 from enothereska/minor-schedule-round-robin",2017-03-29 15:00:26,Eno Thereska,Mixed
c808e8955f23c551c86ec0f51683c88486ad394e,"MINOR: FetchRequest.Builder maxBytes for version <3

The maxBytes field should be set to DEFAULT_RESPONSE_MAX_BYTES,
the same way as the constructor using the Struct does.

codeveloped with mimaison

Author: Edoardo Comar <ecomar@uk.ibm.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2694 from edoardocomar/MINOR-FetchRequest",2017-03-30 12:33:59,Edoardo Comar,Not TDD
43fb2df7a4b2bc7637dcba9436a5435cdcb4fb27,"MINOR: Map `mkString` format updated to default java format

This is a minor change but it helps to improve the log readability.

Author: Kamal C <kamal.chandraprakash@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2709 from Kamal15/util",2017-03-30 13:23:52,Kamal C,Mixed
d345d53e4e5e4f74707e2521aa635b93ba3f1e7b,"KAFKA-4902; Utils#delete should correctly handle I/O errors and symlinks

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Jun Rao <junrao@gmail.com>, Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #2691 from cmccabe/KAFKA-4902",2017-03-30 13:38:09,Colin P. Mccabe,Mixed
a3e13776e6c0889131ddfdaa8b10cd2ef2498603,"MINOR: Fix typos in javadoc and code comments

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2595 from vahidhashemian/minor/fix_typos_1702",2017-03-30 13:52:22,Vahid Hashemian,Not TDD
dd71e4a8d830c9de40b5ec3f987f60a1d2f26b39,"MINOR: Ensure streaming iterator is closed by Fetcher

Author: Jason Gustafson <jason@confluent.io>
Author: Ismael Juma <github@juma.me.uk>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2762 from hachikuji/ensure-decompression-stream-closed",2017-03-30 22:39:28,Jason Gustafson,Mixed
15e0234a5f4976facd4cfe61b91cfcdec6f6083c,"KAFKA-4791: unable to add state store with regex matched topics

Fix for adding state stores with regex defined sources

Author: bbejeck <bbejeck@gmail.com>

Reviewers: Matthias J. Sax, Damian Guy, Guozhang Wang

Closes #2618 from bbejeck/KAFKA-4791_unable_to_add_statestore_regex_topics",2017-03-30 15:44:56,Bill Bejeck,Mixed
bdf4cba047334943aa8357585c4fb379b27e9ffd,"KAFKA-4817; Add idempotent producer semantics

This is from the KIP-98 proposal.

The main points of discussion surround the correctness logic, particularly the Log class where incoming entries are validated and duplicates are dropped, and also the producer error handling to ensure that the semantics are sound from the users point of view.

There is some subtlety in the idempotent producer semantics. This patch only guarantees idempotent production upto the point where an error has to be returned to the user. Once we hit a such a non-recoverable error, we can no longer guarantee message ordering nor idempotence without additional logic at the application level.

In particular, if an application wants guaranteed message order without duplicates, then it needs to do the following in the error callback:

1. Close the producer so that no queued batches are sent. This is important for guaranteeing ordering.
2. Read the tail of the log to inspect the last message committed. This is important for avoiding duplicates.

Author: Apurva Mehta <apurva@confluent.io>
Author: hachikuji <jason@confluent.io>
Author: Apurva Mehta <apurva.1618@gmail.com>
Author: Guozhang Wang <wangguoz@gmail.com>
Author: fpj <fpj@apache.org>
Author: Jason Gustafson <jason@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #2735 from apurvam/exactly-once-idempotent-producer",2017-04-02 19:41:44,Apurva Mehta,Mixed
3364f12bc240e3fefa6a467519ef608fa768917c,"MINOR: Fix deadlock between StreamThread and KafkaStreams

This may be a reason why we see Jenkins jobs time out at times.
I can reproduce it locally.

With current trunk there is a possibility to run into this:

```sh
""kafka-streams-close-thread"" #585 daemon prio=5 os_prio=0 tid=0x00007f66d052d800 nid=0x7e02 waiting for monitor entry [0x00007f66ae2e5000]
   java.lang.Thread.State: BLOCKED (on object monitor)
	at org.apache.kafka.streams.processor.internals.StreamThread.close(StreamThread.java:345)
	- waiting to lock <0x000000077d33c538> (a org.apache.kafka.streams.processor.internals.StreamThread)
	at org.apache.kafka.streams.KafkaStreams$1.run(KafkaStreams.java:474)
	at java.lang.Thread.run(Thread.java:745)

""appId-bd262a91-5155-4a35-bc46-c6432552c2c5-StreamThread-97"" #583 prio=5 os_prio=0 tid=0x00007f66d052f000 nid=0x7e01 waiting for monitor entry [0x00007f66ae4e6000]
   java.lang.Thread.State: BLOCKED (on object monitor)
	at org.apache.kafka.streams.KafkaStreams.setState(KafkaStreams.java:219)
	- waiting to lock <0x000000077d335760> (a org.apache.kafka.streams.KafkaStreams)
	at org.apache.kafka.streams.KafkaStreams.access$100(KafkaStreams.java:117)
	at org.apache.kafka.streams.KafkaStreams$StreamStateListener.onChange(KafkaStreams.java:259)
	- locked <0x000000077d42f138> (a org.apache.kafka.streams.KafkaStreams$StreamStateListener)
	at org.apache.kafka.streams.processor.internals.StreamThread.setState(StreamThread.java:168)
	- locked <0x000000077d33c538> (a org.apache.kafka.streams.processor.internals.StreamThread)
	at org.apache.kafka.streams.processor.internals.StreamThread.setStateWhenNotInPendingShutdown(StreamThread.java:176)
	- locked <0x000000077d33c538> (a org.apache.kafka.streams.processor.internals.StreamThread)
	at org.apache.kafka.streams.processor.internals.StreamThread.access$1600(StreamThread.java:70)
	at org.apache.kafka.streams.processor.internals.StreamThread$RebalanceListener.onPartitionsRevoked(StreamThread.java:1321)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinPrepare(ConsumerCoordinator.java:406)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.joinGroupIfNeeded(AbstractCoordinator.java:349)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureActiveGroup(AbstractCoordinator.java:310)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:296)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1037)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1002)
	at org.apache.kafka.streams.processor.internals.StreamThread.pollRequests(StreamThread.java:531)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:669)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:326)

```

In a nutshell: `KafkaStreams` and `StreamThread` are both
waiting for each other since another intermittent `close`
(eg. from a test) comes along also trying to lock on
`KafkaStreams` :

```sh
""main"" #1 prio=5 os_prio=0 tid=0x00007f66d000c800 nid=0x78bb in Object.wait() [0x00007f66d7a15000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1249)
	- locked <0x000000077d45a590> (a java.lang.Thread)
	at org.apache.kafka.streams.KafkaStreams.close(KafkaStreams.java:503)
	- locked <0x000000077d335760> (a org.apache.kafka.streams.KafkaStreams)
	at org.apache.kafka.streams.KafkaStreams.close(KafkaStreams.java:447)
	at org.apache.kafka.streams.KafkaStreamsTest.testCannotStartOnceClosed(KafkaStreamsTest.java:115)
```

=> causing a deadlock.

Fixed this by softer locking on the state change, that guarantees
atomic changes to the state but does not lock on the whole object
(I at least could not find another method that would require more
than atomicly-locked access except for `setState`).

Also qualified the state listeners with their outer-class to make
the whole code-flow around this more readable (having two
interfaces with the same naming for interface and method and then
using them between their two outer classes is crazy hard to read
imo :)).

Easy to reproduced yourself by running
`org.apache.kafka.streams.KafkaStreamsTest` in a loop for a bit
(save yourself some time by running 2-4 in parallel :)). Eventually
it will lock on one of the tests (for me this takes less than 1 min
with 4 parallel runs).

Author: Armin Braun <me@obrown.io>
Author: Armin <me@obrown.io>

Reviewers: Eno Thereska <eno@confluent.io>, Damian Guy <damian.guy@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2791 from original-brownbear/fix-streams-deadlock",2017-04-03 12:50:57,Armin Braun,Mixed
f54b61909d525547d65123c02bbd36d92ccee5da,"HOTFIX: Set `baseOffset` correctly in `RecordAccumulator`

The bug meant that the base offset was the same as the batch size instead of 0 so the broker would always recompress batches.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #2794 from ijuma/fix-records-builder-construction",2017-04-03 09:40:38,Ismael Juma,Mixed
040fde8ec1f94856799c6bb47fa23a73c20bda66,"KAFKA-4878: Improved Invalid Connect Config Error Message

Addresses for https://issues.apache.org/jira/browse/KAFKA-4878

* Adjusted the error message to explicitly state errors and their number
* Dried up the logic for generating the message between standalone and distributed

Example

messed up two config keys in the file source config:
````
namse=local-file-source
connector.class=FileStreamSource
tasks.max=1
fisle=test.txt
topic=connect-test
```

Produces:

```
[2017-03-22 08:57:11,896] ERROR Stopping after connector error (org.apache.kafka.connect.cli.ConnectStandalone:99)
java.util.concurrent.ExecutionException: org.apache.kafka.connect.runtime.rest.errors.BadRequestException: Connector configuration is invalid and contains the following 2 error(s):
Missing required configuration ""file"" which has no default value.
Missing required configuration ""name"" which has no default value.
You can also find the above list of errors at the endpoint `/{connectorType}/config/validate`
```

Author: Armin Braun <me@obrown.io>

Reviewers: Gwen Shapira, Konstantine Karantasis, Ewen Cheslack-Postava

Closes #2722 from original-brownbear/KAFKA-4878",2017-04-03 13:09:10,Armin Braun,Mixed
ca2979f847ead39b4480f31085c5cf26bb102080,"MINOR: Suppress ProducerConfig warning in MirrorMaker

Though MirrorMaker uses the `producer.type` value of the
producer properties, ProducerConfig show the warning:
`The configuration 'producer.type' was supplied but
isn't a known config.`

Author: Shun Takebayashi <shun@takebayashi.asia>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2676 from takebayashi/suppress-mirrormaker-warning",2017-04-04 00:16:35,Shun Takebayashi,Not TDD
75e213e55036850abef77e4641af9b9071465f80,"KAFKA-4855: Struct SchemaBuilder should not allow duplicate fields

ewencp can you please review.

Author: Balint Molnar <balintmolnar91@gmail.com>

Reviewers: Gwen Shapira <cshapi@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2732 from baluchicken/KAFKA-4855",2017-04-03 20:07:47,Balint Molnar,Mixed
54bf2fb5ff8f1841aea2df2e6fa76f8a05fddfba,"KAFKA-4810: Make Kafka Connect SchemaBuilder more lax about checking that fields are unset

https://issues.apache.org/jira/browse/KAFKA-4810

> Currently SchemaBuilder is strict when checking that certain fields have not been set yet (e.g. version, name, doc). It just checks that the field is null. This is intended to protect the user from buggy code that overwrites a field with different values, but it's a bit too strict currently. In generic code for converting schemas (e.g. Converters) you will sometimes initialize a builder with these values (e.g. because you get a SchemaBuilder for a logical type, which sets name & version), but then have generic code for setting name & version from the source schema.

Changed the validation method to not only check if a field is null but also to check if the new value that is being set is the same as the current value of the field.
ewencp

Author: Vitaly Pushkar <vitaly.pushkar@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2806 from vitaly-pushkar/KAFKA-4810-schema-builder-default-fields-validation",2017-04-04 14:58:45,Vitaly Pushkar,Mixed
9160810072e540a3a037481505aaaa23e3b50546,"KAFKA-4837: Fix class name comparison in connector-plugins REST endpoint

Author: Konstantine Karantasis <konstantine@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2798 from kkonstantine/KAFKA-4837-Config-validation-in-Connector-plugins-need-to-compare-against-both-canonical-and-simple-class-names",2017-04-04 15:07:32,Konstantine Karantasis,Mixed
49f80b2360ab55274ad28405352596f9d560ec1c,"KAFKA-4916: test streams with brokers failing

Several fixes for handling broker failures:
- default replication value for internal topics is now 3 in test itself (not in streams code, that will require a KIP.
- streams producer waits for acks from all replicas in test itself (not in streams code, that will require a KIP.
- backoff time for streams client to try again after a failure to contact controller.
- fix bug related to state store locks (this helps in multi-threaded scenarios)
- fix related to catching exceptions property for network errors.
- system test for all the above

Author: Eno Thereska <eno@confluent.io>
Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Dan Norwood <norwood@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2719 from enothereska/KAFKA-4916-broker-bounce-test",2017-04-04 18:32:58,Eno Thereska,Mixed
aea14651184476940c69238535de5143e61f4c31,"HOTFIX: WindowedStreamPartitioner does not provide topic name to serializer

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Eno Thereska <eno@confluent.io>, Damian Guy <damian.guy@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2777 from mjsax/hotfix-window-serdes-trunk",2017-04-05 10:31:06,Matthias J. Sax,Mixed
d4c4bcf017a1b770dca71868b97d37ec7327ea00,"MINOR: Make ConfigDef safer by not using empty string for NO_DEFAULT_VALUE.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Damian Guy <damian.guy@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2660 from ewencp/minor-make-configdef-safer",2017-04-05 11:35:04,Ewen Cheslack-Postava,Mixed
afeadbef50ee8cb5c23de26c1b2a5ad2c7ad941e,"KAFKA-5003; StreamThread should catch InvalidTopicException

We should catch `InvalidTopicException` and not just
`NoOffsetForPartitionException`. Also, we need to step through
all partitions that might be affected and reset those.

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Bill Bejeck <bbejeck@gmail.com>, Eno Thereska <eno@confluent.io>, Damian Guy <damian.guy@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2747 from mjsax/minor-fix-reset",2017-04-06 12:00:38,Matthias J. Sax,Not TDD
0baea2ac13532981f3fea11e5dfc6da5aafaeaa8,"KIP-101: Alter Replication Protocol to use Leader Epoch rather than High Watermark for Truncation

This PR replaces https://github.com/apache/kafka/pull/2743 (just raising from Confluent repo)

This PR describes the addition of Partition Level Leader Epochs to messages in Kafka as a mechanism for fixing some known issues in the replication protocol. Full details can be found here:

[KIP-101 Reference](https://cwiki.apache.org/confluence/display/KAFKA/KIP-101+-+Alter+Replication+Protocol+to+use+Leader+Epoch+rather+than+High+Watermark+for+Truncation)

*The key elements are*:
- Epochs are stamped on messages as they enter the leader.
- Epochs are tracked in both leader and follower in a new checkpoint file.
- A new API allows followers to retrieve the leader's latest offset for a particular epoch.
- The logic for truncating the log, when a replica becomes a follower, has been moved from Partition into the ReplicaFetcherThread
- When partitions are added to the ReplicaFetcherThread they are added in an initialising state. Initialising partitions request leader epochs and then truncate their logs appropriately.

This test provides a good overview of the workflow `EpochDrivenReplicationProtocolAcceptanceTest.shouldFollowLeaderEpochBasicWorkflow()`

The corrupted log use case is covered by the test
`EpochDrivenReplicationProtocolAcceptanceTest.offsetsShouldNotGoBackwards()`

Remaining work: There is a do list here: https://docs.google.com/document/d/1edmMo70MfHEZH9x38OQfTWsHr7UGTvg-NOxeFhOeRew/edit?usp=sharing

Author: Ben Stopford <benstopford@gmail.com>
Author: Jun Rao <junrao@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #2808 from benstopford/kip-101-v2",2017-04-06 14:51:09,Ben Stopford,Mixed
865d82af2cc050d10544d70b95468da90c1d800b,"KAFKA-4990; Request/response classes for transactions (KIP-98)

Author: Matthias J. Sax <matthias@confluent.io>
Author: Guozhang Wang <wangguoz@gmail.com>
Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2799 from mjsax/kafka-4990-add-api-stub-config-parameters-request-types",2017-04-07 12:07:25,Matthias J. Sax,Not TDD
a4c50687f6a5a5a7ea9e523df7c55355441c7ffa,"KAFKA-5042: InFlightRequests#isEmpty() always returns false

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Gwen Shapira

Closes #2823 from ijuma/kafka-5042-fix-inflight-requests-is-empty",2017-04-07 10:14:06,Ismael Juma,Not TDD
5cf64f06a877a181d12a2ae2390516ba1a572135,"MINOR: Log append validation improvements

- Consistent validation across different code paths in LogValidator
- Validate baseOffset for message format V2
- Flesh out LogValidatorTest to check producerId, baseSequence, producerEpoch and partitionLeaderEpoch.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #2802 from ijuma/validate-base-offset",2017-04-07 18:29:55,Ismael Juma,Mixed
67fc2a91a6e80bfda30537c7c95cd9ce396d4e7d,"KAFKA-4943: Make /config/users with SCRAM credentials not world-readable

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma, Jun Rao

Closes #2733 from rajinisivaram/KAFKA-4943",2017-04-07 11:07:06,Rajini Sivaram,Not TDD
82a8e83de622f777a81e9ea0c01d6832f44e7956,"MINOR: Fix incorrect pattern matching on `version` in `CheckpointFile`

Also add test and refactor things a little to make testing easier.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Ben Stopford <benstopford@gmail.com>, Jun Rao <junrao@gmail.com>

Closes #2822 from ijuma/hotfix-checkpoint-file",2017-04-08 01:03:49,Ismael Juma,Mixed
d0e7c6b9304b23ced046934c799df0cba39c28e5,"KAFKA-5043; Rename GroupCoordinator to FindCoordinator (KIP-98)

Also:
1. FindCoordinator is more general and takes a coordinator_type
so that it can be used for the group and transaction coordinators.
2. Include an error message in FindCoordinatorResponse to make the
errors at the client side more informative. We have just added the
field to the protocol in this PR, a subsequent PR will update the
code to use it.
3. Rename `Errors` names for FindCoordinator to be more generic. This
is a compatible change as the ids remain the same.
4. Since the exception classes for the error codes are in a public
package, we introduce new ones and deprecate the old ones.
The classes were not thrown back to the user (KAFKA-5052 aside),
so this is a compatible change.
5. Update InitPidRequest for transactions. Since this protocol API
was introduced recently and is not used by default, we did not bump
its version.

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2825 from apurvam/exactly-once-rpc-stubs",2017-04-11 09:11:46,Apurva Mehta,Mixed
8e7516ea2e6b99a6e9a3fb5a958e62b1fb186cf9,"KAFKA-4866; Console consumer `print.value` property is ignored

This property is mentioned in the quickstart.

Author: huxi <huxi@zhenrongbao.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2661 from amethystic/kafka4866_consoleconsumer_ignore_printvalue",2017-04-11 12:38:09,huxi,Mixed
1d25369d22f47567a7117dede14b62b8586f394a,"MINOR: Make LeaderAndIsr immutable case class

Also include a few code readability improvements.

Author: jozi-k <jozef.koval@protonmail.ch>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2731 from jozi-k/immutable_LeaderAndIsr",2017-04-12 01:01:59,jozi-k,Not TDD
0be835dde50611277504a4ddd93cc62f39e6defe,"KAFKA-4965; set internal.leave.group.on.close to false in StreamsConfig

Set the internal consumer config internal.leave.group.on.close in
`StreamsConfig`. This is to reduce the number of rebalances we get
during bounces.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2750 from dguy/kafka-4965",2017-04-12 13:04:44,Damian Guy,Mixed
1e93c3b9a3b8cbf069c57b46737fc02c818cb286,"KAFKA-5038; Throw correct exception of locking of state directory fails

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #2848 from enothereska/KAFKA-5038-trunk",2017-04-12 16:34:07,Eno Thereska,Mixed
148f8c25453e453f56ef429f8ef607de808de679,"KAFKA-4986; Producer per StreamTask support (KIP-129)

Enable producer per task if exactly-once config is enabled.

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Eno Thereska <eno@confluent.io>, Damian Guy <damian.guy@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2773 from mjsax/exactly-once-streams-producer-per-task",2017-04-14 15:19:52,Matthias J. Sax,Mixed
17ce2a7307222d7476eb60318fab2e672eebe559,"KAFKA-5075; Defer exception to the next pollOnce() if consumer's fetch position has already increased

Author: Dong Lin <lindong28@gmail.com>
Author: Dong Lin <lindong28@users.noreply.github.com>

Reviewers: Jiangjie Qin <becket.qin@gmail.com>

Closes #2859 from lindong28/KAFKA-5075",2017-04-16 23:23:25,Dong Lin,Mixed
020ca7903669306862950260b8d63177402322c3,"KAFKA-5036; Second part: Points 2 -> 5): Refactor caching of Latest Epoch

This PR covers point (2) and point (5) from KAFKA-5036:

**Commit 1:**
2. Currently, we update the leader epoch in epochCache after log append in the follower but before log append in the leader. It would be more consistent to always do this after log append. This also avoids issues related to failure in log append.
5. The constructor of LeaderEpochFileCache has the following:
lock synchronized { ListBuffer(checkpoint.read(): _*) }
But everywhere else uses a read or write lock. We should use consistent locking.
This is a refactor to the way epochs are cached, replacing the code to cache the latest epoch in the LeaderEpochFileCache by reusing the cached value in Partition. There is no functional change.

**Commit 2:**
Adds an assert(epoch >=0) as epochs are written. Refactors tests so they never hit this assert.

Author: Ben Stopford <benstopford@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #2831 from benstopford/KAFKA-5036-part2-second-try",2017-04-17 17:24:45,Ben Stopford,Mixed
c4e59a338a045fc9d9b726ad68641e93582a8642,"KAFKA-5069; add controller integration tests

Test the various controller protocols by observing zookeeper and broker state.

Author: Onur Karaman <okaraman@linkedin.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #2853 from onurkaraman/KAFKA-5069",2017-04-18 16:39:47,Onur Karaman,Mixed
41c0f8addeef44be23524bade61bcb2ab6077706,"KAFKA-5049; Chroot check should be done for each ZkUtils instance

Author: anukin <anukin2611@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2857 from anukin/KAFKA_5049_zkroot_check",2017-04-19 11:30:55,anukin,Not TDD
63f01a8af897ee9510ab0364f2d026e4bf5472ef,"KAFKA-4814; Enable ZK ACLs only when zookeeper.set.acl is set

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2845 from rajinisivaram/KAFKA-4814",2017-04-20 09:42:23,Rajini Sivaram,Not TDD
6af876b94dc588c8d6098a7fef7a18c46625d1d5,"MINOR: Fix open file leak in log cleaner integration tests

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2870 from hachikuji/fix-log-cleaner-test-leak",2017-04-20 13:19:36,Jason Gustafson,Not TDD
588ed4644fe8842e4217c8e2add39f6e08e07db9,"MINOR: Improvements to PID snapshot management

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #2866 from hachikuji/improve-snapshot-management",2017-04-20 13:01:46,Jason Gustafson,Mixed
98d62a880d91ac1b552ac3a049c5d202c2d63520,"KAFKA-4937: Batch offset fetches in the Consumer

change `consumer.position` so that it always updates any partitions that need an update. Keep track of partitions that `seekToBeginning` in `StoreChangeLogReader` and do the `consumer.position` call after all `seekToBeginning` calls.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang, Jason Gustafson, Ismael Juma

Closes #2769 from dguy/kafka-4937",2017-04-20 13:36:52,Damian Guy,Mixed
3c471d25b97b9a867ec6a2a1ed9467b8e4ba6b66,"KAFKA-5047: NullPointerException while using GlobalKTable in KafkaStreams

Skip null keys when initializing GlobalKTables. This is inline with what happens during normal processing.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Michael G. Noll, Eno Thereska, Matthias J. Sax, Guozhang Wang

Closes #2834 from dguy/kafka-5047",2017-04-20 14:24:47,Damian Guy,Mixed
fc5ad22e33cb9f757f645cec9d4afe9e65292712,"KAFKA-5088: some spelling error in code comment

fix some spelling errors

Author: xinlihua <xin.lihua1@zte.com.cn>

Reviewers: Matthias J. Sax, Guozhang Wang

Closes #2871 from auroraxlh/fix_spellingerror",2017-04-20 21:43:08,Lihua Xin,Not TDD
d18de0e9547728e4fa0df985c1778aab5ffec751,"KAFKA-5094; Replace SCRAM credentials in broker logs with tag hidden

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2879 from rajinisivaram/KAFKA-5094",2017-04-21 10:47:24,Rajini Sivaram,Not TDD
3bedcce01b9d3e8ba0516fa33eb59d57817ce27e,"MINOR: fix record collector to stick with streams partitioner behavior if it is specified

If `partition==null` and `partitioner!=null` we should not fall back to default partitioner (as we do before the patch if `producer.partitionsFor(...)` returns empty list. Falling back to default partitioner might corrupt hash partitioning.

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Eno Thereska, Damian Guy, Guozhang Wang

Closes #2868 from mjsax/minor-fix-RecordCollector",2017-04-21 10:47:28,Matthias J. Sax,Mixed
72be1df5984a8d2df7b4d2ea8f386c69fe31f4d2,"KAFKA-4564: Add system test for pre-0.10 brokers

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Ismael Juma, Eno Thereska, Matthias J. Sax, Guozhang Wang

Closes #2837 from mjsax/kafka-4564-fail-fast-test-stream-compatibility",2017-04-21 10:53:29,Matthias J. Sax,Not TDD
cba0094f5a9833194bf2a13965eda678bd4a05ea,"MINOR: improve test cleanup for Streams

 - call close() on Metrics to join created threads

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Eno Thereska, Damian Guy, Guozhang Wang

Closes #2788 from mjsax/minor-improve-test-metric-cleanup",2017-04-21 13:10:05,Matthias J. Sax,Mixed
19f266d4075a8c56d56f6b8c7e95773378b95211,"MINOR: Move `Os` class to utils package and rename it to OperatingSystem

The `common` package is public and this class is
internal.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #2759 from ijuma/move-os-to-utils",2017-04-22 13:57:27,Ismael Juma,Not TDD
c43eb856d16e648c2a6ab1f87b58f59035fce065,"KAFKA-4840; BufferPool errors can cause buffer pool to go into a bad state

Author: Sean McCauliff <smccauliff@linkedin.com>

Reviewers: Dong Lin <lindong28@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jiangjie Qin <becket.qin@gmail.com>

Closes #2659 from smccauliff/kafka-4840",2017-04-25 10:31:16,Sean McCauliff,Mixed
f7b7b4745541a576eb0219468263487b07bac959,"KAFKA-5111: Improve internal Task APIs of Streams

 Refactors Task with proper interface methods `init()`, `resume()`, `commit()`, `suspend()`, and `close()`. All other methods for task handling are internal now. This allows to simplify `StreamThread` code, avoid code duplication and allows for easier reasoning of control flow.

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Ismael Juma, Damian Guy, Eno Thereska, Guozhang Wang

Closes #2895 from mjsax/kafka-5111-cleanup-task-code",2017-04-25 18:10:49,Matthias J. Sax,Mixed
f69d94158ce72f4ef2df5b98f2395c2b2e61251e,"KAFKA-5059: Implement Transactional Coordinator

Author: Damian Guy <damian.guy@gmail.com>
Author: Guozhang Wang <wangguoz@gmail.com>
Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Guozhang Wang, Jason Gustafson, Apurva Mehta, Jun Rao

Closes #2849 from dguy/exactly-once-tc",2017-04-26 14:10:38,Damian Guy,Mixed
bb663d04febcadd4f120e0ff5c5919ca8bf7e971,"KAFKA-5028; convert kafka controller to a single-threaded event queue model

The goal of this ticket is to improve controller maintainability by simplifying the controller's concurrency semantics. The controller code has a lot of shared state between several threads using several concurrency primitives. This makes the code hard to reason about.

This ticket proposes we convert the controller to a single-threaded event queue model. We add a new controller thread which processes events held in an event queue. Note that this does not mean we get rid of all threads used by the controller. We merely delegate all work that interacts with controller local state to this single thread. With only a single thread accessing and modifying the controller local state, we no longer need to worry about concurrent access, which means we can get rid of the various concurrency primitives used throughout the controller.

Performance is expected to match existing behavior since the bulk of the existing controller work today already happens sequentially in the ZkClient’s single ZkEventThread.

Author: Onur Karaman <okaraman@linkedin.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #2816 from onurkaraman/KAFKA-5028",2017-04-27 08:51:23,Onur Karaman,Not TDD
a82f194b21a6af2f52e36e55e2c6adcdba942c08,"KAFKA-4818; Exactly once transactional clients

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #2840 from apurvam/exactly-once-transactional-clients",2017-04-27 14:11:36,Apurva Mehta,Mixed
5b5efd4b5cb092813d878b080e0657f40fc1f72c,"KAFKA-5086: Update topic expiry time in Metadata every time the topic metadata is requested

Update topic expiry time after every metadata update to handle max.block.ms greater than 5 minutes

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>

Closes #2869 from lindong28/KAFKA-5086",2017-04-27 23:01:01,Dong Lin,Mixed
36aef1c2682169571b410a4986680361db5eec01,"KAFKA-5005: IntegrationTestUtils to override consumer configs and reuse consumer

* Producer and Consumer `close` calls were not handled via `try-with-resources`
* `cleanRun` unused field removed
* Refactored handling of Consumer configuration in `IntegrationTestUtils` to ensure auto-committing of offsets and starting from `earliest`
  * As a result reverted https://github.com/apache/kafka/pull/2921 since it's redundant now

Author: Armin Braun <me@obrown.io>

Reviewers: Matthias J. Sax, Guozhang Wang

Closes #2920 from original-brownbear/cleanup-it-utils-closing",2017-04-27 16:38:28,Armin Braun,Not TDD
6753af270c8a966411f5574afa57f6e5ffe43dbe,"KAFKA-5111: Code cleanup and improved log4j on StreamThread and Task

 - mainly moving methods
 - also improved logging

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy, Eno Thereska, Guozhang Wang

Closes #2917 from mjsax/kafka-5111-code-cleanup-follow-up",2017-04-27 17:11:46,Matthias J. Sax,Mixed
ee8c5e2dc391222b618b8a48dde9e407031ea85b,"KAFKA-4379; Follow-up to avoid sending to changelog while restoring InMemoryLRUCache

1. Added a flag to indicate if it is restoring or not in the LRU Store; since we only have a restore callback we have to set it each time applying the change.
2. Fixed the corresponding unit test, plus some minor cleaning up.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Jason Gustafson <jason@confluent.io>

Closes #2908 from guozhangwang/K4379-remove-listener",2017-04-27 17:19:14,Guozhang Wang,Mixed
4b9de871df1b2574a7e5d1159b45ae9e4ba31955,"MINOR: adding global store must ensure unique names

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy, Guozhang Wang

Closes #2909 from mjsax/minor-fix-add-global-store",2017-04-27 17:41:21,Matthias J. Sax,Mixed
a931e9954d27f4c9f12fd89afd6f0fe523cf35e8,"KAFKA-4986 Follow-up: cleanup unit tests and further comments addressed

 - addressing open Github comments from #2773
 - test clean-up

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy, Guozhang Wang

Closes #2854 from mjsax/kafka-4986-producer-per-task-follow-up",2017-04-27 23:28:50,Matthias J. Sax,Mixed
f0152a7fdac2ae4dcac65d5ed24fa201f3d30120,"KAFKA-5097; Add testFetchAfterPartitionWithFetchedRecordsIsUnassigned

I verified that the test would trigger an `IllegalStateException` if the
`position` call was added back.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Eno Thereska <eno@confluent.io>, Jason Gustafson <jason@confluent.io>

Closes #2887 from ijuma/kafka-5097-unit-test",2017-04-27 23:40:33,Ismael Juma,Not TDD
6185bc0276c03075022c30d3c36f7f5c09ef19c6,"KAFKA-4208; Add Record Headers

As per KIP-82

Adding record headers api to ProducerRecord, ConsumerRecord
Support to convert from protocol to api added Kafka Producer, Kafka Fetcher (Consumer)
Updated MirrorMaker, ConsoleConsumer and scala BaseConsumer
Add RecordHeaders and RecordHeader implementation of the interfaces Headers and Header

Some bits using are reverted to being Java 7 compatible, for the moment until KIP-118 is implemented.

Author: Michael Andre Pearce <Michael.Andre.Pearce@me.com>

Reviewers: Radai Rosenblatt <radai.rosenblatt@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #2772 from michaelandrepearce/KIP-82",2017-04-28 19:18:27,Michael Andre Pearce,Mixed
0104b657a154fb15e716d872a0e6084f9da650bf,"KAFKA-4954; Request handler utilization quotas

See KIP-124 (https://cwiki.apache.org/confluence/display/KAFKA/KIP-124+-+Request+rate+quotas) for details

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #2744 from rajinisivaram/KAFKA-4954",2017-05-01 09:13:31,Rajini Sivaram,Mixed
c96656efb3718f8b2badc30e56c7f179c0658de8,"KAFKA-5091; ReassignPartitionsCommand should protect against empty replica list assignment

ReassignPartitionsCommand should protect against empty replica list assignment.

Author: amethystic <huxi_2b@hotmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #2904 from amethystic/kafka-5901_ReassignPartitionsCommand_protect_against_empty_replica_list",2017-05-01 11:17:30,amethystic,Not TDD
4aed28d1897c6c5293f372cb4fc44ab363dfc365,"KAFKA-3265; Add a public AdminClient API in Java (KIP-117)

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Dan Norwood <norwood@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #2472 from cmccabe/KAFKA-3265",2017-05-02 00:20:22,Colin P. Mccabe,Mixed
1f2451d4e7e3766540d3650d177e304fcddf49b8,"KAFKA-5059 Follow-up: Remove broken locking and fix handleAddPartitions

remove broken locking. fix handleAddPartitions after complete commit/abort
respond with CONCURRENT_TRANSACTIONS in initPid

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #2934 from dguy/follow-up-tc-work",2017-05-01 16:47:08,Damian Guy,Mixed
67f1f4d270c279480cea5e6120ca157637910cba,"MINOR: Some cleanups in the transactional producer

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #2933 from hachikuji/minor-transactional-client-cleanup",2017-05-02 01:10:40,Jason Gustafson,Mixed
324b475eca48502fb16c8efd0de99756f68437bf,"KAFKA-5136: move coordinatorEpoch from WriteTxnMarkerRequest to TxnMarkerEntry

Moving the coordinatorEpoch from WriteTxnMarkerRequest to TxnMarkerEntry will generate fewer broker send requests

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Ismael Juma, Guozhang Wang

Closes #2925 from dguy/tc-write-txn-request-follow-up",2017-05-01 17:15:32,Damian Guy,Mixed
64ea193ceee931ee42c3fce27341980ee7c50d15,"MINOR: Describe topics should describe, not delete

Author: dan norwood <norwood@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2952 from norwood/describe-not-delete",2017-05-02 12:28:20,dan norwood,Not TDD
46da01a4a7d12243a7f8b1d5a51f7815a9162320,"KAFKA-4623; Default unclean.leader.election.enabled to false (KIP-106)

Author: sharad.develop <sharad.develop@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2625 from sharad-develop/KAFKA-4623",2017-05-02 16:27:28,sharad-develop,Mixed
619fd7aeb62b2c1a68938a341ff81f728fc60090,"KAFKA-5131; WriteTxnMarkers and complete commit/abort on partition immigration

Write txn markers and complete the commit/abort for transactions in PrepareXX
state during partition immigration.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #2926 from dguy/kafka-5059",2017-05-03 01:18:17,Damian Guy,Mixed
0e7cc4aa384372d1e08d7bd444b5e23510f447d9,"MINOR: Serialize the real isolationLevel in FetchRequest

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2961 from apurvam/MINOR-serialize-isolation-level-in-fetch-request",2017-05-03 01:19:35,Apurva Mehta,Not TDD
f60009b14dae33168009290e549e4e9544595685,"MINOR: Handle 0 futures in all()

If we pass in 0 futures to an AllOfAdapter, we should complete immediately

Author: dan norwood <norwood@confluent.io>

Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #2953 from norwood/handle-all-of-0",2017-05-03 02:26:53,dan norwood,Mixed
4a6bbd5f1386562262193b5054b44894a196997b,"KAFA-4378: Fix Scala 2.12 ""eta-expansion of zero-argument method"" warnings

Author: Bernard Leach <leachbj@bouncycastle.org>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2098 from leachbj/4378-eta-expansion",2017-05-03 10:17:42,Bernard Leach,Not TDD
a7671c7f3723113e716b99471e7be3499fde1b15,"KAFKA-4703: Test with two SASL_SSL listeners with different JAAS contexts

Tests broker with multiple SASL mechanisms with different endpoints for different mechanisms. Each endpoint uses its own JAAS context.

Author: Balint Molnar <balintmolnar91@gmail.com>

Reviewers: Rajini Sivaram, Ismael Juma

Closes #2506 from baluchicken/KAFKA-4703",2017-05-03 21:08:30,Balint Molnar,Not TDD
ec9e4eafa406fec897713310bafdedf6bbb3c0c5,"KAFKA-5045: Clarify on KTable APIs for queryable stores

This is the implementation of KIP-114: KTable state stores and improved semantics:
- Allow for decoupling between querying and materialisation
- consistent APIs, overloads with queryableName and without
- depreciated several KTable calls
- new unit and integration tests

In this implementation, state stores are materialized if the user desires them to be queryable. In subsequent versions we can offer a second option, to have a view-like state store. The tradeoff then would be between storage space (materialize) and re-computation (view). That tradeoff can be exploited by later query optimizers.

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Damian Guy, Matthias J. Sax, Guozhang Wang

Closes #2832 from enothereska/KAFKA-5045-ktable",2017-05-03 16:15:54,Eno Thereska,Mixed
ed59f742b0b2c7920444d56c44d0bc79dbc8a2ad,"KAFKA-4925: delay initial rebalance of consumer group

Add new broker config, `group.initial.rebalance.delay.ms`, with a default of 3 seconds.
When a consumer creates a new group, set the group's state to InitialRebalance and delay the rebalance until `min(group.initial.rebalance.delay.ms, rebalanceTimeout)`. As other members join the group further delay the rebalance by `min(group.initial.rebalance.delay.ms, remainingRebalanceTimeout)`. Once `rebalanceTimeout` is hit or no new members join the group within the delay, complete the rebalance.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Ewen Cheslack-Postava, Guozhang Wang

Closes #2758 from dguy/kafka-4925",2017-05-04 11:14:28,Damian Guy,Mixed
a6728f6ee7a87da2859baca95b50e00dd6368431,"KAFKA-5118: Improve message for Kafka failed startup with non-Kafka data in data.dirs

Explicitly throwing clear exceptions when starting up a Kafka with some non-Kafka data in data.dirs.

Author: amethystic <huxi_2b@hotmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #2907 from amethystic/kafka-5118_improve_msg__for_failed_startup_with_nonKafka_data",2017-05-04 11:46:06,Xi Hu,Mixed
95b48b157aca44beec4335e62a59f37097fe7499,"KAFKA-5161: add code in reassign-partitions to check broker existence

Added code to check existence of the brokers in the proposed plan.

Author: amethystic <huxi_2b@hotmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #2962 from amethystic/kafka5161_reassign_check_invalid_brokerID",2017-05-04 22:12:28,amethystic,Not TDD
715eae6da92d5d1db7ac65e3c8ff753e15b5c0ca,"KAFKA-5169; KafkaConsumer.close should be idempotent

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2968 from mjsax/kafka-5169-consumer-close",2017-05-05 08:51:02,Matthias J. Sax,Mixed
e71dce89c0da50f3eccc47d0fc050c92d5a99b88,"KAFKA-5121; Implement transaction index for KIP-98

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #2910 from hachikuji/eos-txn-index",2017-05-06 11:49:35,Jason Gustafson,Mixed
e472ee7b613dbcab2ba1f5b6b384fa713f3906d0,"KAFKA-5172: Fix fetchPrevious to find the correct session

Change fetchPrevious to use findSessions with the proper key and timestamps rather than using fetch.

Author: Kyle Winkelman <kyle.winkelman@optum.com>

Reviewers: Damian Guy, Guozhang Wang

Closes #2972 from KyleWinkelman/CachingSessionStore-fetchPrevious",2017-05-07 22:15:40,Kyle Winkelman,Mixed
2554a8dd4dd07b0ac844839b51533bd1e67eed85,"KAFKA-4839; Throw NoOffsetForPartitionException from poll once for all TopicPartitions affected

Signed-off-by: radai-rosenblatt <radai.rosenblattgmail.com>

Author: radai-rosenblatt <radai.rosenblatt@gmail.com>

Reviewers: Apurva Mehta <apurva@confluent.io>, Vahid Hashemian <vahidhashemian@us.ibm.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #2637 from radai-rosenblatt/KAFKA-4839",2017-05-08 09:42:44,radai-rosenblatt,Mixed
78ace3725151dc056e83a8ec389141fc8809d4c0,"KAFKA-5176; AdminClient: add controller and clusterId methods to DescribeClusterResults

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: dan norwood <norwood@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #2977 from cmccabe/KAFKA-5176",2017-05-09 02:10:31,Colin P. Mccabe,Not TDD
c69842336d87cc321a58171c517c46cdddfe1a64,"KAFKA-5126: Implement KIP-98 transactional methods in the MockProducer

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy, Guozhang Wang

Closes #2951 from mjsax/kafka-5126-add-transactions-to-mock-producer",2017-05-09 10:15:40,Matthias J. Sax,Mixed
7371bf7f65d1245b084f17e534b5728d5929e207,"KAFKA-5063: Fix flaky o.a.k.streams.integration.ResetIntegrationTest

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy, Eno Thereska, Guozhang Wang

Closes #2931 from mjsax/kafka-5140-flaky-reset-integration-test",2017-05-09 14:35:57,Matthias J. Sax,Not TDD
a420d20c0e3da2c9637820f7d1a344706fd835fa,"KAFKA-5099; Replica Deletion Regression from KIP-101

Replica deletion regressed from KIP-101. Replica deletion happens when a broker receives a StopReplicaRequest with delete=true. Ever since KAFKA-1911, replica deletion has been async, meaning the broker responds with a StopReplicaResponse simply after marking the replica directory as staged for deletion. This marking happens by moving a data log directory and its contents such as /tmp/kafka-logs1/t1-0 to a marked directory like /tmp/kafka-logs1/t1-0.8c9c4c0c61c44cc59ebeb00075a2a07f-delete, acting as a soft-delete. A scheduled thread later actually deletes the data. It appears that the regression occurs while the scheduled thread is actually trying to delete the data, which means the controller considers operations such as partition reassignment and topic deletion complete. But if you look at the log4j logs and data logs, you'll find that the soft-deleted data logs actually won't get deleted.

The bug is that upon log deletion, we attempt to flush the LeaderEpochFileCache to the original file location instead of the moved file location. Restarting the broker actually allows for the soft-deleted directories to get deleted.

This patch avoids the issue by simply not flushing the LeaderEpochFileCache upon log deletion.

Author: Onur Karaman <okaraman@linkedin.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #2986 from onurkaraman/KAFKA-5099",2017-05-10 13:45:32,Onur Karaman,Mixed
0bede30ada6d5719950ad35a69c586f0ba9c4f7e,"KAFKA-5184 KAFKA-5173; Various improvements to SASL tests

1. Call `closeSasl` in `MultipleListenersWithSameSecurityProtocolBaseTest`
2. Refactor the code to make it easier to reason about
3. Add an assert that may possibly help us narrow down how KAFKA-5184
can happen (it seems impossible).
4. Remove SaslTestHarness to make it easier to reason about setUp
and tearDown methods.
5. Fix *AdminClientIntegrationTest to have a single `tearDown`
6. Remove a *ReplicaFetcherTest and *TopicMetadataTest secure variants.
They are redundant from a security perspective given the consumer and
producer tests.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #3010 from ijuma/kafka-5184-kafka-5173-sasl-issues",2017-05-10 22:38:30,Ismael Juma,Not TDD
970c00eab80d82b97456e276ee0f5615cb1ccfa1,"KAFKA-5213; Mark a MemoryRecordsBuilder as full as soon as the append stream is closed

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #3015 from apurvam/KAFKA-5213-illegalstateexception-in-ensureOpenForAppend",2017-05-10 18:15:54,Apurva Mehta,Not TDD
27107ee34d1df89035eb9b9b4e11036fca6cf723,"MINOR: JoinGroupRequest V0 invalid rebalance timeout

A JoinGroupRequest V0 built with the Builder had
a rebalance timeout  = -1 rather than equal to session timeout
as it would have been if coming from the wire and deserialized
from a V0 Struct

fix developed with mimaison

Author: Edoardo Comar <ecomar@uk.ibm.com>

Reviewers: Rajini Sivaram

Closes #2936 from edoardocomar/MINOR-JoinGroupRequestV0",2017-05-11 16:17:34,Edoardo Comar,Not TDD
b6effcbba50eaa3abf91e24f0ae83abb53881add,"KAFKA-4343: Expose Connector type in REST API (KIP-151)

https://cwiki.apache.org/confluence/display/KAFKA/KIP-151+Expose+Connector+type+in+REST+API

Author: dan norwood <norwood@confluent.io>

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2960 from norwood/KIP-151",2017-05-11 18:16:25,dan norwood,Mixed
911c768bcc3ba950d63536ce4e6ba2542542d573,"KAFKA-5078; PartitionRecords.fetchRecords(...) should defer exception to the next call if iterator has already moved across any valid record

Suppose there are two valid records followed by one invalid records in the FetchResponse.PartitionData(). As of current implementation, PartitionRecords.fetchRecords(...) will throw exception without returning the two valid records. The next call to PartitionRecords.fetchRecords(...) will not return that two valid records either because the iterator has already moved across them.

We can fix this problem by defering exception to the next call of PartitionRecords.fetchRecords(...) if iterator has already moved across any valid record.

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>, Jiangjie Qin <becket.qin@gmail.com>

Closes #2864 from lindong28/KAFKA-5078",2017-05-11 20:03:30,Dong Lin,Mixed
d96866243990a4d739ec8fc239f0c2758bba66e8,"KAFKA-5194; Include only client traffic in BytesOutPerSec metric (KIP-153)

Also added 2 new metrics to account for incoming/outgoing traffic due to internal replication
- ReplicationBytesInPerSec
- ReplicationBytesOutPerSec

Author: Mickael Maison <mickael.maison@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3003 from mimaison/KAFKA-5194",2017-05-12 12:33:48,Mickael Maison,Not TDD
4951849163b1defea91129472b5354531407deb9,"KAFKA-5132: abort long running transactions

Abort any ongoing transactions that haven't been touched for longer than the transaction timeout

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Jason Gustafson, Apurva Mehta, Ismael Juma, Guozhang Wang

Closes #2957 from dguy/kafka-5132",2017-05-12 10:36:02,Damian Guy,Mixed
1c2bbaa501c2d0fd4db9c2dacacc3ff7f5236d3d,"MINOR: Fix consumer and producer to actually support metrics recording level

Also add tests and a few clean-ups.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Eno Thereska <eno.thereska@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #2937 from ijuma/metrics-recording-level-producer",2017-05-12 10:36:44,Ismael Juma,Mixed
7baa58d797126b6fb2b1de30e72428895d2bcb40,"KAFKA-5196; Make LogCleaner transaction-aware

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #3008 from hachikuji/KAFKA-5196",2017-05-12 12:07:22,Jason Gustafson,Mixed
794e6dbd14f040d21d3402c5eda22cfa8f5c4b3d,"KAFKA-5130: Refactor transaction coordinator's in-memory cache; plus fixes on transaction metadata synchronization

1. Collapsed the `ownedPartitions`, `pendingTxnMap` and the `transactionMetadataCache` into a single in-memory structure, which is a two-layered map: first keyed by the transactionTxnLog, and then valued with the current coordinatorEpoch of that map plus another map keyed by the transactional id.

2. Use `transactionalId` across the modules in transactional coordinator, attach this id with the transactional marker entries.

3. Use two keys: `transactionalId` and `txnLogPartitionId` in the writeMarkerPurgatory as well as passing it along with the TxnMarkerEntry, so that `TransactionMarkerRequestCompletionHandler` can use it to access the two-layered map upon getting responses.

4. Use one queue per `broker-id` and `txnLogPartitionId`. Also when there is a possible update on the end point associated with the `broker-id`, update the Node without clearing the queue but relying on the requests to retry in the next round.

5. Centralize the error handling callback for appending-metadata-to-log and sending-markers-to-brokers in `TransactionStateManager#appendTransactionToLog`, and `TransactionMarkerChannelManager#addTxnMarkersToSend`.

6. Always update the in-memory transaction metadata AFTER the txn log has been appended and replicated, and then double check on the cache to make sure nothing has changed since log appending. The only exception is when initializing the pid for the first time, in which we will put a dummy into the cache but set its pendingState as `Empty` (so it will be valid to transit from `Empty` to `Empty`) so that it can be updated after the log append has completed.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Ismael Juma, Damian Guy, Jason Gustafson, Jun Rao

Closes #2964 from guozhangwang/K5130-refactor-tc-inmemory-cache",2017-05-12 15:01:01,Guozhang Wang,Mixed
da0b5b8596fa20836b8c80c473b3f37af96c9b96,"KAFKA-5216: Fix peekNextKey in cached window/session store iterators

guozhangwang mjsax dguy

Author: Xavier Léauté <xavier@confluent.io>

Reviewers: Damian Guy, Matthias J. Sax, Guozhang Wang

Closes #3016 from xvrl/kafka-5216",2017-05-12 15:27:03,Xavier Léauté,Not TDD
7258a5fddf3fb77480cd414819cdbfbd96b709e5,"KAFKA-5160; KIP-98 Broker side support for TxnOffsetCommitRequest

This patch adds support for the `TxnOffsetCommitRequest` added in KIP-98. Desired handling for this request is [described here](https://docs.google.com/document/d/11Jqy_GjUGtdXJK94XGsEIK7CP1SnQGdp2eF0wSw9ra8/edit#bookmark=id.55yzhvkppi6m) .

The functionality includes handling the stable state of receiving `TxnOffsetCommitRequests` and materializing results only when the commit marker for the transaction is received. It also handles partition emigration and immigration and rebuilds the required data structures on these events.

Tests are included for all the functionality.

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #2970 from apurvam/KAFKA-5160-broker-side-support-for-txnoffsetcommitrequest",2017-05-12 16:27:11,Apurva Mehta,Mixed
238e739782222b17f33a3ac5a0374d8dac3be28f,"KAFKA-5227; Remove unsafe assertion, make jaas config safer

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3037 from rajinisivaram/KAFKA-5227",2017-05-13 01:38:35,Rajini Sivaram,Not TDD
f21f8f2d44f97eba4ce155ac9fcc8432f00cad24,"KAFKA-4982; Add listener tags to socket-server-metrics (KIP-136)

Author: Edoardo Comar <ecomar@uk.ibm.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3004 from edoardocomar/KAFKA-4982",2017-05-13 02:42:37,Edoardo Comar,Mixed
a1c8e7d941ad9c765dac232435a297f905eeeed5,"MINOR: Rename InitPidRequest/InitPidResponse to InitProducerIdRequest/InitProducerIdResponse

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #2997 from hachikuji/minor-rename-initpid",2017-05-12 19:59:34,Jason Gustafson,Mixed
9198467eb293435385edcef9028a59fa41a3828a,"KAFKA-4144: Allow per stream/table timestamp extractor

Author: Jeyhun Karimov <je.karimov@gmail.com>

Reviewers: Damian Guy, Eno Thereska, Matthias J. Sax, Guozhang Wang

Closes #2466 from jeyhunkarimov/KAFKA-4144",2017-05-12 21:38:49,Jeyhun Karimov,Mixed
e3892c29c342629be789437c2c52b4e367af52ef,"MINOR: Handle nulls in NonEmptyListValidator

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3045 from ewencp/minor-non-empty-list-validator-nulls",2017-05-14 18:33:05,Ewen Cheslack-Postava,Mixed
885643ce100b3b74a2b6859bf0b85103d8c05ef8,"KAFKA-5230; Fix conversion of Class configs to handle nested classes properly

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #3044 from ewencp/kafka-5230-nested-class-recommended-values",2017-05-15 00:39:12,Ewen Cheslack-Postava,Mixed
bc55f85237cb46e73c6774298cf308060a4a739c,"MINOR: Consolidate Topic classes

During the 0.11.0.0 cycle, a Java version of the class
was introduced so that Streams could use it. Given that
it includes the bulk of the functionality of the Scala
version of the class, it makes sense to consolidate them.

While doing this, I noticed that one of the tests for
the Java class (`shouldThrowOnInvalidTopicNames`) was
broken as it only checked if the first topic name in
the list was invalid.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #3046 from ijuma/consolidate-topic-classes",2017-05-15 09:10:09,Ismael Juma,Mixed
f56bbb6510df8c12db3ad075e2f6c78dd0092d60,"KAFKA-5232; Fix Log.parseTopicPartitionName to handle deleted topics with a period in the name

This issue would only be triggered if a broker was restarted while
deletion was still taking place.

Included a few minor improvements to that method and its tests.

Author: Jaikiran Pai <jaikiran.pai@gmail.com>
Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3050 from jaikiran/KAFKA-5232-trunk",2017-05-15 09:14:26,Jaikiran Pai,Mixed
50eacb7b45143dbc26a341620290991428194e4d,"MINOR: Fix one flaky test in MetricsTest and improve checks for another

* Fix flakiness of `testBrokerTopicMetricsUnregisteredAfterDeletingTopic` by not
consuming messages. Filed KAFKA-5238 to track the issue that metrics for a deleted
topic may be re-created if there are fetch requests in the purgatory.

* Check the log size in `testBrokerTopicMetricsBytesInOut` before attempting to read
the `replicationBytesIn` metric. This helps understand where things have gone wrong
if if the metric has not increased (i.e. if it was an issue replicating or with the metric).

* Only remove the replication bytes in/out if the metrics are defined. This should not
affect the behaviour due to the tags, but it makes the code clearer. We've seen some
cases in Jenkins when the metric does not exist and it's still unclear how that can
happen.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #3042 from ijuma/more-informative-assertion-for-flaky-metrics-test",2017-05-15 14:08:18,Ismael Juma,Not TDD
a511a47020a1a3f58c7778b5d5aba08d2b4876d6,"KAFKA-5203; Metrics: fix resetting of histogram sample

Without the histogram cleanup, the percentiles are calculated
incorrectly after purging of one or more samples: event counts
go out of sync with counts in histogram buckets, and bucket
with lower value gets chosen for the given quantile.

This change adds the necessary histogram cleanup.

Author: Ivan A. Melnikov <iv@altlinux.org>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #3002 from iv-m/kafka-5203-percentiles-fix",2017-05-15 10:50:33,Ivan A. Melnikov,Not TDD
3e6669000f082808999a7216b00c4b0f5a94e1da,"MINOR: Eliminate PID terminology from non test code

Producer id is used instead.

Also refactored TransactionLog schema code to follow
our naming convention and to have better structure.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #3041 from ijuma/eliminate-pid-terminology",2017-05-15 11:26:08,Ismael Juma,Mixed
0186794104b7106fe426024d65730fec79ad999a,"KAFKA-5248; Remove unused/unneeded retention time in TxnOffsetCommitRequest

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #3058 from hachikuji/KAFKA-5248",2017-05-15 12:58:50,Jason Gustafson,Not TDD
46aa88b9cf82971a0890f4f83efa9639f84c677b,"KAFKA-5244; Refactor BrokerTopicStats and ControllerStats so that they are classes

This removes the need to force object initialisation via hacks to register
the relevant Yammer metrics during start-up.

It also works around issues caused by tests that delete JVM-wide singleton
metrics (like `MetricsDuringTopicCreationDeletionTest`). Without this
change, they would never be registered again. After this change, they will
be registered again during KafkaServer start-up.

It would be even better not to rely on JVM side singleton metrics (like we do
for Kafka Metrics), but that's a bigger change that should be considered
separately.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #3059 from ijuma/kafka-5244-broker-static-stats-and-controller-stats-as-classes",2017-05-15 22:35:17,Ismael Juma,Mixed
4c75f31a5f80e6a717d040b0534c79f5ed8d9346,"KAFKA-5179; Log connection termination during authentication

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma, Jun Rao

Closes #2980 from rajinisivaram/KAFKA-5179",2017-05-15 18:13:20,Rajini Sivaram,Mixed
7bb551b4a1737f1819e11e08248b1f2277a0680e,"KAFKA-5249; Fix incorrect producer snapshot offsets when recovering segments

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #3060 from hachikuji/KAFKA-5249",2017-05-15 15:23:26,Jason Gustafson,Mixed
d66e7af6526f208900a5d6cb588cf47058800804,"KAFKA-5129; Add ACL checks for Transactional APIs

Add ACL checks for Transactional APIs

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #2979 from dguy/kafka-5129",2017-05-16 09:57:15,Damian Guy,Mixed
4e3092d27648b9db18a496d16cd44f600429dcfc,"MINOR: Some minor improvements to TxnOffsetCommit handling

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3040 from hachikuji/txn-offset-commit-cleanups",2017-05-16 13:22:15,Jason Gustafson,Mixed
73703a15c5006ddca166a458dcde72e17c91de4a,"KAFKA-5241: GlobalKTable should checkpoint offsets after restoring state

Ensure checkpointable offsets for GlobalKTables are always written on close.

Author: Tommy Becker <tobecker@tivo.com>

Reviewers: Damian Guy, Eno Thereska, Guozhang Wang

Closes #3054 from twbecker/KAFKA-5241",2017-05-16 13:59:19,Tommy Becker,Mixed
ebc7f7caaeb47c9588d79a2f3ed496daa0bd39e5,"KAFKA-4923: Add Exactly-Once Semantics to Streams

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Apurva Metha, Ismael Juma, Damian Guy, Eno Thereska, Guozhang Wang

Closes #2945 from mjsax/kafka-4923-add-eos-to-streams",2017-05-16 17:23:11,Matthias J. Sax,Mixed
1cea4d8f5a51cc5795ddd3af2ea015b9e14d937d,"KAFKA-4714; Flatten and Cast single message transforms (KIP-66)

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Shikhar Bhushan <shikhar@confluent.io>, Jason Gustafson <jason@confluent.io>

Closes #2458 from ewencp/kafka-3209-even-more-transforms",2017-05-16 23:05:35,Ewen Cheslack-Postava,Mixed
6910baf548ebad4c1530432e51be40793b4a4f10,"KAFKA-4772: Exploit #peek to implement #print() and other methods

I remove `KeyValuePrinter` and `KStreamForeach` two class, then implements them by `KStreamPeek`.
So, now `KStreamPeek` can do `KeyValuePrinter` and `KStreamForeach` job.

Author: jameschien <jameschien@staff.ruten.com.tw>
Author: JamesChien <jedichien@users.noreply.github.com>

Reviewers: Matthias J. Sax, Guozhang Wang

Closes #2955 from jedichien/trunk",2017-05-17 11:15:31,James Chien,Mixed
2181ae768719a9ae3a929ba875faa89c67edf643,"KAFKA-4743; [KIP-122] Add Reset Consumer Group Offsets tooling

Author: Jorge Quilcate <quilcate.jorge@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #2624 from jeqo/feature/rewind-consumer-group-offset",2017-05-17 14:24:40,Jorge Quilcate,Not TDD
b3a33ce4b81a20ae5635cf28490fd2e1f9d86141,"KAFKA-5188; Integration tests for transactions

Author: Apurva Mehta <apurva@confluent.io>
Author: Jason Gustafson <jason@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #2994 from apurvam/KAFKA-5188-exactly-once-integration-tests",2017-05-17 16:20:33,Apurva Mehta,Mixed
c64cfd2e2bffd0a8fcfa515d3bbbe76416a89ee7,"KAFKA-5231: Bump up producer epoch when sending abort txn markers on InitPid

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Jason Gustafson, Jun Rao

Closes #3066 from guozhangwang/K5231-bump-up-epoch-when-abort-txn",2017-05-17 18:05:12,Guozhang Wang,Mixed
24915206260c33cd7118db5359f3927d3be1ff60,"KAFKA-5036; hold onto the leader lock in Partition while serving an O…

…ffsetForLeaderEpoch request

Author: Jun Rao <junrao@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Ben Stopford <benstopford@gmail.com>

Closes #3074 from junrao/kafka-5036",2017-05-17 18:54:46,Jun Rao,Not TDD
9815e18fefa27d8d901356ec1d994a41b4db4622,"KAFKA-3266; Describe, Create and Delete ACLs Admin APIs (KIP-140)

Includes server-side code, protocol and AdminClient.

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #2941 from cmccabe/KAFKA-3266",2017-05-18 03:20:30,Colin P. Mccabe,Mixed
e1abf17708918b82d3974ea028a4d74e3892fa0f,"KAFKA-2273; Sticky partition assignment strategy (KIP-54)

This PR implements a new partition assignment strategy called ""sticky"", and it's purpose is to balance partitions across consumers in a way that minimizes moving partitions around, or, in other words, preserves existing partition assignments as much as possible.

This patch is co-authored with rajinisivaram and edoardocomar.

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #1020 from vahidhashemian/KAFKA-2273",2017-05-17 20:15:17,Vahid Hashemian,Mixed
972b7545363ae85a55f94cf7ea83614be8840b75,"KAFKA-3267; Describe and Alter Configs Admin APIs (KIP-133)

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #3076 from ijuma/kafka-3267-describe-alter-configs-protocol",2017-05-18 06:51:02,Ismael Juma,Mixed
45f2261763eac5caaebf860daab32ef5337c9293,"KAFKA-3487: Support classloading isolation in Connect (KIP-146)

Author: Konstantine Karantasis <konstantine@confluent.io>

Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #3028 from kkonstantine/KAFKA-3487-Support-classloading-isolation-in-Connect",2017-05-18 10:39:15,Konstantine Karantasis,Mixed
d662b09c9f32d7d4dcfc18522a4d2789b43d319c,"KAFKA-5268; Fix bounce test transient failure by clearing partitions before writing Complete state to transaction log

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #3089 from hachikuji/KAFKA-5268",2017-05-18 11:17:30,Jason Gustafson,Mixed
34e379f10779bfb17fb399fde0357d17dc34ab62,"KAFKA-5171; TC should not accept empty string transactional id

This is a rebase version of [PR#2973](https://github.com/apache/kafka/pull/2973).

guozhangwang , please review this updated PR.

Author: umesh chaudhary <umesh9794@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #3086 from umesh9794/mylocal",2017-05-18 11:38:44,umesh chaudhary,Mixed
65edd64ca4902c9b2bc48e952056235f016031e1,"KAFKA-3070: SASL unit tests dont work with IBM JDK

Use IBM Kerberos module for SASL tests if running on IBM JDK

Developed with edoardocomar
Based on https://github.com/apache/kafka/pull/738 by rajinisivaram

Author: Mickael Maison <mickael.maison@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>, Edoardo Comar <ecomar@uk.ibm.com>

Closes #2878 from mimaison/KAFKA-3070",2017-05-18 16:11:14,Mickael Maison,Mixed
56623efd73ec77e68cf35021d18d630b27062e82,"KAFKA-4667: Connect uses AdminClient to create internal topics when needed (KIP-154)

The backing store for offsets, status, and configs now attempts to use the new AdminClient to look up the internal topics and create them if they don’t yet exist. If the necessary APIs are not available in the connected broker, the stores fall back to the old behavior of relying upon auto-created topics. Kafka Connect requires a minimum of Apache Kafka 0.10.0.1-cp1, and the AdminClient can work with all versions since 0.10.0.0.

All three of Connect’s internal topics are created as compacted topics, and new distributed worker configuration properties control the replication factor for all three topics and the number of partitions for the offsets and status topics; the config topic requires a single partition and does not allow it to be set via configuration. All of these new configuration properties have sensible defaults, meaning users can upgrade without having to change any of the existing configurations. In most situations, existing Connect deployments will have already created the storage topics prior to upgrading.

The replication factor defaults to 3, so anyone running Kafka clusters with fewer nodes than 3 will receive an error unless they explicitly set the replication factor for the three internal topics. This is actually desired behavior, since it signals the users that they should be aware they are not using sufficient replication for production use.

The integration tests use a cluster with a single broker, so they were changed to explicitly specify a replication factor of 1 and a single partition.

The `KafkaAdminClientTest` was refactored to extract a utility for setting up a `KafkaAdminClient` with a `MockClient` for unit tests.

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2984 from rhauch/kafka-4667",2017-05-18 16:02:29,Randall Hauch,Mixed
b661d3b8ab37fc63b44145ba29d129b07c1582b9,"MINOR: Small refactor of request quotas handling in KafkaApis

- Avoid unnecessary inner methods
- Remove redundant parameter in `sendResponseExemptThrottle`
- Go through `sendResponseExemptThrottle` for produce requests with acks=0
- Tighten how we handle cases where there’s no response

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #3087 from ijuma/kafka-apis-improvements",2017-05-19 00:14:08,Ismael Juma,Mixed
e28752357705568219315375c666f8e500db9c12,"KAFKA-5192: add WindowStore range scan (KIP-155)

Implements range scan for keys in windowed and session stores

Modifies caching session and windowed stores to use segmented cache keys.
Cache keys are internally prefixed with their segment id to ensure key ordering in the cache matches the ordering in the underlying store for keys spread across multiple segments.
This should also result in fewer cache keys getting scanned for queries spanning only some segments.

Author: Xavier Léauté <xavier@confluent.io>

Reviewers: Damian Guy, Guozhang Wang

Closes #3027 from xvrl/windowstore-range-scan",2017-05-18 17:02:51,Xavier Léauté,Mixed
abe699176babe4f065b67b2b72d20daa0a2e46a1,"KAFKA-3878; Support exponential backoff policy via reconnect.backoff.max (KIP-144)

Summary:
- add `reconnect.backoff.max.ms` common client configuration parameter
- if `reconnect.backoff.max.ms` > `reconnect.backoff.ms`, apply an exponential backoff policy
- apply +/- 20% random jitter to smooth cluster reconnects

Author: Dana Powers <dana.powers@gmail.com>

Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Roger Hoover <roger.hoover@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #1523 from dpkp/exp_backoff",2017-05-19 14:06:40,Dana Powers,Mixed
61bab2d875ab5e03d0df4f62217346549a4c64c3,"KAFKA-4714; TimestampConverter transformation (KIP-66)

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Jason Gustafson <jason@confluent.io>

Closes #3065 from ewencp/kafka-3209-timestamp-converter",2017-05-19 11:26:59,Ewen Cheslack-Postava,Mixed
8b04d8ba071fbcafc72a17d4cbfe6f00613e59b3,"KAFKA-5269; Retry on unknown topic/partition error in transactional requests

We should retry AddPartitionsToTxnRequest and TxnOffsetCommitRequest when receiving an UNKNOWN_TOPIC_OR_PARTITION error.

As described in the JIRA: It turns out that the `UNKNOWN_TOPIC_OR_PARTITION` is returned from the request handler in KafkaAPis for the AddPartitionsToTxn and the TxnOffsetCommitRequest when the broker's metadata doesn't contain one or more partitions in the request. This can happen for instance when the broker is bounced and has not received the cluster metadata yet.

We should retry in these cases, as this is the model followed by the consumer when committing offsets, and by the producer with a ProduceRequest.

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #3094 from apurvam/KAFKA-5269-handle-unknown-topic-partition-in-transaction-manager",2017-05-19 18:51:42,Apurva Mehta,Mixed
7fad45557e4cb7b345f34cec32f910b437c59bc2,"KAFKA-3995; KIP-126 Allow KafkaProducer to split and resend oversized batches

Author: Jiangjie Qin <becket.qin@gmail.com>

Reviewers: Joel Koshy <jjkoshy.w@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2638 from becketqin/KAFKA-3995",2017-05-21 17:31:31,Jiangjie Qin,Mixed
dc10b0ea014974b450f2abcd4a58e09d5b988e9e,"MINOR: Fix race condition in TestVerifiableProducer sanity test

## Fixes race condition in TestVerifiableProducer sanity test:
The test starts a producer, waits for at least 5 acks, and then
logs in to the worker to grep for the producer process to figure
out what version it is running.

The problem was that the producer was set up to produce 1000 messages
at a rate of 1000 msgs/s and then exit. This means it will have a
typical runtime slightly above 1 second.

Logging in to the vagrant instance might take longer than that thus
resulting in the process grep to fail, failing the test.

This commit doesn't really fix the issue - a proper fix would be to tell
the producer to stick around until explicitly killed - but it increases
the chances of the test passing, at the expense of a slightly longer
runtime.

## Improves error reporting when is_version() fails

Author: Magnus Edenhill <magnus@edenhill.se>

Reviewers: Apurva Mehta <apurva@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2765 from edenhill/trunk",2017-05-21 18:23:12,Magnus Edenhill,Not TDD
495836a4a27c2219f72a5f3776ba8e5216493b41,"KAFKA-4923: Modify compatibility test for Exaclty-Once Semantics in Streams

 - add broker compatibility system tests

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy, Eno Thereska, Guozhang Wang

Closes #2974 from mjsax/kafka-4923-add-eos-to-streams-add-broker-check-and-system-test",2017-05-21 22:16:18,Matthias J. Sax,Not TDD
65861a712ddf67eb071a00218730926fdeef7084,"KAFKA-5277; Sticky Assignor should not cache previous assignment (KIP-54 follow-up)

... plus some minor cleanup

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3092 from vahidhashemian/KAFKA-5277",2017-05-22 10:59:38,Vahid Hashemian,Mixed
fcdbb71953fc4c92559a9c7adb4cb8ad4a74acd6,"KAFKA-5186; Avoid expensive log scan to build producer state when upgrading

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #3113 from hachikuji/KAFKA-5186",2017-05-22 15:41:26,Jason Gustafson,Mixed
e3e2f1d22d17a20ccccf67218c600e7e1647e1ca,"MINOR: Broker should disallow downconversion of transactional/idempotent records

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #3118 from hachikuji/disallow-transactional-idempotent-downconversion",2017-05-22 20:00:07,Jason Gustafson,Mixed
d1853f791147d66303c2700a8e58af762518188c,"KAFKA-5247; Materialize committed offsets in offset order

With this patch, offset commits are always materialized according to the order of the commit records in the offsets topic.

Before this patch, transactional offset commits were materialized in transaction order. However, the log cleaner will always preserve the record with the greatest offset. This meant that if there was a mix of offset commits from a consumer and a transactional producer, then it we would switch from transactional order to offset order after cleaning, resulting in an inconsistent state.

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #3108 from apurvam/KAFKA-5247-materialize-committed-offsets-in-offset-order",2017-05-23 09:45:31,Apurva Mehta,Mixed
70ec4b1d927cad7373eda2c54ef44bfc4275832f,"MINOR: Log transaction metadata state transitions plus a few cleanups

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #3081 from hachikuji/minor-add-txn-transition-logging",2017-05-23 09:53:18,Jason Gustafson,Mixed
49587750570a2aaf332eb73f5aad373196f984ce,"MINOR: improve EmbeddedKafkaCluster test utility for deleting topics

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Bill Bejeck, Damian Guy, Eno Thereska, Guozhang Wang

Closes #3104 from mjsax/minor-improve-embedded-kafka-cluster",2017-05-23 11:53:13,Matthias J. Sax,Not TDD
1bf64833168e81015e1f30a30c64eb6849c15422,"KAFKA-5280: Protect txn metadata map with read-write lock

Two major changes plus one minor change:

0. change stateLock to a read-write lock.

1. Put the check of ""isCoordinator"" and ""coordinatorLoading"" together with the return of the metadata, under one read lock block, since otherwise we can get incorrect behavior if there is a change in the metadata cache after the check but before the accessing of the metadata.

2. Grab the read lock right before trying to append to local txn log, and until the local append returns; this is to avoid the scenario that the epoch has actually changed when we are appending to local log (e.g. emigration followed by immigration).

3. only watch on txnId instead of txnId and txnPartitionId in the txn marker purgatory, and disable reaper thread, as we can now safely clear all the delayed operations by traversing the marker queues.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Jason Gustafson, Jun Rao

Closes #3082 from guozhangwang/K5231-read-write-lock",2017-05-23 13:34:43,Guozhang Wang,Mixed
516d8457d8142111a91af94cab918c84990685da,"KAFKA-5135; Controller Health Metrics (KIP-143)

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>, Onur Karaman <okaraman@linkedin.com>

Closes #2983 from ijuma/kafka-5135-controller-health-metrics-kip-143",2017-05-24 00:37:06,Ismael Juma,Mixed
4d89db968257c0c3273ece7e5546cb95ddcbeb46,"KAFKA-5273: Make KafkaConsumer.committed query the server for all partitions

Before this patch the consumer would return the cached offsets for partitions in its current assignment. This worked when all the offset commits went through the consumer.

With KIP-98, offsets can be committed transactionally through the producer. This means that relying on cached positions in the consumer returns incorrect information: since commits go through the producer, the cache is never updated.

Hence we need to update the `KafkaConsumer.committed` method to always lookup the server for the last committed offset to ensure it gets the correct information every time.

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Jason Gustafson, Guozhang Wang

Closes #3119 from apurvam/KAFKA-5273-kafkaconsumer-committed-should-always-hit-server",2017-05-23 23:08:57,Apurva Mehta,Mixed
38f6cae9e879baa35c5dbc5829bf09ecd59930c2,"KAFKA-5259; TransactionalId auth implies ProducerId auth

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Jun Rao <junrao@gmail.com>

Closes #3075 from hachikuji/KAFKA-5259-FIXED",2017-05-24 15:26:46,Jason Gustafson,Mixed
fdcee8b8b3c027cdc1b13031fa19fcfc7de5609f,"MINOR: GroupCoordinator can append with group lock

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #3133 from hachikuji/minor-replica-manager-append-refactor",2017-05-24 21:00:44,Jason Gustafson,Mixed
cea319a4ad9c55d3d3263cf7a4224c25772d0e11,"KAFKA-4935; Deprecate client checksum API and compute lazy partial checksum for magic v2

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #3123 from hachikuji/KAFKA-4935",2017-05-25 08:21:01,Jason Gustafson,Mixed
64fc1a7cae348fad10e84c5ebc457c2a391573ee,"KAFKA-5263: Avoid tight polling loop in consumer with no ready nodes

For consumers with manual partition assignment, await metadata when there are no ready nodes to avoid busy polling.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #3124 from rajinisivaram/KAFKA-5263",2017-05-25 11:23:18,Rajini Sivaram,Mixed
20e2008785d46aa0500b02d8737380c50d66da3b,"KAFKA-5279: TransactionCoordinator must expire transactionalIds

remove transactions that have not been updated for at least `transactional.id.expiration.ms`

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Apurva Mehta, Guozhang Wang

Closes #3101 from dguy/kafka-5279",2017-05-25 11:01:10,Damian Guy,Mixed
73ca0d215ead9574487744eb89f7ae677a9e13ea,"KAFKA-5320: Include all request throttling in client throttle metrics

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3137 from rajinisivaram/KAFKA-5320",2017-05-25 20:28:18,Rajini Sivaram,Mixed
37433638271718344498d695d5da08db12c24eed,"MINOR: Preserve the base offset of the original record batch in V2

The previous code did not handle this correctly if a batch was
compacted more than once.

Also add test case for duplicate check after log cleaning and
improve various comments.

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3145 from hachikuji/minor-improve-base-sequence-docs",2017-05-26 09:46:09,Jason Gustafson,Mixed
faa1803aa35871e5e040a22b7fcec61a2be16e24,"KAFKA-5309: Stores not queryable after one thread died

 - introduces a new thread state DEAD
 - ignores DEAD threads when querying

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy, Eno Thereska, Guozhang Wang

Closes #3140 from mjsax/kafka-5309-stores-not-queryable",2017-05-26 09:42:02,Matthias J. Sax,Mixed
7892b4e6c7c32be09d78a8bbbeeaa823d3197aaa,"KAFKA-5128; Check inter broker version in transactional methods

Add check in `KafkaApis` that the inter broker protocol version is at least `KAFKA_0_11_0_IV0`, i.e., supporting transactions

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #3103 from dguy/kafka-5128",2017-05-26 09:52:47,Damian Guy,Mixed
68eed84f24a4771ccd805d8f39340eb7599df2ed,"KAFKA-5333; Remove Broker ACL resource type

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #3154 from ijuma/kafka-5333-remove-broker-acl-resource-type",2017-05-26 15:25:02,Ismael Juma,Mixed
0bc4f75eedf14af6d0b2e3e9be62a460b1049d0b,"KAFKA-5191: Autogenerate Consumer Fetcher metrics

Autogenerate docs for the Consumer Fetcher's metrics. This is a smaller subset of the original PR https://github.com/apache/kafka/pull/1202.

CC ijuma benstopford hachikuji

Author: James Cheng <jylcheng@yahoo.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>

Closes #2993 from wushujames/fetcher_metrics_docs",2017-05-26 15:34:20,James Cheng,Mixed
dfa3c8a92dddd58cab95e12c72669f250bb99683,"KAFKA-5316; LogCleaner should account for larger record sets after cleaning

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #3142 from hachikuji/KAFKA-5316",2017-05-28 09:57:59,Jason Gustafson,Mixed
a8794d8a5d18bb4eaafceac1ef675243af945862,"KAFKA-5260; Producer should not send AbortTxn unless transaction has actually begun

Keep track of when a transaction has begun by setting a flag, `transactionStarted` when a successfull `AddPartitionsToTxnResponse` or `AddOffsetsToTxnResponse` had been received. If an `AbortTxnRequest` about to be sent and `transactionStarted` is false, don't send the request and transition the state to `READY`

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #3126 from dguy/kafka-5260",2017-05-29 22:52:59,Damian Guy,Mixed
6b03497915665bb4823073a5a34b03be709eb287,"KAFKA-5344; set message.timestamp.difference.max.ms back to Long.MaxValue

Author: Jiangjie Qin <becket.qin@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3163 from becketqin/KAFKA-5344",2017-05-30 15:44:34,Jiangjie Qin,Mixed
b3788d8dcbeee7a20f562e878c187a75bac11ff0,"KAFKA-5316; Follow-up with ByteBufferOutputStream and other misc improvements

ByteBufferOutputStream improvements:
* Document pitfalls
* Improve efficiency when dealing with direct byte buffers
* Improve handling of buffer expansion
* Be consistent about using `limit` instead of `capacity`
* Add constructors that allocate the internal buffer

Other minor changes:
* Fix log warning to specify correct Kafka version
* Clean-ups

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3166 from ijuma/minor-kafka-5316-follow-ups",2017-05-30 12:53:32,Ismael Juma,Mixed
f0745cd514a8af6ea22e1fddfef66f0e69ae8b1c,"KAFKA-4603: Disallow abbreviations in OptionParser constructor

KAFKA-4603 the command parsed error
Using ""new OptionParser"" might result in parse error

Change all the OptionParser constructor in Kafka into ""new OptionParser(false)""

Author: xinlihua <xin.lihua1@zte.com.cn>
Author: unknown <00067310@A23338408.zte.intra>
Author: auroraxlh <xin.lihua1@zte.com.cn>
Author: xin <xin.lihua1@zte.com.cn>

Reviewers: Damian Guy, Guozhang Wang

Closes #2349 from auroraxlh/fix_OptionParser_bug",2017-05-30 13:53:32,xinlihua,Not TDD
80223b14ee092e95d05b40b12631df2d6db7ef53,"KAFKA-5202: Handle topic deletion while trying to send txn markers

Here is the sketch of this proposal:

1. When it is time to send the txn markers, only look for the leader node of the partition once instead of retrying, and if that information is not available, it means the partition is highly likely been removed since it was in the cache before. In this case, we just remove the partition from the metadata object and skip putting into the corresponding queue, and if all partitions' leader broker are non-available, complete this delayed operation to proceed to write the complete txn log entry.

2. If the leader id is unknown from the cache but the corresponding node object with the listener name is not available, it means that the leader is likely unavailable right now. Put it into a separate queue and let sender thread retry fetching its metadata again each time upon draining the queue.

One caveat of this approach is the delete-and-recreate case, and the argument is that since all the messages are deleted anyways when deleting the topic-partition, it does not matter whether the markers are on the log partitions or not.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Apurva Mehta <apurva@confluent.io>, Damian Guy <damian.guy@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #3130 from guozhangwang/K5202-handle-topic-deletion",2017-05-30 14:35:51,Guozhang Wang,Mixed
6021618f9dafa3478104575d307e7bcd2cb4cca9,"MINOR: onControllerResignation should be invoked if triggerControllerMove is called

Also update the test to be simpler since we can use a mock event to simulate the issue
more easily (thanks Jun for the suggestion). This should fix two issues:

1. A transient test failure due to a NPE in ControllerFailoverTest.testMetadataUpdate:

```text
Caused by: java.lang.NullPointerException
	at kafka.controller.ControllerBrokerRequestBatch.addUpdateMetadataRequestForBrokers(ControllerChannelManager.scala:338)
	at kafka.controller.KafkaController.sendUpdateMetadataRequest(KafkaController.scala:975)
	at kafka.controller.ControllerFailoverTest.testMetadataUpdate(ControllerFailoverTest.scala:141)
```

The test was creating an additional thread and it does not seem like it was doing the
appropriate synchronization (perhaps this became more of an issue after we changed
the Controller to be single-threaded and changed the locking)

2. Setting `activeControllerId.set(-1)` in `triggerControllerMove` causes `Reelect` not to invoke `onControllerResignation`. Among other things, this causes an `IllegalStateException` to be thrown when `KafkaScheduler.startup` is invoked for the second time without the corresponding `shutdown`. We now simply call `onControllerResignation` as part of `triggerControllerMove`.

Finally, I included a few clean-ups:

1. No longer update the broker state in `onControllerFailover`. This is no longer needed
since we removed the `RunningAsController` state (KAFKA-3761).
2. Trivial clean-ups in KafkaController
3. Removed unused parameter in `ZkUtils.getPartitionLeaderAndIsrForTopics`

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #2935 from ijuma/on-controller-resignation-if-trigger-controller-move",2017-05-30 16:59:33,Ismael Juma,Not TDD
c060c482855bb9f51e19dde51911645413d85260,"KAFKA-5150; Reduce LZ4 decompression overhead

- reuse decompression buffers in consumer Fetcher
- switch lz4 input stream to operate directly on ByteBuffers
- avoids performance impact of catching exceptions when reaching the end of legacy record batches
- more tests with both compressible / incompressible data, multiple
  blocks, and various other combinations to increase code coverage
- fixes bug that would cause exception instead of invalid block size
  for invalid incompressible blocks
- fixes bug if incompressible flag is set on end frame block size

Overall this improves LZ4 decompression performance by up to 40x for small batches.
Most improvements are seen for batches of size 1 with messages on the order of ~100B.
We see at least 2x improvements for for batch sizes of < 10 messages, containing messages < 10kB

This patch also yields 2-4x improvements on v1 small single message batches for other compression types.

Full benchmark results can be found here
https://gist.github.com/xvrl/05132e0643513df4adf842288be86efd

Author: Xavier Léauté <xavier@confluent.io>
Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #2967 from xvrl/kafka-5150",2017-05-31 02:22:07,Xavier Léauté,Mixed
3250cc767e8ef79d0160312a8b605535d3002851,"KAFKA-5324; AdminClient: add close with timeout, fix some timeout bugs

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3141 from cmccabe/KAFKA-5324",2017-05-31 03:02:52,Colin P. Mccabe,Not TDD
d41cf1b77819ede5716b31683d0137eb60cb7bfb,"KAFKA-5251; Producer should cancel unsent AddPartitions and Produce requests on abort

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3161 from hachikuji/KAFKA-5251",2017-05-30 20:32:51,Jason Gustafson,Mixed
d082563907103ea79eed681305df7093053f52ec,"KAFKA-5211; Do not skip a corrupted record in consumer

Author: Jiangjie Qin <becket.qin@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3114 from becketqin/KAFKA-5211",2017-05-30 22:41:21,Jiangjie Qin,Mixed
dd8cdb79d356b3049c21bf00613b8144dff0882c,"KAKFA-5334: Allow rocksdb.config.setter to be specified as a String or Class instance

Handle` rocksdb.config.setter` being set as a class name or class
instance.

Author: Tommy Becker <tobecker@tivo.com>
Author: Tommy Becker <twbecker@gmail.com>

Reviewers: Matthias J. Sax, Damian Guy, Guozhang Wang

Closes #3155 from twbecker/KAFKA-5334",2017-05-30 23:21:12,Tommy Becker,Mixed
2cc8f48ae5358087381fa5f79233789499d6b939,"KAFKA-5308; TC should handle UNSUPPORTED_FOR_MESSAGE_FORMAT in WriteTxnMarker response

Return UNSUPPORTED_MESSAGE_FORMAT in handleWriteTxnMarkers when a topic is not the correct message format.
Remove any TopicPartitions that have same error from those waiting for markers

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3152 from dguy/kafka-5308",2017-05-30 23:38:50,Damian Guy,Mixed
ef9551297c815a0ac3065a65a0831863090714f0,"KAFKA-5266; Follow-up improvements for consumer offset reset tool (KIP-122)

Implement improvements defined here: https://issues.apache.org/jira/browse/KAFKA-5266

Author: Jorge Quilcate Otoya <quilcate.jorge@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3102 from jeqo/feature/KAFKA-5266",2017-05-31 00:50:48,Jorge Quilcate Otoya,Not TDD
aebba89a2b9b5ea6a7cab2599555232ef3fe21ad,"KAFKA-5349; Fix illegal state error in consumer's ListOffset handler

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #3175 from hachikuji/KAFKA-5349",2017-05-31 10:27:16,Jason Gustafson,Mixed
da9a171c99eb456378bdda95a563d09dfd9af4d8,"KAFKA-5265; Move ACLs, Config, Topic classes into org.apache.kafka.common

Also introduce TopicConfig.

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3120 from cmccabe/KAFKA-5265",2017-05-31 17:35:31,Colin P. Mccabe,Mixed
81f0c1e8f2ba2d86f061361b5ee33bb8e6f640c5,"KAFKA-5093; Avoid loading full batch data when possible when iterating FileRecords

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3160 from hachikuji/KAFKA-5093",2017-05-31 14:11:47,Jason Gustafson,Mixed
dc5bf4bd453495af050ea7c0ec7a66b8d2b2e8d4,"KAFKA-5218; New Short serializer, deserializer, serde

Author: Mario Molina <mmolimar@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>, Michael G. Noll <michael@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3017 from mmolimar/KAFKA-5218",2017-05-31 15:09:58,Mario Molina,Not TDD
647afeff6a2e3fd78328f6989e8d9f96bcde5121,"KAFKA-5353; baseTimestamp should always have a create timestamp

This makes the case where we build the records from scratch consistent
with the case where update the batch header ""in place"". Thanks to
edenhill who found the issue while testing librdkafka.

The reason our tests don’t catch this is that we rely on the maxTimestamp
to compute the record level timestamps if log append time is used.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3177 from ijuma/set-base-sequence-for-log-append-time",2017-06-01 00:16:55,Ismael Juma,Not TDD
7311dcbc5363d59dd0a0de86518dd12a7b259ca4,"KAFKA-5291; AdminClient should not trigger auto creation of topics

- Added a boolean `allow_auto_topic_creation` to MetadataRequest and
bumped the protocol version to V4.

- When connecting to brokers older than 0.11.0.0, the `allow_auto_topic_creation`
field won't be considered, so we send a metadata request for all topics
to keep the behavior consistent.

- Set `allow_auto_topic_creation` to false in the new AdminClient and
StreamsKafkaClient (which exists for the purpose of creating topics
manually); set it to true everywhere else for now. Other clients will eventually
rely on client-side auto topic creation, but that’s not there yet.

- Add `allowAutoTopicCreation` field to `Metadata`, which is used by
`DefaultMetadataUpdater`. This is not strictly needed for the new
`AdminClient`, but it avoids surprises if it ever adds a topic to `Metadata`
via `setTopics` or `addTopic`.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #3098 from ijuma/kafka-5291-admin-client-no-auto-topic-creation",2017-06-01 01:00:11,Ismael Juma,Mixed
681c6fc1fb37c9cfec00df09fdfe5bf1b11f3b4b,"KAFKA-5350: Modify unstable annotations in Streams API

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Jason Gustafson <jason@confluent.io>

Closes #3172 from guozhangwang/K5350-compatibility-annotations",2017-05-31 19:30:43,Guozhang Wang,Not TDD
6360e04e70b8f5ce562c2f24f85208aaae788363,"KAFKA-5226; Fixes issue where adding topics matching a regex

subscribed stream may not be detected by all followers until
onJoinComplete returns.

Author: Bill Bejeck <bill@confluent.io>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3157 from bbejeck/KAFKA-5226_null_pointer_source_node_deserialize",2017-05-31 19:36:08,Bill Bejeck,Mixed
e4a6b50deca8fabc9880c6764334bfaa830a6d5e,"KAFKA-5340; Batch splitting should preserve magic and transactional flag

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Jiangjie Qin <becket.qin@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #3162 from hachikuji/KAFKA-5340",2017-05-31 21:31:52,Jason Gustafson,Mixed
049abe7efa17c9660fce7b57b4c235e24c72315c,"KAFKA-5351: Reset pending state when returning an error in appendTransactionToLog

Without this patch, future client retries would get the `CONCURRENT_TRANSACTIONS` error code indefinitely, since the pending state wouldn't be cleared when the append to the log failed.

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3184 from apurvam/KAFKA-5351-clear-pending-state-on-retriable-error",2017-05-31 22:48:43,Apurva Mehta,Mixed
e0150a25e8127c282f54a0395eb2b1c80ebda94a,"MINOR: Traverse plugin path recursively in Connect (KIP-146)

Author: Konstantine Karantasis <konstantine@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #3173 from kkonstantine/MINOR-Traverse-plugin-path-recursively-in-Connect",2017-06-01 02:07:53,Konstantine Karantasis,Mixed
8e8b3c56572a825d3c1beb6ad77ce88571354f51,"KAFKA-5360; Down-converted uncompressed batches should respect fetch offset

More specifically, V2 messages are always batched (whether compressed or not) while
V0/V1 are only batched if they are compressed.

Clients like librdkafka expect to receive messages from the fetch offset when dealing with uncompressed V0/V1 messages. When converting from V2 to V0/1, we were returning all the
messages in the V2 batch.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3191 from ijuma/kafka-5360-down-converted-uncompressed-respect-offset",2017-06-01 10:17:03,Ismael Juma,Mixed
1959835d9e148f0eb6407b36ff96b334d5e785cb,"KAFKA-5281; System tests for transactions

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3149 from apurvam/KAFKA-5281-transactions-system-tests",2017-06-01 10:25:29,Apurva Mehta,Not TDD
39c1e6259c8ff547c3f7c5165b43c88f9f3ea158,"KAFKA-5361: Add EOS integration tests for Streams API

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3193 from mjsax/kafka-5361-add-eos-integration-tests-for-streams-api",2017-06-01 13:16:42,Matthias J. Sax,Mixed
b3036c5861df2c5fc8a06ca5b817d43147f5ba92,"KAFKA-5293; Do not apply exponential backoff if users have overridden…

… reconnect.backoff.ms

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3174 from cmccabe/KAFKA-5293",2017-06-01 21:21:58,Colin P. Mccabe,Mixed
1b16acaaa181ceb214d84e70b8ddc146af9c0c5c,"KAFKA-5154: do not set rejoinNeeded in joinGroup response but in syncGroup response handler

Scenario is as follows:
1. Consumer subscribes to topic t1 and begins consuming
2. heartbeat fails as the group is rebalancing
3. ConsumerCoordinator.onJoinGroupPrepare is called
   3.1 onPartitionsRevoked is called
4. consumer becomes the group leader
5. sends sync group request
6. sync group is cancelled due to disconnection
7. fetch request is sent for partitions that have previously been revoked

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3181 from dguy/kafka-5154",2017-06-01 13:30:49,Damian Guy,Not TDD
1c882ee5fb4ef2d256c914bd69239d58d9706108,"KAFKA-5283; Handle producer epoch/sequence overflow

- Producer sequence numbers should wrap around
- Generate a new producerId if the producer epoch would overflow

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3183 from hachikuji/KAFKA-5283",2017-06-01 23:37:36,Jason Gustafson,Mixed
673ab671e6d72f48fcc98de0b73564983c34e752,"KAFKA-5364; Don't fail producer if drained partition is not yet in transaction

Due to the async nature of the producer, it is possible to attempt to drain a messages whose partition hasn't been added to the transaction yet. Before this patch, we considered this a fatal error. However, it is only in error if the partition isn't in the queue to be sent to the coordinator.

This patch updates the logic so that we only fail the producer if the partition would never be added to the transaction. If the partition of the batch is yet to be added, we will simply wait for the partition to be added to the transaction before sending the batch to the broker.

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #3202 from apurvam/KAFKA-5364-ensure-partitions-added-to-txn-before-send",2017-06-02 00:53:21,Apurva Mehta,Mixed
1188db5657e1db6944b59b1c91a75e47856f4e5c,"KAFKA-5311: Support ExtendedDeserializer in Kafka Streams

Author: Dale Peakall <dale@peakall.net>

Reviewers: Michael André Pearce <michael.andre.pearce@me.com>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bbejeck@gmail.com>, Damian Guy <damian.guy@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3199 from subnova/streams-extendeddeserializer",2017-06-02 09:26:02,Dale Peakall,Mixed
47a3066ccb216bfb65dda2746ca1b7775d8cba05,"KAFKA-5365; Fix regression in compressed message iteration affecting magic v0 and v1

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3203 from hachikuji/KAFKA-5365",2017-06-02 09:45:15,Jason Gustafson,Mixed
f85c18032be5d583c2ca8f9fa1eb1b5ec55e59fa,"KAFKA-3264; Deprecate the old Scala consumer (KIP-109)

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

This patch had conflicts when merged, resolved by
Committer: Ismael Juma <ismael@juma.me.uk>

Closes #2328 from vahidhashemian/KAFKA-3264",2017-06-02 12:27:47,Vahid Hashemian,Mixed
af85e05b98a41cd5f8ac45a853b2ddd28463c084,"KAFKA-5164: Ensure SetSchemaMetadata updates key or value when Schema changes

When the `SetSchemaMetadata` SMT is used to change the name and/or version of the key or value’s schema, any references to the old schema in the key or value must be changed to reference the new schema. Only keys or values that are `Struct` have such references, and so currently only these are adjusted.

This is based on `trunk` since the fix is expected to be targeted to the 0.11.1 release.

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #3198 from rhauch/kafka-5164",2017-06-02 10:02:40,Randall Hauch,Mixed
b63e41ea78a58bdea78be33f90bfcb61ce5988d3,"KAFKA-3982: Fix processing order of some of the consumer properties

This PR updates processing of console consumer's input properties.

For both old and new consumer, the value provided for `auto.offset.reset` indirectly through `consumer.config` or `consumer.property` arguments will now take effect.
For new consumer and for `key.deserializer` and `value.deserializer` properties, the precedence order is fixed to first the value directly provided as an argument, then the value provided indirectly via `consumer.property` and then `consumer.config`, and finally a default value.

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #1655 from vahidhashemian/KAFKA-3982",2017-06-02 12:38:11,Vahid Hashemian,Mixed
4959444afc927026f48f5c7d9babed7b9f1bea50,"KAFKA-5236; Increase the block/buffer size when compressing with Snappy or Gzip

We had originally increased Snappy’s block size as part of KAFKA-3704. However,
we had some issues with excessive memory usage in the producer and we reverted
it in 7c6ee8d5e.

After more investigation, we fixed the underlying reason why memory usage seemed
to grow much more than expected via KAFKA-3747 (included in 0.10.0.1).

In 0.10.2, we changed the broker to use the same classes as the producer and the
broker’s block size for Snappy was changed from 32 KB to 1KB. As reported in
KAFKA-5236, the on disk size is, in some cases, 50% larger when the data is compressed
with 1 KB instead of 32 KB as the block size.

As discussed in KAFKA-3704, it may be worth making this configurable and/or allocate
the compression buffers from the producer pool. However, for 0.11.0.0, I think the
simplest thing to do is to default to 32 KB for Snappy (the default if no block size
is provided).

I also increased the Gzip buffer size. 1 KB is too small and the default is smaller
still (512 bytes). 8 KB (which is the default buffer size for BufferedOutputStream)
seemed like a reasonable default.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3205 from ijuma/kafka-5236-snappy-block-size",2017-06-02 21:20:02,Ismael Juma,Mixed
a318b1512900d29dc9ff0082f52f467999ba69b8,"KAFKA-5322; Add `OPERATION_NOT_ATTEMPTED` error code to resolve AddPartitionsToTxn inconsistency

In the `AddPartitionsToTxn` request handling, if even one partition fails authorization checks, the entire request is essentially failed. However, the `AddPartitionsToTxnResponse` today will only contain the error codes for the topics which failed authorization. It will have no error code for the topics which succeeded, making it inconsistent with other APIs.

This patch adds a new error code `OPERATION_NOT_ATTEMPTED` which is returned for the successful partitions to indicate that they were not added to the transaction.

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #3204 from apurvam/KAFKA-5322-add-operation-not-attempted-for-add-partitions",2017-06-02 14:21:50,Apurva Mehta,Mixed
8104c0de273fb7627c4172f18a609472186860fd,"KAFKA-5373; Revert breaking change to console consumer

This patch reverts b63e41ea78a58bdea78be33f90bfcb61ce5988d3
since it broke the console consumer -- the consumer prints
the addresses of the messages instead of the contents with
that patch.

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3218 from apurvam/KAFKA-5373-fix-console-consumer",2017-06-03 01:53:30,Apurva Mehta,Mixed
1c786c589ab6737e1660981e739582935f9e0f0d,"MINOR: Reuse decompression buffers in log cleaner

Follow-up to KAFKA-5150, reuse decompression buffers in the log cleaner thread.

Author: Xavier Léauté <xavier@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #3180 from xvrl/logcleaner-decompression-buffers",2017-06-03 02:07:01,Xavier Léauté,Mixed
eb5586102e5bb4b66f2cacafbe45f9a7bad8eb10,"KAFKA-5272; Policy for Alter Configs (KIP-133)

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #3210 from ijuma/kafka-5272-improve-validation-for-describe-alter-configs",2017-06-03 03:14:55,Ismael Juma,Not TDD
f389b715707e4e53eaf6ce476a218a4a06c427ee,"KAFKA-5374; Set allow auto topic creation to false when requesting node information only

It avoids the need to handle protocol downgrades and it's safe (i.e. it will never cause
the auto creation of topics).

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3220 from ijuma/kafka-5374-admin-client-metadata",2017-06-03 06:26:16,Colin P. Mccabe,Not TDD
a598c4d26fb06acb455e14e84468306dfa6e1c8b,"KAFKA-4291; TopicCommand --describe should show topics marked for deletion

Developed with edoardocomar

Author: Mickael Maison <mickael.maison@gmail.com>

Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2011 from mimaison/KAFKA-4291",2017-06-03 10:28:57,Mickael Maison,Mixed
3557f097b81edd6518100d79b442223fadf9f81f,"KAFKA-5355; Test cases to ensure isolation level propagated in delayed fetch

Include a few logging improvements.

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3230 from hachikuji/KAFKA-5355-TESTS",2017-06-05 00:36:26,Jason Gustafson,Mixed
8e3ed7028e235b014cd14aedde6808b4ae411232,"KAFKA-5357: capture unexpected exception in txn marker sender thread and treat as fatal error

Replace recursion in `TransactionMarkerChannelManager#appendToLogCallback` with retryQueue. Retry the enqueued log appends each time the InterBrokerSendThread runs

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>

Closes #3192 from dguy/kafka-5357",2017-06-05 11:43:19,Damian Guy,Mixed
b119d04093c2eb771fc3d9bc2d5c1390fc3dd184,"KAFKA-5112; Update compatibility system tests to include 0.10.2.1

Also update message format tests now that we have a third message
format.

Finally, set group.initial.rebalance.delay.ms=100.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Jason Gustafson <jason@confluent.io>

Closes #2701 from ijuma/update-upgrade-tests-for-0.11",2017-06-06 03:21:43,Ismael Juma,Not TDD
2bb48a4fa45422d0773f2f4ea5b38328d3c173ac,"KAFKA-5376; Ensure aborted transactions are propagated in DelayedFetch

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #3239 from hachikuji/KAFKA-5376",2017-06-06 03:37:37,Jason Gustafson,Mixed
9934d28a34351a63738f8e9bac6b53fd699a4905,"KAFKA-5325; Avoid and handle exceptions for Kerberos re-login

If producer creates a connection during Kerberos re-login (after logout,
before login), there are no principals in the subject and
`SaslClientAuthenticator.configure` may throw an exception while trying
to determine the principal. A socket channel is created and its key
registered with the selector, but the `RuntimeException` thrown leaves
the key registered with the selector without adding the channel to the
channel list. This results in an infinite loop of `NullPointerExceptions`.
The PR applies two fixes:

1. Convert the `RuntimeException` to a meaningful `KafkaException`
2. Handle any exception in `buildChannel`, cleanup and throw `IOException`.
Retries will take care of re-connections.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3208 from rajinisivaram/KAFKA-5325",2017-06-06 03:43:14,Rajini Sivaram,Not TDD
4b37918ef47f5d8c4874644f576d8e1a72e16212,"KAFKA-5239; Allocate memory outside the lock in producer buffer pool

Move byte buffer allocation out of lock.
Add unit test for restoring count when OOM is thrown from byte buffer allocation.

Author: Sean McCauliff <smccauliff@linkedin.com>

Reviewers: Jiangjie Qin <becket.qin@gmail.com>

Closes #3053 from smccauliff/kafka-5239",2017-06-05 19:45:14,Sean McCauliff,Mixed
17b2bde4be6296dfd47defce85443cbf6e23835b,"KAFKA-5051; Avoid reverse DNS lookup to obtain hostname for TLS

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #2835 from rajinisivaram/KAFKA-5051",2017-06-06 12:34:39,Rajini Sivaram,Not TDD
313f8d7ddc48943d9f2290a27751d7a0fa1d3a82,"MINOR: Create offsets topic explicitly in DescribeConsumerGroupTest

This should fix transient failures due to timeouts caused by slow
auto creation of the offsets topic. The one exception is
`testDescribeGroupWithNewConsumerWithShortInitializationTimeout` where
we want initialisation to take longer than the timeout so we let
it be auto created. That test has also been a bit flaky and I reduced
the timeout to 1 ms.

Also:
- Simplified resource handling
- Removed usage of EasyMock that didn't make sense.
- `findCoordinator` should retry if `sendAnyNode` throws an exception

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #3237 from ijuma/kafka-49480-describe-consumer-group-test-failure",2017-06-06 13:31:46,Ismael Juma,Mixed
cb78ba1294d1a27b2c4d842a125486ffec593d98,"KAFKA-5364; ensurePartitionAdded does not handle pending partitions in abortable error state

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3231 from hachikuji/KAFKA-5364",2017-06-06 13:58:51,Jason Gustafson,Mixed
d655d806ee4fe345ea25f8ff4a5f168c1a5f609b,"KAFKA-4942: Fix commitTimeoutMs being set before the commit actually started

This fixes KAFKA-4942

This supersededs #2730

/cc simplesteph gwenshap ewencp

Author: Nick Pillitteri <nickp@smartertravelmedia.com>
Author: simplesteph <stephane.maarek@gmail.com>

Reviewers: simplesteph <stephane.maarek@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2912 from 56quarters/fix-connect-offset-commit",2017-06-06 14:22:39,Nick Pillitteri,Mixed
202cb8ea892f443e95c7a08fce5828131809a678,"KAFKA-5366; Add concurrent reads to transactions system test

This currently fails in multiple ways. One of which is most likely KAFKA-5355, where the concurrent consumer reads duplicates.

During broker bounces, the concurrent consumer misses messages completely. This is another bug.

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3217 from apurvam/KAFKA-5366-add-concurrent-reads-to-transactions-system-test",2017-06-06 17:21:45,Apurva Mehta,Mixed
bb914a0445549b41fb0b667ea2f5f15a90060133,"KAFKA-5380: Fix transient failure in KafkaConsumerTest, close consumers

1. Fix ordering of metadata update request for regex subscription to avoid timing issue when heartbeat thread updates metadata
2. Override metadata cluster in MockClient for `KafkaConsumer#testChangingRegexSubscription` to avoid timing issues during update
3. Close consumer in all KafkaConsumer tests since they leave behind heartbeat threads.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #3238 from rajinisivaram/KAFKA-5380",2017-06-07 12:51:53,Rajini Sivaram,Mixed
dcbdce31ba525771016be5be4abc4a2067e0890b,"KAFKA-5378; Return LSO in FetchResponse plus some metrics

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3248 from hachikuji/KAFKA-5378",2017-06-07 16:36:57,Jason Gustafson,Mixed
5c3d7ca7113dd380d7465d5f914adfb4c7394eaa,"MINOR: log4j template should accept log_level

The log_level parameter is used in system tests in kafka.py. However the log4j template accepted that parameter in only one place. This led to a large number of DEBUG lines printed even when the intention was to capture only INFO lines. Led to huge log files. Thanks to ijuma for noticing this.

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3247 from enothereska/minor-log4j-template-fix",2017-06-07 16:52:10,Eno Thereska,Not TDD
38ae746448f799c3ff8be113f608aaa870e00c87,"KAFKA-5394; KafkaAdminClient#timeoutCallsInFlight does not work as ex…
KAFKA-5394; Fix disconnections due to timeouts in AdminClient

* Create KafkaClient#disconnect to tear down a connection and
deliver disconnects to all the requests on it.
* AdminClient.java: fix mismatched braces in JavaDoc.
* Make the AdminClientConfig constructor visible for testing.
* KafkaAdminClient: add TimeoutProcessorFactory to make the
TimeoutProcessor swappable for testing.
* Make TimeoutProcessor a static class rather than an inner
class.

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3250 from cmccabe/KAFKA-5394",2017-06-07 18:05:25,Colin P. Mccabe,Mixed
79db393ffaca25fdaac0fef69d6fb082f1628649,"KAFKA-5385; ProducerBatch expiry should go through Sender.failBatch

Before this patch, we would call `producerBatch.done` directly from the accumulator when expiring batches. This meant that we would not transition to the `ABORTABLE_ERROR` state in the transaction manager, allowing other transactional requests (including Commits!) to go through, even though the produce failed.

This patch modifies the logic so that we call `Sender.failBatch` on every expired batch, thus ensuring that the transaction state is accurate.

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #3252 from apurvam/KAFKA-5385-fail-transaction-if-batches-expire",2017-06-07 13:01:54,Apurva Mehta,Mixed
2fc91afbad2229ef2f8ef6fbeebc257ab7019746,"KAFKA-5292; Fix authorization checks in AdminClient

* NetworkClient.java: when trace logging is enabled, show AbstractResponse Struct objects, rather than just a memory address of the AbstractResponse.
* AclOperation.java: add documentation of what ACLs imply other ACLs.
* Resource.java: add CLUSTER, CLUSTER_NAME constants.
* Reconcile the Java and Scala classes for ResourceType, OperationType, etc.  Add unit tests to ensure they can be converted to each other.
* AclCommand.scala: we should be able to apply ACLs containing Alter and Describe operations to Cluster resources.
* SimpleAclAuthorizer: update the authorizer to handle the ACL inheritance rules described in AclOperation.java.
* KafkaApis.scala: update createAcls and deleteAcls to use ALTER on CLUSTER, as described in the KIP.  describeAcls should use DESCRIBE on CLUSTER.  Use      fromJava methods instead of fromString methods to convert from Java objects to Scala ones.
* SaslSslAdminClientIntegrationTest.scala: do not use AllowEveryoneIfNoAclIsFound.  Add a configureSecurityBeforeServerStart hook which installs the ACLs     necessary for the tests.  Add a test of ACL authorization ALLOW and DENY functionality.

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3240 from cmccabe/KAFKA-5292",2017-06-08 01:56:08,Colin P. Mccabe,Mixed
12612e82971b8dc85941c771b7fe87ff95a07ab5,"KAFKA-5329; Fix order of replica list in metadata cache

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Jun Rao <junrao@gmail.com>

Closes #3257 from ijuma/kafka-5329-fix-order-of-replica-list-in-metadata-cache",2017-06-08 03:26:54,Ismael Juma,Mixed
f4e0deca43595f30b9c6f1a1666192416ecc8a9c,"KAFKA-5314; exception handling and cleanup for state stores

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3135 from enothereska/exceptions-stores-KAFKA-5314",2017-06-07 21:16:46,Eno Thereska,Mixed
b4b65e9eafc45cadca093b023361bd15e77ccb21,"KAFKA-5357 follow-up: Yammer metrics, not Kafka Metrics

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3242 from guozhangwang/K5357-yammer-metrics",2017-06-08 11:50:29,Guozhang Wang,Mixed
ba07d828c545d542cc11db60249e660d88a20fbb,"KAFKA-5362: Add EOS system tests for Streams API

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3201 from mjsax/kafka-5362-add-eos-system-tests-for-streams-api",2017-06-08 14:08:54,Matthias J. Sax,Not TDD
8e7839f610a9278f800ba2f7378fb10abded8f28,"KAFKA-5422; Handle multiple transitions to ABORTABLE_ERROR correctly

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3285 from apurvam/KAFKA-5422-allow-multiple-transitions-to-abortable-error",2017-06-09 15:54:23,Apurva Mehta,Mixed
9d6f0f40ceb4859d54454e03f6abfe8b67963e83,"KAFKA-5416; TC should not reset pending state if log append is retried

In `TransationStateManager`, we reset the pending state if an error occurred while appending to log; this is correct except that for the `TransactionMarkerChannelManager`, as it will retry appending to log and if eventually it succeeded, the transaction metadata's completing transition will throw an IllegalStateException since pending state is None, this will be thrown all the way to the `KafkaApis` and be swallowed.

1. Do not reset the pending state if the append will be retried (as is the case when write the complete transition).
2. A bunch of log4j improvements based the debugging experience. The main principle is to make sure all error codes that is about to sent to the client will be logged, and unnecessary log4j entries to be removed.
3. Also moved some log entries in ReplicationUtils.scala to `trace`: this is rather orthogonal to this PR but I found it rather annoying while debugging the logs.
4. A couple of unrelated bug fixes as pointed by hachikuji and apurvam.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Apurva Mehta <apurva@confluent.io>, Jason Gustafson <jason@confluent.io>

Closes #3287 from guozhangwang/KHotfix-transaction-coordinator-append-callback",2017-06-12 12:47:46,Guozhang Wang,Mixed
2724053adf3466d01a70ad9020b3d639150050d6,"MINOR: A few cleanups of usage of Either in TC

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3284 from hachikuji/minor-either-usage-cleanup",2017-06-12 14:56:28,Jason Gustafson,Mixed
43e935a630eb0a7fa64c5a1a38bfee17f9b724dc,"KAFKA-5427; Transactional producer should allow FindCoordinator in error state

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3297 from hachikuji/KAFKA-5427",2017-06-12 15:04:05,Jason Gustafson,Mixed
6c92fc557682e853a0a3ed5684c13174fff45acf,"KAFKA-5429; Ignore produce response if batch was previously aborted

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #3300 from hachikuji/KAFKA-5429",2017-06-12 16:29:29,Jason Gustafson,Mixed
aea53108a7d9573b8976da83235639a981c09af3,"KAFKA-5428; Transactional producer should only abort batches in fatal error state

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #3298 from hachikuji/KAFKA-5428",2017-06-12 18:07:27,Jason Gustafson,Mixed
4660bac4eb45a65767d05b03d275e3bf08a85c2a,"MINOR: Avoid calling interceptors.onSendError() with null TopicPartition

Assign non-null tp as soon as possible once we know the partition. This is
so that if ensureValidRecordSize() throws, the
interceptors.onSendError() call is made with a non-null tp.

Author: Tom Bentley <tbentley@redhat.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3280 from tombentley/tp-assign",2017-06-13 13:11:13,Tom Bentley,Mixed
435e5e196b64625f017ef2c8c7ab49ce7fc271b8,"KAFKA-5418; ZkUtils.getAllPartitions() may fail if a topic is marked for deletion

Skip topics that don't have any partitions in zkUtils.getAllPartitions()

Author: Mickael Maison <mickael.maison@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3295 from mimaison/KAFKA-5418",2017-06-13 13:33:26,Mickael Maison,Mixed
aaca1b478fcce99860e2eb89aa468ff863458572,"KAFKA-5439; Verify that no unexpected threads are left behind in tests

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3314 from rajinisivaram/KAFKA-5439",2017-06-13 13:47:41,Rajini Sivaram,Not TDD
c2daf4c623e5919872012aff57ffa25af46a97f8,"KAFKA-5438; Fix UnsupportedOperationException in WriteTxnMarkersRequest

Before this patch, the `partitionErrors` was an immutable map. As a result if a single producer had a marker for multiple partitions, and if there were multiple response callbacks for a single append, we would get an `UnsupportedOperationException` in the `writeTxnMarker` handler.

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #3313 from apurvam/KAFKA-5438-fix-unsupportedoperationexception-in-writetxnmarker",2017-06-13 16:14:36,Apurva Mehta,Not TDD
d099c749591ac0e819017a9d3ae48144ddbbff0d,"MINOR: NetworkClient#disconnect should not erase connection info

NetworkClient#disconnect should not erase the connection information.  This will allow exponential
backoff to occur.

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3309 from cmccabe/disc",2017-06-14 01:59:24,Colin P. Mccabe,Mixed
32f0f1f50aa618e8a3c52eb37006f4945fa6865a,"MINOR: Temporarily remove the apiVersions API for 0.11

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3324 from cmccabe/removeApiVersions",2017-06-14 02:05:02,Colin P. Mccabe,Not TDD
09b354a84606fe1862edecc9378908abb4048121,"KAFKA-5354; MirrorMaker not preserving headers

Headers are only preserved if the new consumer is
used since the old consumer does not support
them.

Add test case to verify the fix and to avoid regression.

Author: Michael Andre Pearce <Michael.Andre.Pearce@me.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3322 from michaelandrepearce/KAFKA-5354",2017-06-14 11:50:28,Michael Andre Pearce,Mixed
160933bc092b4392cac1dd9497010320c6ae4d10,"KAFKA-5361: Add more integration tests for Streams EOS

 - multi-subtopology tests
 - fencing test
 - producer fenced bug fix: Streams did not recover correctly from ProducerFencedException

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3276 from mjsax/kafka-5361-add-eos-integration-tests-for-streams-api",2017-06-14 09:18:59,Matthias J. Sax,Not TDD
2572637121527f8c37bc95212e7eaf8190eb436b,"KAFKA-5443; Consumer should use last offset from batch to set next fetch offset

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3331 from hachikuji/KAFKA-5443",2017-06-14 17:54:15,Jason Gustafson,Mixed
3c2329ad0b56fe39d9cbc8301c5902689e54fb3a,"MINOR: Update `TransactionMarkerChannelManager` metric name

Also remove broker-id tags as we generally use them to provide
additional context.

Finally, do a few clean-ups (could not resist).

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #3341 from ijuma/tweak-transaction-metrics",2017-06-14 23:09:11,Ismael Juma,Mixed
b760615f3d58ed1fd4e17bb3ec647b26135cf458,"KAFKA-5448: Change TimestampConverter configuration name to avoid conflicting with reserved 'type' configuration used by all Transformations

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: David Tucker, Gwen Shapira

Closes #3342 from ewencp/kafka-5448-change-timestamp-converter-config-name",2017-06-14 15:24:32,Ewen Cheslack-Postava,Mixed
005b86ecf3bd881cb2005c177c2555eeb2a049d9,"MINOR: Add random aborts to system test transactional copier service

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #3340 from hachikuji/add-random-aborts-to-system-test",2017-06-14 16:20:18,Jason Gustafson,Not TDD
0f60617fab5fc6805f522d0b9a213a7f600fab12,"KAFKA-5275; AdminClient API consistency

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Jason Gustafson <jason@confluent.io>

Closes #3339 from ijuma/kafka-5275-admin-client-api-consistency",2017-06-15 02:05:41,Ismael Juma,Mixed
54a3718a900a5286baf2193713ea8d58ca2c08f6,"KAFKA-5449; Fix race condition on producer dequeuing of EndTxn request

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #3348 from hachikuji/fix-has-unflushed-synchronization",2017-06-16 01:17:54,Jason Gustafson,Mixed
c83719f3d8799ec35cf9af95fd93c97b910df570,"KAFKA-5457; MemoryRecordsBuilder.hasRoomFor should account for record headers

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #3355 from apurvam/KAFKA-5457-memoryrecordsbuilder-has-room-for-should-account-for-headers",2017-06-16 14:39:11,Apurva Mehta,Mixed
f49697a2796540452a21d4a29ab879ba04214046,"KAFKA-5456; Ensure producer handles old format large compressed messages

More specifically, fix the case where a compressed V0 or V1 message is
larger than the producer batch size.

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #3356 from hachikuji/KAFKA-5456",2017-06-16 20:36:28,Jason Gustafson,Mixed
fdd12698b8c8f9d4b70d775e5844b76912977843,"MINOR: A few cleanups in KafkaApis and TransactionMarkerChannelManager

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #3171 from hachikuji/minor-txn-channel-cleanups",2017-06-17 02:05:34,Jason Gustafson,Mixed
48de613a90fe91ca56628803fe9f02fdfd99813a,"KAFKA-5031; Validate count of records and headers for new message format

https://issues.apache.org/jira/browse/KAFKA-5031

Implements additional check for `DefaultRecordBatch` that compares number of records declared in the header with actual number of records. Similarly for headers.

Author: gosubpl <github@gosub.pl>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #3156 from gosubpl/KAFKA-5031",2017-06-16 21:58:34,gosubpl,Mixed
51fc50ed0ba7aa4d0e618f9103a1531680489139,"KAFKA-5031; Follow-up with small cleanups/improvements

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3363 from hachikuji/KAFKA-5031-FOLLOWUP",2017-06-17 12:48:38,Jason Gustafson,Mixed
d68f9e2fe6cf2f76a81105ace5061eb7abb85995,"HOTFIX: Improve error handling for ACL requests

- Use ResourceType.toJava instead of ResourceType.fromString. The latter
doesn't work for TransactionalId (or any type with two camel-case
words).
- Replace Throwable with ApiError in response classes.
- Return InvalidRequest instead of Unknown error if ANY or UNKNOWN
are provided during ACL creation.
- Rename `unknown()` to `isUnknown()` in a few places that
were missed previously.
- Add tests.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3364 from ijuma/acls-fromString-fixes",2017-06-17 14:02:01,Ismael Juma,Mixed
bcaee7fe19b3f2e75f6de0dfc5487deebfef446e,"KAFKA-5435; Improve producer state loading after failure

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Jun Rao <junrao@gmail.com>

Closes #3361 from hachikuji/KAFKA-5435-ALT",2017-06-17 10:20:00,Jason Gustafson,Mixed
198a43d84693153c0f0177b8314117525c05047b,"KAFKA-5412: Using connect-console-sink/source.properties raises an exception related to ""file"" property not found

Author: ppatierno <ppatierno@live.com>

Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #3279 from ppatierno/kafka-5412",2017-06-19 09:22:19,ppatierno,Mixed
1d24e10aeab616eede416201336e928b9a8efa98,"MINOR: Remove unused `AdminUtils.fetchTopicMetadataFromZk` methods

These are internal methods with no tests and since we now have an `AdminClient`,
we should remove them.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3299 from ijuma/remove-unused-admin-utils-methods",2017-06-20 11:29:11,Ismael Juma,Not TDD
54205697aea5bfeb4fbcd40fc849c0c975fd6070,"MINOR: MemoryRecordsBuilder.sizeInBytes should consider initial position

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3376 from hachikuji/records-builder-improvements",2017-06-20 13:01:17,Jason Gustafson,Mixed
76f6e14b07bd97d17f9275968a047d68b4658704,"KAFKA-5413; Log cleaner fails due to large offset in segment file

the contribution is my original work and I license the work to the project under the project's open source license.

junrao , I had already made the code change before your last comment.  I've done pretty much what you said, except that I've not used the current segment because I wasn't sure if it will always be available.
I'm happy to change it if you prefer.
I've run all the unit and integration tests which all passed.

Author: Kelvin Rutt <ruttkelvin@gmail.com>
Author: Kelvin Rutt <kelvin.rutt@sky.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #3357 from kelvinrutt/kafka_5413_bugfix",2017-06-20 18:00:41,Kelvin Rutt,Mixed
55a90938a12d8928289a30588bbad6c959c48674,"MINOR: add Yahoo benchmark to nightly runs

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>

Closes #3289 from enothereska/yahoo-benchmark",2017-06-21 11:46:59,Eno Thereska,Not TDD
254add953477df65fe36144dc0714e0c9815c767,"KAFKA-5477; Lower retry backoff for first AddPartitions in transaction

This patch lowers the retry backoff when receiving a CONCURRENT_TRANSACTIONS error from an AddPartitions request. The default of 100ms would mean that back to back transactions would be 100ms long at minimum, making things to slow.

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #3377 from apurvam/HOTFIX-lower-retry-for-add-partitions",2017-06-21 11:00:08,Apurva Mehta,Mixed
96587f4b1ffd372d3e4f9a1fba6fc1d2f84a191d,"KAFKA-5475: Connector config validation should include fields for defined transformation aliases

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Jason Gustafson <jason@confluent.io>

Closes #3399 from ewencp/kafka-5475-validation-transformations",2017-06-21 14:20:48,Ewen Cheslack-Postava,Mixed
914e42a28254ef6a4818b3fcdc2197db6fbe8e0f,"KAFKA-5474: Streams StandbyTask should no checkpoint on commit if EOS is enabled

<strike> - actual fix for `StandbyTask#commit()` </strike>

Additionally (for debugging):
 - EOS test, does not report ""expected"" value correctly
 - add `IntegerDecoder` (to be use with `kafka.tools.DumpLogSegments`)
 - add test for `StreamTask` to not checkpoint on commit if EOS enabled

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Bill Bejeck <bbejeck@gmail.com>, Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #3375 from mjsax/kafka-5474-eos-standby-task",2017-06-21 17:16:48,Matthias J. Sax,Not TDD
4e8797f54ef9d2d7f40e3100943ae8afd5496b16,"KAFKA-4659; Improve test coverage of CachingKeyValueStore

Author: Jeyhun Karimov <je.karimov@gmail.com>

Reviewers: Matthias J Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>

Closes #3291 from jeyhunkarimov/KAFKA-4659",2017-06-22 08:40:54,Jeyhun Karimov,Mixed
cb5e1f0a40e9a9779a5dcabf555a593363728b33,"KAFKA-4785; Records from internal repartitioning topics should always use RecordMetadataTimestampExtractor

Author: Jeyhun Karimov <je.karimov@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Eno Thereska <eno.thereska@gmail.com>, Bill Bejeck <bbejeck@gmail.com>, Damian Guy <damian.guy@gmail.com>

Closes #3106 from jeyhunkarimov/KAFKA-4785",2017-06-22 12:23:58,Jeyhun Karimov,Mixed
adfaa1161150635b9bb0e36a573382c5b68960e2,"KAFKA-4655; Improve test coverage of CompositeReadOnlySessionStore

Author: Jeyhun Karimov <je.karimov@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>

Closes #3290 from jeyhunkarimov/KAFKA-4655",2017-06-22 15:00:41,Jeyhun Karimov,Not TDD
fc58ac594f0eb63e0928374f67eba25bfa18eaea,"KAFKA-5490; Skip empty record batches in the consumer

The actual fix for KAFKA-5490 is in
https://github.com/apache/kafka/pull/3406.

This is just the consumer change that will allow the cleaner
to use empty record batches without breaking 0.11.0.0
consumers (assuming that KAFKA-5490 does not make the cut).
This is a safe change even if we decide to go with a different option
for KAFKA-5490 and I'd like to include it in RC2.

Author: Jason Gustafson <jason@confluent.io>
Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Damian Guy <damian.guy@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3408 from ijuma/kafka-5490-consumer-should-skip-empty-batches",2017-06-22 16:54:28,Jason Gustafson,Mixed
cd11fd787438d26324d9644c248b812d25e26b34,"KAFKA-5498: ConfigDef derived from another ConfigDef did not correctly compute parentless configs

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Gwen Shapira

Closes #3412 from ewencp/kafka-5498-base-configdef-parentless-configs",2017-06-22 13:00:12,Ewen Cheslack-Postava,Mixed
2420491f417012ba5215a9f72fa5e3a0c586c8e8,"KAFKA-4913; prevent creation of window stores with less than 2 segments

Throw IllegalArgumentException when attempting to create a `WindowStore` via `Stores` or directly with `RocksDBWindowStoreSupplier` when it has less than 2 segments.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska <eno.thereska@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bbejeck@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #3410 from dguy/kafka-4913",2017-06-23 08:59:13,Damian Guy,Mixed
701e318ee1046946ce6681a59223504d8c33d751,"KAFKA-4653; Improve test coverage of RocksDBStore

Author: Jeyhun Karimov <je.karimov@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>

Closes #3294 from jeyhunkarimov/KAFKA-4653",2017-06-23 11:41:02,Jeyhun Karimov,Mixed
b490368735b3bfe82acab3f2db4894a757abb966,"HOTFIX: Don't check metadata unless you are creating topic

During a broker rolling upgrade, it's likely we don't have enough brokers ready yet. If streams does not need to create a topic it shouldn't check how many brokers are up.

The system test for this is in a separate PR: https://github.com/apache/kafka/pull/3411

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>

Closes #3418 from enothereska/hotfix-replication",2017-06-23 15:56:29,Eno Thereska,Mixed
d65844b52723c7a093d969c4b2822e3b36389b70,"MINOR: SaslChannelBuilder should be idempotent

After we call `release`, we should null out the reference so
that we neither use it or release it a second time.

This should fix the following exception that has been reported:

```text
[2017-06-23 03:24:02,485] ERROR stream-thread [...] Failed to close consumer:  (org.apache.kafka.streams.processor.internals.StreamThread:1054)
org.apache.kafka.common.KafkaException: Failed to close kafka consumer
        at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1623)
        at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1573)
        at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1549)
        at org.apache.kafka.streams.processor.internals.StreamThread.shutdown(StreamThread.java:1052)
        at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:538)
Caused by: java.lang.IllegalStateException: release called on LoginManager with refCount == 0
        at org.apache.kafka.common.security.authenticator.LoginManager.release(LoginManager.java:106)
        at org.apache.kafka.common.network.SaslChannelBuilder.close(SaslChannelBuilder.java:125)
        at org.apache.kafka.common.network.Selector.close(Selector.java:257)
        at org.apache.kafka.clients.NetworkClient.close(NetworkClient.java:505)
        at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.close(ConsumerNetworkClient.java:439)
        at org.apache.kafka.clients.ClientUtils.closeQuietly(ClientUtils.java:71)
        at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1613)
```

It's worth noting that it's not clear how `SaslChannelBuilder.close()` is called more than
once and it would be good to understand that as well.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Damian Guy <damian.guy@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #3422 from ijuma/sasl-channel-builder-idempotent",2017-06-23 11:19:14,Ismael Juma,Mixed
ee5eac715d58e6b16a115692ede93ae481ae7785,"KAFKA-5487; upgrade and downgrade streams app system test

-Tests for rolling upgrades for a streams app (keeping broker config fixed)
-Tests for rolling upgrades of brokers (keeping streams app config fixed)

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>

Closes #3411 from enothereska/KAFKA-5487-upgrade-test-streams",2017-06-24 07:48:10,Eno Thereska,Not TDD
a5c47db1382c14720106ae1da20d2b332f89c22c,"KAFKA-5506; Fix NPE in OffsetFetchRequest.toString and logging improvements

NetworkClient's logging improvements:
- Include correlation id in a number of log statements
- Avoid eager toString call in parameter passed to log.debug
- Use node.toString instead of passing a subset of fields to the
logger
- Use requestBuilder instead of clientRequest in one of the log
statements

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Damian Guy <damian.guy@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #3420 from ijuma/kafka-5506-offset-fetch-request-to-string-npe",2017-06-24 08:20:55,Ismael Juma,Not TDD
2265834803649d2f9fb090e86d11309f6e9789cb,"KAFKA-5362: Add Streams EOS system test with repartitioning topic

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #3310 from mjsax/kafka-5362-add-eos-system-tests-for-streams-api",2017-06-25 09:34:27,Matthias J. Sax,Not TDD
031da889bc811200da67568c5779760dcb006238,"MINOR: Fix race condition in KafkaConsumer close

We intended to make `KafkaConsumer.close()` idempotent,
but due to the fact that the `closed` variable is
checked without a lock prior to beginning close logic,
it is possible for two or more threads to see
`closed=false` and attempt to close.

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #3426 from hachikuji/minor-fix-consumer-idempotent-close",2017-06-27 16:36:45,Jason Gustafson,Mixed
efb060c57f05d1d586bb14c016b0187c60f8e994,"KAFKA-5233; KIP-138: Change punctuate semantics

Implementation for KIP-138: Change punctuate semantics

Author: Michal Borowiecki <michal.borowiecki@openbet.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bbejeck@gmail.com>, Eno Thereska <eno.thereska@gmail.com>, Damian Guy <damian.guy@gmail.com>

Closes #3055 from mihbor/KIP-138",2017-06-28 11:26:02,Michal Borowiecki,Mixed
cb0325d484b957432048dd29419f0fa59c5f132d,"KAFKA-5490; Cleaner should retain empty batch if needed to preserve producer last sequence

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>, Jun Rao <junrao@gmail.com>

Closes #3406 from hachikuji/KAFKA-5490",2017-06-28 11:35:13,Jason Gustafson,Mixed
dc95456f1df1a6ba451944d515fcee81c29262f5,"KAFKA-5402; Avoid creating quota related metrics if quotas not enabled

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3303 from rajinisivaram/KAFKA-5402",2017-06-29 08:01:12,Rajini Sivaram,Mixed
5536b1237fe954ba712cd62013e7cd91b7caee51,"KAFKA-5484: Refactor kafkatest docker support

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #3389 from cmccabe/KAFKA-5484",2017-06-29 13:28:35,Colin P. Mccabe,Not TDD
c4193cd1ad8eeed8383a1c2660383c455e848929,"MINOR: Rename baseTimestamp to firstTimestamp to clarify usage

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3457 from hachikuji/rename-base-timestamp",2017-06-30 06:48:45,Jason Gustafson,Mixed
0dfeb31a116d26023540f6c6074127f0aab00b6d,"KAFKA-5485; Streams should not suspend tasks twice

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Eno Thereska <eno.thereska@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>

Closes #3390 from mjsax/kafka-5485-dont-suspend-tasks-twice",2017-06-30 08:56:40,Matthias J. Sax,Mixed
49ed16daf43b5f28e51fed7cc124cd308de3deca,"MINOR: Compatibility and upgrade tests for 0.11.0.x

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Eno Thereska <eno.thereska@gmail.com>, Ewen Cheslack-Postava <me@ewencp.org>

Closes #3454 from ijuma/test-upgrades-from-0.11.0.x",2017-06-30 23:36:21,Ismael Juma,Not TDD
9238aeaa2171f7860fd6ae7980608505a63c12ca,"KAFKA-5522; ListOffsets should bound timestamp search by LSO in read_committed

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3456 from hachikuji/KAFKA-5522",2017-06-30 15:38:03,Jason Gustafson,Mixed
ab8e9d1755e9527ca76e994dd59a21cc94550312,"KAFKA-5548: Extended validation for SchemaBuilder methods.

More input validation for SchemaBuilder methods.

Author: Jeremy Custenborder <jcustenborder@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #3474 from jcustenborder/KAFKA-5548",2017-07-01 02:46:55,Jeremy Custenborder,Mixed
c9f777cc44269c2e9537eab2451481422e613383,"HOTFIX: Add back the copy-constructor of abstract stream

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>

Closes #3428 from guozhangwang/KHotfix-add-copy-constructor-abstract-stream",2017-07-03 09:34:16,Guozhang Wang,Mixed
70e949d522eba72b22c2619c4fde372d0f1a26b3,"KAFKA-5167: Release state locks in case of failure

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #3449 from mjsax/kafka-5167-streams-task-gets-stuck-after-re-balance-due-to-LockException",2017-07-05 20:20:51,Matthias J. Sax,Mixed
9078554232f9de56849b5c35bf45b81a67a748c4,"KAFKA-5372; fixes to state transitions

Several fixes to state transition logic:
- Kafka streams will now be in ERROR when all threads are DEAD or when global thread stops unexpectedly
- Fixed transition logic in corner cases when thread is already dead or Kafka Streams is already closed
- Fixed incorrect transition diagram in StreamThread
- Unit tests to verify transitions

Also:
- re-enabled throwing an exception when an unexpected state change happens
- fixed a whole bunch of EoS tests that did not start a thread
- added more comments.

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>

Closes #3432 from enothereska/KAFKA-5372-state-transitions",2017-07-06 10:05:16,Eno Thereska,Mixed
a1f97c8dc4edd49c7a8a2ebb72734728029a85aa,"KAFKA-5157; Options for handling corrupt data during deserialization

This is the implementation of KIP-161: https://cwiki.apache.org/confluence/display/KAFKA/KIP-161%3A+streams+deserialization+exception+handlers

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>

Closes #3423 from enothereska/KAFKA-5157-deserialization-exceptions",2017-07-10 11:58:51,Eno Thereska,Mixed
2628695356de87aba7d046855fbe1f1963d3f911,"MINOR: need to be backwards compatible with deprecated default configs until removed

…s until removed

Author: Bill Bejeck <bill@confluent.io>

Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3461 from bbejeck/MINOR_make_sure_deprecated_streams_configs_still_usable",2017-07-10 17:59:43,Bill Bejeck,Mixed
2d2e9adb5d8d3805f082208ae9dd241f87566b27,"KAFKA-5584; Fix integer overflow in Log.size

It may lead to wrong metrics and it may break
size-based retention.

Author: Gregor Uhlenheuer <kongo2002@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3521 from kongo2002/KAFKA-5584",2017-07-12 17:20:19,Gregor Uhlenheuer,Mixed
e391045473f258562d55bbc07faafe75ec7213ac,"KAFKA-5127; Replace pattern matching with foreach where the case None is ignored

Author: Balint Molnar <balintmolnar91@gmail.com>

Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #2919 from baluchicken/KAFKA-5127",2017-07-14 09:57:14,Balint Molnar,Not TDD
1685e7112c5d4dc723ffcfa219febaed045b6426,"MINOR: Enable a number of xlint scalac warnings

Update the code where possible to fix the warnings. The unused
warning introduced in Scala 2.12 is quite handy and provides
a reason to compile with Scala 2.12.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3464 from ijuma/scala-xlint",2017-07-14 11:44:42,Ismael Juma,Mixed
d0ce0a95de8c5451d73dcc87f3f9b6c03f5f85de,"MINOR: Correct the ConsumerPerformance print format

Currently, the output of `ConsumerPerformance` looks strange. The `header` format as follow:
```
""time, threadId, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec""
```
while the `body` as follow:
```
println(""%s, %d, %.4f, %.4f, %d, %.4f"".format(dateFormat.format(endMs), id, totalMBRead,
        1000.0 * (mbRead / elapsedMs), messagesRead, ((messagesRead - lastMessagesRead) / elapsedMs) * 1000.0))
```

So we get the follow result:
```
time, data.consumeed.in.MB, MB.sec, data.consumeed.in.nMsg, nMsg.Sec
09:52:00, 0, 1100.3086, 220.0177, 563358, 112649.0702
```
So the `header` and `body` mismatching.

And also, this pr makes the functions more readable.

Author: Xianyang Liu <xianyang.liu@intel.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3417 from ConeyLiu/consumertest",2017-07-14 13:50:38,Xianyang Liu,Mixed
6d7a81b478e1f36d7632c84d34280c22a2f717b1,"KAFKA-5579: check for null

Author: Jeremy Custenborder <jcustenborder@gmail.com>

Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #3517 from jcustenborder/KAFKA-5579",2017-07-17 10:45:31,Jeremy Custenborder,Mixed
e2fe19d22a42525001c5a66f21f02f49c051ecb5,"KAFKA-5600; Fix group loading regression causing stale metadata/offset cache

the while loop was too big and need to be closed earlier
to see the fix, ignore whitespace since most of it is indentation

this bug was introduced by commit
5bd06f1d542e6b588a1d402d059bc24690017d32

Author: Jan Burkhardt <jan.burkhardt@just.social>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #3538 from bjrke/trunk",2017-07-17 11:51:57,Jan Burkhardt,Mixed
28c83d9667676515607713d4ccfd3757a8afcba2,"KAFKA-5587; Remove channel only after staged receives are delivered

When idle connections are closed, ensure that channels with staged
receives are retained in `closingChannels` until all staged receives
are completed. Also ensure that only one staged receive is completed
in each poll, even when channels are closed.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3526 from rajinisivaram/KAFKA-5587",2017-07-17 23:58:22,Rajini Sivaram,Mixed
f87d58b796977fdaefb089d17cb30b2071cd4485,"MINOR: Code Cleanup

Clean up includes:

- Switching try-catch-finally blocks to try-with-resources when possible
- Removing some seemingly unnecessary `SuppressWarnings` annotations
- Resolving some Java warnings
- Closing unclosed Closable objects
- Removing unused code

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Balint Molnar <balintmolnar91@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #3222 from vahidhashemian/minor/code_cleanup_1706",2017-07-19 10:51:28,Vahid Hashemian,Mixed
272956f03a54ef4f476d6f6f49c0cf74e5daf7d0,"KAFKA-5134; Replace zkClient.getChildren method with zkUtils.getChildren

Author: Balint Molnar <balintmolnar91@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3097 from baluchicken/KAFKA-5134-2",2017-07-20 12:48:17,Balint Molnar,Not TDD
fe4a469fce5a47b89083781ed8a03d0d71428aeb,"KAFKA-4830; Augment KStream.print() to allow users pass in extra parameters in the printed string

I extend `KStream#print()` to `KStream#print(KeyValueMapper<K, V, String>)`.
So I add the following methods :
1. `KStream#print(KeyValueMapper<K, V, String>)`
2. `KStream#print(KeyValueMapper<K, V, String>, String streamName)`
3. `KStream#print(KeyValueMapper<K, V, String>, Serde<K>, Serde<V>)`
4. `KStream#print(KeyValueMapper<K, V, String>, Serde<K>, Serde<V>, String streamName)`

Author: jameschien <jameschien@staff.ruten.com.tw>
Author: jedichien <james.chain1990@gmail.com>
Author: JamesChien <jedichien@users.noreply.github.com>
Author: JamesChien <james.chain1990@gmail.com>

Reviewers: Bill Bejeck <bbejec@gmail.com>, Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #3085 from jedichien/KAFKA-4830",2017-07-20 14:47:38,jameschien,Not TDD
e0099e1f5852536918bfa27b4d1c33779e45ab6b,"KAFKA-5556; Fix IllegalStateException in KafkaConsumer.commitSync due to missing future completion check

This PR makes `commitOffsetsSync` method check whether future is completed after client's poll or not.

Author: umesh chaudhary <umesh9794@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #3489 from umesh9794/KAFKA-5556",2017-07-20 08:54:25,umesh chaudhary,Mixed
b04bed022aec0f1f478a03383ab5184f048133b6,"KAFKA-3856; Cleanup Kafka Stream builder API (KIP-120)

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bbejeck@gmail.com>

Closes #2301 from mjsax/kafka-3856-topology-builder-API",2017-07-20 18:47:47,Matthias J. Sax,Mixed
cdff011fe02cb8e14cb5bf226e47b83cbbec8f3c,"KAFKA-5610; WriteTxnMarker handler should return UNKNOWN_TOPIC_OR_PARTITION if replica is not available

Before this patch, we would instead return the non-retriable `UNSUPPORTED_FOR_MESSAGE_FORMAT` causing markers to be lost.

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #3550 from apurvam/KAFKA-5610-handleWriteTxnMarker-should-handle-emigration",2017-07-20 13:05:51,Apurva Mehta,Mixed
5bb53e034e4f8a06550dd06377fae7b3c2137ce2,"KAFKA-5534; KafkaConsumer `offsetForTimes` result should include partitions with no offset

For topics that support timestamp search, if no offset is found for a partition, the partition should still be included in the result with a `null` offset value. This `KafkaConsumer` method currently excludes such partitions from the result.

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #3460 from vahidhashemian/KAFKA-5534",2017-07-20 17:38:30,Vahid Hashemian,Mixed
cd207dd3feb08052a82db90d2e5da956bad5ac33,"KAFKA-5431; cleanSegments should not set length for cleanable segment files

For a compacted topic with preallocate enabled, during log cleaning, LogCleaner.cleanSegments does not have to pre-allocate the underlying file size since we only want to store the cleaned data in the file.

It's believed that this fix should also solve KAFKA-5582.

Author: huxihx <huxi_2b@hotmail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #3525 from huxihx/log_compact_test",2017-07-20 21:49:27,huxihx,Mixed
1110f66fa7278212160c6e8392b6e6ab09560452,"KAFKA-3741; allow users to specify default topic configs for internal topics

Allow users to specify default topic configs for streams internal topics by supplying properties from `TopicConfig` with a prefix.
Supplied defaults are used when creating the internal topics. They are overridden by the configs supplied along with the `InternalTopicConfig`

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3459 from dguy/kafka-3741",2017-07-21 12:15:40,Damian Guy,Mixed
4a7064d1ae323903a0d1353372aabadabebb1ed6,"KAFKA-5512; Awake the heartbeat thread when timetoNextHeartbeat is equal to 0

Author: Stephane Roset <stephane@roset.me>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #3442 from rosets/KAFKA-5512",2017-07-21 08:47:54,Stephane Roset,Mixed
fc93fb4b6116e809f2b69ddb2f7e0f12548fef51,"KAFKA-4763; Handle disk failure for JBOD (KIP-112)

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Onur Karaman <okaraman@linkedin.com>

Closes #2929 from lindong28/KAFKA-4763",2017-07-22 12:35:32,Dong Lin,Mixed
5d798511b12c5ef7555e4234fdd99a360176e435,"KAFKA-3856 (KIP-120) step two: extract internal functions from public facing TopologyBuilder class

 - extract InternalTopologyBuilder from TopologyBuilder
 - deprecate all ""leaking"" methods from public TopologyBuilder API
 - changed TopologyDescription and all nested classed into interfaces

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Eno Thereska <eno.thereska@gmail.com>, Bill Bejeck <bbejeck@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #3536 from mjsax/kafka-3856-extract-internal-topology-builder",2017-07-24 11:03:27,Matthias J. Sax,Mixed
f15cdbc91b240e656d9a2aeb6877e94624b21f8d,"KAFKA-5627; Reduce classes needed for LeaderAndIsrPartitionState and MetadataPartitionState

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3565 from lindong28/KAFKA-5627",2017-07-25 20:38:30,Dong Lin,Mixed
47ee8e954df62b9a79099e944ec4be29afe046f6,"KAFKA-4602; KIP-72 - Allow putting a bound on memory consumed by Incoming requests

this is the initial implementation.

Author: radai-rosenblatt <radai.rosenblatt@gmail.com>

Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>, Jun Rao <junrao@gmail.com>

Closes #2330 from radai-rosenblatt/broker-memory-pool-with-muting",2017-07-26 08:19:56,radai-rosenblatt,Mixed
e5e88f636fa9857105324f62cc758b1fed3602bb,"KAFKA-5501; introduce async ZookeeperClient

Author: Onur Karaman <okaraman@linkedin.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #3427 from onurkaraman/KAFKA-5501",2017-07-26 08:03:10,Onur Karaman,Mixed
89faed8d30eb441fac7f1564edd40115006f5051,"MINOR: enforce setting listeners in CREATE state.

Author: Bill Bejeck <bill@confluent.io>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>

Closes #3569 from bbejeck/MINOR_enforce_adding_listeners_only_created_state",2017-07-26 09:08:14,Bill Bejeck,Mixed
9f3f8b4de64501902a4843064b1cf1feb21c690a,"KAFKA-5562; execute state dir cleanup on single thread

Use a single `StateDirectory` per streams instance.
Use threadId to determine which thread owns the lock.
Only allow the owning thread to unlock.
Execute cleanup on a scheduled thread in `KafkaStreams`

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bbejeck@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #3516 from dguy/kafka-5562",2017-07-26 10:10:50,Damian Guy,Mixed
f8498ec9e27ca0f08e3791d7a19ad8c6a97e210f,"MINOR: updated configs to use one try/catch for serdes

removed `try/catch` from `keySerde` and `valueSerde` methods so only the `try\catch` blocks in `defaultKeySerde` and `defaultValueSerde` perform error handling resulting in correct error message.

Author: Bill Bejeck <bill@confluent.io>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3568 from bbejeck/MINOR_ensure_correct_error_messages_for_configs",2017-07-26 12:58:33,Bill Bejeck,Mixed
3620035c45736b74e69921f7c50a1c3857aec334,"KAFKA-5611; AbstractCoordinator should handle wakeup raised from onJoinComplete

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3571 from hachikuji/KAFKA-5611",2017-07-26 22:53:11,Jason Gustafson,Mixed
8b14e11743360a711b2bb670cf503acc0e604602,"KAFKA-1595; Remove deprecated and slower Scala JSON parser

In a test by onurkaraman involving 3066 topics and 95895 partitions,
Controller initialisation time spent on JSON parsing would be reduced from
37.1 seconds to 0.7 seconds by switching from the current JSON parser to
Jackson. See the following JIRA comment for more details:

https://issues.apache.org/jira/browse/KAFKA-5328?focusedCommentId=16027086

I tested that we only use Jackson methods introduced in 2.0 in the main
codebase by compiling it with the older version locally. We use a
constructor introduced in 2.4 in one test, but I didn't remove it as it
seemed harmless. The reasoning for this is explained in the mailing list
thread:

http://search-hadoop.com/m/uyzND1FWbWw1qUbWe

Finally, this PR only handles the parsing side. It would be good to use Jackson
for serialising to JSON as well. I filed KAFKA-5631 for that.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Onur Karaman <okaraman@linkedin.com>, Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #83 from ijuma/kafka-1595-remove-deprecated-json-parser-jackson",2017-07-27 14:12:57,Ismael Juma,Mixed
6bd7302645a6167299de6de4e5a19749502db25c,"KAFKA-5634; Do not allow segment deletion beyond high watermark

This patch changes the segment deletion behavior to take the high watermark of the partition into account. In particular, segments containing offsets equal to or larger than the high watermark are no longer eligible for deletion. This is needed to ensure that the log start offset reported in fetch responses does not get ahead of the high watermark.

Impact: segment deletion may be delayed compared to existing behavior since the broker must await advancement of the high watermark. For topics with heavy load, this may make the active segment effectively ineligible for deletion since the high watermark may never catch up to the log end offset.

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #3575 from hachikuji/KAFKA-5634",2017-07-27 12:53:26,Jason Gustafson,Mixed
c50c941af1395d010160790f0127f06106cc69c8,"KAFKA-5363 (KIP-167): implementing bulk load, restoration event notification

Author: Bill Bejeck <bill@confluent.io>

Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3325 from bbejeck/KAFKA-5363_add_ability_to_batch_restore",2017-07-28 11:30:56,Bill Bejeck,Mixed
1844bf2b2f4cdf5a8209d7ceccb6701fc7dcf768,"KAFKA-5670: (KIP-120) Add Topology and deprecate TopologyBuilder

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3590 from mjsax/kafka-3856-replace-topology-builder-by-topology",2017-07-28 16:46:34,Matthias J. Sax,Mixed
da2205578be3228ce40eb5e59f6bbcb0c8da0aba,"KAFKA-5671: Add StreamsBuilder and Deprecate KStreamBuilder

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3602 from mjsax/kafka-5671-add-streamsbuilder",2017-07-31 15:28:59,Matthias J. Sax,Mixed
cd4c6c0183edfbf8e7e8ce526d638e31fcd09186,"KAFKA-5630; Consumer should block on corrupt records and keep throwing an exception

This patch handles the case that a CorruptRecordException is thrown from the iterator directly.
The fix is a little tricky as exceptions can be thrown from a few different scenarios. The current approach is to let the same record go through the exact same process as last time when exception is thrown, so the exception will be thrown at the same step. The only problem for that is the iterator state will change once it throws an exception. To handle that we cache the first iterator exception and put it into the suppressed exception of the IllegalStateException thrown in the future.

Author: Jiangjie Qin <becket.qin@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3573 from becketqin/KAFKA-5630",2017-08-01 08:56:23,Jiangjie Qin,Mixed
228a4fdb6dc15d1b8615615e00825e7ce53a41fa,"HOTFIX: handle commit failed exception on stream thread's suspend task

1. Capture `CommitFailedException` in `StreamThread#suspendTasksAndState`.

2. Remove `Cache` from AbstractTask as it is not needed any more; remove not used cleanup related variables from StreamThread (cc dguy to double check).

3.  Also fix log4j outputs for error and warn, such that for WARN we do not print stack trace, and for ERROR we remove the dangling colon since the exception stack trace will start in newline.

4. Update one log4j entry to always print as WARN for errors closing a zombie task (cc mjsax ).

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>

Closes #3574 from guozhangwang/KHotfix-handle-commit-failed-exception-in-suspend",2017-08-01 12:28:24,Guozhang Wang,Mixed
b7684b47b80a2a7d604632bb325fde49e570480f,"KAFKA-5096; Log invalid user configs and use defaults

Kafka Streams does not allow users to modify some consumer configurations.
Currently, it does not allow modifying the value of 'enable.auto.commit'.
If the user modifies this property, currently an exception is thrown.
The following changes were made in this patch:
- Defined a new array 'NON_CONFIGURABLE_CONSUMER_CONFIGS' to hold the names
  of the configuration parameters that is not allowed to be modified
- Defined a new method 'checkIfUnexpectedUserSpecifiedConsumerConfig' to
  check if user overwrote the values of any of the non configurable configuration
  parameters. If so, then log a warning message and reset the default values
- Updated the javadoc to include the configuration parameters that cannot be
  modified by users.
- Updated the corresponding tests in StreamsConfigTest.java to reflect the changes
  made in StreamsConfig.java

Author: Mariam John <mariamj@us.ibm.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Eno Thereska <eno.thereska@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>

Closes #2990 from johnma14/bug/kafka-5096",2017-08-02 14:11:23,Mariam John,Mixed
125d69caee993710bc07523fdd3deb0e06b10636,"KAFKA-5671 Followup: Remove reflections in unit test classes

1. Remove rest deprecation warnings in streams:jar.

2. Consolidate all unit test classes' reflections to access internal topology builder from packages other than `o.a.k.streams`. We need to refactor the hierarchies of StreamTask, StreamThread and KafkaStreams to remove these hacky reflections.

3. Minor fixes such as reference path, etc.

4. Minor edits on web docs for the describe function under developer-guide.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Bill Bejeck <bill@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Damian Guy <damian.guy@gmail.com>

Closes #3603 from guozhangwang/K5671-followup-comments",2017-08-02 15:13:02,Guozhang Wang,Mixed
fb21209b5ad30001eeace56b3c8ab060e0ceb021,"KAFKA-5663; Pass non-null logDirFailureChannel to Log.apply

Also:
- Improve logging
- Remove dangerous default arguments in Log.apply
- Improve naming of methods and fields in LogDirFailureChannel
- Some clean-ups

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Jiangjie (Becket) Qin <becket.qin@gmail.com>, Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #3594 from lindong28/KAFKA-5663",2017-08-02 23:53:56,Dong Lin,Mixed
6bee1e9e5799398550e1897bcef6c5067452500b,"HOTFIX: Fixes to metric names of Streams

A couple of fixes to metric names to match the KIP
- Removed extra strings in the metric names that are already in the tags
- add a separate metric for ""all""

Author: Eno Thereska <eno.thereska@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #3491 from enothereska/hotfix-metric-names",2017-08-03 14:16:47,Eno Thereska,Mixed
13deb84dcf4b3e583997dbd05a0e25840f024375,"MINOR: Null out all buffer references in RequestChannel.Request

The previous code kept two references to `Buffer` and only nulled
out one of them.

As part of this, I removed the `case` modifier from
`RequestChannel.{Request, Response}`. They don't seem to be good
matches given the types of fields they contain (mutable buffers and
opaque `Send` instances).

Also removed a couple of unused files in `kafka.network`.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Radai Rosenblatt <radai.rosenblatt@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #3596 from ijuma/release-buffer-in-request",2017-08-03 14:56:20,Ismael Juma,Mixed
5a516fb28e6a2af559fcbac5df12f048a5916fc6,"KAFKA-2507 KAFKA-2959; Remove legacy ControlledShutdown request/response objects

This patch replaces the legacy ControlledShutdown objects in `kafka.api` with the alternatives in `org.apache.kafka.common.requests`. Since this was the last API that needed updating, we have also dropped the reference in `RequestChannel.Request` to the legacy object type.

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3612 from hachikuji/remove-old-controlled-shutdown-objects",2017-08-03 16:18:26,Jason Gustafson,Mixed
e7f7d4093968d8de494e371a6d3c85e555332cbb,"KAFKA-5461; Add metric to track global topic count and global parition count in a cluster

Author: Abhishek Mendhekar <amendhekar@linkedin.com>

Reviewers: Joel Koshy <jjkoshy.w@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3549 from abhishekmendhekar/KAFKA-5461",2017-08-04 11:28:46,Abhishek Mendhekar,Not TDD
62f03ba2cd27880562dbf85c5ef6699d25bc5b43,"MINOR: Avoid duplicate processing of notifications in ZkNodeChangeNotificationListener

Also fix potential NPE.

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3615 from omkreddy/zk-notif-duplicates",2017-08-04 11:55:01,Manikumar Reddy,Mixed
22611aca9b33cc3db9362add785e44c7a3698ba3,"KAFKA-5535: Handle null values in ExtractField

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Jason Gustafson <jason@confluent.io>

Closes #3559 from ewencp/kafka-5535-extract-field-null",2017-08-04 10:25:21,Ewen Cheslack-Postava,Mixed
70796c3ca3306943e74d2ca260f3f28707481985,"MINOR: Fix error response handler for controlled shutdown v0

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3627 from hachikuji/minor-fix-controlled-shutdown-error-response",2017-08-04 13:08:12,Jason Gustafson,Not TDD
1cd86284e808e2846e94b312bb55141f6d216d51,"KAFKA-5700; Producer should not drop header information when splitting batches

Producer should not drop header information when splitting batches.  This PR also corrects a minor typo in Sender.java, where `spitting and retrying` should be `splitting and retrying`.

Author: huxihx <huxi_2b@hotmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jiangjie Qin <becket.qin@gmail.com>

Closes #3620 from huxihx/KAFKA-5700",2017-08-06 22:25:52,huxihx,Mixed
1f0ad0121e03a2e4f6c0cf3551b14c75085bd34f,"HOTFIX: fix for standby tasks using batching restore

Author: Bill Bejeck <bill@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #3625 from bbejeck/HOTFIX_need_to_correct_stanby_task_restoration_to_use_new_restore_api",2017-08-07 09:54:43,Bill Bejeck,Mixed
57770dd235a82994f296971079a97281be0a130b,"KAFKA-5701: fix flaky RocksDBStore unit test

1. Remove separate thread from test failing periodically due to race condition.
2. Remove anonymous `AbstractNotifyingBatchingRestoreCallback` declare as concrete inner class `RocksDBBatchingRestoreCallback` and set as package private variable.  Class is static so it has to initialize it's dependency on `RocksDBStore`

Author: Bill Bejeck <bill@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #3640 from bbejeck/KAFKA-5701_fix_flaky_unit_test",2017-08-07 15:20:24,Bill Bejeck,Mixed
c9ffab16228ecd5d931b58d93dfa3f49287d2909,"KAFKA-5658; Fix AdminClient request timeout handling bug resulting in continual BrokerNotAvailableExceptions

The AdminClient does not properly clear calls from the callsInFlight structure.
Later, in an effort to clear the lingering call objects, it closes the connection
they are associated with. This disrupts new incoming calls, which then get
BrokerNotAvailableException.

This patch fixes this bug by properly removing completed calls from the
callsInFlight structure. It also adds the Call#aborted flag, which
ensures that we throw the right exception (TimeoutException instead of
DisconnectException) and only abort a connection once -- even if there
is a similar bug in the future which causes old Call objects to linger.

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3584 from cmccabe/KAFKA-5658",2017-08-08 09:38:22,Colin P. Mccabe,Mixed
fb8edbdc6314411e0ed006a76e9658460a99208a,"MINOR: Update dependencies for 1.0.0 release

Notable updates:

1. Gradle 4.1 includes a number of performance and
CLI improvements as well as initial Java 9 support.

2. Scala 2.12.3 has substantial compilation time
improvements.

3. lz4-java 1.4 allows us to remove a workaround in
KafkaLZ4BlockInputStream (not done in this PR).

4. snappy-java 1.1.4 improved performance of compression (5%)
and decompression (20%). There was a slight increase in the
compressed size in one of our tests.

Not updated:

1. PowerMock due to a couple of regressions. I investigated one of them
and filed https://github.com/powermock/powermock/issues/828.

2. Jackson, which will be done via #3631.

3. Rocksdb, which will be done via #3519.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3619 from ijuma/update-deps-for-1.0.0",2017-08-09 01:11:39,Ismael Juma,Not TDD
1a653c813c842c0b67f26fb119d7727e272cf834,"KAFKA-5704: Corrected Connect distributed startup behavior to allow older brokers to auto-create topics

When a Connect distributed worker starts up talking with broker versions 0.10.1.0 and later, it will use the AdminClient to look for the internal topics and attempt to create them if they are missing. Although the AdminClient was added in 0.11.0.0, the AdminClient uses APIs to create topics that existed in 0.10.1.0 and later. This feature works as expected when Connect uses a broker version 0.10.1.0 or later.

However, when a Connect distributed worker starts up using a broker older than 0.10.1.0, the AdminClient is not able to find the required APIs and thus will throw an UnsupportedVersionException. Unfortunately, this exception is not caught and instead causes the Connect worker to fail even when the topics already exist.

This change handles the UnsupportedVersionException by logging a debug message and doing nothing. The existing producer logic will get information about the topics, which will cause the broker to create them if they don’t exist and broker auto-creation of topics is enabled. This is the same behavior that existed prior to 0.11.0.0, and so this change restores that behavior for brokers older than 0.10.1.0.

This change also adds a system test that verifies Connect works with a variety of brokers and is able to run source and sink connectors. The test verifies that Connect can read from the internal topics when the connectors are restarted.

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #3641 from rhauch/kafka-5704",2017-08-08 20:20:41,Randall Hauch,Mixed
a593db6a2b6c3511215008b6d3dd6bd77f84e8c4,"MINOR: Standardize logging of Worker-level messages from Tasks and Connectors

This ensures all logs have the connector/task ID, whether tasks are source or sink, and formats them consistently.

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Jason Gustafson <jason@confluent.io>

Closes #3639 from ewencp/standardize-connector-task-logging",2017-08-09 09:07:27,Ewen Cheslack-Postava,Mixed
c35c4798139bc30e3a380311e45a22ba56fcc918,"KAFKA-5717; InMemoryKeyValueStore should delete keys with null values during restore

Fixed a bug in the InMemoryKeyValueStore restoration where a key with a `null` value is written in to the map rather than being deleted.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Bill Bejeck <bbejeck@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #3650 from dguy/kafka-5717",2017-08-09 20:03:28,Damian Guy,Mixed
1ad74f5b760d16f3990a5024e717f4826278675d,"KAFKA-5629; ConsoleConsumer should respect auto.offset.reset if specified on the command line

when ""auto.offset.reset"" property is specified on the command line but overridden by the code during startup. Currently the ConsoleConsumer silently overrides that setting, which can create confusing behavior.

Author: Soenke Liebau <soenke.liebau@opencore.com>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3566 from soenkeliebau/KAFKA-5629",2017-08-09 13:22:05,Soenke Liebau,Mixed
8ffb1a1fedad4350dd0f0ce0dd52107f962ce428,"KAFKA-5711: batch restore should handle deletes

Author: Bill Bejeck <bill@confluent.io>

Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #3644 from bbejeck/KAFKA-5711_bulk_restore_should_handle_deletes",2017-08-10 11:31:55,Bill Bejeck,Mixed
3e69ce80157eb6a5e6dd05e3be522b5208a41bc5,"KAFKA-5702; extract refactor StreamThread

Extracted `TaskManager` to handle all task related activities.
Make `StandbyTaskCreator`, `TaskCreator`, and `RebalanceListener` static classes so they must define their dependencies and can be testing independently of `StreamThread`
Added interfaces between `StreamPartitionAssignor` & `StreamThread` to reduce coupling.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Eno Thereska <eno.thereska@gmail.com>

Closes #3624 from dguy/stream-thread-refactor",2017-08-11 12:14:01,Damian Guy,Mixed
e19c37e5914b1fa64befdfdf24edbf2415f8cdb3,"KAFKA-5673; refactor KeyValueStore hierarchy to make MeteredKeyValueStore outermost

refactor StateStoreSuppliers such that a `MeteredKeyValueStore`  is the outermost store.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Eno Thereska <eno.thereska@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #3592 from dguy/key-value-store-refactor",2017-08-14 10:02:32,Damian Guy,Mixed
8265a43897b3da88839df061ce22559820087ad9,"MINOR: Safer handling of requests prior to SASL authentication

This implements two improvements for request handling prior to SASL authentication:

1. Only parse request types that are allowed prior to authentication.
2. Limit the maximum request size (the default is 100Mb).

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3558 from hachikuji/minor-restrict-presasl-request-parsing",2017-08-14 14:05:40,Jason Gustafson,Mixed
21ea4b1d2a1b99aa804bd4461015abaf31673923,"KAFKA-5595; Ensure client connection ids are not reused too quickly

When there are broker delays that cause a response to take longer
than `connections.max.idle.ms`, connections may be closed by the
broker (as well as by the client) before the response is processed.
If the port is reused, broker may send the outstanding response to
a new connection with the reused port. The new connection will end
up with correlation id mismatch, requiring process restart. This
is also a security exposure since clients receive response
intended for the wrong connection.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3530 from rajinisivaram/KAFKA-5595",2017-08-14 17:07:50,Rajini Sivaram,Mixed
869ef5579f00661a5d68e92f09e088e7ed884189,"HOTFIX: ConsoleConsumer using wrong old consumer config value for auto.offset.reset

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3665 from hachikuji/hotfix-auto-reset-console-consumer",2017-08-14 13:52:02,Jason Gustafson,Mixed
3b1cea60e909e579e54775fc479397ddbeba95eb,"KAFKA-5731; Corrected how the sink task worker updates the last committed offsets

Prior to this change, it was possible for the synchronous consumer commit request to be handled before previously-submitted asynchronous commit requests. If that happened, the out-of-order handlers improperly set the last committed offsets, which then became inconsistent with the offsets the connector task is working with.

This change ensures that the last committed offsets are updated only for the most recent commit request, even if the consumer reorders the calls to the callbacks.

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3662 from rhauch/kafka-5731",2017-08-15 14:16:00,Randall Hauch,Mixed
72eacbea5b831096a6cc9a4fa42401bc74a88a80,"KAFKA-5567: Connect sink worker should commit offsets of original topic partitions

Author: Konstantine Karantasis <konstantine@confluent.io>

Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #3499 from kkonstantine/KAFKA-5567-With-transformations-that-mutate-the-topic-partition-committing-offsets-should-to-refer-to-the-original-topic-partition",2017-08-16 14:43:29,Konstantine Karantasis,Mixed
efe4f6540a3c26371c88b3f956bbd4abfe9dc52e,"KAFKA-5733: RocksDB bulk load with lower number of levels

This is to complete Bill's PR #3664 on KAFKA-5733, incorporating the suggestion in https://github.com/facebook/rocksdb/issues/2734.

Some minor changes: move `open = true` in `openDB`.

Author: Bill Bejeck <bill@confluent.io>
Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>

Closes #3681 from guozhangwang/K5733-rocksdb-bulk-load",2017-08-17 14:02:10,Bill Bejeck,Mixed
334a30bcfffc3759aeded08f2089cea4ed6e9937,"KAFKA-5730; Consumer should invoke async commit callback before sync commit returns

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <me@ewencp.org>

Closes #3666 from hachikuji/KAFKA-5730",2017-08-17 15:04:03,Jason Gustafson,Mixed
520e651d532558b346d08388cb9aa0ac6e156ece,"KAFKA-5742: support ZK chroot in system tests

Author: Xavier Léauté <xavier@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #3677 from xvrl/support-zk-chroot-in-tests",2017-08-17 15:14:32,Xavier Léauté,Not TDD
75c78e9692a479e2c94dbd08e564f64faedd2071,"KAFKA-5668; fetch across stores in CompositeReadOnlyWindowStore & CompositeReadOnlySessionStore

Fix range queries in `CompositeReadOnlyWindowStore` and `CompositeReadOnlySessionStore` to fetch across all stores (was previously just looking in the first store)

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #3685 from dguy/kafka-5668",2017-08-18 17:59:33,Damian Guy,Mixed
ed96523a2c763b48399a9720dcce0af44f5fc1a1,"KAFKA-4501; Java 9 compilation and runtime fixes

Compilation error fixes:
- Avoid ambiguity error when appending to Properties in Scala
code (https://github.com/scala/bug/issues/10418)
- Use position() and limit() to fix ambiguity issue (
https://github.com/scala/bug/issues/10418#issuecomment-316364778)
- Disable findBugs if Java 9 is used (
https://github.com/findbugsproject/findbugs/issues/105)

Compilation warning fixes:
- Avoid deprecated Class.newInstance in Utils.newInstance
- Silence a few Java 9 deprecation warnings
- var -> val and unused fixes

Runtime error fixes:
- Introduce Base64 class that works in Java 7 and Java 9

Also:
- Set --release option if building with Java 9

Note that tests involving EasyMock (https://github.com/easymock/easymock/issues/193)
or PowerMock (https://github.com/powermock/powermock/issues/783)
will fail as neither supports Java 9 currently.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3647 from ijuma/kafka-4501-support-java-9",2017-08-19 08:55:29,Ismael Juma,Mixed
6896f1ddb7650f42630aef8c67c8b61866e9fc00,"MINOR: Ensure consumer logging has clientId/groupId context

This patch ensures that the consumer groupId and clientId are available in all log messages which makes debugging much easier when a single application has multiple consumer instances. To make this easier, I've added a new `LogContext` object which builds a log prefix similar to the broker-side `kafka.utils.Logging` mixin. Additionally this patch changes the log level for a couple minor cases:

- Consumer wakeup events are now logged at DEBUG instead of TRACE
- Heartbeat enabling/disabling is now logged at DEBUG instead of TRACE

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3676 from hachikuji/log-consumer-wakeups",2017-08-19 11:17:02,Jason Gustafson,Mixed
bf3bfd6749610eb49a4e47bdda2e667ca7458ff2,"KAFKA-5747; Producer snapshot loading should cover schema errors

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #3688 from hachikuji/KAFKA-5747",2017-08-21 10:22:53,Jason Gustafson,Mixed
ee8e9349b22277ec69bf831dda66cfc6e767df14,"KAFKA-5689; Add MeteredWindowStore and refactor store hierarchy

Add MeteredWindowStore and ChangeLoggingWindowBytesStore.
Refactor Store hierarchy such that Metered is always the outermost store
Do serialization in MeteredWindowStore

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #3692 from dguy/kafka-5689",2017-08-22 11:21:32,Damian Guy,Mixed
3615ef730caeab3f79874c8e2acb9f7e0e9cff82,"KAFKA-5752; Update index files correctly during async delete

timeIndex and txnIndex were not being updated previously.

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3700 from omkreddy/KAFKA-5752",2017-08-22 15:11:04,Manikumar Reddy,Mixed
b78d7ba5d58fa77b831244444eef005a62883f9b,"KAFKA-5152: perform state restoration in poll loop

In onPartitionsAssigned:

release all locks for non-assigned suspended tasks.
resume any suspended tasks.
Create new tasks, but don't attempt to take the state lock.
Pause partitions for any new tasks.
set the state to PARTITIONS_ASSIGNED
In StreamThread#runLoop

poll
if state is PARTITIONS_ASSIGNED
2.1 attempt to initialize any new tasks, i.e, take out the state locks and init state stores
2.2 restore some data for changelogs, i.e., poll once on the restore consumer and return the partitions that have been fully restored
2.3 update tasks with restored partitions and move any that have completed restoration to running
2.4 resume consumption for any tasks where all partitions have been restored.
2.5 if all active tasks are running, transition to RUNNING and assign standby partitions to the restoreConsumer.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #3675 from dguy/kafka-5152",2017-08-22 11:13:08,Damian Guy,Mixed
ea21752a79f3e843f0c2a74ea093a8793e42edb4,"KAFKA-5417; Fix Selector's handling of some failures during prepare

If prepare throws an exception in the same poll when the connection
is established, the channel id should be in `disconnected`, but
not in `connected`.

Author: dongeforever <dongeforever@apache.org>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3282 from dongeforever/KAFKA-5417",2017-08-23 14:47:41,dongeforever,Mixed
5b99a288cd2d4461380b041067768ee6c1b2efc7,"KAFKA-5644; Fix Reset Consumer Group Offset tool to handle minute component of TimeZone

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3626 from omkreddy/KAFKA-5644",2017-08-23 14:31:44,Manikumar Reddy,Not TDD
71417552c7651a5b41e73460d0577615864aafe8,"KAFKA-5342; Clarify producer fatal/abortable errors and fix inconsistencies

This patch improves documentation on the handling of errors for the idempotent/transactional producer. It also fixes a couple minor inconsistencies and improves test coverage. In particular:
- UnsupportedForMessageFormat should be a fatal error for TxnOffsetCommit responses
- UnsupportedVersion should be fatal for Produce responses and should be returned instead of InvalidRequest

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #3716 from hachikuji/KAFKA-5342",2017-08-24 16:03:55,Jason Gustafson,Mixed
e6164ec611ca48e71c549f88d8a92fef90bf5a71,"MINOR: Fix transient failure in SocketServerTest.testConnectionIdReuse

Two requests sent together may not always trigger a staged receive since the requests may not be received in a single poll and the channel is muted when receives are complete. Hence attempt to stage multiple times until a receive is staged to make the test more stable.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Apurva Mehta <apurva@confluent.io>

Closes #3712 from rajinisivaram/MINOR-connectionidreuse-test",2017-08-24 22:12:50,Rajini Sivaram,Mixed
05e3850b2ea24f372ea1cc6ca7457e0ff99445f6,"KAFKA-5771; org.apache.kafka.streams.state.internals.Segments#segments method returns incorrect results when segments were added out of order

Suggested fix for the bug

Author: radzish <radzish@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>

Closes #3737 from radzish/KAFKA-5771",2017-08-25 13:59:10,radzish,Mixed
c4d629a0b3cbd11c174cb8b09a50bc8de77825e9,"MINOR: Consolidate broker request/response handling

This patch contains a few small improvements to make request/response handling more consistent. Primarily it consolidates request/response serialization logic so that `SaslServerAuthenticator` and `KafkaApis` follow the same path. It also reduces the amount of custom logic needed to handle unsupported versions of the ApiVersions requests.

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3673 from hachikuji/consolidate-response-handling",2017-08-25 10:23:11,Jason Gustafson,Mixed
607c3c21f652a8f911d1efb8374d2eec313a4e2d,"KAFKA-5755; KafkaProducer should be refactored to use LogContext

With LogContext, each producer log item is automatically prefixed with client id and transactional id.

Author: huxihx <huxi_2b@hotmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3703 from huxihx/KAFKA-5755",2017-08-25 10:42:40,huxihx,Mixed
0772fde562ed361beec6ad745895a0ee0cf229e8,"KAFKA-5776; Add the Trogdor fault injection daemon

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #3699 from cmccabe/trogdor-review",2017-08-25 12:29:40,Colin P. Mccabe,Mixed
c715f6a5ab94d187eb662efde594f0f14dcd9910,"KAFKA-5749; Add MeteredSessionStore and ChangeloggingSessionBytesStore.

Make MeteredSessionStore the outermost store.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #3729 from dguy/kafka-5749",2017-08-26 09:08:46,Damian Guy,Mixed
551d57561d6cb9e53aa16e0616190d370d339355,"KAFKA-5787: StoreChangelogReader needs to restore partitions that were added post initialization

If a task fails during initialization due to a LockException, its changelog partitions are not immediately added to the StoreChangelogReader as the thread doesn't hold the lock. However StoreChangelogReader#restore will be called and it sets the initialized flag. On a subsequent successfull call to initialize the new tasks the partitions are added to the StoreChangelogReader, however as it is already initialized these new partitions will never be restored. So the task would remain in a non-running state forever.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3736 from dguy/kafka-5787",2017-08-26 11:14:08,Damian Guy,Mixed
7ae02a69c4965ccc6b9aeb72a0803d8ab1f62cc8,"KAFKA-5720; Fix AdminClientIntegrationTest#testCallInFlightTimeouts

* When a call is aborted, that should count as a ""try"" in the failure log message.
* FailureInjectingTimeoutProcessorFactory should fail the first request it is asked about.
* testCallTimeouts should expect the first request it makes to fail because of the timeout we injected.
* FailureInjectingTimeoutProcessorFactory should track how many failures it has injected, and the test should verify that one has been injected.

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3731 from cmccabe/KAFKA-5720",2017-08-27 09:26:38,Colin P. Mccabe,Mixed
1f659913a631d9e77e7cd9b9c9775e3249ef803a,"MINOR: simplify state transition for Kafka Streams and stream threads

1. StreamThread: prevent `PARTITIONS_REVOKED` to transit to itself in `setState` by returning false. And only execute the task suspension logic when `setState(PARTITIONS_REVOKED)` returns true in `onPartitionsRevoked`.

2. StreamThread: minor, renaming `shutdown` to `completeShutdown`, and `close` to `shutdown`, `stillRunning` to `isRunning`, `isInitialized` to `isRunningAndNotRebalancing`.

3. GlobalStreamThread: tighten the transition a bit in `setState`. Force transiting to `PENDING_SHUTDOWN` and `DEAD` when initialization failed.

4. GlobalStreamThread: minor, add logPrefix to StateConsumer. Also removing its state change listener when closing the thread.

5. KafkaStreams: because of 1) above we can now prevent its `REBALANCING` to `REBALANCING`.

6. KafkaStreams: prevent `CREATED` to ever go to `REBALANCING` first to force it transit to `RUNNING` when starting. Also prevent `CREATED` to go to `ERROR`.

7. KafkaStreams: collapse `validateStartOnce` and `checkFirstTimeClosing ` into `setState`.

8. KafkaStreams: in `close` and `start`, only execute the logic when `setState` succeeds.

Author: Guozhang Wang <wangguoz@gmail.com>
Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>

Closes #3713 from guozhangwang/KMinor-set-state",2017-08-29 10:40:42,Guozhang Wang,Mixed
9ef2b3ce8e4553504e52385a6370bf641fc6ea1e,"KAFKA-5379: ProcessorContext.appConfigs() should return parsed values

Author: Tommy Becker <tobecker@tivo.com>
Author: Tommy Becker <twbecker@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3455 from twbecker/kafka-5379",2017-08-29 13:01:57,Tommy Becker,Mixed
76c9a6dcbc1fa92d1a7c2e913ad42b5f1a72fe62,"KAFKA-5804; retain duplicates in ChangeLoggingWindowBytesStore

`ChangeLoggingWindowBytesStore` needs to have the same `retainDuplicates` functionality as `RocksDBWindowStore` else data could be lost upon failover/restoration.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3754 from dguy/hotfix-changelog-window-store",2017-08-30 13:52:44,Damian Guy,Mixed
6682abe4ae68fdbf0eb362e45f43ea14e2aba847,"KAFKA-5797: Delay checking of partition existence in StoreChangelogReader

1. Remove timeout-based validatePartitionExists from StoreChangelogReader; instead only try to refresh metadata once after all tasks have been created and their topology initialized (hence all stores have been registered).
2. Add the logic to refresh partition metadata at the end of initialization if some restorers needing initialization cannot find their changelogs, hoping that in the next run loop these stores can find their changelogs.

As a result, after `initialize` is called we may not be able to start initializing all the `needsInitializing` ones.

As an optimization, we would not call `consumer#partitionsFor` any more, but only `consumer#listTopics` fetching all the topic metadata; so the only blocking calls left are `listTopics` and `endOffsets`, and we always capture timeout exceptions around these two calls, and delay to retry in the next run loop after refreshing the metadata. By doing this we can also reduce the number of request round trips between consumer and brokers.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>

Closes #3748 from guozhangwang/K5797-handle-metadata-available",2017-08-30 08:43:22,Guozhang Wang,Mixed
9836adc732288924813927c4869ffb3908febba1,"KAFKA-2105; Check for null in KafkaProducer.partitionsFor

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3697 from omkreddy/KAFKA-2105",2017-08-31 16:30:42,Manikumar Reddy,Mixed
9ebc303bb85bf5aae2b732c60d3b3e0a6e07512d,"KAFKA-5379 follow up: reduce redundant mock processor context

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>

Closes #3757 from guozhangwang/K5379-follow-up",2017-08-31 08:43:13,Guozhang Wang,Not TDD
47c2753496875db2849065ad91ee03c7c842c8e9,"MINOR: Test SASL authorization id

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3766 from rajinisivaram/MINOR-sasl",2017-08-31 12:42:08,Rajini Sivaram,Mixed
bc999989bff39db2f5e7b07968988ed9ccba49b2,"KAFKA-5759; Allow user to specify relative path as log directory

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jiangjie Qin<becket.qin@gmail.com>

Closes #3709 from lindong28/KAFKA-5759",2017-09-01 09:38:27,Dong Lin,Not TDD
14a7c297ab917efb28e579fa942d58cdcf4930c5,"KAFKA-5818; KafkaStreams state transitions not correct

- need to check that state is CRATED at startup
- some minor test cleanup

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>

Closes #3775 from mjsax/kafka-5818-kafkaStreams-state-transition",2017-09-02 08:24:43,Matthias J. Sax,Mixed
b2a328daf2a51520290fc4ec31ce5d92b2c0ef01,"KAFKA-5659; Fix error handling, efficiency issue in AdminClient#describeConfigs

If a request for a broker configuration failed due to a timeout or
the broker not being available, we would fail the futures
associated with the non-broker request instead (and never fail the
broker future, which would be left uncompleted forever).

We would also do an unnecessary request if only broker configs were
requested.

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3585 from cmccabe/KAFKA-5659",2017-09-02 08:54:58,Colin P. Mccabe,Mixed
adefc8ea076354e07839f0319fee1fba52343b91,"KAFKA-5694; Add AlterReplicaDirRequest and DescribeReplicaDirRequest (KIP-113 part-1)

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Jiangjie Qin <becket.qin@gmail.com>, Colin P. Mccabe <cmccabe@confluent.io>

Closes #3621 from lindong28/KAFKA-5694",2017-09-02 23:20:13,Dong Lin,Mixed
facd2c5a8c7a4379755955ba3e318bfecde6af39,"KAFKA-4819: Expose states for active tasks to public API

Simple implementation of the feature : [KAFKA-4819](https://issues.apache.org/jira/browse/KAFKA-4819)
 KAFKA-4819

This PR adds a new method `threadStates` to public API of `KafkaStreams` which returns all currently states of running threads and active tasks.

Below is a example for a simple topology consuming from topics; test-p2 and test-p4.

[{""name"":""StreamThread-1"",""state"":""RUNNING"",""activeTasks"":[{""id"":""0_0"", ""assignments"":[""test-p4-0"",""test-p2-0""], ""consumedOffsetsByPartition"":[{""topicPartition"":""test-p2-0"",""offset"":""test-p2-0""}]}, {""id"":""0_2"", ""assignments"":[""test-p4-2""], ""consumedOffsetsByPartition"":[]}]}, {""name"":""StreamThread-2"",""state"":""RUNNING"",""activeTasks"":[{""id"":""0_1"", ""assignments"":[""test-p4-1"",""test-p2-1""], ""consumedOffsetsByPartition"":[{""topicPartition"":""test-p2-1"",""offset"":""test-p2-1""}]}, {""id"":""0_3"", ""assignments"":[""test-p4-3""], ""consumedOffsetsByPartition"":[]}]}]

Author: Florian Hussonnois <florian.hussonnois@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #2612 from fhussonnois/KAFKA-4819",2017-09-05 14:11:59,Florian Hussonnois,Mixed
752e5317410f05d08f69f302e4ee0cadae183b59,"KAFKA-5603; Don't abort TX for zombie tasks

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #3719 from mjsax/kafka-5603-dont-abort-tx-for-zombie-tasks-2",2017-09-05 15:47:31,Matthias J. Sax,Mixed
81e789ae3dc6ea8369db181c5aef440491d74f19,"KAFKA-4860; Allow spaces in paths on windows

When we install kafka on path with spaces, batch files were failing, this PR is trying to fix this issue.

Author: Vladimír Kleštinec <klestinec@gmail.com>

Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Jason Gustafson <jason@confluent.io>

Closes #2649 from klesta490/trunk",2017-09-05 16:27:08,Vladimír Kleštinec,Not TDD
5d69966195409d73e6e4d74e8a898fac754450cc,"KAFKA-5837; Set defaults for ReassignPartitionsCommand correctly

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Dong Lin <lindong28@gmail.com>

Closes #3792 from rajinisivaram/KAFKA-5837",2017-09-06 00:32:59,Rajini Sivaram,Not TDD
2fb5664bf4591f3e7bdc02894b9de392bf72913c,"KAFKA-5597: Autogenerate producer sender metrics

Subtask of https://issues.apache.org/jira/browse/KAFKA-3480

The changes are very similar to what was done for the consumer in https://issues.apache.org/jira/browse/KAFKA-5191 (pull request https://github.com/apache/kafka/pull/2993)

Author: James Cheng <jylcheng@yahoo.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #3535 from wushujames/producer_sender_metrics_docs

Fix one minor naming bug",2017-09-05 17:38:58,James Cheng,Mixed
b687c068008a81fad390c80da289249cc04b3efb,"KAFKA-5817; Add Serialized class and overloads to KStream#groupBy and KStream#groupByKey

Part of KIP-182
- Add the `Serialized` class
- implement overloads of `KStream#groupByKey` and KStream#groupBy`
- deprecate existing methods that have more than default arguments

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3772 from dguy/kafka-5817",2017-09-06 10:43:14,Damian Guy,Not TDD
45394d52c1ba566178c57897297a3ea31379f957,"KAFKA-5819; Add Joined class and relevant KStream join overloads

Add the `Joined` class and the overloads to `KStream` that use it.
Deprecate existing methods that have `Serde` params

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3776 from dguy/kip-182-stream-join",2017-09-06 10:55:43,Damian Guy,Mixed
23d01c805bef7504abfa83ecac7e384d121a583a,"KAFKA-5726; KafkaConsumer.subscribe() overload that takes just Pattern

- changed the interface & implementations
- updated tests to use the new method where applicable

Author: Attila Kreiner <attila@kreiner.hu>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #3669 from attilakreiner/KAFKA-5726",2017-09-06 11:41:33,Attila Kreiner,Mixed
3f155eaa23c6081e4afa3b49f0f8a65a16b8e05c,"MINOR: Log encountered exception during rebalance

Some other minor changes:

1. Do not throw the exception form callback as it would only be swallowed by consumer coordinator; remembering it and re-throw in the next loop is good enough.
2. Change Creating to Defining in Stores to avoid confusions that the stores have already been successfully created at that time.
3. Do not need unAssignChangeLogPartitions as the restore consumer will be unassigned already inside changelog reader.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>

Closes #3769 from guozhangwang/KMinor-logging-before-throwing",2017-09-06 18:38:08,Guozhang Wang,Mixed
9b85cf9ed02d4b3b87ea39e0c2f8c35e1e813f2f,"MINOR: KIP-138 renaming of string names

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>

Closes #3796 from guozhangwang/kip-138-minor-renames",2017-09-06 18:39:40,Guozhang Wang,Mixed
667cd60dc6ba68831423a256b6e455f7d955581c,"KAFKA-5816; add Produced class, KStream#to(topic, Produced), and KStream#through(topic, Produced)

Add the `Produced` class and `KStream` overloads that use it:
`KStream#to(String, Produced)`
`KStream#through(String, Produced)`
Deprecate all other to and through methods accept the single param methods that take a topic param

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3770 from dguy/kafka-5652-produced",2017-09-07 08:54:10,Damian Guy,Mixed
9cbb9f0939c88868bf33ae340c5fa756ee2965e8,"KAFKA-5650; add StateStoreBuilder interface and implementations

Part of KIP-182

- Add `StateStoreBuilder` interface and `WindowStateStoreBuilder`, `KeyValueStateStoreBuilder`, and `SessionStateStoreBuilder` implementations
- Add `StoreSupplier`, `WindowBytesStoreSupplier`, `KeyValueBytesStoreSupplier`, `SessionBytesStoreSupplier` interfaces and implementations
- Add new methods to `Stores` to create the newly added `StoreSupplier` and `StateStoreBuilder` implementations
- Update `Topology` and `InternalTopology` to use the interfaces

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3767 from dguy/kafka-5650",2017-09-07 09:39:46,Damian Guy,Mixed
329d5fa64a2a3ac1d39ac37fdacbf6e43d500d11,"KAFKA-5844; add groupBy(selector, serialized) to Ktable

add `KTable#groupBy(KeyValueMapper, Serialized)` and deprecate the overload with `Serde` params

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bill@confluent.io>

Closes #3802 from dguy/kip-182-ktable-groupby",2017-09-07 12:35:31,Damian Guy,Not TDD
4065ffb3e1a82f71578811a0a329cdc90e5e1567,"KAFKA-5777; Add ducktape integration for Trogdor

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #3726 from cmccabe/KAFKA-5777",2017-09-07 13:23:03,Colin P. Mccabe,Mixed
3410f02fec6bc8633ebb58e3c1a8f9c2e49a1aa4,"KAFKA-4585: Lower the Minimum Required ACL Permission of OffsetFetch (KIP-163)

Details can be found in the [KIP](https://cwiki.apache.org/confluence/display/KAFKA/KIP-163%3A+Lower+the+Minimum+Required+ACL+Permission+of+OffsetFetch).

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #3661 from vahidhashemian/KAFKA-4585",2017-09-07 11:40:54,Vahid Hashemian,Not TDD
674407908b898dd18b447447ad3346b5268b1dfc,"KAFKA-5698: Sort processor nodes based on its sub-tree size

1. Sort processor nodes within a sub-topology by its sub-tree size: nodes with largest sizes are source nodes and hence printed earlier.

2. Sort sub-topologies by ids; sort global stores by the source topic names.

3. Open for discussion: start newlines for predecessor and successor.

4. Minor: space between processor nodes and stores / topics; maintain `[]` for the topic names.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Ted Yu <yuzhihong@gmail.com>

Closes #3618 from guozhangwang/K5698-topology-description-sorting",2017-09-07 14:36:49,Guozhang Wang,Mixed
27336192ff62d43d0beabc5dab2855b87befcc55,"MINOR: Include response in request log

It's implemented such that there is no overhead if request logging is
disabled.

Also:
- Reduce metrics computation duplication in `updateRequestMetrics`
- Change a couple of log calls to use string interpolation instead of `format`
- Fix a few compiler warnings related to unused imports and unused default
arguments.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Roger Hoover <roger.hoover@gmail.com>, Jason Gustafson <jason@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #3801 from ijuma/log-response-in-request-log",2017-09-08 04:40:24,Ismael Juma,Mixed
d0ee6ed36baf702fa24dac8ae31f45fc27324d89,"KAFKA-5832; add Consumed and change StreamBuilder to use it

Added `Consumed` class.
Updated `StreamBuilder#stream`, `StreamBuilder#table`, `StreamBuilder#globalTable`

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3784 from dguy/kip-182-stream-builder",2017-09-08 08:21:48,Damian Guy,Mixed
ef17d5b892fa34811c805cac366744040e6d6efb,"KAFKA-4260; Disallow non-routable address in advertised.listeners

As described in the JIRA ticket, when `listeners=PLAINTEXT://0.0.0.0:9092`
(note the 0.0.0.0 ""bind all interfaces"" IP address) and
`advertised.listeners` is not specified it defaults to `listeners`,
but it makes no sense to advertise 0.0.0.0 as it's not a routable IP
address.

This patch checks for a 0.0.0.0 host in `advertised.listeners`
(whether via default or not) and fails with a meaningful error if it's
found.

This contribution is my original work and I license the work to the
project under the project's open source license.

Author: Tom Bentley <tbentley@redhat.com>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3382 from tombentley/advertised.listeners",2017-09-08 13:10:13,Tom Bentley,Mixed
ee4e4c8cb35d1403c521518d6c269bbc03700325,"KAFKA-5656; Support bulk attributes request on KafkaMbean where some attributes do not exist

Author: Erik Kringen <erik.kringen@icloud.com>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3582 from ErikKringen/trunk",2017-09-08 13:30:23,Erik Kringen,Not TDD
e16b9143dfcecbd58e3bebecbdb7d8e933b88cc4,"KAFKA-5853; implement WindowedKStream

Add the `WindowedKStream` interface and implementation of methods that don't require `Materialized`

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3809 from dguy/kgrouped-stream-windowed-by",2017-09-08 16:49:18,Damian Guy,Mixed
4769e3d92acdc6036f1f834c70004f0c867ae582,"KAFKA-5815; add Printed class and KStream#print(printed)

Part of KIP-182
- Add `Printed` class and `KStream#print(Printed)`
- deprecate all other `print` and `writeAsText` methods

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3768 from dguy/kafka-5652-printed",2017-09-08 18:22:04,Damian Guy,Mixed
6ebd9d35fc081bca3f1efeba8b70ec71cde85270,"KAFKA-5790, KAFKA-5607; Improve error handling in SocketServer to avoid issues later

Changes:
  1. When an exception is encountered in any of the methods in `Processor` while processing a channel, log the exception and close the connection. Continue to process other channels.
  2. Fixes KAFKA-5790: SocketServer.processNewResponses should not skip a response if exception is thrown.
  3. For `IllegalStateException` and `IOException` in `poll()`, don't close the `Selector`. Log the exception and continue.
  4. Close channel on any failed send in `Selector`.
  5. When closing channel fails or is closed, leave channel state as-is, indicating the state in which the channel was moved to closing.
  6. Add tests for various failure scenarios.
  7. Fix timing issue in `SocketServerTest.testConnectionIdReuse` by waiting for new connections to be processed by the server.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3548 from rajinisivaram/KAFKA-5607",2017-09-08 18:42:42,Rajini Sivaram,Mixed
2db1e4423fb33405a319b253b040e57e069c1f7a,"KAFKA-5852: Add filter, filterNot, mapValues and Materialized to KTable

Add overloads of `filter`, `filterNot`, `mapValues` that take `Materialized` as a param to `KTable`. Deprecate overloads using `storeName` and `storeSupplier`

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3807 from dguy/ktable-filter-map",2017-09-08 14:01:58,Damian Guy,Mixed
ae4100f82c13b3e6978c0a0f697312bd073e0eb3,"KAFKA-5792; Fix Transient failure in KafkaAdminClientTest.testHandleTimeout

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3822 from cmccabe/KAFKA-5792",2017-09-09 08:34:03,Colin P. Mccabe,Mixed
c5464edbb7a6821e0a91a3712b1fe2fd92a22d68,"KAFKA-5531; throw concrete exceptions in streams tests

1. Now instead of just generic `Exception` methods declare more concrete
exceptions throwing or don't declare any throwing at all, if not needed.
2. `SimpleBenchmark.run()` throws `RuntimeException`
3. `SimpleBenchmark.produce()` throws `IllegalArgumentException`
4. Expect `ProcessorStateException` in
`StandbyTaskTest.testUpdateNonPersistentStore()`

/cc enothereska

Author: Evgeny Veretennikov <evg.veretennikov@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>

Closes #3485 from evis/5531-throw-concrete-exceptions",2017-09-11 09:42:10,Evgeny Veretennikov,Not TDD
9bb06c3eef3ebdff77e5e3b98c26b86c40efc56c,"KAFKA-5763; Use LogContext in NetworkClient, Selector and broker

Author: Andrey Dyachkov <andrey.dyachkov@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3761 from adyach/kafka-5763",2017-09-11 15:37:46,Andrey Dyachkov,Mixed
a67140317a644034e91ee596ab22bfb55adde1e0,"MINOR: update processor topology test driver

Author: Bill Bejeck <bill@confluent.io>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>

Closes #3828 from bbejeck/MINOR_update_processor_topology_test_driver",2017-09-12 09:23:28,Bill Bejeck,Not TDD
08063f50a04fda3e40c6060a432a97f49bb68c8c,"KAFKA:5653: add join overloads to KTable

Add `join`, `leftJoin`, `outerJoin` overloads that use `Materialized` to `KTable`

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3826 from dguy/kafka-5653",2017-09-12 16:01:19,Damian Guy,Mixed
8bd2a68b5020f0bf8f79cbe59676d649eebf170f,"KAFKA-5655; materialized count, aggregate, reduce to KGroupedTable

Add overloads of `count`, `aggregate`, `reduce` using `Materialized` to `KGroupedTable`
deprecate other overloads

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3829 from dguy/kafka-5655",2017-09-12 17:20:43,Damian Guy,Mixed
9ed8bf273c6ee5569ed68b71782ec7ab947f9c93,"KAFKA-5872; Fix transient failure in SslSelectorTest.testMuteOnOOM

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3836 from rajinisivaram/KAFKA-5872-sslselectortest-failure",2017-09-12 17:39:47,Rajini Sivaram,Not TDD
90b4b07e6e3b44edfa41eebea83a674cb6f61922,"KAFKA-4468: Correctly calculate the window end timestamp after read from state stores

I have decided to use the following approach to fixing this bug:

1) Since the Window Size in WindowedDeserializer was originally unknown, I have initialized
a field _windowSize_ and created a constructor to allow it to be instantiated

2) The default size for __windowSize__ is _Long.MAX_VALUE_. If that is the case, then the
deserialize method will return an Unlimited Window, or else will return Timed one.

3) Temperature Demo was modified to demonstrate how to use this new constructor, given
that the window size is known.

Author: Richard Yu <richardyu@Richards-Air.attlocal.net>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3745 from ConcurrencyPractitioner/trunk",2017-09-12 16:42:06,Richard Yu,Not TDD
ffd8f18a129fa826d62f527ea2c8eba2cfd644b2,"KAFKA-4501; Fix EasyMock and disable PowerMock tests under Java 9

- EasyMock 3.5 supports Java 9.

- Fixed issues in `testFailedSendRetryLogic` and
`testCreateConnectorAlreadyExists` exposed by new EasyMock
version. The former was passing `anyObject` to
`andReturn`, which doesn't make sense. This was leaving
behind a global `any` matcher, which caused a few issues in
the new version. Fixing this meant that the correlation ids had
to be updated to actually match. The latter was missing a
couple of expectations that the previous version of EasyMock
didn't catch.

- Removed unnecessary PowerMock dependency from 3 tests.

- Disabled remaining PowerMock tests when running with Java 9
until https://github.com/powermock/powermock/issues/783 is
in a release.

- Once we merge this PR, we can enable tests in the Java 9 builds
in Jenkins.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #3845 from ijuma/kafka-4501-easymock-powermock-java-9",2017-09-13 18:18:54,Ismael Juma,Not TDD
3b5d88febb186c4b92cc514fa2338de7bc338f67,"KAFKA-5783; Add KafkaPrincipalBuilder with support for SASL (KIP-189)

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #3795 from hachikuji/KAFKA-5783",2017-09-14 10:16:00,Jason Gustafson,Mixed
2656659e0d7c0e427768ce216df2698acc8c9b11,"MINOR: Update TransactionManager to use LogContext

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3852 from hachikuji/minor-use-log-context-txn-manager",2017-09-14 11:24:25,Jason Gustafson,Mixed
dfd625daa36de2e34e6c596967775394c55bc605,"MINOR: Remove unused SecurityProtocol.TRACE

It adds complexity for no benefit since we don't use
it anywhere.

Also removed a few unused imports, variables and
default parameters.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>

Closes #3856 from ijuma/remove-security-protocol-trace",2017-09-14 13:39:30,Ismael Juma,Not TDD
8a5e86660593eab49c64fdfb5ef090634ae5ae06,"KAFKA-5738; Add cumulative count for rate metrics (KIP-187)

Implementation of https://cwiki.apache.org/confluence/display/KAFKA/KIP-187+-+Add+cumulative+count+metric+for+all+Kafka+rate+metrics

Also made locking in Sensor for `CompoundStat` consistent with simple `Stat`, avoiding locking the whole sensor.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3686 from rajinisivaram/KAFKA-5738",2017-09-15 00:07:17,Rajini Sivaram,Mixed
5d2422258cb975a137a42a4e08f03573c49a387e,"KAFKA-5494; Enable idempotence with max.in.flight.requests.per.connection > 1

Here we introduce client and broker changes to support multiple inflight requests while still guaranteeing idempotence. Two major problems to be solved:

1. Sequence number management on the client when there are request failures. When a batch fails,  future inflight batches will also fail with `OutOfOrderSequenceException`. This must be handled on the client with intelligent sequence reassignment. We must also deal with the fatal failure of some batch: the future batches must get different sequence numbers when the come back.
2. On the broker, when we have multiple inflights, we can get duplicates of multiple old batches. With this patch, we retain the record metadata for 5 older batches.

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3743 from apurvam/KAFKA-5494-increase-max-in-flight-for-idempotent-producer",2017-09-14 16:10:19,Apurva Mehta,Mixed
f6f56a645bb1c5ec6810c024ba517e43bf77056c,"KAFKA-5822; Consistent log formatting of topic partitions

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3778 from hachikuji/KAFKA-5822",2017-09-15 01:51:35,Jason Gustafson,Not TDD
985cc534a4278b64fc37dc37913ab974266efe43,"KAFKA-5908; fix range query in CompositeReadOnlyWindowStore

The `NextIteratorFunction` in `CompositeReadOnlyWindowStore` was incorrectly using the `timeFrom` as the `timeTo`

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3868 from dguy/window-store-range-scan",2017-09-15 11:35:57,Damian Guy,Mixed
8fca432223da521b78e60e0cf8fa881ced19589c,"KAFKA-4764; Wrap SASL tokens in Kafka headers to improve diagnostics (KIP-152)

SASL handshake protocol changes from KIP-152.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #3708 from rajinisivaram/KAFKA-4764-SASL-diagnostics",2017-09-15 17:16:29,Rajini Sivaram,Mixed
f305dd68f6524abc25c4ed88983f0e78b4e6c243,"KAFKA-5754; Refactor Streams to use LogContext

This PR utilizes `org.apache.kafka.common.utils.LogContext` for logging in `KafkaStreams`. hachikuji, ijuma please review this and let me know your thoughts.

Author: umesh chaudhary <umesh9794@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>

Closes #3727 from umesh9794/KAFKA-5754",2017-09-18 09:53:27,umesh chaudhary,Mixed
a339a387e0669226bc1537783b3d4c6ea5b9b4c0,"MINOR: Add metric templates for sender/fetcher rate totals

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: James Cheng <jylcheng@yahoo.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3882 from rajinisivaram/MINOR-KAFKA-5738-metricstemplates",2017-09-18 10:13:28,Rajini Sivaram,Mixed
a3f068e22da6915cbc473be8da0cfbb229817436,"MINOR: Update powermock and enable its tests when running with Java 9

Also:
1. Fix WorkerTest to use the correct `Mock` annotations. `org.easymock.Mock`
is not supported by PowerMock 2.x.
2. Rename `powermock` to `powermockJunit4` in `dependencies.gradle` for
clarity.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #3881 from ijuma/kafka-5884-powermock-java",2017-09-18 10:49:12,Ismael Juma,Not TDD
d83252ebaeeca5bf19584908d95b424beb31b12e,"KAFKA-5654; add materialized count, reduce, aggregate to KGroupedStream

Add overloads of `count`, `reduce`, and `aggregate` that are `Materialized` to `KGroupedStream`.
Refactor common parts between `KGroupedStream` and `WindowedKStream`

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3827 from dguy/kafka-5654",2017-09-18 11:54:14,Damian Guy,Mixed
ed0e692147d81e396bf10f4d9425516d51bd52cc,"KAFKA-5515; Remove date formatting from Segments

Remove date formatting from `Segments` and use the `segementId` instead.
Add tests to make sure can load old segments.
Rename old segment dirs to new formatting at load time.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: tedyu <yuzhihong@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3783 from dguy/kafka-5515",2017-09-18 12:11:56,Damian Guy,Mixed
52d7b6763b7f8ec1973f1bc399d428542e6e962e,"MINOR: Fix replica_verification_tool.py to handle slight change in output format

The string representation of TopicPartition was changed to be
{topic}-{partitition} consistently in the following commit:

f6f56a645bb1c5ec6810c024ba517e43bf77056c

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Damian Guy <damian.guy@gmail.com>

Closes #3890 from ijuma/fix-replica-verification-test",2017-09-18 15:49:44,Ismael Juma,Not TDD
f2b74aa1c36bf2882006c14f7cbd56b493f39d26,"KAFKA-5873; add materialized overloads to StreamsBuilder

Add overloads for `table` and `globalTable` that use `Materialized`

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3837 from dguy/kafka-5873",2017-09-18 15:53:44,Damian Guy,Mixed
ae3eeb3e1c194c60fa62fbc7931566f3d8c87d68,"MINOR: Make the state change log more consistent

Use logIdent to achieve this.

Also fixed an issue where we were logging about replicas going offline with
an empty set of replicas (i.e. no replicas had gone offline so no need to log).

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3869 from ijuma/improve-state-change-log",2017-09-18 09:00:37,Ismael Juma,Not TDD
0cf7708007b01faac5012d939f3c50db274f858d,"MINOR: Move request/response schemas to the corresponding object representation

This refactor achieves the following:

1. Breaks up the increasingly unmanageable `Protocol` class and moves schemas closer to their actual usage.
2. Removes the need for redundant field identifiers maintained separately in `Protocol` and the respective request/response objects.
3. Provides a better mechanism for sharing common fields between different schemas (e.g. topics, partitions, error codes, etc.).
4. Adds convenience helpers to `Struct` for common patterns (such as setting a field only if it exists).

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3813 from hachikuji/protocol-schema-refactor",2017-09-19 05:12:55,Jason Gustafson,Mixed
c8f1471992c98e0104e3a7b2e093adc21b2d2a6f,"KAFKA-5921; add Materialized overloads to windowed kstream

Add `Materialized` overloads to `WindowedKStream`. Deprecate existing methods on `KGroupedStream`

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #3889 from dguy/kafka-5921",2017-09-19 10:56:42,Damian Guy,Mixed
239dad1b9fb6803842067dd588f679ba6ae5efe7,"KAFKA-5358; Consumer perf tool should count rebalance time (KIP-177)

Author: huxihx <huxi_2b@hotmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3188 from huxihx/KAKFA-5358",2017-09-20 09:29:39,huxihx,Mixed
552b1707871fd92656debe33b03381f597be2578,"KAFKA-5657: Connect REST API should include the connector type when describing a connector (KIP-151)

Embed the type of connector in ConnectorInfo

Author: tedyu <yuzhihong@gmail.com>

Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #3812 from tedyu/trunk",2017-09-20 14:01:43,tedyu,Mixed
69d2a177101eb1c29b59b4c64d8c22f6d5e3d281,"KAFKA-5854; Handle SASL authentication failures as non-retriable exceptions in clients

This PR implements the client-side of KIP-152, by modifying `KafkaConsumer`, `KafkaProducer`, and `ConsumerGroupCommand` to throw a non-retriable exception when SASL authentication fails.

This PR is co-authored with rajinisivaram.

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>, tedyu <yuzhihong@gmail.com>

Closes #3832 from vahidhashemian/KAFKA-5854",2017-09-20 22:51:53,Vahid Hashemian,Mixed
94692288bedc353383e014914937a4798a1d4caa,"KAFKA-5793; Tighten up the semantics of the OutOfOrderSequenceException

Description of the solution can be found here: https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Exactly+Once+-+Solving+the+problem+of+spurious+OutOfOrderSequence+errors

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #3865 from apurvam/KAFKA-5793-tighten-up-out-of-order-sequence-v2",2017-09-20 20:31:33,Apurva Mehta,Mixed
5f6393f9b17cce17ded7a00e439599dfa77deb2d,"KAFKA-5856; Add AdminClient.createPartitions() (KIP-195)

The contribution is my original work and I license the work to the project under the project's open source license.

This patch adds AdminClient.createPartitions() and the network protocol is
uses. The broker-side algorithm is as follows:

1. KafkaApis makes some initial checks on the request, then delegates to the
   new AdminManager.createPartitions() method.
2. AdminManager.createPartitions() performs some validation then delegates to
   AdminUtils.addPartitions().

Aside: I felt it was safer to add the extra validation in
AdminManager.createPartitions() than in AdminUtils.addPartitions() since the
latter is used on other code paths which might fail differently with the
introduction of extra checks.

3. AdminUtils.addPartitions() does its own checks and adds the partitions.
4. AdminManager then uses the existing topic purgatory to wait for the
   PartitionInfo available from the metadata cache to become consistent with
   the new total number of partitions.

The messages of exceptions thrown in AdminUtils affecting this new API have
been made consistent with initial capital letter and terminating period.
A few have been reworded for clarity.

Author: Tom Bentley <tbentley@redhat.com>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3870 from tombentley/KAFKA-5856-AdminClient.createPartitions",2017-09-21 05:06:36,Tom Bentley,Mixed
a2da064cbf01558d0af64adc9d6fc9444cd744ec,"KAFKA-5922: Add SessionWindowedKStream

Add `SessionWindowedKStream` and implementation. Deprecate existing `SessionWindow` `aggregate` methods on `KGroupedStream`

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3902 from dguy/kafka-5922",2017-09-21 16:10:17,Damian Guy,Mixed
96ba21e0dfb1a564d5349179d844f020abf1e08b,"KAFKA-5947; Handle authentication failure in admin client, txn producer

1. Raise AuthenticationException for authentication failures in admin client
2. Handle AuthenticationException as a fatal error for transactional producer
3. Add comments to authentication exceptions

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3928 from rajinisivaram/KAFKA-5947-auth-failure",2017-09-21 13:58:43,Rajini Sivaram,Not TDD
a553764c8b1611cafd318022d0fc4a34c861f6ba,"KAFKA-5856; AdminClient.createPartitions() follow-up (KIP-195)

- Remove DelayedCreatePartitions to reduce code duplication
- Avoid unnecessary ZK calls (call it once per request instead
of once per topic, if possible)
- Simplify code
- A few minor clean-ups

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Tom Bentley <tbentley@redhat.com>, Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #3930 from ijuma/kafka-5856-admin-client-creation-partitions",2017-09-21 15:21:09,Ismael Juma,Not TDD
c8c6ab63248639b167350642efdfc4341fa3ce37,"KAFKA-5735; KIP-190: Handle client-ids consistently

Developed with edoardocomar

Author: Mickael Maison <mickael.maison@gmail.com>

Reviewers: Edoardo Comar <ecomar@uk.ibm.com>, Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #3906 from mimaison/KAFKA-5735",2017-09-21 21:16:57,Mickael Maison,Mixed
ea533f0c5e2438f0aef070dbadb023bffb9ce009,"KAFKA-5913; Add hasOffset() and hasTimestamp() methods to RecordMetadata

These methods help users check for cases in which this metadata was not returned by the broker (e.g. in the case of acks=0 or a duplicate error when idempotence is enabled).

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #3878 from apurvam/KAFKA-5913-add-record-metadata-not-available-exception",2017-09-21 14:39:00,Apurva Mehta,Mixed
402aa093db243965d2b6c04118ac7ee6d196fd45,"KAFKA-5937: Improve ProcessorStateManager exception handling

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Ted Yu <yuzhihong@gmail.com>, Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #3913 from mjsax/kafka-5937-exceptions-processor-state-manager",2017-09-22 07:33:50,Matthias J. Sax,Mixed
7c988a3c8bc9429c1f28f9c29dafed185cec1a67,"KAFKA-5330: Use per-task converters in Connect

Instead of sharing the same converter instance within the worker, use a converter per task.

More details:
- https://github.com/confluentinc/schema-registry/issues/514
- https://issues.apache.org/jira/browse/KAFKA-5330

Author: Thibaud Chardonnens <Thibaud.Chardonnens@swisscom.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #3196 from tbcdns/KAFKA-5330",2017-09-21 20:12:08,Thibaud Chardonnens,Mixed
125d8d6f70829b9a0dbeabfef8f6b2df438dc12b,"KAFKA-5956; use serdes from materialized in table and globalTable

The new overloads `StreamBuilder.table(String, Materialized)` and `StreamsBuilder.globalTable(String, Materialized)` need to set the serdes from `Materialized` on the internal `Consumed` instance that is created, otherwise the defaults will be used and may result in serialization errors

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3936 from dguy/table-materialized",2017-09-22 13:45:19,Damian Guy,Mixed
e554dc518eaaa0747899e708160275f95c4e525f,"KAFKA-5915; Support unmapping of mapped/direct buffers in Java 9

As mentioned in MappedByteBuffers' class documentation, its
implementation was inspired by Lucene's MMapDirectory:

https://github.com/apache/lucene-solr/blob/releases/lucene-solr/6.6.1/lucene/core/src/java/org/apache/lucene/store/MMapDirectory.java#L315

Without this change, unmapping fails with the following message:

> java.lang.IllegalAccessError: class kafka.log.AbstractIndex (in unnamed module 0x45103d6b) cannot access class jdk.internal.ref.Cleaner (in module java.base) because module java.base does not export jdk.internal.ref to unnamed module 0x45103d6b

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #3879 from ijuma/kafka-5915-unmap-mapped-buffers-java-9",2017-09-22 19:32:09,Ismael Juma,Mixed
d60f011d77ce80a44b02d43bf0889a50a8797dcd,"KAFKA-5920; Handle SSL handshake failures as authentication exceptions

1. Propagate `SSLException` as `SslAuthenticationException` to enable clients to report these and avoid retries
2. Updates to `SslTransportLayer` to process bytes received even if end-of-stream
3. Some tidy up of authentication handling
4. Report exceptions in SaslClientAuthenticator as AuthenticationExceptions

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3918 from rajinisivaram/KAFKA-5920-SSL-handshake-failure",2017-09-22 20:29:25,Rajini Sivaram,Mixed
8f90fd6530ce2c4f7e2fdfe3541c61d0178289d5,"KAFKA-5959; Fix NPE in Sender.canRetry when idempotence is not enabled

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: tedyu <yuzhihong@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #3947 from apurvam/KAFKA-5959-npe-in-sender",2017-09-22 13:07:59,Apurva Mehta,Mixed
f4a1ca347bd21cacf5906887f56001bce61c4544,"KAFKA-5899: Added Connect metrics for connectors (KIP-196)

This PR is the first of several subtasks for [KAFKA-2376](https://issues.apache.org/jira/browse/KAFKA-2376) to add metrics to Connect worker processes. See that issue and [KIP-196 for details](https://cwiki.apache.org/confluence/display/KAFKA/KIP-196%3A+Add+metrics+to+Kafka+Connect+framework).

This PR adds metrics for each connector using Kafka’s existing `Metrics` framework. This is the first of several changes to add several groups of metrics, this change starts by adding a very simple `ConnectMetrics` object that is owned by each worker and that makes it easy to define multiple groups of metrics, called `ConnectMetricGroup` objects. Each metric group maps to a JMX MBean, and each metric within the group maps to an MBean attribute.

Future PRs will build upon this simple pattern to add metrics for source and sink tasks, workers, and worker rebalances.

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewencp@confluent.io>

Closes #3864 from rhauch/kafka-5899",2017-09-22 13:17:28,Randall Hauch,Mixed
71a65d95a257d98925b5f0f6f2227504cf5043a2,"MINOR: Fix ClassCastException in ConsumerGroupCommand

Offset and partition are not converted from String to
long and int correctly.

Running the command line with --from-file option causes
the following exception:

java.lang.ClassCastException: java.lang.String cannot be
cast to java.lang.Integer

Reason: asInstanceOf used for the conversion.

Also, unit test is using --to-earliest and --from-file
together when executing the test. This is executing
--to-earliest option only and ignoring --from-file
option. Since the preparation part is also using
--to-earliest to create the file, this unit test
passes without testing --from-file option. Fixed
the unit test too.

Author: Erkan Unal <eunal@cisco.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3938 from eu657/eu657-patch-1",2017-09-22 22:34:11,Erkan Unal,Not TDD
271f6b5aec885d2eb348dea4de637ac269d3e1ca,"KAFKA-5862: Remove ZK dependency from Streams reset tool, Part I

Author: Bill Bejeck <bill@confluent.io>
Author: bbejeck <bbejeck@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Ted Yu <yuzhihong@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #3927 from bbejeck/KAFKA-5862_remove_zk_dependency_from_streams_reset_tool",2017-09-23 12:05:16,Bill Bejeck,Not TDD
852297efd99af04df28710b1b5c99530ab20a072,"KAFKA-5960; Fix regression in produce version selection on old brokers

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #3944 from hachikuji/KAFKA-5960",2017-09-26 00:13:02,Jason Gustafson,Mixed
b8be86b80543e41fd3181a8de8f1a3ac0a72e4c5,"KAFKA-5765; Move merge() from StreamsBuilder to KStream

This is the polished version.
1. The old merge() method in StreamsBuilder has been removed,
2. The merge() method in KStreamBuilder was changed so that it would use the single variable argument
rather than several variable arguments in the KStreamImpl implementation
3. The merge() method in KStream has been declared as final and tests have been added to test correctness.

Author: Richard Yu <richardyu@Richards-Air.attlocal.net>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>

Closes #3916 from ConcurrencyPractitioner/trunk",2017-09-26 09:42:53,Richard Yu,Mixed
73cc416664dbc8e1442f70cb3c4cd8f4d365ea50,"KAFKA-5900: Add task metrics common to both sink and source tasks

Added metrics that are common to both sink and source tasks.

Marked as ""**WIP**"" since this PR is built upon #3864, and will need to be rebased once that has been merged into `trunk`. However, I would still appreciate initial reviews since this PR is largely additive.

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #3911 from rhauch/kafka-5900",2017-09-26 22:23:37,Randall Hauch,Mixed
8e0e2a5b238092a3730d22d36046fe078a01c15b,"KAFKA-5597; Improve Metrics docs generation

Instead of having the metrics registry and the
org.apache.kafka.common.metrics.Metrics object be separate things,
have the metrics registry hold a copy of the Metrics object.
That way, all the metricInstance stuff is hidden, and we don't
have to make sure that the metrics registry and the Metrics
object are configured identicailly (with the same tags).

I personally think this looks a little better.

Author: James Cheng <jylcheng@yahoo.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3799 from wushujames/producer_sender_metrics_docs_different",2017-09-27 17:54:37,James Cheng,Mixed
e1543a5a8ecbd9da6e39fb0952b1193450b3c931,"KAFKA-5958; Global stores access state restore listener

Author: Bill Bejeck <bill@confluent.io>

Reviewers: Damian Guy <damian.guy@gmail.com>

Closes #3973 from bbejeck/KAFKA-5958_global_stores_access_state_restore_listener",2017-09-28 10:54:38,Bill Bejeck,Mixed
2703fda52a14eeae70b206b19a47c5acd4a83915,"KAFKA-5960; Follow-up cleanup

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3976 from hachikuji/version-fix-followup",2017-09-28 10:57:53,Jason Gustafson,Mixed
e5f2471c548fc490a42dd0321bcf7fcdd4ddc52d,"KAFKA-5949; User Callback Exceptions need to be handled properly

 - catch user exception in user callback (TimestampExtractor, DeserializationHandler, StateRestoreListener) and wrap with StreamsException

Additional cleanup:
 - rename globalRestoreListener to userRestoreListener
 - remove unnecessary interface -> collapse SourceNodeRecordDeserializer and RecordDeserializer
 - removed unused parameter loggingEnabled from ProcessorContext#register

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>

Closes #3939 from mjsax/kafka-5949-exceptions-user-callbacks",2017-09-28 11:00:31,Matthias J. Sax,Mixed
e846daa89b1cbdf7c08f1b719fcf1ffc3885614f,"KAFKA-5979; Use single AtomicCounter to generate internal names

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>

Closes #3979 from mjsax/kafka-5979-kip-120-regression",2017-09-28 11:07:54,Matthias J. Sax,Mixed
89ba0c1525b8f8a4e36d1e1b486ca660d5c24a7b,"KAFKA-5901: Added Connect metrics specific to source tasks (KIP-196)

Added Connect metrics specific to source tasks, and builds upon #3864 and #3911 that have already been merged into `trunk`.

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: tedyu <yuzhihong@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #3959 from rhauch/kafka-5901",2017-09-28 09:53:19,Randall Hauch,Mixed
021d8a8e9698dce454e0e801092460b98f0a8a4d,"KAFKA-5746; Add new metrics to support health checks (KIP-188)

Adds new metrics to support health checks:
1. Error rates for each request type, per-error code
2. Request size and temporary memory size
3. Message conversion rate and time
4. Successful and failed authentication rates
5. ZooKeeper latency and status
6. Client version

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3705 from rajinisivaram/KAFKA-5746-new-metrics",2017-09-28 21:58:59,Rajini Sivaram,Mixed
a86873be50b3bf1585098a13b2ce710a717c0321,"KAFKA-5957; Prevent second deallocate if response for aborted batch returns

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #3942 from hachikuji/KAFKA-5957",2017-09-29 03:20:36,Jason Gustafson,Mixed
177dd7f210c7783b49f47de1c7028c9830d3d795,"KAFKA-5746; Fix conversion count computed in `downConvert`

It should be the number of records instead of the
number of batches.

A few additional clean-ups:
- Minor renames
- Removed unused variable
- Some test fixes
- Ignore a flaky test

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, tedyu <yuzhihong@gmail.com>

Closes #3989 from ijuma/kafka-5746-health-metrics-follow-up",2017-09-29 09:53:32,Ismael Juma,Not TDD
eaabb6cd0173c4f6854eb5da39194a7e3fc0162c,"KAFKA-4593; Don't throw IllegalStateException and die on task migration

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #3948 from mjsax/kafka-4593-illegal-state-exception-in-restore",2017-09-29 10:00:13,Matthias J. Sax,Mixed
082def05ca5af4f30e05aa28ba83fa299f30337b,"MINOR: always set Serde.Long on count operations

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>

Closes #3943 from dguy/count-materialized",2017-09-29 11:06:34,Damian Guy,Mixed
36556b8041d3647375380e6fd70b8f37ba572ddc,"KAFKA-5932; Avoid call to fetchPrevious in FlushListeners

Author: Bill Bejeck <bill@confluent.io>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>

Closes #3978 from bbejeck/KAFKA-5932_no_fetch_previous_when_no_old_values_returned",2017-09-29 11:11:12,Bill Bejeck,Mixed
3107a6c5c8d1358b8e705c5d5a16b7441d2225a6,"KAFKA-5986; Streams State Restoration never completes when logging is disabled

When logging is disabled and there are state stores the task never transitions from restoring to running. This is because we only ever check if the task has state stores and return false on initialization if it does. The check should be if we have changelog partitions, i.e., we need to restore.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, tedyu <yuzhihong@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3983 from dguy/restore-test",2017-09-29 15:07:41,Damian Guy,Mixed
0ef960304b6b81c1b725bf8e036f20d295045c4a,"KAFKA-5968; Create/remove request metrics during broker startup/shutdown

Replaces the static `RequestMetrics` object with a class so that metrics
are created and removed during broker startup and shutdown to avoid metrics
tests being affected by metrics left behind by previous tests.

Also reinstates `kafka.api.MetricsTest` which was failing frequently earlier
due to tests removing the static request metrics.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3991 from rajinisivaram/KAFKA-5968",2017-09-29 15:11:29,Rajini Sivaram,Mixed
f9865d52e81bbdddb7889d6c3cc7be537e610826,"KAFKA-5225; StreamsResetter doesn't allow custom Consumer properties

Author: Matthias J. Sax <matthias@confluent.io>
Author: Bharat Viswanadham <bharatv@us.ibm.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Damian Guy <damian.guy@gmail.com>

Closes #3970 from mjsax/kafka-5225-streams-resetter-properties",2017-10-02 13:47:45,Matthias J. Sax,Not TDD
e110e1c1ea6a365bcde07a1ee3fe466a6fde1541,"KAFKA-5758; Don't fail fetch request if replica is no longer a follower for a partition

We log a warning instead, which is what we also do if the partition
hasn't been created yet.

A few other improvements:
- Return updated high watermark if fetch is returned immediately.
This seems to be more intuitive and is consistent with the case
where the fetch request is served from the purgatory.
- Centralise offline partition handling
- Remove unnecessary `tryCompleteDelayedProduce` that would
already have been done by the called method
- A few other minor clean-ups

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #3954 from ijuma/kafka-5758-dont-fail-fetch-request-if-replica-is-not-follower",2017-10-02 22:35:55,Ismael Juma,Mixed
a1a5e93beb16e38cf997554a7819a0b92c6661e5,"KAFKA-5995; Rename AlterReplicaDir to AlterReplicaDirs

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #3993 from lindong28/KAFKA-5995",2017-10-02 22:24:09,Dong Lin,Mixed
42b356500b7188eb2507f9b48399d5491a7eff16,"KAFKA-6005; Reject JoinGroup request from first member with empty protocol type/protocol list

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3957 from omkreddy/JOIN-GROUP-EMPTY-PROTOCOL",2017-10-03 08:37:30,Manikumar Reddy,Mixed
05357b7030c784a6548453f533d3c00e19548ba2,"KAFKA-5902: Added sink task metrics (KIP-196)

Added Connect metrics specific to source tasks, and builds upon #3864 and #3911 that have already been merged into `trunk`, and #3959 that has yet to be merged.

I'll rebase this PR when the latter is merged.

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #3975 from rhauch/kafka-5902",2017-10-03 11:52:14,Randall Hauch,Mixed
cbef33f3d0bc686e1258352cd5e13143b3f09d78,"KAFKA-5864; ReplicaFetcherThread should not die due to replica in offline log directory

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3820 from lindong28/KAFKA-5864",2017-10-03 17:11:21,Dong Lin,Mixed
28aaba2818053ffc36b1ae65b7714638ef41b91e,"MINOR: Java 9 version handling improvements

- Upgrade Gradle to 4.2.1, which handles Azul Zulu 9's version
correctly.
- Add tests to our Java version handling code
- Refactor the code to make it possible to add tests
- Rename `isIBMJdk` method to use consistent naming
convention.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #4007 from ijuma/java-9-version-handling-improvements",2017-10-04 08:06:05,Ismael Juma,Mixed
198302feecf17cd1eff38e6d93e807d7b04922f2,"KAFKA-4416; Add a `--group` option to console consumer

This simplifies running a console consumer as part of a custom group. Note that group id can be provided via only one of the three possible means: directly using `--group ` option (as part of this PR), as property via `--consumer-property` option,  or inside a config file via `--consumer.config` option.

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Apurva Mehta <apurva@confluent.io>, Jason Gustafson <jason@confluent.io>

Closes #2150 from vahidhashemian/KAFKA-4416",2017-10-04 08:50:56,Vahid Hashemian,Mixed
5383f9bed0ec4fda86b74a94d9d1ba595a2a1c8a,"MINOR: Use SecurityProtocol in AuthenticationContext

Since we removed the unused `TRACE` option from `SecurityProtocol`, it now seems safer to expose it from `AuthenticationContext`. Additionally this patch exposes javadocs under security.auth and relocates the `Login` and `AuthCallbackHandler` to a non-public package.

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3863 from hachikuji/use-security-protocol-in-auth-context",2017-10-04 09:20:21,Jason Gustafson,Mixed
5afeddaa99c48ac827d1cade7812deb83b1f80bd,"KAFKA-5967; Ineffective check of negative value in CompositeReadOnlyKeyValueStore#approximateNumEntries()

package name: org.apache.kafka.streams.state.internals
Minor change to approximateNumEntries() method in CompositeReadOnlyKeyValueStore class.

long total = 0;
   for (ReadOnlyKeyValueStore<K, V> store : stores) {
          total += store.approximateNumEntries();
   }

return total < 0 ? Long.MAX_VALUE : total;

The check for negative value seems to account for wrapping. However, wrapping can happen within the for loop. So the check should be performed inside the loop.

Author: siva santhalingam <ssanthalingam@netskope.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>

Closes #3988 from shivsantham/trunk",2017-10-04 10:11:11,siva santhalingam,Mixed
9949e1ed1be8293ba60dcab10345fbcce8d61e36,"KAFKA-6004; Allow authentication providers to override error message

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #4015 from rajinisivaram/KAFKA-6004-auth-exception",2017-10-04 13:44:46,Rajini Sivaram,Mixed
2a1b39ef1b65a4de4f3813bc749458f9fd6a1e38,"MINOR: Simplify log cleaner and fix compiler warnings

- Simplify LogCleaner.cleanSegments and add comment regarding thread
unsafe usage of `LogSegment.append`. This was a result of investigating
KAFKA-4972.
- Fix compiler warnings (in some cases use the fully qualified name as a
workaround for deprecation warnings in import statements).

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #4016 from ijuma/simplify-log-cleaner-and-fix-warnings",2017-10-04 18:55:46,Ismael Juma,Mixed
c6e5a32d0464622ced4b7887923ca37c717b9e74,"KAFKA-5856; AdminClient.createPartitions() follow up

- Improve tests and javadoc (including expected exceptions)
- Return correct authorization error if no describe topic
permission

Author: Tom Bentley <tbentley@redhat.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3937 from tombentley/KAFKA-5856-AdminClient.createPartitions-follow-up",2017-10-04 18:57:31,Tom Bentley,Not TDD
11afff09908035166febf9b75c410112693ff98c,"KAFKA-5990: Enable generation of metrics docs for Connect (KIP-196)

A new mechanism was added recently to the Metrics framework to make it easier to generate the documentation. It uses a registry with a MetricsNameTemplate for each metric, and then those templates are used when creating the actual metrics. The metrics framework provides utilities that can generate the HTML documentation from the registry of templates.

This change moves the recently-added Connect metrics over to use these templates and to then generate the metric documentation for Connect.

This PR is based upon #3975 and can be rebased once that has been merged.

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #3987 from rhauch/kafka-5990",2017-10-04 11:05:50,Randall Hauch,Mixed
f8621b4174ddb14f9e8377da34e81e1b7ddd205f,"KAFKA-5970; Use ReentrantLock for delayed operation lock to avoid blocking

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #3956 from rajinisivaram/KAFKA-5970-delayedproduce-deadlock",2017-10-04 11:35:37,Rajini Sivaram,Mixed
713a67fddaec3fa9cd7cce53dd6fef5ab6e0cdab,"MINOR: add suppress warnings annotations in Streams API

 - fixes examples with regard to new API
 - fixes `Topology#addGlobalStore` parameters

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>

Closes #4003 from mjsax/minor-deprecated",2017-10-04 14:42:07,Matthias J. Sax,Not TDD
20d9adb173a0cde010a2502da7415ecda9bcaa80,"KAFKA-5767; Kafka server should halt if IBP < 1.0.0 and there is log directory failure

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #3718 from lindong28/KAFKA-5767",2017-10-04 17:12:53,Dong Lin,Not TDD
6ea4fffdd287a0c6a02c1b6dc1006b1a7b614405,"KAFKA-6003; Accept appends on replicas unconditionally when local producer state doesn't exist

Without this patch, if the replica's log was somehow truncated before
the leader's, it is possible for the replica fetcher thread to
continuously throw an OutOfOrderSequenceException because the
incoming sequence would be non-zero and there is no local state.

This patch changes the behavior so that the replica state is updated to
the leader's state if there was no local state for the producer at the
time of the append.

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #4004 from apurvam/KAFKA-6003-handle-unknown-producer-on-replica",2017-10-04 22:27:03,Apurva Mehta,Mixed
e61002e2ab70454304e12f2834cbbcb4bed002d7,"KAFKA-5989; resume consumption of tasks that have state stores but no changelogging

Stores where logging is disabled where never consumed as the partitions were paused, but never resumed.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: tedyu <yuzhihong@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #4002 from dguy/restore",2017-10-05 08:23:15,Damian Guy,Mixed
e40b3a2e74133de6d60599beefb65407ca4cc7dd,"KAFKA-6012; Close request metrics only after closing request handlers

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #4024 from rajinisivaram/KAFKA-6012-error-metric",2017-10-05 12:25:34,Rajini Sivaram,Not TDD
a47bfbcae050659d32f777ed2f4b26dda5fbdbbd,"KAFKA-5903: Added Connect metrics to the worker and distributed herder (KIP-196)

Added metrics to the Connect worker and rebalancing metrics to the distributed herder.

This is built on top of #3987, and I can rebase this PR once that is merged.

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #4011 from rhauch/kafka-5903",2017-10-05 11:23:11,Randall Hauch,Mixed
196bcfca0c56420793f85514d1602bde564b0651,"KAFKA-5576: RocksDB upgrade to 5.8, plus one bug fix on Bytes.wrap

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>

Closes #3819 from guozhangwang/KMinor-rocksDB-573",2017-10-05 17:02:53,Guozhang Wang,Not TDD
10cd98cc894b88c5d1e24fc54c66361ad9914df2,"KAFKA-5547; Return TOPIC_AUTHORIZATION_FAILED error if no describe access for topics

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #3924 from omkreddy/KAFKA-5547-TOPIC-AUTHRO",2017-10-06 12:51:30,Manikumar Reddy,Not TDD
105ab47ed90c8a0e83c159c97a8f2294c5582657,"KAFKA-6015; Fix NPE in RecordAccumulator after ProducerId reset

It is possible for batches with sequence numbers to be in the `deque` while at the same time the in flight batches in the `TransactionManager` are removed due to a producerId reset.

In this case, when the batches in the `deque` are drained, we will get a `NullPointerException` in the background thread due to this line:

```java
if (first.hasSequence() && first.baseSequence() != transactionManager.nextBatchBySequence(first.topicPartition).baseSequence())
```

Particularly, `transactionManager.nextBatchBySequence` will return null, because there no inflight batches being tracked.

In this patch, we simply allow the batches in the `deque` to be drained if there are no in flight batches being tracked in the TransactionManager. If they succeed, well and good. If the responses come back with an error, the batces will be ultimately failed in the producer with an `OutOfOrderSequenceException` when the response comes back.

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #4022 from apurvam/KAFKA-6015-npe-in-record-accumulator",2017-10-06 15:01:29,Apurva Mehta,Mixed
23a014052d39521a3af471b3f95809c2164820f7,"KAFKA-5651; Follow-up: add with method to Materialized

Add a `with(Serde keySerde, Serde valSerde)` to `Materialized` for cases where people don't care about the state store name.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Matthias J. Sax <matthias@confluent.io>

Closes #4009 from dguy/materialized",2017-10-06 15:38:23,Damian Guy,Mixed
91517e8fbd7767ba6d7f43b517f5a26b6f870585,"KAFKA-5829; Only delete producer snapshots before the recovery point

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #4023 from ijuma/kafka-5829-avoid-reading-older-segments-on-hard-shutdown",2017-10-06 16:45:45,Ismael Juma,Mixed
51063441d3ed4dec8a96794f085028b4b8feb20c,"KAFKA-5362; Follow up to Streams EOS system test

 - improve tests to get rid of calls to `sleep` in Python
 - fixed some flaky test conditions
 - improve debugging

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3542 from mjsax/failing-eos-system-tests",2017-10-06 17:48:34,Matthias J. Sax,Not TDD
6d6080f13633508c57e48cbc12788ce643af4953,"KAFKA-5565: Add a broker metric specifying the number of consumer group rebalances in progress

…up rebalances in progress

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #3506 from cmccabe/KAFKA-5565",2017-10-09 09:28:42,Colin P. Mccabe,Mixed
b411f57c1ce82d66ec2c837349a54357b322e803,"KAFKA-6026; Fix for indefinite wait in KafkaFutureImpl

Author: bartdevylder <bartdevylder@gmail.com>
Author: Bart De Vylder <bartdevylder@gmail.com>

Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #4044 from bartdevylder/KAFKA-6026",2017-10-09 17:57:13,bartdevylder,Mixed
29c46ddb91fac8c0fb3f35c1511e2afdcf67fd2e,"KAFKA-6027; Access to log should throw KafkaStorageException after the log has been marked offline

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #4045 from lindong28/KAFKA-6027",2017-10-10 08:29:17,Dong Lin,Mixed
90b5ce3f04626ee24aebd1d06588489180a4bb05,"KAFKA-6016; Make the reassign partitions system test use the idempotent producer

With these changes, we are ensuring that the partitions being reassigned are from non-zero offsets. We also ensure that every message in the log has producerId and sequence number.

This means that it successfully reproduces https://issues.apache.org/jira/browse/KAFKA-6003.

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #4029 from apurvam/KAFKA-6016-add-idempotent-producer-to-reassign-partitions",2017-10-10 10:32:17,Apurva Mehta,Not TDD
7d6ca52a2751908c7fc6b752d70dfaaaaa9bbe8c,"MINOR: Push JMX metric name mangling into the JmxReporter (KIP-190 follow up)

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #3980 from ewencp/dont-mangle-names",2017-10-11 17:32:40,Ewen Cheslack-Postava,Mixed
62682d07885fe8b15d3e4874d58f9e5174c96edf,"MINOR: Don't register signal handlers if running on Windows

The following happens on Windows for `HUP`:

[2017-10-11 21:45:11,642] FATAL  (kafka.Kafka$)
java.lang.IllegalArgumentException: Unknown signal: HUP
        at sun.misc.Signal.<init>(Unknown Source)
        at kafka.Kafka$.registerHandler$1(Kafka.scala:67)
        at kafka.Kafka$.registerLoggingSignalHandler(Kafka.scala:73)
        at kafka.Kafka$.main(Kafka.scala:82)
        at kafka.Kafka.main(Kafka.scala)

I thought it was safer not to register them at all since the additional
logging is a nice to have and we haven't tested it on Windows.

Also changed map to be concurrent and removed stray
printStackTrace in test.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Damian Guy <damian.guy@gmail.com>

Closes #4066 from ijuma/dont-register-signal-handler-windows",2017-10-12 15:37:02,Ismael Juma,Not TDD
53c23bb5e65c147d7b2cae0a7fd9b3ba46c8fce5,"MINOR: improve Store parameter checks

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>

Closes #4063 from mjsax/minor-improve-store-parameter-checks",2017-10-12 15:55:43,Matthias J. Sax,Mixed
9806c1b176a8a07016ad18e0a6843cc486e52cc6,"MINOR: add unit test for StateStoreSerdes

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #4064 from mjsax/minor-add-state-serdes-test",2017-10-12 22:52:54,Matthias J. Sax,Mixed
ef4914520019e941827dac8eda6000a82cb74cc5,"MINOR: a few web doc and javadoc fixes

1. Added missing Javadocs in public interfaces.
2. Added missing upgrade web docs.
3. Minor improvements on exception messages.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Antony Stubbs <antony.stubbs@gmail.com>

Closes #4071 from guozhangwang/KMinor-javadoc-gaps",2017-10-16 16:50:59,Guozhang Wang,Mixed
6c416aceeb172dc6b0103855f3c1ecbfc9f4d411,"MINOR: add equals to SessionWindows

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax<matthias@confluent.io>, Bill Bejeck <bill@confluent.io>

Closes #4074 from dguy/minor-session-window-equals",2017-10-16 18:01:32,Damian Guy,Mixed
5cc162f30eca28f699a622671669fefba56fb447,"KAFKA-5163; Support replicas movement between log directories (KIP-113)

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Tom Bentley <tbentley@redhat.com>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #3874 from lindong28/KAFKA-5163",2017-10-17 08:35:18,Dong Lin,Mixed
68f324f4bf0003d5dcfd79c5ab7f9c53bd0c1522,"KAFKA-6023 ThreadCache#sizeBytes() should check overflow

    long sizeBytes() {
        long sizeInBytes = 0;
        for (final NamedCache namedCache : caches.values()) {
            sizeInBytes += namedCache.sizeInBytes();
        }
        return sizeInBytes;
    }
The summation w.r.t. sizeInBytes may overflow.
Check similar to what is done in size() should be performed.

Author: siva santhalingam <siva.santhalingam@gmail.com>

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>

Closes #4041 from shivsantham/kafka-6023",2017-10-18 09:44:39,siva santhalingam,Mixed
b71ee043f8959ee0d4699071ba8fc1e2c5675842,"KAFKA-5642; Use async ZookeeperClient in Controller

Kafka today uses ZkClient, a wrapper client around the raw Zookeeper client. This library only exposes synchronous apis to the user. Synchronous apis mean we must wait an entire round trip before doing the next operation.

This becomes problematic with partition-heavy clusters, as we find the controller spending a significant amount of time just sending many sequential reads and writes to zookeeper at the per-partition granularity. This especially becomes an issue during:
- controller failover, where the newly elected controller effectively reads all zookeeper state.
- broker failures and controlled shutdown. The controller tries to elect a new leader for partitions previously led by the broker. The controller also removes the broker from isr on partitions for which the broker was a follower. These all incur partition-granular reads and writes to zookeeper.

As a first step in addressing these issues, we built a low-level wrapper client called ZookeeperClient in KAFKA-5501 that encourages pipelined, asynchronous apis.

This patch converts the controller to use the async ZookeeperClient to improve controller failover, broker failure handling, and controlled shutdown times.

Some notable changes made in this patch:
- All ControllerEvents now defer access to zookeeper at processing time instead of enqueue time as was intended with the single-threaded event queue model patch from KAFKA-5028. This results in a fresh view of the zookeeper state by the time we process the event. This reverts the hacks from KAFKA-5502 and KAFKA-5879.
- We refactored PartitionStateMachine and ReplicaStateMachine to process multiple partitions and replicas in batch rather than one-at-a-time so that we can send a batch of requests over to ZookeeperClient to pipeline.
- We've decouple ZookeeperClient handler registration from watcher registration. Previously, these two were coupled, which meant handler registrations actually sent out a request to the zookeeper ensemble to do the actual watcher registration. In KafkaController.onControllerFailover, we register partition modification handlers (thereby registering watchers) and additionally lookup the partition assignments for every topic in the cluster. We can shave a bit of time off failover if we merge these two operations. We can do this by decoupling ZookeeperClient handler registration from watcher registration. This means ZookeeperClient's registration apis have been changed so that they are purely in-memory operations, and they only take effect when the client sends ExistsRequest, GetDataRequest, or GetChildrenRequest.
- We've simplified the logic for updating LeaderAndIsr such that if we get a BADVERSION error code, the controller will now just retry in the next round by reading the new state and trying the update again. This simplifies logic when updating the partition leader epoch, removing replicas from isr, and electing leaders for partitions.
- We've implemented KAFKA-5083: always leave the last surviving member of the ISR in ZK. This means that if people re-disabled unclean leader election, we can still try to elect the leader from the last in-sync replica.
- ZookeeperClient's handlers have been changed so that their methods default to no-ops for convenience.
- All znode paths and definitions for znode encoding and decoding have been consolidated as static methods in ZkData.scala.
- The partition leader election algorithms have been refactored as pure functions so that they can be easily unit tested.
- PartitionStateMachine and ReplicaStateMachine now have unit tests.

Author: Onur Karaman <okaraman@linkedin.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #3765 from onurkaraman/KAFKA-5642",2017-10-18 09:14:59,Onur Karaman,Mixed
5c1a85caa074267fd84a2fed3662cbe1af93738d,"KAFKA-6051; Close the ReplicaFetcherBlockingSend earlier on shutdown

Rearranged the testAddPartitionDuringDeleteTopic() test to keep the
likelyhood of the race condition.

Author: Maytee Chinavanichkit <maytee.chinavanichkit@linecorp.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #4056 from mayt/KAFKA-6051",2017-10-18 09:59:13,Maytee Chinavanichkit,Not TDD
6cb649b56b1194f4f1cf080d4596244119c3ce78,"MINOR: Remove dead code

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #4087 from ijuma/remove-dead-code",2017-10-18 22:15:22,Ismael Juma,Not TDD
249e398bf84cdd475af6529e163e78486b43c570,"KAFKA-6069: Properly tag KafkaStreams metrics with the client id.

Author: Tommy Becker <tobecker@tivo.com>

Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>

Closes #4081 from twbecker/KAFKA-6069",2017-10-19 15:40:26,Tommy Becker,Mixed
5ec6765bdbe136951d737f30b5da62b07cc5cc68,"KAFKA-6087: Scanning plugin.path needs to support relative symlinks.

Author: Konstantine Karantasis <konstantine@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #4092 from kkonstantine/KAFKA-6087-Scanning-plugin.path-needs-to-support-relative-symlinks",2017-10-19 14:24:57,Konstantine Karantasis,Mixed
9be71f7bdcd147aee7a360a4ccf400acb858a056,"MINOR: Use ObjectName.quote instead of URL-encoding for JMX metric tags

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #4099 from rajinisivaram/1.0

(cherry picked from commit 51bb83d0dce8110b941891eddedba1fe3abdf658)
Signed-off-by: Ewen Cheslack-Postava <me@ewencp.org>",2017-10-19 19:37:52,Rajini Sivaram,Mixed
efefb452df0d60ae427c708cc7da312217bbe647,"KAFKA-6042: Avoid deadlock between two groups with delayed operations

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #4103 from rajinisivaram/KAFKA-6042-group-deadlock

(cherry picked from commit 5ee157126d595b913761cf1887963460bbe12855)
Signed-off-by: Guozhang Wang <wangguoz@gmail.com>",2017-10-21 20:18:20,Rajini Sivaram,Mixed
b1cd6c530119f5d97a1801b8983166248573481a,"MINOR: Controller and async ZookeeperClient improvements

* Fix issue in `retryRequestsUntilConnected` where the same response
could appear multiple times (implies that we are lacking test coverage)
* Introduce type member in AsyncRequest for the AsyncResponse
type and refactor the code to eliminate most downcasts
* Remove a number of unnecessary collection copies in
`retryRequestsUntilConnected`
* Move ControllerContext to its own file
* Rename getACL/setACL to getAcl/setAcl to match Kafka naming
convention
* Replace tuple of 3 elements with case class in one place (we
should do this in other places too)
* Extract `send` and `shouldWatch` from
`ZooKeeperClient.handleRequests`
* Use pattern matching instead of if/else chains in a few places (we
should do it in more places)
* A couple of renames to avoid overloads and hence benefit from
better type inference
* Use Option and default arguments instead of passing null in
some places
* `Expired` is no longer a case class since it has no parameters,
but it has state
* Various minor clean-ups

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>, Onur Karaman <okaraman@linkedin.com>

Closes #4088 from ijuma/async-zkclient-cleanups",2017-10-22 08:44:08,Ismael Juma,Mixed
277fc927c0d6c2699b64a5a54461fb96a50f58ae,"KAFKA-6101; Reconnecting to broker does not exponentially backoff

Author: tedyu <yuzhihong@gmail.com>
Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Soenke Liebau <soenke.liebau@opencore.com>, Ismael Juma <ismael@juma.me.uk>

Closes #4118 from tedyu/trunk",2017-10-23 15:52:30,tedyu,Not TDD
d3f24798f92a6e4d6038d28b63daf3ac9d14fcbf,"KAFKA-5140: Fix reset integration test

A couple of root causes of this flaky test is fixed:

1. The MockTime was incorrectly used across multiple test methods within the class, as a class rule. Instead we set it on each test case; also remove the scala MockTime dependency.

2. List topics may not contain the deleted topics while their ZK paths are yet to be deleted; so the delete-check-recreate pattern may fail to successfully recreate the topic at all. Change the checking to read from zk path directly instead.

Another minor fix is to remove the misleading wait condition error message as the accumData is always empty.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>

Closes #4095 from guozhangwang/KMinor-reset-integration-test",2017-10-23 12:35:31,Guozhang Wang,Not TDD
b281015c150cb95c4205ff6a8d8945b86fc94d4b,"HOTFIX: Poll with zero milliseconds during restoration phase

1. After the poll call, re-check if the state has been changed or not; if yes, initialize the tasks again.
2. Minor log4j improvements.

Author: Guozhang Wang <wangguoz@gmail.com>
Author: Damian Guy <damian.guy@gmail.com>
Author: Jason Gustafson <jason@confluent.io>
Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Ted Yu <yuzhihong@gmail.com>

Closes #4096 from guozhangwang/KHotfix-restore-only",2017-10-23 16:12:54,Guozhang Wang,Not TDD
ab6f848ba6cafaed3d75b54005c954733f0d1735,"MINOR: Rename and change package of async ZooKeeper classes

- kafka.controller.ZookeeperClient -> kafka.zookeeper.ZooKeeperClient
- kafka.controller.ControllerZkUtils -> kafka.zk.KafkaZkClient
- kafka.controller.ZkData -> kafka.zk.ZkData
- Renamed various fields to match new names and for consistency
- A few clean-ups in ZkData
- Document intent

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Onur Karaman <okaraman@linkedin.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Jun Rao <junrao@gmail.com>

Closes #4112 from ijuma/rename-zookeeper-client-and-move-to-zookeper-package",2017-10-25 21:11:16,Ismael Juma,Mixed
070ec0fc586958f260f71558171abfd0d447290d,"MINOR: Revert EmbeddedZooKeeper rename

Even though this class is internal, it's widely
used by other projects and it's better to avoid
breaking them until we have a publicly supported
test library.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #4138 from ijuma/revert-embedded-zookeeper-rename",2017-10-26 14:23:00,Ismael Juma,Not TDD
69e8463c06b51299f16b30274da1026febebaecc,"KAFKA-6131; Use atomic putIfAbsent to create txn marker queues

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #4140 from rajinisivaram/KAFKA-6131-txn-concurrentmap",2017-10-27 02:56:19,Rajini Sivaram,Mixed
501a5e262702bcc043724cb9e1f536e16a66399e,"KAFKA-6119: Bump epoch when expiring transactions in the TransactionCoordinator

A description of the problem is in the JIRA. I have added an integration test which reproduces the original scenario, and also added unit test cases.

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>, Ted Yu <yuzhihong@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #4137 from apurvam/KAFKA-6119-bump-epoch-when-expiring-transactions",2017-10-26 23:26:33,Apurva Mehta,Mixed
f4e9c84c52fbb7ec6a4ca50c9ac35cacbd0df082,"MINOR: Remove TLS renegotiation code

This has been disabled since the start and since
it's removed in TLS 1.3, there are no plans to
ever support it.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #4034 from ijuma/remove-tls-renegotiation-support",2017-10-27 16:40:39,Ismael Juma,Mixed
9504af72ff915f5e82833fd96b57dc00e5825925,"KAFKA-6073; Use ZookeeperClient in KafkaApis

I kept zkUtils for the call to AdminUtils.createTopic(). AdminUtils can be done in another PR.

Is there a reason why we use TopicAndPartition instead of TopicPartition in KafkaControllerZkUtils ?

Author: Mickael Maison <mickael.maison@gmail.com>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #4111 from mimaison/KAFKA-6073",2017-10-30 09:46:11,Mickael Maison,Mixed
8e4b3dca7b1bcef0e4875fea4fa79377998616c3,"KAFKA-2903; FileRecords.read doesn't handle size > sizeInBytes when start is not zero

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #4158 from ijuma/kafka-2903-file-records-read-slice-size-greater",2017-10-30 11:06:11,Ismael Juma,Mixed
7fe88e8bd9acedcb74a4b3e61440f61481b60711,"KAFKA-5212; Consumer ListOffsets request can starve group heartbeats

Author: Richard Yu <richardyu@Richards-Air.attlocal.net>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #4110 from ConcurrencyPractitioner/trunk",2017-10-30 11:31:36,Richard Yu,Mixed
c7ab3efcbe5d34c28e19a5a6a59962c2abfd2235,"MINOR: Code cleanup and JavaDoc improvements for clients and Streams

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Bill Bejeck <bill@confluent.io>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #4128 from mjsax/minor-cleanup

minor fix",2017-10-30 13:13:19,Matthias J. Sax,Mixed
71fe23b445e242ca0f03f06aa8dad96e610db00b,"MINOR: Fix inconsistency in StopReplica/LeaderAndIsr error counts

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #4147 from hachikuji/fix-error-inconsistencies",2017-10-31 09:43:18,Jason Gustafson,Mixed
3c9e30a2f71c83b7efd45a65ffb5df5a80f48d19,"MINOR: Tighten up locking when aborting expired transactions

This is a followup to #4137

Author: Apurva Mehta <apurva@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>

Closes #4146 from apurvam/MINOR-followups-to-bump-epoch-on-expire-patch",2017-10-31 09:57:05,Apurva Mehta,Not TDD
f88fdbd3115cdb0f1bd26817513f3d33359512b1,"KAFKA-6072; User ZookeeperClient in GroupCoordinator and TransactionCoordinator

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Ted Yu <yuzhihong@gmail.com>, Jun Rao <junrao@gmail.com>

Closes #4126 from omkreddy/KAFKA-6072-ZK-IN-GRoupCoordinator",2017-10-31 18:06:51,Manikumar Reddy,Mixed
e4208b1d5fa1c28ac7e64e2cb039404a14084dc0,"MINOR: update producer client request timeout in system test

Author: Bill Bejeck <bill@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #4168 from bbejeck/MINOR_update_streams_produer_timeout_in_system_test",2017-11-02 17:53:15,Bill Bejeck,Not TDD
4fac83ba1f80353e9544b15b95b8da9dc557041d,"KAFKA-6060; Add workload generation capabilities to Trogdor

Previously, Trogdor only handled ""Faults.""  Now, Trogdor can handle
""Tasks"" which may be either faults, or workloads to execute in the
background.

The Agent and Coordinator have been refactored from a
mutexes-and-condition-variables paradigm into a message passing
paradigm.  No locks are necessary, because only one thread can access
the task state or worker state.  This makes them a lot easier to reason
about.

The MockTime class can now handle mocking deferred message passing
(adding a message to an ExecutorService with a delay).  I added a
MockTimeTest.

MiniTrogdorCluster now starts up Agent and Coordinator classes in
paralle in order to minimize junit test time.

RPC messages now inherit from a common Message.java class.  This class
handles implementing serialization, equals, hashCode, etc.

Remove FaultSet, since it is no longer necessary.

Previously, if CoordinatorClient or AgentClient hit a networking
problem, they would throw an exception.  They now retry several times
before giving up.  Additionally, the REST RPCs to the Coordinator and
Agent have been changed to be idempotent.  If a response is lost, and
the request is resent, no harm will be done.

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #4073 from cmccabe/KAFKA-6060",2017-11-03 09:37:29,Colin P. Mccabe,Mixed
86062e9a78dccad74e012f11755025512ad5cf63,"KAFKA-6157; Fix repeated words words in JavaDoc and comments.

Author: Adem Efe Gencer <agencer@linkedin.com>

Reviewers: Jiangjie Qin <becket.qin@gmail.com>

Closes #4170 from efeg/bug/typoFix",2017-11-05 18:00:43,Adem Efe Gencer,Not TDD
7672e9ec3def7af6797bc0ecf254ac694efdfad5,"KAFKA-6156; Metric tag values with colons must be sanitized

Windows directory paths often contain colons which are not allowed in
yammer metrics. Metric tag values with special characters must be
quoted.

Author: huxihx <huxi_2b@hotmail.com>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #4173 from huxihx/KAFKA-6156",2017-11-06 15:59:23,huxihx,Mixed
d637ad0dafb727bb73c63f1b187d9f83abcd4ec1,"KAFKA-6115: TaskManager should be type aware

 - remove type specific methods from Task interface
 - add generics to preserve task type
 - add sub classes for different task types

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #4129 from mjsax/kafka-6115-taskManager-should-be-type-aware",2017-11-06 10:26:52,Matthias J. Sax,Mixed
2b5a21395cf8ce6e3e29a9a778bc20f727ec35fd,"KAFKA-6120: RecordCollector should not retry sending

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #4148 from mjsax/kafka-6120-recordCollector",2017-11-06 10:50:57,Matthias J. Sax,Mixed
6f96d7f1735c53b97ebac43168ded64007277beb,"MINOR: PartitionReassignmentHandler should only generate event when znode is created

We only need to generate the event when the znode is created or deleted.
In the former case, we start the reassignment while in the latter we
re-register the watcher (necessary for the Controller to detect future
reassignments).

During Controller failover, we restart the reassignment without generating
an event so it's not affected by this change.

Also use the Controller cache (`ControllerContext.partitionsBeingReassigned`)
in `removePartitionFromReassignedPartitions` instead of reloading the
data from ZooKeeper.

Overall, we would previously load the reassignment data from ZooKeeper twice
per completed partition whereas now as don't do it at all. As an example,
say there were 30k partitions being reassigned, these changes save the
allocation of 900 million `TopicAndPartition` and `Seq[Int]` (replicas)
instances (could easily amount to 20-40 GB depending on the topic name
length). This matters most in cases where the partitions being reassigned
don't have much data allowing the reassignment to complete reasonably
fast for many of the partitions.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>, Onur Karaman <okaraman@linkedin.com>

Closes #4143 from ijuma/partition-reassignment-ignore-handle-deletion-and-data-change",2017-11-06 21:37:55,Ismael Juma,Mixed
58138126ce93efc48291fe444f554eabdf4a5609,"KAFKA-5894; add the notion of max inflight requests to async ZooKeeperClient

ZooKeeperClient is a zookeeper client that encourages pipelined requests to zookeeper. We want to add the notion of max inflight requests to the client for several reasons:
1. to bound memory overhead associated with async requests on the client.
2. to not overwhelm the zookeeper ensemble with a burst of requests.

Author: Onur Karaman <okaraman@linkedin.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Ted Yu <yuzhihong@gmail.com>, Jun Rao <junrao@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #3860 from onurkaraman/KAFKA-5894",2017-11-06 16:46:31,Onur Karaman,Mixed
3735a6ca8b6432db2de4a0bd07df9301459bbf0b,"MINOR: Eliminate unnecessary Topic(And)Partition allocations in Controller

- Eliminated all the unnecessary allocations of `TopicPartition` and
`TopicAndPartition` in the Controller. We now use the former
in the Controller (bringing it inline with the rest of the non legacy
code).
- Fixed missed `Listener` -> `Handler` renames for companion
objects.
- More String.format -> String interpolation conversions (the former
is roughly 5 times more expensive).
- Some other minor clean-ups.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Onur Karaman <okaraman@linkedin.com>, Viktor Somogyi <viktorsomogyi@gmail.com>

Closes #4152 from ijuma/controller-topic-partition-and-other-clean-ups",2017-11-07 09:55:44,Ismael Juma,Mixed
9b44c3e7f89b55528b12ba280007c804682beb0b,"KAFKA-5645; Use async ZookeeperClient in SimpleAclAuthorizer

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Onur Karaman <okaraman@linkedin.com>, Jun Rao <junrao@gmail.com>

Closes #4155 from omkreddy/KAFKA-5645-ZK-AUTHORIZER-VERSION2",2017-11-08 09:34:43,Manikumar Reddy,Mixed
ee1aaa091fc68587635604de5006b7acdb160361,"KAFKA-6179: Clear min timestamp tracker upon partition queue cleanup

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>

Closes #4186 from guozhangwang/K6179-cleanup-timestamp-tracker-on-clear",2017-11-08 15:07:14,Guozhang Wang,Mixed
fef80c8636d03a25a3b17f31d9cf2ab9b98f385f,"KAFKA-6146; minimize the number of triggers enqueuing PreferredReplicaLeaderElection events

We currently enqueue a PreferredReplicaLeaderElection controller event in PreferredReplicaElectionHandler's handleCreation, handleDeletion, and handleDataChange. We can just enqueue the event upon znode creation and after preferred replica leader election completes. The processing of this latter enqueue will register the exist watch on PreferredReplicaElectionZNode and perform any pending preferred replica leader election that may have occurred between completion and registration.

Author: Onur Karaman <okaraman@linkedin.com>

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #4189 from onurkaraman/KAFKA-6146",2017-11-09 00:57:15,Onur Karaman,Not TDD
fe3171844b599a3e6c0cfe1e606a21eb4ef32ce6,"KAFKA-6164; Shutdown quota managers if other components fail to start

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #4181 from rajinisivaram/KAFKA-6164",2017-11-09 15:17:52,Rajini Sivaram,Mixed
0653a895f51492a8687aaba0dc7a43b21fca2a56,"KAFKA-6185; Remove channels from explictlyMutedChannels set when closed

This memory leak could eventually lead to an OutOfMemoryError. This
was particularly likely in case of down conversions as the leaked
channels would hold on to the record batch (which is only loaded
into the heap in case of down conversions).

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #4193 from rajinisivaram/KAFKA-6185-oom",2017-11-09 16:03:24,Rajini Sivaram,Mixed
718dda1144629d824f4bdb8ff73fbd531a22723a,"MINOR: Add HttpMetricsReporter for system tests

Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>

Closes #4072 from ewencp/http-metrics",2017-11-09 09:42:46,Ewen Cheslack-Postava,Mixed
564d7b365d102ffbeb24e2421ab6319db311e6b5,"MINOR: make controller helper methods private

Author: Onur Karaman <okaraman@linkedin.com>

Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #4198 from onurkaraman/make-controller-helper-methods-private",2017-11-09 13:51:32,Onur Karaman,Not TDD
66cab2f7fb72417f9bf8759fccb26dfdb33ac6ce,"KAFKA-6190: Use consumer.position() instead of record.offset() to advance in GlobalKTable restoration to avoid transactional control messages

Calculate offset using consumer.position() in GlobalStateManagerImp#restoreState

Author: Alex Good <alexjsgood@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #4197 from alexjg/0.11.0

(cherry picked from commit 1321d89484a9a0657620b20c08ce96ee43d8a691)
Signed-off-by: Guozhang Wang <wangguoz@gmail.com>",2017-11-09 15:35:00,Alex Good,Not TDD
12af521c487a146456442f895b9fc99a45ed100f,"KAFKA-6175; AbstractIndex should cache index file to avoid unnecessary disk access during resize()

This patch also adds the a test for test the log deletion after close.

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Jiangjie Qin <becket.qin@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #4179 from lindong28/KAFKA-6175",2017-11-09 22:08:03,Dong Lin,Not TDD
b9039bbd4b3d8eb231c9f2d1d40042706f8f4f19,"MINOR: Use Scala Future in CoreUtils test

Also rename UtilsTest to CoreUtilsTest and note
that `getOrElseUpdate` has the right behaviour
in Scala 2.12.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #4142 from ijuma/use-scala-futures-in-core-utils-test",2017-11-10 09:44:43,Ismael Juma,Mixed
3cfbb25c616bee44ac181e9320d4fd6d79ab9c58,"MINOR: Handle error metrics removal during shutdown

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #4187 from rajinisivaram/MINOR-metrics-cleanup",2017-11-15 09:54:42,Rajini Sivaram,Mixed
cdcbd9283ddea0207dad7a9f534a534a463f01f4,"KAFKA-6210; IllegalArgumentException if 1.0.0 is used for inter.broker.protocol.version or log.message.format.version

Added unit test for ApiVersion and testApiVersions from
Scala to Java.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #4220 from ijuma/kafka-6210-iae-if-1.0.0-inter-broker-protocol-version",2017-11-16 01:21:11,Ismael Juma,Mixed
539c4d53f8fac65063e4e519c6a51911550a151f,"KAFKA-6167: Timestamp on streams directory contains a colon, which is an illegal character

 - change segment delimiter to .
 - added upgrade path
 - added test for old and new upgrade path

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #4210 from mjsax/kafka-6167-windows-issue",2017-11-15 17:43:35,Matthias J. Sax,Mixed
53c5ccb33401b772678e9d1ef3bebd5784e22814,"KAFKA-5925: Adding records deletion operation to the new Admin Client API

This is the PR related to the [KIP-204](https://cwiki.apache.org/confluence/display/KAFKA/KIP-204+%3A+Adding+records+deletion+operation+to+the+new+Admin+Client+API) in order to add the `deleteRecords` operation to the new Admin Client (it's already available in the ""legacy"" one).
Other than that, unit test and integration tests are added as well (such integration tests come from the ""legacy"" integration tests in order to test the new addition in the same way as the ""legacy"" one).

Author: Paolo Patierno <ppatierno@live.com>

Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #4132 from ppatierno/kafka-5925",2017-11-16 09:52:33,Paolo Patierno,Mixed
d9cbc6b1a28e2fb3f88137429e08c12201998bc7,"KAFKA-5811; Add Kibosh integration for Trogdor and Ducktape

For ducktape: add Kibosh to the testing Dockerfile.
Create files_unreadable_fault_spec.py.

For trogdor: create FilesUnreadableFaultSpec.java.
Add a unit test of using the Kibosh service.

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #4195 from cmccabe/KAFKA-5811",2017-11-16 17:59:24,Colin P. Mccabe,Mixed
40fd9fa98105111bca373e76f8f39914cade709b,"KAFKA-6122: Global Consumer should handle TimeoutException

Implements KIP-224:
- adding new StreamsConfig `retires`
- uses `retires` and `retry.backoff.ms` to handle TimeoutException in GlobalStateManager
- adds two new tests to trigger TimeoutException in global consumer
- some minor code cleanup to reduce number of parameters we need to pass around

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #4206 from mjsax/kafka-6122-global-consumer-timeout-exception",2017-11-18 14:54:01,Matthias J. Sax,Mixed
e3c32391f95d82a217295c7e4c1519981124bc3f,"KAFKA-6170; KIP-220 Part 1: Add AdminClient to Streams

1. Add The AdminClient into Kafka Streams, which is shared among all the threads.
2. Add ADMIN_PREFIX to StreamsConfig.
3. Also made a few tweaks on the metrics of the AdminClient, which is slightly different from the StreamsKafkaClient (note these changes will not be reflected in this PR but only take place when we eventually replace StreamsKafkaClient):
3.1. ""clientId"" tag will be set as ""clientId-admin"": in StreamsKafkaClient it is whatever user sets, and hence could even be null.
3.2. ""groupPrefix"" will be set as ""admin-client"": in StreamsKafkaClient it will be ""kafka-client"".

So the metrics from `StreamsKafkaClient` to `AdminClient` would be changed from

`kafka.admin.client:type=kafka-client-metrics,client-id=`

to

`kafka.admin.client:type=admin-client-metrics,client-id=myApp-UUID-admin`

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Ted Yu <yuzhihong@gmail.com>

Closes #4211 from guozhangwang/K6170-admin-client",2017-11-20 11:25:22,Guozhang Wang,Mixed
049342e440a5ca045771f3eb5b4c72d3e52ffac6,"KAFKA-3073: Add topic regex support for Connect sinks

There are more methods that had to be touched than I anticipated when writing [the KIP](https://cwiki.apache.org/confluence/display/KAFKA/KIP-215%3A+Add+topic+regex+support+for+Connect+sinks).

The implementation here is now complete and includes a test that verifies that there's a call to `consumer.subscribe(Pattern, RebalanceHandler)` when `topics.regex` is provided.

Author: Jeff Klukas <jeff@klukas.net>

Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #4151 from jklukas/connect-topics.regex",2017-11-21 16:01:16,Jeff Klukas,Mixed
225b0b9c712deb3c29f8bca300ba9f73d1084e81,"KAFKA-6214: enable use of in-memory store for standby tasks

Remove the flag in `ProcessorStateManager` that checks if a store is persistent when registering it as a standby task.
Updated the smoke test to use an in-memory store.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <matthias@confluent.io>

Closes #4239 from dguy/kafka-6214",2017-11-21 17:55:30,Damian Guy,Not TDD
ed8b0315a6c3705b2a163ce3ab4723234779264f,"KAFKA-1044; Eliminate direct and non-optional log4j references from `core`

Use slf4j (via scala-logging) instead. Also:

- Log4jController is only initialised if log4j if in the classpath
- Use FATAL marker to support log4j's FATAL level (as the log4j-slf4j bridge does)
- Removed `Logging.swallow` in favour of CoreUtils.swallow, which logs to the
correct logger

Author: Viktor Somogyi <viktor.somogyi@cloudera.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3477 from viktorsomogyi/KAFKA-1044",2017-11-22 15:06:56,Viktor Somogyi,Mixed
c5f31fe3840e87fbdda63444ef285ede840744cf,"KAFKA-4827: Correctly encode special chars while creating URI objects

Signed-off-by: Arjun Satish <arjunconfluent.io>

Author: Arjun Satish <arjun@confluent.io>

Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #4205 from wicknicks/KAFKA-4827",2017-11-22 09:54:06,Arjun Satish,Mixed
bc852baffbf602ead9cb719a01747de414940d53,"KAFKA-5646; Use KafkaZkClient in DynamicConfigManager and AdminManager

* Add AdminZkClient class
* Use KafkaZkClient, AdminZkClient  in ConfigCommand, TopicCommand
* All the existing tests should work

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #4194 from omkreddy/KAFKA-5646-ZK-ADMIN-UTILS-DYNAMIC-MANAGER",2017-11-22 13:25:52,Manikumar Reddy,Mixed
0bc2d0e02aaea5b2517c40f7a76654460467177c,"KAFKA-6074; Use ZookeeperClient in ReplicaManager and Partition

Replaced ZkUtils with KafkaZkClient in ReplicaManager and Partition.

Relying on existing tests.

Author: tedyu <yuzhihong@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #4254 from tedyu/trunk",2017-11-24 11:25:31,tedyu,Mixed
be2918b3a04f669a1264f5d1b0be3cdb6915b2fa,"KAFKA-6261; Fix exception thrown by request logging if acks=0

Only expect responseAsString to be set if request logging is
enabled _and_ responseSend is defined.

Also fixed a couple of issues that would manifest themselves
if trace logging is enabled:

- `MemoryRecords.toString` should not throw exception if data is corrupted
- Generate `responseString` correctly if unsupported api versions request is
received.

Unit tests were added for every issue fixed. Also changed
SocketServerTest to run with trace logging enabled as
request logging breakage has been a common issue.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #4250 from ijuma/fix-issues-when-trace-logging-is-enabled",2017-11-24 20:00:00,Ismael Juma,Mixed
5a2960f811c27f59d78dfdb99c7c3c6eeed16c4b,"KAFKA-5563: Standardize validation and substitution of connector names in REST API connector configs

…from config to own function and added check to create connector call.

Author: Soenke Liebau <soenke.liebau@opencore.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #4230 from soenkeliebau/KAFKA-5563",2017-11-25 17:50:17,Soenke Liebau,Mixed
5df1eee7d689e18ac2f7b74410e7a30159d3afdc,"KAFKA-6170; KIP-220 Part 2: Break dependency of Assignor on StreamThread

This refactoring is discussed in https://github.com/apache/kafka/pull/3624#discussion_r132614639. More specifically:

1. Moved the access of `StreamThread` in `StreamPartitionAssignor` to `TaskManager`, removed any fields stored in `StreamThread` such as `processId` and `clientId` that are only to be used in `StreamPartitionAssignor`, and pass them to `TaskManager` if necessary.
2. Moved any in-memory states, `metadataWithInternalTopics`, `partitionsByHostState`, `standbyTasks`, `activeTasks` to `TaskManager` so that `StreamPartitionAssignor` becomes a stateless thin layer that access TaskManager directly.
3. Remove the reference of `StreamPartitionAssignor` in `StreamThread`, instead consolidate all related functionalities such as `cachedTasksIds ` in `TaskManager` which could be retrieved by the `StreamThread` and the `StreamPartitionAssignor` directly.
4. Finally, removed the two interfaces used for `StreamThread` and `StreamPartitionAssignor`.

5. Some minor fixes on logPrefixes, etc.

Future work: when replacing the StreamsKafkaClient, we would let `StreamPartitionAssignor` to retrieve it from `TaskManager` directly, and also its closing call do not need to be called (`KafkaStreams` will be responsible for closing it).

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>

Closes #4224 from guozhangwang/K6170-refactor-assignor",2017-11-28 09:37:27,Guozhang Wang,Mixed
1a1d923f252e9b1576dad6f7285f237feb064f64,"KAFKA-6274: Use topic plus dash as prefix of auto-generated state store names

Use `topic-` as the prefix of the auto-generated state store name.

Also add a unit test for this functionality.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>, Ted Yu <yuzhihong@gmail.com>

Closes #4268 from guozhangwang/K6274-table-source-store-name",2017-11-28 11:08:42,Guozhang Wang,Mixed
58877a0deacd6c13436af83ef5be1a6f75a3ac4a,"KAFKA-6255; Add ProduceBench to Trogdor

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #4245 from cmccabe/KAFKA-6255",2017-11-28 22:09:55,Colin P. Mccabe,Mixed
0cc32abc17d26c5faf6fdc3b63a01016e05a65b9,"KAFKA-4499: Add all() and fetchAll() API for querying window store

A rebased version of the code.

Author: RichardYuSTUG <yohan.richard.yu2@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #4258 from ConcurrencyPractitioner/trunk

Add EmptyWindowStoreIterator to NoOpWindowStore",2017-11-29 10:55:43,Richard Yu,Mixed
b512cd474c6ebfbbbe0192764cec3413a94baba0,"KAFKA-6259: Make KafkaStreams.cleanup() clean global state directory

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #4255 from mjsax/kafka-6259-clean-global-state-dir

add log4j entry",2017-11-29 11:20:29,Matthias J. Sax,Mixed
38c5d7fba7387b797a10c9c6ed71bf99c6d417bc,"KAFKA-5936; KafkaProducer.close should throw InterruptException

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #3912 from mjsax/kafka-5936-producer-close",2017-11-29 16:22:07,Matthias J. Sax,Mixed
d01f01ec63f61bd4742f02abff2ab6cf339e2897,"KAFKA-6260; Ensure selection keys are removed from all collections on socket close

When a socket is closed, we must remove corresponding selection keys from internal collections. This fixes an NPE which is caused by attempting to access the selection key's attached channel after it had been cleared after disconnecting.

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #4276 from hachikuji/KAFKA-6260",2017-12-01 11:32:44,Jason Gustafson,Mixed
2d8918b1aec2601a66e9321da4460a8826b88139,"KAFKA-6118: Fix transient failure testTwoConsumersWithDifferentSaslCredentials

It's rare, but it can happen that the initial FindCoordinator request returns before the first Metadata request. Both authorization errors are fine for this test case.

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #4287 from hachikuji/KAFKA-6118",2017-12-01 23:52:25,Jason Gustafson,Not TDD
4b8a29f12a142d02be0b64eac71975b6a129d04a,"KAFKA-6150: KIP-204 part III; Purge repartition topics with the admin client

1. Add the repartition topics information into ProcessorTopology: personally I do not like leaking this information into the topology but it seems not other simple way around.
2. StreamTask: added one more function to expose the consumed offsets from repartition topics only.
3. TaskManager: use the AdminClient to send the gathered offsets to delete only if a) previous call has completed and client intentionally ignore-and-log any errors, or b) no requests have ever called before.

NOTE that this code depends on the assumption that purge is only called right after the commit has succeeded, hence we presume all consumed offsets are committed.

4. MINOR: Added a few more constructor for ProcessorTopology for cleaner unit tests.
5. MINOR: Extracted MockStateStore out of the deprecated class.
6. MINOR: Made a pass over some unit test classes for clean ups.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian.guy@gmail.com>

Closes #4270 from guozhangwang/K6150-purge-repartition-topics",2017-12-04 10:21:42,Guozhang Wang,Mixed
fd8f182cc4ea80c6d394ca68a47c0ee26b114ebe,"MINOR: Add maybeThrow method to ZooKeeperClient AsyncResponse

* Add maybeThrow method to AsyncResponse
* Update KafkaZkClient to use newly introduced maybeThrow
* Change AsyncResponse from trait to abstract class for
more readable stacktraces (there's no benefit in using a
trait here)

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #4266 from omkreddy/KAFKAZKCLEINT_EXCEPTION_CLEANUP",2017-12-06 16:27:21,Manikumar Reddy,Mixed
30f08d158a97e0d83b59e5910fbb0a84c5c6d14f,"KAFKA-5520: KIP-171; Extend Consumer Group Reset Offset for Stream Application

KIP: https://cwiki.apache.org/confluence/display/KAFKA/KIP-171+-+Extend+Consumer+Group+Reset+Offset+for+Stream+Application

Merge changes from KIP-198

Ref: https://github.com/apache/kafka/pull/3831

Author: Jorge Quilcate Otoya <quilcate.jorge@gmail.com>
Author: Ismael Juma <ismael@juma.me.uk>
Author: Matthias J. Sax <matthias@confluent.io>
Author: Manikumar Reddy <manikumar.reddy@gmail.com>
Author: Guozhang Wang <wangguoz@gmail.com>
Author: Apurva Mehta <apurva@confluent.io>
Author: Rajini Sivaram <rajinisivaram@googlemail.com>
Author: Jason Gustafson <jason@confluent.io>
Author: Vahid Hashemian <vahidhashemian@us.ibm.com>
Author: Bill Bejeck <bill@confluent.io>
Author: Dong Lin <lindong28@gmail.com>
Author: Soenke Liebau <soenke.liebau@opencore.com>
Author: Colin P. Mccabe <cmccabe@confluent.io>
Author: Damian Guy <damian.guy@gmail.com>
Author: Xavier Léauté <xl+github@xvrl.net>
Author: Maytee Chinavanichkit <maytee.chinavanichkit@linecorp.com>
Author: Joel Hamill <git config --global user.email>
Author: Paolo Patierno <ppatierno@live.com>
Author: siva santhalingam <siva.santhalingam@gmail.com>
Author: Tommy Becker <tobecker@tivo.com>
Author: Mickael Maison <mickael.maison@gmail.com>
Author: Onur Karaman <okaraman@linkedin.com>
Author: tedyu <yuzhihong@gmail.com>
Author: Xin Li <Xin.Li@trivago.com>
Author: Magnus Edenhill <magnus@edenhill.se>
Author: Manjula K <manjula@kafka-summit.org>
Author: Hugo Louro <hmclouro@gmail.com>
Author: Jeff Widman <jeff@jeffwidman.com>
Author: bartdevylder <bartdevylder@gmail.com>
Author: Ewen Cheslack-Postava <me@ewencp.org>
Author: Jacek Laskowski <jacek@japila.pl>
Author: Tom Bentley <tbentley@redhat.com>
Author: Konstantine Karantasis <konstantine@confluent.io>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #4159 from jeqo/feature/kip-171",2017-12-06 11:38:38,Jorge Quilcate Otoya,Mixed
d543e19a09ed34ccb6fa435d430c2c715c3c7098,"KAFKA-6193; Only delete reassign_partitions znode after reassignment is complete

- Ensure that `partitionsBeingReassigned` is fully populated before
`removePartitionFromReassignedPartitions` is invoked. This is
necessary to avoid premature deletion of the `reassign_partitions`
znode.
- Modify and add tests to verify the fixes.
- Add documentation.
- Use `info` log message if assignedReplicas == newReplicas and
remove control flow based on exceptions.
- General logging improvements.
- Simplify `initializePartitionAssignment` by relying on logic already
present in `maybeTriggerPartitionReassignment`.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #4283 from ijuma/kafka-6193-flaky-shouldPerformMultipleReassignmentOperationsOverVariousTopics",2017-12-06 22:18:41,Ismael Juma,Mixed
b00a9fc7c3b62506262cbd759c35d58ad99eb17a,"KAFKA-6065; Latency metric for KafkaZkClient

Measures the latency of each request.

Updated existing `ZkUtils` test to use `KafkaZkClient`
instead.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #4265 from ijuma/kafka-6065-async-zk-metrics",2017-12-07 01:13:40,Ismael Juma,Mixed
b73c765d7e172de4742a3aa023d5a0a4b7387247,"MINOR: Avoid intermediate strings when parsing/decoding ZK JSON

Also:
- Fix bug in result type of `createSequentialPersistentPath`
- Remove duplicated code from `ReplicationUtils`
- Move `propagateIsrChanges` from `ReplicationUtils` to `KafkaZkClient`
- Add tests
- Minor clean-ups

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>, Ted Yu <yuzhihong@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #4261 from ijuma/zk-data-improvements",2017-12-07 02:38:34,Ismael Juma,Mixed
234ec8a8af76bfb7874dd99714a65089d6048953,"KAFKA-4857: Replace StreamsKafkaClient with AdminClient in Kafka Streams

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Bill Bejeck <bbejeck@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #4242 from mjsax/kafka-4857-admit-client",2017-12-07 16:16:54,Matthias J. Sax,Mixed
2bf2348b5fc9f9f62bee5b91a431b8703a20cdbb,"KAFKA-6289; NetworkClient should not expose failed internal ApiVersions requests

The NetworkClient internally ApiVersion requests to each broker following connection establishment. If this request happens to fail (perhaps due to an incompatible broker), the NetworkClient includes the response in the result of poll(). Applications will generally not be expecting this response which may lead to failed assertions (or in the case of AdminClient, an obscure log message).

I've added test cases which await the ApiVersion request sent by NetworkClient to be in-flight, and then disconnect the connection and verify that the response is not included from poll().

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #4280 from hachikuji/KAFKA-6289",2017-12-08 10:54:31,Jason Gustafson,Mixed
043951753b6fb6c8bae6d25d7a6a97e74b614cac,"KAFKA-6121: Restore and global consumer should not use auto.offset.reset

- set auto.offset.reste to ""none"" for restore and global consumer
- handle InvalidOffsetException for restore and global consumer
- add corresponding tests
- some minor cleanup

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Damian Guy <damian.guy@gmail.com, Bill Bejeck <bill@confluent.io>, GuozhangWang <wangguoz@gmail.com>

Closes #4215 from mjsax/kafka-6121-restore-global-consumer-handle-reset",2017-12-11 14:20:10,Matthias J. Sax,Mixed
a5cd34d7962ff5da9b99d0229ef5a9a5fcb3f318,"KAFKA-6324; Change LogSegment.delete to deleteIfExists and harden log recovery

- Rename `delete()` to `deleteIfExists()` in `LogSegment`, `AbstractIndex`
and `TxnIndex`. Throw exception in case of IO errors for more informative
errors and to make it less likely that errors are ignored, `boolean` is used
for the case where the file does not exist (like `Files.deleteIfExists()`).
- Fix an instance of delete while open (should fix KAFKA-6322 and
KAFKA-6075).
- `LogSegment.deleteIfExists` no longer throws an exception if any of
the files it tries to delete does not exist (fixes KAFKA-6194).
- Remove unnecessary `FileChannel.force(true)` when deleting file.
- Introduce `LogSegment.open()` and use it to improve encapsulation
and reduce duplication.
- Expand functionality of `LogSegment.onBecomeInactiveSegment()`
to reduce duplication and improve encapsulation.
- Use `AbstractIndex.deleteIfExists()` instead of deleting files manually.
- Improve logging when deleting swap files.
- Use CorruptIndexException instead of IllegalArgumentException.
- Simplify `LogCleaner.cleanSegments()` to reduce duplication and
improve encapsulation.
- A few other clean-ups in Log, LogSegment, etc.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Jun Rao <junrao@gmail.com>, Ted Yu <yuzhihong@gmail.com>

Closes #4040 from ijuma/kafka-5829-follow-up",2017-12-12 10:00:05,Ismael Juma,Mixed
651c6e480a233ce374bc0a9128f0398d18de7898,"KAFKA-6319: Quote strings stored in JSON configs

This is required for ACLs where SSL principals contain
special characters (e.g. comma) that are escaped using
backslash. The strings need to be quoted for JSON to
ensure that the JSON stored in ZK is valid.

Also converted `SslEndToEndAuthorizationTest` to use a
principal with special characters to ensure that this
path is tested.

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #4303 from rajinisivaram/KAFKA-6319",2017-12-12 12:05:11,Rajini Sivaram,Mixed
0a508a436c928c0440e8b90dda98c22dc0ec244c,"KAFKA-5631; Use Jackson for serialising to JSON

- Rename `encode` to `legacyEncodeAsString`, we
can remove this when we remove `ZkUtils`.
- Introduce `encodeAsString` that uses Jackson.
- Change `encodeAsBytes` to use Jackson.
- Avoid intermediate string when converting
Broker to json bytes.

The methods that use Jackson only support
Java collections unlike `legacyEncodeAsString`.

Tests were added `encodeAsString` and
`encodeAsBytes`.

Author: umesh chaudhary <umesh9794@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #4259 from umesh9794/KAFKA-5631",2017-12-12 18:34:03,umesh chaudhary,Mixed
b08882213489706c663785f2c94d76584ba6e856,"KAFKA-5764; Add toLowerCase support to sasl.kerberos.principal.to.local rule (KIP-203)

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #3800 from omkreddy/KAFKA-5764-REGEX",2017-12-12 15:47:57,Manikumar Reddy,Not TDD
d1a9252ca1808711882ae4c3043b0576620f8177,"KAFKA-6349: Fix concurrent modification exception in AbstractStateManager during restore

Fixes a `ConcurrentModificationException` in`AbstractStateManager` that is triggered when a `StateStore` is re-initialized and there are multiple stores in the context.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, GuozhangWang <wangguoz@gmail.com>

Closes #4317 from dguy/kafka-6349",2017-12-12 19:25:01,Damian Guy,Not TDD
1cf7ec87d3afeaab7b4f40d387d34e91e9616e64,"KAFKA-6360: Clear RocksDB Segments when store is closed

Now that we support re-initializing state stores, we need to clear the segments when the store is closed so that they can be re-opened.

Author: Damian Guy <damian.guy@gmail.com>

Reviewers: Bill Bejeck <bbejeck@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Ted Yu <yuzhihong@gmail.com>

Closes #4324 from dguy/kafka-6360",2017-12-14 09:51:56,Damian Guy,Mixed
616321bcb618b57d063273df7764058dbd2b7a9c,"KAFKA-6102; Consolidate MockTime implementations between connect and clients

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #4105 from cmccabe/KAFKA-6102",2017-12-14 14:50:34,Colin P. Mccabe,Mixed
68712dcdec6e15f24f720f094ccc504ae7829b30,"KAFKA-6308; Connect Struct should use deepEquals/deepHashCode

This changes the Struct's equals and hashCode method to use Arrays#deepEquals and Arrays#deepHashCode, respectively. This resolves a problem where two structs with values of type byte[] would not be considered equal even though the byte arrays' contents are equal. By using deepEquals, the byte arrays' contents are compared instead of ther identity.

Since this changes the behavior of the equals method for byte array values, the behavior of hashCode must change alongside it to ensure the methods still fulfill the general contract of ""equal objects must have equal hashCodes"".

Test rationale:
All existing unit tests for equals were untouched and continue to work. A new test method was added to verify the behavior of equals and hashCode for Struct instances that contain a byte array value. I verify the reflixivity and transitivity of equals as well as the fact that equal Structs have equal hashCodes
and not-equal structs do not have equal hashCodes.

Author: Tobias Gies <tobias.gies@trivago.com>
Author: Tobias Gies <tobias@tobiasgies.de>

Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #4293 from tobiasgies/feature/kafka-6308-deepequals",2017-12-14 15:26:20,Tobias Gies,Mixed
69777260e05ab12ee8480c23cd2e6acc6e218a12,"KAFKA-6086: Provide for custom error handling when Kafka Streams fails to produce

This PR creates and implements the `ProductionExceptionHandler` as described in [KIP-210](https://cwiki.apache.org/confluence/display/KAFKA/KIP-210+-+Provide+for+custom+error+handling++when+Kafka+Streams+fails+to+produce).

I've additionally provided a default implementation preserving the existing behavior. I fixed various compile errors in the tests that resulted from my changing of method signatures, and added tests to cover the new behavior.

Author: Matt Farmer <mfarmer@rsglab.com>
Author: Matt Farmer <matt@frmr.me>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>

Closes #4165 from farmdawgnation/msf/kafka-6086",2017-12-15 12:53:17,Matt Farmer,Mixed
529786638baeb4335065df4e2b240aad42caca9a,"KAFKA-5526; Additional `--describe` views for ConsumerGroupCommand (KIP-175)

The `--describe` option of ConsumerGroupCommand is expanded, as proposed in [KIP-175](https://cwiki.apache.org/confluence/display/KAFKA/KIP-175%3A+Additional+%27--describe%27+views+for+ConsumerGroupCommand), to support:
* `--describe` or `--describe --offsets`: listing of current group offsets
* `--describe --members` or `--describe --members --verbose`: listing of group members
* `--describe --state`: group status

Example: With a single partition topic `test1` and a double partition topic `test2`, consumers `consumer1` and `consumer11` subscribed to `test`, consumers `consumer2` and `consumer22` and `consumer222` subscribed to `test2`, and all consumers belonging to group `test-group`, this is an output example of the new options above for `test-group`:

```
--describe, or --describe --offsets:

TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                     HOST            CLIENT-ID
test2           0          0               0               0               consumer2-bad9496d-0889-47ab-98ff-af17d9460382  /127.0.0.1      consumer2
test2           1          0               0               0               consumer22-c45e6ee2-0c7d-44a3-94a8-9627f63fb411 /127.0.0.1      consumer22
test1           0          0               0               0               consumer1-d51b0345-3194-4305-80db-81a68fa6c5bf  /127.0.0.1      consumer1
```

```
--describe --members

CONSUMER-ID                                      HOST            CLIENT-ID       #PARTITIONS
consumer2-bad9496d-0889-47ab-98ff-af17d9460382   /127.0.0.1      consumer2       1
consumer222-ed2108cd-d368-41f1-8514-5b72aa835bcc /127.0.0.1      consumer222     0
consumer11-dc8295d7-8f3f-4438-9b11-7270bab46760  /127.0.0.1      consumer11      0
consumer22-c45e6ee2-0c7d-44a3-94a8-9627f63fb411  /127.0.0.1      consumer22      1
consumer1-d51b0345-3194-4305-80db-81a68fa6c5bf   /127.0.0.1      consumer1       1
```

```
--describe --members --verbose

CONSUMER-ID                                      HOST            CLIENT-ID       #PARTITIONS     ASSIGNMENT
consumer2-bad9496d-0889-47ab-98ff-af17d9460382   /127.0.0.1      consumer2       1               test2(0)
consumer222-ed2108cd-d368-41f1-8514-5b72aa835bcc /127.0.0.1      consumer222     0               -
consumer11-dc8295d7-8f3f-4438-9b11-7270bab46760  /127.0.0.1      consumer11      0               -
consumer22-c45e6ee2-0c7d-44a3-94a8-9627f63fb411  /127.0.0.1      consumer22      1               test2(1)
consumer1-d51b0345-3194-4305-80db-81a68fa6c5bf   /127.0.0.1      consumer1       1               test1(0)
```

```
--describe --state

COORDINATOR (ID)         ASSIGNMENT-STRATEGY       STATE                #MEMBERS
localhost:9092 (0)       range                     Stable               5
```

Note that this PR also addresses the issue reported in [KAFKA-6158](https://issues.apache.org/jira/browse/KAFKA-6158) by dynamically setting the width of columns `TOPIC`, `CONSUMER-ID`, `HOST`, `CLIENT-ID` and `COORDINATOR (ID)`. This avoid truncation of column values when they go over the current fixed width of these columns.

The code has been restructured to better support testing of individual values and also the console output. Unit tests have been updated and extended to take advantage of this restructuring.

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #4271 from vahidhashemian/KAFKA-5526",2017-12-15 10:26:00,Vahid Hashemian,Not TDD
e5daa40e316261e8e6cb8866ad9a4eedcf17f919,"KAFKA-5473; handle ZK session expiration properly when a new session can't be established

(WIP: this commit isn't ready to be reviewed yet. I was checking the travis-ci build with the configuration changes in my account and opened the PR prematurely against trunk. I will make it consistent with Contribution guidelines once it's well tested.)

https://issues.apache.org/jira/browse/KAFKA-5473

Design:
`zookeeper.connection.retry.timeout.ms` => this determines how long to wait before triggering the shutdown. The default is 60000ms.

Currently the implementation only handles the `handleSessionEstablishmentError` by waiting for the sessionTimeout.

Author: Prasanna Gautam <prasannagautam@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #3990 from prasincs/KAFKA-5473",2017-12-15 14:48:30,Prasanna Gautam,Not TDD
066bfc314c912aa90283a1c1c53a958237d1adff,"KAFKA-6258; SSLTransportLayer should keep reading from socket until either the buffer is full or the socket has no more data

When consumer uses plaintext and there is remaining data in consumer's buffer, consumer.poll() will read all data available from the socket buffer to consumer buffer. However, if consumer uses ssl and there is remaining data, consumer.poll() may only read 16 KB (the size of SslTransportLayer.appReadBuffer) from socket buffer. This will reduce efficient of consumer.poll() by asking user to call more poll() to get the same amount of data.

Furthermore, we observe that for users who naively sleep a constant time after each consumer.poll(), some partition will lag behind after they switch from plaintext to ssl. Here is the explanation why this can happen.

Say there are 1 partition of 1MB/sec and 9 partition of 32KB/sec. Leaders of these partitions are all different and consumer is consuming these 10 partitions. Let's also assume that socket read buffer size is large enough and consume sleeps 1 sec between consumer.poll(). 1 sec is long enough for consumer to receive the FetchResponse back from broker.

When consumer uses plaintext, each consumer.poll() will read all data from the socket buffer and it means 1 MB data is read from each partition.

When consumer uses ssl, each consumer.poll() is likely to find that there is some data available in the memory. In this case consumer only reads 16 KB data from other sockets, particularly the socket for the broker with the large partition. Then the throughput of the large partition will be limited to 16KB/sec.

Arguably user should not sleep 1 sec if its consumer is lagging behind. But on Kafka dev side it is nice to keep the previous behavior and optimize consumer.poll() to read as much data from socket as possible.

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>

Closes #4248 from lindong28/KAFKA-6258",2017-12-18 11:15:09,Dong Lin,Mixed
9aad649fd0defa4b55f305e3e025883ebb567b34,"MINOR: Fix race condition in KafkaStreamsTest.shouldReturnThreadMetadata

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #4337 from mjsax/minor-fix-kafakstreamstest",2017-12-18 17:39:25,Matthias J. Sax,Not TDD
f3b9afe62265d7559ef65f5aa692feecc5fa8f25,"MINOR: Broker down for significant amt of time system test

System test where a broker is offline more than the configured timeouts.  In this case:
- Max poll interval set to 45 secs
- Retries set to 2
- Request timeout set to 15 seconds
- Max block ms set to 30 seconds

The broker was taken off-line for 70 seconds or more than double request timeout * num retries

[passing system test results](http://confluent-kafka-branch-builder-system-test-results.s3-us-west-2.amazonaws.com/2017-12-11--001.1513034559--bbejeck--KSTREAMS_1179_broker_down_for_significant_amt_of_time--6ab4802/report.html)

Author: Bill Bejeck <bill@confluent.io>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #4313 from bbejeck/KSTREAMS_1179_broker_down_for_significant_amt_of_time",2017-12-19 15:37:21,Bill Bejeck,Not TDD
82c6d429e70f1c782103953072dc6dbec650dd6e,"KAFKA-6150: KIP-204 part III; Change repartition topic segment size and ms

1. Create default internal topic configs in StreamsConfig, especially for repartition topics change the segment size and time to smaller value.
2. Consolidate the default internal topic settings to InternalTopicManager and simplify InternalTopicConfig correspondingly.
3. Add an integration test for purging data.
4. MINOR: change TopologyBuilderException to IllegalStateException in StreamPartitionAssignor (part of https://issues.apache.org/jira/browse/KAFKA-5660).

Here are a few public facing APIs that get added:

1. AbstractConfig#originalsWithPrefix(String prefix, boolean strip): this for simplify the logic of passing admin and topic prefixed configs to consumer properties.
2. KafkaStreams constructor with Time object for convienent mocking in tests.

Will update KIP-204 accordingly if people re-votes these changes.

Author: Guozhang Wang <wangguoz@gmail.com>
Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Damian Guy <damian.guy@gmail.com>

Closes #4315 from guozhangwang/K6150-segment-size",2017-12-19 16:05:42,Guozhang Wang,Mixed
488ea4b9fd797b5edd58c6f9685d70acd15e3e74,"KAFKA-5647; Use KafkaZkClient in ReassignPartitionsCommand and PreferredReplicaLeaderElectionCommand

*  Use KafkaZkClient in ReassignPartitionsCommand
*  Use KafkaZkClient in PreferredReplicaLeaderElectionCommand
*  Updated test classes to use new methods
*  All existing tests should pass

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #4260 from omkreddy/KAFKA-5647-ADMINCOMMANDS",2017-12-20 12:19:36,Manikumar Reddy,Mixed
760d86a970d20643f1b8f71e78c60a7ad2be7003,"KAFKA-5849; Add process stop, round trip workload, partitioned test

* Implement process stop faults via SIGSTOP / SIGCONT

* Implement RoundTripWorkload, which both sends messages, and confirms that they are received at least once.

* Allow Trogdor tasks to block until other Trogdor tasks are complete.

* Add CreateTopicsWorker, which can be a building block for a lot of tests.

* Simplify how TaskSpec subclasses in ducktape serialize themselves to JSON.

* Implement some fault injection tests in round_trip_workload_test.py

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #4323 from cmccabe/KAFKA-5849",2017-12-20 21:35:33,Colin P. Mccabe,Mixed
dca1474b4b33b85dba461c61568b86b17d6be18f,"KAFKA-6126: Remove unnecessary topics created check

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #4322 from mjsax/kafka-6126-remove-topic-check-on-rebalance-2",2017-12-20 18:02:33,Matthias J. Sax,Mixed
27c2c81663d6518a3da5cfde88109f90ded8a6db,"KAFKA-6320: Move ZK metrics in KafkaHealthCheck to ZookeeperClient (#4351)

* Moved metrics in KafkaHealthCheck to ZookeeperClient.
* Converted remaining ZkUtils usage in KafkaServer to ZookeeperClient and removed ZkUtils from KafkaServer.
* Made the re-creation of ZooKeeper during ZK session expiration with infinite retries.
* Added unit tests for all new methods in KafkaZkClient.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2017-12-22 10:28:57,Jun Rao,Mixed
2652565d429138c5841f254afef3cfd689315dbb,"KAFKA-6390: Update ZooKeeper to 3.4.11, Gradle and other minor updates (#4345)

Updates:
- Gradle, gradle plugins and maven artifact updated
- Bug fix updates for ZooKeeper, Jackson, EasyMock and Snappy

Not updated:
- RocksDB as it often causes issues, so better done separately
- args4j as our test coverage is weak and the update was a
feature release

Also fixed scala-reflect version to match scala-library.

Release notes for ZooKeeper 3.4.11:
https://zookeeper.apache.org/doc/r3.4.11/releasenotes.html

A notable fix is improved handling of UnknownHostException:
https://issues.apache.org/jira/browse/ZOOKEEPER-2614

Manually tested that IntelliJ import and build still works.
Relying on existing test suite otherwise.

Reviewers: Jun Rao <junrao@gmail.com>",2017-12-22 18:41:22,Ismael Juma,Not TDD
5d4965bad4ea4a64d798f1cc0271de8d4e3d4289,"KAFKA-6307: Fix KafkaMbean leak in JmxReporter (#4307)

We should remove the map entry from mbeans if it becomes
empty during metric removal.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Satish Duggana <satish.duggana@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2018-01-01 10:16:07,tedyu,Mixed
47db063c310cf47e4c544196acab2abfe62977b0,"KAFKA-6383: complete shutdown for CREATED StreamThreads (#4343)

* KAFKA-6383: complete shutdown for CREATED StreamThreads

When transitioning StreamThread from CREATED to PENDING_SHUTDOWN
free up resources from the caller, rather than the stream thread,
since in this case the stream thread was never actually started.

Have StreamThread.setState return the old state. If the old state is
CREATED in StreamThread.shutdown() then start the thread so that it
can free the resources owned by the StreamThread.

Add a KafkaStreams test to verify that the producer gets closed even
if KafkaStreams was not started

Reviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",2018-01-02 09:32:17,Rohan,Mixed
0ecc3596b450b3cf638b5d830c6fea4577038d40,"KAFKA-6269: KTable restore fails after rebalance (#4300)

* Return offset of next record of records left after restore completed
* Changed check for restoring partition to remove the ""+1"" in the guard condition

Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",2018-01-02 09:42:40,Bill Bejeck,Mixed
5ca1226c22976050fd929c7bf66f3af8a5cd0493,"KAFKA-6391 ensure topics are created with correct partitions BEFORE building the… (#4347)

* ensure topics are created with correct partitions BEFORE building the metadata for our stream tasks

* Added a test case. The test should fail with the old logic, because:
While stream-partition-assignor-test-KSTREAM-MAP-0000000001-repartition is created correctly with four partitions, the StreamPartitionAssignor will only assign three tasks to the topic. Test passes with the new logic.

Reviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>, Ted Yu <yuzhihong@gmail.com>",2018-01-02 10:22:28,Clemens Valiente,Mixed
fd2bdbfd700273699725f281a7abab4ff8e55a04,"KAFKA-6318: StreamsResetter should return non-zero return code on error (#4305)

Reviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>, Ted Yu <yuzhihong@gmail.com>, Bill Bejeck <bbejeck@gmail.com>",2018-01-02 10:45:57,Siva Santhalingam,Not TDD
2119e9f26ed988746ee22d139d1eb1aca2bbb950,"Revert ""KAFKA-6383: complete shutdown for CREATED StreamThreads (#4343)""

This reverts commit 47db063c310cf47e4c544196acab2abfe62977b0.",2018-01-02 14:21:42,Guozhang Wang,Mixed
98296f852f334067553e541d6ecdfa624f0eb689,"MINOR: Fix zk client session state metric names and various async zk clean-ups

- Fix zk session state and session change rate metric names: type
should be SessionExpireListener instead of KafkaHealthCheck. Test
verifying the fix was included.
- Handle missing controller in controlled shutdown in the same way as if
the broker is not registered (i.e. retry after backoff).
- Restructure BrokerInfo to reduce duplication. It now contains a
Broker instance and the JSON serde is done in BrokerIdZNode
since `Broker` does not contain all the fields.
- Remove dead code from `ZooKeeperClient.initialize` and remove
redundant `close` calls.
- Move ACL handling and persistent paths definition from ZkUtils to
ZkData (and call ZkData from ZkUtils).
- Remove ZooKeeperClientWrapper and ZooKeeperClientMetrics from
ZkUtils (avoids metrics clash if third party users create a ZkUtils
instance in the same process as the broker).
- Introduce factory method in KafkaZkClient that creates
ZooKeeperClient and remove metric name defaults from
ZooKeeperClient.
- Fix a few instances where ZooKeeperClient was not closed in tests.
- Update a few TestUtils methods to use KafkaZkClient instead of
ZkUtils.
- Add test verifying SessionState metric.
- Various clean-ups.

Testing: mostly relying on existing tests, but added a couple
of new tests as mentioned above.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Jun Rao <junrao@gmail.com>

Closes #4359 from ijuma/kafka-6320-kafka-health-zk-metrics-follow-up",2018-01-03 14:02:14,Ismael Juma,Mixed
3ea2d912c82a021bf43ba7a26b9b714c2fc0e817,"MINOR: Fix concurrency bug in MetadataCache and Metadata request when listeners inconsistent (#4374)

- Add missing locking/volatile in MetadataCache.aliveEndPoint
- Fix topic metadata not to throw BrokerNotAvailableException
when listeners are inconsistent. Add test verifying the fix. As
part of this fix, renamed Broker methods to follow Map
convention where the `get` version returns `Option`.

Reviewers: Jason Gustafson <jason@confluent.io>",2018-01-04 10:16:04,Ismael Juma,Mixed
bfb272c5cdb227040d862f0ab7337df68f787764,"KAFKA-6311: Expose Kafka cluster ID in Connect REST API (KIP-238) (#4314)

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-01-05 07:52:50,Ewen Cheslack-Postava,Mixed
ecf0ab42c1591be2a3784b6e107567ad883e0330,"KAFKA-4335: Add batch.size to FileStreamSource connector to prevent OOM

When the source file of `FileStreamSource` is a large file, `FileStreamSourceTask.poll()` will result in OOM. This pull request added `batch.size` parameter which can restrict the poll size.

*More detailed description of your change,
if necessary. The PR title and PR message become
the squashed commit message, so use a separate
comment to ping reviewers.*

*Summary of testing strategy (including rationale)
for the feature or bug fix. Unit and/or integration
tests are expected for any behaviour change and
system tests should be considered for larger changes.*

Author: Study <ph.study@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #4356 from phstudy/KAFKA-4335",2018-01-05 18:31:53,Study,Mixed
3b03c9d3484f59c7a5fccb282ff77ad45734c10c,"KAFKA-6252; Close the metric group to clean up any existing metrics

We are closing the metricGroups created in a Worker, Source task and Sink task before populating them with new metrics. This helps in cases where an Exception is thrown when previously created groups were not cleaned up correctly.

Signed-off-by: Arjun Satish <arjunconfluent.io>

Author: Arjun Satish <arjun@confluent.io>

Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #4397 from wicknicks/KAFKA-6252",2018-01-05 21:24:39,Arjun Satish,Not TDD
a7e49027b2b95bc8656ee9f419306c559ad1cb5c,"MINOR: Catch JsonMappingException subclass (#3821)

Handle InvalidTypeIdException as NOT_IMPLEMENTED and add unit tests for all exceptions.

Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2018-01-08 12:14:25,Romain Hardouin,Mixed
697a4af35a3672dd339c3a6a34d5ab27e31e0fbd,"KAFKA-6363: Use MockAdminClient for any unit tests that depend on AdminClient (#4371)

* Implement MockAdminClient.deleteTopics
* Use MockAdminClient instead of MockKafkaAdminClientEnv in StreamsResetterTest
* Rename MockKafkaAdminClientEnv to AdminClientUnitTestEnv
* Use MockAdminClient instead of MockKafkaAdminClientEnv in TopicAdminTest
* Rename KafkaAdminClient to AdminClientUnitTestEnv in KafkaAdminClientTest.java
* Migrate StreamThreadTest to MockAdminClient
* Fix style errors
* Address review comments
* Fix MockAdminClient call

Reviewers: Matthias J. Sax <matthias@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-01-08 11:58:56,Filipe Agapito,Not TDD
6396d01957ea355c21d658c3614190458229fa5b,"KAFKA-6096: Add multi-threaded tests for group coordinator, txn manager (#4122)

Reviewers: Jason Gustafson <jason@confluent.io>",2018-01-08 16:15:35,Rajini Sivaram,Not TDD
fa5ebc8a019f8cb24823dd29ef84d422d93624dc,"KAFKA-6398: fix KTable.filter that does not include its parent's queryable storename

1. Include the parent's queryable store name in KTable.filter if this operator is not materialized.
2. Augment InternalTopologyBuilder checking on null processor / store names from the enum.
3. Unit test.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>

Closes #4384 from guozhangwang/K6398-topology-builder-exception",2018-01-10 11:14:20,Guozhang Wang,Mixed
4d544d4f08b027ce318b088b112f03dccc566098,"KAFKA-6383: Complete shut down for streams threads that have not started

*More detailed description of your change,
if necessary. The PR title and PR message become
the squashed commit message, so use a separate
comment to ping reviewers.*

*Summary of testing strategy (including rationale)
for the feature or bug fix. Unit and/or integration
tests are expected for any behaviour change and
system tests should be considered for larger changes.*

Author: Rohan Desai <desai.p.rohan@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #4382 from rodesai/KAFKA-6383",2018-01-10 16:24:43,Rohan Desai,Mixed
b8aa1761c39bd320950104fa2ddf4fbd7163fc85,"KAFKA-6265: Add #queryableStoreName() to GlobalKTable

A spinoff of original pull request #4340 for resolving conflicts.

Author: RichardYuSTUG <yohan.richard.yu2@gmail.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #4413 from ConcurrencyPractitioner/kafka-6265-2",2018-01-11 09:54:02,Richard Yu,Mixed
936e81afcb0488e65a3dbca688c768b0100fe04a,"KAFKA-6250: Use existing Kafka Connect internal topics without requiring ACL (#4247)

When using Kafka Connect with a cluster that doesn't allow the user to
create topics (due to ACL configuration), Connect fails when trying to
create its internal topics even if these topics already exist. This is
incorrect behavior according to the documentation, which mentions that
R/W access should be enough.

This happens specifically when using Aiven Kafka, which does not permit
creation of topics via the Kafka Admin Client API.

The patch ignores the returned error, similar to the behavior for older
brokers that don't support the API.",2018-01-11 15:52:50,Gavrie Philipson,Mixed
3e21e17a7d3613bfab8c34555c0f598a07cf0675,"MINOR: Improve Join integration test coverage, PART I

0. Rename `JoinIntegrationTest` to `StreamStreamJoinIntegrationTest`, which is only for KStream-KStream joins.
1. Extract the `AbstractJoinIntegrationTest` which is going to be used for all the join integration test classes, parameterized with and without caching.
2. Merge `KStreamRepartitionJoinTest.java` into `StreamStreamJoinIntegrationTest.java` with augmented stream-stream join.
3. Add `TableTableJoinIntegrationTest` with detailed per-step expected results and removed `KTableKTableJoinIntegrationTest`.

Findings of the integration test:

1. Confirmed KAFKA-4309 with caching turned on.
2. Found bug KAFKA-6398.
3. Found bug KAFKA-6443.
4. Found a bug that in CachingKeyValueStore, we would flush before putting the record into the underlying store, when the store is going to be used in the downstream processors with flushing it would result in incorrect results, fixed the issue along with this PR.
5. Consider a new optimization described in KAFKA-6286.

Future works including stream-table joins will be in other PRs.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>

Closes #4331 from guozhangwang/KMinor-join-integration-tests",2018-01-12 15:40:59,Guozhang Wang,Not TDD
5d81639907869ce7355c40d2bac176a655e52074,"KAFKA-5890; records.lag should use tags for topic and partition rather than using metric name.

This is the implementation of KIP-225.
It marks the previous metrics as deprecated in the documentation and adds new metrics using tags.

Testing verifies that both the new and the old metric report the same value.

Author: cmolter <cmolter@apple.com>

Reviewers: Jiangjie (Becket) Qin <becket.qin@gmail.com>

Closes #4362 from lahabana/kafka-5890",2018-01-14 16:18:39,cmolter,Mixed
27a8d0f9e7f3b05f331d1449b17cf7e085a4b45c,"KAFKA-4541; Support for delegation token mechanism

- Add capability to create delegation token
- Add authentication based on delegation token.
- Add capability to renew/expire delegation tokens.
- Add units tests and integration tests

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #3616 from omkreddy/KAFKA-4541",2018-01-16 09:50:31,Manikumar Reddy,Mixed
bcc712b45820da74b44209857ebbf7b9d59e0ed7,"KAFKA-4218: Enable access to key in ValueTransformer and ValueMapper

This PR is the partial implementation for KIP-149. As the discussion for this KIP is still ongoing, I made a PR on the ""safe"" portions of the KIP (so that it can be included in the next release) which are 1) `ValueMapperWithKey`, 2) `ValueTransformerWithKeySupplier`, and 3) `ValueTransformerWithKey`.

Author: Jeyhun Karimov <je.karimov@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #4309 from jeyhunkarimov/KIP-149_hope_last",2018-01-16 10:47:29,Jeyhun Karimov,Mixed
2771f52ea7070a3147058e0d6661e0a7e4158161,"KAFKA-6328: Sort node groups considering global stores in InternalTopologyBuilder#makeNodeGroups

Author: RichardYuSTUG <yohan.richard.yu2@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>

Closes #4339 from ConcurrencyPractitioner/kafka-6238

Minor edits on description",2018-01-16 16:57:15,RichardYuSTUG,Mixed
5701ba88f895ac9211f25c15204d6281aed00ffc,"MINOR: Need to get a new transformer for each get() call. can't share'em (#4435)

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>",2018-01-18 08:45:22,dan norwood,Mixed
51f0f3ee792cf9352ce61afeca098c765cdad664,"MINOR: additional check to follower fetch handling  (#4433)

add check to KafkaApis, add unit test specific to follower fetch
developed with @mimaison

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>",2018-01-18 19:14:49,Edoardo Comar,Not TDD
75e37d7e2063b726aa0185f4b695f32cde69d95c,"KAFKA-6398: Return value getter based on KTable materialization status

This is a bug fix that is composed of two parts:

1. The major part is, for all operators that is generating a KTable, we should construct its value getter based on whether the KTable itself is materialized.
1.a If yes, then query the materialized store directly for value getter.
1.b If not, then hand over to its parents value getter (recursively) and apply the computation to return.

2. The minor part is, in KStreamImpl, when joining with a table, we should connect with table's `valueGetterSupplier().storeNames()`, not the `internalStoreName()` as the latter always assume that the KTable is materialized, but that is not always true.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>

Closes #4421 from guozhangwang/K6398-KTableValueGetter",2018-01-18 13:12:44,Guozhang Wang,Mixed
ca30c2d55b4f882fda34a13aff6f9ea510a959f6,"KAFKA-6366: Fix stack overflow in consumer due to many offset commits during coordinator disconnect (#4349)

When the coordinator is marked unknown, we explicitly disconnect its connection and cancel pending requests. Currently the disconnect happens before the coordinator state is set to null, which means that callbacks which inspect the coordinator state will see it still as active. If there are offset commit requests which need to be cancelled, each request callback will inspect the coordinator state and attempt to mark the coordinator dead again. In the worst case, if there are many pending offset commit requests that need to be cancelled, this can cause a stack overflow. To fix the problem, we need to set the coordinator to null prior to cancelling pending requests.

I have added a test case which reproduced the stack overflow with many pending offset commits. I have also added a basic test case to verify that callbacks for in-flight or unsent requests see the coordinator as unknown which prevents them from attempting to resend.

This patch also includes some minor cleanups which were noticed along the way.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2018-01-20 13:28:24,Jason Gustafson,Mixed
b814a16b968d144802d08523b5c359d6706f5632,"KAFKA-6241; Enable dynamic updates of broker SSL keystore (#4263)

Enable dynamic broker configuration (see KIP-226 for details). Includes
 - Base implementation to allow specific broker configs and custom configs to be dynamically updated
 - Extend DescribeConfigsRequest/Response to return all synonym configs and their sources in the order of precedence
 - Extend AdminClient to alter dynamic broker configs
 - Dynamic update of SSL keystores

Reviewers: Ted Yu <yuzhihong@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-01-23 08:44:31,Rajini Sivaram,Mixed
5e04fb8d8e55a5281bd40da9e1c99e9eb5e3c5f5,"KAFKA-6287; Consumer group command should list simple consumer groups (#4407)

With this patch, simple consumer groups which only use Kafka for offset storage will be viewable using the `--list` option in consumer-groups.sh. In addition, this patch fixes a bug in the offset loading logic which caused us to lose the protocol type of empty groups on coordinator failover. I also did some cleanup of the various consumer group command test cases.

For testing, I have added new integration tests which cover listing and describing simple consumer groups. I also added unit tests to cover loading empty groups with assertions on the protocol type.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2018-01-23 18:58:49,Jason Gustafson,Mixed
aa42a11dfd99ee9ab24d2e9a7521ef1c97ae1ff4,KAFKA-6180; Add a Validator for NonNull configurations and remove redundant null checks on lists (#4188),2018-01-24 21:06:44,Charly Molter,Mixed
7a246eea7b68851c3de5345d43f70853b4a15f21,"KAFKA-4897; Add pause method to ShutdownableThread (#4393)

 - Use newly added pause method in LogCleaner and ControllerChannelManager classes
 - Remove LogCleaner, Cleaner exclusions from findbugs-exclude.xml

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2018-01-25 12:39:20,Manikumar Reddy O,Not TDD
993d3c727e6f21931bf66c671358dfe7b0e1fae3,"KAFKA-6467; Enforce layout of dependencies within a connect plugin to be deterministic (#4459)

Adds alphanumeric ordering of dependencies as they added to a Connect plugin's class loader path. 

This makes the layout of the dependencies consistent across systems and deployments. Dependencies should still, in principle, not include conflicts and ideally order should not matter. 

Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-01-26 08:39:57,Konstantine Karantasis,Mixed
c615c597aa24cc5a4552102f1b6d27fcf4e24d12,"KAFKA-6205: initialize topology after state stores restoration completed

Initialize topology after state store restoration.
Although IMHO updating some of the existing tests demonstrates the correct order of operations, I'll probably add an integration test, but I wanted to get this PR in for feedback on the approach.

Author: Bill Bejeck <bill@confluent.io>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>

Closes #4415 from bbejeck/KAFKA-6205_restore_state_stores_before_initializing_topology

minor log4j edits",2018-01-26 09:34:55,Bill Bejeck,Mixed
70cecb6881f8b4f45cfd4780ef27f9fb9a8ce0b6,KAFKA-6244; Dynamic update of log cleaner configuration (#4465),2018-01-26 14:38:46,Rajini Sivaram,Mixed
e8b30e4d255dce455632d809f7bd54b04e6bc6fd,"MINOR: MetadataResponse#toStruct should serialize null leaders correctly. (#4449)

In MetadataResponse deserialization, if the partition leader key is set
to -1, the leader is set to null.  The MetadataResponse#toStruct code
should handle this correctly as well.

Also fix a case in KafkaApis where we were not taking into account the
possibility of the leader being null.

RequestResponseTest should test this as well.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2018-01-26 16:44:49,Colin Patrick McCabe,Not TDD
9b3722cea1845784853073d2a22764ec9fd5a8e5,"KAFKA-6245: Dynamic update of topic config defaults (#4466)

Dynamic update of default topic configs as described in KIP-226.",2018-01-27 12:22:05,Rajini Sivaram,Not TDD
1e04f5d2348d91fc18d4e0f330c231919663be1a,"MINOR: Fix Javadoc Issues (#4190)

This PR mainly fixes some broken links and invalid references in the clients Javadoc",2018-01-27 18:08:51,Vahid Hashemian,Mixed
a78f66a5ae7865418ee482c535e883598e1ec51f,"KAFKA-3625: Add public test utils for Kafka Streams (#4402)

* KAFKA-3625: Add public test utils for Kafka Streams
 - add new artifact test-utils
 - add TopologyTestDriver
 - add MockTime, TestRecord, add TestRecordFactory

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>, Bill Bejeck <bill@confluent.io>",2018-01-29 17:21:48,Matthias J. Sax,Mixed
05e42e1df12d87a29c8127dec23d7a9c290901d6,"KAFKA-6451: Simplifying KStreamReduce and KStreamAggregate

[KAFKA-6451](https://issues.apache.org/jira/browse/KAFKA-6451)

Simplified KStreamReduce and KStreamAggregate.
Updated comments in KStreamAggregate.

Author: Tanvi Jaywant <tanvijaywant@Tanvis-Air.home>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>

Closes #4477 from tanvijaywant31/KAFKA-6451",2018-01-29 17:28:49,Tanvi Jaywant,Not TDD
fdc14dacedc3d3497dcc222b44f539e6355b45a9,"MINOR: Code refacotring in KTable-KTable Join (#4486)

1. Rename KTableKTableJoin to KTableKTableInnerJoin. Also removed abstract from other joins.
2. Merge KTableKTableJoinValueGetter.java into KTableKTableInnerJoin.
3. Use set instead of arrays in the stores function, to avoid duplicate stores to be connected to processors.

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-01-29 17:48:53,Guozhang Wang,Mixed
b7a0c327cc24adf38e91c05af6f96a7271f2ab61,"KAFKA-6464: Fix Base64URL encode padding issue under JRE 1.7 (#4455)

The org.apache.kafka.common.utils.Base64 class defers Base64 encoding/decoding to the java.util.Base64 class beginning with JRE 1.8 but leverages javax.xml.bind.DatatypeConverter under JRE 1.7.  The implementation of the encodeToString(bytes[]) method returned under JRE 1.7 by Base64.urlEncoderNoPadding() blindly removed the last two trailing characters of the Base64 encoding under the assumption that they would always be the string ""=="" but that is incorrect; padding can be ""="", ""=="", or non-existent. This commit fixes that problem.

The commit also adds a Base64.urlDecoder() method that defers to java.util.Base64 under JRE 1.8+ but leverages javax.xml.bind.DatatypeConverter under JRE 1.7.

Finally, there is a unit test to confirm that encode/decode are inverses in both the Base64 and Base64URL cases.",2018-01-30 03:09:06,Ron Dagostino,Mixed
b4165522b3c244b67c0f88e4df9f0cd581a75bb0,"KAFKA-6148; ClassCastException in connectors that include kafka-clients packages (#4457)

Exclusion for packages that need not be loaded in isolation needs to be extended to all the `org.apache.kafka` packages (that do not belong to transforms and the other whitelisted packages). Most notably, this refers to any classes in `kafka-clients` package. 

Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-01-30 08:45:07,Konstantine Karantasis,Mixed
710aa678b7a6409296fb3c852a47c1876d8fa8e9,"KAFKA-6242: Dynamic resize of various broker thread pools (#4471)

Dynamic resize of broker thread pools as described in KIP-226:
  - num.network.threads
  - num.io.threads
  - num.replica.fetchers
  - num.recovery.threads.per.data.dir
  - background.threads

Reviewers: Jason Gustafson <jason@confluent.io>",2018-01-30 09:29:27,Rajini Sivaram,Not TDD
cb93d764613d801a1185989f09ce2d6b76009020,"KAFKA-6166: Streams configuration requires consumer. and producer. in order to be read (#4434)

* Implement method to get custom properties
* Add custom properties to getConsumerConfigs and getProducerConfigs
* Add tests

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-01-30 10:18:51,Filipe Agapito,Mixed
d97e63b26063c8fe629005ff61c8150317c88503,"KAFKA-6345; Keep a separate count of in-flight requests to avoid ConcurrentModificationException.

This keeps a separate count of the number of in flight requests so that sensor threads will not need to deal with ConcurrentModfiicationException.

This would probably still be correct with volatile rather than AtomicInteger, but FindBugs flags the use of volatile as the count is incremented and decremented.

Author: Sean McCauliff <smccauliff@linkedin.com>

Reviewers: Jiangjie (Becket) Qin <becket.qin@gmail.com>

Closes #4460 from smccauliff/KAFKA-6345",2018-01-30 10:20:08,Sean McCauliff,Mixed
70d3b19b1126ae64c214615adef590275f218ee7,"KAFKA-6243: Enable dynamic updates of broker metrics reporters (#4464)

Dynamic metrics reporter updates described in KIP-226. This includes:
  - Addition and removal of metrics reporters
  - Reconfiguration of custom metrics reporter configs
  - Tests for metrics reporter updates at default cluster-level and as per-broker config for testing

Reviewers: Jason Gustafson <jason@confluent.io>",2018-01-30 12:55:32,Rajini Sivaram,Not TDD
ef93998fa7e31f6222d6f0b12b9a01fa785faf48,KAFKA-6418; AdminClient should handle empty or null topic names better (#4470),2018-01-30 14:47:28,Colin Patrick McCabe,Mixed
3431be2aeb4f16599c419f89360856b72d0d335d,"KAFKA-4029: SSL support for Connect REST API (KIP-208)

This PR implements the JIRA issue [KAFKA-4029: SSL support for Connect REST API](https://issues.apache.org/jira/browse/KAFKA-4029) / [KIP-208](https://cwiki.apache.org/confluence/display/KAFKA/KIP-208%3A+Add+SSL+support+to+Kafka+Connect+REST+interface).

Summary of the main changes:
- Jetty `HttpClient` is used as HTTP client instead of the one shipped with Java. That allows to keep the SSL configuration for Server and Client be in single place (both use the Jetty `SslContextFactory`). It also has much richer configuration than the JDK client (it is easier to configure things such as supported cipher suites etc.).
- The `RestServer` class has been broker into 3 parts. `RestServer` contains the server it self. `RestClient` contains the HTTP client used for forwarding requests etc. and `SSLUtils` contain some helper classes for configuring SSL. One of the reasons for this was Findbugs complaining about the class complexity.
- A new method `valuesWithPrefixAllOrNothing` has been added to `AbstractConfig` to make it easier to handle the situation that we want to use either only the prefixed SSL options or only the non-prefixed. But not mixed them.

Author: Jakub Scholz <www@scholzj.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #4429 from scholzj/kip-208",2018-01-30 15:09:40,Jakub Scholz,Mixed
c6635e8d12fa5fed32ac75a727e62332fffa210b,"KAFKA-4969: Attempt to evenly distribute load of tasks (#4410)

* removed round-robin approach, try to assign tasks to consumers in a more even manner, added unit test.
* better interleaved task approach, updated tests

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <mjsax@apache.org>",2018-01-30 15:30:58,Bill Bejeck,Mixed
ae42cc803023c795eae00d138ea22a6a7951db31,"KAFKA-6018: Make KafkaFuture.Future an interface (KIP-218)

Changing KafkaFuture.Future and KafkaFuture.BiConsumer into an interface makes
them a functional interface.  This makes them Java 8 lambda compatible.

Author: Colin P. Mccabe <cmccabe@confluent.io>
Author: Steven Aerts <steven.aerts@gmail.com>

Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Xavier Léauté <xl+github@xvrl.net>, Tom Bentley <tbentley@redhat.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #4033 from steven-aerts/KAFKA-6018",2018-01-30 15:55:49,Steven Aerts,Mixed
15568fdbe753ea1c2e5fef571daf45e435999c07,"KAFKA-6323: punctuate with WALL_CLOCK_TIME triggered immediately (#4301)

This PR avoids unnecessary punctuation calls if punctuations are missed due to large time advances. It also aligns punctuation schedules to the epoch.

Author: Frederic Arno

Reviewers: Michal Borowiecki <michal.borowiecki@openbet.com>, Guozhang Wang <wangguoz@gmail.com>, Damian Guy <damian.guy@gmail.com>, Matthias J. Sax <matthias@confluent.io>",2018-01-30 18:18:55,fredfp,Mixed
530bc59de2732ba71e82c0110c59e9f6162531c6,"KAFKA-4930: Enforce set of legal characters for connector names (KIP-212)

…to check for empty connector name and illegal characters in connector name. This also fixes  KAFKA-4938 by removing the check for slashes in connector name from ConnectorsResource.

Author: Ewen Cheslack-Postava <me@ewencp.org>
Author: Soenke Liebau <soenke.liebau@opencore.com>

Reviewers: Gwen Shapira <cshapi@gmail.com>, Viktor Somogyi <viktor.somogyi@cloudera.com>, Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #2755 from soenkeliebau/KAFKA-4930",2018-01-31 08:49:23,Soenke Liebau,Mixed
4c48942f9d9e1428e21f934746cb7ce22b3df746,"KAFKA-5142: Add Connect support for message headers (KIP-145)

**[KIP-145](https://cwiki.apache.org/confluence/display/KAFKA/KIP-145+-+Expose+Record+Headers+in+Kafka+Connect) has been accepted, and this PR implements KIP-145 except without the SMTs.**

Changed the Connect API and runtime to support message headers as described in [KIP-145](https://cwiki.apache.org/confluence/display/KAFKA/KIP-145+-+Expose+Record+Headers+in+Kafka+Connect).

The new `Header` interface defines an immutable representation of a Kafka header (key-value pair) with support for the Connect value types and schemas. This interface provides methods for easily converting between many of the built-in primitive, structured, and logical data types.

The new `Headers` interface defines an ordered collection of headers and is used to track all headers associated with a `ConnectRecord` (and thus `SourceRecord` and `SinkRecord`). This does allow multiple headers with the same key. The `Headers` contains methods for adding, removing, finding, and modifying headers. Convenience methods allow connectors and transforms to easily use and modify the headers for a record.

A new `HeaderConverter` interface is also defined to enable the Connect runtime framework to be able to serialize and deserialize headers between the in-memory representation and Kafka’s byte[] representation. A new `SimpleHeaderConverter` implementation has been added, and this serializes to strings and deserializes by inferring the schemas (`Struct` header values are serialized without the schemas, so they can only be deserialized as `Map` instances without a schema.) The `StringConverter`, `JsonConverter`, and `ByteArrayConverter` have all been extended to also be `HeaderConverter` implementations. Each connector can be configured with a different header converter, although by default the `SimpleHeaderConverter` is used to serialize header values as strings without schemas.

Unit and integration tests are added for `ConnectHeader` and `ConnectHeaders`, the two implementation classes for headers. Additional test methods are added for the methods added to the `Converter` implementations. Finally, the `ConnectRecord` object is already used heavily, so only limited tests need to be added while quite a few of the existing tests already cover the changes.

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Arjun Satish <arjun@confluent.io>, Ted Yu <yuzhihong@gmail.com>, Magesh Nandakumar <magesh.n.kumar@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #4319 from rhauch/kafka-5142-b",2018-01-31 10:40:24,Randall Hauch,Mixed
1ed6da7cc8eb2231f73509c907c2e67af2f249d2,"KAFKA-6275: Add DeleteGroups API (KIP-229) (#4479)

Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-01-31 13:23:12,Vahid Hashemian,Mixed
c38a34559fd078be3ed30162619078f129802353,"MINOR: Fix brokerId passed to metrics reporters (#4497)

Remove caching of brokerId in DynamicBrokerConfig constructor and delay initialization until brokerId is set in KafkaConfig.

Reviewers: Jason Gustafson <jason@confluent.io>",2018-01-31 17:59:49,Rajini Sivaram,Not TDD
7804ea173bdbb0f401ad0135442c563fb52f895c,"KAFKA-6489; Fetcher.retrieveOffsetsByTimes() should batch the metadata fetch.

Currently if users call KafkaConsumer.offsetsForTimes() with a large set of partitions. The consumer will add one topic at a time for the metadata refresh. We should add all the topics to the metadata topics and just do one metadata refresh instead.

Author: Jiangjie Qin <becket.qin@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #4478 from becketqin/KAFKA-6849",2018-02-01 08:58:29,Jiangjie Qin,Mixed
4a2aa4bb6700c02b573c3ae71a40bdb8df5ab3a7,"KAFKA-6499: Do not write offset checkpoint file with empty offset map (#4492)

* In Checkpoint.write(), if the offset map passed in is empty, skip the writing of the file which would only contain version number and the empty size. From the reading pov, it is the same as no file existed.
* Add related unit tests.
* Minor fixes on log4j messages.

Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-02-01 10:11:29,Guozhang Wang,Mixed
86de4a86b87c1b45732303c07d263e317ffd0ebf,"KAFKA-6378: For KStream-GlobalKTable joins let null KeyValueMapper results indicate no match (#4494)

Reviewers: Damian Guy <damian@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-02-01 10:27:59,Andy Bryant,Mixed
afdf9a85101539e2afb2b0355d7a2008b3055780,"KAFKA-6492; Fix log truncation to empty segment

This patch ensures that truncation to an empty segment forces resizing of the index file in order to prevent premature rolling.

I have added unit tests which verify that appends are permitted following truncation to an empty segment. Without the fix, this test case reproduces the failure in which the rolled segment matches the current active segment.

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jiangjie (Becket) Qin <becket.qin@gmail.com>

Closes #4498 from hachikuji/KAFKA-6492",2018-02-01 11:57:52,Jason Gustafson,Mixed
b0132c31e91bb090ff012c726ac4ed92566ce7fb,"KAFKA-6487: ChangeLoggingKeyValueBytesStore does not propagate delete (#4495)

The ChangeLoggingKeyValueBytesStore used to write null to its underlying store instead of propagating the delete, which has two drawbacks:

* an iterator will see null values
* unbounded memory growth of the underlying in-memory keyvalue store

The fix will just propagate the delete instead of performing put(key, null).

The changes to the tests:

*extra test whether the key is really gone after delete by calling the approximateEntries on the underlying store. This number is exact because we know the underlying store in the test is of type InMemoryKeyValueStore
* extra test to check a delete is logged as <key, null> (the existing test would also succeed if the key is just absent)

While also updating the corresponding tests of the ChangeLoggingKeyValueStore I noticed the class is nowhere used anymore so I removed it from the source code for clarity.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-02-01 16:14:22,bartdevylder,Mixed
505adefcecc6e7282b73f934aa8c7a59adcb675e,"KAFKA-6494; ConfigCommand update to use AdminClient for broker configs (#4503)

Use new AdminClient for describing and altering broker configs using ConfigCommand. Broker quota configs as well as other configs will continue to be processed directly using ZooKeeper until KIP-248 is implemented.

Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-02-02 16:31:58,Rajini Sivaram,Mixed
4019b21d602c0912d9dc0286f10701e7e724f750,"KAFKA-6246; Dynamic update of listeners and security configs (#4488)

Dynamic update of listeners as described in KIP-226. This includes:
  - Addition of new listeners with listener-prefixed security configs
  - Removal of existing listeners
  - Password encryption
  - sasl.jaas.config property for broker's JAAS config prefixed with listener and mechanism name",2018-02-04 09:19:16,Rajini Sivaram,Mixed
eb3fef760e1c876b936f175e0eb9a1446cf5bdcf,"KAFKA-6253: Improve sink connector topic regex validation

KAFKA-3073 added topic regex support for sink connectors. The addition requires that you only specify one of topics or topics.regex settings. This is being validated in one place, but not during submission of connectors. This PR adds validation at `AbstractHerder.validateConnectorConfig` and `WorkerConnector.initialize`.

This adds a test of the new behavior to `AbstractHerderTest`.

Author: Jeff Klukas <jeff@klukas.net>

Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #4251 from jklukas/connect-topics-validation",2018-02-05 09:46:07,Jeff Klukas,Mixed
7fe1c2b3d3a78ea3ffb9e269563653626861fbd2,"KAFKA-6254; Incremental fetch requests

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>

Closes #4418 from cmccabe/KAFKA-6254",2018-02-05 10:09:17,Colin P. Mccabe,Mixed
65d262cc30315ed47bd17e94c0db672de93d908a,"KAFKA-6528: Fix transient test failure in testThreadPoolResize (#4526)

Add locking to access AbstractFetcherThread#partitionStates during dynamic thread update. Also make testing of thread updates that trigger retries more resilient.

Reviewers: Jason Gustafson <jason@confluent.io>",2018-02-06 01:50:51,Rajini Sivaram,Not TDD
7d70a427b2689c0a1de4345db4b04ea557b4c27b,"KAFKA-6504: Ensure uniqueness of connect task metric sensor creation (#4514)

This change ensures that when sensors are created, they are unique to the metric group associated with the task that created them. Previously the sensors were being shared between task metric groups, causing incorrect metrics.

Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-02-06 09:18:37,Robert Yokota,Mixed
7c97b239a5261cf030984f71427287196e657d95,"KAFKA-6184; report a metric of the lag between the consumer offset ...

Add `records-lead` and partition-level `{topic}-{partition}.records-lead-min|avg` for fetcher metrics.

junrao  Please kindly review. Thanks.

Author: huxihx <huxi_2b@hotmail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #4191 from huxihx/KAFKA-6184",2018-02-06 10:40:51,huxihx,Mixed
c32860b22427ca32a9e83e4f741b85062bb22140,"MINOR:  exchange redundant Collections.addAll with parameterized constructor (#4521)

* Exchange manual copy to collection with Collections.addAll call
* Exchange redundant Collections.addAll with parameterized constructor call

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2018-02-06 11:33:49,Wladimir Schmidt,Not TDD
a88db9595910a1a7f249f7c9f3effb14636955c7,"KAFKA-4750: Bypass null value and treat it as deletes (#4508)

Here is the new rule for handling nulls:
* in the interface store, put(key, null) are handled normally and value serde will still be applied to null, hence needs to handle null values
* in the inner bytes store, null bytes after serialization will be treated as deletes.
* in the interface store, if null bytes get returned in get(key), it indicate the key is not available; and hence serde will be avoided and null object will be returned.

More changes:
* Update javadocs, add unit tests accordingly; augment MockContext to set serdes for the newly added tests.
* Fixed a discovered bug which is exposed by the newly added tests.
* Use the new API to remove all old APIs in the existing state store tests.
* Remove SerializedKeyValueIterator since it is not used any more.

This is originally contributed by @evis.

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian@confluent.io>",2018-02-06 13:14:33,Guozhang Wang,Mixed
65b5ccf6413369aa4f21c72abcdf31ca72a79b00,"KAFKA-6532: Reduce impact of delegation tokens on public interfaces (#4524)

Keep delegation token implementation internal without exposing implementation details to pluggable classes:
  1. KafkaPrincipal#tokenAuthenticated must always be set by SaslServerAuthenticator so that custom PrincipalBuilders cannot override.
  2. Replace o.a.k.c.security.scram.DelegationTokenAuthenticationCallback with a more generic ScramExtensionsCallback that can be used to add more extensions in future.
  3. Separate out ScramCredentialCallback (KIP-86 makes this a public interface) from delegation token credential callback (which is internal).

Reviewers: Jun Rao <junrao@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2018-02-07 03:29:08,Rajini Sivaram,Mixed
263a510676ee0173cbaa11b5de1de4c19d2f5202,"KAFKA-6367: StateRestoreListener use actual last restored offset for restored batch (#4507)

Author: Bill Bejeck <bill@confluent.io>

Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-02-07 11:07:32,Bill Bejeck,Mixed
5d69a79948bce0fab4705c7d7d0f3b02f2548c0d,"KAFKA-4641: Add more unit test for stream thread (#4531)

Before the patch, jacoco coverage test:

Element	Missed Instructions	Cov.	Missed Branches	Cov.	Missed	Cxty	Missed	Lines	Missed	Methods	Missed	Classes
Total	3,386 of 22,177	84%	336 of 1,639	79%	350	1,589	526	4,451	103	768	1	102
StreamThread	 	77%	 	76%	27	102	48	299	1	31	0	1
After the patch:

Element	Missed Instructions	Cov.	Missed Branches	Cov.	Missed	Cxty	Missed	Lines	Missed	Methods	Missed	Classes
Total	3,329 of 22,180	84%	329 of 1,639	79%	345	1,590	516	4,452	102	769	1	102
StreamThread	 	81%	 	80%	23	103	39	300	1	32	0	1


Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Damian Guy <damian@confluent.io>",2018-02-07 14:08:53,Guozhang Wang,Mixed
67803384d9b7959661bb2a32129b03a374507c8a,"MINOR: adding system tests for how streams functions with broker faiures (#4513)

System test for two cases:

* Starting a multi-node streams application with the broker down initially, broker starts and confirm rebalance completes and streams application still able to process records.

* Multi-node streams app running, broker goes down, stop stream instance(s) confirm after broker comes back remaining streams instance(s) still function.

Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-02-07 17:21:35,Bill Bejeck,Not TDD
ac267dc5cec605f3981c9db7d889cabd59f09a61,"KAFKA-6362; Async auto-commit should discover coordinator if it is unknown (#4326)

Currently `maybeAutoCommitOffsetsAsync` does not try to find the coordinator if it is unknown. As a result, asynchronous auto-commits will fail indefinitely. This patch changes the behavior to add coordinator discovery to the async auto-commit path.",2018-02-08 09:49:12,huxi,Mixed
a1352f8c5a96c8e861c17c8105557428a47f4334,"MINOR: Add missing generics and surpress warning annotations (#4518)

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-02-08 13:21:56,Matthias J. Sax,Mixed
77a6104f548a42851cd44ca0ce73145784f924d3,"KAFKA-3625: add docs for Kafka Streams test-utils (follow up) (#4493)

Adds web page docs for KIP-247

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>, Joel Hamill <joel@confluent.io>, Damian Guy <damian@confluent.io>",2018-02-08 13:35:57,Matthias J. Sax,Not TDD
15bc40507b06cccd1777e94b83ef8e5a9bdc9bc1,"KAFKA-6501; Dynamic broker config tests updates and metrics fix (#4539)

1. Handle listener-not-found in MetadataCache since this can occur when listeners are being updated. To avoid breaking clients, this is handled in the same way as broker-not-available so that clients may retry.
2. Set retries=1000 for listener reconfiguration tests to avoid transient failures when metadata cache has not been updated 
3. Remove IdlePercent metric when Processor is deleted, add test
4. Reduce log segment size used during reconfiguration to avoid timeout while waiting for log rolling
5.Test markPartitionsForTruncation after fetcher thread resize
6. Move per-processor ResponseQueueSize metric back to RequestChannel.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2018-02-08 16:22:51,Rajini Sivaram,Mixed
fc56a90e05a922722859ebc594736d6e7d3514ba,"KAFKA-6529: Stop file descriptor leak when client disconnects with staged receives (#4517)

If an exception is encountered while sending data to a client connection, that connection is disconnected. If there are staged receives for that connection, they are tracked to process those records. However, if the exception was encountered during processing a `RequestChannel.Request`, the `KafkaChannel` for that connection is muted and won't be processed.

Disable processing of outstanding staged receives if a send fails. This stops the leak of the memory for pending requests and the file descriptor of the TCP socket.

Test that a channel is closed when an exception is raised while writing to a socket that has been closed by the client. Since sending a response requires acks != 0, allow specifying the required acks for test requests in SocketServerTest.scala.

Author: Graham Campbell <graham.campbell@salesforce.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>, Ted Yu <yuzhihong@gmail.com>",2018-02-09 04:59:18,parafiend,Not TDD
976a3b0cc858d4a13cf8b34b325aefc8d706be9e,"KAFKA-6513: Corrected how Converters and HeaderConverters are instantiated and configured

The commits for KIP-145 (KAFKA-5142) changed how the Connect workers instantiate and configure the Converters, and also added the ability to do the same for the new HeaderConverters. However, the last few commits removed the default value for the `converter.type` property for Converters and HeaderConverters, and this broke how the internal converters were being created.

This change corrects the behavior so that the `converter.type` property is always set by the worker (or by the Plugins class), which means the existing Converter implementations will not have to do this. The built-in JsonConverter, ByteArrayConverter, and StringConverter also implement HeaderConverter which implements Configurable, but the Worker and Plugins methods do not yet use the `Configurable.configure(Map)` method and instead still use the `Converter.configure(Map,boolean)`.

Several tests were modified, and a new PluginsTest was added to verify the new behavior in Plugins for instantiating and configuring the Converter and HeaderConverter instances.

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #4512 from rhauch/kafka-6513",2018-02-09 15:47:44,Randall Hauch,Mixed
9f4fe7679e96f0ca38a9f0bc0b43797ec0bf23e0,"KAFKA-5550; Connect Struct.put() should include the field name if validation fails (#3507)

Changed call to use the overload of ConnectSchema.validateValue() method with the field name passed in. Ensure that field in put call is not null.

Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-02-12 09:16:25,Jeremy Custenborder,Mixed
596d3d0ec4ee1ba719ce87e464a095bd63ab72be,KAFKA-5944: Unit tests for handling SASL authentication failures in clients (#3965),2018-02-12 14:29:44,Vahid Hashemian,Not TDD
a68a8b6b6cc47d488ada99e4bfe87cc7467621bb,"KAFKA-6511; Corrected connect list/map parsing logic (#4516)

Corrected the parsing of invalid list values. A list can only be parsed if it contains elements that have a common type, and a map can only be parsed if it contains keys with a common type and values with a common type.

Reviewers: Arjun Satish <arjun@confluent.io>, Magesh Nandakumar <magesh.n.kumar@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Jason Gustafson <jason@confluent.io>",2018-02-13 11:44:12,Randall Hauch,Mixed
d902b6b4b6bcf1cc1c488f6a975db8beed5689a6,"KAFKA-5996; JsonConverter generates Mismatching schema DataException (#4523)

JsonConverter should use object equality rather than reference equality in `convertToJson`.

Reviewers: Bartlomiej Tartanus <bartektartanus@gmail.com>, Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-02-14 08:46:22,ConcurrencyPractitioner,Mixed
f3a3253e24d63cbfcbd42c8a550a3f898c734044,"HOTFIX: Fix reset integration test hangs on busy wait (#4491)

* do not use static properties
* use new object to take appID
* capture timeout exception inside condition

Reviewers: Matthias J. Sax <matthias@confluent.io>",2018-02-14 08:49:23,Guozhang Wang,Not TDD
6d18d882b850a8d757c32bb124b1e42e60587c69,"KAFKA-6397: Consumer should not block setting positions of unavailable partitions (#4557)

Prior to this patch, the consumer always blocks in poll() if there are any partitions which are awaiting their initial positions. This behavior was inconsistent with normal fetch behavior since we allow fetching on available partitions even if one or more of the assigned partitions becomes unavailable _after_ initial offset lookup. With this patch, the consumer will do offset resets asynchronously, which allows other partitions to make progress even if the initial positions for some partitions cannot be found.

I have added several new unit tests in `FetcherTest` and `KafkaConsumerTest` to verify the new behavior. One minor compatibility implication worth mentioning is apparent from the change I made in `DynamicBrokerReconfigurationTest`. Previously it was possible to assume that all partitions had a fetch position after `poll()` completed with a non-empty assignment. This assumption is no longer generally true, but you can force the positions to be updated using the `position()` API which still blocks indefinitely until a position is available.

Note that this this patch also removes the logic to cache committed offsets in `SubscriptionState` since it was no longer needed (the consumer's `committed()` API always does an offset lookup anyway). In addition to avoiding the complexity of maintaining the cache, this avoids wasteful offset lookups to refresh the cache when `commitAsync()` is used.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2018-02-14 10:52:46,Jason Gustafson,Mixed
27b56b1458d0af0a397e9f47ecd008c10c088c6d,"KAFKA-6364: Second check for ensuring changelog topic not changed during restore (#4511)

Added a second check for race condition where store changelog topic updated during restore, but not if a KTable changelog topic. This will be tricky to test, but I wanted to push the PR to get feedback on the approach.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <matthias@confluent.io>",2018-02-14 12:43:57,Bill Bejeck,Mixed
38e9958d6e5d2224fbb9a54d04b1505ad561e8a3,"KAFKA-6476: Documentation for dynamic broker configuration (#4558)

Docs for dynamic broker configuration (KIP-226)",2018-02-14 22:09:45,Rajini Sivaram,Mixed
50cd85538580c9c9833ad957d64d39953c124374,"HOTFIX: Fix lgtm.com alerts (dead code and out-of-bounds error) (#4388)

This fixes two alerts flagged on lgtm.com for Apache Kafka.

This dead code alert where InvalidTypeIdException indirectly extends JsonMappingException. The flagged condition with the type test appears after the type test for the latter and thus makes its body dead. I opted to change the order of the tests. Please let me know if this is the intended behavior.

The second commit addresses this out-of-bounds alert.

More alerts can be found here. Note that my colleague Aditya Sharad addressed some of those in the now outdated #2939.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2018-02-14 17:02:47,Sebastian Bauersfeld,Mixed
015e224b3d3c8e7bc412686ff22d5e99324b1019,"MINOR: Support dynamic JAAS config for broker's LoginManager cache (#4568)

Fix LoginManager caching when sasl.jaas.config is defined for broker and add unit tests.

Reviewers: Jason Gustafson <jason@confluent.io>",2018-02-15 09:26:34,Rajini Sivaram,Mixed
d9d0d79287eeec0a1c3dcc2203288421284b5ca1,"MINOR: Update test classes to use KafkaZkClient methods (#4367)

Remove ZkUtils reference form ZooKeeperTestHarness plus some minor cleanups.",2018-02-15 08:41:38,Manikumar Reddy O,Mixed
1067cc3422e6f2731ae57df9f01e84f2242a60be,"KAFKA-6512: Discard references to buffers used for compression (#4570)

ProducerBatch retains references to MemoryRecordsBuilder and cannot be freed until acks are received. Removing references to buffers used for compression after records are built will enable these to be garbage collected sooner, reducing the risk of OOM.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>, Lothsahn <Lothsahn@gmail.com>",2018-02-15 17:36:44,Rajini Sivaram,Mixed
bce8125dcf5a87ed29bbe795cd7591d45bdf3d9a,"MINOR: Resuming Tasks should not be initialized twice (#4562)

Avoids double initialization of resuming tasks
Removes race condition in StreamThreadTest plus code cleanup

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-02-15 10:52:58,Matthias J. Sax,Not TDD
c72062ddc089c338a3017aff6db702ca74e56847,"KAFKA-6517: Avoid deadlock in ZooKeeperClient during session expiry (#4551)

ZooKeeperClient acquires initializationLock#writeLock to establish a new connection while processing session expiry WatchEvent. ZooKeeperClient#handleRequests acquires initializationLock#readLock, allowing multiple batches of requests to be processed concurrently, but preventing reconnections while processing requests. At the moment, handleRequests holds onto the readLock throughout the method, even while waiting for responses and inflight requests to complete. But responses cannot be delivered if event thread is blocked on the writeLock to process session expiry event. This results in a deadlock. During broker shutdown, the shutdown thread is also blocked since it needs the readLock to perform ZooKeeperClient#unregisterStateChangeHandler, which cannot be acquired if a session expiry had occurred earlier since this thread gets queued behind the event handler thread waiting for writeLock.

This commit reduces locking in ZooKeeperClient#handleRequests to just the non-blocking send, so that session expiry handling doesn't get blocked when a send is blocked waiting for responses. Also moves session expiry handling to a separate thread so that Kafka controller doesn't block the event handler thread when processing session expiry.",2018-02-15 20:21:12,Rajini Sivaram,Mixed
f12d237fdd47302d1c6c77553db986dd6dda568a,"MINOR: Free sends in MultiSend as they complete (#4574)

Currently we hold onto all Records references in a multi-partition fetch response until the full response has completed. This can be a problem when the records have been down-converted since they will be occupying a (potentially large) chunk of memory. This patch changes the behavior in MultiSend so that once a Send is completed, we no longer keep a reference to it, which will allow the Records objects to be freed sooner.

I have added a simple unit test to verify that sends are removed as the MultiSend progresses.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-02-16 07:58:49,Jason Gustafson,Mixed
0b3b6049f002acf040a5312cef35c87f199bbfd2,"MINOR: Fix Streams EOS system tests (#4572)

Avoid loosing log/stdout/stderr files on restart
Reenables tests

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",2018-02-16 13:13:13,Matthias J. Sax,Not TDD
b20639db4489a264d25ca5ad6f5b78489cc3fb0f,"MINOR: Enable deep-iteration to print data in DumpLogSegments (#4396)

Enable deep-iteration option when print-data-log is enabled in DumpLogSegments. Otherwise data is not printed.

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2018-02-16 23:20:16,Rajini Sivaram,Mixed
7c09b9410a63a1dda118b872afcbd2fcdcd56b65,"KAFKA-6568; Log cleaner should check partition state before removal from inProgress map  (#4580)

The log cleaner should not naively remove the partition from in progress map without checking the partition state. This may cause the other thread calling `LogCleanerManager.abortAndPauseCleaning()` to hang indefinitely.",2018-02-16 18:04:21,Jiangjie (Becket) Qin,Mixed
ee352be9c88663b95b1096b7a294e61857857380,"MINOR: Fix bug introduced by adding batch.size without default in FileStreamSourceConnector (#4579)

https://github.com/apache/kafka/pull/4356 added `batch.size` config property to `FileStreamSourceConnector` but the property was added as required without a default in config definition (`ConfigDef`). This results in validation error during connector startup. 

Unit tests were added for both `FileStreamSourceConnector` and `FileStreamSinkConnector` to avoid such issues in the future.

Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-02-16 18:30:12,Konstantine Karantasis,Mixed
1547cf6de86bbb8f7bacc26ab9ab89d4c9ec5566,"KAFKA-6554; Missing lastOffsetDelta validation before log append (#4585)

Add validation checks that the offset range is valid and aligned with the batch count prior to appending to the log. Several unit tests have been added to verify the various invalid cases.",2018-02-20 09:32:09,Jason Gustafson,Mixed
a41373309497da449a1f757e2c24399794d77072,"KAFKA-6568: Minor clean-ups follow-up (#4592)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-02-20 07:19:30,Jiangjie (Becket) Qin,Mixed
ac2536e77e43510cde6009146487a5f867bf9b3f,KAFKA-5624; Add expiry check to sensor.add() methods (#4404),2018-02-20 08:57:21,Manikumar Reddy O,Mixed
eaafbdecb56d11f66d833b63fbc2aced65990e69,"MINOR: Fix logger name override (#4600)

This regressed during the log4j -> scalalogging change.
Added unit tests, one of which failed before the fix.",2018-02-20 20:42:05,Ismael Juma,Mixed
256708dbbb7204e4025f2ca74eceea1170236255,"KAFKA-4651: improve test coverage of stores (#4555)

Working on increasing the coverage of stores in unit tests.  
Started with `InMemoryKeyValueLoggedStore` 

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-02-20 12:46:36,Bill Bejeck,Mixed
660c0c0aa33ced5307ee70bfdb78ebde4b978d73,"KAFKA-6238; Fix inter-broker protocol message format compatibility check

This patch fixes a bug in the validation of the inter-broker protocol and the message format version. We should allow the configured message format api version to be greater than the inter-broker protocol api version as long as the actual message format versions are equal. For example, if the message format version is set to 1.0, it is fine for the inter-broker protocol version to be 0.11.0 because they both use message format v2.

I have added a unit test which checks compatibility for all combinations of the message format version and the inter-broker protocol version.

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #4583 from hachikuji/KAFKA-6328-REOPENED",2018-02-21 09:38:39,Jason Gustafson,Mixed
90e0bbec94dd85e1c5b1af0b6426df0a02e5da3f,"KAFKA-6573: Update brokerInfo in KafkaController on listener update (#4603)

Update `KafkaController.brokerInfo` when listeners are updated since this value is used to register the broker in ZooKeeper if there ZK session expires. Also added test to verify values in ZK after session expiry.",2018-02-21 08:43:25,Rajini Sivaram,Mixed
fc19c3e6f243a8d1b3e27cdc912dc092bbd342e0,"KAFKA-6577: Fix Connect system tests and add debug messages

**NOTE: This should be backported to the `1.1` branch, and is currently a blocker for 1.1.**

The `connect_test.py::ConnectStandaloneFileTest.test_file_source_and_sink` system test is failing with the SASL configuration without a sufficient explanation. During the test, the Connect worker fails to start, but the Connect log contains no useful information. There are actual several things compounding to cause the failure and make it difficult to understand the problem.

First, the `tests/kafkatest/tests/connect/templates/connect_standalone.properties` is only adding in the broker's security configuration with the `producer.` and `consumer.` prefixes, but is not adding them with no prefix. The worker uses the AdminClient to connect to the broker to get the Kafka cluster ID and to manage the three internal topics, and the AdminClient is configured via top-level properties. Because the SASL test requires the clients all connect using SASL, the lack of broker security configs means the AdminClient was attempting and failing to connect to the broker. This is corrected by adding the broker's security configuration to the Connect worker configuration file at the top-level. (This was already being done in the `connect_distributed.properties` file.)

Second, the default `request.timeout.ms` for the AdminClient (and the other clients) is 120 seconds, so the AdminClient was retrying for 120 seconds before it would give up and thrown an error. However, the test was only waiting for 60 seconds before determining that the service failed to start. This can be corrected by setting `request.timeout.ms=10000` in the Connect distributed and standalone worker configurations.

Third, the Connect workers were recently changed to lookup the Kafka cluster ID before it started the herder. This is unlike the older uses of the AdminClient to find and manage the internal topics, where failure to connect was not necessarily logged correctly but nevertheless still skipped over, relying upon broker auto-topic creation to create the internal topics. (This may be why the test did not fail prior to the recent change to always require a successful AdminClient connection.) Although the worker never got this far in its startup process, the fact that we missed such an error since the prior releases means that failure to connect with the AdminClient was not being properly reported.

The `ConnectStandaloneFileTest.test_file_source_and_sink` system tests were run locally prior to this fix, and they failed as with the nightlies. Once these fixes were made, the locally run system tests passed.

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <me@ewencp.org>

Closes #4610 from rhauch/kafka-6577-trunk",2018-02-22 09:39:59,Randall Hauch,Mixed
66039b1312be6356a3cb12efa8e562d2264498d1,MINOR: Fix ConcurrentModificationException in TransactionManager (#4608),2018-02-22 22:23:14,Colin Patrick McCabe,Mixed
e26d0d760466c3da6189637a7de69eb5509e7b51,"MINOR: Revert incompatible behavior change to consumer reset tool (#4611)

This patch reverts the removal of the --execute option in the offset reset tool and the change to the default behavior when no options were present. For consistency, this patch adds the --execute flag to the streams reset tool, but keeps its current default behavior. A note has been added to both of these commands to warn the user that future default behavior will be to prompt before acting.

Test cases were not actually validating that offsets were committed when the --execute option was present, so I have fixed that and added basic assertions for the dry-run behavior. I also removed some duplicated test boilerplate.

Reviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",2018-02-23 15:31:50,Jason Gustafson,Mixed
99d650c2c882cc1f359a1dbb5fc6bea2d5b303b6,"KAFKA-6590; Fix bug in aggregation of consumer fetch bytes and counts metrics (#4278)

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-02-24 18:43:10,Igor Kostiakov,Mixed
5df535e8a349771942050f1e3fd58851f413fa3a,"MINOR: fixes lgtm.com warnings (#4582)

fixes lgmt.com warnings
cleanup PrintForeachAction and Printed

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Sebastian Bauersfeld <sebastianbauersfeld@gmx.de>, Damian Guy <damian@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-02-25 12:26:18,Matthias J. Sax,Mixed
2591a469305532ba79497dd435f58a9051b689db,"KAFKA-5327; Console Consumer should not commit messages not printed (#4546)

Ensure that the consumer's offsets are reset prior to closing so that any buffered messages which haven't been printed are not committed.",2018-02-26 11:26:34,huxi,Mixed
f26fbb9adcd66a31740da5c99f14a108bbc24304,"MINOR: Rename stream partition assignor to streams partition assignor (#4621)

This is a straight-forward change that make the name of the partition assignor to be aligned with Streams.

Reviewers: Matthias J. Sax <mjsax@apache.org>",2018-02-26 14:39:47,Guozhang Wang,Mixed
97ad549d56d3432b0c70e72d402ebec1d07f8273,"KAFKA-6534: Enforce a rebalance in the next poll call when encounter task migration (#4544)

The fix is in two folds:

For tasks that's closed in closeZombieTask, their corresponding partitions are still in runningByPartition so those closed tasks may still be returned in activeTasks and standbyTasks. Adding guards on the returned tasks and if they are closed notify the thread to trigger rebalance immediately.

When triggering a rebalance, un-subscribe and re-subscribe immediately to make sure we are not dependent on the background heartbeat thread timing.

Some minor changes on log4j. More specifically, I moved the log entry of closeZombieTask to its callers with more context information and the action going to take.

I can re-produce the issue with EosIntegrationTest may hand-code the heartbeat thread to GC, and confirmed this patch fixed the issue. Unfortunately this test cannot be added to AK since currently we do not have ways to manipulate the heartbeat thread in unit tests.

Reviewers: Jason Gustafson <jason@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-02-27 00:29:25,Guozhang Wang,Not TDD
eb449fe7c55a0816328a851fc1102dfeac6d8616,"KAFKA-6560: Replace range query with newly added single point query in Windowed Aggregation (#4578)

* Add a new fetch(K key, long window-start-timestamp) API into ReadOnlyWindowStore.
* Use the new API to replace the range fetch API in KStreamWindowedAggregate and KStreamWindowedReduce.
* Added corresponding unit tests.
* Also removed some redundant byte serdes in byte stores.",2018-03-01 09:27:11,Guozhang Wang,Mixed
6cfcc9d553622e7d511a849935e9b504f947399d,"KAFKA-6593; Fix livelock with consumer heartbeat thread in commitSync (#4625)

Contention for the lock in ConsumerNetworkClient can lead to a livelock situation in which an active commitSync is unable to make progress because its completion is blocked in the heartbeat thread. The fix is twofold:

1) We change ConsumerNetworkClient to use a fair lock to reduce the chance of each thread getting starved.
2) We eliminate the dependence on the lock in ConsumerNetworkClient for callback completion so that callbacks will not be blocked by an active poll().

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2018-03-01 11:04:11,Jason Gustafson,Mixed
9868976747fb4a7a4a9b18e1f4050633c226be7d,"KAFKA-6111: Improve test coverage of KafkaZkClient, fix bugs found by new tests;",2018-03-02 11:25:43,Sandor Murakozi,Mixed
604b93cfdee7a8c5c879ef2217d50be88e39ac89,"KAFKA-6606; Ensure consumer awaits auto-commit interval after sending… (#4641)

We need to reset the auto-commit deadline after sending the offset commit request so that we do not resend it while the request is still inflight. 

Added unit tests ensuring this behavior and proper backoff in the case of a failure.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2018-03-03 13:27:29,Jason Gustafson,Mixed
2a4ba75e1338eaa97da87077330b43d7448a18bc,"KAFKA-6054: Code cleanup to prepare the actual fix for an upgrade path (#4630)

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-03-05 10:56:42,Matthias J. Sax,Mixed
8a7d7e7955889125b1196caeded6fa57d93a0b46,"MINOR: Add System test for standby task-rebalancing (#4554)

Author: Bill Bejeck <bill@confluent.io>

Reviewers: Damian Guy <damian@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-03-05 11:06:32,Bill Bejeck,Not TDD
8f2c08716630eba7e3badacc79be4c8c413a00da,"MINOR: Complete inflight requests in order on disconnect (#4642)

NetworkClient should use FIFO order when completing inflight requests following a disconnect.

I've added new unit tests for `InFlightRequests` and `NetworkClient` which verify completion order.

Reviewers: Jun Rao <junrao@gmail.com>",2018-03-05 16:48:05,Jason Gustafson,Mixed
a1b01f48e9ef06291f3e052a37bde887b891e708,"KAFKA-6309: Improve task assignor load balance (#4624)

Sorts TaskIds on first assignment evenly distributing tasks by topicGroupId should help with evening the load of work across topologies. This PR is an initial ""strawman"" approach which will be followed up (at a later date YTBD) by scoring or assigning weight to processing nodes to ensure even processing distribution.

Added a new test to existing unit test.",2018-03-05 21:24:22,Bill Bejeck,Mixed
d13cbd0cae26d13c36c25d04a489ee309187ebeb,"KAFKA-3806: Increase offsets retention default to 7 days (KIP-186) (#4648)

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2018-03-05 22:21:53,Ewen Cheslack-Postava,Not TDD
e5d6c9a79a4ca9b82502b8e7f503d86ddaddb7fb,"MINOR: Do not start processor for bounce-at-start (#4639)

Only start it after the broker has been shutdown.",2018-03-06 11:19:38,Guozhang Wang,Not TDD
cf092aeecc473b70d81c00b604e29de8c9f6d84b,"KAFKA-5660 Don't throw TopologyBuilderException during runtime (#4645)

Reviewers: Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-03-06 17:49:33,nafshartous,Not TDD
925d6a2ef363ee540e65f7ec3b699dce05aa591c,"MINOR: Skip sending fetches/offset lookups when awaiting the reconnect backoff (#4644)

Logging can get spammy during the reconnect blackout period because any requests we send to ConsumerNetworkClient will immediately be failed when poll() returns. This patch checks for connection failures prior to sending fetches and offset lookups and skips sending to any failed nodes. Test cases added for both.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2018-03-08 11:00:20,Jason Gustafson,Mixed
989088f697a221bc2b7b1d0d0ae6e9d03b2bf8ac,"KAFKA-6560: [FOLLOW-UP] don't deserialize null byte array in window store fetch (#4665)

If the result of a fetch from a Window Store results in a null byte array we should return null rather than passing it to the serde to deserialize.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2018-03-08 13:24:22,Damian Guy,Mixed
3ef2fb843e873a4597b1d1d068144102271d3002,"MINOR: Fix record conversion time in metrics (#4671)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-03-09 16:50:34,Rajini Sivaram,Mixed
b1aa1912f08765d9914e3d036deee6b71ea009dd,"KAFKA-4831: Extract WindowedSerde to public APIs (#3307)

Now that we have augmented WindowSerde with non-arg parameters, extract it out as part of the public APIs so that users who want to I/O windowed streams can use it. This is originally introduced by @vitaly-pushkar

This PR grows out to be a much larger one, as I found a few tech debts and bugs while working on it. Here is a summary of the PR:

Public API changes (I will propose a KIP after a first round of reviews):
Add TimeWindowedSerializer, TimeWindowedDeserializer, SessionWindowedSerializer, SessionWindowedDeserializer into o.a.k.streams.kstream. The serializers would implemented an internal WindowedSerializer interface for the serializeBaseKey function used in 3) below.

Add WindowedSerdes into o.a.k.streams.kstream. The reason to now add them into o.a.k.clients's Serdes is that it then needs dependency of streams.

Add ""default.windowed.key.serde.inner"" and ""default.windowed.value.serde.inner"" into StreamsConfig, used when ""default.key.serde"" is specified to use time or session windowed serde. Note this requires the serde class, not the type class.

Consolidated serde format from multiple classes, including SessionKeySerde.java for session, and WindowStoreUtils for time window, into SessionKeySchema and WindowKeySchema.

Bug fix: WindowedStreamPartitioner needs to consider both time window and session window serdes.

Removed RocksDBWindowBytesStore etc optimization since after KIP-182 all the serde know happens on metered store, hence this optimization is not worth.

Bug fix: for time window, the serdes used for store and the serdes used for piping (source and sink node) are different: the former needs to append sequence number but not for the later.

Other minor cleanups: remove unnecessary throws, etc.

Authors: Guozhang Wang <wangguoz@gmail.com>, Vitaly Pushkar <vitaly.pushkar@gmail.com>

Reviewers: Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bill@confluent.io>, Xi Hu",2018-03-09 11:08:08,Vitaly Pushkar,Mixed
f1c112c63d8223e62cf9e2f31cc42321f1e6dada,"MINOR: Add PayloadGenerator to Trogdor (#4640)

It generates the producer payload (key and value) and makes sure that the values are
populated to target a realistic compression rate (0.3 - 0.4) if compression is used.
The generated payload is deterministic and can be replayed from a given position.
For now, all generated values are constant size, and key types can be configured
to be either null or 8 bytes.

Added messageSize parameter to producer spec, that specifies produced
key + message size.",2018-03-09 13:57:04,Anna Povzner,Mixed
8d4d5f8c9ffeba45022014bdcf98eddbd3a3afc8,"MINOR: Fix deadlock in ZooKeeperClient.close() on session expiry (#4672)

Reviewers: Jun Rao <junrao@gmail.com>",2018-03-09 15:18:23,Rajini Sivaram,Mixed
825bfe5adefe4b5f967068b332cb0feedd7dc4fc,"MINOR: Revert to ZooKeeper 3.4.10 due to ZOOKEEPER-2960 (#4678)

It's a critical bug that only affects the server, but we
don't have an easy way to use 3.4.11 for the client
only.

Reviewers: Jun Rao <junrao@gmail.com>, Damian Guy <damian.guy@gmail.com>",2018-03-12 04:40:59,Ismael Juma,Not TDD
95ad03540f0d15ae47fd73bae935ab1cb3e8f4b9,"KAFKA-6634: Delay starting new transaction in task.initializeTopology (#4684)

As titled, not starting new transaction since during restoration producer would have not activity and hence may cause txn expiration. Also delay starting new txn in resuming until initializing topology.

Reviewers: Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bill@confluent.io>",2018-03-13 08:43:58,Guozhang Wang,Mixed
6b08905dfb40923317745b5e2237b2310b713333,"KAFKA-3978; Ensure high watermark is always positive (#4695)

Partition high watermark may become -1 if the initial value is out of range. This situation can occur during partition reassignment, for example. The bug was fixed and validated with unit test in this patch.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2018-03-13 22:52:59,Dong Lin,Not TDD
bf8a4c2ce7291e2f92fca297e970f668b4b85066,"MINOR: Improve Trogdor client logging. (#4675)

AgentClient and CoordinatorClient should have the option of logging failures to custom log4j objects.  There should also be builders for these objects, to make them easier to extend in the future.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2018-03-14 10:12:15,Colin Patrick McCabe,Mixed
5cdb951091129b530326140aa711f0b61c446f06,"KAFKA-6653; Complete delayed operations even when there is lock contention (#4704)

If there is lock contention while multiple threads check if a delayed operation may be completed (e.g. a produce request with acks=-1), the threads perform completion only if the lock is free, to avoid deadlocks. This leaves a timing window when an operation becomes ready to complete after another thread has acquired the lock and performed the check for completion, but not yet released the lock. The PR adds an additional flag to ensure that the operation is completed in this case.",2018-03-15 00:09:48,Rajini Sivaram,Mixed
8c10e0600736e8620f868ae15516d1fc06f775a2,MINOR: Avoid nulls when deserializing Trogodor JSON (#4688),2018-03-15 11:44:27,Colin Patrick McCabe,Not TDD
372b4c6a775461c6ca54d4c58078718f5f046216,"KAFKA-6656; Config tool should return non-zero status code on failure (#4711)

Prior to this patch, we caught some exceptions when executing the command, which meant that it would return with status code zero. This patch fixes this and makes the expected exit behavior explicit. Test cases have been added to verify the change.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-03-15 10:33:29,Jason Gustafson,Mixed
a6fad27372f9a931540c2e4345e428b643535d46,"KAFKA-6106: Postpone normal processing of tasks within a thread until restoration of all tasks have completed. (#4651)

Author:  Kamal Chandraprakash <kamal.chandraprakash@gmail.com>

Reviewer: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",2018-03-15 13:02:28,Kamal C,Mixed
7006d0f58b9a72f181b13bab6f1f64b0e7b4117e,"MINOR: Streams system tests fixes/updates (#4689)

Some changes required to get the Streams system tests working via Docker

To test:

TC_PATHS=""tests/kafkatest/tests/streams"" bash tests/docker/run_tests.sh

That command will take about 3.5 hours, and should pass. Note there are a couple of ignored tests.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bill@confluent.io>",2018-03-15 14:42:43,John Roesler,Not TDD
9e0e6e43a787092ff908cb17da37ab5dea03978b,MINOR: Trogdor should not assume an agent co-located with the controller (#4712),2018-03-16 17:57:38,Colin Patrick McCabe,Mixed
394aa7426117d0d04666c1c2a63d5f98229b7894,"KAFKA-6454: Allow timestamp manipulation in Processor API (#4519)

Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-03-16 16:02:11,Matthias J. Sax,Mixed
a70e4f95d713dd34757b3807171a2e520dd9c04d,"KAFKA-6658; Fix RoundTripWorkload and make k/v generation configurable (#4710)

Make PayloadGenerator an interface which can have multiple implementations: constant, uniform random, sequential.

Allow different payload generators to be used for keys and values.

This change fixes RoundTripWorkload.  Previously RoundTripWorkload was unable to get the sequence number of the keys that it produced.",2018-03-16 16:15:49,Colin Patrick McCabe,Mixed
9782465d6f28dda7fd7f156743f4278e6b62364b,"KAFKA-6672; ConfigCommand should create config change parent path if needed (#4727)

Change `KafkaZkClient.createConfigChangeNotification` to ensure creation of the change directory. This fixes failing system tests which depend on setting SCRAM credentials prior to broker startup. Existing test case has been modified for new expected usage.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-03-16 22:29:22,Jason Gustafson,Mixed
ae31ee63dc3bdb9068543791bea44a12a97aa928,"KAFKA-6530: Use actual first offset of message set when rolling log segment (#4660)

Use the exact first offset of message set when rolling log segment. This is possible to do for message format V2 and beyond without any performance penalty, because we have the first offset stored in the header. This augments the fix made in KAFKA-4451 to avoid using the heuristic for V2 and beyond messages.

Added unit tests to simulate cases where segment needs to roll because of overflow in index offsets. Verified that the new segment created in these cases uses the first offset, instead of the heuristic in use previously.",2018-03-17 10:29:42,Dhruvil Shah,Mixed
02a8ef859539349151e9d1dd0c69ac83a24ee7a2,"KAFKA-6486: Implemented LinkedHashMap in TimeWindows (#4628)

Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-03-18 20:44:11,asutosh936,Mixed
f264bfa2967f4b431f09d8b99d5f468fca310805,"KAFKA-6676: Ensure Kafka chroot exists in system tests and use chroot on one test with security parameterizations (#4729)

Ensures Kafka chroot exists in ZK when starting KafkaService so commands that use ZK and are executed before the first Kafka broker starts do not fail due to the missing chroot.

Also uses chroot with one test that also has security parameterizations so Kafka's test suite exercises these combinations. Previously no tests were exercising chroots.

Changes were validated using sanity_checks which include the chroot-ed test as well as some non-chroot-ed tests.",2018-03-19 10:37:02,Ewen Cheslack-Postava,Not TDD
6fab286da2735517f6d0c945328abcb77fa0a7a4,MINOR: Fix some compiler warnings (#4726),2018-03-19 15:03:58,Ismael Juma,Not TDD
0f364cd53a7a56e4ddea1db44fd044860ba2c0b4,"MINOR: Pass a streams config to replace the single state dir (#4714)

This is a general change and is re-requisite to allow streams benchmark test with different streams tests. For the streams benchmark itself I will have a separate PR for switching configs. Details:

1. Create a ""streams.properties"" file under PERSISTENT_ROOT before all the streams test. For now it will only contain a single config of state.dir pointing to PERSISTENT_ROOT.

2. For all the system test related code, replace the main function parameter of state.dir with propsFilename, then inside the function load the props from the file and apply overrides if necessary.

3. Minor fixes.

Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",2018-03-19 14:17:00,Guozhang Wang,Not TDD
aefe35e493758e439d7dd5cb5aa50762132a5e5d,"KAFKA-6680: Fix issues related to Dynamic Broker configs (#4731)

- Fix kafkaConfig initialization if there are no dynamic configs defined in ZK.
- Update DynamicListenerConfig.validateReconfiguration() to check new Listeners must be subset of listener map

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2018-03-19 22:22:53,Manikumar Reddy O,Mixed
5c24295d44b4f015a620914992542c4d2083c611,"Trogdor's ProducerBench does not fail if topics exists (#4673)

Added configs to ProducerBenchSpec:
topicPrefix: name of topics will be of format topicPrefix + topic index. If not provided, default is ""produceBenchTopic"".
partitionsPerTopic: number of partitions per topic. If not provided, default is 1.
replicationFactor: replication factor per topic. If not provided, default is 3.

The behavior of producer bench is changed such that if some or all topics already exist (with topic names = topicPrefix + topic index), and they have the same number of partitions as requested, the worker uses those topics and does not fail. The producer bench fails if one or more existing topics has number of partitions that is different from expected number of partitions.

Added unit test for WorkerUtils -- for existing methods and new methods.

Fixed bug in MockAdminClient, where createTopics() would over-write existing topic's replication factor and number of partitions while correctly completing the appropriate futures exceptionally with TopicExistsException.

Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2018-03-20 13:51:45,Anna Povzner,Mixed
2f90cb86c18e854fd687ea7bbeb8692178bbb02d,"MINOR: Remove acceptor creation in network thread update code (#4742)

Fix dynamic addition of network threads to only create new Processor threads and not the Acceptor.",2018-03-20 22:40:16,Rajini Sivaram,Not TDD
57b1c28d60e05f2cf7394ef727a86df92b1bb02b,"MINOR: Fix AdminClient.describeConfigs() of listener configs (#4747)

Don't return config values from `describeConfigs` if the config type cannot be determined. Obtain config types correctly for listener configs for `describeConfigs` and password encryption.

Reviewers: Jason Gustafson <jason@confluent.io>",2018-03-22 20:05:45,Rajini Sivaram,Mixed
286216b56e27d8db18f7268b63cbd8d7f8bd8830,"MINOR: Rolling bounce upgrade fixed broker system test (#4690)

Reviewers: Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-03-22 16:02:16,Bill Bejeck,Not TDD
f2fbfaaccc99f889ae0796005a46d6c62c8e5be9,"KAFKA-6611: PART I, Use JMXTool in SimpleBenchmark (#4650)

1. Use JmxMixin for SimpleBenchmark (will remove the self reporting in #4744), only when loading phase is false (i.e. we are in fact starting the streams app).

2. Reported the full jmx reported metrics in log files, and in the returned data only return the max values: this is because we want to skip the warming up and cooling down periods that will have lower rate numbers, while max represents the actual rate at full speed.

3. Incorporates two other improves to JMXTool: #1241 and #2950

Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Rohan Desai <desai.p.rohan@gmail.com>",2018-03-22 16:46:56,Guozhang Wang,Not TDD
fcf87816028830d168fd2142cf5277adcbade91b,"KAFKA-6683; Ensure producer state not mutated prior to append (#4755)

We were unintentionally mutating the cached queue of batches prior to appending to the log. This could have several bad consequences if the append ultimately failed or was truncated. In the reporter's case, it caused the snapshot to be invalid after a segment roll. The snapshot contained producer state at offsets higher than the snapshot offset. If we ever had to load from that snapshot, the state was left inconsistent, which led to an error that ultimately crashed the replica fetcher.

The fix required some refactoring to avoid sharing the same underlying queue inside ProducerAppendInfo. I have added test cases which reproduce the invalid snapshot state. I have also made an effort to clean up logging since it was not easy to track this problem down.

One final note: I have removed the duplicate check inside ProducerStateManager since it was both redundant and incorrect. The redundancy was in the checking of the cached batches: we already check these in Log.analyzeAndValidateProducerState. The incorrectness was the handling of sequence number overflow: we were only handling one very specific case of overflow, but others would have resulted in an invalid assertion. Instead, we now throw OutOfOrderSequenceException.

Reviewers: Apurva Mehta <apurva@confluent.io>, Jun Rao <junrao@gmail.com>",2018-03-22 21:42:49,Jason Gustafson,Mixed
2307314432c871cf045787b44295d8dc4943e77d,"MINOR: Fix encoder config to make DynamicBrokerReconfigurationTest stable (#4764)

DynamicBrokerReconfigurationTest currently assumes that passwords encoded with one secret will fail with an exception if decoded with another secret and configures an old.secret in setUp. This could potentially cause test failures if a password was incorrectly decoded with the wrong secret, since the test writes passwords encoded with the new secret directly to ZooKeeper. Since old.secret is only used in one test for verifying secret rotation, this config can be moved to that test to avoid transient failures.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-03-23 17:01:32,Rajini Sivaram,Not TDD
685fd03dda02957a91a50fa16409400b1ea08f81,"KAFKA-6612: Added logic to prevent increasing partition counts during topic deletion

This patch adds logic in handling the PartitionModifications event, so that if the partition count is increased when a topic deletion is still in progress, the controller will restore the data of the path /brokers/topics/""topic"" to remove the added partitions.

Testing done:
Added a new test method to cover the bug

Author: Lucas Wang <luwang@linkedin.com>

Reviewers: Jiangjie (Becket) Qin <becket.qin@gmail.com>

Closes #4666 from gitlw/prevent_increasing_partition_count_during_topic_deletion",2018-03-23 18:18:16,Lucas Wang,Not TDD
f66aebff363c768afb50b10f31458c2f447b0abc,"KAFKA-6710: Remove Thread.sleep from LogManager.deleteLogs (#4771)

`Thread.sleep` in `LogManager.deleteLogs` potentially blocks a scheduler thread for up to `log.segment.delete.delay.ms` with a default value of a minute. To avoid this, `deleteLogs` now deletes the logs for which `currentDefaultConfig.fileDeleteDelayMs` has elapsed after the delete was scheduled. Logs for which this interval has not yet elapsed are considered for deletion in the next iteration of `deleteLogs`, which is scheduled sooner if required.

Reviewers: Jun Rao <junrao@gmail.com>, Dong Lin <lindong28@gmail.com>, Ted Yu <yuzhihong@gmail.com>",2018-03-24 20:54:09,Rajini Sivaram,Mixed
3f611044cc55c6633cb64fd86a3ac6274952fa72,"KAFKA-6052; Fix WriteTxnMarkers request retry issue in InterBrokerSendThread (#4705)

This resolves the issue found when running the brokers on Windows which prevents the coordinator from sending WriteTxnMarkers requests to complete a transaction.",2018-03-24 14:04:08,Vahid Hashemian,Mixed
9eb32eaad5fa3863d60b84ef095fa041e83b7b47,"KAFKA-6446; KafkaProducer initTransactions() should timeout after max.block.ms (#4563)

Currently the `initTransactions()` API blocks indefinitely if the broker cannot be reached. This patch changes the behavior to raise a `TimeoutException` after waiting for `max.block.ms`. 

Reviewers: Apurva Mehta <apurva@confluent.io>, Jason Gustafson <jason@confluent.io>",2018-03-27 09:21:18,huxi,Mixed
adbf31ab1d27cda0b62d611e6141d830736a8e2e,"KAFKA-6473: Add MockProcessorContext to public test-utils (#4736)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",2018-03-27 14:03:24,John Roesler,Mixed
964693e40d9303d5d754010f03731d2134bae749,"KAFKA-6386: Use Properties instead of StreamsConfig in KafkaStreams constructor

This pull request targets https://issues.apache.org/jira/browse/KAFKA-6386
The minor fix to deprecate usage of `StreamsConfig` in favor of `java.util.Properties`.
I created separate public constructors using `Properties` in order to replace the old ones,
and prioritize new functions in the `KafkaStreams.java` file.

Since this is my first time doing open source contribution, I'm very happy to get
any comment or pointer to be more professional and get better next time, thank you Guozhang guozhangwang and Liquan Ishiihara!

testing strategy: existing unit test should be suffice to cover this change.

Author: cs427fa16staff <bchen11@outlook.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>

Closes #4354 from abbccdda/starter

github comments",2018-03-27 16:09:34,Boyang Chen,Mixed
2ef6ee2338178c7501f5bd4c7cce5f4cea9d3e17,"KAFKA-6630: Speed up the processing of TopicDeletionStopReplicaResponseReceived events on the controller (#4668)

Reviewed by Jun Rao <junrao@gmail.com>",2018-03-29 22:08:28,gitlw,Mixed
4106cb1db18cc45cbbeb54546a7468a4727bd88f,"KAFKA-4914: Partition reassignment tool should check types before persisting state in ZooKeeper (#2708)

Prior to this, there have been instances where invalid data was allowed to be persisted in
ZooKeeper, which causes ClassCastExceptions when a broker is restarted and reads this
type-unsafe data.

Adds basic structural and type validation for the reassignment JSON via
introduction of Scala case classes that map to the expected JSON
structure. Also use the Scala case classes to deserialize the JSON
to avoid duplication.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Viktor Somogyi <viktor.somogyi@cloudera.com>, Ismael Juma <ismael@juma.me.uk>",2018-03-31 07:57:19,Nick Travers,Mixed
2e5d4af83f6b9f87fc84c0ff10462a5414ff8cb4,"MINOR: refactor error message of task migration (#4803)

In the stream thread capture of the TaskMigration exception, print the task full information in WARN. In other places only log as INFO, plus additional context information.

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-04-01 17:37:00,Guozhang Wang,Not TDD
8662a022c42b7a6245e8ec54c544fccd8b79b6f8,"MINOR: Fix partition loading checks in GroupCoordinator (#4788)

In the group coordinator, we currently check whether the partition is owned before checking whether it is loading. Since loading is a prerequisite for partition ownership, it means that it is not actually possible to see the COORDINATOR_LOAD_IN_PROGRESS error. The impact is mostly harmless: while loading the group, the client may send unnecessary FindCoordinator requests to rediscover the coordinator. I've fixed the bug and restructured the code to enable testing.

In the process of fixing this bug, the following improvements have been made:

1. We now verify valid groupId in all request handlers.
2. Currently if the coordinator is loading when a SyncGroup is received, we'll return NOT_COORDINATOR. I've changed this to return REBALANCE_IN_PROGRESS since the rebalance state will have been lost on coordinator failover. This effectively forces the consumer to rejoin the group, which seems preferable over unnecessarily rediscovering the coordinator. 
3. I added a check for the COORDINATOR_LOAD_IN_PROGRESS handler in SyncGroup. Although we do not currently return this error, it seems reasonable that we might want to some day, so it seems better to get the check in now.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2018-04-02 08:35:17,Jason Gustafson,Mixed
1dc30272e1e684764563e3091a19a8ff8892f8eb,"KAFKA-5674; Reduce max.connections.per.ip minimum to 0 (#3610)

By allowing `max.connections.per.ip` to be 0, Kafka can support IP-based filtering using `max.connections.per.ip.overrides`.",2018-04-02 08:45:15,Viktor Somogyi,Not TDD
d9369de8f2c6435843fb7577d313bb24e3b09cba,"KAFKA-6728: Corrected the worker’s instantiation of the HeaderConverter

## Summary of the problem
When the `header.converter` is not specified in the worker config or the connector config, a bug in the `Plugins` test causes it to never instantiate the `HeaderConverter` instance, even though there is a default value.

This is a problem as soon as the connector deals with headers, either in records created by a source connector or in messages on the Kafka topics consumed by a sink connector. As soon as that happens, a NPE occurs.

A workaround is to explicitly set the `header.converter` configuration property, but this was added in AK 1.1 and thus means that upgrading to AK 1.1 will not be backward compatible and will require this configuration change.

## The Changes

The `Plugins.newHeaderConverter` methods were always returning null if the `header.converter` configuration value was not specified in the supplied connector or worker configuration. Thus, even though the `header.converter` property has a default, it was never being used.

The fix was to only check whether a `header.converter` property was specified when the connector configuration was being used, and if no such property exists in the connector configuration to return null. Then, when the worker configuration is being used, the method simply gets the `header.converter` value (or the default if no value was explicitly set).

Also, the ConnectorConfig had the same default value for the `header.converter` property as the WorkerConfig, but this resulted in very confusing log messages that implied the default header converter should be used even when the worker config specified the `header.converter` value. By removing the default, the log messages now make sense, and the Worker still properly instantiates the correct header converter.

Finally, updated comments and added log messages to make it more clear which converters are being used and how they are being converted.

## Testing

Several new unit tests for `Plugins.newHeaderConverter` were added to check the various behavior. Additionally, the runtime JAR with these changes was built and inserted into an AK 1.1 installation, and a source connector was manually tested with 8 different combinations of settings for the `header.converter` configuration:

1. default value
1. worker configuration has `header.converter` explicitly set to the default
1. worker configuration has `header.converter` set to a custom `HeaderConverter` implementation in the same plugin
1. worker configuration has `header.converter` set to a custom `HeaderConverter` implementation in a _different_ plugin
1. connector configuration has `header.converter` explicitly set to the default
1. connector configuration has `header.converter` set to a custom `HeaderConverter` implementation in the same plugin
1. connector configuration has `header.converter` set to a custom `HeaderConverter` implementation in a _different_ plugin
1. worker configuration has `header.converter` explicitly set to the default, and the connector configuration has `header.converter` set to a custom `HeaderConverter` implementation in a _different_ plugin

The worker created the correct `HeaderConverter` implementation with the correct configuration in all of these tests.

Finally, the default configuration was used with the aforementioned custom source connector that generated records with headers, and an S3 connector that consumes the records with headers (but didn't do anything with them). This test also passed.

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #4815 from rhauch/kafka-6728",2018-04-03 08:48:05,Randall Hauch,Mixed
719a21f7c9fefc6ebe16089b2a5e4c155fde8b16,"KAFKA-6739; Ignore headers when down-converting from V2 to V0/V1 (#4813)

Ignore headers when down-converting to V0/V1 since they are not supported. Added a test-case to verify down-conversion sanity in presence of headers.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2018-04-03 10:39:20,Dhruvil Shah,Not TDD
53d4267c59177cd826e1b0645168b1e9330bdbcd,"MINOR: Don’t send the DeleteTopicsRequest for invalid topic names (#4763)

The invalid topic name is already handled locally so it is unnecessary to send the DeleteTopicsRequest. This PR adds a count to MockClient for testing.

Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Jason Gustafson <jason@confluent.io>",2018-04-05 00:06:14,Chia-Ping Tsai,Mixed
9f8c3167eb2fcab158147eb4fefdabc933b8a3a1,"KAFKA-4292: Configurable SASL callback handlers (KIP-86) (#2022)

Implementation of KIP-86. Client, server and login callback handlers have been made configurable for both brokers and clients.

Reviewers: Jun Rao <junrao@gmail.com>, Ron Dagostino <rndgstn@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2018-04-05 09:41:42,Rajini Sivaram,Mixed
63642d6051015d84aa8c084380bcab174a5f3303,KAFKA-6694: The Trogdor Coordinator should support filtering task responses (#4741),2018-04-05 13:35:20,Colin Patrick McCabe,Mixed
ed2f10e0500e48e42cf5c5b9c9358c36be332413,"MINOR: Update max.connections.per.ip.overrides config docs (#4819)

Add a validation check to make sure max.connections.per.ip.overrides is configured when max.connections.per.ip is set zero. Also clean up the config description.",2018-04-05 08:59:35,Manikumar Reddy O,Mixed
3abd4107082ff69619d434d456c664c21cf77f82,"KAFKA-6748: double check before scheduling a new task after the punctuate call (#4827)

After the punctuate() call, we would like to double check on the scheduled flag since the call itself may cancel it.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, John Roesler <john@confluent.io>",2018-04-05 11:17:40,fredfp,Mixed
ac542c9a835d3a2dd46f37712c6b5438f56747c0,"KAFKA-6747 Check whether there is in-flight transaction before aborting transaction (#4826)

As Frederic reported on mailing list under the subject ""kafka-streams Invalid transition attempted from state READY to state ABORTING_TRANSACTION"", producer#abortTransaction should only be called when transactionInFlight is true.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <matthias@confluent.io>",2018-04-05 15:29:04,tedyu,Mixed
da32db9f3462242082f23973dc154f6f5e69f069,"Trogdor: Added commonClientConf and adminClientConf to workload specs (#4757)

Currently, WorkerUtils will be able to create topics when there is no security. To be able to work with secure kafka, WorkerUtils.createTopic() needs to be able to take security configs. This PR adds commonClientConf field to both producer bench and roundtrip workload specs so that users can specify security and other common configs once for producer/consumer and adminClient. Also added adminClientConf field to workload specs so that users can specify adminClient specific configs if they want to. For completeness, added consumerConf and producerConf to roundtrip workload spec.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Colin P. Mccabe <cmccabe@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2018-04-06 19:21:41,Anna Povzner,Mixed
77ebd32016d13c64ee5a3c7db63ca71bf4b79aad,"KAFKA-6576: Configurable Quota Management (KIP-257) (#4699)

Enable quota calculation to be customized using a configurable callback. See KIP-257 for details.

Reviewers: Jun Rao <junrao@gmail.com>",2018-04-06 22:49:34,Rajini Sivaram,Mixed
0c0d8363e5787e97cce5e0b9b86486d737a6890c,"KAFKA-6054: Fix upgrade path from Kafka Streams v0.10.0 (#4779)

Reviewers: Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Damian Guy <damian@confluent.io>",2018-04-06 17:00:52,Matthias J. Sax,Mixed
40183e31567795d4d0f2b836294bc5d5fac2a56b,"KAFKA-6688. The Trogdor coordinator should track task statuses (#4737)

Reviewers: Anna Povzner <anna@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2018-04-08 09:35:33,Colin Patrick McCabe,Mixed
0a8f35b68415bb3f79b0ec61df6cb0ab0db937c4,"KAFKA-6768; Transactional producer may hang in close with pending requests (#4842)

This patch fixes an edge case in producer shutdown which prevents `close()` from completing due to a pending request which will never be sent due to shutdown initiation. I have added a test case which reproduces the scenario.

Reviewers: Apurva Mehta <apurva@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2018-04-09 15:39:07,Jason Gustafson,Not TDD
989fe0497ec72ea3470a30a9ef47389b48ee5421,"Kafka-6693: Added consumer workload to Trogdor (#4775)

Added consumer only workload to Trogdor. The topics must already be pre-populated. The spec lets the user request topic pattern and range of partitions to assign to [startPartition, endPartition].

Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2018-04-10 09:45:08,Anna Povzner,Mixed
79c6f7cd9af462807a9f6b6313fd6c6c7908951f,"MINOR: Move creation of quota callback to ensure single instance (#4848)

Move creation of quota callback instance out of KafkaConfig constructor to QuotaFactory.instantiate to avoid creating a callback instance for every KafkaConfig since we create temporary KafkaConfigs during dynamic config updates.

Reviewers: Jun Rao <junrao@gmail.com>",2018-04-10 20:42:07,Rajini Sivaram,Mixed
5e277e5579f4a989ecef6473fbc3619178b33a35,KAFKA-4883: handle NullPointerException while parsing login modue control flag (#4849),2018-04-10 20:46:32,Manikumar Reddy O,Not TDD
4223ef61060673e95077abfe6aca27bc0f71fffa,MINOR: Add NullPayloadGenerator to Trogdor (#4844),2018-04-10 20:48:38,Colin Patrick McCabe,Mixed
e29fa9a4ca72e6eae0a4b75ef30f2df4ffec943d,"KAFKA-6752: Enable unclean leader election metric (#4838)

Reviewers: Jun Rao <junrao@gmail.com>",2018-04-11 10:30:30,Manikumar Reddy O,Not TDD
47918f2d79e907f6a6da599ab82a97c169722229,"KAFKA-6447: Add Delegation Token Operations to KafkaAdminClient (KIP-249) (#4427)

Reviewers: Jun Rao <junrao@gmail.com>",2018-04-11 10:48:04,Manikumar Reddy O,Mixed
6a99da87abff26a749cee4e765d125bec8b6c424,"KAFKA-6058: KIP-222; Add Consumer Group operations to Admin API

KIP: https://cwiki.apache.org/confluence/display/KAFKA/KIP-222+-+Add+Consumer+Group+operations+to+Admin+API

Author: Jorge Quilcate Otoya <quilcate.jorge@gmail.com>
Author: Jorge Esteban Quilcate Otoya <quilcate.jorge@gmail.com>
Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Guozhang Wang <wangguoz@gmail.com>

Closes #4454 from jeqo/feature/admin-client-describe-consumer-group",2018-04-11 14:17:46,Jorge Quilcate Otoya,Mixed
7421f9dce2d2e763f70602b13df1efcd32f691b9,"KAFKA-6773; Allow offset commit/fetch/describe/delete with empty groupId (#4851)

We had a regression in #4788 which caused the offset commit/fetch/describe APIs to fail if the groupId was empty. This should be allowed for backwards compatibility. Additionally, I have modified DeleteGroups to allow removal of the empty group, which was missed in the initial implementation. I've added a test case to ensure that we do not miss this again in the future.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-04-11 16:47:11,Jason Gustafson,Mixed
cc43e77bbbfad71883011186de55603c936cbcd1,"MINOR: make Sensor#add idempotent (#4853)

This change makes adding a metric to a sensor idempotent.
That is, if the metric is already added to the sensor, the method
returns with success.

The current behavior is that any attempt to register a second metric
with the same name is an error.

Testing strategy: There is a new unit test covering this behavior

Reviewers: Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",2018-04-11 20:50:10,John Roesler,Mixed
4e35a2bfb7f3b0437a27bb58b8cb39339f750064,"KAFKA-6592: ConsoleConsumer should support WindowedSerdes (#4797)

Have Console consumer support TimeWindowedDeserializer/SessionWindowedDeserializer.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2018-04-12 09:35:37,huxi,Mixed
b599b395f3d421b3fdb1d25b294778478c2467cf,"KAFKA-6058: Refactor consumer API result return types (#4856)

Refactored the return types in consumer group APIs the following way:

```
Map<TopicPartition, KafkaFuture<Void>> DeleteConsumerGroupsResult#deletedGroups()

Map<TopicPartition, KafkaFuture<ConsumerGroupDescription>> DescribeConsumerGroupsResult#describedGroups()

KafkaFuture<Collection<ConsumerGroupListing>> ListConsumerGroupsResult#listings()

KafkaFuture<Map<TopicPartition, OffsetAndMetadata>> ListConsumerGroupOffsetsResult#partitionsToOffsetAndMetadata()
```

* For DeleteConsumerGroupsResult and DescribeConsumerGroupsResult, for each group id we have two round-trips to get the coordinator, and then send the delete / describe request; I leave the potential optimization of batching requests for future work.

* For ListConsumerGroupOffsetsResult, it is a simple single round-trip and hence the whole map is wrapped as a Future.

* ListConsumerGroupsResult, it is the most tricky one: we would only know how many futures we should wait for after the first listNode returns, and hence I constructed the flattened future in the middle wrapped with the underlying map of futures; also added an iterator API to compensate the ""fail the whole future if any broker returns error"" behavior. The iterator future will throw exception on the failing brokers, while return the consumer for other succeeded brokers.

Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Jason Gustafson <jason@confluent.io>",2018-04-15 10:13:22,Guozhang Wang,Mixed
0dc7f0e66f849346049f6f90cee05a2796735d14,"KAFKA-6611, PART II: Improve Streams SimpleBenchmark (#4854)

SimpleBenchmark:

1.a Do not rely on manual num.records / bytes collection on atomic integers.
1.b Rely on config files for num.threads, bootstrap.servers, etc.
1.c Add parameters for key skewness and value size.
1.d Refactor the tests for loading phase, adding tumbling-windowed count.
1.e For consumer / consumeproduce, collect metrics on consumer instead.
1.f Force stop the test after 3 minutes, this is based on empirical numbers of 10M records.

Other tests: use config for kafka bootstrap servers.

streams_simple_benchmark.py: only use scale 1 for system test, remove yahoo from benchmark tests.

Note that the JMX based metrics is more accurate than the manually collected metrics. 

Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-04-15 10:15:31,Guozhang Wang,Not TDD
98713570867619de7de8e885a82d5fb0bfdb3b4e,"KAFKA-6592: Follow-up (#4864)

Do not require ConsoleConsumer to specify inner serde as s special property, but just a normal property of the message formatter.",2018-04-15 20:51:53,Guozhang Wang,Mixed
832b096f4fcfde9e90d796470eb0ce2a26283e81,"KAFKA-6696 Trogdor should support destroying tasks (#4759)

Implement destroying tasks and workers.  This means erasing all record of them on the Coordinator and the Agent.

Workers should be identified by unique 64-bit worker IDs, rather than by the names of the tasks they are implementing.  This ensures that when a task is destroyed and re-created with the same task ID, the old workers will be not be treated as part of the new task instance.

Fix some return results from RPCs.  In some cases RPCs were returning values that were never used.  Attempting to re-create the same task ID with different arguments should fail.  Add RequestConflictException to represent HTTP error code 409 (CONFLICT) for this scenario.

If only one worker in a task stops, don't stop all the other workers for that task, unless the worker that stopped had an error.

Reviewers: Anna Povzner <anna@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2018-04-16 08:51:33,Colin Patrick McCabe,Mixed
93e03414f72c24854abaa6925149196580cfc691,KAFKA-6771. Make specifying partitions more flexible (#4850),2018-04-16 08:55:13,Colin Patrick McCabe,Mixed
19418fc86aefde2acdc62f6790b2ff0bb4d15699,"KAFKA-6514; Add API version as a tag for the RequestsPerSec metric (#4506)

Updated `RequestChannel` to include `version` as a tag for all RequestsPerSec metrics (KIP-272). Updated tests to verify that the extra tag exists.",2018-04-16 10:16:26,Allen Wang,Not TDD
432c82d3bf6bbe679df1c2ac7cc11683e8f9c611,"KAFKA-6727; Fix broken Config hashCode() and equals() (#4796)

Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2018-04-16 12:32:07,Andy Coates,Mixed
341db990dc4e2acb207622c7fa254f07650742bc,"KAFKA-6650: Allowing transition to OfflineReplica state for replicas without leadership info (#4825)

A partially deleted topic can end up with some partitions having no leadership info.
For the partially deleted topic, a new controller should be able to finish the topic deletion
by transitioning the rogue partition's replicas to OfflineReplica state.
This patch adds logic to transition replicas to OfflineReplica state whose partitions have
no leadership info.

Added a new test method to cover the partially deleted topic case.

Reviewers: Jun Rao <junrao@gmail.com>",2018-04-16 17:16:08,gitlw,Mixed
e5de679d62f734eb1cdfc91c863107b64cd630b6,"KAFKA-6765: Handle exception while reading throttle metric value in test (#4869)

Quota tests wait for throttle metric to be updated without waiting for requests to complete to avoid waiting for potentially large throttle times. This requires the test to read metric values while a broker may be updating the value, resulting in exception in the test. Since this issue can also occur with JMX metrics reporter, change synchronization on metrics with sensors to use the sensor as lock.",2018-04-17 14:46:28,Rajini Sivaram,Mixed
ac9c3ed0b43ee848e6e555a01c55ea2eee78540a,"KAFKA-6376: preliminary cleanup (#4872)

General cleanup of Streams code, mostly resolving compiler warnings and re-formatting.

The regular testing suite should be sufficient.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-04-17 13:13:15,John Roesler,Mixed
cae42215b7597cc39afc682cb0399782cf42fe23,"KAFKA-6054: Update Kafka Streams metadata to version 3 (#4880)

 - adds Streams upgrade tests for 1.1 release
 - introduces metadata version 3

Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-04-18 09:38:27,Matthias J. Sax,Mixed
98bb75a58fc241b400ed7535d9e9723f678b4803,"KAFKA-6772: Load credentials from ZK before accepting connections (#4867)

Start processing client connections only after completing KafkaServer initialization to ensure that credentials are loaded from ZK into cache before authentications are processed. Acceptors are started earlier so that bound port is known for registering in ZK.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2018-04-18 10:20:28,Rajini Sivaram,Not TDD
6b2be2693c60fd222bf8c80b3c9ee783feb00d40,"KAFKA-6775: Fix the issue of without init super class's (#4859)

Some anonymous classes of AbstractProcessor didn't initialize their superclass. This will not set up ProcessorContext context at AbstractProcessor.

Reviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",2018-04-18 15:07:09,Jimin Hsieh,Not TDD
1f523d9d72ad3008664146e1d2a5b40861b06072,"MINOR: add window store range query in simple benchmark (#4894)

There are a couple minor additions in this PR:

1. Add a new test for window store, to range query upon receiving each record.
2. In the non-windowed state store case, add a get call before the put call.
3. Enable caching by default to be consistent with other Join / Aggregate cases, where caching is enabled by default.

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-04-19 16:14:32,Guozhang Wang,Not TDD
b510737e761e21e63e6ed15e5111358d7515fdd2,"KAFKA-5253: Fixed TopologyTestDriver to handle streams created with patterns (#4793)

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-04-20 15:22:28,Jagadesh Adireddi,Not TDD
ed51b2cdf5bdac210a6904bead1a2ca6e8411406,"KAFKA-6376; refactor skip metrics in Kafka Streams

* unify skipped records metering
* log warnings when things get skipped
* tighten up metrics usage a bit

### Testing strategy:
Unit testing of the metrics and the logs should be sufficient.

Author: John Roesler <john@confluent.io>

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #4812 from vvcephei/kip-274-streams-skip-metrics",2018-04-23 11:41:03,John Roesler,Mixed
b2e4db01b679e0759bdd340310a864cc83f48deb,"KAFKA-6670: Implement a Scala wrapper library for Kafka Streams

This PR implements a Scala wrapper library for Kafka Streams. The library is implemented as a project under streams, namely `:streams:streams-scala`. The PR contains the following:

* the library implementation of the wrapper abstractions
* the test suite
* the changes in `build.gradle` to build the library jar

The library has been tested running the tests as follows:

```
$ ./gradlew -Dtest.single=StreamToTableJoinScalaIntegrationTestImplicitSerdes streams:streams-scala:test
$ ./gradlew -Dtest.single=StreamToTableJoinScalaIntegrationTestImplicitSerdesWithAvro streams:streams-scala:test
$ ./gradlew -Dtest.single=WordCountTest streams:streams-scala:test
```

Author: Debasish Ghosh <ghosh.debasish@gmail.com>
Author: Sean Glover <seglo@randonom.com>

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Ismael Juma <ismael@juma.me.uk>, John Roesler <john@confluent.io>, Damian Guy <damian@confluent.io>, Guozhang Wang <wangguoz@gmail.com>

Closes #4756 from debasishg/scala-streams",2018-04-23 13:33:35,Debasish Ghosh,Not TDD
a05e33693b66ac38ccb21f2238c194ca59fcb6ec,"KAFKA-6677: Fixed StreamsConfig producer's max-in-flight allowed when EOS enabled. (#4868)

Reviewers: Matthias J Sax <matthias@confluentio>, Bill Bejeck <bill@confluent.io>",2018-04-24 19:13:12,Jagadesh Adireddi,Mixed
acd669e4248c605ac54c38862a8678f521f6f574,"KAFKA-6796; Fix surprising UNKNOWN_TOPIC error from requests to non-replicas (#4883)

Currently if the client sends a produce request or a fetch request to a broker which isn't a replica,
we return UNKNOWN_TOPIC_OR_PARTITION. This is a bit surprising to see when the topic actually
exists. It would be better to return NOT_LEADER to avoid confusion. Clients typically handle both errors by refreshing metadata and retrying, so changing this should not cause any change in behavior on the client. This case can be hit following a partition reassignment after the leader is moved and the local replica is deleted.

To validate the current behavior and the fix, I've added integration tests for the fetch and produce APIs.",2018-04-24 21:49:44,Jason Gustafson,Mixed
cbb5b51475368613c7972297ea6055a4f75285e1,"KAFKA-6795; Added unit tests for ReplicaAlterLogDirsThread

Added unit tests for ReplicaAlterLogDirsThread. Mostly focused on unit tests for truncating logic.

Fixed  ReplicaAlterLogDirsThread.buildLeaderEpochRequest() to use future replica's latest epoch (not the latest epoch of replica it is fetching from). This follows the logic that offset for leader epoch request should be based on leader epoch of the follower (in this case it's the future local replica).

Also fixed PartitionFetchState constructor that takes offset and delay. The code ignored the delay parameter and used 0 for the delay. This constructor is used only by another constructor which passes delay = 0, which luckily works.

Author: Anna Povzner <anna@confluent.io>

Reviewers: Dong Lin <lindong28@gmail.com>

Closes #4918 from apovzner/kafka-6795",2018-04-25 14:24:29,Anna Povzner,Mixed
6be908a8296456adee254b405605acff55fd47a5,"MINOR: Refactor AdminClient ListConsumerGroups API (#4884)

The current Iterator-based ListConsumerGroups API is synchronous.  The API should be asynchronous to fit in with the other AdminClient APIs.  Also fix some error handling corner cases.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-04-25 17:49:02,Colin Patrick McCabe,Mixed
fc6e92260c3ff3b5ef72ac05e7a518a8cb2e7090,"MINOR: fix NamedCache metrics in Streams (#4917)

* Fixes a bug in which all NamedCache instances in a process shared
one parent metric.

* Also fixes a bug which incorrectly computed the per-cache metric tag
(which was undetected due to the former bug).

* Drop the StreamsMetricsConventions#xLevelSensorName convention
in favor of StreamsMetricsImpl#xLevelSensor to allow StreamsMetricsImpl
to track thread- and cache-level metrics, so that they may be cleanly declared
from anywhere but still unloaded at the appropriate time. This was necessary
right now so that the NamedCache could register a thread-level parent sensor
to be unloaded when the thread, not the cache, is closed.

* The above changes made it mostly unnecessary for the StreamsMetricsImpl to
expose a reference to the underlying Metrics registry, so I did a little extra work
to remove that reference, including removing inconsistently-used and unnecessary
calls to Metrics#close() in the tests.

The existing tests should be sufficient to verify this change.

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-04-26 10:01:17,John Roesler,Mixed
e7f019690a10306a717b9757a21d5bf01964532e,"MINOR: Fixes for streams system tests (#4935)

This PR fixes some regressions introduced into streams system tests and sets the upgrade tests to ignore until PR #4636 is merged as it has the fixes for the upgrade tests.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2018-04-26 10:04:59,Bill Bejeck,Not TDD
8725e3604b31d0bf822959fc6d870512411c7a05,"MINOR: Remove deprecated streams config (#4906)

Removed the following: ""zookeeper.connect"", ""key.serde"", ""value.serde"", ""timestamp.extractor""

Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Jason Gustafson <jason@confluent.io>",2018-04-26 13:16:51,Guozhang Wang,Mixed
ff1875fce0a82737069e195060b6a93881954a23,"KAFKA-6778; AdminClient.describeConfigs() should return error for non-existent topics (#4866)

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2018-04-26 14:01:04,Manikumar Reddy O,Not TDD
c6fd3d488e8dba904f6abb2324a89466fc354387,"MINOR: update VerifiableProducer to send keys if configured and removed StreamsRepeatingKeyProducerService (#4841)

This PR does the following:

* Remove the StreamsRepeatingIntegerKeyProducerService and the associated Java class
* Add a parameter to VerifiableProducer.java to enable sending keys when specified
* Update the corresponding Python file verifiable_producer.py to support the new parameter.

Reviewers: Matthias J Sax <matthias@confluentio>, Guozhang Wang <wangguoz@gmail.com>",2018-04-27 22:12:57,Bill Bejeck,Not TDD
8577632b3a7dd3dd5ce9cf2562627983bbabba20,"MINOR: Fix Trogdor tests, partition assignments (#4892)",2018-04-29 15:54:38,Colin Patrick McCabe,Mixed
6655a4d75f8d839c9f87e68fbda77ed0637825d2,"KAFKA-6535: Set default retention ms for Streams repartition topics to Long.MAX_VALUE (#4730)

Implements KIP-284

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-04-30 12:18:40,khairy,Not TDD
902009ea981075bdad178c96eb9e9a835d9cc52f,"KAFKA-3417: Wrap metric reporter calls in try/catch blocks (#3635)

Prevent exception thrown by metric reporters to impact request processing and other reporters.

Co-authored-by: Mickael Maison <mickael.maison@gmail.com>
Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2018-04-30 12:34:02,Mickael Maison,Not TDD
f467c9c2438a8b182083879927ff171a6a2c6f2f,"MINOR: Ensure exception messages include partition/segment info when possible (#4907)

Reviewers: Anna Povzner <anna@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2018-04-30 08:59:04,Jason Gustafson,Mixed
9d2efd83a6a8e5576886dd146eebdb072f4c8d47,"KAFKA-6810; Enable dynamic update of SSL truststores (#4904)

Enable broker's SSL truststores to be dynamically updated using ConfigCommand in the same way as keystores are updated.",2018-04-30 13:08:34,Rajini Sivaram,Mixed
b4d8552218c9ab41bc1e0221c4e79417a2662d19,"KAFKA-6526: Enable unclean leader election without controller change (#4920)

Enable dynamic update of default unclean leader election config of brokers. A new controller event has been added to process unclean leader election when the config is enabled dynamically.

Reviewers: Dong Lin <lindong28@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2018-05-01 15:27:02,Rajini Sivaram,Not TDD
1b170df31c7304f6d4c938b5e0c2a09ae1e9189d,"KAFKA-6657: Add StreamsConfig prefix for different consumers (#4805)

This pull request is for JIRA 6657, for KIP-276.

Added unit tests for new getGlobalConsumerConfigs API and make sure existing restore consumer tests are passing.

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-05-02 13:24:15,Boyang Chen,Mixed
04a70bd3fe40628462f63955c8522cae625feee3,"KAFKA-6829: retry commits on unknown topic or partition (#4948)

For the UNKNOWN_TOPIC_OR_PARTITION error, we could change the consumer's behavior to retry after this error. While this is a rare case since the user would not commit offsets for topics unless they had been able to fetch from them, but this doesn't really handle the situation where the broker hasn't received any metadata updates.

Reviewers: Jason Gustafson <jason@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-05-02 17:01:28,Bill Bejeck,Mixed
55cdc934fb0e3bb184dc3fe3072acc918a0b1174,"Upgrade ZooKeeper to 3.4.12 and Scala to 2.12.6 (#4940)

Reviewers: Jun Rao <junrao@gmail.com>",2018-05-03 09:25:33,Ismael Juma,Not TDD
de147837dda5865565d718d32465ec41f8f44d25,"KAFKA-6853: ZooKeeperRequestLatencyMs is incorrect (#4961)

ResponseMetadata.responseTimeMs is always 0 or negative.

Reviewers: Rajini Sivaram <rajinisivaram@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2018-05-03 09:46:30,Fedor Bobin,Not TDD
6dbd9b59e60eff821fe677af1c6ed33b96243153,"KAFKA-6854; Handle batches deleted during log cleaning of logs with txns (#4962)

Log cleaner grows buffers when result.messagesRead is zero. This contains the number of filtered messages read from source which can be zero when transactions are used because batches may be discarded. Log cleaner incorrectly assumes that messages were not read because the buffer was too small and attempts to double the buffer size unnecessarily, failing with an exception if the buffer is already max.message.bytes. Additional check for discarded batches has been added to avoid growing buffers when batches are discarded.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2018-05-03 13:05:36,Rajini Sivaram,Mixed
a5318722c74ec0279a2e831e93e4164d9adcb8a1,"KAFKA-6857; Leader should reply with undefined offset if undefined leader epoch requested (#4967)

The leader must explicitly check if requested leader epoch is undefined, and return undefined offset so that the follower can fall back to truncating to high watermark. Otherwise, if the leader also is not tracking leader epochs, it may return its LEO, which will the follower to truncate to the incorrect offset.",2018-05-03 23:06:34,Anna Povzner,Mixed
af983267be7a2d0f81527f5a348af377f30caee4,"MINOR: Removed deprecated schedule function (#4908)

While working on this, I also refactored the MockProcessor out of the MockProcessorSupplier to cleanup the unit test paths.

Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-05-04 08:42:01,Guozhang Wang,Mixed
2d8049b713f2b9982bd43e7340a0e0f302f30d6b,"KAFKA-5697: issue Consumer#wakeup during Streams shutdown

Wakeup consumers during shutdown to break them out of any internally blocking calls.

Semantically, it should be fine to treat a WakeupException as ""no work to do"", which will then continue the threads' polling loops, leading them to discover that they are supposed to shut down, which they will do gracefully.

The existing tests should be sufficient to verify no regressions.

Author: John Roesler <john@confluent.io>

Reviewers: Bill Bejeck <bbejeck@gmail.com>, Guozhang Wang <wangguoz@gmail.com>

Closes #4930 from vvcephei/streams-client-wakeup-on-shutdown

minor javadoc updates",2018-05-04 09:05:53,John Roesler,Mixed
f448e49fbe8c3c609f9beffa2f421fc0b875aa3d,"KAFKA-6844: Call shutdown on GlobalStreamThread after all StreamThreads have stopped (#4950)

Moved the shutdown of GlobalStreamThread to after all StreamThread instances have stopped.

There can be a race condition where shut down is called on a StreamThread then shut down is called on a GlobalStreamThread, but if StreamThread is delayed in shutting down, the GlobalStreamThread can shutdown first.
If the StreamThread tries to access a GlobalStateStore before closing the user can get an exception stating ""..Store xxx is currently closed ""

Tested by running all current streams tests.

Reviewers: Ted Yu <yuzhihong@gmail.com>, John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-05-04 15:18:44,Bill Bejeck,Not TDD
564311f5cdedd63fa03052368c321db5ce15dc4f,"MINOR: Remove KafkaStreams#toString (#4909)

Remove the deprecated KafkaStreams#toString function. Also override toString() for internal classes for debugging purposes.

Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-05-04 16:35:17,Guozhang Wang,Mixed
893e0445150614d3538654af0e25f78d87a717ba,"MINOR: Build and code sample updates for Kafka Streams DSL for Scala (#4949)

Several build and documentation updates were required after the merge of KAFKA-6670: Implement a Scala wrapper library for Kafka Streams.

Encode Scala major version into streams-scala artifacts.
To differentiate versions of the kafka-streams-scala artifact across Scala major versions it's required to encode the version into the artifact name before its published to a maven repository. This is accomplished by following a similar release process as kafka core, which encodes the Scala major version and then runs the build for each major version of Scala supported. This is considered standard practice when releasing Scala libraries, but is not handled for us automatically with the basic Scala for Gradle support.

After this change you can generate and install the kafka-streams-scala artifact into the local maven repository:

$ ./gradlew -PscalaVersion=2.11 install
$ ./gradlew -PscalaVersion=2.12 install

Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>",2018-05-06 20:55:12,Sean Glover,Not TDD
32e97b1d9db46cab526d1882eaf9633934ed21bd,"MINOR: Remove deprecated parameter in ProcessorContext#register (#4911)

Updated the upgrade doc as well since we do not have an overloaded function without the deprecated parameter before. Also renamed the 1.2 release version to 2.0.

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-05-07 09:22:26,Guozhang Wang,Mixed
42771eb37d6abd0a34220d30773e559680bdf9b0,"MINOR: Remove deprecated KTable#writeAs, print, foreach, to, through (#4910)

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-05-07 09:44:45,Guozhang Wang,Mixed
2b5a59406622affa1e333e073546f075f59b4ac9,"KAFKA-6813: Remove deprecated APIs in KIP-182, Part I (#4919)

I'm breaking KAFKA-6813 into a couple of ""smaller"" PRs and this is the first one. It focused on:

Remove deprecated APIs in KStream, KTable, KGroupedStream, KGroupedTable, SessionWindowedKStream, TimeWindowedKStream.

Also found a couple of overlooked bugs while working on them:

2.a) In KTable.filter / mapValues without the additional parameter indicating the materialized stores, originally we will not materialize the store. After KIP-182 we mistakenly diverge the semantics: for KTable.mapValues it is still the case, for KTable.filter we will always materialize.

2.b) In XXStream/Table.reduce/count, we used to try to reuse the serdes since their types are pre-known (for reduce it is the same types for both key / value, for count it is the same types for key, and Long for value). This was somehow lost in the past refactoring.

2.c) We are enforcing to cast a Serde<V> to Serde<VR> for XXStream / Table.aggregate, for which the returned value type is NOT known, such the enforced casting should not be applied and we should require users to provide us the value serde if they believe the default ones are not applicable.

2.d) Whenever we are creating a new MaterializedInternal we are effectively incrementing the suffix index for the store / processor-node names. However in some places this MaterializedInternal is only used for validation, so the resulted processor-node / store suffix is not monotonic.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",2018-05-07 17:34:34,Guozhang Wang,Mixed
b88d70b53290af715034a1f772a271f7e44505fd,"MINOR: Make Serdes less confusing in Scala (#4963)

Serdes are confusing in the Scala wrapper:

* We have wrappers around Serializer, Deserializer and Serde which are not very useful.
* We have Serdes in 2 places org.apache.kafka.common.serialization.Serde and in DefaultSerdes, instead we should be having only one place where to find all the Serdes.

I wanted to do this PR before the release as this is a breaking change.
This shouldn't add more so the current tests should be enough.

Reviewers: Debasish Ghosh <dghosh@acm.org>, Guozhang Wang <guozhang@confluent.io>",2018-05-08 09:15:31,Joan Goyeau,Not TDD
bce10794a016f86cda63ceb437d8db7dfc65063b,"KAFKA-6879; Invoke session init callbacks outside lock to avoid Controller deadlock (#4977)

Fixes a deadlock between the controller's beforeInitializingSession callback which holds the zookeeper client initialization lock while awaiting completion of an asynchronous event which itself depends on the same lock.

Also catch and log callback exceptions to ensure the ZooKeeper reconnection takes place.
Finally, configure KafkaScheduler in ZooKeeperClient to have at least 1 thread.

Added tests that fail or hang without the changes in this PR.

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2018-05-08 15:52:43,Jason Gustafson,Mixed
fcb15e357c1b818d2d543dc9db3e011ddc1fbf5e,"KAFKA-6292; Improve FileLogInputStream batch position checks to avoid type overflow (#4928)

Switch from sum operations to subtraction to avoid type casting in checks and type overflow during `FlieLogInputStream` work, especially in cases where property `log.segment.bytes` was set close to the `Integer.MAX_VALUE` and used as a `position` inside `nextBatch()` function.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2018-05-08 17:07:50,Roman Khlebnov,Mixed
7afcb3a64c53831f05f99037dfa07aba1d396c48,"KAFKA-6877; Remove completedFetch upon a failed parse if it contains no records.

This patch removed a completedFetch from the completedFetches queue upon a failed parse if it contains no records. The following scenario explains why this is needed for an instance of this case – i.e. in TopicAuthorizationException.

0. Let's assume a scenario, in which the consumer is attempting to read from a topic without the necessary read permission.
1. In Fetcher#fetchedRecords(), after peeking the completedFetches, the Fetcher#parseCompletedFetch(CompletedFetch) throws a TopicAuthorizationException (as expected).
2. Fetcher#fetchedRecords() passes the TopicAuthorizationException up without having a chance to poll completedFetches. So, the same completedFetch remains at the completedFetches queue.
3. Upon following calls to Fetcher#fetchedRecords(), peeking the completedFetches will always return the same completedFetch independent of any updates to the ACL that the topic is trying to read from.
4. Hence, despite the creation of an ACL with correct permissions, once the consumer sees the TopicAuthorizationException, it will be unable to recover without a bounce.

Author: Adem Efe Gencer <agencer@linkedin.com>

Reviewers: Jiangjie (Becket) Qin <becket.qin@gmail.com>

Closes #4974 from efeg/fix/parseCompletedFetchRemainsInQueue",2018-05-08 18:57:34,Adem Efe Gencer,Mixed
0ecb72f59da6491edc96b99b147b4983be794acf,"KAFKA-6834: Handle compaction with batches bigger than max.message.bytes (#4953)

Grow buffers in log cleaner to hold one message set after sanity check even if message set is bigger than max.message.bytes.

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",2018-05-09 11:46:36,Rajini Sivaram,Mixed
abbd53da4ad98c3a95118c9770a9d247e54b0eef,"KAFKA-6299; Fix AdminClient error handling when metadata changes (#4295)

When AdminClient gets a NOT_CONTROLLER error, it should refresh its metadata and retry the request, rather than making the end-user deal with NotControllerException.

Move AdminClient's metadata management outside of NetworkClient and into AdminMetadataManager. This will make it easier to do more sophisticated metadata management in the future, such as implementing a NodeProvider which fetches the leaders for topics.

Rather than manipulating newCalls directly, the AdminClient service thread now drains it directly into pendingCalls. This minimizes the amount of locking we have to do, since pendingCalls is only accessed from the service thread.",2018-05-09 14:27:28,Colin Patrick McCabe,Mixed
0b1a118f45418aba6af03e71e7169e38cb3ec9af,"KAFKA-6813: Remove deprecated APIs in KIP-182, Part II (#4976)

1. Remove the deprecated StateStoreSuppliers, and the corresponding Stores.create() functions and factories: only the base StateStoreSupplier and MockStoreSupplier were still preserved as they are needed by the deprecated TopologyBuilder and KStreamBuilder. Will remove them in a follow-up PR.

2. Add TopologyWrapper.java as the original InternalTopologyBuilderAccessor was removed, but I realized it is still needed as of now.

3. Minor: removed StateStoreTestUtils.java and inline its logic in its callers since now with StoreBuilder it is just a one-liner.

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-05-09 17:13:05,Guozhang Wang,Mixed
9679c44d2b521b5c627e7bde375c0883f5857e0c,"KAFKA-6361: Fix log divergence between leader and follower after fast leader fail over (#4882)

Implementation of KIP-279 as described here: https://cwiki.apache.org/confluence/display/KAFKA/KIP-279%3A+Fix+log+divergence+between+leader+and+follower+after+fast+leader+fail+over

In summary:
- Added leader_epoch to OFFSET_FOR_LEADER_EPOCH_RESPONSE
- Leader replies with the pair( largest epoch less than or equal to the requested epoch, the end offset of this epoch)
- If Follower does not know about the leader epoch that leader replies with, it truncates to the end offset of largest leader epoch less than leader epoch that leader replied with, and sends another OffsetForLeaderEpoch request. That request contains the largest leader epoch less than leader epoch that leader replied with.

Reviewers: Dong Lin <lindong28@gmail.com>, Jun Rao <junrao@gmail.com>",2018-05-09 18:49:51,Anna Povzner,Mixed
4f7c11a1df26836c7a15f062a5431adb3d371a86,"KAFKA-6870 Concurrency conflicts in SampledStat (#4985)

Make `KafkaMetric.measurableValue` thread-safe

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2018-05-10 12:27:45,Chia-Ping Tsai,Not TDD
fa1702fece04c5fc50149fc9b05d77a459b7180b,"MINOR: Remove deprecated valueTransformer.punctuate (#4993)

Also removed the InternalValueTransformerWithKey / Supplier which is used to mock away the deprecated punctuate function.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2018-05-10 09:50:59,Guozhang Wang,Mixed
c3921d489f4da80aad6f387158c33ec2e4bca52d,"MINOR: Rename RecordFormat to RecordVersion (#4809)

Also include a few clean-ups:

* Method/variable/parameter renames to make them consistent with
the class name
* Return `ApiVersion` from `minSupportedFor`
* Use `values` to remove some code duplication
* Reduce duplication in `ApiVersion` by introducing the `shortVersion`
method and building the versions map programatically
* Avoid unnecessary `regex` in `ApiVersion.apply`
* Added scaladoc to a few methods

Some of these were originally discussed in:

https://github.com/apache/kafka/pull/4583#pullrequestreview-98089400

Added a test for `ApiVersion.shortVersion`. Relying on existing tests
for the rest since there is no change in behaviour.

Reviewers: Jason Gustafson <jason@confluent.io>",2018-05-10 22:06:18,Ismael Juma,Mixed
ec7ba32af6542c6dbbf264a79804d25a98707971,"KAFKA-6394; Add a check to prevent misconfiguration of advertised listeners (#4897)

Do not allow server startup if one of its configured advertised listeners has already been registered by another broker.",2018-05-11 08:49:49,Manikumar Reddy O,Mixed
40d191b563cb8e94b28b15a217a759a1df9b6759,"MINOR: Count fix and Type alias refactor in Streams Scala API (#4966)

Reviewers: Debasish Ghosh <dghosh@acm.org>, Guozhang Wang <guozhang@confluent.io>",2018-05-11 10:15:48,Joan Goyeau,Not TDD
caca1fdc90b6ef877385b044b2a3230f8e6e9874,"KAFKA-6813: Remove deprecated APIs in KIP-182, Part III (#4991)

1. Remove TopologyBuilder, TopologyBuilderException, KStreamBuilder,

2. Completed the leftover work of https://issues.apache.org/jira/browse/KAFKA-5660, when we remove TopologyBuilderException.

3. Added MockStoreBuilder to replace MockStateStoreSupplier, remove all XXStoreSupplier except StateStoreSupplier as it is still referenced in the logical streams graph.

4. Minor: rename KStreamsFineGrainedAutoResetIntegrationTest.java to FineGrainedAutoResetIntegrationTest.java.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2018-05-11 11:38:02,Guozhang Wang,Mixed
9947cd40c617d4e12690b81a2d28624355580e34,"MINOR: Ensure sensor names are unique in Kafka Streams (#5009)

Reviewer: Guozhang Wang <guozhang@confluent.io>",2018-05-11 17:19:11,Matthias J. Sax,Mixed
0bb48a1669d7fdc30d3768f087fd6e592530dde2,"KAFKA-3473; More Controller Health Metrics (KIP-237)

This patch adds a few metrics that are useful for monitoring controller health. See KIP-237 for more detail.

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #4392 from lindong28/KAFKA-3473",2018-05-14 23:04:56,Dong Lin,Not TDD
1e207b2ef83db4296fb944ade4c301794f9e8460,"KAFKA-6896: Add producer metrics exporting in KafkaStreams (#4998)

We would like to also export the producer metrics from StreamThread just like consumer metrics, so that we could gain more visibility of stream application. The approach is to pass in the threadProducer into the StreamThread so that we could export its metrics in dynamic.

Note that this is a pure internal change that doesn't require a KIP, and in the future we also want to export admin client metrics. A followup KIP for admin client will be created once this is merged.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2018-05-15 14:29:07,Boyang Chen,Mixed
1a324d784cfc53288730b7c1b5c1bde0685e4686,"KAFKA-6729: Reuse source topics for source KTable's materialized store's changelog (#5017)

1. In InternalTopologyBuilder#topicGroups, which is used in StreamsPartitionAssignor, look for book-kept storeToChangelogTopic map before creating a new internal changelog topics. In this way if the source KTable is created, its source topic stored in storeToChangelogTopic will be used.

2. Added unit test (confirmed that without 1) it will fail).

3. MINOR: removed TODOs that are related to removed KStreamBuilder.

4. MINOR: removed TODOs in StreamsBuilderTest util functions and replaced with TopologyWrapper.

5. MINOR: removed StreamsBuilderTest#testFrom as it is already covered by TopologyTest#shouldNotAllowToAddSourcesWithSameName, plus it requires KStreamImpl.SOURCE_NAME which should be a package private field of the KStreamImpl.

Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias
 J. Sax <matthias@confluent.io>",2018-05-17 11:28:45,Guozhang Wang,Mixed
6b8e79b13780d4e91d79325e0bf9f1c8df191176,"HOTFIX: move Conusmed to o.a.k.streams.kstream (#5033)

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-05-17 11:56:07,Guozhang Wang,Not TDD
58a910f0a7e6e2da4af9f1fcebdabeb22d909fcb,"KAFKA-5697: revert wakeup-based impl (#5035)

The wakeup-based strategy caused more problems than it
solved, so we'll instead focus on KIP-266.

Revert commit 2d8049b.

Keep the metrics addition and the new test util.

Also keep the tests for shutdown, although they must be ignored until
poll(Duration) is done in the scope of KIP-266.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2018-05-18 08:05:09,John Roesler,Mixed
c53e274d3128bc92f0e8b6a79c407cf764f16f7b,"KAFKA-6917; Process txn completion asynchronously to avoid deadlock (#5036)

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-05-18 13:30:12,Rajini Sivaram,Mixed
4e1c8ffd0d44ab7d1c0ca9ac9d70a98b46f35181,"KAFKA-6849: add transformValues methods to KTable. (#4959)

See the KIP: https://cwiki.apache.org/confluence/display/KAFKA/KIP-292%3A+Add+transformValues%28%29+method+to+KTable

This PR adds the transformValues method to the KTable interface. The semantics of the call are the same as the methods of the same name on the KStream interface.

Fixes KAFKA-6849

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-05-18 16:06:50,Andy Coates,Mixed
9752ccad552543964c2ba92a152cb67636233e13,"KAFKA-6729: Follow up; disable logging for source KTable. (#5038)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2018-05-20 10:24:07,Guozhang Wang,Mixed
96cda0e07ac4981a642c6b32fa543bcce78be769,"MINOR: Fix type inference on joins and aggregates (#5019)

The type inference doesn't currently work for the join functions in Scala as it doesn't know yet the types of the given KStream[K, V] or KTable[K, V].

The fix here is to curry the joiner function. I personally prefer this notation but this also means it differs more from the Java API.
I believe the diff with the Java API is worth in this case as it's not only solving the type inference but also fits better the Scala way of coding (ex: fold).

Moreover any Scala dev will bug and spend little time on these functions trying to understand why the type inference is not working and then get frustrated to be obliged to be explicit here where it's not harmful to be inferred.

Reviewers: Debasish Ghosh <dghosh@acm.org>, Guozhang Wang <guozhang@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2018-05-20 16:25:16,Joan Goyeau,Not TDD
16ad358d64a138fc4b455379745ae1550a93d57b,"KAFKA-6868; Fix buffer underflow and expose group state in the consumer groups API (#4980)

* The consumer groups API should expose group state and coordinator information.  This information is needed by administrative tools and scripts that access consume groups.

* The partition assignment will be empty when the group is rebalancing. Fix an issue where the adminclient attempted to deserialize this empty buffer.

* Remove nulls from the API and make all collections immutable.

* DescribeConsumerGroupsResult#all should return a result as expected, rather than Void

* Fix exception text for GroupIdNotFoundException, GroupNotEmptyException. It was being filled in as ""The group id The group id does not exist was not found"" and similar.

Reviewers: Attila Sasvari <asasvari@apache.org>, Andras Beni <andrasbeni@cloudera.com>, Dong Lin <lindong28@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-05-21 08:37:35,Colin Patrick McCabe,Not TDD
70a506b9839605304a0a67b70e711a1139b47cbe,"MINOR: Ignore test_broker_type_bounce_at_start system test (#5055)

test_broker_type_bounce_at_start tries to validate that when the controller is down, the streams client will always fail trying to create the topic; with the current behavior of admin client it is actually not always true: the actual behavior depends on the admin client internals as well as when the controller becomes unavailable during the leader assign partitions phase. I'd suggest at least ignore this test for now until the admin client has more stable (personally I'd even suggest removing this test as its coverage benefits is smaller than its introduced issues to me).

Also adding a few more log4j entries as a result of investigating this issue.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2018-05-21 17:28:40,Guozhang Wang,Not TDD
e70a191d3038e00790aa95fbd1e16e78c32b79a4,"KAFKA-4423: Drop support for Java 7 (KIP-118) and update deps (#5046)

* Set --source, --target and --release to 1.8.
* Build Scala 2.12 by default.
* Remove some conditionals in the build file now that Java 8
is the minimum version.
* Bump the version of Jetty, Jersey and Checkstyle (the newer
versions require Java 8).
* Fixed issues uncovered by the new version if Checkstyle.
* A couple of minor updates to handle an incompatible source
change in the new version of Jetty.
* Add dependency to jersey-hk2 to fix failing tests caused
by Jersey upgrade.
* Update release script to use Java 8 and to take into account
that Scala 2.12 is now built by default.
* While we're at it, bump the version of Gradle, Gradle plugins,
ScalaLogging, JMH and apache directory api.
* Minor documentation updates including the readme and upgrade
notes. A number of Streams Java 7 examples can be removed
subsequently.",2018-05-21 23:17:42,Ismael Juma,Mixed
a30ecc67556e46e423a16e725bd712eb72ab338b,"MINOR: Remove o.a.kafka.common.utils.Base64 and IS_JAVA8_COMPATIBLE

We no longer need them since we now require Java 8.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Andras Beni <andrasbeni@cloudera.com>, Manikumar Reddy O <manikumar.reddy@gmail.com>, Dong Lin <lindong28@gmail.com>

Closes #5049 from ijuma/remove-base64",2018-05-22 09:57:39,Ismael Juma,Mixed
c1b30a12b1a01ca0d1e39783884e8180f79ed8b1,"MINOR: AdminClient metadata manager should reset state on failure

If the internal metadata request fails, we must reset the state inside `AdminClientMetadataManager` or we will be stuck indefinitely in the `UPDATE_PENDING` state and have no way to fetch new metadata.

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Dong Lin <lindong28@gmail.com>

Closes #5057 from hachikuji/fix-admin-client-metadata-update-failure",2018-05-22 10:12:18,Jason Gustafson,Mixed
133108cdacf7ee1cc4569e797f2cdf9ec60f7fdd,"KAFKA-6850: Add Record Header support to Kafka Streams Processor API (KIP-244) (#4955)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-05-22 15:44:37,Jorge Quilcate Otoya,Mixed
0f86e6884070ec9c867c9354ae331aceeb90b1e8,"MINOR: Remove dependence on __consumer_offsets in AdminClient listConsumerGroups

Avoid dependence on the internal __consumer_offsets topic to handle `listConsumerGroups()` since it unnecessarily requires users to have Describe access on an internal topic. Instead we query each broker independently. For most clusters, this amounts to the same thing since the default number of partitions for __consumer_offsets is 50. This also provides better encapsulation since it avoids exposing the use of __consumer_offsets, which gives us more flexibility in the future.

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Dong Lin <lindong28@gmail.com>

Closes #5007 from hachikuji/remove-admin-use-of-offsets-topic",2018-05-23 12:13:04,Jason Gustafson,Mixed
ff9f928c16ddf95311f1c1badc64212b4975e623,"KAFKA-6911; Fix dynamic keystore/truststore update check (#5029)

Fix the check, add unit test to verify the change, update `DynamicBrokerReconfigurationTest` to avoid dynamic keystore update in tests which are not expected to update keystores.",2018-05-24 16:24:37,Rajini Sivaram,Not TDD
7132a85fc394bc0627fe1763c17cb523d8a8ff37,"KAFKA-6921; Remove old Scala producer and related code

* Removed Scala producers, request classes, kafka.tools.ProducerPerformance, encoders,
tests.
* Updated ConsoleProducer to remove Scala producer support (removed `BaseProducer`
and several options that are not used by the Java producer).
* Updated a few Scala consumer tests to use the new producer (including a minor
refactor of `produceMessages` methods in `TestUtils`).
* Updated `ClientUtils.fetchTopicMetadata` to use `SimpleConsumer` instead of
`SyncProducer`.
* Removed `TestKafkaAppender` as it looks useless and it defined an `Encoder`.
* Minor import clean-ups

No new tests added since behaviour should remain the same after these changes.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Dong Lin <lindong28@gmail.com>

Closes #5045 from ijuma/kafka-6921-remove-old-producer",2018-05-24 17:32:49,Ismael Juma,Mixed
70f0d0bd3f16aa6493271398da34c5960066456c,"MINOR: Use reflection for signal handler and do not enable it for IBM JDK (#5047)

The Signal classes are not available in the compile classpath
if --release is used so we use reflection as a workaround.
As part of that moved the code to Java and added a simple
unit test.

Also disabled the signal handler if the IBM JDK is being used
due to KAFKA-6918.

Manually tested shutdown via ctrl+c and verified that
the message is printed.",2018-05-25 07:00:56,Ismael Juma,Mixed
345db596502de59a3119d2f86186143395b74e5b,"KAFKA-6937: In-sync replica delayed during fetch if replica throttle is exceeded (#5074)

Reviewers: Ismael Juma <ismael@juma.me.uk>, Dong Lin <lindong28@gmail.com>, Ben Stopford <benstopford@gmail.com>",2018-05-25 16:19:12,Jun Rao,Not TDD
39fe105dfd1cae724238f5452d91c84cb6820e50,"Minor: Fixed ConsumerOffset#path (#5060)

consumer offset path in zookeeper should be /consumers/${group}/offsets/${topic}/${partition} instead of /consumers/${group}/offset/${topic}/${partition}. Added `s` to the word `offset`.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy O <manikumar.reddy@gmail.com>, Jun Rao <junrao@gmail.com>",2018-05-25 17:10:59,maytals,Not TDD
7f19df29ac60ec9aef1dbd14704a2dd045b1cfbf,"MINOR: AdminClient should respect retry backoff

AdminClient should backoff when retrying a Call. Fixed and added a unit test

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Dong Lin <lindong28@gmail.com>

Closes #5077 from hachikuji/admin-client-retry-backoff",2018-05-25 17:55:21,Jason Gustafson,Mixed
8c5d7e0408a62aa5f414e8b707050bf8e313a57e,"KAFKA-6562: OAuth Authentication via SASL/OAUTHBEARER (KIP-255) (#4994)

This KIP adds the following functionality related to SASL/OAUTHBEARER:

1) Allow clients (both brokers when SASL/OAUTHBEARER is the inter-broker protocol as well as non-broker clients) to flexibly retrieve an access token from an OAuth 2 authorization server based on the declaration of a custom login CallbackHandler implementation and have that access token transparently and automatically transmitted to a broker for authentication.

2) Allow brokers to flexibly validate provided access tokens when a client establishes a connection based on the declaration of a custom SASL Server CallbackHandler implementation.

3) Provide implementations of the above retrieval and validation features based on an unsecured JSON Web Token that function out-of-the-box with minimal configuration required (i.e. implementations of the two types of callback handlers mentioned above will be used by default with no need to explicitly declare them).

4) Allow clients (both brokers when SASL/OAUTHBEARER is the inter-broker protocol as well as non-broker clients) to transparently retrieve a new access token in the background before the existing access token expires in case the client has to open new connections.",2018-05-26 08:18:41,Ron Dagostino,Mixed
c470ff70d3e829c8b12f6eb6cc812c4162071a1f,"KAFKA-5697; Implement new consumer poll API from KIP-266 (#4855)

Add the new stricter-timeout version of `poll` proposed in KIP-266.

The pre-existing variant `poll(long timeout)` would block indefinitely for metadata
updates if they were needed, then it would issue a fetch and poll for `timeout` ms 
for new records. The initial indefinite metadata block caused applications to become
stuck when the brokers became unavailable. The existence of the timeout parameter
made the indefinite block especially unintuitive.

This PR adds `poll(Duration timeout)` with the semantics:
1. iff a metadata update is needed:
    1. send (asynchronous) metadata requests
    2. poll for metadata responses (counts against timeout)
        - if no response within timeout, **return an empty collection immediately**
2. if there is fetch data available, **return it immediately**
3. if there is no fetch request in flight, send fetch requests
4. poll for fetch responses (counts against timeout)
    - if no response within timeout, **return an empty collection** (leaving async fetch request for the next poll)
    - if we get a response, **return the response**

The old method, `poll(long timeout)` is deprecated, but we do not change its semantics, so it remains:
1. iff a metadata update is needed:
    1. send (asynchronous) metadata requests
    2. poll for metadata responses *indefinitely until we get it*
2. if there is fetch data available, **return it immediately**
3. if there is no fetch request in flight, send fetch requests
4. poll for fetch responses (counts against timeout)
    - if no response within timeout, **return an empty collection** (leaving async fetch request for the next poll)
    - if we get a response, **return the response**

One notable usage is prohibited by the new `poll`: previously, you could call `poll(0)` to block for metadata updates, for example to initialize the client, supposedly without fetching records. Note, though, that this behavior is not according to any contract, and there is no guarantee that `poll(0)` won't return records the first time it's called. Therefore, it has always been unsafe to ignore the response.",2018-05-26 11:50:51,John Roesler,Mixed
8bf20bb58637a59aa816e9d9668741a15fe9b55d,"MINOR: Update consumer javadoc for invalid operations on unassigned partitions  (#5005)

Document cases where  `IllegalStateException` is raised when attempting an invalid operation on an unassigned partition. Also change `position()` to raise `IllegalStateException` when called on an unassigned partition for consistency.",2018-05-28 12:08:14,Manikumar Reddy O,Not TDD
3a8d3a792755cb2bc2a72d3a64dd84b6c8653035,"KAFKA-6916; Refresh metadata in admin client if broker connection fails (#5050)

Refresh metadata if broker connection fails so that new calls are sent only to nodes that are alive and requests to controller are sent to the new controller if controller changes due to broker failure. Also reassign calls that could not be sent.

Reviewers: Dong Lin <lindong28@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-05-29 08:37:17,Rajini Sivaram,Not TDD
a64ab91238aa8fc499397374c3589127425fb229,"KAFKA-5540: Deprecate internal converter configs (KIP-174)

Implementation of [KIP-174](https://cwiki.apache.org/confluence/display/KAFKA/KIP-174+-+Deprecate+and+remove+internal+converter+configs+in+WorkerConfig)

Configuration properties 'internal.key.converter' and 'internal.value.converter'
are deprecated, and default to org.apache.kafka.connect.json.JsonConverter.

Warnings are logged if values are specified for either, or if properties that
appear to configure instances of internal converters (i.e., ones prefixed with
either 'internal.key.converter.' or 'internal.value.converter.') are given.

The property 'schemas.enable' is also defaulted to false for internal
JsonConverter instances (both for keys and values) if it isn't specified.

Documentation and code have also been updated with deprecation notices and
annotations, respectively.

Unit tests have been updated in `PluginsTest` to account for the new defaults for `schemas.enable` for internal key/value converters, and to ensure that (for the time being), internal key/value converters are still configurable despite being deprecated.

Author: Chris Egerton <chrise@confluent.io>
Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #4693 from C0urante/kafka-5540",2018-05-29 16:22:47,Chris Egerton,Mixed
fffb9c5b5cac1a669f22dd99860774d6c0fdb94b,"KAFKA-6913: Add Connect converters and header converters for short, integer, long, float, and double (KIP-305)

*[KIP-305](https://cwiki.apache.org/confluence/display/KAFKA/KIP-305%3A+Add+Connect+primitive+number+converters) has been approved.*

Added converters and header converters for the primitive number types for which Kafka already had serializers and deserializers. All extend a common base class, `NumberConverter`, that encapsulates most of the shared functionality. Unit tests were added to check the basic functionality.

These classes are not used by any other Connect code, and must be explicitly used in Connect workers and connectors.

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Arjun Satish <wicknicks@users.noreply.github.com>, Magesh Nandakumar <magesh.n.kumar@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5034 from rhauch/kafka-6913",2018-05-29 16:37:33,Randall Hauch,Mixed
98094954a27849b027831a7401e965c6a949790c,"KAFKA-6776: ConnectRestExtension Interfaces & Rest integration (KIP-285)

This PR provides the implementation for KIP-285 and also a reference implementation for authenticating BasicAuth credentials using JAAS LoginModule

Author: Magesh Nandakumar <magesh.n.kumar@gmail.com>

Reviewers: Randall Hauch <rhauch@gmail.com>, Arjun Satish <wicknicks@users.noreply.github.com>, Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #4931 from mageshn/KIP-285",2018-05-29 21:35:22,Magesh Nandakumar,Mixed
1facab387f8c2e513c8b7397430251dc44970e35,"KAFKA-6028: Improve the quota throttle communication (KIP-219)

This implements KIP-219, where a broker returns a response with throttle time on
quota violation immediately after processing the corresponding request.  After
the response is sent out, the broker will keep the channel muted until the
throttle time is over. Also, on receiving a response with throttle time, client
will block outgoing communication to the broker for the specified throttle time.

See PR 4830, 5064 and 5094 for all the review history

Author: Jon Lee <jonlee@jonlee-ld1.linkedin.biz>

Reviewers: Jun Rao <junrao@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>,  Dong Lin <lindong28@gmail.com>

Closes #5064 from jonlee2/kip-219",2018-05-30 10:10:33,Jon Lee,Mixed
14171fa8b43e445afd7731463e0b548422602712,"KAFKA-6957 make InternalTopologyBuilder accessible from AbstractStream subclasses (#5085)

Currently, the AbstractStream class defines a copy-constructor that allow to extend KStream and KTable APIs with new methods without impacting the public interface.

However adding new processor or/and store to the topology is made throught the internalTopologyBuilder that is not accessible from AbstractStream subclasses defined outside of the package (package visibility).

Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-05-30 11:13:24,Florian Hussonnois,Mixed
f8dfbb067caa797c19494e12da6b4c6786980f73,"KAFKA-6738: Implement error handling for source and sink tasks (KIP-298)

This PR implements the features described in this KIP: https://cwiki.apache.org/confluence/display/KAFKA/KIP-298%3A+Error+Handling+in+Connect

This PR changes the Connect framework to allow it to automatically deal with errors encountered while processing records in a Connector. The following behavior changes are introduced here:

**Retry on Failure**: Retry the failed operation a configurable number of times, with backoff between each retry.
**Task Tolerance Limits**: Tolerate a configurable number of failures in a task.

We also add the following ways to report errors, along with sufficient context to simplify the debugging process:

**Log Error Context**: The error information along with processing context is logged along with standard application logs.
**Dead Letter Queue**: Produce the original message into a Kafka topic (applicable only to sink connectors).

New **metrics** which will monitor the number of failures, and the behavior of the response handler are added.

The changes proposed here **are backward compatible**. The current behavior in Connect is to kill the task on the first error in any stage. This will remain the default behavior if the connector does not override any of the new configurations which are provided as part of this feature.

Testing: added multiple unit tests to test the retry and tolerance logic.

Author: Arjun Satish <arjun@confluent.io>
Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Magesh Nandakumar <magesh.n.kumar@gmail.com>, Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5065 from wicknicks/KAFKA-6378",2018-05-30 11:39:45,Arjun Satish,Mixed
f33e9a346e22e29bb66e0ea0f3442903d136ca67,"KAFKA-4936: Add dynamic routing in Streams (#5018)

implements KIP-303

Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-05-30 11:54:53,Guozhang Wang,Mixed
08e8facdc9fce3a9195f5f646b49f55ffa043c73,"KAFKA-6886: Externalize secrets from Connect configs (KIP-297)

This commit allows secrets in Connect configs to be externalized and replaced with variable references of the form `${provider:[path:]key}`, where the ""path"" is optional.

There are 2 main additions to `org.apache.kafka.common.config`: a `ConfigProvider` and a `ConfigTransformer`.  The `ConfigProvider` is an interface that allows key-value pairs to be provided by an external source for a given ""path"".  An a TTL can be associated with the key-value pairs returned from the path.  The `ConfigTransformer` will use instances of `ConfigProvider` to replace variable references in a set of configuration values.

In the Connect framework, `ConfigProvider` classes can be specified in the worker config, and then variable references can be used in the connector config.  In addition, the herder can be configured to restart connectors (or not) based on the TTL returned from a `ConfigProvider`.  The main class that performs restarts and transformations is `WorkerConfigTransformer`.

Finally, a `configs()` method has been added to both `SourceTaskContext` and `SinkTaskContext`.  This allows connectors to get configs with variables replaced by the latest values from instances of `ConfigProvider`.

Most of the other changes in the Connect framework are threading various objects through classes to enable the above functionality.

Author: Robert Yokota <rayokota@gmail.com>
Author: Ewen Cheslack-Postava <me@ewencp.org>

Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5068 from rayokota/KAFKA-6886-connect-secrets",2018-05-30 14:43:11,Robert Yokota,Mixed
d166485be15d95192ec1b2818f815fa58726ec54,"KAFKA-6054: Add 'version probing' to Kafka Streams rebalance (#4636)

implements KIP-268

Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-05-30 22:39:42,Matthias J. Sax,Mixed
837f31dd1850b179918f83338b4b4487486b2c58,"KAFKA-6927; Chunked down-conversion to prevent out of memory errors on broker [KIP-283] (#4871)

Implementation for lazy down-conversion in a chunked manner for efficient memory usage during down-conversion. This pull request is mainly to get initial feedback on the direction of the patch. The patch includes all the main components from KIP-283.

Reviewers: Jason Gustafson <jason@confluent.io>",2018-05-30 23:03:51,Dhruvil Shah,Mixed
ad56f04af9d6173628f3ec41b0d9fd9f35855c14,"KAFKA-6936: Implicit materialized for aggregate, count and reduce (#5066)

In #4919 we propagate the SerDes for each of these aggregation operators.

As @guozhangwang mentioned in that PR:

```
reduce: inherit the key and value serdes from the parent XXImpl class.
count: inherit the key serdes, enforce setting the Serdes.Long() for value serdes.
aggregate: inherit the key serdes, do not set for value serdes internally.
```

Although it's all good for reduce and count, it is quiet unsafe to have aggregate without Materialized given. In fact I don't see why we would not give a Materialized for the aggregate since the result type will always be different (otherwise use reduce) and also the value Serde is simply not propagated.

This has been discussed previously in a broader PR before but I believe for aggregate we could pass implicitly a Materialized the same way we pass a Joined, just to avoid the stupid case. Then if the user wants to specialize, he can give his own Materialized.

Reviewers: Debasish Ghosh <dghosh@acm.org>, Guozhang Wang <guozhang@confluent.io>",2018-05-31 17:19:37,Joan Goyeau,Not TDD
0120e88e2cab1c02cac471ab4acc76ce876bf72b,"KAFKA-6973: Validate topic config message.timestamp.type (#5106)

Specifying an invalid config (i.e. something other than `CreateTime` or
`LogAppendTime`) via `TopicCommand` would previously cause the
broker to fail on start-up.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2018-06-01 07:12:42,huxi,Not TDD
cb2f024f87aa1d4848eb059b15fefd7eca028a73,"MINOR: Use thread name and task for sensor name (#5111)

Changes to keep the operation name as is and make the sensor name unique.

Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-06-01 14:48:44,Bill Bejeck,Not TDD
73e2cbbd8f56f70bd5ef4594adc3770fa5a402ce,"KAFKA-6760: Fix response logging in the Controller (#4834)

- Override toString in LeaderAndIsrResponse and StopReplicaResponse
- Add unit tests

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-06-01 16:40:16,Mickael Maison,Mixed
341d5db2604f20a8bd2a69e9ad08d14462829068,"KAFKA-6955: Use Java AdminClient in DeleteRecordsCommand (#5088)

- Removed internal kafka.admin.AdminClient.deleteRecordsBefore since it's
no longer used.
- Removed redundant tests and rewrote non redundant ones to use the Java
AdminClient.

Reviewers: Viktor Somogyi <viktor.somogyi@cloudera.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2018-06-02 12:41:55,Vahid Hashemian,Not TDD
0cacbcf30e0a90ab9fad7bc310e5477cf959f1fd,"MINOR: Remove usages of JavaConversions and fix some typos (#5115)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-06-02 23:45:44,Vahid Hashemian,Not TDD
d02f02130eb36cdc4375eb40bdbe4a1f9b58fc60,"MINOR: Fix bug in AdminClient node reassignment following connection failure (#5112)

We added logic to reassign nodes in callToSend after a connection failure, but we do not handle the case when there is no node currently available to reassign the request to. This can happen when using MetadataUpdateNodeIdProvider if all of the known nodes are blacked out awaiting the retry backoff. To fix this, we need to ensure that the call is added to pendingCalls if a new node cannot be found.",2018-06-04 10:23:05,Jason Gustafson,Mixed
718d6f2475d377fd220da9898d25f7c8191f98cd,"MINOR: Remove deprecated KafkaStreams constructors in docs (#5118)

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-06-04 13:43:20,Guozhang Wang,Not TDD
6f9f3655731ea1d46bd1f0ed0957579d831e2692,"KAFKA-6813: return to double-counting for count topology names (#5075)

#4919 unintentionally changed the topology naming scheme. This change returns to the prior scheme.

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-06-04 15:33:53,John Roesler,Mixed
9df3872fbd1526bf6aecab1fcfdc52a33ab9630e,"KAFKA-3665: Enable TLS hostname verification by default (KIP-294) (#4956)

Make HTTPS the default ssl.endpoint.identification.algorithm.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-06-05 04:08:13,Rajini Sivaram,Mixed
8a166f8c28cf046cba0c596d781f1daeca795ccd,"KAFKA-6750: Add listener name to authentication context (KIP-282) (#4829)

PrincipalBuilder implementations can now take the listener into account
when creating the Principal. This is especially interesting in deployments
where inter-broker traffic is on a different listener than client traffic or
when the same protocol is used by multiple listeners.

The change in itself is mostly ""plumbing"" as the listener name needs to be
passed from ChannelBuilders all the way down to all classes implementing
AuthenticationContext.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>

Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>
Co-authored-by: Mickael Maison <mickael.maison@gmail.com>",2018-06-05 05:23:10,Mickael Maison,Mixed
ef413699b658c939fa0a3930ddbface69bedd26e,"KAFKA-6704: InvalidStateStoreException from IQ when StreamThread closes store (#4801)

While using an iterator from IQ, it's possible to get an InvalidStateStoreException if the StreamThread closes the store during a range query.

Added a unit test to SegmentIteratorTest for this condition.

Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-06-05 11:49:36,Bill Bejeck,Mixed
7c69de42df78bbb4a651b293038d4e957e528970,MINOR: Rename package `internal` to `internals` for consistency (#5137),2018-06-05 21:07:30,Rajini Sivaram,Mixed
ba0ebca7a516d4179b6327ddc60b0b49b1265347,"[KAFKA-6730] Simplify State Store Recovery (#5013)

Reviewer: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",2018-06-05 13:35:47,ConcurrencyPractitioner,Mixed
faa15b8b758ed4e3f93aaa4d49a941562bdc86bb,"KAFKA-6981: Move the error handling configuration properties into the ConnectorConfig and SinkConnectorConfig classes (KIP-298)

Move the error handling configuration properties into the ConnectorConfig and SinkConnectorConfig classes, and refactor the tests and classes to use these new properties.

Testing: Unit tests and running the connect-standalone script with a file sink connector.

Author: Arjun Satish <arjun@confluent.io>
Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Magesh Nandakumar <magesh.n.kumar@gmail.com>, Robert Yokota <rayokota@gmail.com>, Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5125 from wicknicks/KAFKA-6981",2018-06-05 13:59:15,Arjun Satish,Mixed
be8808dd4b4c67add4cd3b5adbc54b263a027831,"KAFKA-5588: Remove deprecated --new-consumer tools option (#5097)

Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Vahid Hashemian <vahidhashemian@us.ibm.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2018-06-05 20:28:03,Paolo Patierno,Mixed
0c035c46b47cd4734d0529486e776c6c18d6643d,"KAFKA-6726: Fine Grained ACL for CreateTopics (KIP-277) (#4795)

- CreateTopicsRequest now requires Create auth on Topic resource
or Create on Cluster resource.
- AclCommand --producer option adjusted
- Existing unit and Integration tests adjusted accordingly and
new tests added.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>
Co-authored-by: Mickael Maison <mickael.maison@gmail.com>",2018-06-06 03:36:52,Edoardo Comar,Mixed
b3aa655a70d92fedfebd32cf469a87b45766fc59,"KAFKA-6841: Support Prefixed ACLs (KIP-290) (#5117)

Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Jun Rao <junrao@gmail.com>

Co-authored-by: Piyush Vijay <pvijay@apple.com>
Co-authored-by: Andy Coates <big-andy-coates@users.noreply.github.com>",2018-06-06 07:22:57,Andy Coates,Mixed
8264492deefa594567573fecd19fba3068bf3d6f,"MINOR: Use service loader for ConfigProvider impls (KIP-297)

This is a small change to use the Java ServiceLoader to load ConfigProvider plugins.  It uses code added by mageshn for Connect Rest Extensions.

Author: Robert Yokota <rayokota@gmail.com>

Reviewers: Magesh Nandakumar <magesh.n.kumar@gmail.com>, Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5141 from rayokota/service-loader-for-config-plugins",2018-06-06 08:55:57,Robert Yokota,Mixed
0eddddb82be563bee9e4b65030e27efd5148ff4b,"KAFKA-6967: TopologyTestDriver does not allow pre-populating state stores that have change logging (#5096)

Reviewers: Guozhang Wang <guozhang@confluent.io>, James Cheng <jylcheng@yahoo.com>, Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>",2018-06-06 15:16:21,Matthias J. Sax,Mixed
f54acdbb13a6cf2a7ef9979f5a4e04240b1724c5,"KAFKA-6935: Add config for allowing optional optimization (#5071)

Adding configuration to StreamsConfig allowing for making topology optimization optional.

Added unit tests are verifying default values, setting correct value and failure on invalid values.

Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-06-06 18:11:03,Bill Bejeck,Mixed
642a09168c38e961a2936e5a2fe72f5cd83ae7a6,"KAFKA-6991: Fix ServiceLoader issue with PluginClassLoader (KIP-285)

Fix ServiceLoader issue with PluginClassLoader and add basic-auth-extension packaging & classpath

*More detailed description of your change,
if necessary. The PR title and PR message become
the squashed commit message, so use a separate
comment to ping reviewers.*

*Summary of testing strategy (including rationale)
for the feature or bug fix. Unit and/or integration
tests are expected for any behaviour change and
system tests should be considered for larger changes.*

Author: Magesh Nandakumar <magesh.n.kumar@gmail.com>

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5135 from mageshn/KAFKA-6991",2018-06-06 21:09:16,Magesh Nandakumar,Mixed
22612be46dd68255642ca50a1f78fa1790eb4759,"KAFKA-7002: Add a config property for DLQ topic's replication factor (KIP-298)

Currently, the replication factor is hardcoded to a value of 3. This means that we cannot use a DLQ in any cluster setup with less than three brokers. It is better to have the user specify this value if the default value does meet the requirements.

Testing: A unit test is added.

Signed-off-by: Arjun Satish <arjunconfluent.io>

Author: Arjun Satish <arjun@confluent.io>

Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5145 from wicknicks/KAFKA-7002",2018-06-07 15:49:57,Arjun Satish,Not TDD
b4fa87cc51f0a7d640dc6ae2cc8f89f006aae652,"KAFKA-7011 - Remove ResourceNameType field from Java Resource class. (#5160)

The initial PR for KIP-290 #5117 added a `ResourceNameType` field to the Java and Scala `Resource` classes to introduce the concept of Prefixed ACLS.  This does not make a lot of sense as these classes are meant to represent cluster resources, which would not have a concept of 'name type'. This work has not been released yet, so we have time to change it.

This PR looks to refactor the code to remove the name type field from the Java `Resource` class. (The Scala one will age out once KIP-290 is done, and removing it would involve changes to the `Authorizer` interface, so this class was not touched).

This is achieved by replacing the use of `Resource` with `ResourcePattern` and `ResourceFilter` with `ResourceFilterPattern`.  A `ResourcePattern` is a combination of resource type, name and name type, where each field needs to be defined. A `ResourcePatternFilter` is used to select patterns during describe and delete operations.

The adminClient uses `AclBinding` and `AclBindingFilter`. These types have been switched over to use the new pattern types.

The AclCommands class, used by Kafka-acls.sh, has been converted to use the new pattern types.

The result is that the original `Resource` and `ResourceFilter` classes are not really used anywhere, except deprecated methods. However, the `Resource` class will be used if/when KIP-50 is done.

Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Jun Rao <junrao@gmail.com>",2018-06-07 16:35:30,Andy Coates,Mixed
0b3989fd72acc6e989c495c63cb8ca6aa5850811,"KAFKA-7006 - remove duplicate Scala ResourceNameType in preference to… (#5152)

remove duplicate Scala ResourceNameType in preference to in preference to Java ResourceNameType.

This is follow on work for KIP-290 and PR #5117, which saw the Scala ResourceNameType class introduced.

I've added tests to ensure AclBindings can't be created with ResourceNameType.ANY or UNKNOWN.

Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Jun Rao <junrao@gmail.com>",2018-06-08 08:13:44,Andy Coates,Mixed
d2b2fbdf94cf48094081650ebc18ee860e67d8d5,"KAFKA-6264; Split log segments as needed if offsets overflow the indexes (#4975)

This patch adds logic to detect and fix segments which have overflowed offsets as a result of bugs in older versions of Kafka.

Reviewers: Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-06-08 08:39:59,Dhruvil Shah,Mixed
74bdafe386ae6080d6f5ead852f9026061a65be4,"KAFKA-5697: Use nonblocking poll in Streams (#5107)

Make use of the new Consumer#poll(Duration) to avoid getting stuck in poll when the broker is unavailable.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",2018-06-08 10:54:26,John Roesler,Mixed
7d85785d3de7640ca0ee61e7110a32286e328343,"KAFKA-6946; Keep the session id for incremental fetch when fetch responses are throttled

Currently, a throttled fetch response is returned with INVALID_SESSION_ID, which causes dropping the current fetch session if incremental fetch is in progress. This patch fixes this by returning the correct session id.

Author: Jon Lee <jonlee@linkedin.com>

Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Dong Lin <lindong28@gmail.com>

Closes #5164 from jonlee2/KAFKA-6946",2018-06-11 10:35:30,Jon Lee,Mixed
49db5a63c043b50c10c2dfd0648f8d74ee917b6a,"KAFKA-7005: Remove duplicate resource class. (#5184)

This is a follow-on change requested as part of the initial PR for KIP-290 #5117.  @cmccabe requested that the `resource.Resource` class be factored out in favour of `ConfigResource` to avoid confusion between all the `Resource` implementations.

Colin Patrick McCabe <colin@cmccabe.xyz>, Jun Rao <junrao@gmail.com>",2018-06-11 13:26:22,Andy Coates,Mixed
ee5cc974d2ef449444861d82e1793668184ca86f,"KAFKA-6906: Fixed to commit transactions if data is produced via wall clock punctuation (#5105)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-06-11 14:40:03,Jagadesh Adireddi,Mixed
3face7fce2489715c040c9756ec05406aaa657d4,"KAFKA-7003: Set error context in message headers (KIP-298)

If the property `errors.deadletterqueue.context.headers.enable` is set to true, add a set of headers to the message describing the context under which the error took place.

A unit test is added to check the correctness of header creation.

Signed-off-by: Arjun Satish <arjunconfluent.io>

Author: Arjun Satish <arjun@confluent.io>

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5159 from wicknicks/KAFKA-7003",2018-06-11 15:16:46,Arjun Satish,Not TDD
d98ec33364d4ddb6ee53e0cd6001857207ba2089,"KAFKA-7021: Reuse source based on config (#5163)

This PR actually contains two changes:

1. leverage on the TOPOLOGY_OPTIMIZATION config to ""adjust"" the topology internally to reuse the source topic.

2. fixed a long dangling bug that whenever source topic is reused as changelog topic, write the checkpoint file for the consumed offset, this is done by union the ackedOffset from the producer, plus the consumed offset from the consumer, note we will priori ackedOffset since the same topic may show up in both (think about repartition topic), by doing this the consumed offset from source topics can be treated as checkpointed offset when reuse happens.

3. added a few unit and integration tests with / wo the reusing, and make sure the restoration, standby task, and internal topic creation behaviors are all correct.

Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-06-11 16:08:24,Guozhang Wang,Mixed
4580d9f16aabc44f3d97931c6bfa29de1e40bf2d,"MINOR: Remove deprecated per-partition lag metrics

It takes O(n^2) time to instantiate a mbean with n attributes which can be very slow if the number of attributes of this mbean is large. This PR removes metrics whose number of attributes can grow with the number of partitions in the cluster to fix the performance issue. These metrics have already been marked for removal in 2.0 by KIP-225.

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #5172 from lindong28/remove-deprecated-metrics",2018-06-11 23:32:30,Dong Lin,Mixed
2bfb239495c97e57ee51f2f462f5d09160a0d67b,"KAFKA-7029: Update ReplicaVerificationTool not to use SimpleConsumer (#5188)

We need to send fetch requests to replicas so we have to use
NetworkClient instead of KafkaConsumer.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-06-12 00:46:24,Manikumar Reddy O,Mixed
fa1d0383902260576132e09bdf9efcc2784b55b4,"MINOR: Clean up imports and unused variables (#5171)

Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2018-06-12 02:08:51,Jimin Hsieh,Not TDD
7a590612524bd8e899c8d6bbb73daece7f352d46,"KAFKA-7023: Add unit test (#5197)

Add a unit test that validates after restoreStart, the options are set with bulk loading configs; and after restoreEnd, it resumes to the customized configs

Reviewers: Matthias J. Sax <matthias@confluent.io>",2018-06-12 11:12:07,Guozhang Wang,Mixed
40f63eb9c1775bd292a5d028412fb784b7854701,"KAFKA-6782: solved the bug of restoration of aborted messages for GlobalStateStore and KGlobalTable (#4900)

Reviewer: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-06-12 11:54:07,Gitomain,Not TDD
16190e9bfd2db13a886b4122127fbe4f96ed8f65,"MINOR: Move FileConfigProvider to provider subpackage (#5194)

This moves FileConfigProvider to the org.apache.common.config.provider package to more easily isolate provider implementations going forward.

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2018-06-12 12:52:51,Robert Yokota,Mixed
a5924025126a6ab77fd9fb74cf66a180931ffecf,"KAFKA-7007:  Use JSON for /kafka-acl-extended-changes path (#5161)

Keep Literal ACLs on the old paths, using the old formats, to maintain backwards compatibility.
Have Prefixed, and any latter types, go on new paths, using JSON, (old brokers are not aware of them)
Add checks to reject any adminClient requests to add prefixed acls before the cluster is fully upgraded.

Colin Patrick McCabe <colin@cmccabe.xyz>, Jun Rao <junrao@gmail.com>",2018-06-12 19:07:10,Andy Coates,Mixed
53ca52f855e903907378188d29224b3f9cefa6cb,"KAFKA-6979; Add `default.api.timeout.ms` to KafkaConsumer (KIP-266) (#5122)

Adds a configuration that specifies the default timeout for KafkaConsumer APIs that could block. This was introduced in KIP-266.

Reviewers: Satish Duggana <satish.duggana@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-06-12 16:29:50,Dhruvil Shah,Mixed
22356d55ef232871f144be750087f71c5ed1e9a9,"KAFKA-7043: Modified plugin isolation whitelist with recently added converters (KIP-305)

Several recently-added converters are included in the plugin isolation whitelist, similarly to the `StringConverter`. This is a change in the implementation, and does not affect the approved KIP. Several unit tests were added to verify they are being loaded in isolation, again similarly to `StringConverter`.

These changes should be applied only to `trunk` and `2.0`, since these converters were added as part of KIP-305 for AK 2.0.

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Magesh Nandakumar <magesh.n.kumar@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5198 from rhauch/kafka-7043",2018-06-12 21:35:45,Randall Hauch,Mixed
5145d6b6b413721948bf89079b13ddbe82143bf1,"MINOR: Remove unnecessary old consumer usage in tests and other clean-ups (#5199)

- Update some tests to use the Java consumer.
- Remove ignored `ProducerBounceTest.testBrokerFailure`. This test
is flaky and it has been superseded by `TransactionBounceTest`.
- Use non-blocking poll for consumption methods in `TestUtils`.

This is a step on the road to remove the old consumers.",2018-06-13 00:51:11,Ismael Juma,Mixed
ff96d574371811c75f4f454847f67508d1de98c0,"KAFKA-6860: Fix NPE in Kafka Streams with EOS enabled (#5187)

Reviewers: John Roesler <john@confluent.io>, Ko Byoung Kwon, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-06-13 15:13:55,Matthias J. Sax,Mixed
443091b844d4119637d252a5303568e22d4f1d48,"KAFKA-7050; Decrease default consumer request timeout to 30s (#5203)

This patch changes the default `request.timeout.ms` of the consumer to 30 seconds. Additionally, it adds logic to `NetworkClient` and related to components to support timeouts at the request level. We use this to handle the special case of the JoinGroup request, which may block for as long as the value configured by `max.poll.interval.ms`.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <guozhang@confluent.io>",2018-06-13 16:21:30,Jason Gustafson,Mixed
9a71bfb9d64dae5d0296d162a01a62d8c13324da,"KAFKA-7030; Add configuration to disable message down-conversion (KIP-283) (#5192)

Add support for the topic-level `message.downconversion.enable` config as part of KIP-283.",2018-06-13 21:23:23,Dhruvil Shah,Not TDD
0dfa53c47a5a6ea0c06dfbd8341507322efe199f,KAFKA-6711: GlobalStateManagerImpl should not write offsets of in-memory stores in checkpoint file (#5219),2018-06-14 12:44:09,Matthias J. Sax,Mixed
37a4d5ea46bb5ba1bdf2d7cb03c3678a128b6f9e,"KAFKA-6975; Fix replica fetching from non-batch-aligned log start offset (#5133)

It is possible that log start offset may fall in the middle of the batch after AdminClient#deleteRecords(). This will cause a follower starting from log start offset to fail fetching (all records). Use-cases when a follower will start fetching from log start offset includes: 1) new replica due to partition re-assignment; 2) new local replica created as a result of AdminClient#AlterReplicaLogDirs(); 3) broker that was down for some time while AdminClient#deleteRecords() move log start offset beyond its HW. 

Added two integration tests:
1) Produce and then AdminClient#deleteRecords() while one of the followers is down, and then restart of the follower requires fetching from log start offset;
2)  AdminClient#AlterReplicaLogDirs() after AdminClient#deleteRecords()

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-06-14 08:26:45,Anna Povzner,Mixed
642a97783d29bb1d43ee20e8564db7b9432dade2,"KAFKA-7010: Rename ResourceNameType to PatternType (#5205)

The initial PR for KIP-290 #5117 added a new `ResourceNameType`, which was initially a field on `Resource` and `ResourceFilter`. However, follow on PRs have now moved the name type fields to new `ResourcePattern` and `ResourcePatternFilter` classes. This means the old name is no longer valid and may be confusing. The PR looks to rename the class to a more intuitive `resource.PatternType`.

@cmccabe also requested that the current `ANY` value for this class be renamed to avoid confusion. `PatternType.ANY` currently causes `ResourcePatternFilter` to bring back all ACLs that would affect the supplied resource, i.e. it brings back literal, wildcard ACLs, and also does pattern matching to work out which prefix acls would affect the resource.  This is very different from the behaviour of `ResourceType.ANY`, which just means the filter ignores the type of resources. 

 `ANY` is to be renamed to `MATCH` to disambiguate it from other `ANY` filter types. A new `ANY` will be added that works in the same way as others, i.e. it will cause the filter to ignore the pattern type, (but won't do any pattern matching).

Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Jun Rao <junrao@gmail.com>",2018-06-14 17:47:59,Andy Coates,Mixed
339fc2379dd0d01bc039518f70b017b7520dcc9f,"KAFKA-7055: Update InternalTopologyBuilder to throw TopologyException if a processor or sink is added with no upstream node attached (#5215)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",2018-06-14 20:26:01,nixsticks,Mixed
a8c17e36c3239f33925b061d99a5d1d1074bbc67,"MINOR: Fix chunked down-conversion behavior when no valid batch exists after conversion (#5173)

We might decide to drop certain message batches during down-conversion because older clients might not be able to interpret them. One such example is control batches which are typically removed by the broker if down-conversion to V0 or V1 is required. This patch makes sure the chunked down-conversion implementation is able to handle such cases.",2018-06-14 23:00:33,Dhruvil Shah,Mixed
f2cb8523d1d9c74ebf2fd6f58f51e8afc95f01ca,"KAFKA-7032 The TimeUnit is neglected by KakfaConsumer#close(long, Tim… (#5182)",2018-06-15 12:16:04,Chia-Ping Tsai,Mixed
fab8b7e676bcaf4faf84d563ab48e3ebee61b4ab,"KAFKA-7056: Moved Connect’s new numeric converters to runtime (KIP-305)

KIP-305 added numeric converters to Connect, but these were added in Connect’s API module in the same package as the `StringConverter`. This commit moves them into the Runtime module and into the `converters` package where the `ByteArrayConverter` already lives. These numeric converters have not yet been included in a release, and so they can be moved without concern.

All of Connect’s converters must be referenced in worker / connector configurations and are therefore part of the API, but otherwise do not need to be in the “api” module as they do not need to be instantiated or directly used by extensions. This change makes them more similar to and aligned with the `ByteArrayConverter`.

It also gives us the opportunity to move them into the “api” module in the future (keeping the same package name), should we ever want or need to do so. However, if we were to start out with them in the “api” module, we would never be able to move them out into the “runtime” module, even if we kept the same package name. Therefore, moving them to “runtime” now gives us a bit more flexibility.

This PR moves the unit tests for the numeric converters accordingly, and updates the `PluginsUtil` and `PluginUtilsTest` as well.

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5222 from rhauch/kafka-7056",2018-06-15 14:52:28,Randall Hauch,Mixed
f0282cb3de9b60d6eea12803103f8ca4d7f45734,"KAFKA-7047: Added SimpleHeaderConverter to plugin isolation whitelist

This was originally missed when headers were added as part of KIP-145 in AK 1.1. An additional unit test was added in line with the StringConverter.

This should be backported to the AK `1.1` branch so that it is included in the next bugfix release. The `SimpleHeaderConverter` class that we're referencing was first added in the 1.1.0 release, so there's no reason to backport earlier.

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5204 from rhauch/kafka-7047",2018-06-16 22:23:20,Randall Hauch,Mixed
be846d833caade74f1d0536ecf9d540855cde758,"KAFKA-7058: Comparing schema default values using Objects#deepEquals()

https://issues.apache.org/jira/browse/KAFKA-7058
* Summary of testing strategy: Added new unit test

Author: Gunnar Morling <gunnar.morling@googlemail.com>

Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5225 from gunnarmorling/KAFKA-7058",2018-06-16 23:04:31,Gunnar Morling,Mixed
d06da1b7f424ebad16ea5eca11b58b7c2ca3fa34,"KAFKA-7068: Handle null config values during transform (KIP-297)

Fix NPE when processing null config values during transform.

Author: Robert Yokota <rayokota@gmail.com>

Reviewers: Magesh Nandakumar <magesh.n.kumar@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5241 from rayokota/KIP-297-null-config-values",2018-06-17 12:12:11,Robert Yokota,Mixed
6810617179222ae659343efb02ef7e6cefb15662,"KAFKA-7048 NPE when creating connector (#5202)

Reviewers: Robert Yokota <rayokota@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-06-17 16:49:01,Chia-Ping Tsai,Mixed
d504e85011332016447472fb37f1c1edd8acbf1a,"KAFKA-6805: Enable broker configs to be stored in ZK before broker start (#4898)

Support configuration of dynamic broker configs in ZooKeeper before starting brokers using ConfigCommand. This will allow password configs to be encrypted and stored in ZooKeeper, without requiring clear passwords in server.properties to bootstrap the broker first.

Reviewers: Jason Gustafson <jason@confluent.io>",2018-06-18 18:28:08,Rajini Sivaram,Mixed
1354371d4f4dd208458c776e1f27715ec5f77f47,"KAFKA-6761: Construct logical Streams Graph in DSL Parsing (#4983)

This version is a WIP and intentionally leaves out some additional required changes to keep the reviewing effort more manageable. This version of the process includes

1. Cleaning up the graph objects to reduce the number of parameters and make the naming conventions more clear.
2. Intercepting all calls to the InternalToplogyBuilder and capturing all details required for possible optimizations and building the final topology.

This PR does not include writing out the current physical plan, so no tests included. The next PR will include additional changes to building the graph and writing the topology out without optimizations, using the current streams tests.

Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-06-18 10:58:26,Bill Bejeck,Mixed
e8955f731eff61417ec04253547f125cb921a59a,"KAFKA-7012: Don't process SSL channels without data to process (#5237)

Avoid unnecessary processing of SSL channels when there are some bytes buffered, but not enough to make progress.

Reviewers: Radai Rosenblatt <radai.rosenblatt@gmail.com>, Jun Rao <junrao@gmail.com>",2018-06-19 15:16:16,Rajini Sivaram,Not TDD
cc4dce94af8b19a796eeb7a9be78640739cb1a48,"KAFKA-2983: Remove Scala consumers and related code (#5230)

- Removed Scala consumers (`SimpleConsumer` and `ZooKeeperConsumerConnector`)
and their tests.
- Removed Scala request/response/message classes.
- Removed any mention of new consumer or new producer in the code
with the exception of MirrorMaker where the new.consumer option was
never deprecated so we have to keep it for now. The non-code
documentation has not been updated either, that will be done
separately.
- Removed a number of tools that only made sense in the context
of the Scala consumers (see upgrade notes).
- Updated some tools that worked with both Scala and Java consumers
so that they only support the latter (see upgrade notes).
- Removed `BaseConsumer` and related classes apart from `BaseRecord`
which is used in `MirrorMakerMessageHandler`. The latter is a pluggable
interface so effectively public API.
- Removed `ZkUtils` methods that were only used by the old consumers.
- Removed `ZkUtils.registerBroker` and `ZKCheckedEphemeral` since
the broker now uses the methods in `KafkaZkClient` and no-one else
should be using that method.
- Updated system tests so that they don't use the Scala consumers except
for multi-version tests.
- Updated LogDirFailureTest so that the consumer offsets topic would
continue to be available after all the failures. This was necessary for it
to work with the Java consumer.
- Some multi-version system tests had not been updated to include
recently released Kafka versions, fixed it.
- Updated findBugs and checkstyle configs not to refer to deleted
classes and packages.

Reviewers: Dong Lin <lindong28@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2018-06-19 07:32:54,Ismael Juma,Mixed
3afe2ed8e39da3605274baddc7245be569b4aed7,"MINOR: Handle segment splitting edge cases and fix recovery bug  (#5169)

This patch fixes the following issues in the log splitting logic added to address KAFKA-6264:

1. We were not handling the case when all messages in the segment overflowed the index. In this case, there is only one resulting segment following the split.
2. There was an off-by-one error in the recovery logic when completing a swap operation which caused an unintended segment deletion.

Additionally, this patch factors out of `splitOverflowedSegment` a method to write to a segment using from with an instance of `FileRecords`. This allows for future reuse and isolated testing.

Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",2018-06-19 13:26:29,Jason Gustafson,Mixed
d2b84bd4b03d528ff82c8fb6067f118ca9256792,"Kafka_7064 - bug introduced when switching config commands to ConfigResource  (#5245)

Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Jun Rao <junrao@gmail.com>",2018-06-19 13:47:24,Andy Coates,Mixed
410e00cbcb7dd664dcd1f451eca57e5882985186,"KAFKA-7066 added better logging in case of Serialisation issue (#5239)

Following the error message of: 

https://github.com/apache/kafka/blob/trunk/streams/src/main/java/org/apache/kafka/streams/processor/internals/SinkNode.java#L93

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-06-19 14:10:13,Stephane Maarek,Mixed
fd969beae7326aed70fd201f299e9ebb0e0b72a9,"KAFKA-6697: Broker should not die if getCanonicalPath fails (#4752)

A broker with multiple log dirs will die on startup if dir.getCanonicalPath() throws
IOException for one of the log dirs. We should mark such log directory as offline
instead and the broker should start if there is a healthy log dir.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-06-20 01:24:26,Dong Lin,Mixed
96bcfdfc7c9aac075635b2034e65e412a725672e,"MINOR: Use exceptions in o.a.k.common if possible and deprecate ZkUtils (#5255)

Also:
- Remove exceptions in `kafka.common` that are no longer used.
- Keep `kafka.common.KafkaException` as it's still used by `ZkUtils`,
`kafka.admin.AdminClient` and `kafka.security.auth` classes and
we would like to maintain compatibility for now.
- Add deprecated annotation to `kafka.admin.AdminClient`. The scaladoc
stated that the class is deprecated, but the annotation was missing.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2018-06-20 05:05:50,Ismael Juma,Mixed
e5ec3f55c968292ae8fd0cb8ad8b626abed8f503,"KAFKA-6546: Use LISTENER_NOT_FOUND_ON_LEADER error for missing listener (#5189)

For metadata request version 6 and above, use a different error code to indicate missing listener on leader broker to enable diagnosis of listener configuration issues.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-06-20 17:08:58,Rajini Sivaram,Mixed
6732593bbad3d1e07f1ec7c2d00a2e1eabf382f2,"KAFKA-7072: clean up segments only after they expire (#5253)

Significant refactor of Segments to use stream-time as the basis of segment expiration.
Previously Segments assumed that the current record time was representative of stream time.

In the event of a ""future"" event (one whose record time is greater than the stream time), this
would inappropriately drop live segments. Now, Segments will provision the new segment
to house the future event and drop old segments only after they expire.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-06-20 18:40:48,John Roesler,Mixed
d3e264e773c4652f34b40c7c3b494c0f7fbabffc,"MINOR: update web docs and examples of Streams with Java8 syntax (#5249)

Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Damian Guy <damian@confluent.io>",2018-06-21 10:02:58,Guozhang Wang,Not TDD
e33ccb628efd9a039d2ad9f9ca74f001bc682fcd,"KAFKA-7082: Concurrent create topics may throw NodeExistsException (#5259)

This is an unexpected exception so `UnknownServerException`
is thrown back to the client.

This is a minimal change to make the behaviour match `ZkUtils`.
This is better, but one could argue that it's not perfect. A more
sophisticated approach can be tackled separately.

Added a concurrent test that fails without this change.

Reviewers: Jun Rao <junrao@gmail.com>",2018-06-21 16:47:44,Ismael Juma,Mixed
418a91b5d4e3a0579b91d286f61c2b63c5b4a9b6,"KAFKA-4682; Revise expiration semantics of consumer group offsets (KIP-211 - Part 1) (#4896)

This patch contains the improved offset expiration semantics proposed in KIP-211. Committed offsets will not be expired as long as a group is active. Once all members have left the group, then offsets will be expired after the timeout configured by `offsets.retention.minutes`. Note that the optimization for early expiration of unsubscribed topics will be implemented in a separate patch.",2018-06-21 17:19:24,Vahid Hashemian,Mixed
624acc63dabd6f46974540ef27a5ca1caa891c1b,"MINOR: Cleanup threads in integration tests (#5269)

Leftover threads doing network I/O can interfere with subsequent tests. Add missing shutdown in tests and include admin client in the check for leftover threads.

Reviewers: Anna Povzner <anna@confluent.io>, Dhruvil Shah <dhruvil@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy O <manikumar.reddy@gmail.com>",2018-06-22 15:41:52,Rajini Sivaram,Not TDD
954be11bf2d3dc9fa11a69830d2ef5ff580ff533,"KAFKA-6978: make window retention time strict (#5218)

Enforce window retention times strictly:

* records for windows that are expired get dropped
* queries for timestamps old enough to be expired immediately answered with null

Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-06-22 17:08:00,John Roesler,Mixed
9ea81baf34113ccb05244ea9fb63199e7f071bb0,"KAFKA-6949; alterReplicaLogDirs() should grab partition lock when accessing log of the future replica

NoSuchElementException will be thrown if ReplicaAlterDirThread replaces the current replica with future replica right before the request handler thread executes `futureReplica.log.get.dir.getParent` in the ReplicaManager.alterReplicaLogDirs(). The solution is to grab the partition lock when request handler thread attempts to check the destination log directory of the future replica.

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #5081 from lindong28/KAFKA-6949",2018-06-25 23:39:02,Dong Lin,Mixed
7a74ec62d291bf344b308115bd115a6788074a93,"MINOR: Avoid FileInputStream/FileOutputStream (#5281)

They rely on finalizers (before Java 11), which create
unnecessary GC load. The alternatives are as easy to
use and don't have this issue.

Also use FileChannel directly instead of retrieving
it from RandomAccessFile whenever possible
since the indirection is unnecessary.

Finally, add a few try/finally blocks.

Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Rajini Sivaram <rajinisivaram@googlemail.com>",2018-06-27 01:00:05,Ismael Juma,Mixed
2db7eb7a8c28f4f5d2550b45a9215948652f82ca,"KAFKA-7076; Skip rebuilding producer state when using old message format (#5254)

This patch removes the need to build up producer state when the log is using V0 / V1 message format where we did not have idempotent and transactional producers yet.

Also fixes a small issue where we incorrectly reported the offset index corrupt if the last offset in the index is equal to the base offset of the segment.",2018-06-27 14:48:08,Dhruvil Shah,Mixed
51935ee2e6dc473415b6708b60c9d47410876997,"KAFKA-7091; AdminClient should handle FindCoordinatorResponse errors (#5278)

- Update KafkaAdminClient implementation to handle FindCoordinatorResponse errors
- Remove scala AdminClient usage from core and streams tests

Reviewers: Matthias J. Sax <matthias@confluent.io>, Jason Gustafson <jason@confluent.io>",2018-06-27 15:09:44,Manikumar Reddy O,Mixed
10b84a3661cde77b25f6408e6f360655ee618a18,"KAFKA-7104: More consistent leader's state in fetch response (#5305)

Do not update LogReadResult after it is initially populated when returning fetches immediately (i.e. without hitting the purgatory). This was done in #3954 as an optimization so that the followers get the potentially updated high watermark. However, since many things can happen (like deleting old segments and advancing log start offset) between initial creation of LogReadResult and the update, we can hit issues like log start offset in fetch response being higher than the last offset in fetched records.

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2018-06-27 21:15:20,Anna Povzner,Mixed
daa8082d6718d39584ed6d25863af48acec2cea6,"KAFKA-6809: Count inbound connections in the connection-creation metric (#5301)

Previously, the connection-creation metric only accounted for opened connections from the broker. This change extends it to account for received connections.",2018-06-28 14:15:15,Stanislav Kozlovski,Mixed
919409bb2331fbd60cd3d425fe7d9384d66967fa,"MINOR: Ensure heartbeat last poll time always updated (#5308)

We need to ensure that the last poll time is always updated when the user call poll(Duration). This patch fixes a bug in the new KIP-266 timeout behavior which would cause this to be skipped if the coordinator could not be found while the consumer was in an active group.

Note that I've also fixed some type inconsistencies for various timeouts.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2018-06-28 20:45:29,Jason Gustafson,Mixed
b0d2ddb330a24971c53ba96129a3c66312b30c5c,"KAFKA-7028: Properly authorize custom principal objects (#5311)

Use KafkaPrincipal objects for authorization in `SimpleAclAuthorizer` so that comparison with super.users and ACLs instantiated from Strings work. Previously, it would compare two different classes `KafkaPrincipal` and the custom class, which would always return false because of the implementation of `KafkaPrincipal#equals`.",2018-06-29 14:13:45,Stanislav Kozlovski,Mixed
d44d5d7520d31f33feb03b0679f8c552254dac4e,"KAFKA-6986: Export Admin Client metrics through Stream Threads (#5210)

KAFKA-6986:Export Admin Client metrics through Stream Threads

We already exported producer and consumer metrics through KafkaStreams class:

#4998

It makes sense to also export the Admin client metrics.

I didn't add a separate unittest case for this. Let me know if it's needed.

This is my first contribution, feel free to point out any mistakes that I did.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2018-06-29 13:27:26,Yishun Guan,Mixed
0db8074d492ec96f3e894b484e8f0bb9fdd45544,"MINOR: Close timing window in SimpleAclAuthorizer startup (#5318)

ZooKeeper listener for change notifications should be created before loading the ACL cache to avoid timing window if acls are modified when broker is starting up.

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@confluent.io>",2018-07-02 22:11:05,Rajini Sivaram,Mixed
64fff8bfcc9b92769640bfaa692e19d0db8861a6,"KAFKA-7080: replace numSegments with segmentInterval (#5257)

See also KIP-319.

Replace number-of-segments parameters with segment-interval-ms parameters in various places. The latter was always the parameter that several components needed, and we accidentally supplied the former because it was the one available.

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-07-02 16:07:38,John Roesler,Mixed
8250738ae41f6f0a87dc1e21e7623c5d69cae148,"KAFKA-7101: Consider session store for windowed store default configs (#5298)

1. extend isWindowStore to consider session store as well.
2. extend the existing unit test accordingly.

Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-07-02 22:00:23,Guozhang Wang,Mixed
e38e3a66ab099996ecb156ec9105869f3d9b9228,"MINOR: Fix standby streamTime (#5288)

#5253 broke standby restoration for windowed stores.

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-07-03 07:07:50,John Roesler,Mixed
1f8527b331f3d4c8e3ea16993d96caae2ea18fc5,"KAFKA-7136: Avoid deadlocks in synchronized metrics reporters (#5341)

We need to use the same lock for metric update and read to avoid NPE and concurrent modification exceptions. Sensor add/remove/update are synchronized on Sensor since they access lists and maps that are not thread-safe. Reporters are notified of metrics add/remove while holding (Sensor, Metrics) locks and reporters may synchronize on the reporter lock. Metric read may be invoked by metrics reporters while holding a reporter lock. So read/update cannot be synchronized using Sensor since that could lead to deadlock. This PR introduces a new lock in Sensor for update/read.
Locking order:

- Sensor#add: Sensor -> Metrics -> MetricsReporter
- Metrics#removeSensor: Sensor -> Metrics -> MetricsReporter
- KafkaMetric#metricValue: MetricsReporter -> Sensor#metricLock
- Sensor#record: Sensor -> Sensor#metricLock


Reviewers: Jun Rao <junrao@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2018-07-06 10:54:28,Rajini Sivaram,Not TDD
f54ba7cf8528b5082471a86850ba951244a990e1,"MINOR: Use FetchRequest v8 and ListOffsetRequest v3 in ReplicaFetcherThread (#5342)

If inter.broker.protocol.version is 2.0-IV1 or newer. Also fixed ListOffsetRequest
so that v2 is used, if applicable.

Added a unit test which verifies that we use the latest version of the various
requests by default. Included a few minor tweaks to make testing easier.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2018-07-06 14:35:25,Ismael Juma,Mixed
05c5854d1ff8510c867066b65e28ad9414d6c266,"MINOR: Add Scalafmt to Streams Scala API (#4965)

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2018-07-09 16:48:34,Joan Goyeau,Not TDD
8119683a234543aa7b523a571b8a68a5002c5b56,"MINOR: Tighten FileRecords size checks to prevent overflow (#5332)

Add some additional size validation to prevent overflows when using `FileRecords`. 

Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2018-07-11 11:44:54,Jason Gustafson,Mixed
8ec8ec542264604cc44ef5a17439573c0de0990a,"KAFKA-6884; Consumer group command should use new admin client (#5032)

Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Vahid Hashemian <vahidhashemian@us.ibm.com>, Jason Gustafson <jason@confluent.io>",2018-07-17 11:51:05,Attila Sasvari,Mixed
f6219c6ad1d338792413c562615bad22f6baca1c,"KAFKA-4041: Update ZooKeeper to 3.4.13 (#5376)

This includes a fix for ZOOKEEPER-2184 (Zookeeper Client
should re-resolve hosts when connection attempts fail), which
fixes KAFKA-4041.

Updated a couple of tests as unresolvable addresses are now
retried until the connection timeout. Cleaned up tests a little.

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2018-07-17 13:53:03,Ismael Juma,Not TDD
08fe24b46a327424e3249eeef1a32e05db717b18,"KAFKA-7103: Use bulkloading for RocksDBSegmentedBytesStore during init (#5276)

This PR uses bulk loading for recovering RocksDBWindowStore, same as RocksDBStore. 

Reviewers: Boyang Chen <bchen11@outlook.com>, Shawn Nguyen <shnguyen@pinterest.com>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-07-17 14:04:51,Liquan Pei,Mixed
8c47a3e52f3d6871a708b1d2c8b5a7e30a2a5b99,"KAFKA-5098; KafkaProducer should reject sends to invalid topics

…egal char and generates InvalidTopicException

If config parameter max.block.ms config parameter is set to a non-zero value,
KafkaProducer.send() blocks for the max.block.ms time if topic name has illegal
char or is invalid.

Wrote a unit test that verifies the appropriate exception is returned when
performing a get on the returned future by KafkaProducer.send().

Author: Ahmed Al Mehdi <aalmehdi@aalmehdi-ld1.linkedin.biz>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Joel Koshy <jjkoshy@gmail.com>, Manikumar Reddy O <manikumar.reddy@gmail.com>

Closes #5247 from ahmedha/KAFKA-5098",2018-07-17 15:45:29,Ahmed Al Mehdi,Mixed
0875ddeb2381c68afb0e4d5a15b25baf4cde29a2,"KAFKA-7168: Treat connection close during SSL handshake as retriable (#5371)

SSL `close_notify` from broker connection close was processed as a handshake failure in clients while unwrapping the message if a handshake is in progress. Updated to handle this as a retriable IOException rather than a non-retriable SslAuthenticationException to avoid authentication exceptions in clients during rolling restart of brokers.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-07-18 12:27:21,Rajini Sivaram,Mixed
06d96628f0e098d93aecc650534c9e9965127d92,"MINOR: remove unused MeteredKeyValueStore (#5380)

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-07-18 09:30:52,Matthias J. Sax,Mixed
2f6240ac944f2a55ece50a179b79f4e2ee63a621,"KAFKA-3514: Remove min timestamp tracker (#5382)

1. Remove MinTimestampTracker and its TimestampTracker interface.
2. In RecordQueue, keep track of the head record (deserialized) while put the rest raw bytes records in the fifo queue, the head record as well as the partition timestamp will be updated accordingly.

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-07-19 08:06:17,Guozhang Wang,Mixed
284b46b7ce8520792a337b721762721817628b3f,"KAFKA-7182: SASL/OAUTHBEARER client response missing %x01 seps (#5391)

The SASL/OAUTHBEARER client response as currently implemented in OAuthBearerSaslClient sends the valid gs2-header ""n,,"" but then sends the ""auth"" key and value immediately after it.
This does not conform to the specification because there is no %x01 after the gs2-header, no %x01 after the auth value, and no terminating %x01. Fixed this and the parsing of the client response in
OAuthBearerSaslServer, which currently allows the malformed text. Also updated to accept and ignore unknown properties as required by the spec.

Reviewers: Stanislav Kozlovski <familyguyuser192@windowslive.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2018-07-19 17:55:29,Ron Dagostino,Mixed
96c53e96b8834c550e6db54b2748c08e545f9150,"MINOR: Remove deprecated ZkUtils usage from EmbeddedKafkaCluster (#5324)

Reviewers: Matthias J. Sax <mjsax@apache.org>, Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>",2018-07-19 14:28:12,Manikumar Reddy O,Not TDD
82f124ae30116b2b7d45878aaeb9699b6bdf1c30,"KAFKA-5037: Fix infinite loop if all input topics are unknown at startup

1. At the beginning of assign, we first check that all the non-repartition source topics are included in the metadata. If not, we log an error at the leader and set an error in the Assignment userData bytes, indicating that leader cannot complete assignment and the error code would indicate the root cause of it.

2. Upon receiving the assignment, if the error is not NONE the streams will shutdown itself with a log entry re-stating the root cause interpreted from the error code.

Author: tedyu <yuzhihong@gmail.com>

Reviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>

Closes #5322 from tedyu/trunk",2018-07-19 15:22:53,Ted Yu,Mixed
80b55309d1090b0bb45d571c5f6114461f6cb041,"KAFKA-7098; Improve accuracy of throttling by avoiding under-estimating actual rate in Throttler

Author: Zhanxiang (Patrick) Huang <hzxa21@hotmail.com>

Reviewers: Dong Lin <lindong28@gmail.com>

Closes #5350 from hzxa21/KAFKA-7098",2018-07-19 23:48:41,Zhanxiang (Patrick) Huang,Mixed
bf237fa7c576bd141d78fdea9f17f65ea269c290,"KAFKA-7141; Consumer group describe should include groups with no committed offsets (#5356)

Currently, if a consumer group never commits offsets, ConsumerGroupCommand will not include it in the describe output even if the member assignment is valid. Instead, the tool should be able to describe the group information showing empty current_offset and LAG.

Reviewers: Sriharsha Chintalapani <sriharsha@apache.org>, Vahid Hashemian <vahidhashemian@us.ibm.com>, Jason Gustafson <jason@confluent.io>",2018-07-20 08:52:04,huxi,Mixed
9449f055c7a0b340a8d69d7365c5817464b2f6ed,"KAFKA-7185: Allow empty resource name when matching ACLs (#5400)

Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>",2018-07-20 20:35:12,Dhruvil Shah,Mixed
5d2bf6328e1c5b054017419cf4de562dc8a3ec7a,"MINOR: FileStreamSinkTask should create file if it doesn't exist (#5406)

A recent change from `new FileOutputStream` to `Files.newOutputStream` missed the `CREATE` flag (which is necessary in addition to `APPEND`).

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-07-20 21:01:10,Konstantine Karantasis,Mixed
b9b70c95a2cfdf01379f053c65e393bfc4ed7f37,"MINOR: Change ""no such session ID"" log to debug (#5316)

Improve the log messages while at it and fix some code style issues.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-07-21 03:32:56,Colin Patrick McCabe,Mixed
591954e2e55e0c262bf029f4b8f17566dcae6818,"MINOR: Add registerController method to KafkaZkClient (#4598)

And change KafkaController to use the newly introduced method.
Also remove redundant `InZk` postfixes from `registerBrokerInZk` and
`updateBrokerInfoInZk`.

As `checkedEphemeralCreate` is not used outside of `KafkaZkClient`
any longer, reduce its visibility.

ControllerIntegrationTest already covers this functionality well, it validates the
refactor.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-07-21 11:40:00,Sandor Murakozi,Mixed
d11f6f26b773343246c217f498de3c02916bec6c,"KAFKA-6897; Prevent KafkaProducer.send from blocking when producer is closed (#5027)

After successful completion of KafkaProducer#close, it is possible that an application calls KafkaProducer#send. If the send is invoked for a topic for which we do not have any metadata, the producer will block until `max.block.ms` elapses - we do not expect to receive any metadata update in this case because Sender (and NetworkClient) has already exited. It is only when RecordAccumulator#append is invoked that we notice that the producer has already been closed and throw an exception. If `max.block.ms` is set to Long.MaxValue (or a sufficiently high value in general), the producer could block awaiting metadata indefinitely.

This patch makes sure `Metadata#awaitUpdate` periodically checks if the network client has been closed, and if so bails out as soon as possible.",2018-07-21 14:03:14,Dhruvil Shah,Mixed
9a7f29c1ede9f1ece67b73d2d6497d60f38fb62a,"KAFKA-7152; Avoid moving a replica out of isr if its LEO equals leader's LEO

When there are many inactive partitions in the cluster, we observed constant churn of URP in the cluster even if follower can catch up with leader's byte-in-rate because leader broker frequently moves replicas of inactive partitions out of ISR. This PR mitigates this issue by not moving replica out of ISR if follower's LEO == leader's LEO.

Author: Zhanxiang (Patrick) Huang <hzxa21@hotmail.com>

Reviewers: Dong Lin <lindong28@gmail.com>

Closes #5412 from hzxa21/KAFKA-7152",2018-07-21 16:52:54,Zhanxiang (Patrick) Huang,Not TDD
5db2f9903a1e1d9fe574730e89aec0022333db71,"MINOR: Close ZooKeeperClient if waitUntilConnected fails during construction (#5411)

This has always been an issue, but the recent upgrade to ZooKeeper
3.4.13 means it is also an issue when an unresolvable ZK
address is used, causing some tests to leak threads.

The change in behaviour in ZK 3.4.13 is that no exception is thrown
from the ZooKeeper constructor in case of an unresolvable address.
Instead, ZooKeeper tries to re-resolve the address hoping it becomes
resolvable again. We eventually throw a
`ZooKeeperClientTimeoutException`, which is similar to the case
where the the address is resolvable but ZooKeeper is not
reachable.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-07-22 09:49:32,Manikumar Reddy O,Mixed
52c5b5f1118f3571c6c981c16c02484ada0b28c4,"MINOR: Remove unused TopicAndPartition usage in tests (#5419)

Also replace `TopicAndPartition` with `TopicPartition` in `MetadataCache`.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-07-24 00:39:33,Manikumar Reddy O,Not TDD
c83ecf4c55a2dbbb89c71080c601417adb8b699c,"KAFKA-7194; Fix buffer underflow if onJoinComplete is retried after failure (#5417)

An untimely wakeup can cause ConsumerCoordinator.onJoinComplete to throw a WakeupException before completion. On the next poll(), it will be retried, but this leads to an underflow error because the buffer containing the assignment data will already have been advanced. The solution is to duplicate the buffer passed to onJoinComplete.

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2018-07-24 09:25:18,Jason Gustafson,Mixed
1d9a427225c64e7629a4eb2e2d129d5551185049,"KAFKA-7144: Fix task assignment to be even (#5390)

This PR now justs removes the check in TaskPairs.hasNewPair that was causing the task assignment issue.

This was done as we need to further refine task assignment strategy and this approach needs to include the statefulness of tasks and is best done in one pass vs taking a ""patchy"" approach.

Updated current tests and ran locally

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-07-24 22:00:18,Bill Bejeck,Mixed
7fc7136ffd28245629f00870fc7f7cbe1fe1c6ce,"KAFKA-5886; Introduce delivery.timeout.ms producer config (KIP-91) (#5270)

Co-authored-by: Sumant Tambe <sutambe@yahoo.com>
Co-authored-by: Yu Yang <yuyang@pinterest.com>

Reviewers: Ted Yu <yuzhihong@gmail.com>, Apurva Mehta <apurva@confluent.io>, Jason Gustafson <jason@confluent.io>",2018-07-26 09:13:50,Yu Yang,Mixed
42af41d5fc991c392b75396352903b4d919da5d3,"MINOR: Caching layer should forward record timestamp (#5423)

Reviewer: Guozhang Wang <guozhang@confluent.io>",2018-07-26 09:31:02,Matthias J. Sax,Not TDD
a932520135d42c7d9731064d96c21ab2fc5de696,"KAFKA-7126; Reduce number of rebalance for large consumer group after a topic is created

This patch forces metadata update for consumers with pattern subscription at the beginning of rebalance (retry.backoff.ms is respected). This is to prevent such consumers from detecting subscription changes (e.g., new topic creation) independently and triggering multiple unnecessary rebalances. KAFKA-7126 contains detailed scenarios and rationale.

Author: Jon Lee <jonlee@linkedin.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Ted Yu <yuzhihong@gmail.com>, Dong Lin <lindong28@gmail.com>

Closes #5408 from jonlee2/KAFKA-7126",2018-07-26 10:29:09,Jon Lee,Mixed
061885e9f1675221f31ce47cfb0e59eb5748b9c7,"KAFKA-7192: Wipe out if EOS is turned on and checkpoint file does not exist (#5421)

1. As titled and as described in comments.
2. Modified unit test slightly to insert for new keys in committed data to expose this issue.

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-07-26 17:58:29,Guozhang Wang,Mixed
c8c3a7dc48dc1ec6220798294da123bb617a6cd7,"KAFKA-7192 Follow-up: update checkpoint to the reset beginning offset (#5430)

1. When we reinitialize the state store due to no CHECKPOINT with EOS turned on, we should update the checkpoint to consumer.seekToBeginnning() / consumer.position() to avoid falling into endless iterations.

2. Fixed a few other logic bugs around needsInitializing and needsRestoring.

Reviewers: Jason Gustafson <jason@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",2018-07-27 22:11:55,Guozhang Wang,Mixed
814fbe0feabea0f78b690f44ee99b61b07ea7dd2,"MINOR: Remove 1 minute minimum segment interval (#5323)

* new minimum is 0, just like window size
* refactor tests to use smaller segment sizes as well

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-08-01 11:01:12,John Roesler,Mixed
c3e7c0bcb258061568294c0d96b62fea94ef8ee7,"MINOR: Producers should set delivery timeout instead of retries  (#5425)

Use delivery timeout instead of retries when possible and remove various TODOs associated with completion of KIP-91.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>",2018-08-01 11:04:17,Jason Gustafson,Mixed
c19213ab4139aa1f56f89982448184a5c82f98a4,"KAFKA-6761: Construct Physical Plan using Graph, Reduce streams footprint part III (#5201)

The specific changes in this PR from the second PR include:

1. Changed the types of graph nodes to names conveying more context
2. Build the entire physical plan from the graph, after StreamsBuilder.build() is called.

Other changes are addressed directly as review comments on the PR.

Testing consists of using all existing streams tests to validate building the physical plan with graph

Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <vvcephei@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",2018-08-01 15:01:18,Bill Bejeck,Mixed
596c6c0c0b27c13f2017c770ea37cd39e27e5dcf,"KAFKA-7231; Ensure NetworkClient uses overridden request timeout (#5444)

Fixed incorrect use of default timeout instead of the argument explicitly passed to `newClientRequest`.

Reviewers: Ron Dagostino <rndgstn@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2018-08-02 11:02:38,Jason Gustafson,Mixed
70d882861e1bf3eb503c84a31834e8b628de2df9,"KAFKA-7228: Set errorHandlingMetrics for dead letter queue

DLQ reporter does not get a `errorHandlingMetrics` object when created by the worker. This results in an NPE.

Signed-off-by: Arjun Satish <arjunconfluent.io>

*More detailed description of your change,
if necessary. The PR title and PR message become
the squashed commit message, so use a separate
comment to ping reviewers.*

*Summary of testing strategy (including rationale)
for the feature or bug fix. Unit and/or integration
tests are expected for any behaviour change and
system tests should be considered for larger changes.*

Author: Arjun Satish <arjun@confluent.io>

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5440 from wicknicks/KAFKA-7228",2018-08-02 14:36:02,Arjun Satish,Mixed
afe00effe2d79e89e159972cf1f5f7ffeb0c6e97,"KAFKA-3514: Part II, Choose tasks with data on all partitions to process (#5398)

1. In each iteration, decide if a task is processable if all of its partitions contains data, so it can decide which record to process next.

1.a Add one exception that, if the task indeed have data on some but not all of its partitions, we only consider as not processable for some finite round of iterations.
1.b Add a task-level metric to record whenever we are forced to process a task that is only ""partially data available"", since it may leads to non-determinism.

2. Break the main loop on put-raw-data and process-them. Since now not all data put into the queue would be processed completely within a single iteration.

3. NOTE that within an iteration, if a task has exhausted one of its queue it will still be processed, since we only update processable list once in each iteration, I'm improving on this on the follow-up part III PR.

4. Found and fixed a bug in metrics recording: the taskName and sensorName parameters were exchanged.

5. Optimized task stream time computation again since our current partition stream time reasoning has been simplified.

6. Added unit tests.

Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <vvcephei@users.noreply.github.com>, Bill Bejeck <bbejeck@gmail.com>",2018-08-02 18:34:53,Guozhang Wang,Mixed
09fe51f3eb7e3ddee54cfb210d8a22327d1b0773,"KAFKA-6648; Fetcher.getTopicMetadata() should return all partitions for each requested topic

Currently Fetcher.getTopicMetadata() will not include offline partitions. Thus
KafkaConsumer.partitionsFor(topic) will not return all partitions of a topic if
there if any partition of the topic is offline. This causes problem if user
tries to query the total number of partitions of the given topic.

Author: radai-rosenblatt <radai.rosenblatt@gmail.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #4679 from radai-rosenblatt/partition_shenanigans",2018-08-03 10:38:50,radai-rosenblatt,Mixed
3637b2c374d48e99e0a7be37605d3c79f2661007,"MINOR: Require final variables in Streams (#5452)

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-08-03 13:19:46,John Roesler,Mixed
fc5f6b0e46ff81302b3e445fed0cdf454c942792,"MINOR: Add Timer to simplify timeout bookkeeping and use it in the consumer (#5087)

We currently do a lot of bookkeeping for timeouts which is both error-prone and distracting. This patch adds a new `Timer` class to simplify this logic and control unnecessary calls to system time. In particular, this helps with nested timeout operations. The consumer has been updated to use the new class.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>",2018-08-03 17:25:07,Jason Gustafson,Mixed
cf2c5e9ffc066aad37090fb6f2953a602cd8621b,"MINOR: clean up node and store sensors (#5450)

Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-08-03 22:43:18,John Roesler,Mixed
518e9d3eee1b1d2c8c76d68e043edd3cf49139fa,"KAFKA-7169: Custom SASL extensions for OAuthBearer authentication mechanism (KIP-342) (#5379)

Reviewers: Ron Dagostino <rndgstn@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2018-08-06 17:22:04,Stanislav Kozlovski,Mixed
b01f8fb668988caa19feb63e878fe1901a9d0c89,"KAFKA-7142: fix joinGroup performance issues (#5354)

Summary:
1. Revert GroupMetadata.members to private
2. Add back a wrongly removed comment
3. In GroupMetadata.remove(), update supportedProtocols and awaitingJoinCallbackMembers, only when the remove succeeded

Reviewers: Jason Gustafson <jason@confluent.io>,  Ismael Juma <ismael@juma.me.uk>, Sriharsha Chintalapani <sriharsha@apache.org>",2018-08-06 13:20:40,ying-zheng,Mixed
b0d840d34b4172add831367e8fc2c51e75efb549,"KAFKA-5928; Avoid redundant requests to zookeeper when reassign topic partition

Author: uncleGen <hustyugm@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Dong Lin <lindong28@gmail.com>

Closes #3894 from uncleGen/KAFKA-5928",2018-08-06 20:04:59,uncleGen,Mixed
ed13d7eebb0a8c2155ac50fce16c12ec502c1f0d,"KAFKA-7250: fix transform function in scala DSL to accept TranformerSupplier (#5468)

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2018-08-07 08:00:22,Michal Dziemianko,Not TDD
a9d7f8a1fdfa129105c6b3a128a91524874071ef,"MINOR: Fix Streams scala format violations (#5472)

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2018-08-07 12:50:42,Manikumar Reddy O,Not TDD
36a8fec0ab2d05a8386ecd386bbbd294c3dc9126,"KAFKA-7225: Pretransform validated props

If a property requires validation, it should be pretransformed if it is a variable reference, in order to have a value that will properly pass the validation.

Author: Robert Yokota <rayokota@gmail.com>

Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5445 from rayokota/KAFKA-7225-pretransform-validated-props",2018-08-07 13:18:16,Robert Yokota,Mixed
28a1ae4183c707af363b69e2ec2b743bdf4f236c,"MINOR: System test for error handling and writes to DeadLetterQueue

Added a system test which creates a file sink with json converter and attempts to feed it bad records. The bad records should land in the DLQ if it is enabled, and the task should be killed or bad records skipped based on test parameters.

Signed-off-by: Arjun Satish <arjunconfluent.io>

*More detailed description of your change,
if necessary. The PR title and PR message become
the squashed commit message, so use a separate
comment to ping reviewers.*

*Summary of testing strategy (including rationale)
for the feature or bug fix. Unit and/or integration
tests are expected for any behaviour change and
system tests should be considered for larger changes.*

Author: Arjun Satish <arjun@confluent.io>

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5456 from wicknicks/error-handling-sys-test",2018-08-07 14:44:01,Arjun Satish,Mixed
ce19f34f1e3e6e697cce2e01721bedc850fca698,"KAFKA-7255: Fix timing issue with create/update in SimpleAclAuthorizer (#5478)

ACL updates currently get `(currentAcls, currentVersion)` for the resource from ZK and do a conditional update using `(currentAcls+newAcl, currentVersion)`. This supports concurrent atomic updates if the resource path already exists in ZK. If the path doesn't exist, we currently do a conditional createOrUpdate using `(newAcl, -1)`. But `-1` has a special meaning in ZooKeeper for update operations - it means match any version. So two brokers adding acls using `(newAcl1, -1)` and `(newAcl2, -1)` will result in one broker creating the path and setting newAcl1, while the other broker can potentially update the path with `(newAcl2, -1)`, losing newAcl1. The timing window is very small, but we have seen intermittent failures in `SimpleAclAuthorizerTest.testHighConcurrencyModificationOfResourceAcls` as a result of this window.

This commit fixes the version used for conditional updates in ZooKeeper. It also replaces the confusing `ZkVersion.NoVersion=-1` used for `set(any-version)` and `get(return not-found)` with `ZkVersion.MatchAnyVersion` for `set(any-version)` and `ZkVersion.UnknownVersion` for `get(return not-found)` to avoid the return value from `get` matching arbitrary values in `set`.",2018-08-08 17:44:57,Rajini Sivaram,Mixed
59ae73482d17f1bd19a27afd4c8624747b10274e,"MINOR: Follow up for KAFKA-6761 graph should add stores for consistency (#5453)

While working on 4th PR, I noticed that I had missed adding stores via the graph vs. directly via the InternalStreamsBuilder. Probably ok to do so, but we should be consistent.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-08-08 15:41:02,Bill Bejeck,Not TDD
811c6433bdd6c888860d18e28bd9751d57ee8e0d,"KAFKA-4950; Fix ConcurrentModificationException on assigned-partitions metric update (#3907)

Use a volatile field to track the size of the set of assigned partitions to avoid the concurrent access to the underlying linked hash map.

Reviewers: Vahid Hashemian <vahidhashemian@us.ibm.com>, Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2018-08-08 15:43:43,Sébastien Launay,Mixed
b1539ff62dd3e8eeffeae526a2cbd7e4cb63ecda,"KAFKA-7250: switch scala transform to TransformSupplier (#5481)

#5468 introduced a breaking API change that was actually avoidable. This PR re-introduces the old API as deprecated and alters the API introduced by #5468 to be consistent with the other methods

also, fixed misc syntax problems",2018-08-09 10:11:48,John Roesler,Not TDD
92004fa21a9cc75e3790ab39e44d4d3b754d95d9,"KAFKA-6751; Support dynamic configuration of max.connections.per.ip/max.connections.per.ip.overrides configs (KIP-308) (#5334)

KIP-308 implementation. See https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=85474993.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>",2018-08-09 14:40:24,Manikumar Reddy O,Mixed
79a2f892caef38f28c3ad837ad28b63dcbb58b87,"KAFKA-6966: Extend TopologyDescription to better represent Source and (#5284)

Implements KIP-321

Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>",2018-08-10 16:12:03,nprad,Mixed
8a78d76466bacd8a2a3487cc84890d29c9bc4a3d,"KAFKA-7140; Remove deprecated poll usages (#5319)

Reviewers: Matthias J. Sax <mjsax@apache.org>, Jason Gustafson <jason@confluent.io>",2018-08-10 22:51:17,Viktor Somogyi,Mixed
a3dc10f1d9bc90b13f7449902bf5af43de166de0,"KAFKA-7261: Record 1.0 for total metric when Count stat is used for rate (#5484)

Reviewers: Jun Rao <junrao@gmail.com>, John Roesler <john@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2018-08-12 18:38:22,Rajini Sivaram,Not TDD
69283b4038aec24b240e5825766e8d5629e0ba9e,"KAFKA-7164; Follower should truncate after every missed leader epoch change (#5436)

Currently, we skip the steps to make a replica a follower if the leader does not change, including truncating the follower log if necessary. This can cause problems if the follower has missed one or more leader updates. Change the logic to only skip the steps if the new epoch is the same or one greater than the old epoch. Tested with unit tests that verify the behavior of `Partition` and that show log truncation when the follower's log is ahead of the leader's, the follower has missed an epoch update, and the follower receives a `LeaderAndIsrRequest` making it a follower.

Reviewers: Stanislav Kozlovski <familyguyuser192@windowslive.com>, Jason Gustafson <jason@confluent.io>",2018-08-12 23:30:09,Bob Barrett,Mixed
e6fd99dc6253333c5aaa9931d8ae319e637e9a11,"KAFKA-5638; Improve the Required ACL of ListGroups API (KIP-231) (#5352)

Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-08-12 23:59:31,Vahid Hashemian,Not TDD
a2bc237cef86ca701e371196883429efb7f4074a,"MINOR: Remove AbstractFetcherThread.PartitionData (#5233)

Since ConsumerFetcherThread has been removed, we have
an opportunity to simplify the *FetcherThread classes. This
is an unambitious first step which removes the now unneeded
`PartitionData` indirection.",2018-08-13 10:41:33,Ismael Juma,Mixed
6d1685fa45da775f9f971121ec53d6135a4561b2,"KAFKA-7284: streams should unwrap fenced exception (#5499)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-08-13 17:13:13,John Roesler,Mixed
cc8fc7c449b97807fecaa179f5831f9bd31ce950,"MINOR: Clean up to avoid errors in dynamic broker config tests (#5486)

Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Viktor Somogyi <viktorsomogyi@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-08-14 09:14:48,Rajini Sivaram,Not TDD
b3771ba22acad7870e38ff7f58820c5b50946787,"KAFKA-7222: Add Windows grace period (#5369)

Part I of KIP-238:

* add grace period to Windows
* deprecate retention/maintainMs and segmentInterval from Windows
* record expired records in the store with a new metric
* record late record drops as a new metric instead of as a ""skipped record""

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-08-14 09:53:25,John Roesler,Mixed
0d73351852369b0f969e11236332c03e2d955ae7,"KAFKA-7119: Handle transient Kerberos errors as non-fatal exceptions (#5487)

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2018-08-14 18:00:54,Rajini Sivaram,Not TDD
ad84eb5e76cb8db7c27355a2f121c0642a692980,"KAFKA-7169: Validate SASL extensions through callback on server side (#5497)

Reviewers: Ron Dagostino <rndgstn@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2018-08-14 19:44:58,Stanislav Kozlovski,Mixed
bb4cc4962894cf930c6b1cc01b121444f4ebb106,"KAFKA-7019; Make reading metadata lock-free by maintaining an atomically-updated read snapshot

Author: radai-rosenblatt <radai.rosenblatt@gmail.com>

Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Ismael Juma <github@juma.me.uk>, Dong Lin <lindong28@gmail.com>

Closes #5221 from radai-rosenblatt/metadata-adventures",2018-08-14 15:30:47,radai-rosenblatt,Mixed
3e64e5b9c03f13f58e6a049ff1fed039c6a15d69,"KAFKA-6761: Reduce streams footprint part IV add optimization (#5451)

This PR adds the optimization of eliminating multiple repartition topics when the KStream resulting from a key-changing operation executes other methods using the new key and reduces the repartition topics to one.

Note that this PR leaves in place the optimization for re-using a source topic as a changelog topic for source KTable instances. I'll have another follow-up PR to move the source topic optimization to a method within InternalStreamsBuilder so it can be performed in the same area of the code.

Additionally, the current value of StreamsConfig.OPTIMIZE is all and we'll need to have another KIP to change the value to 2.1.

An integration test RepartitionOptimizingIntegrationTest which asserts the same results for an optimized topology with one repartition topic as the un-optimized version with four repartition topics.

Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-08-14 17:46:40,Bill Bejeck,Mixed
a4a65abcd3e5a01e0910afb10a214f4bb47577a3,"MINOR: (re)add equals/hashCode to *Windows (#5510)

Andy Coates <big-andy-coates@users.noreply.github.com>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-08-15 14:30:24,John Roesler,Mixed
3c14feb442219f58e0008a6242a24f1a492ca337,"KAFKA-7285: Create new producer on each rebalance if EOS enabled (#5501)

Reviewers: Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>",2018-08-15 17:12:55,Matthias J. Sax,Mixed
634f9af8c0454f46a2510c12c3a155c6fca876e9,"KAFKA-7119: Handle transient Kerberos errors on server side (#5509)

Don't report retriable Kerberos errors on the server-side as authentication failures to clients.

Reviewers: Jun Rao <junrao@gmail.com>",2018-08-16 09:02:24,Rajini Sivaram,Not TDD
4f25f1fb7118825384f89ed9d00c08a54870e3aa,"KAFKA-7296; Handle coordinator loading error in TxnOffsetCommit (#5514)

We should check TxnOffsetCommit responses for the COORDINATOR_LOADING_IN_PROGRESS error code and retry if we see it. Additionally, if we encounter an abortable error, we need to ensure that pending transaction offset commits are cleared.

Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2018-08-16 09:37:32,Jason Gustafson,Mixed
0d778987ee3b920b5c876696385c0792671adef8,"KAFKA-6998: Disable Caching when max.cache.bytes are zero. (#5488)

1) As titled, add a rewriteTopology that 1) sets application id, 2) maybe disable caching, 3) adjust for source KTable. This optimization can hence be applied for both DSL or PAPI generated Topology.

2) Defer the building of globalStateStores in rewriteTopology so that we can also disable caching. But we still need to build the state stores before InternalTopologyBuilder.build() since we should only build global stores once for all threads.

3) Added withCachingDisabled to StoreBuilder, it is a public API change.

4) [Optional] Fixed unit test config setting functionalities, and set the necessary config to shorten the unit test latency (now it reduces from 5min to 3.5min on my laptop).

Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Ted Yu <yuzhihong@gmail.com>",2018-08-17 09:35:38,Guozhang Wang,Mixed
bf2c46a0b8266562bf4697dc8e3e9443059f9abb,"MINOR: Change order of Property Check To Avoid NPE (#5528)

Reviewer: Matthias J. Sax <matthias@confluent.io>",2018-08-17 15:44:08,Bill Bejeck,Mixed
914ffa9dbef3c8ad6851b380276a1cb7c5aa4a0d,"KAFKA-7210: Add system test to verify log compaction (#5226)

* Updated TestLogCleaning tool to use Java consumer and rename as LogCompactionTester.
* Enabled the log cleaner in every system test.
* Removed configs from ""kafka.properties"" with default values and `socket.receive.buffer.bytes`
as the override did not seem necessary.
* Updated `kafka.py` logic to handle duplicates between `kafka.properties` and `server_prop_overrides`.
* Updated Gradle build so that classes from `kafka-clients` test jar can be used in
system tests.

Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Ismael Juma <ismael@juma.me.uk>",2018-08-20 03:46:57,Manikumar Reddy O,Not TDD
8325046be2f6577c58fdff7366835308a81718f4,"KAFKA-7298; Raise UnknownProducerIdException if next sequence number is unknown (#5518)

If the only producer state left in the log is a transaction marker, then we do not know the next expected sequence number. This can happen if there is a call to DeleteRecords which arrives prior to the writing of the marker. Currently we raise an OutOfOrderSequence error when this happens, but this is treated as a fatal error by the producer. Raising UnknownProducerId instead allows the producer to check for truncation using the last acknowledged sequence number and reset if possible.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2018-08-20 09:00:21,Jason Gustafson,Mixed
028e80204dd9bfd9d6258f1eb5b0e4132bd3795d,"KAFKA-6835: Enable topic unclean leader election to be enabled without controller change (#4957)

Reviewers: Jun Rao <junrao@gmail.com>",2018-08-20 09:48:13,Manikumar Reddy O,Not TDD
e46827c4eab21f89a8a4bad10c4e009b5366f2d1,"KAFKA-7278; replaceSegments() should not call asyncDeleteSegment() for segments which have been removed from segments list (#5491)

Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Jason Gustafson <jason@confluent.io>",2018-08-20 11:00:57,Dong Lin,Not TDD
ea4078e72a737268cc45776a10d8c3a566be9b4a,"KAFKA-7311: Reset next batch expiry time on each poll loop

Sender/RecordAccumulator never resets the next batch expiry time. Its always computed as the min of the current value and the expiry time for all batches being processed. This means that its always set to the expiry time of the first batch, and once that time has passed Sender starts spinning on epoll with a timeout of 0, which consumes a lot of CPU. This patch updates Sender to reset the next batch expiry time on each poll loop so that a new value reflecting the expiry time for the current set of batches is computed.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2018-08-20 12:41:20,Rohan,Mixed
504824b7b3b62fa1774584c74815c47fa07edd4f,"KAFKA-5891; Proper handling of LogicalTypes in Cast (#4633)

Currently logical types are dropped during Cast Transformation.
This patch fixes this behaviour.

Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-08-20 16:43:11,Maciej Bryński,Mixed
d31762a0c2ec1fc8e2a0fce4b38d9e5be0fd9dae,"MINOR: Additional testing of logical type handling in Cast transform

Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-08-21 08:21:46,Robert Yokota,Mixed
5b25d823aff47f1a50848f5d2b3d329441aac8e9,"KAFKA-6753: Updating the OfflinePartitions count only when necessary (#5388)

Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Jun Rao <junrao@gmail.com>",2018-08-21 11:37:35,Lucas Wang,Mixed
dae9c41838e745d51dba4e6be18359d42d5ff8a3,"KAFKA-7301: Fix streams Scala join ambiguous overload (#5502)

Join in the Scala streams API is currently unusable in 2.0.0 as reported by @mowczare:
#5019 (comment)

This due to an overload of it with the same signature in the first curried parameter.
See compiler issue that didn't catch it: https://issues.scala-lang.org/browse/SI-2628

Reviewers: Debasish Ghosh <dghosh@acm.org>, Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",2018-08-21 15:41:36,Joan Goyeau,Mixed
d8f9f278a2326f3d1ef872a21ef1b43593df571f,"KAFKA-7316: Fix Streams Scala filter recursive call #5538

Due to lack of conversion to kstream Predicate, existing filter method in KTable.scala would result in StackOverflowError.

This PR fixes the bug and adds testing for it.

Reviewers: Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",2018-08-23 09:15:27,Joan Goyeau,Mixed
c968267bf1362a91eca8bb22566da76d6c9aeb26,"MINOR: Return correct instance of SessionWindowSerde (#5546)

Plus minor javadoc cleanups.

Reviewers: Matthias J. Sax <matthias@confluent.io>,Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",2018-08-23 13:39:35,Kamal Chandraprakash,Mixed
e577f6d36665012c65fc651ad392dc49e87618e6,"KAFKA-7225; Corrected system tests by generating external properties file (#5489)

Fix system tests from earlier #5445 by moving to the `ConnectSystemBase` class the creation & cleanup of a file that can be used as externalized secrets in connector configs. 

Reviewers: Arjun Satish <arjun@confluent.io>, Robert Yokota <rayokota@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Jason Gustafson <jason@confluent.io>",2018-08-23 14:22:09,Randall Hauch,Mixed
b8559de23d120ca07daa6f66de6bba253d16a74a,"MINOR: Fix streams Scala foreach recursive call (#5539)

Reviewers: Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",2018-08-23 17:07:39,Joan Goyeau,Mixed
1dd85a328f437643a5c135f242c644f47c3767e4,"MINOR: restructure Windows to favor immutable implementation (#5536)

Update to KIP-328.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Ted Yu <yuzhihong@gmail.com>, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>",2018-08-23 17:53:10,John Roesler,Mixed
04770916a743ca9526cfa2fdecaef419d429a443,"KAFKA-5975; No response when deleting topics and delete.topic.enable=false (#3960)

This PR implements [KIP-322](https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=87295558).

Reviewers: Tom Bentley <tbentley@redhat.com>, Manikumar Reddy O <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-08-24 08:32:06,Mario Molina,Not TDD
6f48978b629d7f6eaf3f82783789cf46c3566d9b,"KAFKA-7240: -total metrics in Streams are incorrect (#5467)

Changes:

1. Add org.apache.kafka.streams.processor.internals.metrics.CumulativeCount analogous to Count, but not a SampledStat
2. Use CumulativeCount for -total metrics in streams instead of Count

Testing strategy:

Add a test in StreamsMetricsImplTest which fails on old, incorrect behavior

The contribution is my original work and I license the work to the project under the project's open source license.

Reviewers: Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",2018-08-24 11:20:57,Sam Lendle,Mixed
93a60ee266a202c0b1e94010ce72ba7eb8d068a5,"KAFKA-7139; Support option to exclude the internal topics in kafka-topics.sh (#5349)

This patch implements KIP-338: https://cwiki.apache.org/confluence/display/KAFKA/KIP-338+Support+to+exclude+the+internal+topics+in+kafka-topics.sh+command.

Reviewers: Andras Beni <andrasbeni@cloudera.com>, Jason Gustafson <jason@confluent.io>",2018-08-25 12:08:25,Chia-Ping Tsai,Mixed
ebd1354fd7578deb1cfb15846d7dbf8c9cf26074,"KAFKA-7347; Return not leader error for OffsetsForLeaderEpoch requests to non-replicas (#5576)

The broker should return NOT_LEADER_FOR_PARTITION for OffsetsForLeaderEpoch requests against non-replicas instead of UNKNOWN_TOPIC_OR_PARTITION. This patch also fixes a minor bug in the handling of ListOffsets request using the DEBUG replica id. We should return UNKNOWN_TOPIC_OR_PARTITION if the topic doesn't exist.

Reviewers: Jun Rao <junrao@gmail.com>",2018-08-27 17:39:44,Jason Gustafson,Not TDD
70c51633f2f4bdcdc045697c17cbb47c78ed14ad,"KAFKA-7128; Follower has to catch up to offset within current leader epoch to join ISR (#5557)

If follower is not in ISR, it has to fetch up to start offset of the current leader epoch. Otherwise we risk losing committed data. Added unit test to verify this behavior.

Reviewers: Jason Gustafson <jason@confluent.io>",2018-08-28 10:45:00,Anna Povzner,Mixed
fd5acd73e648a2aab4b970ddf04ad4cace6bad9a,"KAFKA-7242: Reverse xform configs before saving (KIP-297)

During actions such as a reconfiguration, the task configs are obtained
via `Worker.connectorTaskConfigs` and then subsequently saved into an
instance of `ClusterConfigState`.  The values of the properties that are saved
are post-transformation (of variable references) when they should be
pre-transformation.  This is to avoid secrets appearing in plaintext in
the `connect-configs` topic, for example.

The fix is to change the 2 clients of `Worker.connectorTaskConfigs` to
perform a reverse transformation (values converted back into variable
references) before saving them into an instance of `ClusterConfigState`.
The 2 places where the save is performed are
`DistributedHerder.reconfigureConnector` and
`StandaloneHerder.updateConnectorTasks`.

The way that the reverse transformation works is by using the
""raw"" connector config (with variable references still intact) from
`ClusterConfigState` to convert config values back into variable
references for those keys that are common between the task config
and the connector config.

There are 2 additional small changes that only affect `StandaloneHerder`:

1) `ClusterConfigState.allTasksConfigs` has been changed to perform a
transformation (resolution) on all variable references.  This is
necessary because the result of this method is compared directly to
`Worker.connectorTaskConfigs`, which also has variable references
resolved.

2) `StandaloneHerder.startConnector` has been changed to match
`DistributedHerder.startConnector`.  This is to fix an issue where
during `StandaloneHerder.restartConnector`, the post-transformed
connector config would be saved back into `ClusterConfigState`.

I also performed an analysis of all other code paths where configs are
saved back into `ClusterConfigState` and did not find any other
issues.

Author: Robert Yokota <rayokota@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5475 from rayokota/KAFKA-7242-reverse-xform-props",2018-08-28 12:59:08,Robert Yokota,Mixed
9e23af3115ddfbf311f6b37c273327b3fa8e9a14,"KAFKA-7287: Set open ACL for old consumer znode path (#5503)

Reviewers: Sriharsha Chintalapani <sriharsha@apache.org>, Satish Duggana <satishd@apache.org>, Jun Rao <junrao@gmail.com>",2018-08-28 15:47:07,Manikumar Reddy O,Not TDD
7cef37cf55353f542db3562157547d26c992e782,"KAFKA-7324: NPE due to lack of SASLExtensions in SASL/OAUTHBEARER (#5552)

Set empty extensions if null is passed in.

Reviewers: Satish Duggana <sduggana@hortonworks.com>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2018-08-29 11:16:29,Ron Dagostino,Mixed
c580f08b7775e4431a4a1559ef7239b69708a782,"KAFKA-7134: KafkaLog4jAppender exception handling with ignoreExceptions (#5415)

Reviewers: Andras Beni <andrasbeni@cloudera.com>, Sandor Murakozi <smurakozi@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2018-08-29 12:30:39,Andras Katona,Mixed
34d9ae66281602dad3a70ecd07ca0f2b6237ae8c,"MINOR: Fix streams Scala peek recursive call (#5566)

This PR fixes the previously recursive call of Streams Scala peek

Reviewers: Joan Goyeau <joan@goyeau.com>, Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",2018-08-29 09:34:01,tedyu,Mixed
f3a4ebc8f8be12884ff67a63c7ba5ce5c5f67881,"KAFKA-6859; Do not send LeaderEpochRequest for undefined leader epochs (#5320)

If a broker or topic has a message format < 0.11, it does not track leader epochs. LeaderEpochRequests for such will always return undefined, making the follower truncate to the highe watermark. Since there is no use to use the network for such cases, don't send a request.

Reviewers: Anna Povzner <anna@confluent.io>, Jason Gustafson <jason@confluent.io>",2018-08-30 17:04:28,Stanislav Kozlovski,Mixed
5d1bfa0665ce0850ee76cee152e397c23ac329a7,"KAFKA-6950: Delay response to failed client authentication to prevent potential DoS issues (KIP-306) (#5082)

Reviewers: Ron Dagostino <rndgstn@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>",2018-08-31 12:04:33,Dhruvil Shah,Mixed
f6890e78687afbbe09ff34b0a9383b548be77ee6,"MINOR: Next round of fetcher thread consolidation (#5587)

Pull the epoch request build logic up to `AbstractFetcherThread`. Also get rid of the `FetchRequest` indirection.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>",2018-08-31 13:10:27,Jason Gustafson,Mixed
4f38c8cd6079100548ca8056c358a2fea57986c2,"KAFKA-7369; Handle retriable errors in AdminClient list groups API (#5595)

We should retry when possible if ListGroups fails due to a retriable error (e.g. coordinator loading).

Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>,  Guozhang Wang <wangguoz@gmail.com>",2018-08-31 18:40:42,Jason Gustafson,Mixed
4a46a353482116ed5502737f7809bc6c0d37bf36,"MINOR: Tidy up pattern type comparisons, remove unused producer-id (#5593)

Reviewers: Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy <manikumar.reddy@gmail.com>",2018-09-04 21:24:06,Rajini Sivaram,Mixed
79a608b286fd6271b841d3cc7997bf69227de912,"KAFKA-7211; MM should handle TimeoutException in commitSync

With KIP-266 introduced, MirrorMaker should handle TimeoutException thrown in commitSync(). Besides, MM should only commit offsets for existsing topics.

Author: huxihx <huxi_2b@hotmail.com>

Reviewers: Dong Lin <lindong28@gmail.com>

Closes #5492 from huxihx/KAFKA-7211",2018-09-04 13:56:05,huxihx,Not TDD
297fb396a0038addea06a76fd4ab9a451eb7562e,"KAFKA-6082; Fence zookeeper updates with controller epoch zkVersion

This PR aims to enforce that the controller can only update zookeeper states after checking the controller epoch zkVersion. The check and zookeeper state updates are wrapped in the zookeeper multi() operations to ensure that they are done atomically. This PR is necessary to resolve issues related to multiple controllers (i.e. old controller updates zookeeper states before resignation, which is possible during controller failover based on the single threaded event queue model we have)

This PR includes the following changes:
- Add MultiOp request and response in ZookeeperClient
- Ensure all zookeeper updates done by controller are protected by checking the current controller epoch zkVersion
- Modify test cases in KafkaZkClientTest to test mismatch controller epoch zkVersion

Tests Done:
- Unit tests (with updated tests to test mismatch controller epoch zkVersion)
- Existing integration tests

Author: Zhanxiang (Patrick) Huang <hzxa21@hotmail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Dong Lin <lindong28@gmail.com>, Manikumar Reddy O <manikumar.reddy@gmail.com>

Closes #5101 from hzxa21/KAFKA-6082",2018-09-07 14:17:49,Zhanxiang (Patrick) Huang,Mixed
f348f10ef87925081fdf9455ace6d2a86179b483,"KAFKA-7117: Support AdminClient API in AclCommand (KIP-332) (#5463)

Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Jun Rao <junrao@gmail.com>",2018-09-07 17:40:59,Manikumar Reddy O,Mixed
0984a76b712caa18c688eafbacaa2a7c889d27b2,"MINOR: Move common out of range handling into AbstractFetcherThread (#5608)

This patch removes the duplication of the out of range handling between `ReplicaFetcherThread` and `ReplicaAlterLogDirsThread` and attempts to expose a cleaner API for extension. It also adds a mock implementation to facilitate testing and several new test cases.

Reviewers: Jun Rao <junrao@gmail.com>",2018-09-08 17:00:13,Jason Gustafson,Mixed
958cdca9bece8b65ceb204e1c7a14cf44729bb66,"KAFKA-7385; Fix log cleaner behavior when only empty batches are retained (#5623)

With idempotent/transactional producers, we may leave empty batches in the log during log compaction. When filtering the data, we keep track of state like `maxOffset` and `maxTimestamp` of filtered data. This patch ensures we maintain this state correctly for the case when only empty batches are left in `MemoryRecords#filterTo`. Without this patch, we did not initialize `maxOffset` in this edge case which led us to append data to the log with `maxOffset` = -1L, causing the append to fail and log cleaner to crash.

Reviewers: Jason Gustafson <jason@confluent.io>",2018-09-08 18:01:01,Dhruvil Shah,Mixed
4a5cba87bcd4621b999f7290d17d88d6859afb84,"KAFKA-7286; Avoid getting stuck loading large metadata records (#5500)

If a group metadata record size is higher than offsets.load.buffer.size, 
loading offsets and group metadata from __consumer_offsets would hang 
forever. This was due to the buffer being too small to fit any message 
bigger than the maximum configuration. This patch grows the buffer 
as needed so the large records will fit and the loading can move on.
A similar change was made to the logic for state loading in the transaction
coordinator.

Reviewers: John Roesler <vvcephei@users.noreply.github.com>, lambdaliu <lambdaliu@users.noreply.github.com>, Dhruvil Shah <dhruvil@confluent.io>, Jason Gustafson <jason@confluent.io>",2018-09-09 00:05:49,Flavien Raynaud,Mixed
05ba5aa00847b18b74369a821e972bbba9f155eb,"KAFKA-7333; Protocol changes for KIP-320

This patch contains the protocol updates needed for KIP-320 as well as some of the basic consumer APIs (e.g. `OffsetAndMetadata` and `ConsumerRecord`). The inter-broker format version has not been changed and the brokers will continue to use the current API versions.

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Dong Lin <lindong28@gmail.com>

Closes #5564 from hachikuji/KAFKA-7333",2018-09-09 00:17:25,Jason Gustafson,Mixed
b8651d4e82d45463d2c71798bd5852f8a605b440,"MINOR: Code cleanup of 'clients' module (#5427)

Cleanup involves:
* Refactoring to use Java 8 constructs (lambdas,
diamond for `empty` collection methods) and library
methods (`computeIfAbsent`)
* Simplifying code (including unnecessarily complex
`equals` and `hashCode` implementations)
* Removing redundant code
* Fixing typos

Reviewers: Ryanne Dolan, Ismael Juma <ismael@juma.me.uk>",2018-09-09 14:25:30,Vahid Hashemian,Mixed
164ef9462e9d18a36f7be856243a1cacf9a300bf,"KAFKA-4932: Add support for UUID serialization and deserialization (KIP-206)

[KAFKA-4932](https://issues.apache.org/jira/browse/KAFKA-4932)

Added a UUID Serializer / Deserializer.

Added the UUID type to the SerializationTest

Author: Brandon Kirchner <brandon.kirchner@civitaslearning.com>

Reviewers: Jeff Klukas <jeff@klukas.net>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #4438 from brandonkirchner/KAFKA-4932.uuid-serde",2018-09-09 17:22:18,Brandon Kirchner,Not TDD
25b13bca7b696b349bae2e9d5e41b75496bfdb1b,"KAFKA-7096 : Clear buffered data for partitions that are explicitly unassigned by user

Author: mgharat <gharatmayuresh15@gmail.com>

Reviewers: Dong Lin <lindong28@gmail.com>

Closes #5289 from MayureshGharat/KAFKA-7096",2018-09-10 21:41:14,mgharat,Mixed
257c402c1565eebf421dbd44a272a3dd6c99d609,"MINOR: Remove deprecated Resource class constructor usage (#5624)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-09-11 00:00:52,Manikumar Reddy O,Not TDD
79ad9026a667469a2013ce82961c0c90f3bb0877,"MINOR: Missing throttle time in OffsetsForLeaderEpoch response (#5635)

With KIP-320, the OffsetsForLeaderEpoch API is intended to be used by consumers to detect log truncation. Therefore the new response schema should expose a field for the throttle time like all the other APIs.

Reviewers: Dong Lin <lindong28@gmail.com>",2018-09-11 09:08:22,Jason Gustafson,Not TDD
e2ec2d79c8d5adefc0c764583cec47144dbc5705,"KAFKA-7044; Fix Fetcher.fetchOffsetsByTimes and NPE in describe consumer group (#5627)

A call to `kafka-consumer-groups --describe --group ...` can result in NullPointerException for two reasons:
1)  `Fetcher.fetchOffsetsByTimes()` may return too early, without sending list offsets request for topic partitions that are not in cached metadata.
2) `ConsumerGroupCommand.getLogEndOffsets()` and `getLogStartOffsets()` assumed that endOffsets()/beginningOffsets() which eventually call Fetcher.fetchOffsetsByTimes(), would return a map with all the topic partitions passed to endOffsets()/beginningOffsets() and that values are not null. Because of (1), null values were possible if some of the topic partitions were already known (in metadata cache) and some not (metadata cache did not have entries for some of the topic partitions). However, even with fixing (1), endOffsets()/beginningOffsets() may return a map with some topic partitions missing, when list offset request returns a non-retriable error. This happens in corner cases such as message format on broker is before 0.10, or maybe in cases of some other errors. 

Testing:
-- added unit test to verify fix in Fetcher.fetchOffsetsByTimes() 
-- did some manual testing with `kafka-consumer-groups --describe`, causing NPE. Was not able to reproduce any NPE cases with DescribeConsumerGroupTest.scala,

Reviewers: Jason Gustafson <jason@confluent.io>",2018-09-11 10:10:42,Anna Povzner,Mixed
acd3858ea69e676a7840d998240deb32aee62dc0,"KAFKA-7396: Materialized, Serialized, Joined, Consumed and Produced with implicit Serdes (#5551)

We want to make sure that we always have a serde for all Materialized, Serialized, Joined, Consumed and Produced.
For that we can make use of the implicit parameters in Scala.

KIP: https://cwiki.apache.org/confluence/display/KAFKA/KIP-365%3A+Materialized%2C+Serialized%2C+Joined%2C+Consumed+and+Produced+with+implicit+Serde

Reviewers: John Roesler <vvcephei@users.noreply.github.com>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bbejeck@gmail.com>, Guozhang Wang <guozhang@confluent.io>, Ted Yu <yuzhihong@gmail.com>",2018-09-11 14:08:42,Joan Goyeau,Mixed
283a19481d1ce4a77f5f465e7b96288db22a8ff1,"KAFKA-3514: Part III, Refactor StreamThread main loop (#5428)

* Refactor the StreamThread main loop, in the following:

1. Fetch from consumer and enqueue data to tasks.
2. Check if any tasks should be enforced process.
3/ Loop over processable tasks and process them for N iterations, and then check for 1) commit, 2) punctuate, 3) need to call consumer.poll
4. Even if there is not data to process in this iteration, still need to check if commit / punctuate is needed
5. Finally, try update standby tasks.

*Add an optimization to only commit when it is needed (i.e. at least some process() or punctuate() was triggered since last commit).

*Found and fixed a ProducerFencedException scenario: producer.send() call would never throw a ProducerFencedException directly, but it may throw a KafkaException whose ""cause"" is a ProducerFencedException.

Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>",2018-09-11 16:16:52,Guozhang Wang,Mixed
c121f4eb82da654acbdd133a556cfe1f9197a46a,"MINOR: Remove deprecated Metric.value() method usage (#5626)

Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, John Roesler <john@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2018-09-12 19:05:19,Manikumar Reddy O,Mixed
ac7cd16e936116ee92ce5f179b671203b3bacf25,"KAFKA-7394; OffsetsForLeaderEpoch supports topic describe access (#5634)

As part of KIP-320, allow OffsetsForLeaderEpoch requests with Topic Describe permission.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2018-09-12 23:34:41,Jason Gustafson,Not TDD
466d89306ea23d1f17be0914416944618ceb9f86,"MINOR: Insure that KafkaStreams client is closed if test fails (#5618)

Reviewers: Guozhang Wang <guozhang@confluent.io>, John Roessler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Eno Thereska <enother@amazon.com>",2018-09-13 13:04:09,Matthias J. Sax,Mixed
b74e7e407c0b065adf68bc45042063def922aa10,"MINOR: Enable ignored upgrade system tests - trunk (#5605)

Removed ignore annotations from the upgrade tests. This PR includes the following changes for updating the upgrade tests:

* Uploaded new versions 0.10.2.2, 0.11.0.3, 1.0.2, 1.1.1, and 2.0.0 (in the associated scala versions) to kafka-packages
* Update versions in version.py, Dockerfile, base.sh
* Added new versions to StreamsUpgradeTest.test_upgrade_downgrade_brokers including version 2.0.0
* Added new versions StreamsUpgradeTest.test_simple_upgrade_downgrade test excluding version 2.0.0
* Version 2.0.0 is excluded from the streams upgrade/downgrade test as StreamsConfig needs an update for the new version, requiring a KIP. Once the community votes the KIP in, a minor follow-up PR can be pushed to add the 2.0.0 version to the upgrade test.
* Fixed minor bug in kafka-run-class.sh for classpath in upgrade/downgrade tests across versions.
* Follow on PRs for 0.10.2x, 0.11.0x, 1.0.x, 1.1.x, and 2.0.x will be pushed soon with the same updates required for the specific version.

Reviewers: Eno Thereska <eno.thereska@gmail.com>, John Roesler <vvcephei@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <matthias@confluent.io>",2018-09-13 13:46:47,Bill Bejeck,Not TDD
e24d82e0eb66b62b5d74f2c60b1eb5db9f378673,"KAFKA-7280; Synchronize consumer fetch request/response handling (#5495)

This patch fixes unsafe concurrent access in the consumer by the heartbeat thread and the thread calling `poll()` to the fetch session state in `FetchSessionHandler`.

Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-09-14 11:51:46,Rajini Sivaram,Mixed
c5ef614bbf133e18bd207e22f2697a2d1d3e8e4e,"KAFKA-7414; Out of range errors should never be fatal for follower (#5654)

This patch fixes the inconsistent handling of out of range errors in the replica fetcher. Previously we would raise a fatal error if the follower's offset is ahead of the leader's and unclean leader election is not enabled. The behavior was inconsistent depending on the message format. With KIP-101/KIP-279 and the new message format, upon becoming a follower, the replica would use leader epoch information to reconcile the end of the log with the leader and simply truncate. Additionally, with the old format, the check is not really bulletproof for detecting data loss since the unclean leader's end offset might have already caught up to the follower's offset at the time of its initial fetch or when it queries for the current log end offset.

With this patch, we simply skip the unclean leader election check and allow the needed truncation to occur. When the truncation offset is below the high watermark, a warning will be logged. This makes the behavior consistent for all message formats and removes a scenario in which an error on one partition can bring the broker down.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",2018-09-17 12:36:53,Jason Gustafson,Mixed
d87ed233c9e3a8faf2a8032d62ff9b90b0e40bfb,"KAFKA-7322; Fix race condition between log cleaner thread and log retention thread when topic cleanup policy is updated

In order to fix race condition between log cleaner thread and log retention thread when dynamically switching topic cleanup policy, existing log cleaner in-progress map is used to prevent more than one thread from working on the same topic partition.

Author: Xiongqi Wesley Wu <xiongqi.wu@gmail.com>

Reviewers: Dong Lin <lindong28@gmail.com>

Closes #5591 from xiowu0/trunk",2018-09-17 23:38:01,Xiongqi Wesley Wu,Mixed
43e21252cac8eebfbb168cd47d4de18241f8b755,"KAFKA-7388 equal sign in property value for password (#5630)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Murali Mani <murali.mani@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2018-09-18 09:35:59,Mutasem Aldmour,Mixed
88823c6016ea2e306340938994d9e122abf3c6c0,"MINOR: cleanup some state store code (#5656)

Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-09-18 14:19:41,Matthias J. Sax,Mixed
7bc1019d4bdf2b9592a7fc3e08659aae7961046b,"[KAFKA-7379] [streams] send.buffer.bytes should be allowed to set -1 in KafkaStreams (#5643)

What changes were proposed in this pull request?
atLeast(0) in StreamsConfig, ProducerConfig and ConsumerConfig were replaced by SEND_BUFFER_LOWER_BOUND and RECEIVE_BUFFER_LOWER_BOUND from CommonClientConfigs.

How was this patch tested?
Three unit tests were added to KafkaStreamsTest

Reviewers: Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>, Matthias J. Sax <mjsax@apache.org>",2018-09-20 12:20:03,Aleksei Izmalkin,Not TDD
f1f719211e5f28fe5163e65dba899b1da796a8e0,"KAFKA-6923; Refactor Serializer/Deserializer for KIP-336 (#5494)

This patch implements KIP-336. It adds a default implementation to the Serializer/Deserializer interface to support the use of headers and it deprecates the ExtendedSerializer and ExtendedDeserializer interfaces for later removal.

Reviewers: Satish Duggana <sduggana@hortonworks.com>, John Roesler <john@confluent.io>, Jason Gustafson <jason@confluent.io>",2018-09-20 15:55:10,Viktor Somogyi,Mixed
96132e2dbb69a0c6c11cb183bb05cefef4e30557,"MINOR: rename InternalProcessorContext.initialized (#5672)

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-09-21 11:55:56,John Roesler,Mixed
0bc7008e7559337b588c60366d1b935eace59ffc,"KAFKA-7400: Compacted topic segments that precede the log start offse… (#5646)

* KAFKA-7400: Compacted topic segments that precede the log start offset are not cleaned up

Currently we don't delete any log segments if the cleanup policy doesn't include delete. This patch changes the behavior to delete log segments that fully precede the log start offset even when deletion is not enabled. Tested with unit tests to verify that LogManager.cleanupLogs now cleans logs with cleanup.policy=compact and that Log.deleteOldSegments deletes segments that preced the start offset regardless of the cleanup policy.

Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Jason Gustafson <jason@confluent.io>, Jun Rao <junrao@gmail.com>",2018-09-21 13:31:45,Bob Barrett,Mixed
057c5307e0f055b37794453d16f6f43b8c56528c,"KAFKA-7223: Suppress API with only immediate emit (#5567)

Part 1 of the suppression API.

* add the DSL suppress method and config objects
* add the processor, but only in ""identity"" mode (i.e., it will forward only if the suppression spec says to forward immediately)
* add tests

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-09-24 13:27:39,John Roesler,Mixed
c835331c7855c4bd60b3eb82b8f284006a1ee9b7,"KAFKA-5066; Add KafkaMetricsConfig (Yammer metrics reporters) props to documentation

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Dong Lin <lindong28@gmail.com>

Closes #5563 from omkreddy/KAFKA-5066-KAFKA-METRICS-CONFIG",2018-09-24 22:01:00,Manikumar Reddy,Mixed
f712ce69fc2cb6a164b1ea8e491c9d68e6661933,"KAFKA-7223: add tests in preparation for suppression (#5687)

This is Part 2 of suppression.
Part 1 was #5567

In an effort to control the scope of the review, this PR is just the tests for buffered suppression.

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-09-25 13:41:22,John Roesler,Mixed
9f7267dd2fedde86bf15aabdbc5256e5fc617184,"KAFKA-7437; Persist leader epoch in offset commit metadata (#5689)

This commit implements the changes described in KIP-320 for the persistence of leader epoch information in the offset commit protocol.

Reviewers:  Rajini Sivaram <rajinisivaram@googlemail.com>",2018-09-26 14:25:55,Jason Gustafson,Mixed
70d90c371833b09cf934c8c2358171433892a085,"KAFKA-7409; Validate message format version before creating topics or altering configs (#5651)

Values for `message.format.version` and `log.message.format.version` should be verified before topic creation or config change.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2018-09-27 22:39:44,huxi,Not TDD
0a8205cb45667fd7d001f21e4e0412220b1abec1,"KAFKA-7453: Expire registered channels not selected within idle timeout (#5712)

Reviewers: Jun Rao <junrao@gmail.com>. Ismael Juma <ismael@juma.me.uk>",2018-09-28 21:07:57,Rajini Sivaram,Mixed
cb21bca400359e6b7e61555578b7539f27d9d2ff,"KAFKA-7454: Use lazy allocation for SslTransportLayer buffers and null them on close (#5713)

Lazy allocation helps when there are a large number of connections
that have been accepted, but where no data has been received from
the clients. Each buffer is often around 16k (max TLS record size).

Nulling the buffers should not make a difference in the current
implementation since we release the reference to the channel
and transport layer after we close them, but it's a good practice
to release medium/large buffers after `close` is called.

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2018-09-28 23:09:10,Rajini Sivaram,Mixed
22f1724123c267352116c18db1abdee25c31b382,"KAFKA-7434: Fix NPE in DeadLetterQueueReporter

*More detailed description of your change,
if necessary. The PR title and PR message become
the squashed commit message, so use a separate
comment to ping reviewers.*

*Summary of testing strategy (including rationale)
for the feature or bug fix. Unit and/or integration
tests are expected for any behaviour change and
system tests should be considered for larger changes.*

Author: Michał Borowiecki <mbor81@gmail.com>

Reviewers: Arjun Satish <arjun@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5700 from mihbor/KAFKA-7434",2018-09-29 10:19:10,Michał Borowiecki,Not TDD
08dfab06e7919dfe625431b1978a3754b72d46a2,"KAFKA-3514: Upgrade Documentation (#5714)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2018-09-30 12:01:11,Guozhang Wang,Not TDD
eb61df642d8227fb7eaa1099ec055145b02e3dca,"KAFKA-7223: internally provide full consumer record during restore (#5710)

The Suppression buffer stores the full record context, not just the key and value,
so its changelog/restore loop will also need to preserve this information.

This change is a precondition to that, creating an option to register a
state restore callback to receive the full consumer record.

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-09-30 16:04:28,John Roesler,Mixed
49b5206a82d0a47e01f4c5f7098119440061a1bb,"MINOR: don't log config during unit tests (#5671)

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-09-30 16:52:55,John Roesler,Not TDD
fd44dc7fb210614349a873cdd82087ef5677f583,"KAFKA-6684: Support casting Connect values with bytes schema to string

Allow to cast LogicalType to string by calling the serialized (Java) object's toString().

Added tests for `BigDecimal` and `Date` as whole record and as fields.

Author: Amit Sela <amitsela33@gmail.com>

Reviewers: Randall Hauch <rhauch@gmail.com>, Robert Yokota <rayokota@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #4820 from amitsela/cast-transform-bytes",2018-09-30 22:24:09,Amit Sela,Mixed
d568f73fc6ece3d29989413174eee0195d3d0a4a,"KAFKA-7456: Serde Inheritance in DSL (#5521)

Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-10-01 16:24:12,Guozhang Wang,Mixed
dff1a3799c1c25b1b0009be6835f2c9c78cb5900,"KAFKA-7406: Name join group repartition topics (#5709)

Reviewer: John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-10-01 23:09:12,Bill Bejeck,Not TDD
5ba9cade7b066cc26842aeaac5662a57c502ffcb,"KAFKA-7223: In-Memory Suppression Buffering (#5693)

Reviewer: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-10-01 23:10:34,John Roesler,Mixed
8fb5e63aa88019216e95fdbe0b6874c723b64bb4,KAFKA-7429: Enable key/truststore update with same filename/password (#5699),2018-10-02 12:57:31,Rajini Sivaram,Mixed
b793eaade4fcb0705ab80c2a806331fab8c29f9f,"KAFKA-7223: Make suppression buffer durable (#5724)

This is Part 4 of suppression (durability)
Part 1 was #5567 (the API)
Part 2 was #5687 (the tests)
Part 3 was #5693 (in-memory buffering)

Implement a changelog for the suppression buffer so that the buffer state may be recovered on restart or recovery.
As of this PR, suppression is suitable for general usage.

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-10-03 09:52:13,John Roesler,Mixed
a5335e7cbd1e53790b4bb5e95b6f9027e17fbf2b,KAFKA-6123: Give client MetricsReporter auto-generated client.id (#5383),2018-10-03 09:56:22,Kevin Lu,Mixed
7bd8ada8e21cd9717eea6916a5a55274a49fdeda,"MINOR: Docs on state store instantiation (#5698)

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-10-03 11:20:47,Guozhang Wang,Not TDD
87879d51521d5574cbbf37dd97c83b7e4fc00dae,"KAFKA-7223: Add name config to Suppressed (#5731)

KIP-372 (allow naming all internal topics) was designed and developed concurrently with suppression.

Since suppression introduces a new internal topic, it also needs to be nameable.

Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-10-03 18:05:41,John Roesler,Mixed
260b07a6da070e6312443fb7cc6b937bef2865ea,"KAFKA-7196; Remove heartbeat delayed operation for those removed consumers at the end of each rebalance

During the consumer group rebalance, when the joining group phase finishes, the heartbeat delayed operation of the consumer that fails to rejoin the group should be removed from the purgatory. Otherwise, even though the member ID of the consumer has been removed from the group, its heartbeat delayed operation is still registered in the purgatory and the heartbeat delayed operation is going to timeout and then another unnecessary rebalance is triggered because of it.

Author: Lincong Li <lcli@linkedin.com>

Reviewers: Dong Lin <lindong28@gmail.com>

Closes #5556 from Lincong/remove_heartbeat_delayedOperation",2018-10-04 09:15:11,Lincong Li,Mixed
ca641b3e2e48c14ff308181c775775408f5f35f7,"KAFKA-7277: Migrate Streams API to Duration instead of longMs times (#5682)

Reviewers: Johne Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-10-04 13:51:39,Nikolay,Mixed
f2dd6aa2698345fd0b0348f7bc74ce3215adf682,"KAFKA-7415; Persist leader epoch and start offset on becoming a leader (#5678)

This patch ensures that the leader epoch cache is updated when a broker becomes leader with the latest epoch and the log end offset as its starting offset. This guarantees that the leader will be able to provide the right truncation point even if the follower has data from leader epochs which the leader itself does not have. This situation can occur when there are back to back leader elections.

Additionally, we have made the following changes:

1. The leader epoch cache enforces monotonically increase epochs and starting offsets among its entry. Whenever a new entry is appended which violates requirement, we remove the conflicting entries from the cache.
2. Previously we returned an unknown epoch and offset if an epoch is queried which comes before the first entry in the cache. Now we return the smallest . For example, if the earliest entry in the cache is (epoch=5, startOffset=10), then a query for epoch 4 will return (epoch=4, endOffset=10). This ensures that followers (and consumers in KIP-320) can always determine where the correct starting point is for the active log range on the leader.

Reviewers: Jun Rao <junrao@gmail.com>",2018-10-04 14:02:23,Jason Gustafson,Mixed
7ea0655711a664296cddb656364d367c66ed277c,"KAFKA-7441; Allow LogCleanerManager.resumeCleaning() to be used concurrently

Author: Xiongqi Wesley Wu <xiongqi.wu@gmail.com>

Reviewers: Dong Lin <lindong28@gmail.com>

Closes #5694 from xiowu0/fixrace2",2018-10-04 17:02:27,Xiongqi Wesley Wu,Mixed
d76805f0fd2d65e9fb5582e4e0d30c1bd3fccd89,"MINOR: Fix generic type of ProcessorParameters (#5741)

In unrelated recent work, I noticed some warnings about the missing type parameters on ProcessorParameters.

While investigating it, it seems like there was a bug in the creation of repartition topics.

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-10-04 17:37:53,John Roesler,Not TDD
3edd8e7333ec0bb32ab5ae4ec4814fe30bb8f91d,"KAFKA-7476: Fix Date-based types in SchemaProjector

Various converters (AvroConverter and JsonConverter) produce a
SchemaAndValue consisting of a logical schema type and a java.util.Date.
This is a fix for SchemaProjector to properly handle the Date.

Author: Robert Yokota <rayokota@gmail.com>

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5736 from rayokota/KAFKA-7476",2018-10-04 20:34:50,Robert Yokota,Mixed
1bc620d1af50d24b4d5f12147e425bb7cb7f19bf,"MINOR: Clarify usage of stateful processor node (#5740)

In recent PRs, we have been confused about the proper usage of
StatefulProcessorNode (#5731 , #5737 )

This change disambiguates it.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-10-05 09:44:49,John Roesler,Not TDD
089d1b154fff1536fe7953ffe157a203b4a24455,"MINOR: Add topic config to PartitionsSpec (#5523)

Reviewers: Bob Barrett <bob.barrett@outlook.com>, Ismael Juma <ismael@juma.me.uk>",2018-10-05 11:45:50,Colin Patrick McCabe,Not TDD
79757c90df8ee8390aa256998ce5cd1394d8822a,"KAFKA-7467; NoSuchElementException is raised because controlBatch is empty (#5727)

This patch adds checks before reading the first record of a control batch. If the batch is empty, it is treated as having already been cleaned. In the case of LogCleaner this means it is safe to discard. In the case of ProducerStateManager it means it shouldn't cause state to be stored because the relevant transaction has already been cleaned. In the case of Fetcher, it just preempts the check for an abort. In the case of GroupMetadataManager, it doesn't process the offset as a commit. The patch also adds isControl to the output of DumpLogSegments. Changes were tested with unit tests, except the DumpLogSegments change which was tested manually.",2018-10-05 11:58:59,Bob Barrett,Mixed
ed3bd79633ae227ad995dafc3d9f384a5534d4e9,"KAFKA-7395; Add fencing to replication protocol (KIP-320) (#5661)

This patch contains the broker-side support for the fencing improvements from KIP-320. This includes the leader epoch validation in the ListOffsets, OffsetsForLeaderEpoch, and Fetch APIs as well as the changes needed in the fetcher threads to maintain and use the current leader epoch. The client changes from KIP-320 will be left for a follow-up.

One notable change worth mentioning is that we now require the read lock in `Partition` in order to read from the log or to query offsets. This is necessary to ensure the safety of the leader epoch validation. Additionally, we forward all leader epoch changes to the replica fetcher thread and go through the truncation phase. This is needed to ensure the fetcher always has the latest epoch and to guarantee that we cannot miss needed truncation if we missed an epoch change.

Reviewers: Jun Rao <junrao@gmail.com>",2018-10-05 13:25:08,Jason Gustafson,Mixed
c26823b01e61f301bc2fbd3fe54665e5b92284d1,"KAFKA-7462: Make token optional for OAuthBearerLoginModule (#5733)

OAuthBearerLoginModule is used both on the server-side and client-side (similar to login modules for other mechanisms). OAUTHBEARER tokens are client credentials used only on the client-side to authenticate with servers, but the current implementation requires tokens to be provided on the server-side even if OAUTHBEARER is not used for inter-broker communication. This commit makes tokens optional for server-side login context to allow brokers to be configured without a token when OAUTHBEARER is not used for inter-broker communication.

Reviewers: Ron Dagostino <rndgstn@gmail.com>, Jun Rao <junrao@gmail.com>",2018-10-08 10:14:25,Rajini Sivaram,Not TDD
13379af17d95788568038c0c6daeb983819669e3,"KAFKA-7215: Improve LogCleaner Error Handling (#5439)

The thread no longer dies. When encountering an unexpected error, it marks the partition as ""uncleanable"" which means it will not try to clean its logs in subsequent runs.

Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Jun Rao <junrao@gmail.com>",2018-10-08 12:54:37,Stanislav Kozlovski,Mixed
0848b78881afce5899cea1f10c323249f9f0b8cc,"KAFKA-7366: Make topic configs segment.bytes and segment.ms to take effect immediately (#5728)

Reviewers: Ismael Juma <ismael@juma.me.uk> and Jun Rao <junrao@gmail.com>",2018-10-09 10:37:54,Manikumar Reddy O,Mixed
6d16879c0ffc4b52a544a8664329d09101832964,"KAFKA-7477: Improve Streams close timeout semantics (#5747)

Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-10-09 11:37:08,Nikolay,Mixed
9a74569b994681a7b672ccb22a2e359ab8f7ed0b,"KAFKA-7483: Allow streams to pass headers through Serializer. (#5751)

Satish Duggana <sduggana@hortonworks.com>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-10-09 15:29:04,Kamal Chandraprakash,Mixed
578205cadd0bf64d671c6c162229c4975081a9d6,"KAFKA-7439; Replace EasyMock and PowerMock with Mockito in clients module

Development of EasyMock and PowerMock has stagnated while Mockito
continues to be actively developed. With the new Java release cadence,
it's a problem to depend on libraries that do bytecode manipulation
and are not actively maintained. In addition, Mockito is also
easier to use.

While updating the tests, I attempted to go from failing test to
passing test. In cases where the updated test passed on the first
attempt, I artificially broke it to ensure the test was still doing its
job.

I included a few improvements that were helpful while making these
changes:

1. Better exception if there are no nodes in `leastLoadedNodes`
2. Always close the producer in `KafkaProducerTest`
3. requestsInFlight producer metric should not hold a reference to
`Sender`

Finally, `Metadata` is no longer final so that we don't need
`PowerMock` to mock it. It's an internal class, so it's OK.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Dong Lin <lindong28@gmail.com>

Closes #5691 from ijuma/kafka-7438-mockito",2018-10-09 15:55:09,Ismael Juma,Mixed
741cb761c5239297029a446518c332f6c4ed08f6,"KAFKA-4514; Add Codec for ZStandard Compression (#2267)

This patch adds support for zstandard compression to Kafka as documented in KIP-110: https://cwiki.apache.org/confluence/display/KAFKA/KIP-110%3A+Add+Codec+for+ZStandard+Compression. 

Reviewers: Ivan Babrou <ibobrik@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2018-10-09 17:13:33,Lee Dongjin,Mixed
34f029e3dc30d8a7b0f1f1ec639d16a4e1fb4cbf,"MINOR: Fix broken standalone ReplicationQuotasTestRig test (#5773)

* Fix `ZkUtils.getReassignmentJson` to pass Java map to `Json.encodeAsString`
* Allow new file creation in ReplicationQuotasTestRig test

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-10-10 13:18:00,Manikumar Reddy O,Not TDD
adb3a950ee2d5843673cdf14d5471ded5c0419b2,"MINOR: Fix remaining core, connect and clients tests to pass with Java 11 (#5771)

- SslFactoryTest should use SslFactory to create SSLEngine
- Use Mockito instead of EasyMock in `ConsoleConsumerTest` as one of
the tests mocks a standard library class and the latest released EasyMock
version can't do that when Java 11 is used.
- Avoid mocking `ConcurrentMap` in `SourceTaskOffsetCommitterTest`
for similar reasons. As it happens, mocking is not actually needed here.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2018-10-10 13:31:06,Ismael Juma,Not TDD
79bc0dcf7059fb65bab466a662f6f969e359d7bd,"KAFKA-7475 - capture remote address on connection authetication errors, and log it (#5729)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2018-10-11 12:20:19,Radai Rosenblatt,Not TDD
f393b2f7dd477c3a43e70631f7036a211bf5d740,"KAFKA-6863 Kafka clients should try to use multiple DNS resolved IP (#4987)

Implementation of KIP-302: Based on the new client configuration `client.dns.lookup`, a NetworkClient can use InetAddress.getAllByName to find all IPs and iterate over them when they fail to connect. Only uses either IPv4 or IPv6 addresses similar to the default mode.

Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>
Co-authored-by: Mickael Maison <mickael.maison@gmail.com>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2018-10-11 18:14:17,Edoardo Comar,Mixed
21f88a595b5785d8b9b9a17a3fb667b1712f3b61,"KAFKA-7223: Add late-record metrics (#5742)

Add late record metrics, as specified in KIP-328

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-10-12 09:12:51,John Roesler,Mixed
aaf8e0240355d77777eb3828583f61af14dc3c3b,"KAFKA-7482: LeaderAndIsrRequest should be sent to the shutting down broker (#5745)

Reviewers: Dong Lin <lindong28@gmail.com>",2018-10-12 10:11:54,Jun Rao,Mixed
a947fe8da8646058335ff76b9a744462a3337a63,"KAFKA-6195: Resolve DNS aliases in bootstrap.server (KIP-235) (#4485)

Adds `client.dns.lookup=resolve_canonical_bootstrap_servers_only` option to perform full dns resolution of bootstrap addresses

Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Sriharsha Chintalapani <sriharsha@apache.org>, Edoardo Comar <ecomar@uk.ibm.com>, Mickael Maison <mickael.maison@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2018-10-13 21:39:35,jonathanskrzypek,Mixed
4c602e6130e869abbd111d5d4efe1c2046935c6c,"KAFKA-7498: Remove references from `common.requests` to `clients` (#5784)

Add CreatePartitionsRequest.PartitionDetails similar to CreateTopicsRequest.TopicDetails to avoid references from `common.requests` package to `clients`.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-10-15 13:21:15,Rajini Sivaram,Not TDD
5681309094b114c65018c6951f23eca88c329e03,KAFKA-6764: Improve the whitelist command-line option for console-consumer (#5637),2018-10-15 20:14:17,Suman,Mixed
4b7148a5b66d2207c4c6ef1d2729ce32ec6f8bcf,"KAFKA-7223: Suppression documentation (#5787)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",2018-10-15 21:04:01,John Roesler,Not TDD
509dd95ebbf03681ea680a84b8436814ba3e7541,KAFKA-7496: Handle invalid filters gracefully in KafkaAdminClient#describeAcls  (#5774),2018-10-16 12:07:49,Colin Patrick McCabe,Mixed
86b1150e18d3fe0a0e3019e034e2a6f0204f7a17,"MINOR: Update Streams Scala API for addition of Grouped (#5793)

While working on the documentation updates I realized the Streams Scala API needs
to get updated for the addition of Grouped

Added a test for Grouped.scala ran all streams-scala tests and streams tests

Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-10-16 07:24:50,Bill Bejeck,Mixed
9951f8fee145ce10b5dccde665e160a5f4ff6d03,"KAFKA-7513: Fix timing issue in SaslAuthenticatorFailureDelayTest (#5805)

Reduce tick interval of the mock timer and avoid large timer increments to avoid hitting idle expiry on the client-side before delayed close is processed by the server. Also reduce poll interval in the server to make the test complete faster (since delayed close is only processed when poll returns).

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-10-16 17:15:21,Rajini Sivaram,Not TDD
eae5ae3b047b776fa144064b45cf7a6a62e285c6,"KAFKA-7080 and KAFKA-7222: Cleanup overlapping KIP changes Part 2

#5804 removed `Windows#segmentInterval`, but did not remove all references to it.

Author: John Roesler <john@confluent.io>

Reviewers: Damian Guy <damian.guy@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5806 from vvcephei/fix-missing-segment-interval",2018-10-17 11:03:16,John Roesler,Not TDD
1e92b703063433bb6855f9fad8d171dce43080b3,"MINOR: Ensure initial topic configs and updates are logged

This patch adds logging of topic config overrides during creation or during the handling of alter config requests. Also did some minor cleanup to avoid redundant validation logic when adding partitions.

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #5812 from hachikuji/minor-log-topic-creation-configs",2018-10-18 16:05:49,Jason Gustafson,Mixed
928f45f61f793f0b2d7df11ff92463d7edda60d6,"KAFKA-7464; catch exceptions in ""leaderEndpoint.close()"" when shutting down ReplicaFetcherThread

After KAFKA-6051, we close leaderEndPoint in replica fetcher thread initiateShutdown to try to preempt in-progress fetch request and accelerate repica fetcher thread shutdown. However, leaderEndpoint can throw an Exception when the replica fetcher thread is still actively fetching, which can cause ReplicaManager to fail to shutdown cleanly. This PR catches the exceptions thrown in ""leaderEndpoint.close()"" instead of letting it throw up in the call stack.

Author: Zhanxiang (Patrick) Huang <hzxa21@hotmail.com>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Dong Lin <lindong28@gmail.com>

Closes #5808 from hzxa21/KAFKA-7464",2018-10-18 11:25:03,Zhanxiang (Patrick) Huang,Mixed
83c39969745dc7076e3756439f6842e7431a8c55,"MINOR: Fix some typos

Just a doc change

Author: John Eismeier <john.eismeier@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #4573 from jeis2497052/trunk",2018-10-20 19:40:53,John Eismeier,Not TDD
fed27fdd75e3f7994b87a035f4984d77b8f4411b,"KAFKA-7501: Fix producer batch double deallocation when receiving message too large error on expired batch (#5807)

Minor clean-ups for clarity included.

Reviewers: Dong Lin <lindong28@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2018-10-22 01:36:24,Xiongqi Wu,Mixed
ed94cf4d314d1fea63fa4972e5aec73d35cd6813,"KAFKA-7519 Clear pending transaction state when expiration fails (#5820)

Make sure that the transaction state is properly cleared when the
`transactionalId-expiration` task fails. Operations on that transactional
id would otherwise return a `CONCURRENT_TRANSACTIONS` error
and appear ""untouchable"" to transaction state changes, preventing
transactional producers from operating until a broker restart or
transaction coordinator change.

Unit tested by verifying that having the `transactionalId-expiration` task
won't leave the transaction metadata in a pending state if the replica
manager returns an error.

Reviewers: Jason Gustafson <jason@confluent.io>",2018-10-22 05:14:32,Bridger Howell,Mixed
e9bbfde10f1d73e500063817ada7a9ad474bca3f,"MINOR: Prohibit setting StreamsConfig commit.interval.ms to a negative value (#5809)

Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",2018-10-22 17:21:19,occho,Mixed
cb6d69cbee42d26006c62abb6ae6cea50b346fb9,"MINOR: buffer should ignore caching (#5819)

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-10-23 22:21:37,John Roesler,Mixed
32e1da570a8aa2ac87d9b5ab1cda1e3cdb867874,"KAFKA-5462: Add configuration to build custom SSL principal name (KIP-371)

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Sriharsha Chintalapani <sriharsha@apache.org>

Closes #5684 from omkreddy/KAFKA-5462-SSL-Name",2018-10-25 17:10:14,Manikumar Reddy,Mixed
73da59191606fe9c03ef6e1b978549bc1d9ee81e,"KAFKA-7535; KafkaConsumer doesn't report records-lag if isolation.level is read_committed

FetchResponse should return the partitionData's lastStabeleOffset

Author: lambdaliu <lambdaliu@tencent.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Dhruvil Shah <dhruvil@confluent.io>, Dong Lin <lindong28@gmail.com>

Closes #5835 from lambdaliu/KAFKA-7535",2018-10-25 08:22:31,lambdaliu,Not TDD
b403a09ec0d78a352411414aaac0663885f777c0,"MINOR: Simplify handling of KafkaProducer serializer overrides

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Dong Lin <lindong28@gmail.com>

Closes #5781 from ijuma/simplify-producer-constructor",2018-10-25 16:26:55,Ismael Juma,Mixed
e8a3bc74254a8e4e4aaca41395177fa4a98b480c,"KAFKA-7352; Allow SASL Connections to Periodically Re-Authenticate (KIP-368) (#5582)

KIP-368 implementation to enable periodic re-authentication of SASL clients. Also adds a broker configuration option to terminate client connections that do not re-authenticate within the configured interval.",2018-10-26 23:18:15,Ron Dagostino,Mixed
57502a6995d3e086e2d9019405c949bbbdc29b8c,"KAFKA-7534: Error in flush calling close may prevent underlying store  from closing (#5833)

Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-10-26 16:00:33,Bill Bejeck,Mixed
9a0ea25fee85837748145d37c69cf4d9bb7f9933,"MINOR: Use string/log interpolation instead of string concat in core and clients (#5850)

Also removed a few unused imports and tweaked the log message slightly.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-10-29 06:37:23,Mickael Maison,Mixed
d28c5348197256db09b59d1ebbfe7db9d3934f47,"KAFKA-7515: Trogdor - Add Consumer Group Benchmark Specification (#5810)

This ConsumeBenchWorker now supports using consumer groups.  The groups may be either used to store offsets, or as subscriptions.",2018-10-29 10:51:07,Stanislav Kozlovski,Mixed
d71cb54672e63d2f0f4b999668336642a9a63a1d,"KAFKA-7567; Clean up internal metadata usage for consistency and extensibility (#5813)

This patch makes two improvements to internal metadata handling logic and testing:

1. It reduce dependence on the public object `Cluster` for internal metadata propagation since it is not easy to evolve. As an example, we need to propagate leader epochs from the metadata response to `Metadata`, but it is not straightforward to do this without exposing it in `PartitionInfo` since that is what `Cluster` uses internally. By doing this change, we are able to remove some redundant `Cluster` building logic. 
2. We want to make the metadata handling in `MockClient` simpler and more consistent. Currently we have mix of metadata update mechanisms which are internally inconsistent with each other and do not match the implementation in `NetworkClient`.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2018-10-30 13:20:13,Jason Gustafson,Mixed
fc1dc358ee9b956e062b0966e1ed1fef40ab43d8,"KAFKA-7568; Return leader epoch in ListOffsets response (#5855)

As part of KIP-320, the ListOffsets API should return the leader epoch of any fetched offset. We either get this epoch from the log itself for a timestamp query or from the epoch cache if we are searching the earliest or latest offset in the log. When handling queries for the latest offset, we have elected to choose the current leader epoch, which is consistent with other handling (e.g. OffsetsForTimes).

Reviewers: Jun Rao <junrao@gmail.com>",2018-11-01 14:34:28,Jason Gustafson,Mixed
6f83d051315e120d148a53e3deba6541d3bb9857,"KAFKA-7313; StopReplicaRequest should attempt to remove future replica for the partition only if future replica exists

This patch fixes two issues:

1) Currently if a broker received StopReplicaRequest with delete=true for the same offline replica, the first StopRelicaRequest will show KafkaStorageException and the second StopRelicaRequest will show ReplicaNotAvailableException. This is because the first StopRelicaRequest will remove the mapping (tp -> ReplicaManager.OfflinePartition) from ReplicaManager.allPartitions before returning KafkaStorageException, thus the second StopRelicaRequest will not find this partition as offline.

This result appears to be inconsistent. And since the replica is already offline and broker will not be able to delete file for this replica, the StopReplicaRequest should fail without making any change and broker should still remember that this replica is offline.

2) Currently if broker receives StopReplicaRequest with delete=true, the broker will attempt to remove future replica for the partition, which will cause KafkaStorageException in the StopReplicaResponse if this replica does not have future replica. It is problematic to always return KafkaStorageException in the response if future replica does not exist.

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #5533 from lindong28/KAFKA-7313",2018-11-06 11:40:39,Dong Lin,Not TDD
7b5ffa0a070065e5e8320f481bbd8a3a26378f91,"KAFKA-7537: Avoid sending full UpdateMetadataRequest to existing brokers in the cluster on broker changes to reduce controller memory footprint (#5869)

This PR avoids sending out full UpdateMetadataReuqest in the following scenarios:

1. On broker startup, send out full UpdateMetadataRequest to newly added brokers and only send out UpdateMetadataReuqest with empty partition states to existing brokers.
2. On broker failure, if it doesn't require leader election, only include the states of partitions that are hosted by the dead broker(s) in the UpdateMetadataReuqest instead of including all partition states.

This PR also introduces a minor optimization in the MetadataCache update to avoid copying the previous partition states upon receiving UpdateMetadataRequest with no partition states.

Reviewers: Jun Rao <junrao@gmail.com>",2018-11-06 15:28:53,Zhanxiang (Patrick) Huang,Not TDD
df0faee09787ec4d14a1a5da98fe9bf4cd7f461c,"KAFKA-7560; PushHttpMetricsReporter should not convert metric value to double

Currently PushHttpMetricsReporter will convert value from KafkaMetric.metricValue() to double. This will not work for non-numerical metrics such as version in AppInfoParser whose value can be string. This has caused issue for PushHttpMetricsReporter which in turn caused system test kafkatest.tests.client.quota_test.QuotaTest.test_quota to fail.

Since we allow metric value to be object, PushHttpMetricsReporter should also read metric value as object and pass it to the http server.

Author: Dong Lin <lindong28@gmail.com>

Reviewers: Manikumar Reddy O <manikumar.reddy@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5886 from lindong28/KAFKA-7560",2018-11-07 08:04:29,Dong Lin,Mixed
eb3335ef592a3dd22895a5bb499a2d0b232227a7,"KAFKA-7165: Retry the BrokerInfo registration into ZooKeeper (#5575)

* Add logic to retry the BrokerInfo registration into ZooKeeper

In case the ZooKeeper session has been regenerated and the broker
tries to register the BrokerInfo into Zookeeper, this code deletes
the current BrokerInfo from Zookeeper and creates it again, just if
the znode ephemeral owner belongs to the Broker which tries to register
himself again into ZooKeeper

* Add test to validate the BrokerInfo re-registration into ZooKeeper",2018-11-08 13:28:37,Jonathan Santilli,Mixed
ecb71cf4719e6d22d6738f8df2fd9e16dad33295,"KAFKA-7564: Expose single task details in Trogdor (#5852)

This commit adds a new ""/coordinator/tasks/{taskId}"" endpoint which fetches details for a single task.",2018-11-09 10:31:04,Stanislav Kozlovski,Mixed
af2e6fb548cf3b5778455a7b5791bbebe3b74b44,"MINOR: Update zstd, easymock, powermock, zkclient and build plugins (#5846)

EasyMock 4.0.x includes a change that relies on the caller for inferring
the return type of mock creator methods. Updated a number of Scala
tests for compilation and execution to succeed.

The versions of EasyMock and PowerMock in this PR include full support
for Java 11.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2018-11-10 13:58:18,Ismael Juma,Not TDD
3eaf44ba8ea26a7a820894390e8877d404ddd5a2,"KAFKA-7557: optimize LogManager.truncateFullyAndStartAt() (#5848)

Instead of calling deleteSnapshotsAfterRecoveryPointCheckpoint for allLogs, invoking it only for the logs being truncated.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",2018-11-12 09:02:44,huxi,Mixed
1c1e5ee97959d1841c9190deb0de2f18d55a4030,"KAFKA-7518: Fix FutureRecordMetadata.get when TimeUnit is not ms (#5815)

Also check for timeout before calling `nextRecordMetadata.get`. Added unit test
validating the fix.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-11-12 11:17:55,Andras Katona,Mixed
6c2e7005badf1bde8843c45017f93220fa4ca8e4,"MINOR: Remove unused IteratorTemplate (#5903)

There seems to be no reason to keep this around since it is not used outside
of testing and AbstractIterator is basically the same thing.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-11-12 13:42:29,Jason Gustafson,Mixed
12f310d50e7f5b1c18c4f61a119a6cd830da3bc0,"KAFKA-7612: Fix javac warnings and enable warnings as errors (#5900)

- Use Xlint:all with 3 exclusions (filed KAFKA-7613 to remove the exclusions)
- Use the same javac options when compiling tests (seems accidental that
we didn't do this before)
- Replaced several deprecated method calls with non-deprecated ones:
  - `KafkaConsumer.poll(long)` and `KafkaConsumer.close(long)`
  - `Class.newInstance` and `new Integer/Long` (deprecated since Java 9)
  - `scala.Console` (deprecated in Scala 2.11)
  - `PartitionData` taking a timestamp (one of them seemingly a bug)
  - `JsonMappingException` single parameter constructor
- Fix unnecessary usage of raw types in several places.
- Add @SuppressWarnings for deprecations, unchecked and switch fallthrough in
several places.
- Scala clean-ups (var -> val, ETA expansion warnings, avoid reflective calls)
- Use lambdas to simplify code in a few places
- Add @SafeVarargs, fix varargs usage and remove unnecessary `Utils.mkList` method

Reviewers: Matthias J. Sax <mjsax@apache.org>, Manikumar Reddy <manikumar.reddy@gmail.com>, Randall Hauch <rhauch@gmail.com>, Bill Bejeck <bill@confluent.io>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>",2018-11-12 22:18:59,Ismael Juma,Mixed
8259fda6953be6c87829af80eb85b1c63e86b65c,"KAFKA-7514: Add threads to ConsumeBenchWorker (#5864)

Add threads with separate consumers to ConsumeBenchWorker.  Update the Trogdor test scripts and documentation with the new functionality.

Reviewers: Colin McCabe <cmccabe@apache.org>",2018-11-13 08:38:42,Stanislav Kozlovski,Mixed
14d3ead19d250f2f3117af473ff6244c663ef8ca,"MINOR: Remove deprecated callers (#5911)

Callers of 1) Windows#until, 2) Windows#of, 3) Serialized are replaced when possible with the new APIs.

Reviewers: Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bill@confluent.io>",2018-11-14 17:29:19,Guozhang Wang,Mixed
d2f37944b6043ff443adbdf547d5bd335affbc1a,"KAFKA-7584: StreamsConfig throws ClassCastException if max.in.flight.request.per.connect is specified as String (#5874)

Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-11-15 13:26:58,Matthias J. Sax,Mixed
80eb2c28f6b8bef603b5281f94cb32f5dadbeb7d,"MINOR: improve Puncutation JavaDocs and add runtime argument check (#5895)

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-11-15 13:29:25,Matthias J. Sax,Mixed
1a4d44f2067ed8c575d5927fd8361bb99d42b23e,"KAFKA-7576; Fix shutdown of replica fetcher threads (#5875)

ReplicaFetcherThread.shutdown attempts to close the fetcher's Selector while the thread is running. This in unsafe and can result in `Selector.close()` failing with an exception. The exception is caught and logged at debug level, but this can lead to socket leak if the shutdown is due to dynamic config update rather than broker shutdown. This PR changes the shutdown logic to close Selector after the replica fetcher thread is shutdown, with a wakeup() and flag to terminate blocking sends first.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2018-11-15 17:27:29,Rajini Sivaram,Mixed
c3e7d6252c41d48e74379810595c978efada9efb,"KAFKA-6774; Improve the default group id behavior in KafkaConsumer (KIP-289) (#5877)

Improve the default group id behavior by:
* changing the default consumer group to null, where no offset commit or fetch, or group management operations are allowed
* deprecating the use of empty (`""""`) consumer group on the client

Reviewers: Jason Gustafson <jason@confluent.io>",2018-11-16 00:58:56,Vahid Hashemian,Mixed
8dc4d0e7872bad4cf7e5ebaf28229acc5667ae2d,"KAFKA-6567: Remove KStreamWindowReducer (#5922)

This pull request removes the final reference to KStreamWindowReducer and replaces it with KStreamWindowAggregate

Signed-off-by: Samuel Hawker sam.b.hawker@gmail.com

contribution is my original work and that I license the work to the project under the project's open source license.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-11-19 21:28:12,Samuel Hawker,Mixed
1d4ca5adf360224940984d20d819a85c94d95144,"KAFKA-7616; Make MockConsumer only add entries to the partition map returned by poll() if there are any records to return

…eturned by poll() if there are any records to return

The MockConsumer behaves unlike the real consumer in that it can return a non-empty ConsumerRecords from poll, that also has a count of 0. This change makes the MockConsumer only add partitions to the ConsumerRecords if there are records to return for those partitions.

A unit test in MockConsumerTest demonstrates the issue.

Author: Stig Rohde Døssing <stigdoessing@gmail.com>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #5901 from srdo/KAFKA-7616",2018-11-20 23:16:21,Stig Rohde Døssing,Mixed
46e7b136e22430340337d3540627a1d685dfa31e,"KAFKA-7536: Initialize TopologyTestDriver with non-null topic (#5923)

In TopologyTestDriver constructor set non-null topic; and in unit test intentionally turn on caching to verify this case.

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-11-20 14:39:12,Guozhang Wang,Not TDD
068ab9cefae301f3187ea885d645c425955e77d2,"KAFKA-7528: Standardize on Min/Avg/Max Kafka metrics' default value - NaN (#5908)

While metrics like Min, Avg and Max make sense to respective use Double.MAX_VALUE, 0.0 and Double.MIN_VALUE as default values to ease computation logic, exposing those values makes reading them a bit misleading. For instance, how would you differentiate whether your -avg metric has a value of 0 because it was given samples of 0 or no samples were fed to it?

It makes sense to standardize on the output of these metrics with something that clearly denotes that no values have been recorded.

Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-11-20 15:54:24,Stanislav Kozlovski,Not TDD
808dc0a96b3a8e6a6dbecb0473382b39a366d7a2,"MINOR: Update docs with out-dated context.schedule(...) examples (#5924)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",2018-11-21 09:48:01,cadonna,Not TDD
ad26914de65e2db244fbe36a2a5fd03de87dfb79,"KAFKA-7418: Add the missing '--help' option to Kafka commands (KIP-374)

Changes made as part of this [KIP-374](https://cwiki.apache.org/confluence/x/FgSQBQ) and [KAFKA-7418](https://issues.apache.org/jira/browse/KAFKA-7418)
 - Checking for empty args or help option in command file to print Usage
 - Added new class to enforce help option to all commands
 - Refactored few lines (ex `PreferredReplicaLeaderElectionCommand`) to
   make use of `CommandDefaultOptions` attributes.
 - Made the changes in help text wordings

Run the unit tests in local(Windows) few Linux friendly tests are failing but
not any functionality, verified `--help` and no option response by running
Scala classes, since those all are having `main` method.

Author: Srinivas Reddy <srinivas96alluri@gmail.com>
Author: Srinivas Reddy <mrsrinivas@users.noreply.github.com>
Author: Srinivas <srinivas96alluri@gmail.com>

Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Manikumar Reddy <manikumar.reddy@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Mickael Maison <mickael.maison@gmail.com>

Closes #5910 from mrsrinivas/KIP-374",2018-11-22 17:12:34,Srinivas Reddy,Not TDD
d0ed3894d6c586a580504c5141b3ae7de18f3518,"MINOR: Refactor code for restoring tasks (#5768)

Reviewers: Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",2018-11-23 12:32:37,Matthias J. Sax,Not TDD
7fadf0a11ddb2451adc66e1b179b84b050ad3f4f,"Trogdor: Add Task State filter to /coordinator/tasks endpoint (#5907)

Reviewers: Colin McCabe <cmccabe@apache.org>",2018-11-26 16:46:58,Stanislav Kozlovski,Mixed
9368743b8fd2b42a41b44860ea0f3588bb273cc8,"KAFKA-7597: Add transaction support to ProduceBenchWorker (#5885)

KAFKA-7597: Add configurable transaction support to ProduceBenchWorker.  In order to get support for serializing Optional<> types to JSON, add a new library: jackson-datatype-jdk8. Once Jackson 3 comes out, this library will not be needed.

Reviewers: Colin McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",2018-11-27 12:49:53,Stanislav Kozlovski,Mixed
55c77ebf01ea8662b98f73f6f6c17d05163a85b8,"KAFKA-7223: Suppression Buffer Metrics (#5795)

Add the final batch of metrics from KIP-328

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-11-27 12:57:04,John Roesler,Mixed
dfd545485ab0399e0c129ff2d68fbb3113f3e8c9,"MINOR: Add system test for optimization upgrades (#5912)

This is a new system test testing for optimizing an existing topology. This test takes the following steps

1. Start a Kafka Streams application that uses a selectKey then performs 3 groupByKey() operations and 1 join creating four repartition topics
2. Verify all instances start and process data
3. Stop all instances and verify stopped
4. For each stopped instance update the config for TOPOLOGY_OPTIMIZATION to all then restart the instance and verify the instance has started successfully also verifying Kafka Streams reduced the number of repartition topics from 4 to 1
5. Verify that each instance is processing data from the aggregation, reduce, and join operation
Stop all instances and verify the shut down is complete.
6. For testing I ran two passes of the system test with 25 repeats for a total of 50 test runs.

All test runs passed

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-11-27 13:07:34,Bill Bejeck,Not TDD
de24d4a459ccfac623e71722f8df8b1e99f2ad43,"KAFKA-7367: Streams should not create state store directories unless they are needed (#5696)

* KAFKA-7367: Ensure stateless topologies don't require disk access

* KAFKA-7367: Streams should not create state store directories unless they are needed.

* Addressed the review comments.

* Addressed the review-2 comments.

* Fixed FileAlreadyExistsException

* Addressed the review-3 comments.

* Resolved the conflicts.",2018-11-27 13:09:44,Kamal Chandraprakash,Mixed
a2e87feb8b1db8200ca3a34aa72b0802e8f61096,"KAFKA-7620: Fix restart logic for TTLs in WorkerConfigTransformer

The restart logic for TTLs in `WorkerConfigTransformer` was broken when trying to make it toggle-able.   Accessing the toggle through the `Herder` causes the same code to be called recursively.  This fix just accesses the toggle by simply looking in the properties map that is passed to `WorkerConfigTransformer`.

Author: Robert Yokota <rayokota@gmail.com>

Reviewers: Magesh Nandakumar <magesh.n.kumar@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5914 from rayokota/KAFKA-7620",2018-11-27 22:01:21,Robert Yokota,Mixed
c32b7e5a9f494dc4ef9c04bca6f73902269e1d49,"KAFKA-7037: Improve the topic command description of `--topic` option

Author: Vahid Hashemian <vahidhashemian@us.ibm.com>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #5193 from vahidhashemian/KAFKA-7037",2018-11-28 16:16:45,Vahid Hashemian,Mixed
2c305dc64c033ffcfd6e45548752f0702f373032,"KAFKA-7671: Stream-Global Table join should not reset repartition flag (#5959)

This PR fixes an issue reported from a user. When we join a KStream with a GlobalKTable we should not reset the repartition flag as the stream may have previously changed its key, and the resulting stream could be used in an aggregation operation or join with another stream which may require a repartition for correct results.

I've added a test which fails without the fix.

Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-11-28 18:15:26,Bill Bejeck,Mixed
fb9f2d8c9b296c44f42ae3838380895f95171133,"Forward topic from console consumer to deserializer (#5704)

Some deserializer needs the topic name to be able to correctly deserialize the payload of the message.
Console consumer works great with Deserializer<String> however it calls deserializer with topic set as null.
This breaks the API and the topic information is available in the ConsumerRecord.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>, Gardner Vickers <gardner@vickers.me>, Jun Rao <junrao@gmail.com>",2018-11-28 18:23:30,Mathieu Chataigner,Not TDD
bfbc32d9bc9e63c5e02840aeed4de157654dc5e8,"KAFKA-7660: fix parentSensors memory leak (#5953)

In StreamsMetricsImpl, the parentSensors map was keeping references to Sensors after the sensors themselves had been removed.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-11-29 15:09:50,John Roesler,Mixed
b7d95da88df3a521870fa4f6d6e53cee7e679d40,"KAFKA-7660: Fix child sensor memory leak (#5974)

A heap dump provided by Patrik Kleindl in https://issues.apache.org/jira/browse/KAFKA-7660 identifies the childrenSensors map in Metrics as keeping references to sensors alive after they have been removed.

This PR fixes it and adds a test to be sure.

Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-11-29 20:10:24,John Roesler,Mixed
944f24cfdc8edd2b4ef89ed40a55a480e8f89632,"KAFKA-7259; Remove deprecated ZKUtils usage from ZkSecurityMigrator

- Remove ZKUtils usage from various tests

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Sriharsha Chintalapani <sriharsha@apache.org>, Ismael Juma <ismael@juma.me.uk>, Satish Duggana <satishd@apache.org>, Jun Rao <junrao@gmail.com>, Ryanne Dolan <ryannedolan@gmail.com>

Closes #5480 from omkreddy/zkutils",2018-11-30 11:11:25,Manikumar Reddy,Mixed
ace4dd00566afb7d04235bbbcc50097191af0fec,"KAFKA-7551: Refactor to create producer & consumer in the worker

This is minor refactoring that brings in the creation of producer and consumer to the Worker. Currently, the consumer is created in the WorkerSinkTask. This should not affect any functionality and it just makes the code structure easier to understand.

Author: Magesh Nandakumar <magesh.n.kumar@gmail.com>

Reviewers: Ryanne Dolan <ryannedolan@gmail.com>, Randall Hauch <rhauch@gmail.com>, Robert Yokota <rayokota@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5842 from mageshn/KAFKA-7551",2018-11-29 23:38:50,Magesh Nandakumar,Mixed
e7ce0e7e0a82bb56b1106479c0c8a7984fd92604,"KAFKA-4544: Add system tests for delegation token based authentication

This change adds some basic system tests for delegation token based authentication:
- basic delegation token creation
- producing with a delegation token
- consuming with a delegation token
- expiring a delegation token
- producing with an expired delegation token

New files:
- delegation_tokens.py: a wrapper around kafka-delegation-tokens.sh  - executed in container where a secure Broker is running (taking advantage of automatic cleanup)
- delegation_tokens_test.py: basic test to validate the lifecycle of a delegation token

Changes were made in the following file to extend their functionality:
- config_property was updated to be able to configure Kafka brokers with delegation token related settings
- jaas.conf template because a broker needs to support multiple login modules when delegation tokens are used
- consule-consumer and verifiable_producer to override KAFKA_OPTS (to specify custom jaas.conf) and the client properties (to authenticate with delegation token).

Author: Attila Sasvari <asasvari@apache.org>

Reviewers: Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Andras Katona <41361962+akatona84@users.noreply.github.com>, Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #5660 from asasvari/KAFKA-4544",2018-12-03 11:28:36,Attila Sasvari,Mixed
2155c6d54b087206b6aa1d58747f141761394eaf,"KAFKA-7235: Detect outdated control requests and bounced brokers using broker generation (#5821)

* KAFKA-7235: Detect outdated control requests and bounced brokers using broker generation

* Add broker_epoch in controlled shutdown request

* Move broker epoch check into controller for ControlledShutdownRequest

* Refactor schema definition for controler requests/responses

* Address comments

* Address comments

* Address comments

* Send back STALE_BROKER_EPOCH error in ControlledShutdown response

* Fix build issue

* Address comments

* Address comments

* Address comments

* Address comments

* Fix tests after rebase

* Address comments

* Address comments",2018-12-02 22:00:51,Zhanxiang (Patrick) Huang,Mixed
ab1fb3fdde95be535b97eb1c8c21ef32896f891a,"MINOR: Adding system test for named repartition topics (#5913)

This is a system test for doing a rolling upgrade of a topology with a named repartition topic.

1. An initial Kafka Streams application is started on 3 nodes. The topology has one operation forcing a repartition and the repartition topic is explicitly named.
2. Each node is started and processing of data is validated
3. Then one node is stopped (full stop is verified)
4. A property is set signaling the node to add operations to the topology before the repartition node which forces a renumbering of all operators (except repartition node)
5. Restart the node and confirm processing records
6. Repeat the steps for the other 2 nodes completing the rolling upgrade

I ran two runs of the system test with 25 repeats in each run for a total of 50 test runs.
All test runs passed

Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2018-12-03 12:37:31,Bill Bejeck,Not TDD
437cf35373dbfa9d5c1ca44a8e2c0e363a0ffa7c,"KAFKA-7702: Fix matching of prefixed ACLs to match single char prefix (#5994)

Reviewers: Jun Rao <junrao@gmail.com>",2018-12-04 09:44:11,Rajini Sivaram,Mixed
f65b1c4796fdf34a883e0228f7b74a0fe36dd4a8,"KAFKA-7687; Print batch level information in DumpLogSegments when deep iterating (#5976)

DumpLogSegments should print batch level information when deep-iteration is specified.

Reviewers: Jason Gustafson <jason@confluent.io>",2018-12-04 09:04:39,huxi,Mixed
0d4cf64af359d22749f7e865c4efaee773d64962,"KAFKA-7697: Process DelayedFetch without holding leaderIsrUpdateLock (#5999)

Delayed fetch operations acquire leaderIsrUpdate read lock of one or more Partitions from the fetch request when attempting to complete the fetch operation. While appending new records, complete fetch requests after releasing leaderIsrUpdate of the Partition to which records were appended to avoid deadlocks in request handler threads.

Reviewers: Jason Gustafson <jason@confluent.io>, Jun Rao <junrao@gmail.com>",2018-12-05 09:05:26,Rajini Sivaram,Mixed
ec501f305e53a09072580fb3824048c170d32a48,"KAFKA-7420: Global store surrounded by read only implementation (#5865)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Kamal Chandraprakash (@kamalcph), Bill Bejeck <bill@confluent.io>",2018-12-05 11:25:52,Nikolay,Mixed
b616f913c8a57609476e5cf99b1802ef1dfe1c98,"KAFKA-7678: Avoid NPE when closing the RecordCollector (#5993)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",2018-12-05 11:48:39,Jonathan Santilli,Mixed
0ffdf8307f8c0822def6f97f69777337106fc347,"KAFKA-6388; Recover from rolling an empty segment that already exists (#5986)

There were several reported incidents where the log is rolled to a new segment with the same base offset as an active segment, causing KafkaException: Trying to roll a new log segment for topic partition X-N with start offset M while it already exists. In the cases we have seen, this happens to an empty log segment where there is long idle time before the next append and somehow we get to a state where offsetIndex.isFull() returns true due to _maxEntries == 0. This PR recovers from this state by deleting and recreating the segment and all of its associated index files.

Reviewers: Jason Gustafson <jason@confluent.io>",2018-12-05 14:49:19,Anna Povzner,Mixed
c05050346468cc27bcfb3a43bde90c47533a386c,"KAFKA-7709: Fix ConcurrentModificationException when retrieving expired inflight batches on multiple partitions. (#6005)

Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-12-06 16:55:01,Mark Cho,Mixed
edfa68173615cddaa421ef02ccf7b82ce4181c79,"MINOR: Catch NoRecordsException in testCommaSeparatedRegex() test (#5944)

This test sometimes fails with

```
kafka.tools.MirrorMaker$NoRecordsException
	at kafka.tools.MirrorMaker$ConsumerWrapper.receive(MirrorMaker.scala:483)
	at kafka.tools.MirrorMakerIntegrationTest$$anonfun$testCommaSeparatedRegex$1.apply$mcZ$sp(MirrorMakerIntegrationTest.scala:92)
	at kafka.utils.TestUtils$.waitUntilTrue(TestUtils.scala:738)
```

The test should catch `NoRecordsException` instead of `TimeoutException`.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2018-12-08 09:43:43,Stanislav Kozlovski,Not TDD
b49229675748afae584799e11a8b8f090c4218a9,"MINOR: fix checkpoint write failure warning log (#6008)

We saw a log statement in which the cause of the failure to write a checkpoint was not properly logged.
This change logs the exception properly and also verifies the log message.

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2018-12-08 19:00:57,John Roesler,Mixed
c0353d8ddce88bac6fc04f85dd40cb95b8ca5cf9,"KAFKA-6036: Local Materialization for Source KTable (#5779)

Refactor the materialization for source KTables in the way that:

If Materialized.as(queryableName) is specified, materialize;
If the downstream operator requires to fetch from this KTable via ValueGetters, materialize;
If the downstream operator requires to send old values, materialize.
Otherwise do not materialize the KTable. E.g. builder.table(""topic"").filter().toStream().to(""topic"") would not create any state stores.

There's a couple of minor changes along with PR as well:

KTableImpl's queryableStoreName and isQueryable are merged into queryableStoreName only, and if it is null it means not queryable. As long as it is not null, it should be queryable (i.e. internally generated names will not be used any more).
To achieve this, splitted MaterializedInternal.storeName() and MaterializedInternal.queryableName(). The former can be internally generated and will not be exposed to users. QueryableName can be modified to set to the internal store name if we decide to materialize it during the DSL parsing / physical topology generation phase. And only if queryableName is specified the corresponding KTable is determined to be materialized.

Found some overlapping unit tests among KTableImplTest, and KTableXXTest, removed them.

There are a few typing bugs found along the way, fixed them as well.

-----------------------

This PR is an illustration of experimenting a poc towards logical materializations.

Today we've logically materialized the KTable for filter / mapValues / transformValues if queryableName is not specified via Materialized, but whenever users specify queryableName we will still always materialize. My original goal is to also consider logically materialize for queryable stores, but when implementing it via a wrapped store to apply the transformations on the fly I realized it is tougher than I thought, because we not only need to support fetch or get, but also needs to support range queries, approximateNumEntries, and isOpen etc as well, which are not efficient to support. So in the end I'd suggest we still stick with the rule of always materializing if queryableName is specified, and only consider logical materialization otherwise.

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <mjsax@apache.org>",2018-12-08 22:49:48,Guozhang Wang,Mixed
7a3dffb0ca1f7ff2bd838f42ca2f12b7a2fc3b0e,"KAFKA-7549; Old ProduceRequest with zstd compression does not return error to client (#5925)

Older versions of the Produce API should return an error if zstd is used. This validation existed, but it was done during request parsing, which means that instead of returning an error code, the broker disconnected. This patch fixes the issue by moving the validation outside of the parsing logic. It also fixes several other record validations which had the same problem.

Reviewers: Jason Gustafson <jason@confluent.io>",2018-12-10 09:45:18,Lee Dongjin,Mixed
20069b390637813c289175327f08fe410fd0cb71,"KAFKA-7610; Proactively timeout new group members if rebalance is delayed (#5962)

When a consumer first joins a group, it doesn't have an assigned memberId. If the rebalance is delayed for some reason, the client may disconnect after a request timeout and retry. Since the client had not received its memberId, then we do not have a way to detect the retry and expire the previously generated member id. This can lead to unbounded growth in the size of the group until the rebalance has completed.

This patch fixes the problem by proactively completing all JoinGroup requests for new members after a timeout of 5 minutes. If the client is still around, we expect it to retry.

Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Boyang Chen <bchen11@outlook.com>, Guozhang Wang <wangguoz@gmail.com>",2018-12-10 14:32:29,Jason Gustafson,Mixed
a94c8da5083381d9ca4224b1489e1dc205bf55bb,"KAFKA-7443: OffsetOutOfRangeException in restoring state store from changelog topic when start offset of local checkpoint is smaller than that of changelog topic (#5946)

Reviewer: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>",2018-12-11 00:40:18,linyli001,Mixed
c142809038e67625638165462ceefd3f1191e0e9,"KAFKA-6970: All standard state stores guarded with read only wrapper (#6016)

Reviewer: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>",2018-12-11 01:44:18,Nikolay,Mixed
046b0087bd76637bbfd813ccef31693fa358ff2d,"MINOR: improve Streams checkstyle and code cleanup (#5954)

Reviewers: Guozhang Wang <guozhang@confluent.io>, Nikolay Izhikov <nIzhikov@gmail.com>, Ismael Juma <ismael@confluent.io>, Bill Bejeck <bill@confluent.io>",2018-12-11 01:54:41,Matthias J. Sax,Mixed
46e8081f9cae24f5edbfa2099e317a33e531d2fb,"KAFKA-7712; Remove channel from Selector before propagating exception (#6023)

Ensure that channel and selection keys are removed from `Selector` collections before propagating connect exceptions. They are currently cleared on the next `poll()`, but we can't ensure that callers (NetworkClient for example) wont try to connect again before the next `poll` and hence we should clear the collections before re-throwing exceptions from `connect()`.

Reviewers: Jason Gustafson <jason@confluent.io>",2018-12-12 10:50:56,Rajini Sivaram,Mixed
dffce6e7ae047a21fb40ec2c27d3d1f562a511a3,"KAFKA-7655 Metadata spamming requests from Kafka Streams under some circumstances, potential DOS (#5929)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2018-12-13 16:40:39,Pasquale Vazzana,Mixed
88443b4a3718a848188db9f5152c1077b15f1159,"Fix the missing ApiUtils tests in streams module. (#6003)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",2018-12-13 19:31:58,Srinivas Reddy,Mixed
152292994e45d5bedda0673c142f9406e70d5d3e,"KAFKA-2334; Guard against non-monotonic offsets in the client (#5991)

After a recent leader election, the leaders high-water mark might lag behind the offset at the beginning of the new epoch (as well as the previous leader's HW). This can lead to offsets going backwards from a client perspective, which is confusing and leads to strange behavior in some clients.

This change causes Partition#fetchOffsetForTimestamp to throw an exception to indicate the offsets are not yet available from the leader. For new clients, a new OFFSET_NOT_AVAILABLE error is added. For existing clients, a LEADER_NOT_AVAILABLE is thrown.

This is an implementation of [KIP-207](https://cwiki.apache.org/confluence/display/KAFKA/KIP-207%3A+Offsets+returned+by+ListOffsetsResponse+should+be+monotonically+increasing+even+during+a+partition+leader+change).

Reviewers: Colin Patrick McCabe <colin@cmccabe.xyz>, Dhruvil Shah <dhruvil@confluent.io>, Jason Gustafson <jason@confluent.io>",2018-12-14 13:53:03,David Arthur,Mixed
b23bf41e84d468185aa4165bf171b24735b8fecd,"KAFKA-7742; Fixed removing hmac entry for a token being removed from DelegationTokenCache

Author: Satish Duggana <satishd@apache.org>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #6037 from satishd/KAFKA-7742",2018-12-20 15:55:34,Satish Duggana,Not TDD
ee370d389350b5a6e8afa89a67995fa8b8dbde55,"KAFKA-7759; Disable WADL output in the Connect REST API (#6051)

This patch disables support for WADL output in the Connect REST API since it was never intended to be exposed. 

Reviewers: Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-12-20 14:24:05,Alex Diachenko,Mixed
85906d3d2ba49e593623de1484a9946224ce71cc,"MINOR: Switch anonymous classes to lambda expressions in tools module

Switch to lambda when ever possible instead of old anonymous way
in tools module

Author: Srinivas Reddy <srinivas96alluri@gmail.com>
Author: Srinivas Reddy <mrsrinivas@users.noreply.github.com>

Reviewers: Ryanne Dolan <ryannedolan@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #6013 from mrsrinivas/tools-switch-to-java8",2018-12-21 14:20:57,Srinivas Reddy,Mixed
55334453a561646b303e7de961e5990345effc15,"KAFKA-7054; Kafka describe command should throw topic doesn't exist exception

**User Interface Improvement :** If topic doesn't exist then Kafka describe command should throw topic doesn't exist exception, like alter and delete commands

Author: Manohar Vanam <manohar.crazy09@gmail.com>

Reviewers: Vahid Hashemian <vahid.hashemian@gmail.com>, Jason Gustafson <jason@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #5211 from ManoharVanam/KAFKA-7054",2018-12-21 14:48:22,Manohar Vanam,Mixed
964e2c57c2aead1638d0e7ddb614a08e4fd20d2f,"KAFKA-3832; Kafka Connect's JSON Converter never outputs a null value (#6027)

When using the Connect `JsonConverter`, it's impossible to produce tombstone messages, thus impacting the compaction of the topic. This patch allows the converter with and without schemas to output a NULL byte value in order to have a proper tombstone message. When it's regarding to get this data into a connect record, the approach is the same as when the payload looks like `""{ ""schema"": null, ""payload"": null }""`, this way the sink connectors can maintain their functionality and reduces the BCC.

Reviewers: Gunnar Morling <gunnar.morling@googlemail.com>, Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",2018-12-28 09:39:52,Renato Mefi,Mixed
6ea5474e4c073bec6cfa99bbb73ee547588b11ef,"KAFKA-7734: Metrics tags should use LinkedHashMap to guarantee ordering (#6032)

This pull request replaces HashMap with LinkedHashMap to guarantee ordering of metrics tags.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <guozhang@confluent.io>, John Roesler <vvcephei@users.noreply.github.com>",2019-01-03 17:14:26,lambdaliu,Mixed
eb9ca17a7ed6602c363fe1f77f5b98f2915f2c31,"KAFKA-7752: Add ""/kafka-acl-extended"" zk node path to secure root paths

- This commits sets ACL on /kafka-acl-extended
- Extended ZkAuthorizationTest to check ACL on /kafka-acl-extended
- Using zookeeper-security-migration.sh tool on a Kerberized test cluster, I verified the changes: secured and unsecured Kafka znodes and examined ACL on /kafka-acl-extended with zookeeper client

Author: Attila Sasvari <asasvari@apache.org>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Andras Katona <41361962+akatona84@users.noreply.github.com>

Closes #6072 from asasvari/KAFKA-7752",2019-01-04 16:15:40,Attila Sasvari,Not TDD
f8113c053b1266916ae3ce73385d4ed336ab2730,"KAFKA-7510: preventing data being leaked to logs by default (#5834)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bill Bejeck <bill@confluent.io>",2019-01-04 13:01:57,forficate,Mixed
b16afbb77bc1a497096815e64ed9e97df1edf92d,"KAFKA-6928: Refactor StreamsPartitionAssignor retry logic (#6085)

1. The retry loop of the InternalTopicManager would just be: a) describe topics, and exclude those which already exist with the right num.partitions, b) for the remaining topics, try to create them. Remove any inner loops.

2. In CreateTopicResponse and MetadataResponse (for describe topic), handle the special error code of TopicExist and UnknownTopicOrPartition in order to retry in the next loop.

3. Do not handle TimeoutException since it should already been handled inside AdminClient.

Add corresponding unit tests for a) topic marked for deletion but not complete yet, in which case metadata response would not contain this topic, but create topic would return error TopicExists; b) request keep getting timed out.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2019-01-04 10:49:08,Guozhang Wang,Mixed
329297ba3840df9cead731adf3448edebf6e37e2,"KAFKA-7110: Add windowed changelog serde (#5307)

Currently the TimeWindowedSerde does not deserialize the windowed keys from a changelog topic properly. There are a few assumptions made in the TimeWindowedDeserializer that prevents the changelog windowed keys from being correctly deserialized. This PR will introduce a new WindowSerde to allow proper deserialization of changelog windowed keys. 

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-01-04 11:42:33,Shawn Nguyen,Mixed
ef9204dc586038b97440485c81c218d438f22b9c,"MINOR: improve resilience of Streams test producers (#6028)

Some Streams system tests have failed during the setup phase
due to the producer having retries disabled and getting some
transient error from the broker.

This patch adds a retries parameter to the VerifiableProducer
(default unchanged), and sets retries to 10 for Streams tests.

It also sets acks equal to the number of brokers for Streams tests.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-01-04 13:44:15,John Roesler,Not TDD
d6698308194625e7921b9c3ace27a918f42f26f1,"KAFKA-7657: Fixing thread state change to instance state change (#6018)

While looking into KAFKA-7657, I found there are a few loopholes in this logic:

1. We kept a map of thread-name to thread-state and a global-thread state at the KafkaStreams instance-level, in addition to the instance state itself. stateLock is used when accessing the instance state, however when we are in the thread state change callback, we are accessing both the thread-states as well as the instance state at the same time in the callers of setState without a lock, which is vulnerable to concurrent multi-stream threads. The fix is a) introduce a threadStatesLock in addition to the stateLock, which should always be grabbed to modify the thread-states map before the stateLock for modifying the instance level; and we also defer the checking of the instance-level state inside the setState call.

2. When transiting to state.RUNNING, we check if all threads are either in RUNNING or DEAD state, this is because some threads maybe dead at the rebalance period but we should still proceed to RUNNING if the rest of threads are still transiting to RUNNING.

Added unit test for 2) above. Also simplified another test as a nit change.


Reviewers: John Roesler <vvcephei@users.noreply.github.com>, Matthias J. Sax <mjsax@apache.org>",2019-01-04 14:39:47,Guozhang Wang,Mixed
9d544212e69269f155bb3a51f94a9b13cf1fa565,"Revert ""KAFKA-7657: Fixing thread state change to instance state change (#6018)"" (#6090)

This reverts commit d6698308194625e7921b9c3ace27a918f42f26f1.",2019-01-04 14:41:15,Guozhang Wang,Mixed
8e4799b017c6a3c65eaf47f60ab136654c9741de,"K7657 handling thread dead state change (#6091)

While looking into KAFKA-7657, I found there are a few loopholes in this logic:

We kept a map of thread-name to thread-state and a global-thread state at the KafkaStreams instance-level, in addition to the instance state itself. stateLock is used when accessing the instance state, however when we are in the thread state change callback, we are accessing both the thread-states as well as the instance state at the same time in the callers of setState without a lock, which is vulnerable to concurrent multi-stream threads. The fix is a) introduce a threadStatesLock in addition to the stateLock, which should always be grabbed to modify the thread-states map before the stateLock for modifying the instance level; and we also defer the checking of the instance-level state inside the setState call.

When transiting to state.RUNNING, we check if all threads are either in RUNNING or DEAD state, this is because some threads maybe dead at the rebalance period but we should still proceed to RUNNING if the rest of threads are still transiting to RUNNING.

Added unit test for 2) above. Also simplified another test as a nit change.

Reviewers: John Roesler <vvcephei@users.noreply.github.com>, Matthias J. Sax <mjsax@apache.org>",2019-01-04 21:27:50,Guozhang Wang,Mixed
404bdef08db8c88f1b7a921737279feabfd0cb1f,"MINOR: Remove sleep calls and ignore annotation from streams upgrade test (#6046)

The StreamsUpgradeTest::test_upgrade_downgrade_brokers used sleep calls in the test which led to flaky test performance and as a result, we placed an @ignore annotation on the test. This PR uses log events instead of the sleep calls hence we can now remove the @ignore setting.

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-01-06 23:03:54,Bill Bejeck,Not TDD
e4f233ed33ffa5076becbd5458520eb2945263ca,"KAFKA-7755; Look up client host name since DNS entry may have changed (#6049)

Lookup client host name after every full iteration through the addresses returned.

Reviewers: Loïc Monney <loicmonney@github.com>, Edoardo Comar <ecomar@uk.ibm.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2019-01-07 13:33:58,hackerwin7,Not TDD
f9a22f42a842b2d80ac687567ae04e91dadebefe,"KAFKA-7773; Add end to end system test relying on verifiable consumer (#6070)

This commit creates an EndToEndTest base class which relies on the verifiable consumer. This will ultimately replace ProduceConsumeValidateTest which depends on the console consumer. The advantage is that the verifiable consumer exposes more information to use for validation. It also allows for a nicer shutdown pattern. Rather than relying on the console consumer idle timeout, which requires a minimum wait time, we can halt consumption after we have reached the last acked offsets. This should be more reliable and faster. The downside is that the verifiable consumer only works with the new consumer, so we cannot yet convert the upgrade tests. This commit converts only the replication tests and a flaky security test to use EndToEndTest.",2019-01-08 14:14:51,Jason Gustafson,Not TDD
3991d81f6c645bdf36c58e3d56b829ff92dbff3a,"MINOR: code cleanup (#6056)

Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-01-08 22:32:53,Matthias J. Sax,Not TDD
e32567699451e2fb0ccd63dd8a3df582cfd18d61,"KAFKA-6833; Producer should await metadata for unknown partitions (#6073)

This patch changes the behavior of KafkaProducer.waitOnMetadata to wait up to max.block.ms when the partition specified in the produce request is out of the range of partitions present in the metadata. This improves the user experience in the case when partitions are added to a topic and a client attempts to produce to one of the new partitions before the metadata has propagated to the brokers. Tested with unit tests.

Reviewers: Arjun Satish <arjun@confluent.io>, Jason Gustafson <jason@confluent.io>",2019-01-08 18:05:13,Bob Barrett,Mixed
1c7bf4e4976e2b58826f68f1abe8ffc9fd41692c,"MINOR: code cleanup (#6053)

Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Ryanne Dolan <ryannedolan@gmail.com>, Guozhang Wang <guozhang@confluent.io>",2019-01-09 18:03:16,Matthias J. Sax,Not TDD
b2b79c4f0ef33035ecdb486a6526a2cf20d77385,"KAFKA-7786; Ignore OffsetsForLeaderEpoch response if epoch changed while request in flight (#6101)

There is a race condition in ReplicaFetcherThread, where we can update PartitionFetchState with the new leader epoch (same leader) before handling the OffsetsForLeaderEpoch response with FENCED_LEADER_EPOCH error which causes removing partition from partitionStates, which in turn causes no fetching until the next LeaderAndIsr. 

This patch adds logic to ensure that the leader epoch doesn't change while an OffsetsForLeaderEpoch request is in flight (which could happen with back-to-back leader elections). If it has changed, we ignore the response.

Also added toString() implementation to PartitionData, because some log messages did not show useful info which I found while investigating the above system test failure.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2019-01-09 11:09:48,Anna Povzner,Mixed
b1b792d9a81530fb872176c8d30e5b473f59e12f,"MINOR: Add 2.1 version metadata upgrade (#6111)

Updated the test_metadata_upgrade test. To enable using the 2.1 version I needed to add config change to the StreamsUpgradeTestJobRunnerService to ensure the ductape passes proper args when starting the StreamsUpgradeTest

For testing, I ran the test_metadata_upgrade test and all versions now pass http://confluent-kafka-branch-builder-system-test-results.s3-us-west-2.amazonaws.com/2019-01-09--001.1547049873--bbejeck--MINOR_add_2_1_version_metadata_upgrade--a450c68/report.html

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-01-09 15:19:00,Bill Bejeck,Not TDD
c238af29bf50cade5aa10c1bb2678ad01cfbbf47,"MINOR: Remove throwing exception if not found from describe topics (#6112)

We recently improved the handling of the InternalTopicManager retries with #6085. The AdminClient will throw an InvalidTopicException if the topic is not found. We need to ignore that exception as when calling AdminClient#describe we may not have had a chance to create the topic yet, especially with the case of internal topics

I've created a new test asserting that when an InvalidTopicException is thrown when the topic is not found we continue on.

Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-01-10 10:03:11,Bill Bejeck,Mixed
694da1ac1e77c5b9aafe990def2238e521c0fa1f,"KAFKA-6627: Prevent config default values overriding ones specified through --producer-property on command line. (#6084)

* KAFKA-6627: Prevent config default values overriding ones specified through --producer-property on command line.

In Console{Producer,Consumer}, extraProducerProps (options specified in
--producer-property) is applied first, then overriden unconditionally,
even if the value is not specified explicitly (and default value is
used). This patch fixes it so that it doesn't override the existing
value set by --producer-property if it is not explicitly specified.

The contribution is my original work and I license the work to the
project under the project's open source license.

Reviewers: Sriharsha Chintalapani <sriharsha@apache.org>",2019-01-11 10:29:10,Kan Li,Mixed
625e0d882944f74568464037c3a8aafb585079f2,"KAFKA-7790: Fix Bugs in Trogdor Task Expiration (#6103)

The Trogdor Coordinator now overwrites a task's startMs to the time it received it if startMs is in the past.

The Trogdor Agent now correctly expires a task after the expiry time (startMs + durationMs) passes. Previously, it would ignore startMs and expire after durationMs milliseconds of local start of the task.

Reviewed-by: Colin P. McCabe <cmccabe@apache.org>",2019-01-11 13:38:00,Stanislav Kozlovski,Not TDD
71e85f5e842687c040f9ee69b9073fc285113541,"KAFKA-7609; Add Protocol Generator for Kafka (#5893)

This patch adds a framework to automatically generate the request/response classes for Kafka's protocol. The code will be updated to use the generated classes in follow-up patches. Below is a brief summary of the included components:

**buildSrc/src**
The message generator code is here.  This code is automatically re-run by gradle when one of the schema files changes.  The entire directory is processed at once to minimize the number of times we have to start a new JVM.  We use Jackson to translate the JSON files into Java objects.

**clients/src/main/java/org/apache/kafka/common/protocol/Message.java**
This is the interface implemented by all automatically generated messages.

**clients/src/main/java/org/apache/kafka/common/protocol/MessageUtil.java**
Some utility functions used by the generated message code.

**clients/src/main/java/org/apache/kafka/common/protocol/Readable.java, Writable.java, ByteBufferAccessor.java**
The generated message code uses these classes for writing to a buffer.

**clients/src/main/message/README.md**
This README file explains how the JSON schemas work.

**clients/src/main/message/\*.json**
The JSON files in this directory implement every supported version of every Kafka API.  The unit tests automatically validate that the generated schemas match the hand-written schemas in our code.  Additionally, there are some things like request and response headers that have schemas here.

**clients/src/main/java/org/apache/kafka/common/utils/ImplicitLinkedHashSet.java**
I added an optimization here for empty sets.  This is useful here because I want all messages to start with empty sets by default prior to being loaded with data.  This is similar to the ""empty list"" optimizations in the `java.util.ArrayList` class.

Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Ismael Juma <ismael@juma.me.uk>, Bob Barrett <bob.barrett@outlook.com>, Jason Gustafson <jason@confluent.io>",2019-01-11 16:40:21,Colin Patrick McCabe,Mixed
8afce0e338e3715824e309f6289af6bc607ce020,"KAFKA-4453 : Added code to separate controller connections and requests from the data plane (#5921)

KIP-291 Implementation : Added code to separate controller connections and requests from the data plane.

Tested with local deployment that the controller request are handled by the control plane and other requests are handled by the data plane.
Also added unit tests in order to test the functionality.

Author: Lucas Wang <luwang@linkedin.com>, 
Author: Mayuresh Gharat <gharatmayuresh15@gmail.com>

Reviewers: Joel Koshy <jjkoshy@gmail.com>, Jun Rao <junrao@gmail.com>",2019-01-13 10:17:52,Mayuresh Gharat,Mixed
82d1db635826246570287cfb4c0b3572e3b011b4,"MINOR: code cleanup (#6054)

Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Ryanne Dolan <ryannedolan@gmail.com>, Ismael Juma <ismael@confuent.io>",2019-01-14 13:36:36,Matthias J. Sax,Not TDD
69d8d2ea11c5e08884ab4c7b8079af5fd21247be,"KAFKA-7503: Connect integration test harness

Expose a programmatic way to bring up a Kafka and Zk cluster through Java API to facilitate integration tests for framework level changes in Kafka Connect. The Kafka classes would be similar to KafkaEmbedded in streams. The new classes would reuse the kafka.server.KafkaServer classes from :core, and provide a simple interface to bring up brokers in integration tests.

Signed-off-by: Arjun Satish <arjunconfluent.io>

Author: Arjun Satish <arjun@confluent.io>
Author: Arjun Satish <wicknicks@users.noreply.github.com>

Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #5516 from wicknicks/connect-integration-test",2019-01-14 13:50:23,Arjun Satish,Mixed
aca52b6d2c1381646f211978735be59c0a7de1fd,"KAFKA-7461: Add tests for logical types

Added testing of logical types for Kafka Connect in support of KIP-145 features.
Added tests for Boolean, Time, Date and Timestamp, including the valid conversions.

The area of ISO8601 strings is a bit of a mess because the tokenizer is not compatible with
that format, and a subsequent JIRA will be needed to fix that.

A few small fixes as well as creating test cases, but they're clearly just corrections such as
using 0 to mean January (java.util.Calendar uses zero-based month numbers).

Author: Andrew Schofield <andrew_schofield@uk.ibm.com>

Reviewers: Mickael Maison <mimaison@users.noreply.github.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #6077 from AndrewJSchofield/KAFKA-7461-ConverterValuesLogicalTypesTest",2019-01-14 15:41:23,Andrew Schofield,Mixed
13f679013aaa93198d30df8dada4aba5614790ea,"MINOR: Update Trogdor StringExpander regex to handle an epilogue (#6123)

Update the Trogdor StringExpander regex to handle an epilogue.  Previously the regex would use a lazy quantifier at the end, which meant it would not catch anything after the range expression.  Add a unit test.

Reviewed-by: Colin P. McCabe <cmccabe@apache.org>",2019-01-14 20:49:24,Stanislav Kozlovski,Mixed
af634a4a98eaa2457752e3f2841720020e0e9ad0,"KAFKA-7391; Introduce close(Duration) to Producer and AdminClient instead of close(long, TimeUnit) (#5667)

See KIP-367: https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=89070496.

Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-01-15 08:48:32,Chia-Ping Tsai,Mixed
2e53fa08af6aba8200f4c7846a8e8e568b56560d,"KAFKA-7792: Add simple /agent/uptime and /coordinator/uptime health check endpoints (#6130)

Reviewed-by: Colin P. McCabe <cmccabe@apache.org>",2019-01-15 11:52:48,Stanislav Kozlovski,Mixed
9a9310d074ead70ebf3e93d29d880e094b9080f6,"KAFKA-7824; Require member.id for initial join group request [KIP-394] (#6058)

This patch implements KIP-394 as documented in https://cwiki.apache.org/confluence/display/KAFKA/KIP-394%3A+Require+member.id+for+initial+join+group+request.

Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",2019-01-15 13:26:04,Boyang Chen,Mixed
2c44e77e2f2056ee88b4b9cc8bac1f769748830a,"KAFKA-7738; Track leader epochs in client Metadata (#6045)

Track the last seen partition epoch in the Metadata class. When handling metadata updates, check that the partition info being received is for the last seen epoch or a newer one. This prevents stale metadata from being loaded into the client.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-01-17 10:14:41,David Arthur,Mixed
56139df84495a67d311b160045497ec26f60c3a9,"KAFKA-7652: Part I; Fix SessionStore's findSession(single-key) (#6134)

Let findSessions(final K key) to call on underlying bytes store directly, using the more restricted range.

Fix the conservative upper range for multi-key range in session schema.

Minor: removed unnecessary private WrappedSessionStoreBytesIterator class as it is only used in unit test.

Minor: removed unnecessary schema#init function by using the direct bytes-to-binary function.

Please read the original PR for more detailed explanation of the root cause of the bug.


Reviewers: Bill Bejeck <bill@confluent.io>, Damian Guy <damian@confluent.io>, John Roesler <john@confluent.io>",2019-01-18 12:08:14,Guozhang Wang,Mixed
e19eb3e290cb7b7d2dc434b02648fe5c5726bdc2,"KAFKA-6455: Extend CacheFlushListener to forward timestamp (#6147)

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-01-19 09:39:57,Matthias J. Sax,Mixed
ed7b67dd1135e213ed7eda8ee2d733de7c965519,"KAFKA-3522: Add internal RecordConverter interface (#6150)

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-01-19 22:54:26,Matthias J. Sax,Mixed
e87e3f2cb286add0c315069b3b2a13c31d65043e,"MINOR: Remove unused imports, exceptions, and values (#6117)

1. Remove unthrown exceptions from MemoryRecordsBuilderTest
2. Remove unused imports from ReplicaFetcherThread, ZooKeeperClient, ApiVersionTest, PartitionTest
3. Remove unused value from PartitionTest",2019-01-20 13:25:35,Lee Dongjin,Not TDD
dc935c4beb49a83497536902f96c19fb7f472d41,"MINOR: Handle case where connector status endpoints returns 404 (#6176)

Reviewers: Randall Hauch <randall@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2019-01-20 19:31:20,Arjun Satish,Not TDD
e75e4732c9ad67a5bf7a267346f0774c2a41b4e9,"MINOR: Rejoin split ssl principal mapping rules (#6099)

* Join ssl principal mapping rules correctly before evaluating.

Java properties splits the configuration array on commas, and that leads to rules containing commas being split before being evaluated. This commit adds a code change to re-join those strings into full rules before evaluating them. The function assumes every rule is either DEFAULT or begins with the prefix RULE:",2019-01-21 12:01:36,ryannatesmith,Mixed
fb0db7602abfd54137677d582a7781e4f790d7f9,"KAFKA-7844: Use regular subproject for generator to fix *All targets (#6182)

The presence of the buildSrc subproject is causing problems when we try
to run installAll, jarAll, and the other ""all"" targets. It's easier
just to make the generator code a regular subproject and use the
JavaExec gradle task to run the code. This also makes it more
straightforward to run the generator unit tests.

Reviewers: David Arthur <mumrah@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Co-authored-by: Colin P. Mccabe <cmccabe@confluent.io>
Co-authored-by: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>",2019-01-21 21:06:37,Stanislav Kozlovski,Mixed
523465b3c17fc2ef67b0de10c78f83aae56606ae,"MINOR: Cleanup handling of mixed transactional/idempotent records (#6172)

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>, Colin Patrick McCabe <colin@cmccabe.xyz>",2019-01-22 08:35:14,Jason Gustafson,Mixed
743607af5aa625a19377688709870b021014dee2,"KAFKA-5117: Stop resolving externalized configs in Connect REST API

[KIP-297](https://cwiki.apache.org/confluence/display/KAFKA/KIP-297%3A+Externalizing+Secrets+for+Connect+Configurations#KIP-297:ExternalizingSecretsforConnectConfigurations-PublicInterfaces) introduced the `ConfigProvider` mechanism, which was primarily intended for externalizing secrets provided in connector configurations. However, when querying the Connect REST API for the configuration of a connector or its tasks, those secrets are still exposed. The changes here prevent the Connect REST API from ever exposing resolved configurations in order to address that. rhauch has given a more thorough writeup of the thinking behind this in [KAFKA-5117](https://issues.apache.org/jira/browse/KAFKA-5117)

Tested and verified manually. If these changes are approved unit tests can be added to prevent a regression.

Author: Chris Egerton <chrise@confluent.io>

Reviewers: Robert Yokota <rayokota@gmail.com>, Randall Hauch <rhauch@gmail.com, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #6129 from C0urante/hide-provided-connect-configs",2019-01-23 11:00:23,Chris Egerton,Mixed
0efed12f50f683131b31d33d787e2141122a5c11,"KAFKA-4850: Enable bloomfilters (#6012)

This PR enables BloomFilters for RocksDB to speed up point lookups.
The request for this has been around for some time - https://issues.apache.org/jira/browse/KAFKA-4850

For testing, I've done the following

Ran the standard streams suite of unit and integration tests
Kicked off the simple benchmark test with bloom filters enabled
Kicked off the simple benchmark test with bloom filters not enabled
Kicked off streams system tests

Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, John Roesler <john@confluent.io>",2019-01-23 16:00:26,Bill Bejeck,Mixed
a79d6dcdb687b1df911af024946880a5d9d5490a,"KAFKA-7793: Improve the Trogdor command line. (#6133)

* Allow the Trogdor agent to be started in ""exec mode"", where it simply
runs a single task and exits after it is complete.

* For AgentClient and CoordinatorClient, allow the user to pass the path
to a file containing JSON, instead of specifying the JSON object in the
command-line text itself.  This means that we can get rid of the bash
scripts whose only function was to load task specs into a bash string
and run a Trogdor command.

* Print dates and times in a human-readable way, rather than as numbers
of milliseconds.

* When listing tasks or workers, output human-readable tables of
information.

* Allow the user to filter on task ID name, task ID pattern, or task
state.

* Support a --json flag to provide raw JSON output if desired.

Reviewed-by: David Arthur <mumrah@gmail.com>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>",2019-01-24 09:26:51,Colin Patrick McCabe,Mixed
e4b54a5d97373368e601f47a74f9355b0a8dfbb1,"KAFKA-7692; Fix ProducerStateManager SequenceNumber overflow (#5990)

This patch fixes a few overflow issues with wrapping sequence numbers in the broker's producer state tracking. 

Reviewers: Jason Gustafson <jason@confluent.io>",2019-01-24 16:28:01,mingaliu,Mixed
0f926f0c1ee51f0db7649e63136310a29237ec84,"KAFKA-7693; Fix SequenceNumber overflow in producer (#5989)

The problem is that the sequence number is an Int and should wrap around when it reaches the Int.MaxValue. The bug here is it doesn't wrap around and become negative and raises an error.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-01-24 16:45:08,mingaliu,Mixed
a65940cd820c68ee9613c7ff54676560cd01f88a,"MINOR: clarify why suppress can sometimes drop tombstones (#6195)

Reviewers: Jonathan Gordon, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-01-25 13:17:39,John Roesler,Mixed
269b65279c746bc54c611141a5a6509f9b310f11,"KAFKA-5692: Change PreferredReplicaLeaderElectionCommand to use Admin… (#3848)

See also KIP-183.

This implements the following algorithm:

AdminClient sends ElectPreferredLeadersRequest.
KafakApis receives ElectPreferredLeadersRequest and delegates to
ReplicaManager.electPreferredLeaders()
ReplicaManager delegates to KafkaController.electPreferredLeaders()
KafkaController adds a PreferredReplicaLeaderElection to the EventManager,
ReplicaManager.electPreferredLeaders()'s callback uses the
delayedElectPreferredReplicasPurgatory to wait for the results of the
election to appear in the metadata cache. If there are no results
because of errors, or because the preferred leaders are already leading
the partitions then a response is returned immediately.
In the EventManager work thread the preferred leader is elected as follows:

The EventManager runs PreferredReplicaLeaderElection.process()
process() calls KafkaController.onPreferredReplicaElectionWithResults()
KafkaController.onPreferredReplicaElectionWithResults()
calls the PartitionStateMachine.handleStateChangesWithResults() to
perform the election (asynchronously the PSM will send LeaderAndIsrRequest
to the new and old leaders and UpdateMetadataRequest to all brokers)
then invokes the callback.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Jun Rao <junrao@gmail.com>",2019-01-25 14:06:18,Tom Bentley,Mixed
ef62dd3ef2f88d990bff21e3ff825c992e65fa10,"KAFKA-3522: Generalize Segments (#6170)

Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-01-25 23:56:39,Matthias J. Sax,Mixed
aca027e96cff818177e52196f676a9d3a2a980b4,"KAFKA-4217: Add KStream.flatTransform (#5273)

Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-01-26 21:38:19,cadonna,Mixed
201022d19eac50a4bce8ccfa12c8e233f2b5cad6,"KAFKA-3522: Replace RecordConverter with TimestampedBytesStore (#6204)

Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-01-30 15:57:56,Matthias J. Sax,Mixed
73565b7f679c281f83a5df11e662b0f27cb1e55d,"KAFKA-3522: Add RocksDBTimestampedStore (#6149)

Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-01-30 16:13:19,Matthias J. Sax,Mixed
9d5893d3d5c548ffbc11b8aa880f5a280892e47a,"KAFKA-7652: Part II; Add single-point query for SessionStore and use for flushing / getter (#6161)

#2972 tried to fix a bug about flushing operation, but it was not complete, since findSessions(key, earliestEnd, latestStart) does not guarantee to only return a single entry since its semantics are to return any sessions whose end > earliestEnd and whose start < latestStart.

I've tried various ways to fix it completely and I ended up having to add a single-point query to the public ReadOnlySessionStore API for the exact needed semantics. It is used for flushing to read the old values (otherwise the wrong old values will be sent downstreams, hence it is a correctness issue) and also for getting the value for value-getters (it is for perf only).",2019-01-30 17:31:31,Guozhang Wang,Mixed
dc634f18f7ea2ef24d202d6a2380365754005b60,"KAFKA-7859: Use automatic RPC generation in LeaveGroups (#6188)

Reviewed-by: Colin P. McCabe <cmccabe@apache.org>",2019-01-31 10:25:18,Boyang Chen,Not TDD
4b29487fa9d3d4ff8adaaaa6204db796eccd3a68,"KAFKA-7719: Improve fairness in SocketServer processors (KIP-402) (#6022)

Limit the number of new connections processed in each iteration of each
Processor. Block Acceptor if the connection queue is full on all Processors.
Added a metric to track accept blocked time percent. See KIP-402 for details.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2019-02-01 06:02:25,Rajini Sivaram,Mixed
1f85e8e9235141e1cc5c752c19740e769e03e034,"KAFKA-7433; Introduce broker options in TopicCommand to use AdminClient (KIP-377)

The PR adds --bootstrap-server and --admin.config options to TopicCommand and implements an alternative, AdminClient based way of topic management.

As testing I've duplicated the existing tests and made them working with the AdminClient options.

Author: Viktor Somogyi-Vass <viktorsomogyi@gmail.com>

Reviewers: Andras Katona <41361962+akatona84@users.noreply.github.com>, Sandor Murakozi <smurakozi@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #5683 from viktorsomogyi/topiccommand-adminclient",2019-02-01 14:24:12,Viktor Somogyi-Vass,Mixed
4420d9ec67fcd437cf55b4ca70a0180615215c8a,"KAFKA-7641; Introduce ""group.max.size"" config to limit group sizes (#6163)

This patch introduces a new config - ""group.max.size"", which caps the maximum size any group can reach. It has a default value of Int.MAX_VALUE. Once a group is of the maximum size, subsequent JoinGroup requests receive a MAX_SIZE_REACHED error.

In the case where the config is changed and a Coordinator broker with the new config loads an old group that is over the threshold, members are kicked out of the group and a rebalance is forced.

Reviewers: Vahid Hashemian <vahid.hashemian@gmail.com>, Boyang Chen <bchen11@outlook.com>, Gwen Shapira <cshapi@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-02-01 19:56:39,Stanislav Kozlovski,Mixed
9dc76f8872b862ca008562cdcf8cf50524e2eaa3,"KAFKA-7798: Expose embedded clientIds (#6107)

Reviewers: Damian Guy <damian@confluent.io>, John Roesler <john@confluent.io>, Boyang Chen <bchen11@outlook.com>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",2019-02-01 21:29:00,Guozhang Wang,Mixed
e2e8bdbd8cb6ca2ac962c72147d21a9e8b9ba2c0,"KAFKA-7832: Use automatic RPC generation in CreateTopics (#5972)

Reviewers: Jun Rao <junrao@gmail.com>, Tom Bentley <tbentley@redhat.com>, Boyang Chen <bchen11@outlook.com>",2019-02-04 10:39:43,Colin Patrick McCabe,Mixed
7debda4d41e7c951fe54b8b916d4b87cc7843348,KAFKA-7890: Invalidate ClusterConnectionState cache for a broker if the hostname of the broker changes. (#6215),2019-02-05 12:29:54,Mark Cho,Not TDD
4be68c58da6bbd16cb5682dbf1c9b5b1c93500a7,"KAFKA-7828: Add ExternalCommandWorker to Trogdor (#6219)

Allow the Trogdor agent to execute external commands. The agent communicates with the external commands via stdin, stdout, and stderr.

Based on a patch by Xi Yang <xi@confluent.io>

Reviewers: David Arthur <mumrah@gmail.com>",2019-02-06 16:42:02,Colin Patrick McCabe,Mixed
9f7e6b291309286e3e3c1610e98d978773c9d504,"KAFKA-7902: Replace original loginContext if SASL/OAUTHBEARER refresh login fails (#6233)

Replaces original loginContext if login fails in the refresh thread to ensure that the refresh thread is left in a clean state when there are exceptions while connecting to an OAuth server. Also makes client callback handler more robust by using the token with the longest remaining time for expiry instead of throwing an exception if multiple tokens are found.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2019-02-07 18:06:01,Ron Dagostino,Mixed
d152989f26f51b9004b881397db818ad6eaf0392,"KAFKA-7897; Disable leader epoch cache when older message formats are used (#6232)

When an older message format is in use, we should disable the leader epoch cache so that we resort to truncation by high watermark. Previously we updated the cache for all versions when a broker became leader for a partition. This can cause large and unnecessary truncations after leader changes because we relied on the presence of _any_ cached epoch in order to tell whether to use the improved truncation logic possible with the OffsetsForLeaderEpoch API.

Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>, Jun Rao <junrao@gmail.com>",2019-02-08 09:22:13,Jason Gustafson,Mixed
5148d7b0ae1ff4ac5f8c500d345045c050b47f88,"KAFKA-7915: Don't return sensitive authentication errors to clients (#6252)

Don't return error messages from `SaslException` to clients. Error messages to be returned to clients to aid debugging must be thrown as AuthenticationExceptions. This is a fix for a regression from KAFKA-7352.

Reviewers: Ron Dagostino <rndgstn@gmail.com>, Ismael Juma <ismael@juma.me.uk",2019-02-11 22:23:54,Rajini Sivaram,Not TDD
3fb1d70b6b2dbb78aafe60bae081237980fcd326,"KAFKA-7236: Add --under-min-isr option to describe topics command (KIP-351) (#6224)

* KAFKA-7236: Add --under-min-isr option to describe topics command (KIP-351)

* Minor changes to description and make test consistent with others

* Fix option, and add additional test with mixed partition status

* Add fully-replicated-topic to test case

* Address review nits",2019-02-11 14:39:02,Kevin Lu,Not TDD
08036fa4b1e5b8227fef78c5693897f19bb80de9,"KAFKA-7896; Add sasl.jaas.config/sasl.mechanism props to the log4j kafka appender

This patch adds 2 props to the log4j kafka appender that get put directly
into the sasl properties passed to the producer:
    - ClientJaasConf: This property sets sasl.jaas.config
    - SaslMechanim: This property sets sasl.mechanism

Author: Rohan Desai <desai.p.rohan@gmail.com>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #6216 from rodesai/add-kafka-appender-security-props",2019-02-12 09:33:30,Rohan Desai,Mixed
c7f99bc2bd9af5eb6ca9e20a02d5806c52d434b3,"MINOR: Update JUnit to 4.13 and annotate log cleaner integration test (#6248)

JUnit 4.13 fixes the issue where `Category` and `Parameterized` annotations
could not be used together. It also deprecates `ExpectedException` and
`assertThat`. Given this, we:

- Replace `ExpectedException` with the newly introduced `assertThrows`.
- Replace `Assert.assertThat` with `MatcherAssert.assertThat`.
- Annotate `AbstractLogCleanerIntegrationTest` with `IntegrationTest` category.

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, David Arthur <mumrah@gmail.com>",2019-02-11 22:06:14,Ismael Juma,Not TDD
637355138a426eb678b2cc9348ac07f970f20764,"MINOR: Improve PlainSaslServer error message for empty tokens (#6249)

Empty username or password would result in the ""expected 3 tokens""
error instead of ""username not specified"" or ""password not specified"".

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2019-02-12 11:58:26,Ismael Juma,Mixed
ec42e0378e7c66b8ceadc480bca6f98ad1df0643,"KAFKA-7799; Use httpcomponents-client in RestServerTest.

The test `org.apache.kafka.connect.runtime.rest.RestServerTest#testCORSEnabled` assumes Jersey client can send restricted HTTP headers(`Origin`).

Jersey client uses `sun.net.www.protocol.http.HttpURLConnection`.
`sun.net.www.protocol.http.HttpURLConnection` drops restricted headers(`Host`, `Keep-Alive`, `Origin`, etc) based on static property `allowRestrictedHeaders`.
This property is initialized in a static block by reading Java system property `sun.net.http.allowRestrictedHeaders`.

So, if classloader loads `HttpURLConnection` before we set `sun.net.http.allowRestrictedHeaders=true`, then all subsequent changes of this system property won't take any effect(which happens if `org.apache.kafka.connect.integration.ExampleConnectIntegrationTest` is executed before `RestServerTest`).
To prevent this, we have to either make sure we set `sun.net.http.allowRestrictedHeaders=true` as early as possible or do not rely on this system property at all.

This PR adds test dependency on `httpcomponents-client` which doesn't depend on `sun.net.http.allowRestrictedHeaders` system property. Thus none of existing tests should interfere with `RestServerTest`.

Author: Alex Diachenko <sansanichfb@gmail.com>

Reviewers: Randall Hauch, Konstantine Karantasis, Gwen Shapira

Closes #6236 from avocader/KAFKA-7799",2019-02-12 12:03:08,Alex Diachenko,Not TDD
0a1c26934757afae4dce49ff3ee038311ca6dd4a,"KAFKA-7652: Part III; Put to underlying before Flush (#6191)

1. In the caching layer's flush listener call, we should always write to the underlying store, before flushing (see #4331 's point 4) for detailed explanation). When fixing 4331, it only touches on KV stores, but it turns out that we should fix for window and session store as well.

2. Also apply the optimization that was in session-store already: when the new value bytes and old value bytes are all null (this is possible e.g. if there is a put(K, V) followed by a remove(K) or put(K, null) and these two operations only hit the cache), upon flushing this mean the underlying store does not have this value at all and also no intermediate value has been sent to downstream as well. We can skip both putting a null to the underlying store as well as calling the flush listener sending `null -> null` in this case.

Modifies corresponding unit tests.

Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",2019-02-12 22:36:40,Guozhang Wang,Mixed
b02b5b63a5d43ab552c6cec1237707b2edd1bb36,"KAFKA-7440; Add leader epoch to fetch and list-offset request (#6190)

As part of KIP-320, we should add the expected leader epoch to Fetch and ListOffsets requests. This will allow us ultimately to detect log truncation.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-02-13 09:51:35,David Arthur,Mixed
8b97c3d8a96424e09f5e9ba1846625dfeb419923,"MINOR: Add missing Alter Operation to Topic supported operations list in AclCommand

- Update the AclCommandTest

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #6263 from omkreddy/aclcommand",2019-02-14 09:45:09,Manikumar Reddy,Mixed
01f0f0af28ea05921868171c88448e299766e773,"KAFKA-7916: Unify store wrapping code for clarity (#6255)

Refactor internal store wrapping for improved maintainability.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-02-14 08:38:01,John Roesler,Mixed
d0718718aecdb9030205fde30846b0b6481c762b,"MINOR: Make MockClient#poll() more thread-safe (#5942)

It used to preallocate an array of responses and then complete each response from the original collection sequentially. The problem was that the original collection could have been modified (another thread completing the response) while this was hapenning",2019-02-14 09:59:36,Stanislav Kozlovski,Not TDD
af91eeeb793af2f5b873c48ef8ff636e8b485308,"MINOR: fix bypasses in ChangeLogging stores (#6266)

The change-logging stores should not bypass methods in underlying stores.

If some of you have a minute, can you take a quick look at this? I happened to notice during some other refactoring that the change-logging store layer sometimes bypasses the underlying store and instead calls across to a different layer.

It seems unexpected that it should do so, and it might actually cause problems. There was one spot where it's impossible to avoid it (in the windowed store), but I added a note justifying why we bypass the underlying store.

Thanks,
-John

* MINOR: fix bypasses in ChangeLogging stores

* fix test

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bbejeck@gmail.com>",2019-02-14 13:39:10,John Roesler,Mixed
a421dd2a26ca140f821cd5be1a4f716cf04beb43,"MINOR: Fix bugs identified by compiler warnings (#6258)

- Add missing string interpolation
- Fix and simplify testElectPreferredLeaders
- Remove unused code
- Replace deprecated usage of JUnit `assertThat`
- Change var to val and fix non-exhaustive pattern match
- Fix eta warning
- Simplify code
- Remove commented out code

Reviewers: Jun Rao <junrao@gmail.com>",2019-02-14 17:13:20,Ismael Juma,Mixed
44257f293732588fc493f072b0cee4bd3a1840ab,"KAFKA-7884; Docs for message.format.version should display valid values (#6209)

The config docs for message.format.version and log.message.format.version show invalid (corrupt?) ""valid values"". The problem is that`ApiVersionValidator#toString` is missing. In contrast, all other Validators like `ThrottledReplicaListValidator` or `Range`, have its own `toString` method. This patch solves this problem by adding `ApiVersionValidator#toString`. It also provides a unit test for it.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-02-15 16:50:01,Lee Dongjin,Mixed
247ccd7ac97234d91ba8c6c58a54272e89cd81b4,"KAFKA-7758: Reuse KGroupedStream/KGroupedTable with named repartition topics (#6265)

Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2019-02-16 18:43:48,Bill Bejeck,Not TDD
0846f590dac5d3893d41e262d67ee8a228dcc332,"KAFKA-7895: Fix stream-time reckoning for suppress (#6278)

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2019-02-18 10:14:37,John Roesler,Mixed
45a896e74166a15daf9d8d05d3459f7f6b237de2,"KAFKA-7935: UNSUPPORTED_COMPRESSION_TYPE if ReplicaManager.getLogConfig returns None (#6274)

Replaced `forall` with `exists`. Added a unit test to `KafkaApisTest` that failed before the change.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2019-02-18 18:19:15,Ismael Juma,Mixed
e17352f03ebabc1fd6a8289392b55a2191fd2dfd,"KAFKA-7487: DumpLogSegments misreports offset mismatches (#5756)

- Compare last offset of first batch (instead of first offset) with index offset
- Early exit from loop due to zero entries must happen before checking for mismatch
- {TimeIndex,OffsetIndex}.entry should return absolute offset like other methods.
These methods are only used by DumpLogSegments.
- DumpLogSegments now calls `closeHandlers` on OffsetIndex, TimeIndex
and FileRecords.
- Add OffsetIndex, TimeIndex and DumpLogSegments tests
- Remove unnecessary casts by using covariant returns in OffsetIndex and TimeIndex
- Minor clean-ups
- Fix `checkArgs` so that it does what it says only.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Sriharsha Chintalapani <sriharsha@apache.org>",2019-02-18 11:42:41,Ismael Juma,Mixed
4cb8f56b45f3bfb596fb00ef2cc88938fc66f364,"KAFKA-7909; Ensure timely rebalance completion after pending members rejoin or fail (#6251)

Fix the following situations, where pending members (one that has a member-id, but hasn't joined the group) can cause rebalance operations to fail: 

- In AbstractCoordinator, a pending consumer should be allowed to leave.
- A rebalance operation must successfully complete if a pending member either joins or times out.
- During a rebalance operation, a pending member must be able to leave a group.

Reviewers: Boyang Chen <bchen11@outlook.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2019-02-19 16:14:13,Arjun Satish,Mixed
71a7219dfdc0a40dc1846c749d2f219776b56955,"KAFKA-7920; Do not permit zstd produce requests until IBP is updated to 2.1 (#6256)

Fail produce requests using zstd until the inter.broker.protocol.version is large enough that replicas are ensured to support it. Otherwise, followers receive the `UNSUPPORTED_COMPRESSION_TYPE` when fetching zstd data and ISRs shrink.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-02-20 08:44:04,Lee Dongjin,Mixed
74ad46d880884f9b1435ef10d813a4c6ca843240,"KAFKA-7945: Calc refresh time correctly when token created in the past (#6288)

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2019-02-20 21:26:41,Ron Dagostino,Mixed
18984434df5295b0940e468ffb467c47b0fd72dd,"HOT_FIX: Change flag so plain RocksDB instance returned (#6297)

This PR fixes the issue found in the soak testing cluster regarding using RocksDBTimestampedStore when a regular RocksDB store should have been used.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>, John Roesler <john@confluent.io>",2019-02-20 19:09:23,Bill Bejeck,Mixed
ff603c63bb3e0b47ce14121bb0e96ce0fc42d3c1,"KAFKA-4730: Streams does not have an in-memory windowed store (#6239)

Implemented an in-memory window store allowing for range queries. A finite retention period defines how long records will be kept, ie the window of time for fetching, and the grace period defines the window within which late-arriving data may still be written to the store.

Unit tests were written to test the functionality of the window store, including its insert/update/delete and fetch operations. Single-record, all records, and range fetch were tested, for both time ranges and key ranges. The logging and metrics for late-arriving (dropped)records were tested as well as the ability to restore from a changelog.

Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-02-20 19:09:50,A. Sophie Blee-Goldman,Mixed
2932d32afb293b2c230a6d73b2eb134ef2828c56,"KAFKA-7283: Enable lazy mmap on index files and skip sanity check for segments below recovery point (#5498)

Per the KIP-263 discussion, we think we can improve broker restart time by avoiding performing costly disk operations when sanity checking index files for segments below recovery point on broker startup.

This PR includes the following changes:

1. Mmap the index file and populate fields of the index file on-demand rather than performing costly disk operations when creating the index object on broker startup.
2. Skip sanity checks on the time index and offset index of segments.
   
   1. For segment with offset below the flushed point (recovery point), these segments are safely flushed so we don't need to sanity check the index files. if there are indeed data corruption on disk, given that we don't sanity check the segment file, sanity checking only the indexes adds little benefit.
   2. For segment with offset above the flushed point (recovery point), we will recover these segments in `recoveryLog()` (Log.scala) in any case so sanity checking the index files for these segments is redundant.

We did experiments on a cluster with 15 brokers, each of which has ~3k segments (and there are 31.8k partitions with RF=3 which are evenly distributed across brokers; total bytes-in-rate is around 400 MBps). The results show that rolling bounce time reduces from 135 minutes to 55 minutes.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",2019-02-20 21:50:31,Zhanxiang (Patrick) Huang,Mixed
35a0de32ee3823dfb548a1cd5d5faf4f7c99e4e0,"KAFKA-6161 Add default implementation to close() and configure() for Serdes (#5348)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-02-21 09:05:13,Chia-Ping Tsai,Not TDD
f775be0514dc6a512245fd244e06e0aa11cc45c4,"MINOR: Handle Metadata v0 all topics requests during parsing (#6300)

Use of `MetadataRequest.isAllTopics` is not consistently defined for all versions of the api. For v0, it evaluates to false. This patch makes the behavior consistent for all versions.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2019-02-21 13:11:36,Jason Gustafson,Mixed
201da0542726472d954080d54bc585b111aaf86f,"KAFKA-7763; Calls to commitTransaction and abortTransaction should not block indefinitely  (#6066)

Currently, commitTransaction and abortTransaction wait indefinitely for the respective operation to be completed. This patch uses the producer's max block time to limit the time that we will wait. If the timeout elapses, we raise a TimeoutException, which allows the user to either close the producer or retry the operation.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-02-21 14:18:36,huxi,Mixed
217f45ed554b34d5221e1dd3db76e4be892661cf,"KAFKA-7864; validate partitions are 0-based (#6246)

Reviewers: Sriharsha Chintalapani <sriharsha@apache.org>, Jun Rao <junrao@gmail.com>",2019-02-22 09:11:21,Ryan Chen,Mixed
0d461e4ea0a8353c358ae661837f471995943bb0,"KAFKA-7672: Restoring tasks need to be closed upon task suspension (#6113)

* In activeTasks.suspend, we should also close all restoring tasks as well. Closing restoring tasks would not require `task.close` as in `closeNonRunningTasks `, since the topology is not initialized yet, instead only state stores are initialized. So we only need to call `task.closeStateManager`.
* Also add @linyli001 's fix.
* Unit tests updated accordingly.

Reviewers: Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>",2019-02-22 10:50:55,Guozhang Wang,Mixed
eb8cc09625c9913c4029763a46d4b7e5639c85f5,"KAFKA-7961; Ignore assignment for un-subscribed partitions (#6304)

Whenever the consumer coordinator sends a response that doesn't match the client consumer subscription, we should check the subscription to see if it has changed. If it has, we can ignore the assignment and request a rebalance. Otherwise, we can throw an exception as before.

Testing strategy: create a mocked client that first sends an assignment response that doesn't match the client subscription followed by an assignment response that does match the client subscription.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-02-22 20:51:09,José Armando García Sancio,Mixed
1f9aa01a5b3b59d90499a059d719af03483d5130,"KAFKA-7672 : force write checkpoint during StreamTask #suspend (#6115)

This fix is aiming for #2 issue pointed out within https://issues.apache.org/jira/browse/KAFKA-7672
In the current setup, we do offset checkpoint file write when EOS is turned on during #suspend, which introduces the potential race condition during StateManager #closeSuspend call. To mitigate the problem, we attempt to always write checkpoint file in #suspend call.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",2019-02-22 21:49:28,Boyang Chen,Mixed
4824dc994d7fc56b7540b643a78aadb4bdd0f14d,"KAFKA-7972: Use automatic RPC generation in SaslHandshake

Author: Mickael Maison <mickael.maison@gmail.com>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #6301 from mimaison/sasl-handshake",2019-02-25 11:20:07,Mickael Maison,Not TDD
21b79635474209fcd67d3bf33a70c25f6827c6ef,"KAFKA-7918: Inline generic parameters Pt. I: in-memory key-value store (#6293)

First PR in series to inline the generic parameters of the following bytes stores:

[x] InMemoryKeyValueStore
[ ] RocksDBWindowStore
[ ] RocksDBSessionStore
[ ] MemoryLRUCache
[ ] MemoryNavigableLRUCache
[ ] (awaiting merge) InMemoryWindowStore

A number of tests took advantage of the generic InMemoryKeyValueStore and had to be reworked somewhat -- this PR covers everything related to the in-memory key-value store.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",2019-02-25 19:59:14,A. Sophie Blee-Goldman,Mixed
dc91ce58af941b822fbad3b560c35774130848f0,"[TRIVIAL] Remove unused StreamsGraphNode#repartitionRequired (#6227)

I found this defect while inspecting [KAFKA-7293: Merge followed by groupByKey/join might violate co-partitioning](https://issues.apache.org/jira/browse/KAFKA-7293); This flag is never used now. Instead, `KStreamImpl#repartitionRequired` is now covering its functionality.

Reviewers: Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bbejeck@gmail.com>",2019-02-26 10:22:25,Lee Dongjin,Not TDD
66a6fc7204b3903ae8015bc8bceb200b6838ec10,"MINOR: Refactor replica log dir fetching for improved logging (#6313)

In order to debug problems with log directory reassignments, it is helpful to know when the fetcher thread begins moving a particular partition. This patch refactors the fetch logic so that we stick to a selected partition as long as it is available and log a message when a different partition is selected.

Reviewers: Viktor Somogyi-Vass <viktorsomogyi@gmail.com>, Dong Lin <lindong28@gmail.com>, Jun Rao <junrao@gmail.com>",2019-02-26 08:38:32,Jason Gustafson,Mixed
a8f2307164ce0f1f47c458eee8f54173f7218a16,"KAFKA-7918: Inline generic parameters Pt. II: RocksDB Bytes Store and Memory LRU Caches (#6327)

Second PR in series to inline the generic parameters of the following bytes stores

Reviewers: Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bbejeck@gmail.com>",2019-02-27 10:08:08,A. Sophie Blee-Goldman,Mixed
a1f7925d23be0b81cb77561d2113443df52c6f74,"KAFKA-7962: Avoid NPE for StickyAssignor (#6308)

* KAFKA-7962: StickyAssignor: throws NullPointerException during assignments if topic is deleted

https://issues.apache.org/jira/browse/KAFKA-7962

Consumer using StickyAssignor throws NullPointerException if a subscribed topic was removed.

* addressed vahidhashemian's comments

* lower NPath Complexity

* added a unit test",2019-02-27 22:27:38,huxi,Mixed
3c46b5669de856f4510b8d291a8af7dbd809c07b,"MINOR: Remove types from caching stores (#6331)

* MINOR: remove types from caching stores

* Github comments and rebased",2019-02-28 09:33:53,Matthias J. Sax,Mixed
09136235db2fcae5282a218de75b6356f9420031,"KAFKA-7912: Support concurrent access in InMemoryKeyValueStore (#6336)

Previously the InMemoryKeyValue store would throw a ConcurrentModificationException if the store was modified beneath an open iterator. The TreeMap implementation was swapped with a ConcurrentSkipListMap for similar performance while supporting concurrent access.

Added one test to AbstractKeyValueStoreTest, no existing tests caught this.

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-02-28 14:47:27,A. Sophie Blee-Goldman,Not TDD
70828cea49ab8a3ceb54a9017618b84e0d9c1420,"KAFKA-8012; Ensure partitionStates have not been removed before truncating. (#6333)

This patch fixes a regression in the replica fetcher which occurs when the replica fetcher manager simultaneously calls `removeFetcherForPartitions`, removing the corresponding partitionStates, while a replica fetcher thread attempts to truncate the same partition(s) in `truncateToHighWatermark`. This causes an NPE which causes the fetcher to crash.

This change simply checks that the `partitionState` is not null first. Note that a similar guard exists in `truncateToEpochEndOffsets`.

Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",2019-02-28 16:37:30,Colin Hicks,Mixed
f11fa5ef402193e2da785466e698e11b56bd19c7,"KAFKA-7922: Return authorized operations in describe consumer group responses (KIP-430 Part-1)

-  Use automatic RPC generation in DescribeGroups Request/Response classes

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #6322 from omkreddy/KIP-430-Return-Ops",2019-03-01 21:23:52,Manikumar Reddy,Mixed
33ba2820f4fbb459172022a83d761a7c674a8fdd,"KAFKA-3522: Add TimestampedKeyValueStore builder/runtime classes (#6152)

Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-03-01 15:39:23,Matthias J. Sax,Mixed
57604c2331d8fb307ce9a18c14036746a18df552,"KAFKA-8002; Log dir reassignment stalls if future replica has different segment base offset (#6346)

This patch fixes a bug in log dir reassignment where Partition.maybeReplaceCurrentWithFutureReplica would compare the entire LogEndOffsetMetadata of each replica to determine whether the reassignment has completed. If the active segments of both replicas have different base segments (for example, if the current replica had previously been cleaned and the future replica rolled segments at different points), the reassignment will never complete. The fix is to compare only the LogEndOffsetMetadata.messageOffset for each replica. Tested with a unit test that simulates the compacted current replica case.

Reviewers: Anna Povzner <anna@confluent.io>, Jason Gustafson <jason@confluent.io>",2019-03-01 17:39:42,Bob Barrett,Mixed
0d56f1413557adabc736cae2dffcdc56a620403e,"KAFKA-7997: Use automatic RPC generation in SaslAuthenticate

Author: Mickael Maison <mickael.maison@gmail.com>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #6324 from mimaison/sasl-authenticate",2019-03-02 21:28:30,Mickael Maison,Not TDD
1db46673661cf6dcb7f2fa2565262b04cf580367,"KAFKA-7736; Consolidate Map usages in TransactionManager (#6270)

Refactors the various maps used in TransactionManager into one map to simplify bookkeeping of inflight batches, offsets and sequence numbers.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-03-06 09:52:09,Viktor Somogyi,Mixed
8662efbad24c859aeee5c3b469dbc907e39ff82d,"KAFKA-8006: Guard calls to init and close from global processor (#6353)

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2019-03-06 10:56:44,A. Sophie Blee-Goldman,Mixed
47888630a05260f548988d943a633120845f767d,"KAFKA-8007: Avoid copying on fetch in InMemoryWindowStore (#6335)

Rewrote the InMemoryWindowStore implementation by moving the work of a fetch to the iterator, and cleaned up the iterators as well.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>",2019-03-06 14:02:27,A. Sophie Blee-Goldman,Mixed
ab00c51b6362b41071ae32611ebf698ba9c221ee,"KAFKA-3522: Add public interfaces for timestamped stores (#6175)

Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-03-06 14:57:08,Matthias J. Sax,Mixed
7f6bf95c1e4875b1042746e3d73240496073f081,"Fix for KAFKA-7974: Avoid zombie AdminClient when node host isn't resolvable (#6305)

* Fix for KAFKA-7974: Avoid calling disconnect() when not connecting

* Resolve host only when currentAddress() is called

Moves away from automatically resolving the host when the connection entry is constructed, which can leave ClusterConnectionStates in a confused state.
Instead, resolution is done on demand, ensuring that the entry in the connection list is present even if the resolution failed.

* Add Javadoc to ClusterConnectionStates.connecting()",2019-03-07 00:07:23,Nicholas Parker,Mixed
73737892d5a51688b3403454b6e0f1f59c85ba8d,"KAFKA-8018: Flaky Test SaslSslAdminClientIntegrationTest#testLegacyAclOpsNeverAffectOrReturnPrefixed

Disable forceSync in EmbeddedZookeeper.
Increase ZK tick to allow longer maxSessionTimeout in tests.
Increase ZK client session timeout in tests.
Handle transient ZK session expiration exception in test utils for createTopic.

Author: Jun Rao <junrao@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #6354 from junrao/KAFKA-8018",2019-03-07 15:33:54,Jun Rao,Not TDD
b10d311f8a6c88149a4859c6ca0d2f53bfe2fc35,"KAFKA-8039 - Use MockTime in fast reauth test to avoid transient failures (#6383)

Test uses 100ms as connections.max.reauth.ms and checks that a second reauthentication doesn't occur within the hard-coded 1 second minimum interval. But since the interval is small, we cannot guarantee that the time between the two checks is not higher than 1 second. Change the test to use MockTime so that we can control the time.

Reviewers: Ron Dagostino <rndgstn@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2019-03-07 13:22:16,Rajini Sivaram,Not TDD
1f525cd2c90ec81fa9c3967d1303a905d1afccb2,"KAFKA-8061; Handle concurrent ProducerId reset and call to Sender thread shutdown (#6388)

In KAFKA-5503, we have added a check  for `running` flag in the loop inside maybeWaitForProducerId.  This is to handle concurrent call to Sender close(), while we attempt to get the ProducerId. This avoids blocking indefinitely when the producer is shutting down.

This created a corner case, where Sender thread gets blocked, if we had concurrent producerId reset and call to Sender thread close. The fix here is to check the `forceClose` flag in the loop inside maybeWaitForProducerId instead of the `running` flag.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-03-07 14:28:21,Manikumar Reddy,Mixed
460e46c3bb76a361d0706b263c03696005e12566,"KAFKA-7831; Do not modify subscription state from background thread (#6221)

Metadata may be updated from the background thread, so we need to protect access to SubscriptionState. This patch restructures the metadata handling so that we only check pattern subscriptions in the foreground. Additionally, it improves the following:

1. SubscriptionState is now the source of truth for the topics that will be fetched. We had a lot of messy logic previously to try and keep the the topic set in Metadata consistent with the subscription, so this simplifies the logic.
2. The metadata needs for the producer and consumer are quite different, so it made sense to separate the custom logic into separate extensions of Metadata. For example, only the producer requires topic expiration.
3. We've always had an edge case in which a metadata change with an inflight request may cause us to effectively miss an expected update. This patch implements a separate version inside Metadata which is bumped when the needed topics changes.
4. This patch removes the MetadataListener, which was the cause of https://issues.apache.org/jira/browse/KAFKA-7764. 

Reviewers: David Arthur <mumrah@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2019-03-07 16:29:19,Jason Gustafson,Mixed
027cbbaec521542f53274183daccc2073e91cfe9,"KAFKA-8060: The Kafka protocol generator should allow null defaults

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #6387 from cmccabe/KAFKA-8060",2019-03-08 09:25:28,Colin P. Mccabe,Mixed
f716d08c9c7f0f3ec7456cb9a27a42104457b867,"KAFKA-8040: Streams handle initTransactions timeout (#6372)

As of 2.0, Producer.initTransactions may throw a TimeoutException, which is retriable. Streams should retry instead of crashing when we encounter this exception

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>,  Bill Bejeck <bbejeck@gmail.com>",2019-03-08 10:29:22,John Roesler,Mixed
44be5d2221c9faff2ecb17878d6193504b7289aa,"KAFKA-8069; Fix early expiration of offsets due to invalid loading of expire timestamp (#6401)

After the 2.1 release, if the broker hasn't been upgrade to the latest inter-broker protocol version, the committed offsets stored in the __consumer_offset topic will get cleaned up way earlier than it should be when the offsets are loaded back from the __consumer_offset topic in GroupCoordinator, which will happen during leadership transition or after broker bounce. This patch fixes the bug by setting expireTimestamp to None if it is the default value after loading v1 offset records from __consumer_offsets.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2019-03-08 09:04:04,Zhanxiang (Patrick) Huang,Mixed
04e206154ac614b7d4d34a7a1b6ba2c882f607b9,"KAFKA-3522: Add TimestampedWindowStore builder/runtime classes (#6173)

Add TimestampedWindowStore builder/runtime classes

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>,  Bill Bejeck <bbejeck@gmail.com>",2019-03-08 12:30:00,Matthias J. Sax,Mixed
3619d2f383f65108dfd33686119f675aaeea54b7,"MINOR: cleanup deprectaion annotations (#6290)

If deprecated interface methods are inherited, the @Deprication tag should be used (instead on suppressing the deprecation warning).

Reviewers:  Guozhang Wang <wangguoz@gmail.com>,  John Roesler <john@confluent.io>,  Bill Bejeck <bbejeck@gmail.com>",2019-03-08 15:31:34,Matthias J. Sax,Mixed
09f1009d246b82475bbf018d187fff5a3e035539,"KAFKA-8065: restore original input record timestamp in forward() (#6393)

Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-03-08 19:24:26,Matthias J. Sax,Not TDD
65aea1f362fb6562c39df34b4d5c014f544b45ec,"MINOR: Print usage when parse fails during console producer

*Handle OptionException while parsing options when using console producer and print usage before die.*

Author: Suman BN <sumannewton@gmail.com>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #6386 from sumannewton/console-producer-parse-printusage",2019-03-10 12:19:43,Suman BN,Mixed
a42f16f980cba86a8889be8b7499437ecbc2cd42,"KAFKA-7922: Return authorized operations in Metadata request response (KIP-430 Part-2)

-  Use automatic RPC generation in Metadata Request/Response classes
-  https://cwiki.apache.org/confluence/display/KAFKA/KIP-430+-+Return+Authorized+Operations+in+Describe+Responses

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #6352 from omkreddy/KIP-430-METADATA",2019-03-10 17:30:16,Manikumar Reddy,Mixed
173a7e3d54ede6616037d6c55057417dfeb44ab9,"KAFKA-7939: Fix timing issue in KafkaAdminClientTest.testCreateTopicsRetryBackoff

There is a small timing window where ```time.sleep(retryBackoff)``` will get executed before adminClient adds retry request to the queue.  Added a check to wait until the retry call added to the queue in AdminClient.

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #6418 from omkreddy/KAFKA-7939",2019-03-11 19:48:52,Manikumar Reddy,Mixed
290360692114baa74f6ca1963b6700c38594d876,"KAFKA-7801: TopicCommand should not be able to alter transaction topic partition count

To keep align with the way it handles the offset topic, TopicCommand should not be able to alter transaction topic partition count.

Author: huxihx <huxi_2b@hotmail.com>

Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #6109 from huxihx/KAFKA-7801",2019-03-12 11:35:48,huxihx,Mixed
0f83c4cdb76c2123a4c365ebcdd9cfb7bf711a45,"KAFKA-7976; Update config before notifying controller of unclean leader update (#6426)

When unclean leader election is enabled dynamically on brokers, we notify controller of the update before updating KafkaConfig. When processing this event, controller's decision to elect unclean leaders is based on the current KafkaConfig, so there is a small timing window when the controller may not elect unclean leader because KafkaConfig of the server was not yet updated. The commit fixes this timing window by using the existing BrokerReconfigurable interface used by other classes which rely on the current value of KafkaConfig.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2019-03-12 09:47:05,Rajini Sivaram,Not TDD
ab7ea07f5e57ec405dc7fddce95de7c639a2fd6e,"KAFKA-3522: add missing guards for TimestampedXxxStore (#6356)

Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",2019-03-12 12:28:14,Matthias J. Sax,Mixed
8e975400711b0ea64bf4a00c8c551e448ab48416,"KAFKA-7944: Improve Suppress test coverage (#6382)

* add a normal windowed suppress with short windows and a short grace
period
* improve the smoke test so that it actually verifies the intended
conditions

See https://issues.apache.org/jira/browse/KAFKA-7944

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-03-12 09:53:29,John Roesler,Not TDD
9ecadc4df474d9cfbfda3256f01eba1423cf5902,"MINOR: Use Java 8 lambdas in KStreamImplTest (#6430)

Just a minor cleanup to use Java 8 lambdas vs anonymous classes in this test.

I ran all tests in the streams test suite

Reviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",2019-03-12 13:35:25,Bill Bejeck,Not TDD
3ec2ca5e334ef42683263ed50c718c62917046af,"KAFKA-7730; Limit number of active connections per listener in brokers (KIP-402)

Adds a new listener config `max.connections` to limit the number of active connections on each listener. The config may be prefixed with listener prefix. This limit may be dynamically reconfigured without restarting the broker.

This is one of the PRs for KIP-402 (https://cwiki.apache.org/confluence/display/KAFKA/KIP-402%3A+Improve+fairness+in+SocketServer+processors). Note that this is currently built on top of PR #6022

Author: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Gwen Shapira <cshapi@gmail.com>

Closes #6034 from rajinisivaram/KAFKA-7730-max-connections",2019-03-14 16:18:52,Rajini Sivaram,Mixed
853f24a4a18b26b4e4cc03555673ee951067fa6e,"KAFKA-7027: Add an overload build method in scala (#6373)

The Java API can pass a Properties object to StreamsBuilder#build, to allow, e.g., topology optimization, while the Scala API does not yet. The latter only delegates the work to the underlying Java implementation.

Reviewers: John Roesler <john@confluent.io>,  Bill Bejeck <bbejeck@gmail.com>",2019-03-15 10:56:48,Massimo Siani,Not TDD
f20f3c1a97b8a31a2f211cd66506fb823f420c55,"MINOR: Update Trogdor ConnectionStressWorker status at the end of execution (#6445)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2019-03-15 09:53:21,Stanislav Kozlovski,Not TDD
e1961b8298c6d7ec028cd95721f4b498689c506e,"MINOR: Update code to not use deprecated methods (#6434)

Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Colin P. McCabe <cmccabe@confluent.io>",2019-03-15 19:47:40,Matthias J. Sax,Not TDD
20e3a3035b02388d46a4d7bf93370329aa405956,"KAFKA-8111; Set min and max versions for Metadata requests (#6451)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2019-03-16 11:00:03,Rajini Sivaram,Mixed
ca6ac9393bae9161465275cb8f836bc987a5098d,"MINOR: Retain public constructors of classes from public API (#6455)

TopicDescription and ConsumerGroupDescription in org.apache.kafka.clients.admin. are part of the public API, so we should retain the existing public constructor. Changed the new constructor with authorized operations to be package-private to avoid maintaining more public constructors since we only expect admin client to use this.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2019-03-18 08:51:50,Rajini Sivaram,Not TDD
810bc69b7a474297aa345613cf18cb8bfb115603,"KAFKA-8121; Shutdown ZK client expiry handler earlier during close (#6462)

Shutdown session expiry thread prior to closing ZooKeeper client to ensure that new clients are not created by the expiry thread and left active when returning from ZooKeeperClient.close().

Reviewers: Ismael Juma <ismael@juma.me.uk>",2019-03-18 18:07:24,Rajini Sivaram,Mixed
8406f3624d8f99b614eb7171b71fae8b0e663dcb,"KAFKA-7858: Automatically generate JoinGroup request/response

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2019-03-18 13:26:09,Boyang Chen,Mixed
6d649f503a964ed9612e79ef2d9e55e26240fbc3,"KAFKA-8062: Do not remore StateListener when shutting down stream thread (#6468)

In a previous commit #6091, we've fixed a couple of edge cases and hence do not need to remove state listener anymore (before that we removed the state listener intentionally to avoid some race conditions, which has been gone for now).

Reviewers: Matthias J. Sax <mjsax@apache.org>,   Bill Bejeck <bbejeck@gmail.com>",2019-03-19 10:12:49,Guozhang Wang,Mixed
538bd7eddf13897245524f015e3207affb03fcdc,"KAFKA-8094: Iterating over cache with get(key) is inefficient (#6433)

Use concurrent data structure for the underlying cache in NamedCache, and iterate over it with subMap instead of many calls to get()

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>",2019-03-19 11:51:10,A. Sophie Blee-Goldman,Mixed
b5ce093a24d0fe212b5d1374330fc720b4913bee,"MINOR: capture result timestamps in Kafka Streams DSL tests (#6447)

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-03-19 17:27:32,Matthias J. Sax,Not TDD
1f692bdf53af4a80b7fd256de4e94ff1d17fc861,"KAFKA-8142: Fix NPE for nulls in Headers (#6484)

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-03-21 23:53:56,Matthias J. Sax,Mixed
860e9579994aa00dbbbeadb3ab10eec0cb854ddf,"MINOR: list-topics should not require topic param

`kafka.list_topics(...)` should not require a topic parameter

Author: Brian Bushree <bbushree@confluent.io>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #6367 from brianbushree/list-topics-no-topic",2019-03-22 11:50:00,Brian Bushree,Not TDD
e4cad353124478fd4034f18d2292ba62fb702924,"KAFKA-8014: Extend Connect integration tests to add and remove workers dynamically (#6342)

Extend Connect's integration test framework to add or remove workers to EmbeddedConnectCluster, and choosing whether to fail the test on ungraceful service shutdown. Also added more JavaDoc and other minor improvements. 

Author: Konstantine Karantasis <konstantine@confluent.io>

Reviewers: Arjun Satish <arjun@confluent.io>, Randall Hauch <rhauch@gmail.com>

Closes #6342 from kkonstantine/KAFKA-8014",2019-03-25 09:29:33,Konstantine Karantasis,Not TDD
e0d028bf6cbf140c72706247c40bded7bfabcb0c,"KAFKA-8150: Fix bugs in handling null arrays in generated RPC code (#6489)

ToString functions must not get a NullPointException.  read() functions
must properly translate a negative array length to a null field.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2019-03-25 09:43:44,Colin Patrick McCabe,Mixed
0d55f0f3ec8f97bc250b325481f6f2fa70f52a5c,"KAFKA-8102: Add an interval-based Trogdor transaction generator (#6444)

This patch adds a TimeIntervalTransactionsGenerator class which enables the Trogdor ProduceBench worker to commit transactions based on a configurable millisecond time interval.

Also, we now handle 409 create task responses in the coordinator command-line client by printing a more informative message

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2019-03-25 09:58:11,Stanislav Kozlovski,Mixed
dc0601a1c604bea3f426ed25b6c20176ff444079,"KAFKA-3522: Add RocksDBTimestampedSegmentedBytesStore (#6186)

Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-03-26 14:23:01,Matthias J. Sax,Mixed
369d89f2080586773b5a3cc432cbcf655aa1f625,"MINOR: Move KTable source topic for changelog to optimization framework (#6500)

Since we've added Kafka Streams optimizations in 2.1 we need to move the optimization for source KTable nodes (use source topic as changelog) to the optimization framework.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-03-29 17:16:56,Bill Bejeck,Mixed
981815c8d14daf1042e06f8fa9cb355187719b1d,"KAFKA-8034: Use automatic RPC generation in DeleteTopics

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2019-03-29 14:32:36,Mickael Maison,Mixed
213466b3d4fd21b332c0b6882fea36cf1affef1c,"KAFKA-7190: KIP-443; Remove streams overrides on repartition topics (#6511)

* remove streams overrides on segment.ms and segment.index.bytes

* kip comments",2019-04-02 17:12:32,Guozhang Wang,Not TDD
d3316bc6a7834db9eef6dde21728891ba6b07b37,"KAFKA-8126: Flaky Test org.apache.kafka.connect.runtime.WorkerTest.testAddRemoveTask (#6475)

Changed the WorkerTest to use a mock Executor.

Author: Attila Doroszlai <adoroszlai@apache.org>
Reviewer: Randall Hauch <rhauch@gmail.com>",2019-04-03 15:00:05,"Doroszlai, Attila",Mixed
c3010254843dcdf0bd68602f752f690cd76d9813,"KAFKA-8090: Use automatic RPC generation in ControlledShutdown

Author: Mickael Maison <mickael.maison@gmail.com>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #6423 from mimaison/controlled-shutdown",2019-04-04 22:05:04,Mickael Maison,Not TDD
31d191fc85229c9b0a6e85aad56e8a7975b295e1,"KAFKA-7904; Add AtMinIsr partition metric and TopicCommand option (KIP-427)

- Add `AtMinIsrPartitionCount` metric to `ReplicaManager`
- Add `AtMinIsr` metric to `Partition`
- Add `--at-min-isr-partitions` describe `TopicCommand` option

https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=103089398

Author: Kevin Lu <lu.kevin@berkeley.edu>
Author: lu.kevin@berkeley.edu <kelu@paypal.com>

Reviewers: Gwen Shapira

Closes #6421 from KevinLiLu/KAFKA-7904",2019-04-05 09:14:41,Kevin Lu,Mixed
825fa3fa09b89e9ba9d38a92c1b01bd170494efb,"MINOR: Fixed a few warning in core and connects (#6545)

- var -> val
- unused imports
- Javadoc fix

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2019-04-05 23:30:48,Mickael Maison,Not TDD
844120c601e87693e540fa98a9cdb4d0272f5601,"KAFKA-8190; Don't update keystore modification time during validation (#6539)

Ensure that modification time is checked against the file used to create the SSLContext that is in-use so that SSLContext is updated whenever file is modified and a config update request is received.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2019-04-05 19:42:28,Rajini Sivaram,Mixed
62381bd9152d30e95af58f4423240ed4eaa084b5,"KAFKA-8168; Add a generated ApiMessageType class

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Gwen Shapira

Closes #6510 from cmccabe/KAFKA-8168",2019-04-05 15:27:34,Colin P. Mccabe,Mixed
71e721f1354739b183fa7c58a3483098c6832928,"KAFKA-8058: Fix ConnectClusterStateImpl.connectors() method (#6384)

Fixed the ConnectClusterStateImpl.connectors() method and throw an exception on timeout. Added unit test.

Author: Chris Egerton <chrise@confluent.io>

Reviewers: Magesh Nandakumar <magesh.n.kumar@gmail.com>, Robert Yokota <rayokota@gmail.com>, Arjun Satish <wicknicks@users.noreply.github.com>, Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <ewen@confluent.io>

Closes #6384 from C0urante:kafka-8058",2019-04-07 09:43:09,Chris Egerton,Mixed
1bf1e46e7e7ea192019576a5ee613bcedd843e96,"KAFKA-8013; Avoid underflow when reading a Struct from a partially correct buffer (#6340)

Protocol compatibility can be facilitated if a Struct, that has been defined as an extension of a previous Struct by adding fields at the end of the older version, can read a message of an older version by ignoring the absence of the missing new fields. Reading the missing fields should be allowed by the definition of these fields (they have to be nullable) when supported by the schema.

Reviewers: David Arthur <mumrah@gmail.com>, Randall Hauch <rhauch@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-04-08 14:24:00,Konstantine Karantasis,Not TDD
9f5a69a4c2d6ac812ab6134e64839602a0840b87,"[MINOR] Guard against crashing on invalid key range queries (#6521)

Due to KAFKA-8159, Streams will throw an unchecked exception when a caching layer or in-memory underlying store is queried over a range of keys from negative to positive. We should add a check for this and log it then return an empty iterator (as the RocksDB stores happen to do) rather than crash

Reviewers: Bruno Cadonna <bruno@confluent.io> Bill Bejeck <bbejeck@gmail.com>",2019-04-10 15:10:47,A. Sophie Blee-Goldman,Mixed
53e95ffcdb1cecbba67eb726aa2abcab3ae49c66,"MINOR: Use generated InitProducerId RPC (#6538)

This patch updates the InitProducerId request API to use the generated sources. It also fixes a small bug in the DescribeAclsRequest class where we were using the wrong api key.

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Colin McCabe <cmccabe@apache.org>",2019-04-11 08:27:08,Jason Gustafson,Mixed
02221bd907a23041c95ce6446986bff631652b3a,"MINOR: Remove SubscriptionState.Listener and replace with assignmentId tracking (#6559)

We have not had great experience with listeners. They make the code harder to understand because they result in indirectly maintained circular dependencies. Often this leads to tricky deadlocks when we try to introduce locking. We were able to remove the Metadata listener in KAFKA-7831. Here we do the same for the listener in SubscriptionState.

Reviewers: Viktor Somogyi-Vass <viktorsomogyi@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2019-04-11 11:55:14,Jason Gustafson,Mixed
7bd81628d9f6c21649e615e73ed507520fd74fd9,"KAFKA-6635; Producer close awaits pending transactions (#5971)

Currently close() only awaits completion of pending produce requests. If there is a transaction ongoing, it may be dropped. For example, if one thread is calling commitTransaction() and another calls close(), then the commit may never happen even if the caller is willing to wait for it (by using a long timeout). What's more, the thread blocking in commitTransaction() will be stuck since the result will not be completed once the producer has shutdown. 

This patch ensures that 1) completing transactions are awaited, 2) ongoing transactions are aborted, and 3) pending callbacks are completed before close() returns.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-04-15 15:56:36,Viktor Somogyi,Mixed
b7d7f7590de405d8d527c32ca9f067e073e9d83b,"KAFKA-7778: Add KTable.suppress to Scala API (#6314)

Detailed description

* Adds KTable.suppress to the Scala API.
* Fixed count in KGroupedStream, SessionWindowedKStream, and TimeWindowedKStream so that the value serde gets passed down to the KTable returned by the internal mapValues method.
* Suppress API support for Java 1.8 + Scala 2.11

Testing strategy

I added unit tests covering:

* Windowed KTable.count.suppress w/ Suppressed.untilTimeLimit
* Windowed KTable.count.suppress w/ Suppressed.untilWindowCloses
* Non-windowed KTable.count.suppress w/ Suppressed.untilTimeLimit
* Session-windowed KTable.count.suppress w/ Suppressed.untilWindowCloses

Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-04-15 16:27:19,Casey Green,Mixed
47a9871ef65a13f9d58d5ea216de340f7e123da5,"KAFKA-7471: Multiple Consumer Group Management Feature (#5726)

* Describe/Delete/Reset offsets on multiple consumer groups at a time (including each group by repeating `--group` parameter)
* Describe/Delete/Reset offsets on ALL consumer groups at a time (add new `--all-groups` option similar to `--all-topics`)
* Reset plan CSV file generation reworked: structure updated to support multiple consumer groups and make sure that CSV file generation is done properly since there are no restrictions on consumer group names and symbols like commas and quotes are allowed.
* Extending data output table format by adding `GROUP` column for all `--describe` queries",2019-04-15 16:53:28,Alex Dunayevsky,Not TDD
05668e98f531cf4d6ddb0696f0f72675ca128581,"KAFKA-7875: Add KStream.flatTransformValues (#6424)

Adds flatTrasformValues methods in KStream
Adds processor supplier and processor for flatTransformValues
Improves API documentation of transformValues

Reviewers: Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",2019-04-16 12:10:38,cadonna,Mixed
3b1524c5dfd2a94f3fb919dad0de70984963772b,"KAFKA-7466: Add IncrementalAlterConfigs API (KIP-339) (#6247)

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Viktor Somogyi <viktorsomogyi@gmail.com>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>",2019-04-16 16:26:33,Manikumar Reddy,Mixed
0e08358da4b114834140c720b98125a2a3a84caa,"KAFKA-6455: KStream-KStream join should set max timestamp for result record (#6565)

Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-04-17 09:07:25,Matthias J. Sax,Mixed
7f9b9a60dab990efb79df89a6603e78d9ce5a34f,"KAFKA-8241; Handle configs without truststore for broker keystore update (#6585)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2019-04-17 18:17:40,Rajini Sivaram,Mixed
c7836307c3588ed5d267f32eabcd7dfc0dbeec80,"[HOT FIX] Check for null before deserializing in MeteredSessionStore  (#6575)

The fetchSession() method of SessionStore searches for a (single) specific session and returns null if none are found. This is analogous to fetch(key, time) in WindowStore or get(key) in KeyValueStore. MeteredWindowStore and MeteredKeyValueStore both check for a null result before attempting to deserialize, however MeteredSessionStore just blindly deserializes and as a result NPE is thrown when we search for a record that does not exist.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>, Bruno Cadonna <bruno@confluent.io>",2019-04-17 19:21:59,A. Sophie Blee-Goldman,Mixed
3e8a10e7d9a9d5d3d29c8793e30d8401be1588ac,"KAFKA-7026; Sticky Assignor Partition Assignment Improvement (KIP-341) (#5291)

This patch contains the implementation of KIP-341, which adds protection in the sticky assignor from consumers which are joining with a stale assignment. More details can be found in the proposal: https://cwiki.apache.org/confluence/display/KAFKA/KIP-341%3A+Update+Sticky+Assignor%27s+User+Data+Protocol.

Reviewers: Steven Aerts <steven.aerts@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-04-18 08:35:24,Vahid Hashemian,Mixed
48179677a75276b495c59bd429e1f7874dc905b3,"MINOR: Ensure producer state append exceptions areuseful (#6591)

We should include partition/offset information when we raise exceptions during producer state validation. This saves a lot of the discovery work to figure out where the problem occurred. This patch also includes a new test case to verify additional coordinator fencing cases.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2019-04-18 08:38:43,Jason Gustafson,Mixed
6964c356aa0acdb96d5ccb689a088ba224cf41f5,"KAFKA-7866; Ensure no duplicate offsets after txn index append failure (#6570)

This patch fixes a bug in the append logic which can cause duplicate offsets to be appended to the log when the append to the transaction index fails. Rather than incrementing the log end offset after the index append, we do it immediately after the records are written to the log. If the index append later fails, we do two things:

1) We ensure that the last stable offset cannot advance. This guarantees that the aborted data will not be returned to the user until the transaction index contains the corresponding entry.
2) We skip updating the end offset of the producer state. When recovering the log, we will have to reprocess the log and write the index entries.

Reviewers: Jun Rao <junrao@gmail.com>",2019-04-18 08:41:32,Jason Gustafson,Mixed
075b368d47ad3144518e4d425f9155e35f15f418,"KAFKA-6958: Allow to name operation using parameter classes (#6410)

This is the 2nd PR for the KIP-307
Reviewers: Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",2019-04-18 18:45:33,Florian Hussonnois,Mixed
6538e9e4d6c1f64fe3045a5c3fbfe306277a1bee,"KAFKA-7895: fix Suppress changelog restore (#6536)

Several issues have come to light since the 2.2.0 release:
upon restore, suppress incorrectly set the record metadata using the changelog record, instead of preserving the original metadata
restoring a tombstone incorrectly didn't update the buffer size and min-timestamp

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>,  Bruno Cadonna <bruno@confluent.io>,  Bill Bejeck <bbejeck@gmail.com>",2019-04-20 11:08:32,John Roesler,Mixed
e56ebbffca57741d398283e46073ed4170f8f927,"[KAFKA-3729] Auto-configure non-default SerDes passed alongside the topology builder (#6461)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-04-20 11:30:20,Ted Yu,Mixed
409fabc5610443f36574bdea2e2994b6c20e2829,"KAFKA-7747; Check for truncation after leader changes [KIP-320] (#6371)

After the client detects a leader change we need to check the offset of the current leader for truncation. These changes were part of KIP-320: https://cwiki.apache.org/confluence/display/KAFKA/KIP-320%3A+Allow+fetchers+to+detect+and+handle+log+truncation.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-04-21 16:24:18,David Arthur,Mixed
172fbb2dd55144e2e44777174f970b56768e1777,"MINOR: Add unit test for SerDe auto-configuration (#6610)

Reviewers: Guozhang Wang <guozhang@confluent.io>, Ted Yu <yuzhihong@gmail.com>",2019-04-22 10:15:46,Matthias J. Sax,Mixed
7d9e93ac6df511475a159daedc5e32b12a9ebc8b,"MINOR: Use https instead of http in links (#6477)

Verified that the https links work.

I didn't update the license header in this PR since that touches
so many files. Will file a separate one for that.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2019-04-22 11:58:25,Ismael Juma,Not TDD
3000fda8b9800f4cddfc9675dfae11f762aabccc,"KAFKA-8277: Fix NPEs in several methods of ConnectHeaders (#6550)

Replace `headers.isEmpty()` by calls to `isEmpty()` as the latter does a null check on heathers (that is lazily created).

Author: Sebastián Ortega <sebastian.ortega@letgo.com>
Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Arjun Satish <arjunconfluent.io>, Randall Hauch <rhauch@gmail.com>",2019-04-22 14:19:58,Sebastián Ortega,Mixed
58d6043d4c88892f6718e31799503c3482000ea2,"KAFKA-8204: fix Streams store flush order (#6555)

Streams previously flushed stores in the order of their registration, which is arbitrary. Because stores may forward values upon flush (as in cached state stores), we must flush stores in topological order.

Reviewers: Bill Bejeck <bbejeck@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2019-04-22 14:53:51,John Roesler,Mixed
d801c4fc69398ab96fa8a90feb0fb94ffc5d1ac5,"MINOR: Add support for Standalone Connect configs in Rest Server extensions (#6622)

Add support for Standalone Connect configs in Rest Server extensions

A bug was introduced in 7a42750d that was caught in system tests:
The rest extensions fail if a Standalone worker config is passed,
since it does not have a definition for rebalance timeout.
A new method was introduced on WorkerConfig that by default returns
null for the rebalance timeout, and DistributedConfig overloads this
to return the configured value.

Author: Cyrus Vafadari <cyrus@confluent.io>
Reviewers: Arjun Satish <arjunconfluent.io>, Randall Hauch <rhauch@gmail.com>",2019-04-22 22:29:12,Cyrus Vafadari,Mixed
17c80166461c0005b7603414db4d0a3541df0f82,"KAFKA-8237; Untangle TopicDeleteManager and add test cases (#6588)

The controller maintains state across `ControllerContext`, `PartitionStateMachine`, `ReplicaStateMachine`, and `TopicDeletionManager`. None of this state is actually isolated from the rest. For example, topics undergoing deletion are intertwined with the partition and replica states. As a consequence of this, each of these components tends to be dependent on all the rest, which makes testing and reasoning about the system difficult. This is a first step toward untangling all the state. This patch moves it all into `ControllerContext` and removes many of the circular dependencies. So far, this is mostly a direct translation, but in the future we can add additional validation in `ControllerContext` to make sure that state is maintained consistently.

Additionally, this patch adds several mock objects to enable easier testing: `MockReplicaStateMachine` and `MockPartitionStateMachine`. These have simplified logic for updating the current state. This is used to create some new test cases for `TopicDeletionManager`. 

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jun Rao <junrao@gmail.com>",2019-04-24 22:23:15,Jason Gustafson,Mixed
0c2d829249567c6a87140ae25f631a2abad11d00,"KAFKA-7903: automatically generate OffsetCommitRequest (#6583)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2019-04-25 16:42:54,Boyang Chen,Mixed
eecb403bae80b82b6fb7a27bebb5b53d6c8f3115,"KAFKA-8254: Pass Changelog as Topic in Suppress Serdes (#6602)

Reviewers:  Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-04-26 09:30:20,John Roesler,Mixed
0f995ba6be1c0f949320b0879241d9a7c9578436,"KAFKA-7862 & KIP-345 part-one: Add static membership logic to JoinGroup protocol (#6177)

This is the first diff for the implementation of JoinGroup logic for static membership. The goal of this diff contains:

* Add group.instance.id to be unique identifier for consumer instances, provided by end user;
Modify group coordinator to accept JoinGroupRequest with/without static membership, refactor the logic for readability and code reusability.
* Add client side support for incorporating static membership changes, including new config for group.instance.id, apply stream thread client id by default, and new join group exception handling.
* Increase max session timeout to 30 min for more user flexibility if they are inclined to tolerate partial unavailability than burdening rebalance.
* Unit tests for each module changes, especially on the group coordinator logic. Crossing the possibilities like:
6.1 Dynamic/Static member
6.2 Known/Unknown member id
6.3 Group stable/unstable
6.4 Leader/Follower

The rest of the 345 change will be broken down to 4 separate diffs:

* Avoid kicking out members through rebalance.timeout, only do the kick out through session timeout.
* Changes around LeaveGroup logic, including version bumping, broker logic, client logic, etc.
* Admin client changes to add ability to batch remove static members
* Deprecate group.initial.rebalance.delay

Reviewers: Liquan Pei <liquanpei@gmail.com>, Stanislav Kozlovski <familyguyuser192@windowslive.com>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-04-26 11:44:38,Boyang Chen,Mixed
dc31fea8bc06e1fb58a3698e55ab44d765f3dc9f,"MINOR: In-memory stores cleanup (#6595)

While going through the review of InMemorySessionStore I realized there is also some minor cleanup to be done for the other in-memory stores. This includes trivial changes such as removing unnecessary references to 'this' and moving collection initialization to the declaration. It also fixes some unsafe behavior (registering an iterator from inside its own constructor). In-memory window store iterator classes were made static and some instances of KeyValueIterator missing types were fixed across a handful of tests.

Reviewers: Guozhang Wang <wangguoz@gmail.com>,  Bruno Cadonna <bruno@confluent.io>",2019-04-26 11:50:34,A. Sophie Blee-Goldman,Mixed
8299f2a397b6033d60c295a689b7a45fcf413f4a,"KAFKA-8029: In memory session store (#6525)

First pass at an in-memory session store implementation.

Reviewers: Simon Geisler, Damian Guy <damian@confluent.io>, John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-04-26 13:22:35,A. Sophie Blee-Goldman,Mixed
39400c46ac42518374aefdbd42ea57b6795d5a7c,"MINOR: improve Session expiration notice (#6618)

Reviewers: Matthias J. Sax <matthias@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",2019-04-27 14:59:54,John Roesler,Mixed
b4532a65f758448c763b65b2fdde1405db2f9d9d,"KAFKA-8134: `linger.ms` must be a long

Reviewers: Ismael Juma <ismael@juma.me.uk>, Colin P. McCabe <cmccabe@apache.org>",2019-04-29 08:59:17,Dhruvil Shah,Mixed
c5665e6945c8e63ddfb1056c4893f16cae1f6f99,"KAFAK-3522: add API to create timestamped stores (#6601)

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Bruno Cadonna <bruno@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-05-01 09:28:10,Matthias J. Sax,Mixed
56c64803fa190814232c5f71e9a758346c474bb4,"KAFKA-3729: Revert adding Serde auto-config (#6630)

* Revert ""MINOR: Add unit test for SerDe auto-configuration (#6610)""

This reverts commit 172fbb2dd55144e2e44777174f970b56768e1777.

* Revert ""[KAFKA-3729] Auto-configure non-default SerDes passed alongside the topology builder (#6461)""

This reverts commit e56ebbffca57741d398283e46073ed4170f8f927.

The two merged PRs introduce a breaking change. Reverting to preserve backward compatibility. Jira ticket reopened.

Reviewers: Ted Yu <yuzhihong@gmail.com>, Guozhang Wang <guozhang@confluent.io>",2019-05-01 09:33:53,Matthias J. Sax,Mixed
191f2faae07b6608b0601dc2caf204b196a8fc47,"KAFKA-7992: Introduce start-time-ms metric (#6318)

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",2019-05-01 08:58:02,Stanislav Kozlovski,Mixed
ba1fc21864bbd4c1374695890f98ff1fa2614504,"KAFKA-8298: Fix possible concurrent modification exception (#6643)

When processing multiple key-changing operations during the optimization phase a ConcurrentModificationException is possible.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-05-01 12:07:45,Bill Bejeck,Not TDD
6ca899e56d451eef04e81b0f4d88bdb10f3cf4b3,"KAFKA-8066; Always close the sensors in Selector.close() (#6402)

When shutting down the ReplicaFetcher thread, we may fail to unregister sensors in selector.close(). When that happened, we will fail to start up the ReplicaFetcherThread with the same fetch id again because of the IllegalArgumentException in sensor registration. This issue will cause constant URPs in the cluster because the ReplicaFetchterThread is gone.

This patch addresses this issue by introducing a try-finally block in selector.close() so that we will always unregister the sensors in shutting down ReplicaFetcherThreads.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>",2019-05-01 12:40:48,Zhanxiang (Patrick) Huang,Mixed
c34330c5481803c91705cbfcc499021360ff7fdc,"KAFKA-8248; Ensure time updated before sending transactional request (#6613)

This patch fixes a bug in the sending of transactional requests. We need to call `KafkaClient.send` with an updated current time. Failing to do so can result in an `IllegalStateExcepton` which leaves the producer effectively dead since the in-flight correlation id has been set, but no request has been sent. To avoid the same problem in the future, we update the in flight correlationId only after sending the request.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Apurva Mehta <apurva@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-05-02 09:29:22,Jason Gustafson,Mixed
b074173ea249ef028272c2c07358222550917d8c,"KAFKA-8191: Add pluggability of KeyManager to generate the broker Private Keys and Certificates

Reviewers: Sriharsha Chintalapani <sriharsha@apache.org>, Ismael Juma <ismael@juma.me.uk>",2019-05-02 15:11:42,saisandeep,Mixed
a4f7675db1a928e73c7a69eb906dd1e9ecd4a22a,"KAFKA-8285: enable localized thread IDs in Kafka Streams (#6632)

Details in the JIRA: https://issues.apache.org/jira/browse/KAFKA-8285

Basically we want to avoid sharing of atomic updates for thread id with multiple stream instances on one JVM.

Reviewers: Raoul de Haard, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-05-02 17:16:17,Boyang Chen,Mixed
eab855541a4b776b150a849cecda9c758598cdca,"KAFKA-8289: Fix Session Expiration and Suppression (#6654)

Fix two problems in Streams:

* Session windows expired prematurely (off-by-one error), since the window end is inclusive, unlike other windows
* Suppress duration for sessions incorrectly waited only the grace period, but session windows aren't closed until gracePeriod + sessionGap

Update the tests accordingly

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-05-02 17:44:53,John Roesler,Mixed
3ba4686d4d650f0f9155b2e22dddb192a5a56a6c,"KAFKA-7601; Clear leader epoch cache on downgraded format in append (#6568)

During a partial message format upgrade, it is possible for the message format to flap between new and old versions. If we detect that data appended to the log is on an old format, we can clear the leader epoch cache so that we revert to truncation by high watermark. Once the upgrade completes and all replicas are on the same format, we will append to the epoch cache as usual. Note this is related to KAFKA-7897, which handles message format downgrades through configuration. 

Reviewers: Jun Rao <junrao@gmail.com>",2019-05-02 17:46:01,Jason Gustafson,Mixed
6d3ff132b57835fc879d678e9addc5e7c3804205,"KAFKA-8240: Fix NPE in Source.equals() (#6589)

Reviewers: John Roesler <john@confluent.io>, Bruno Cadonna <bruno@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",2019-05-03 10:32:34,Matthias J. Sax,Mixed
a37282415e4e7f682b43abe78517ed18a8dea962,"MINOR: Upgrade dependencies for Kafka 2.3 (#6665)

Many patch and minor updates.

Scalatest and Jetty deprecated classes that we
use. I removed usages for the former and filed KAFKA-8316 for the latter (I
suppressed the relevant deprecation warnings until the JIRA is fixed). As
part of the scalatest fixes, I also removed `TestUtils.fail` since it duplicates
`Assertions.fail`.

I also fixed a few compiler warnings that have crept in since my last sweep.

Updates of note:
- Jetty: 9.4.14 -> 9.4.18
  * https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.15.v20190215
  * https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.16.v20190411
  * https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.17.v20190418
  * https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.17.v20190418
  * https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.18.v20190429
- zstd: 1.3.8-1 -> 1.4.0-1
  * https://github.com/facebook/zstd/releases/tag/v1.4.0
  * zstd's fastest strategy, 6-8% faster in most scenarios
- zookeeper: 3.4.13 -> 3.4.14
  * https://zookeeper.apache.org/doc/r3.4.14/releasenotes.html

### Committer Checklist (excluded from commit message)
- [ ] Verify design and implementation 
- [ ] Verify test coverage and CI build status
- [ ] Verify documentation (including upgrade notes)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2019-05-03 10:35:07,Ismael Juma,Mixed
56b92a550454765b09047be9ad561f3395c614e4,"KAFKA-8306; Initialize log end offset accurately when start offset is non-zero (#6652)

This patch ensures that the log end offset of each partition is initialized consistently with the checkpointed log start offset.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2019-05-04 14:08:16,Dhruvil Shah,Mixed
407bcdf78e06f83f2b358d2cbd96aed348a5c28f,"KAFKA-8056; Use automatic RPC generation for FindCoordinator (#6408)

Reviewers: Jason Gustafson <jason@confluent.io>",2019-05-06 14:26:22,Mickael Maison,Mixed
a6d5efaf0d06f8a66350a8f1b959baf176fd482a,"KAFKA-3522: Interactive Queries must return timestamped stores (#6661)

Reviewers: John Roesler <john@confluent.io>,  Bill Bejeck <bbejeck@gmail.com>",2019-05-07 13:49:31,Matthias J. Sax,Not TDD
889512202c2a2cfba23e358da08747357b60d8ac,"KAFKA-8275; Take throttling into account when choosing least loaded node (#6619)

If a node is currently throttled, we should take it out of the running for `leastLoadedNode`. Additionally, current logic seems to favor connecting to new nodes rather than using existing connections which have one or more in flight requests. The javadoc is slightly vague about whether this is expected, but it seems not.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2019-05-07 13:13:19,Jason Gustafson,Mixed
cc097e909c7e5b1617565e4456f5328a826eafbc,"KAFKA-8304: Fix registration of Connect REST extensions (#6651)

Fix registration of Connect REST extensions to prevent deadlocks when extensions get the list of connectors before the herder is available. Added integration test to check the behavior.

Author: Chris Egerton <cegerton@oberlin.edu>
Reviewers: Arjun Satish <arjun@confluent.io>, Randall Hauch <rhauch@gmail.com>",2019-05-07 17:20:51,Chris Egerton,Mixed
b0e82a68b34512d23a5a60a9b5da0db86eb880b2,"KAFKA-8284: enable static membership on KStream (#6673)

Part of KIP-345 effort. The strategy is to extract user passed in group.instance.id config and pass it in with given thread-id (because consumer is currently per-thread level).

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-05-07 17:43:13,Boyang Chen,Mixed
5144660040839cee6e213b5146c1ae44340eddb0,"KAFKA-8158: Add EntityType for Kafka RPC fields (#6503)

Reviewers: Jason Gustafson <jason@confluent.io>",2019-05-07 21:35:17,Colin Patrick McCabe,Mixed
83823aedf2e2d176004402152b69bd67f97d8e12,"BUGFIX: Add missing recording of close of stand-by task (#6663)

Adds recording of close of a stand-by task to the task-closed metric
Adds unit tests to verify the recording

Reviewers: Guozhang Wang <wangguoz@gmail.com>, John Roesler <john@confluent.io>",2019-05-08 11:26:25,cadonna,Mixed
e6cff21fd8c5add0eb7e55417a91f0530a7d3a32,"KAFKA-7320; Add consumer configuration to disable auto topic creation [KIP-361] (#5542)

Implements KIP-361 to provide a consumer configuration to specify whether subscribing or assigning a non-existent topic would result in it being automatically created or not.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-05-08 09:31:05,Dhruvil Shah,Mixed
c09e25fac2aaea61af892ae3e5273679a4bdbc7d,"MINOR: Fix bug in Struct.equals and use Objects.equals/Long.hashCode (#6680)

* Fixed bug in Struct.equals where we returned prematurely and added tests
* Update RequestResponseTest to check that `equals` and `hashCode` of
the struct is the same after serialization/deserialization only when possible.
* Use `Objects.equals` and `Long.hashCode` to simplify code
* Removed deprecated usages of `JUnitTestSuite`

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2019-05-09 06:21:24,Ismael Juma,Mixed
a97e55b83868ff786e740db55e73116f85456dcb,"KAFKA-8332: Refactor ImplicitLinkedHashSet to avoid losing ordering when converting to Scala

Because of how conversions between Java collections and Scala collections work, ImplicitLinkedHashMultiSet objects were being treated as unordered in some contexts where they shouldn't be.  This broke JOIN_GROUP handling.  

This patch renames ImplicitLinkedHashMultiSet to ImplicitLinkedHashMultCollection.  The order of Collection objects will be preserved when converting to scala.  Adding Set and List ""views"" to the Collection gives us a more elegant way of accessing that functionality when needed.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2019-05-09 11:08:22,Bob Barrett,Mixed
5a8d74e151e4472d5e5b4541972f5515e4f138ff,"KAFKA-6789; Handle retriable group errors in AdminClient API (#5578)

This patch adds support to retry all group operations after COORDINATOR_LOAD_IN_PROGRESS and COORDINATOR_NOT_AVAILABLE in AdminClient group operations. Previously we only had logic to retry after FindCoordinator failures.

Reviewers: Yishun Guan <gyishun@gmail.com>, Viktor Somogyi <viktorsomogyi@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-05-09 15:31:10,Manikumar Reddy,Mixed
36a5aba4ecf56631372ad12d5c67af8fa3de05f8,"KAFKA-8231: Expansion of ConnectClusterState interface (#6584)

Expand ConnectClusterState interface and implementation with methods that provide the immutable cluster details and the connector configuration. This includes unit tests for the new methods.

Author: Chris Egerton <cegerton@oberlin.edu>
Reviews: Arjun Satish <arjun@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>",2019-05-09 20:27:59,Chris Egerton,Mixed
4c85171a1f1219bb735be3ca034640e298fda0dc,"KAFKA-7633: Allow Kafka Connect to access internal topics without cluster ACLs (#5918)

When Kafka Connect does not have cluster ACLs to create topics,
it fails to even access its internal topics which already exist.
This was originally fixed in KAFKA-6250 by ignoring the cluster
authorization error, but now Kafka 2.0 returns a different response
code that corresponds to a different error. Add a patch to ignore this
new error as well.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-05-11 11:05:37,Arabelle Hou,Mixed
8649717d6dde081c75fc441a56f63ee1556dc758,"KAFKA-6521: Use timestamped stores for KTables (#6667)

Reviewers: John Roesler <john@confluent.io>, Boyang Chen <boyang@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-05-12 11:50:55,Matthias J. Sax,Mixed
8a237f599afa539868a138b5a2534dbf884cb4ec,"KAFKA-6455: Session Aggregation should use window-end-time as record timestamp (#6645)

For session-windows, the result record should have the window-end timestamp as record timestamp.

Rebased to resolve merge conflicts. Removed unused classes TupleForwarder and ForwardingCacheFlushListener (replace with TimestampedTupleForwarder, SessionTupleForwarder, TimestampedCacheFlushListerner, and SessionCacheFlushListener)

Reviewers: John Roesler <john@confluent.io>, Bruno Cadonna <bruno@confluent.io>, Boyang Chen <boyang@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-05-12 15:31:44,Matthias J. Sax,Mixed
d798dbf497d91509517c60d67ceeea02e2b9b383,"KAFKA-8335; Clean empty batches when sequence numbers are reused (#6715)

The log cleaner attempts to preserve the last entry for each producerId in order to ensure that sequence/epoch state is not lost. The current validation checks only the last sequence number for each producerId in order to decide whether a batch should be retained. There are two problems with this:

1. Sequence numbers are not unique alone. It is the tuple of sequence number and epoch which is uniquely defined.
2. The group coordinator always writes batches beginning with sequence number 0, which means there could be many batches which have the same sequence number.

The complete fix for the second issue would probably add proper sequence number bookkeeping in the coordinator. For now, we have left the coordinator implementation unchanged and changed the cleaner logic to use the last offset written by a producer instead of the last sequence number. 

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-05-13 08:47:53,Jason Gustafson,Mixed
1fdc8533016e948b1d534145978252209d7612ed,"KAFKA-7321: Add a Maximum Log Compaction Lag (KIP-354) (#6009)

KAFKA-7321: Add a Maximum Log Compaction Lag (KIP-354)
Records become eligible for compaction after the specified time interval.

Author: Xiongqi Wu <xiowu@linkedin.com>
Reviewer: Joel Koshy <jjkoshy@gmail.com>",2019-05-13 09:16:12,Xiongqi Wu,Mixed
63e4f67d9ba9e08bdce705b35c5acf32dcd20633,"MINOR: Throw ProducerFencedException directly but with a new instance (#6717)

Currently in maybeFailWithError, we always wrap the lastError as a KafkaException. For ProducerFencedException however, we should just throw the exception itself; however we throw a new instance since the previous book-kept one's call trace is not from this call, and hence could be confusing.

Reviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@conflent.io>",2019-05-13 13:36:26,Guozhang Wang,Mixed
e4007a6408236d9b52b355fcf3c3a80fe5f570ff,"KAFKA-8294; Batch StopReplica requests when possible and improve test coverage (#6642)

The main problem we are trying to solve here is the batching of StopReplica requests and the lack of test coverage for `ControllerChannelManager`. Addressing the first problem was straightforward, but the second problem required quite a bit of work because of the dependence on `KafkaController` for all of the events. It seemed to make sense to separate the events from the processing of events so that we could remove this dependence and improve testability. With the refactoring, I was able to add test cases covering most of the logic in `ControllerChannelManager` including the generation of requests and the expected response handling logic. Note that I have not actually changed any of the event handling logic in `KafkaController`.

While refactoring this logic, I found that the event queue time metric was not being correctly computed. The problem is that many of the controller events were singleton objects which inherited the `enqueueTimeMs` field from the `ControllerEvent` trait. This would never get updated, so queue time would be skewed.

Reviewers: Jun Rao <junrao@gmail.com>",2019-05-13 18:58:42,Jason Gustafson,Mixed
e2f6a9c74723328d384f7a9669b9027521b612d6,"KAFKA-8363: Fix parsing bug for config providers (#6726)

Author: Chris Egerton <cegerton@oberlin.edu>
Reviewers: Robert Yokota <rayokota@gmail.com>, Randall Hauch <rhauch@gmail.com>",2019-05-14 14:32:54,Chris Egerton,Mixed
d92eb0d8d85cc24256499eff97672141493fb90b,"KIP-421: Support for resolving externalized secrets in AbstractConfig (#6467)

Updated AbstractConfig to be able to resolve variables in config values when the configuration includes config provider properties.

Author: Tejal Adsul <tejal@confluent.io>
Reviewers: Rajini Sivaram <rajinisivaram@gmail.com>, Randall Hauch <rhauch@gmail.com>",2019-05-14 21:11:07,tadsul,Mixed
050fdd6537fcfb640277ff5e1607e44d18c0d95f,"KAFKA-8336; Enable dynamic reconfiguration of broker's client-side certs (#6721)

Enable reconfiguration of SSL keystores and truststores in client-side channel builders used by brokers for controller, transaction coordinator and replica fetchers. This enables brokers using TLS mutual authentication for inter-broker listener to use short-lived certs that may be updated before expiry without restarting brokers.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2019-05-15 09:17:10,Rajini Sivaram,Not TDD
0494cd329f3aaed94b3b46de0abe495f80faaedd,"MINOR: Refactor SslFactory (#6674)

SslFactory: split the part of SslFactory that creates SSLEngine instances into SslEngineBuilder.  When (re)configuring, we simply create a new SslEngineBuilder.  This allows us to make all the builder fields immutable.  It also simplifies the logic for reconfiguring.  Because we sometimes need to test old SslEngine instances against new ones, being able to use both the old and the new builder at once is useful.

Create an enum named SslClientAuth which encodes the possible values for ssl.client.auth.  This will simplify the handling of this configuration.

SslTransportLayer#maybeProcessHandshakeFailure should treat an SSLHandshakeException with a ""Received fatal alert"" message as a handshake error (and therefore an authentication error.)

SslFactoryTest: add some line breaks for very long lines.

ConfigCommand#main: when terminating the command due to an uncaught exception, log the exception using debug level in slf4j, in addition to printing it to stderr.  This makes it easier to debug failing junit tests, where stderr may not be kept, or may be reordered with respect to other slf4j messages.  The use of debug level is consistent with how we handle other types of exceptions in ConfigCommand#main.

StateChangeLogMerger#main: spell out the full name of scala.io.Source rather than abbreviating it as io.Source.  This makes it clearer that it is part of the Scala standard library.  It also avoids compiler errors when other libraries whose groupId starts with ""io"" are used in the broker.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2019-05-15 13:52:59,Colin Patrick McCabe,Mixed
fbb09952ac5a42b32042e32cde95e48c22ba129a,"KAFKA-5061 - Make default Worker Task client IDs distinct (#6097)

Use the task ID to make the default client IDs used by Worker Tasks distinct and stable. This is avoids name conflicts on JMX MBeans and enables useful monitoring.

This implements https://cwiki.apache.org/confluence/display/KAFKA/KIP-411%3A+Make+default+Kafka+Connect+worker+task+client+IDs+distinct.

See: https://issues.apache.org/jira/browse/KAFKA-5061

Author: Paul Davidson <>
Reviewer: Cyrus Vafadari <cyrusv@alum.mit.edu>, Arjun Satish <arjun@confluent.io>, Randall Hauch <rhauch@gmail.com>",2019-05-15 17:02:35,Paul Davidson,Mixed
2208f9966d31a3f52bf9b63938bd6f3729378d9b,"KAFKA-8354; Replace Sync group request/response with automated protocol (#6729)

Update SyncGroup API to use the generated protocol classes.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-05-15 15:09:00,Boyang Chen,Mixed
b395ef418237a37b95d6452f0111998f63c047db,"KAFKA-3816: Add MDC logging to Connect runtime (#5743)

See https://cwiki.apache.org/confluence/display/KAFKA/KIP-449%3A+Add+connector+contexts+to+Connect+worker+logs

Added LoggingContext as a simple mechanism to set and unset Mapped Diagnostic Contexts (MDC) in the loggers to provide for each thread useful parameters that can be used within the logging configuration. MDC avoids having to modify lots of log statements, since the parameters are available to all log statements issued by the thread, no matter what class makes those calls.

The design intentionally minimizes the number of changes to any existing classes, and does not use Java 8 features so it can be easily backported if desired, although per this KIP it will be applied initially only in AK 2.3 and later and must be enabled via the Log4J configuration.

Reviewers: Jason Gustafson <jason@conflent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-05-16 12:35:01,Randall Hauch,Mixed
6e6dcceb9325a919650e016adde4a02cf87f7529,"KAFKA-8220; Avoid kicking out static group members through rebalance timeout (#6666)

To make static consumer group members more persistent, we want to avoid kicking out unjoined members through rebalance timeout. Essentially we allow static members to participate in a rebalance using their old subscription without sending a JoinGroup. The only catch is that an unjoined static member might be the current group leader, and we may need to elect a different leader.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>",2019-05-16 06:10:24,Boyang Chen,Mixed
80784271043d2da8e93055a5f9b1bcfd53347461,"KAFKA-8347: Choose next record to process by timestamp (#6719)

When choosing the next record to process, we should look at the head record's timestamp of each partition and choose the lowest rather than choosing the lowest of the partition's streamtime.

This change effectively makes RecordQueue return the timestamp of the head record rather than its streamtime. Streamtime is removed (replaced) from RecordQueue as it was only being tracked in order to choose the next partition to poll from.

Reviewers: Matthias J. Sax <mjsax@apache.org>,  Bill Bejeck <bbejeck@gmail.com>",2019-05-16 10:07:53,A. Sophie Blee-Goldman,Mixed
16b408898e75b00ddf6b607246833cdbcd56f507,"KAFAK-3522: Add TopologyTestDriver unit tests (#6179)

Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>",2019-05-16 16:16:00,Matthias J. Sax,Not TDD
855f899bb523f3b334f711926a7db4cc75ebb4b4,"KAFKA-8256; Replace Heartbeat request/response with automated protocol (#6691)

Reviewers: Boyang Chen <bchen11@outlook.com>, Jason Gustafson <jason@confluent.io>",2019-05-16 13:08:49,Mickael Maison,Mixed
26814e060e98f9674127be13a28ce41a21ca6b3c,"KAFKA-8376; Least loaded node should consider connections which are being prepared (#6746)

This fixes a regression caused by KAFKA-8275. The least loaded node selection
should take into account nodes which are currently being connect to. This
includes both the CONNECTING and CHECKING_API_VERSIONS states since
`canSendRequest` would return false in either case.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2019-05-16 13:37:19,Jason Gustafson,Mixed
5a95c2e1cd555d5f3ec148cc7c765d1bb7d716f9,"Add '?expand' query param for additional info on '/connectors'. (#6658)

Per KIP-465, kept existing behavior of `/connectors` resource in the Connect's REST API, but added the ability to specify `?expand` query parameter to get list of connectors with status details on each connector. Added unit tests, and verified passing existing system tests (which use the older list form).

See https://cwiki.apache.org/confluence/display/KAFKA/KIP-465%3A+Add+Consolidated+Connector+Endpoint+to+Connect+REST+API.

Author: Dan Norwood <norwood@confluent.io>
Reviewer: Randall Hauch <rhauch@gmail.com>",2019-05-16 16:29:29,dan norwood,Mixed
ce584a01fff4e73afa96d38c9a7508fcd67e3e46,"KAFKA-5505: Incremental cooperative rebalancing in Connect (KIP-415) (#6363)

Added the incremental cooperative rebalancing in Connect to avoid global rebalances on all connectors and tasks with each new/changed/removed connector. This new protocol is backward compatible and will work with heterogeneous clusters that exist during a rolling upgrade, but once the clusters consist of new workers only some affected connectors and tasks will be rebalanced: connectors and tasks on existing nodes still in the cluster and not added/changed/removed will continue running while the affected connectors and tasks are rebalanced.

This commit attempted to minimize the changes to the existing V0 protocol logic, though that was not entirely possible.

This commit adds extensive unit and integration tests for both the old V0 protocol and the new v1 protocol. Soak testing has been performed multiple times to verify behavior while connectors and added, changed, and removed and while workers are added and removed from the cluster.

Author: Konstantine Karantasis <konstantine@confluent.io>
Reviewers: Randall Hauch <rhauch@gmail.com>, Ewen Cheslack-Postava <me@ewencp.org>, Robert Yokota <rayokota@gmail.com>, David Arthur <mumrah@gmail.com>, Ryanne Dolan <ryannedolan@gmail.com>",2019-05-16 22:46:03,Konstantine Karantasis,Mixed
2e91a310d7bf9e7d4d46b0bc0ca0c11cb4531e10,"KAFKA-8265: Initial implementation for ConnectorClientConfigPolicy to enable overrides (KIP-458) (#6624)

Implementation to enable policy for Connector Client config overrides. This is
implemented per the KIP-458.

Reviewers: Randall Hauch <rhauch@gmail.com>",2019-05-17 01:37:32,Magesh Nandakumar,Mixed
64c2d49cf5c8b1cecbd7601dc2d1577fc606ab1e,"MINOR: Add test for ConsumerNetworkClient.trySend (#6739)

Reviewers: Jason Gustafson <jason@confluent.io>",2019-05-17 08:06:06,Shaobo Liu,Mixed
16769d263e2e8fd91704d2e3519abf9dcba507df,"KAFKA-8215: Upgrade Rocks to v5.18.3 (#6743)

This upgrade exposes a number of new options, including the WriteBufferManager which -- along with existing TableConfig options -- allows users to limit the total memory used by RocksDB across instances. This can alleviate some cascading OOM potential when, for example, a large number of stateful tasks are suddenly migrated to the same host.

The RocksDB docs guarantee backwards format compatibility across versions

Reviewers: Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bbejeck@gmail.com>,",2019-05-17 16:32:17,A. Sophie Blee-Goldman,Mixed
9077d83672a4d08273ce4a6012f1787f5313f948,"MINOR: Add select changes from 3rd KIP-307 PR for incrementing name index counter (#6754)

When users provide a name for operation via the Streams DSL, we need to increment the counter used for auto-generated names to make sure any operators downstream of a named operator still produce a compatible name.

This PR is a subset of #6411 by @fhussonnois. We need to merge this PR now because it covers cases when users name repartition topics or state stores.

Updated tests to reflect the counter produces expected number even when the user provides a name.

Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>",2019-05-17 18:10:11,Bill Bejeck,Mixed
414852c701763b6f8362b44d156753b6c3ef247a,"KAFKA-8346; Improve replica fetcher behavior for handling partition failure [KIP-461] (#6716)

The replica fetcher thread is terminated in case a partition crashes which leads to under replication. This behavior can be improved by dropping the failed partition. The thread can continue monitoring the rest of the partitions. If all partitions of a thread have failed, the thread would be shut down. This is documented in KIP-461: https://cwiki.apache.org/confluence/display/KAFKA/KIP-461+-+Improve+Replica+Fetcher+behavior+at+handling+partition+failure.

Reviewers: Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-05-17 15:39:20,Aishwarya Gune,Mixed
6a2749faa63397caa93dae7bfdc3f1d0573a2ff4,"KAFKA-6455: Improve DSL operator timestamp semantics (#6725)

Basic idea:
KTable-KTable join: set max(left-ts,right-ts) for result
#agg(...) (stream/table windowed/non-windowed): set max(ts1, ts2, ts3,...) of all input records that contribute to the aggregation result
for all stateless transformation: input-ts -> output-ts

Reviewers: Guozhang Wang <wangguoz@gmail.com>,  John Roesler <john@confluent.io>, Andy Coates <andy@confluent.io>,  Bill Bejeck <bbejeck@gmail.com",2019-05-17 19:48:07,Matthias J. Sax,Mixed
e2847e8603fe19a87ff03584fb38954e4bd3a59e,"KAFKA-8365; Consumer and protocol support for follower fetching (#6731)

This patch includes API changes for follower fetching per [KIP-392](https://cwiki.apache.org/confluence/display/KAFKA/KIP-392%3A+Allow+consumers+to+fetch+from+closest+replica) as well as the consumer implementation. After this patch, consumers will continue to fetch only from the leader, since the broker implementation to select an alternate read replica is not included here.

Adds new `client.rack` consumer configuration property is added which allows the consumer to indicate its rack. This is just an arbitrary string to indicate some relative location, it doesn't have to actually represent a physical rack. We are keeping the naming consistent with the broker property (`broker.rack`).

FetchRequest now includes `rack_id` which can optionally be specified by the consumer. FetchResponse includes an optional `preferred_read_replica` field for each partition in the response. OffsetForLeaderEpochRequest also adds new `replica_id` field which is similar to the same field in FetchRequest.

When the consumer sees a `preferred_read_replica` in a fetch response, it will use the Node with that ID for the next fetch.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-05-17 22:45:45,David Arthur,Mixed
9fa331b811d893a0d580e9136c1c7e1fa9774542,"KAFKA-8225 & KIP-345 part-2: fencing static member instances with conflicting group.instance.id (#6650)

For static members join/rejoin, we encode the current timestamp in the new member.id. The format looks like group.instance.id-timestamp.

During consumer/broker interaction logic (Join, Sync, Heartbeat, Commit), we shall check the whether group.instance.id is known on group. If yes, we shall match the member.id stored on static membership map with the request member.id. If mismatching, this indicates a conflict consumer has used same group.instance.id, and it will receive a fatal exception to shut down.

Right now the only missing part is the system test. Will work on it offline while getting the major logic changes reviewed.

Reviewers: Ryanne Dolan <ryannedolan@gmail.com>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-05-18 07:28:36,Boyang Chen,Mixed
e00c0d316db01fbe5e57a4dfd54856c89e761b08,"MINOR: Fix typo in heartbeat request protocol definition (#6759)

This changes the field ""generationid"" to ""generationId"" to be consistent with other uses.

Reviewers: Shaobo Liu <lambda.tencent@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-05-18 16:19:59,Boyang Chen,Mixed
11a8a8d274a16ee2aa8271efc1f7418499372e31,"KAFKA-8290: Close producer for zombie task (#6636)

When we close a task and EOS is enabled we should always close the producer regardless if the task is in a zombie state (the broker fenced the producer) or not.

I've added tests that fail without this change.

Reviewers: Matthias J. Sax <mjsax@apache.org>, Jason Gustafson <jason@confluent.io>",2019-05-20 09:02:25,Bill Bejeck,Mixed
614ea55ad7495c3abcc5942caaf5274ad4029327,"KAFKA-8381; Disable hostname validation when verifying inter-broker SSL (#6757)

- Make endpoint validation configurable on SslEngineBuilder when creating an engine
- Disable endpoint validation for engines created for inter-broker SSL validation since it is unsafe to use `localhost`
- Use empty hostname in validation engine to ensure tests fail if validation is re-enabled by mistake
- Add tests to verify inter-broker SSL validation

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2019-05-20 16:24:11,Rajini Sivaram,Not TDD
b43f5446acd36eb60554e57f5b9bdb415395f2d1,"KAFKA-8316; Remove deprecated usage of Slf4jRequestLog, SslContextFactory (#6668)

* Remove deprecated class Slf4jRequestLog: use Slf4jRequestLogWriter, CustomRequestLog instread.

1. Remove '@SuppressWarnings(""deprecation"")' from RestServer#initializeResources, JsonRestServer#start.
2. Remove unused JsonRestServer#httpRequest.

* Fix deprecated class usage: SslContextFactory -> SslContextFactory.[Server, Client]

1. Split SSLUtils#createSslContextFactory into SSLUtils#create[Server, Client]SideSslContextFactory: each method instantiates SslContextFactory.[Server, Client], respectively.
2. SSLUtils#configureSslContextFactoryAuthentication is called from SSLUtils#createServerSideSslContextFactory only.
3. Update SSLUtilsTest following splittion; for client-side SSL Context Factory, SslContextFactory#get[Need, Want]ClientAuth is always false. (SSLUtilsTest#testCreateClientSideSslContextFactory)

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2019-05-20 10:15:15,Lee Dongjin,Mixed
d77bac1c930afc7b7247f9a1a66b666801ae7798,"KAFKA-3143: Controller should transition offline replicas on startup

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>

Closes #5041 from omkreddy/KAFKA-3143",2019-05-21 20:48:49,Manikumar Reddy,Mixed
012880d4246fedb5c1ea7621e86217c57fd217e2,"KAFKA-8052; Ensure fetch session epoch is updated before new request (#6582)

Reviewers: Jason Gustafson <jason@confluent.io>, Colin Patrick McCabe <cmccabe@confluent.io>, Andrew Olson <aolson1@cerner.com>, José Armando García Sancio <jsancio@users.noreply.github.com>",2019-05-21 21:46:04,Rajini Sivaram,Mixed
bacb45e044aae61fd373f6535f8073263c972370,"MINOR: Set `replicaId` for OffsetsForLeaderEpoch from followers (#6775)

Reviewers: Jason Gustafson <jason@confluent.io>",2019-05-21 15:50:21,David Arthur,Mixed
4f110905975188d0855dc0c7b168724679aae97d,"HOTFIX: Fix recent protocol breakage from KIP-345 and KIP-392 (#6780)

KIP-345 and KIP-392 introduced a couple breaking changes for old versions of bumped protocols. This patch fixes them.

Reviewers: Colin Patrick McCabe <cmccabe@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Boyang Chen <bchen11@outlook.com>, Guozhang Wang <wangguoz@gmail.com>",2019-05-21 22:51:56,Jason Gustafson,Mixed
cafdc1e7df7725c92a374ba9528f7974fe592196,"KAFKA-8399: bring back internal.leave.group.on.close config for KStream (#6779)

As title states. We plan to merge this to both trunk and 2.3 if it could fix the stream system tests globally.
Reference implementation: #6673

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>",2019-05-22 11:03:00,Boyang Chen,Mixed
5f06999cf370ddd773b30f5d707c37c6087fa755,"MINOR: Remove ControllerEventManager metrics on close (#6788)

Remove created metrics when shutting down `ControllerEventManager`. This fixes transient failures in `ControllerEventManagerTest.testEventQueueTime` and is generally good hygiene.

Reviewers: José Armando García Sancio <jsancio@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2019-05-22 15:51:25,Jason Gustafson,Mixed
89f331eac3aaeab53a3b36bc437eba5f6213ca91,"KAFKA-8229; Reset WorkerSinkTask offset commit interval after task commit (#6579)

Prior to this change, the next commit time advances
_each_ time a commit happens -- including when a commit happens
because it was requested by the `Task`. When a `Task` requests a
commit several times, the clock advances far into the future
which prevents expected periodic commits from happening.

This commit changes the behavior, we reset `nextCommit` relative
to the time of the commit.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-05-22 23:50:48,sdreynolds,Mixed
4574b2438a82115c5ec3ca3c381270b06fc2a8e3,"MINOR: Remove checking on original joined subscription within handleAssignmentMismatch (#6782)

When consumer coordinator realize the subscription may have changed, today we check again against the joinedSubscription within handleAssignmentMismatch. This checking however is a bit fishy and over-kill as well. It's better just simplifying it to always request re-join.

The joinedSubscription object itself however still need to be maintained for potential augment to avoid extra re-joining the group.

Since testOutdatedCoordinatorAssignment already cover the normal case we also remove the other invalidAssignment test case.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-05-23 11:38:10,Guozhang Wang,Mixed
68a3eb373b5e176468ba5b9c045f327eb75f5f19,"KAFKA-8415: Interface ConnectorClientConfigOverridePolicy needs to be excluded from class loading isolation (#6796)

Author: Konstantine Karantasis <konstantine@confluent.io>
Reviewer: Randall Hauch <rhauch@gmail.com>",2019-05-23 14:14:09,Konstantine Karantasis,Mixed
5351efe48ac71318fbbca21ac280c43921267744,"KAFKA-8407: Fix validation of class and list configs in connector client overrides (#6789)

Because of how config values are converted into strings in the `AbstractHerder.validateClientOverrides()` method after being validated by the client override policy, an exception is thrown if the value returned by the policy isn't already parsed as the type expected by the client `ConfigDef`. The fix here involves parsing client override properties before passing them to the override policy.

A unit test is added to ensure that several different types of configs are validated properly by the herder.

Author: Chris Egerton <chrise@confluent.io>
Reviewers: Magesh Nandakumar <magesh.n.kumar@gmail.com>, Randall Hauch <rhauch@gmail.com>",2019-05-23 14:21:19,Chris Egerton,Mixed
3696b9882d0267871a31fc3df03da568b59433b7,"KAFKA-8371: Remove dependence on ReplicaManager from Partition (#6705)

This patch attempts to simplify the interaction between Partition and the various components from `ReplicaManager`. This is primarily to make unit testing easier. I have also tried to eliminate the OfflinePartition sentinel which has always been unsafe.

Reviewers: Boyang Chen <bchen11@outlook.com>, David Arthur <mumrah@gmail.com>",2019-05-23 13:20:39,Jason Gustafson,Mixed
c823f32070e19dbdeaf200259777aab668bc012c,"MINOR: Add 2.0, 2.1 and 2.2 to broker and client compat tests

These are important to ensure we don't break compatibility.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Gwen Shapira

Closes #6794 from ijuma/update-version-compat-tests",2019-05-23 13:34:00,Ismael Juma,Not TDD
eefb25d4ca12a9c33ad654bf789eee4d451ebb0d,"MINOR: Fix a few compiler warnings (#6767)

Reviewers: Boyang Chen <bchen11@outlook.com>, Jason Gustafson <jason@confluent.io>",2019-05-24 00:11:04,Lee Dongjin,Not TDD
46a02f3231cd6d340c622636159b9f59b4b3cb6e,"KAFKA-8341. Retry Consumer group operation for NOT_COORDINATOR error (#6723)

An API call for consumer groups must send a FindCoordinatorRequest to find the consumer group coordinator, and then send a follow-up request to that node.  But the coordinator might move after the FindCoordinatorRequest but before the follow-up request is sent.  In that case we currently fail.

This change fixes that by detecting this error and then retrying.  This fixes listConsumerGroupOffsets, deleteConsumerGroups, and describeConsumerGroups.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Boyang Chen <bchen11@outlook.com>",2019-05-24 17:20:22,soondenana,Mixed
5ecac84cd8b5cb7be701e0cbcc53b37f41b50d60,"MINOR: Fix `toString` NPE in tableProcessorNode (#6807)

This gets hit when debug logging is enabled.

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-05-24 21:18:25,Rohan,Mixed
a1808962e56eaaa3657298baad3fc09abcc49040,"KAFKA-8422; Client should send OffsetForLeaderEpoch only if broker supports latest version (#6806)

In the olden days, OffsetForLeaderEpoch was exclusively an inter-broker protocol and
required Cluster level permission. With KIP-320, clients can use this API as well and
so we lowered the required permission to Topic Describe. The only way the client can
be sure that the new permissions are in use is to require version 3 of the protocol
which was bumped for 2.3. If the broker does not support this version, we skip the
validation and revert to the old behavior.

Additionally, this patch fixes a problem with the newly added replicaId field when
parsed from older versions which did not have it. If the field was not present, then
we used the consumer's sentinel value, but this would limit the range of visible
offsets by the high watermark. To get around this problem, this patch adds a
separate ""debug"" sentinel similar to APIs like Fetch and ListOffsets.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2019-05-24 21:29:51,Jason Gustafson,Mixed
6afb0ca735cd5c1a559d496247559d21bcadcb6c,"KAFKA-8351; Cleaner should handle transactions spanning multiple segments (#6722)

When cleaning transactional data, we need to keep track of which transactions still have data associated with them so that we do not remove the markers. We had logic to do this, but the state was not being carried over when beginning cleaning for a new set of segments. This could cause the cleaner to incorrectly believe a transaction marker was no longer needed. The fix here carries the transactional state between groups of segments to be cleaned.

Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Viktor Somogyi <viktorsomogyi@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-05-24 23:10:56,Jason Gustafson,Mixed
e6057e5038c2b681152d2608d551db675960d12a,"KAFKA-8437; Await node api versions before checking if offset validation is possible (#6823)

The consumer should await api version information before determining whether the broker supports offset validation. In KAFKA-8422, we skip the validation if we don't have api version information, which means we always skip validation the first time we connect to a node. This bug was detected by the failing system test `tests/client/truncation_test.py`. The test passes again with this fix.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2019-05-27 14:22:39,Jason Gustafson,Mixed
94195f8643670069545cbe948d4bafa8b291d2f9,"HOTFIX: Fix wrong setting of Serde in `MeteredTimestampWindowStore` (#6808)

Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>,  Bill Bejeck <bbejeck@gmail.com>",2019-05-28 11:50:11,cadonna,Not TDD
24f664aa1621dc70794fd6576ac99547e41d2113,"MINOR: Auth operations must be null when talking to a pre-KIP-430 broker (#6812)

Authorized operations must be null when talking to a pre-KIP-430 broker.
If we present this as the empty set instead, it is impossible for clients
to know if they have no permissions, or are talking to an old broker.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2019-05-28 11:22:09,Colin Patrick McCabe,Mixed
88619b7dd85acd79c111cfdc90a594cb5c2cf96e,"MINOR: improve error message for Serde type miss match (#6801)

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Boyang Chen <boyang@confluent.io>",2019-05-28 11:33:12,Matthias J. Sax,Mixed
901eb3688337a0e173ef7fcff9b3384926520c08,"MINOR: Set default `group.instance.id` in JoinGroupResponse to null (#6831)

As we are planning to add on more supporting features for rebalancing under static membership, we need to make sure the behavior for `group.instance.id` is consistent throughout the whole stack. This patch ensures that the default value is null in the JoinGroup response.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-05-28 13:55:38,Boyang Chen,Not TDD
592410fc585ad72934fef2cef8624b8146fedf3d,"KAFKA-8428: Always require a single batch with un- / compressed messages (#6816)

I think it's better just to make single-batch as a universal requirement for all versions for compressed messages, and for V2 and beyond uncompressed messages as well.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-05-28 21:37:52,Guozhang Wang,Mixed
121308cc7a2639a70fc8a60c99d2eaee52931951,"KAFKA-8286; Generalized Leader Election Admin RPC (KIP-460) (#6686)

Implements KIP-460: https://cwiki.apache.org/confluence/display/KAFKA/KIP-460%3A+Admin+Leader+Election+RPC.

Reviewers: Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-05-29 10:44:52,José Armando García Sancio,Mixed
e82e2e723a8a71e5e0a73af4ce408e60065c1356,"KAFKA-7703; position() may return a wrong offset after seekToEnd (#6407)

When poll is called which resets the offsets to the beginning, followed by a seekToEnd and a position, it could happen that the ""reset to earliest"" call in poll overrides the ""reset to latest"" initiated by seekToEnd in a very delicate way: 

1. both request has been issued and returned to the client side (listOffsetResponse has happened)
2. in Fetcher.resetOffsetIfNeeded(TopicPartition, Long, OffsetData) the thread scheduler could prefer the heartbeat thread with the ""reset to earliest"" call, overriding the offset to the earliest and setting the SubscriptionState with that position.
3. The thread scheduler continues execution of the thread (application thread) with the ""reset to latest"" call and discards it as the ""reset to earliest"" already set the position - the wrong one.
4. The blocking position call returns with the earliest offset instead of the latest, despite it wasn't expected.

The fix makes SubscriptionState synchronized so that we can verify that the reset is expected while holding the lock. 

Reviewers: Jason Gustafson <jason@confluent.io>",2019-05-29 15:59:08,Viktor Somogyi,Mixed
9f1ce60a9c0eae99388504349870018f0dd55afa,"KAFKA-8187: Add wait time for other thread in the same jvm to free the locks (#6818)

Fix KAFKA-8187: State store record loss across multiple reassignments when using standby tasks.
Do not let the thread to transit to RUNNING until all tasks (including standby tasks) are ready.

Reviewers: Guozhang Wang <wangguoz@gmail.com>,  Bill Bejeck <bbejeck@gmail.com>",2019-05-30 11:33:37,Lifei Chen,Mixed
fd9a20e4167c51c6645c55ed98800b768518c863,"KAFKA-8429; Handle offset change when OffsetForLeaderEpoch inflight (#6811)

It is possible for the offset of a partition to be changed while we are in the middle of validation. If the OffsetForLeaderEpoch request is in-flight and the offset changes, we need to redo the validation after it returns. We had a check for this situation previously, but it was only checking if the current leader epoch had changed. This patch fixes this and moves the validation in `SubscriptionState` where it can be protected with a lock.

Additionally, this patch adds test cases for the SubscriptionState validation API. We fix a small bug handling broker downgrades. Basically we should skip validation if the latest metadata does not include leader epoch information.

Reviewers: David Arthur <mumrah@gmail.com>",2019-05-30 08:50:45,Jason Gustafson,Mixed
77e6e8ec054608a30626271b4952b63294a93c3b,"KAFKA-6455: Update integration tests to verify result timestamps (#6751)

Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>",2019-05-30 09:46:12,Matthias J. Sax,Not TDD
a4c0b1841a9fe69d040128129293db201f81fe4a,"KAFKA-8389: Remove redundant bookkeeping from MockProcessor (#6761)

Remove processedKeys / processedValues / processedWithTimestamps as they are covered with processed already.

Reviewers: Matthias J. Sax <mjsax@apache.org>, John Roesler <john@confluent.io>, Boyang Chen <boyang@confluent.io>",2019-05-30 14:58:53,Guozhang Wang,Not TDD
efa6410611aa0862065ad804323c280a4d8a372d,"KAFKA-8199: Implement ValueGetter for Suppress (#6781)

See also #6684

KTable processors must be supplied with a KTableProcessorSupplier, which in turn requires implementing a ValueGetter, for use with joins and groupings.

For suppression, a correct view only includes the previously emitted values (not the currently buffered ones), so this change also involves pushing the Change value type into the suppression buffer's interface, so that it can get the prior value upon first buffering (which is also the previously emitted value).

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-05-30 15:42:04,John Roesler,Mixed
78c55c8d66f5570d975caa53a9751b126ca10538,"KAFKA-6958: Overload KStream methods to allow to name operation name using the new Named class (#6411)

Sub-task required to allow to define custom processor names with KStreams DSL(KIP-307) :
 - overload methods for stateless operations to accept a Named parameter (filter, filterNot, map, mapValues, foreach, peek, branch, transform, transformValue, flatTransform)
 - overload process method to accept a Named parameter
 - overload join/leftJoin/outerJoin methods

Reviewers: John Roesler <john@confluent.io>, Boyang Chen <boyang@confluent.io>,
Bill Bejeck <bbejeck@gmail.com>",2019-05-31 09:29:42,Florian Hussonnois,Not TDD
87d493f07219a215816783557a5981a74f192f06,"KAFKA-8446: Kafka Streams restoration crashes with NPE when the record value is null (#6842)

When the restored record value is null, we are in danger of NPE during restoration phase.

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2019-06-01 19:12:58,Boyang Chen,Mixed
17345b3be527a3e4808440fceb1179a1b9f9e684,"KAFKA-8463: Fix redundant reassignment of tasks when leader worker leaves (#6859)

Author: Konstantine Karantasis <konstantine@confluent.io>
Reviewer: Randall Hauch <rhauch@gmail.com>",2019-06-02 12:19:19,Konstantine Karantasis,Mixed
2c810e4afb1b41ec1f8565d9a830d479b29dc708,"KAFKA-8425: Fix for correctly handling immutable maps (KIP-421 bug) (#6795)

Since the originals map passed to AbstractConfig constructor may be immutable, avoid updating this map while resolving indirect config variables. Instead a new ResolvingMap instance is now used to store resolved configs.

Reviewers: Randall Hauch <rhauch@gmail.com>, Boyang Chen <bchen11@outlook.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2019-06-03 12:43:11,tadsul,Mixed
b042b36674f0bd8046f0229c96e0b8cf99554b2b,"KAFKA-8426; Fix for keeping the ConfigProvider configs consistent with KIP-297 (#6750)

According to KIP-297 a parameter is passed to ConfigProvider with syntax ""config.providers.{name}.param.{param-name}"". Currently AbstractConfig allows parameters of the format ""config.providers.{name}.{param-name}"". With this fix AbstractConfig will be consistent with KIP-297 syntax.

Reviewers: Robert Yokota <rayokota@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2019-06-03 12:56:31,tadsul,Mixed
3c7c988e3903d87ae1072fa9be5f349e5912d98e,"KAFKA-8449: Restart tasks on reconfiguration under incremental cooperative rebalancing (#6850)

Restart task on reconfiguration under incremental cooperative rebalancing, and keep execution paths separate for config updates between eager and cooperative. Include the group generation in the log message when the worker receives its assignment.

Author: Konstantine Karantasis <konstantine@confluent.io>
Reviewer: Randall Hauch <rhauch@gmail.com>",2019-06-03 11:13:39,Konstantine Karantasis,Not TDD
17712b96c86d6c2cce695531d7e5f2e3d5718b21,"KAFKA-6819: Pt. 1 - Refactor thread-level Streams metrics (#6631)

* StreamsMetricsImpl wraps the Kafka Streams' metrics registry and provides logic to create
and register sensors and their corresponding metrics. An example for such logic can be found in
threadLevelSensor(). Furthermore, StreamsMetricsmpl keeps track of the sensors on the
different levels of an application, i.e., thread, task, etc., and provides logic to remove sensors per
level, e.g., removeAllThreadLevelSensors(). There is one StreamsMetricsImpl object per
application instance.
* ThreadMetrics contains only static methods that specify all built-in thread-level sensors and
metrics and provide logic to register and retrieve those thread-level sensors, e.g., commitSensor().
* From anywhere inside the code base with access to StreamsMetricsImpl, thread-level sensors can be accessed by using ThreadMetrics.
* ThreadsMetrics does not inherit from StreamsMetricsImpl anymore.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-06-03 14:31:18,cadonna,Mixed
55d07e717ec3d2a0b79a690d3a3fdf912cf01a26,"KAFKA-8473: Adjust Connect system tests for incremental cooperative rebalancing (#6872)

Author: Konstantine Karantasis <konstantine@confluent.io>
Reviewer: Randall Hauch <rhauch@gmail.com>",2019-06-03 16:50:03,Konstantine Karantasis,Not TDD
573152dfa8087e40ee69b27fb9fb8f45d3825eb6,"HOTFIX: Allow multi-batches for old format and no compression (#6871)

Reviewers: Jason Gustafson <jason@confluent.io>",2019-06-03 16:56:28,Guozhang Wang,Mixed
1a3fe9aa52555eb24ce692963e4461d6f05b771d,"KAFKA-8404: Add HttpHeader to RestClient HTTP Request and Connector REST API (#6791)

When Connect forwards a REST request from one worker to another, the Authorization header was not forwarded. This commit changes the Connect framework to add include the authorization header when forwarding requests to other workers.

Author: Hai-Dang Dam <damquanghaidang@gmail.com>
Reviewers: Robert Yokota <rayokota@gmail.com>, Randall Hauch <rhauch@gmail.com>",2019-06-03 21:06:00,Hai-Dang Dam,Mixed
ba3dc494371145e8ad35d6b85f45b8fe1e44c21f,"KAFKA-8155: Add 2.2.0 release to system tests (#6597)

Reviewers: Bill Bejeck <bill@confluent.io>, Boyang Chen <boyang@confluent.io>, Bruno Cadonna <bruno@confluent.io>, Guozhang Wang <guozhang@confuent.io>",2019-06-03 21:09:58,Matthias J. Sax,Not TDD
e6563aab722b35c4984b77e9eee42a1904cd1ea6,"KAFKA-4893; Fix deletion and moving of topics with long names

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Gwen Shapira, David Arthur, James Cheng, Vahid Hashemian

Closes #6869 from cmccabe/KAFKA-4893",2019-06-04 14:14:32,Colin P. Mccabe,Mixed
8e161580b859b2fcd54c59625e232b99f3bb48d0,"KAFKA-8305; Support default partitions & replication factor in AdminClient#createTopic (KIP-464) (#6728)

This commit makes three changes:
- Adds a constructor for NewTopic(String, Optional<Integer>, Optional<Short>)
which allows users to specify Optional.empty() for numPartitions or
replicationFactor in order to use the broker default.
- Changes AdminManager to accept -1 as valid options for replication
factor and numPartitions (resolving to broker defaults).
- Makes --partitions and --replication-factor optional arguments when creating
topics using kafka-topics.sh.
- Adds a dependency on scalaJava8Compat library to make it simpler to
convert Scala Option to Java Optional

Reviewers: Ismael Juma <ismael@juma.me.uk>, Ryanne Dolan <ryannedolan@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-06-05 14:10:00,Almog Gavra,Mixed
fb1f74958d1431af7c45a4d499b3b6ffef0bf70e,"KAFKA-8386; Use COORDINATOR_NOT_AVAILABLE error when group is Dead (#6762)

The Dead state in the coordinator is used for groups which are either pending deletion or migration to a new coordinator. Currently requests received while in this state result in an UNKNOWN_MEMBER_ID which causes consumers to reset the memberId. This is a problem for KIP-345 since it can cause an older member to fence a newer member. This patch changes the error code returned in this state to COORDINATOR_NOT_AVAILABLE, which causes the consumer to rediscover the coordinator, but not reset the memberId.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-06-05 14:20:04,Boyang Chen,Mixed
0e95c9f3a829110f0cd8c3695f40ba47f146fef7,"KAFKA-8400; Do not update follower replica state if the log read failed (#6814)

This patch checks for errors handling a fetch request before updating follower state. Previously we were unsafely passing the failed `LogReadResult` with most fields set to -1 into `Replica` to update follower state. Additionally, this patch attempts to improve the test coverage for ISR shrinking and expansion logic in `Partition`.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-06-05 14:36:43,Jason Gustafson,Mixed
59d3a56740a8c668ff8151b88d00c7adc371a50c,"Minor: Replace InternalTopicMetadata with InternalTopicConfig (#6886)

Quick tech debt cleanup. For some reason StreamsPartitionAssignor uses an InternalTopicMetadata class which wraps an InternalTopicConfig object along with the number of partitions. But InternalTopicConfig already has a numPartitions field, so we should just use it directly instead.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bruno Cadonna <bruno@confluent.io>,  Bill Bejeck <bbejeck@gmail.com>",2019-06-06 09:58:58,A. Sophie Blee-Goldman,Not TDD
58aa04f91e9cd8203cd58f972d042d068727d256,"MINOR: Improve Trogdor external command worker docs (#6438)

Reviewers: Colin McCabe <cmccabe@apache.org>, Xi Yang <xi@confluent.io>",2019-06-06 10:04:05,Stanislav Kozlovski,Mixed
28eccc3ca3fe591c06d6067f08f60ce71f2a1e3c,"KAFKA-8384; Leader election command integration tests (#6880)

This patch adds test cases for the leader election command added in KIP-460.

Reviewers: Vikas Singh, David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-06-06 21:36:33,José Armando García Sancio,Mixed
cca05cace4105c829f303c13eed8ace2efd7fa0c,"KAFKA-8331: stream static membership system test (#6877)

As title suggested, we boost 3 stream instances stream job with one minute session timeout, and once the group is stable, doing couple of rolling bounces for the entire cluster. Every rejoin based on restart should have no generation bump on the client side.

Reviewers: Guozhang Wang <wangguoz@gmail.com>,  Bill Bejeck <bbejeck@gmail.com>",2019-06-07 16:52:12,Boyang Chen,Not TDD
783ab74793cc7e541e6b8ed4e1c545bf5dcff959,"KAFKA-8333; Load high watermark checkpoint lazily when initializing replicas (#6800)

Currently we load the high watermark checkpoint separately for every replica that we load. This patch makes this loading logic lazy and caches the loaded map while a LeaderAndIsr request is being handled.

Reviewers: Jun Rao <junrao@gmail.com>",2019-06-10 18:59:59,Jason Gustafson,Mixed
bebcbe3a049f78c4184404f2dfb8b4150233856e,"KAFKA-8487: Only request re-join on REBALANCE_IN_PROGRESS in CommitOffsetResponse (#6894)

Plus some minor cleanups on AbstractCoordinator.

Reviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>",2019-06-11 09:48:43,Guozhang Wang,Mixed
e981b82601e9967d3a2492d2cebb45369407b398,"KAFKA-8500; Static member rejoin should always update member.id (#6899)

This PR fixes a bug in static group membership. Previously we limit the `member.id` replacement in JoinGroup to only cases when the group is in Stable. This is error-prone and could potentially allow duplicate consumers reading from the same topic. For example, imagine a case where two unknown members join in the `PrepareRebalance` stage at the same time. 

The PR fixes the following things:

1. Replace `member.id` at any time we see a known static member rejoins group with unknown member.id
2. Immediately fence any ongoing join/sync group callback to early terminate the duplicate member.
3. Clearly handle Dead/Empty cases as exceptional.
4. Return old leader id upon static member leader rejoin to avoid trivial member assignment being triggered.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-06-12 08:41:58,Boyang Chen,Mixed
1cc0b5eb81b838c4ffb6ff2c2d3f16b7b3754a01,"MINOR: Seal the HostedPartition enumeration (#6917)

Makes HostedPartition a sealed trait and make all of the match cases explicit.

Reviewers: Vikas Singh <soondenana@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",2019-06-12 09:38:21,José Armando García Sancio,Not TDD
af2801031c455f86fb771d9f36c313f99459cd1a,"KAFKA-8483/KAFKA-8484; Ensure safe handling of producerId resets (#6883)

The idempotent producer attempts to detect spurious UNKNOWN_PRODUCER_ID errors and handle them by reassigning sequence numbers to the inflight batches. The inflight batches are tracked in a PriorityQueue. The problem is that the reassignment of sequence numbers depends on the iteration order of PriorityQueue, which does not guarantee any ordering. So this can result in sequence numbers being assigned in the wrong order.  This patch fixes the problem by using a sorted set instead of a priority queue so that the iteration order preserves the sequence order. Note that resetting sequence numbers is an exceptional case.

This patch also fixes KAFKA-8484, which can cause an IllegalStateException when the producerId is reset while there are pending produce requests inflight. The solution is to ensure that sequence numbers are only reset if the producerId of a failed batch corresponds to the current producerId.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-06-12 12:54:17,Jason Gustafson,Mixed
e54ab292e7e2fd1d18e82387a586969ba57eb7ea,"KAFKA-8452: Compressed BufferValue (#6848)

De-duplicate the common case in which the prior value is the same as the old value.

Reviewers: Sophie Blee-Goldman <sophie@confluent.io>,  Bill Bejeck <bbejeck@gmail.com>",2019-06-13 09:48:15,John Roesler,Mixed
8dd4fb5ebeccbb427ec5d0d92d4d5281ba9291f6,"KAFKA-8530; Check for topic authorization errors in OffsetFetch response (#6928)

The OffsetFetch requires Topic Describe permission. If a client does not have this, we return TOPIC_AUTHORIZATION_FAILED at the partition level. Currently the consumer does not handle this error explicitly, but raises it as a generic `KafkaException`. For consistency with other APIs and to fix transient test failures in `PlaintextEndToEndAuthorizationTest`, we should raise `TopicAuthorizationFailedException` instead.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2019-06-14 08:16:11,Jason Gustafson,Mixed
2ef02f111e3a1640d3e92aa29dae5677d0eefe18,"KAFKA-8179: Part I, Bump up consumer protocol to v2 (#6528)

1. Add new fields of subscription / assignment and bump up consumer protocol to v2.
2. Update tests to make sure old versioned protocol can be successfully deserialized, and new versioned protocol can be deserialized by old byte code.

Reviewers: Boyang Chen <boyang@confluent.io>, Sophie Blee-Goldman <sophie@confluent.io>,  Bill Bejeck <bbejeck@gmail.com>",2019-06-14 15:51:33,Guozhang Wang,Mixed
e047864f30fa47c6bcb2a0e6d9da86fa053fe6f6,"MINOR: fix some warnings in the broker

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Gwen Shapira

Closes #6942 from cmccabe/fix-scala-warnings",2019-06-15 19:21:10,Colin P. Mccabe,Mixed
57baa4079d9fc14103411f790b9a025c9f2146a4,"KAFKA-8457; Move `Log' reference from `Replica` into `Partition` (#6841)

A `Partition` object contain one or many `Replica` objects. These replica
objects in turn can have the ""log"" if the replica corresponds to the
local node. All the code in Partition or ReplicaManager peek into
replica object to fetch the log if they need to operate on that. As
replica object can represent a local replica or a remote one, this
lead to a bunch of ""if-else"" code in log fetch and offset update code.

NOTE: In addition to a ""log"" that is in use during normal operation, if
an alter log directory command is issued, we also create a future log
object. This object catches up with local log and then we switch the log
directory. So temporarily a Partition can have two local logs. Before
this change both logs are inside replica objects.

This change is an attempt to untangle this relationship. In particular
it moves `Log` from `Replica` into `Partition`. So a partition contains
a local log to which all writes go and possibly a ""future log"" if the 
partition is being moved between directories. Additionally, it maintains
a list of remote replicas for offset and ""caught up time"" data that it uses
for replication protocol. 

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",2019-06-17 08:52:37,Vikas Singh,Mixed
1b9e1073885951697f34950a1ea706c93826e871,"KAFKA-7853: Refactor coordinator config (#6854)

An attempt to refactor current coordinator logic.

Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Konstantine Karantasis <konstantine@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-06-17 10:58:43,Boyang Chen,Mixed
47f908fa73fb7bbaec553635e75bffddd7a473f9,"KAFKA-8539; Add group.instance.id to Subscription (#6936)

This PR is part of KIP-345's effort to utilize this new field for more stable topic partition assignment. We add the group instance id to the `Subscription` object to allow partition assignors to make stickier assignments. More details [here](https://cwiki.apache.org/confluence/display/KAFKA/KIP-345%3A+Introduce+static+membership+protocol+to+reduce+consumer+rebalances#KIP-345:Introducestaticmembershipprotocoltoreduceconsumerrebalances-ClientBehaviorChanges). 

Reviewers: Jason Gustafson <jason@confluent.io>",2019-06-17 11:25:22,Boyang Chen,Mixed
6d6366cd5563ba2a7bd894611ef037cdea99273a,"KAFKA-6958: Overload KTable methods to allow to name operation name using the new Named class (#6412)

Sub-task required to allow to define custom processor names with KStreams DSL(KIP-307). This is the 4th PR for KIP-307. 

Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",2019-06-17 18:02:51,Florian Hussonnois,Mixed
c7db82b59a145735fce227436c6191d1825fe384,"MINOR: rename subscription construction function (#6954)

Per discussion on #6936, some nit fixes to the Subscription initialization path.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-06-17 17:11:11,Boyang Chen,Mixed
33e39de4ad5ff5cdea918e076565416e9295f46c,"KAFKA-8448: Cancel PeriodicProducerExpirationCheck when closing a Log instance (#6847)

Cancel PeriodicProducerExpirationCheck when closing a Log instance, to avoid a memory leak.  Add a method to KafkaScheduler to make this possible.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",2019-06-18 10:52:58,jolshan,Mixed
a7e771c6da72bb7f3c5c5cbab3dc9c4fd403f866,"KAFKA-8452: Compressed BufferValue review follow-up (#6940)

Belatedly address a few code review comments from #6848

Reviewers: Bill Bejeck <bbejeck@gmail.com>",2019-06-19 12:45:35,John Roesler,Mixed
635c21311f6bf0405e743dcf5004ef6ea36737e0,"KAFKA-8564; Fix NPE on deleted partition dir when no segments remain (#6968)

Kafka should not NPE while loading a deleted partition dir with no log segments. This patch ensures that there will always be at least one segment after initialization.

Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>
Co-authored-by: Mickael Maison <mickael.maison@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2019-06-19 12:41:05,Mickael Maison,Mixed
03d61ebfb93aab53b0b0ecdfc77175d18a58e861,"KAFKA-8569: integrate warning message under static membership (#6972)

Static members never leave the group, so potentially we could log a flooding number of warning messages in the hb thread. The solution is to only log as warning when we are on dynamic membership.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-06-20 13:56:00,Boyang Chen,Mixed
1233c963f81ebf09762754c7d4cde97c85ae364f,"MINOR: Remove legacy kafka.admin.AdminClient (#6947)

It has been deprecated since 0.11.0, it was never meant as a publicly
supported API and people should use
`org.apache.kafka.clients.admin.AdminClient` instead. Its presence
causes confusion and people still use them accidentally at times.

`BrokerApiVersionsCommand` uses one method that is not available
in `org.apache.kafka.clients.admin.AdminClient`, we inline it for now.

Reviewers: David Arthur <mumrah@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2019-06-20 23:41:34,Ismael Juma,Not TDD
d7a5e31ca2f694fe0f5aaf8536ea30400fc19d3e,"KAFKA-8519 Add trogdor action to slow down a network (#6912)

This adds a new Trogdor fault spec for inducing network latency on a network device for system testing. It operates very similarly to the existing network partition spec by executing the `tc` linux utility.",2019-06-21 11:30:05,David Arthur,Not TDD
5f8b2898ce512b9d1390857e036bb3a896dca170,"KAFKA-8570; Grow buffer to hold down converted records if it was insufficiently sized (#6974)

When the log contains out of order message formats (for example v2 message followed by v1 message) and consists of compressed batches typically greater than 1kB in size, it is possible for down-conversion to fail. With compressed batches, we estimate the size of down-converted batches using:

```
    private static int estimateCompressedSizeInBytes(int size, CompressionType compressionType) {
        return compressionType == CompressionType.NONE ? size : Math.min(Math.max(size / 2, 1024), 1 << 16);
    }
```

This almost always underestimates size of down-converted records if the batch is between 1kB-64kB in size. In general, this means we may under estimate the total size required for compressed batches.

Because of an implicit assumption in the code that messages with a lower message format appear before any with a higher message format, we do not grow the buffer we copy the down converted records into when we see a message <= the target message format. This assumption becomes incorrect when the log contains out of order message formats, for example because of leaders flapping while upgrading the message format.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-06-21 09:36:29,Dhruvil Shah,Not TDD
f51d7d3c931ad9de34cf9633b5b97d9a7b5a0ad4,"KAFKA-8557: system tests - add support for (optional) interbroker listener with the same security protocol as client listeners (#6938)

Reviewers: Brian Bushree <bbushree@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2019-06-21 17:51:43,Stanislav Vodetskyi,Not TDD
3e9d1c1411c5268de382f9dfcc95bdf66d0063a0,"KAFKA-8106: Skipping ByteBuffer allocation of key / value / headers in logValidator (#6785)

* KAFKA-8106:Reducing the allocation and copying of ByteBuffer when logValidator do validation.

* KAFKA-8106:Reducing the allocation and copying of ByteBuffer when logValidator do validation.

* github comments

* use batch.skipKeyValueIterator

* cleanups

* no need to skip kv for uncompressed iterator

* checkstyle fixes

* fix findbugs

* adding unit tests

* reuse decompression buffer; and using streaming iterator

* checkstyle

* add unit tests

* remove reusing buffer supplier

* fix unit tests

* add unit tests

* use streaming iterator

* minor refactoring

* rename

* github comments

* github comments

* reuse buffer at DefaultRecord caller

* some further optimization

* major refactoring

* further refactoring

* update comment

* github comments

* minor fix

* add jmh benchmarks

* update jmh

* github comments

* minor fix

* github comments",2019-06-21 12:44:45,Guozhang Wang,Mixed
fc27cbe4159eaf9195017bc0fa929b0b84216d61,"KAFKA-8545: Remove legacy ZkUtils (#6948)

`ZkUtils` is not used by the broker, has been deprecated since
2.0.0 and it was never intended as a public API. We should
remove it along with `AdminUtils` methods that rely on it.

Reviewers: David Arthur <mumrah@gmail.com>",2019-06-22 20:44:40,Ismael Juma,Mixed
e5c4ebdd7433d746a46d6962ee04ff2d782d892b,"KAFKA-8179: Part 2, ConsumerCoordinator Algorithm (#6778)

1. In ConsumerCoordinator, select the protocol as the common protocol from all configured assignor instances' supported protocols with the highest number.
1.b. In onJoinPrepare: only call onPartitionRevoked with EAGER.
1.a. In onJoinComplete: call onPartitionAssigned with EAGER; call onPartitionRevoked following onPartitionAssigned with COOPERATIVE, and then request re-join if the error indicates so.
1.c. In performAssignment: update the user's assignor returned assignments by excluding all partitions that are still owned by some other members.

2. I've refactored the Subscription / Assignment such that: assigned partitions, error codes, and group instance id are not-final anymore, instead they can be updated. For the last one, it is directly related to the logic of this PR but I felt it is more convienent to go with other fields.

3. Testing: primarily in ConsumerCoordinatorTest, make it parameterized with protocol, and add necessary scenarios for COOPERATIVE protocol.

I intentionally omitted the documentation change since there are some behavioral updates that needs to be finalized in later PRs, and hence I will also only add the docs in later PRs.

Reviewers: Bill Bejeck <bbejeck@gmail.com>, Boyang Chen <boyang@confluent.io>, Sophie Blee-Goldman <sophie@confluent.io>",2019-06-23 15:22:07,Guozhang Wang,Mixed
14d854936e1d2fed2e69a7c6367becf360f88833,"KAFKA-8390: Use automatic RPC generation in CreateDelegationToken (#6828)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2019-06-25 18:31:11,Mickael Maison,Not TDD
5216839d8bcda5c00825a0f4be866a525d948da8,"Minor: code enhancment (#6999)


Reviewers: Bill Bejeck <bbejeck@gmail.com>",2019-06-25 18:22:44,khairy,Not TDD
fbf6a76fc40fc5fecd679ef6484a0b92a4ab3971,"KAFKA-8356: add static membership info to round robin assignor (#6815)

The purpose here is to leverage static membership information during round robin consumer assignment, because persistent member id could help make the assignment remain the same during rebalance.
The comparison logic is changed to:

1. If member A and member B both have group.instance.id, then compare their group.instance.id
2. If member A has group.instance.id, while member B doesn't, then A < B
3. If both member A and B don't have group.instance.id, compare their member.id

In round robin assignor, we use ephemeral member.id to sort the members in order for assignment. This semantic is not stable and could trigger unnecessary shuffle of tasks. By leveraging group.instance.id the static member assignment shall be persist when satisfying following conditions:

1. number of members remain the same across generation
2. static members' identities persist across generation

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-06-27 21:12:39,Boyang Chen,Mixed
f8db022b08cf0b7fa65f271711a4103ef4b28897,"KAFKA-8538 (part of KIP-345): add group.instance.id to DescribeGroup (#6957)

Include group.instance.id in the describe group result for better visibility.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-06-27 21:14:13,Boyang Chen,Mixed
3d2d87abd1320ffbe6cbfc752845a3e50ea496f4,"MINOR: Add compatibility tests for 2.3.0 (#6995)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2019-06-28 09:25:08,Colin Patrick McCabe,Not TDD
53b837f9c604cdb8a5a77a9363fc058b9ef9cd7e,"KAFKA-8542; Cache transaction first offset metadata on follower (#6943)

Followers should cache the log offset metadata for the start offset of each transaction in order to be able to compute the last stable offset without an offset index lookup. This is needed for follower fetching in KIP-392.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-06-29 16:49:42,Jason Gustafson,Mixed
6dd4ebcea78f9c6fb8a2921cab3fd92be4978063,"MINOR: Make the build compile with Scala 2.13 (#6989)

Scala 2.13 support was added to build via #5454. This PR adjusts the code so that
it compiles with 2.11, 2.12 and 2.13.

Changes:
* Add `scala-collection-compat` dependency.
* Import `scala.collection.Seq` in a number of places for consistent behavior between
Scala 2.11, 2.12 and 2.13.
* Remove wildcard imports that were causing the Java classes to have priority over the
Scala ones, related Scala issue: https://github.com/scala/scala/pull/6589.
* Replace parallel collection usage with `Future`. The former is no longer included by
default in the standard library.
* Replace val _: Unit workaround with one that is more concise and works with Scala 2.13
* Replace `filterKeys` with `filter` when we expect a `Map`. `filterKeys` returns a view
that doesn't implement the `Map` trait in Scala 2.13.
* Replace `mapValues` with `map` or add a `toMap` as an additional transformation
when we expect a `Map`. `mapValues` returns a view that doesn't implement the
`Map` trait in Scala 2.13.
* Replace `breakOut` with `iterator` and `to`, `breakOut` was removed in Scala
2.13.
* Replace to() with toMap, toIndexedSeq and toSet
* Replace `mutable.Buffer.--` with `filterNot`.
* ControlException is an abstract class in Scala 2.13.
* Variable arguments can only receive arrays or immutable.Seq in Scala 2.13.
* Use `Factory` instead of `CanBuildFrom` in DecodeJson. `CanBuildFrom` behaves
a bit differently in Scala 2.13 and it's been deprecated. `Factory` has the behavior
we need and it's available via the compat library.
* Fix failing tests due to behavior change in Scala 2.13,
""Map.values.map is not strict in Scala 2.13"" (https://github.com/scala/bug/issues/11589).
* Use Java collections instead of Scala ones in StreamResetter (a Java class).
* Adjust CheckpointFile.write to take an `Iterable` instead of `Seq` to avoid
unnecessary collection copies.
* Fix DelayedElectLeader to use a Map instead of Set and avoid `to` call that
doesn't work in Scala 2.13.
* Use unordered map for mapping in SimpleAclAuthorizer, mapping of ordered
maps require an `Ordering` in Scala 2.13 for safety reasons.
* Adapt `ConsumerGroupCommand` to compile with Scala 2.13.
* CoreUtils.min takes an `Iterable` instead of `TraversableOnce`, the latter does
not exist in Scala 2.13.
* Replace `Unit` with `()` in a couple places. Scala 2.13 is stricter when it expects
a value instead of a type.
* Fix bug in CustomQuotaCallbackTest where we did not necessarily set `partitionRatio`
correctly, `forall` can terminate early.
* Add a couple of spotbugs exclusions that are needed by code generated by Scala 2.13
* Remove unused variables, simplify some code and remove procedure syntax in a few
places.
* Remove unused `CoreUtils.JSONEscapeString`.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, José Armando García Sancio <jsancio@users.noreply.github.com>",2019-07-02 06:29:39,Ismael Juma,Mixed
711c817254eaf62d91b0d783fdd04c5f1915fa75,"KAFKA-8560; The Kafka protocol generator should support common structures

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Gwen Shapira

Closes #6966 from cmccabe/KAFKA-8560",2019-07-02 09:40:54,Colin P. Mccabe,Mixed
ea6cf41eb5135ec75f976ca769a16984c04a9c07,"MINOR: Preserve the assignment order from the LeaderAndIsr request (#7010)

Leaders should make changes to the assignment and the ISR at the same time as part of processing the LeaderAndIsr requests. The leader should also preserve the order of assignment mainly for consistency with the Controller's code and data representation.

Reviewers: Vikas Singh, David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-07-02 20:27:22,José Armando García Sancio,Mixed
822abe47db07fcf92e8aa24e920a54239a90348d,"MINOR: WorkerUtils#topicDescriptions must unwrap exceptions properly (#6937)

Reviewers: Ismael Juma <ismael@juma.me.uk>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>",2019-07-03 16:08:39,Colin Patrick McCabe,Mixed
442d36241bea6e83c75ed7513e48099b8d73ef39,"MINOR: add useConfiguredPartitioner and skipFlush options for ProduceBench

Add a ""useConfiguredPartitioner"" boolean to specify testing with the configured partitioner, rather than overriding the partitioner in the test.

Add a ""skipFlush"" boolean to specify skipping the flush operation when producing.  This is helpful when testing some scenarios where linger.ms is greater than 0.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2019-07-03 17:23:36,jolshan,Not TDD
23beeea34bf9e5e7a33dc0566d54a17b2b417c0f,"KAFKA-8443; Broker support for fetch from followers (#6832)

Follow on to #6731, this PR adds broker-side support for [KIP-392](https://cwiki.apache.org/confluence/display/KAFKA/KIP-392%3A+Allow+consumers+to+fetch+from+closest+replica) (fetch from followers). 

Changes:
* All brokers will handle FetchRequest regardless of leadership
* Leaders can compute a preferred replica to return to the client
* New ReplicaSelector interface for determining the preferred replica
* Incremental fetches will include partitions with no records if the preferred replica has been computed
* Adds new JMX to expose the current preferred read replica of a partition in the consumer

Two new conditions were added for completing a delayed fetch. They both relate to communicating the high watermark to followers without waiting for a timeout:
* For regular fetches, if the high watermark changes within a single fetch request 
* For incremental fetch sessions, if the follower's high watermark is lower than the leader

A new JMX attribute `preferred-read-replica` was added to the `kafka.consumer:type=consumer-fetch-manager-metrics,client-id=some-consumer,topic=my-topic,partition=0` object. This was added to support the new system test which verifies that the fetch from follower behavior works end-to-end. This attribute could also be useful in the future when debugging problems with the consumer.

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-07-04 08:18:51,David Arthur,Mixed
57903be49665566260160a6f1f995409ec48c9bc,"MINOR: Remove zkclient dependency (#7036)

ZkUtils was removed so we don't need this anymore.

Also:
* Fix ZkSecurityMigrator and ReplicaManagerTest not to
reference ZkClient classes.
* Remove references to zkclient in various `log4j.properties`
and `import-control.xml`.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>",2019-07-05 07:50:32,Ismael Juma,Not TDD
05cba28ca7aafd3974e9e818be08f239b6162855,"MINOR: A few cleanups and compiler warning fixes (#6986)

Reviewers: Jason Gustafson <jason@confluent.io>",2019-07-08 16:53:02,Lee Dongjin,Not TDD
289ac092923a32e5a839750fcaef0ae0856d05b3,"KAFKA-8591; WorkerConfigTransformer NPE on connector configuration reloading (#6991)

A bug in `WorkerConfigTransformer` prevents the connector configuration reload when the ConfigData TTL expires. 

The issue boils down to the fact that `worker.herder().restartConnector` is receiving a null callback. 

```
[2019-06-17 14:34:12,320] INFO Scheduling a restart of connector workshop-incremental in 60000 ms (org.apache.kafka.connect.runtime.WorkerConfigTransformer:88)
[2019-06-17 14:34:12,321] ERROR Uncaught exception in herder work thread, exiting:  (org.apache.kafka.connect.runtime.distributed.DistributedHerder:227)
java.lang.NullPointerException
        at org.apache.kafka.connect.runtime.distributed.DistributedHerder$19.onCompletion(DistributedHerder.java:1187)
        at org.apache.kafka.connect.runtime.distributed.DistributedHerder$19.onCompletion(DistributedHerder.java:1183)
        at org.apache.kafka.connect.runtime.distributed.DistributedHerder.tick(DistributedHerder.java:273)
        at org.apache.kafka.connect.runtime.distributed.DistributedHerder.run(DistributedHerder.java:219)
```
This patch adds a callback which just logs the error.

Reviewers: Robert Yokota <rayokota@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-07-08 23:07:10,Nacho Muñoz Gómez,Mixed
99737588b6db7647d0d03b7306f143714fbae4d5,"KAFKA-3333: Adds RoundRobinPartitioner with tests (#6771)

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Sriharsha Chintalapani <sriharsha@apache.org>, Matthias J. Sax <matthias@confluent.io>",2019-07-09 11:46:07,mmanna-sapfgl,Mixed
38f86d139cbd8a3b92ce555f185e52252f626cd4,"MINOR: Use `Topic::isInternalTopic` instead of directly checking (#7047)

We don't allow changing number of partitions for internal topics. To do
so we check if the topic name belongs to the set of internal topics
directly instead of using the ""isInternalTopic"" method. This breaks the
encapsulation by making client aware of the fact that internal topics
have special names.

This is a simple change to use the method `Topic::isInternalTopic`
method instead of checking it directly in ""alterTopic"" command. We
also reduce visibility to `Topic::INTERNAL_TOPICS` to avoid 
unnecessary reliance on it in the future.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-07-09 17:51:54,Vikas Singh,Not TDD
4f5a5eb579a20cf86eaf5018663d44e5592d0401,"KAFKA-8424: replace ListGroups request/response with automated protocol (#6805)

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",2019-07-10 14:48:37,Boyang Chen,Mixed
ebb80f568da59cf60c76170176584bcb34d88ecb,"KAFKA-8653; Default rebalance timeout to session timeout for JoinGroup v0 (#7072)

The rebalance timeout was added to the JoinGroup protocol in version 1. Prior to 2.3,
we handled version 0 JoinGroup requests by setting the rebalance timeout to be equal
to the session timeout. We lost this logic when we converted the API to use the
generated schema definition (#6419) which uses the default value of -1. The impact
of this is that the group rebalance timeout becomes 0, so rebalances finish immediately
after we enter the PrepareRebalance state and kick out all old members. This causes
consumer groups to enter an endless rebalance loop. This patch restores the old
behavior.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2019-07-10 23:19:04,Jason Gustafson,Mixed
d70fe5ed2d25af432ec6ce02ccfeaa40bcd2f295,"KAFKA-8644; The Kafka protocol generator should allow null defaults for bytes and array fields

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Stanislav Kozlovski, Gwen Shapira

Closes #7059 from cmccabe/KAFKA-8644",2019-07-11 09:52:01,Colin P. Mccabe,Mixed
7a7d4cb5819b169db2f40f0ca2efc04043ff10df,"MINOR: Refactor high watermark access and validation (#7055)

The purpose of this patch is to restrict the paths for updating and accessing the high watermark and the last stable offset. By doing so, we can validate that these offsets always remain within the range of the log. We also ensure that we never expose `LogOffsetMetadata` unless it is fully materialized. Finally, this patch makes a few naming changes. In particular, we remove the `highWatermark_=` and `highWatermarkMetadata_=` which are both misleading and cumbersome to test.

Reviewers: David Arthur <mumrah@gmail.com>",2019-07-11 13:52:04,Jason Gustafson,Mixed
25f4e3c7d4a50a55e3d66ea479e40a38c841ba39,"KAFKA-8643; Bring back public MemberDescription constructor (#7060)

This patch fixes a compatibility breaking `MemberDescription` constructor change in #6957. It also updates `equals` and `hashCode` for the new `groupInstanceId` field that was added in the same patch.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2019-07-11 21:54:33,Boyang Chen,Mixed
53b4ce5c00d61be87962f603682873665155cec4,"KAFKA-5998: fix checkpointableOffsets handling (#7030)

fix checkpoint file warning by filtering checkpointable offsets per task
clean up state manager hierarchy to prevent similar bugs

Reviewers: Bruno Cadonna <bruno@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",2019-07-12 09:42:11,John Roesler,Mixed
fc4fea6761986749f0ac640868d9b4d2a552eb62,"KAFKA-6605: Fix NPE in Flatten when optional Struct is null (#5705)

Correct the Flatten SMT to properly handle null key or value `Struct` instances.

Author: Michal Borowiecki <michal.borowiecki@openbet.com>
Reviewers: Arjun Satish <arjun@confluent.io>, Robert Yokota <rayokota@gmail.com>, Randall Hauch <rhauch@gmail.com>",2019-07-12 10:27:33,Michał Borowiecki,Mixed
fa042bc491cf8b1e8ae0e5b9f7996564ba886d3d,"KAFKA-7157: Fix handling of nulls in TimestampConverter (#7070)

Fix handling of nulls in TimestampConverter.

Authors: Valeria Vasylieva <valeria.vasylieva@gmail.com>, Robert Yokota <rayokota@gmail.com>
Reviewers: Arjun Satish <arjun@confluent.io>, Randall Hauch <rhauch@gmail.com>",2019-07-12 12:12:20,Robert Yokota,Mixed
ea814d78690940827e90950282f40a74ca45eb0f,"KAFKA-8614; Consistent naming for IncrementalAlterConfig and AlterConfig responses (#7022)

This patch changes the name of the `Resources` field of AlterConfigsResponse to `Responses`. This makes it consistent with AlterConfigsResponse, which has a differently-named but structurally-identical field. Tested with unit tests.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-07-12 17:18:40,Bob Barrett,Not TDD
528e5c0f57aa5014cd13baef2b683a1a328f459a,"KAFKA-8602: Fix bug in stand-by task creation (#7008)

Reviewers: Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>, Boyang Chen <boyang@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",2019-07-15 16:40:01,cadonna,Mixed
3e48bdbc333602a042b6b0fb7fb9e14625ab4ece,"KAFKA-8620: fix NPE due to race condition during shutdown while rebalancing (#7021)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bruno Cadonna <bruno@confluent.io>, John Roesler <john@confluent.io>",2019-07-15 15:02:13,Boyang Chen,Mixed
d227f940489434c2f23491340d4399d98fd48d2d,"KAFKA-8662; Fix producer metadata error handling and consumer manual assignment (#7086)

Ensure that Producer#send() throws topic metadata exceptions only for the topic being sent to and not for other topics in the producer's metadata instance. Also removes topics from consumer's metadata when a topic is removed using manual assignment.

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2019-07-16 13:08:16,Rajini Sivaram,Mixed
00757cd99f6d8bf2760c3708d307347f4cde65f6,"KAFKA-8450: Using KeyValueTimeStamp in MockProcessor (#6933)

This PR is to use KeyValueTimeStamp Object in MockProcessor Test file instead of String and change all the dependency files with broken test cases.

Reviewers: Kamal Chandraprakash, Matthias J. Sax <mjsax@apache.org>,  Boyang Chen <boyang@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",2019-07-16 10:16:15,SuryaTeja Duggi,Not TDD
f65c71cf6e13973ebff8ef590eb3d369da4d1b11,"MINOR: Increase `awaitCommits` timeout in ExampleConnectIntegrationTest (#7061)

The transient failures are usually caused by a timeout in `awaitCommits`. This patch increases the timeout from 15s to 30s.

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Matthias J. Sax <mjsax@apache.org>",2019-07-16 12:00:49,Jason Gustafson,Not TDD
f8994897d30ef7508756dceb1d19171d6204f2a2,"MINOR: improve error message for incorrect window-serde initialization (#7067)

Reviewers: Tim Berglund <tim@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>",2019-07-17 18:39:55,Matthias J. Sax,Mixed
ab8a7ff36326742e1c6d4fc0a0aff818c7e6d313,"KAFKA-8670; Fix exception for kafka-topics.sh --describe without --topic mentioned (#7094)

If there are **no topics** in a cluster, kafka-topics.sh --describe without a --topic option should return empty list, not throw an exception.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-07-18 13:25:25,Tirtha Chatterjee,Mixed
62fbc92e3d9d84617dab46329c279835d157bda4,"KAFKA-8615: Change to track partition time breaks TimestampExtractor (#7054)

The timestamp extractor takes a previousTimestamp parameter which should be the partition time. This PR adds back in partition time tracking for the extractor, and renames previousTimestamp --> partitionTime

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>, Matthias J. Sax <mjsax@apache.org>",2019-07-18 13:54:46,A. Sophie Blee-Goldman,Mixed
2e26a46358d97112b9b912a7c5c29a2d6fb517cf,"KAFKA-8635; Skip client poll in Sender loop when no request is sent (#7085)

This patch changes maybeSendTransactionalRequest to handle both sending and polling transactional requests (and renames it to maybeSendAndPollTransactionalRequest), and skips the call to poll if no request is actually sent. It also removes the inner loop inside maybeSendAndPollTransactionalRequest and relies on the main Sender loop for retries.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-07-18 15:07:42,Bob Barrett,Mixed
aa8e850afb7baa447882b493eae29f99a39e35a0,"KAFKA-8392: Fix old metrics leakage by brokers that have no leadership over any partition for a topic (#6977)

* Added removeOldLeaderMetrics in BrokerTopicStats to remove MessagesInPerSec, BytesInPerSec, BytesOutPerSec for any broker that is no longer a leader of any partition for a particular topic

* Modified ReplicaManager to remove the metrics of any topic that the current broker has no leadership (meaning the broker either becomes a follower for all of the partitions in that topic or stops being a replica)

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jun Rao <junrao@gmail.com>",2019-07-19 15:25:18,Tu V. Tran,Mixed
e3524ef350830e3e1fa918ec0ae93b09d51fcf37,"KAFKA-8435: replace delete groups request/response with automated protocol (#6860)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2019-07-19 17:04:22,Boyang Chen,Mixed
2a133ba656ae550cc9ad4bcda0a9afb27b14f4e0,"KAFKA-8454; Add Java AdminClient Interface (KIP-476) (#7087)

Adds an `Admin` interface as specified in [KIP-476](https://cwiki.apache.org/confluence/display/KAFKA/KIP-476%3A+Add+Java+AdminClient+Interface).

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2019-07-22 15:47:34,Andy Coates,Mixed
f98e176746d663fadedbcd3c18312a7f476a20c8,"KAFKA-8678; Fix leave group protocol bug in throttling and error response (#7101)

This is a bug fix PR to resolve errors introduced in https://github.com/apache/kafka/pull/6188. The PR fixes 2 things:

1. throttle time should be set on version >= 1 instead of version >= 2
2. `getErrorResponse` should set throwable exception within LeaveGroupResponseData

The patch also adds more unit tests to guarantee correctness for leave group protocol.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-07-22 16:13:02,Boyang Chen,Mixed
6b6a6b930fda853fd91dfbe85b4462e17654f804,"KAFKA-8526; Fallback to other log dirs after getOrCreateLog failure (#6969)

 LogManager#getOrCreateLog() selects a log dir for the new replica from
 _liveLogDirs, if disk failure is discovered at this point, before
 LogDirFailureHandler finds out, try using other log dirs before failing
 the operation.

Reviewers: Anna Povzner <anna@confluent.io>, Jason Gustafson <jason@confluent.io>",2019-07-23 08:57:38,Igor Soarez,Mixed
a8aedc85ebfadcf1472acafe2e0311a73d3040be,"KAFKA-8696: clean up Sum/Count/Total metrics (#7057)

* Clean up one redundant and one misplaced metric
* Clarify the relationship among these metrics to avoid future confusion

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-07-23 16:54:20,John Roesler,Mixed
e9c61f690e548fb8c587d777e5c8f71149a38fea,"MINOR: Ensure in-memory metadata is removed before physical deletion of segment (#7106)

Minor refactoring of the places where we delete log segments, to ensure we always remove the in-memory metadata of the segment before performing physical deletion.

Reviewers: Ismael Juma <ismael@juma.me.uk>, NIkhil Bhatia <rite2nikhil@gmail.com>, Jun Rao <junrao@gmail.com>",2019-07-24 22:17:05,Dhruvil Shah,Mixed
69d86a197f86ad4c6f1636b5ab4678907e30a4c0,"KAFKA-8179: add public ConsumerPartitionAssignor interface (#7108)

Main changes of this PR:

* Deprecate old consumer.internal.PartitionAssignor and add public consumer.ConsumerPartitionAssignor with all OOTB assignors migrated to new interface
* Refactor assignor's assignment/subscription related classes for easier to evolve API
* Removed version number from classes as it is only needed for serialization/deserialization
* Other previously-discussed cleanup included in this PR:

* Remove Assignment.error added in pt 1
* Remove ConsumerCoordinator#adjustAssignment added in pt 2

Reviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-07-25 13:02:09,A. Sophie Blee-Goldman,Mixed
79341a12f235510d9f78af24d979102c3d8882e1,"KAFKA-8715; Fix buggy reliance on state timestamp in static member.id generation (#7116)

The bug is that we accidentally used the current state timestamp for the group instead of the real current time. When a group is first loaded, this timestamp is not initialized, so this resulted in a `NoSuchElementException`. Additionally this violated the intended uniqueness of the memberId, which could have broken the group instance fencing. Fix is made and unit test to make sure the timestamp is properly encoded within the returned member.id.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-07-26 15:31:30,Boyang Chen,Not TDD
74c90f46c34727be9484e9826ff543b451ada775,"KAFKA-8221; Add batch leave group request (#6714)

This patch is part of KIP-345. We are aiming to support batch leave group request issued from admin client. This diff is the first effort to bump leave group request version.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-07-26 23:13:37,Boyang Chen,Mixed
81900d0ba0a5839a1e5dc876897bab1c24b3bd94,"KAFKA-8345: KIP-455 Protocol changes (part 1) (#7114)

Add a new exception, NoReassignmentInProgressException.  Modify LeaderAndIsrRequest to include the AddingRepicas and RemovingReplicas fields.  Add the ListPartitionReassignments and AlterPartitionReassignments RPCs.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Viktor Somogyi <viktorsomogyi@gmail.com>",2019-07-29 14:35:55,Stanislav Kozlovski,Not TDD
204710832eb4787b185264a0c8e5fe89a3db9d44,"KAFKA-8640; Use generated classes in OffsetFetch request and response (#7062)

Reviewers: Jason Gustafson <jason@confluent.io>",2019-07-30 08:29:45,Boyang Chen,Mixed
c6286b2b3e0d573773844f9b0a2931e9c2058f58,"KAFKA-8442; Include ISR in Metadata response even if there is no leader (#6836)

Currently the Metadata response returns an empty ISR if there is no active leader. The behavior is inconsistent since other fields such as the replica list and offline replicas are included. This patch changes the behavior to return the current known ISR. This fixes a problem with the topic describe command which fails to report ISR when a leader is offline.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-07-30 08:44:11,huxi,Mixed
a48b5d900c6b5c9c52a97124a1b51aff3636c32c,"KAFKA-8717; Reuse cached offset metadata when reading from log (#7081)

Although we currently cache offset metadata for the high watermark and last stable offset, we don't use it when reading from the log. Instead we always look it up from the index. This patch pushes fetch isolation into `Log.read` so that we are able to reuse the cached offset metadata.

Reviewers: Jun Rao <junrao@gmail.com>",2019-07-30 08:50:13,Jason Gustafson,Mixed
de8ce78a90632b0d79e0a6ad6abb638982376b52,"MINOR: Tolerate limited data loss for upgrade tests with old message format (#7102)

To avoid transient system test failures, tolerate a small amount of data loss due to truncation in upgrade system tests using older message format prior to KIP-101, where data loss was possible.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2019-07-31 16:19:36,Rajini Sivaram,Not TDD
211745d0b3346b69451932358f45987dc790858f,"MINOR: Small cleanups in TopicCommand describe handling (#7136)

This patch contains a few small cleanups to make topic describe logic a little clearer. It also fixes a minor inconsistency in the output between the --zookeeper and --bootstrap-server behavior when the leader is unknown. Previously we printed -1 when --zookeeper was used, and now we print ""none."" The patch consolidates the output logic for describing topics and partitions in order to avoid inconsistencies like this in the future.

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",2019-07-31 08:27:38,Jason Gustafson,Mixed
6fbac3cfa88bd3eba36b2d3e254d7ce5e11a550b,"KAFKA-8179: PartitionAssignorAdapter (#7110)

Follow up to new PartitionAssignor interface merged in 7108 is merged

Adds a PartitionAssignorAdapter class to maintain backwards compatibility

Reviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-07-31 13:53:38,A. Sophie Blee-Goldman,Mixed
2c2b30d96b7d30037d3ee69ebbf985cd88557af9,"MINOR: Add RandomComponentPayloadGenerator and update Trogdor documentation (#7103)

Add a new RandomComponentPayloadGenerator that gives a payload based on random selection of another PayloadGenerator.  Additionally, add an example that uses a non-default PayloadGenerator configuration to TROGDOR.md.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2019-07-31 14:00:49,jolshan,Mixed
a028f597d7ea042c414e9669d2261c1423a96f95,"KAFKA-8731: InMemorySessionStore throws NullPointerException on startup (#7132)

Reviewers:  Matthias J. Sax <mjsax@apache.org>, Bill Bejeck <bbejeck@gmail.com>",2019-07-31 17:19:46,A. Sophie Blee-Goldman,Not TDD
717c55be971df862c55f55d245b9997f1d6f998c,"KAFKA-8601: Implement KIP-480: Sticky Partitioning for keyless records (#6997)

Implement KIP-480, which specifies that the default partitioner should use a ""sticky"" partitioning strategy for records that have a null key.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Lucas Bradstreet <lucasbradstreet@gmail.com>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jun Rao <junrao@gmail.com>, Kamal Chandraprakash  <kamal.chandraprakash@gmail.com>",2019-08-01 14:36:12,Justine Olshan,Mixed
1546fc30af520f8d133aa3454cdc8a036bae0f3e,"KAFKA-7548; KafkaConsumer should not discard fetched data for paused partitions (#6988)

This is an updated implementation of #5844 by @MayureshGharat (with Mayuresh's permission). As described in the original ticket:

> Today when we call KafkaConsumer.poll(), it will fetch data from Kafka asynchronously and is put in to a local buffer (completedFetches).
>
> If now we pause some TopicPartitions and call KafkaConsumer.poll(), we might throw away any buffered data that we might have in the local buffer for these TopicPartitions. Generally, if an application is calling pause on some TopicPartitions, it is likely to resume those TopicPartitions in near future, which would require KafkaConsumer to re-issue a fetch for the same data that it had buffered earlier for these TopicPartitions. This is a wasted effort from the application's point of view.

This patch fixes the problem by retaining the paused data in the completed fetches queue, essentially moving it to the back on each call to `fetchedRecords`. 

Reviewers: Jason Gustafson <jason@confluent.io>",2019-08-01 17:10:19,Sean Glover,Mixed
a7d0fdd534ef55533a868ea7388bbc081ee42718,"KAFKA-8578: Add basic functionality to expose RocksDB metrics (#6979)

* Adds RocksDBMetrics class that provides methods to get sensors from the Kafka metrics registry and to setup the sensors to record RocksDB metrics

* Extends StreamsMetricsImpl with functionality to add the required metrics to the sensors.

Reviewers: Boyang Chen <boyang@confluent.io>, Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, John Roesler <vvcephei@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",2019-08-02 09:51:03,cadonna,Mixed
a99e0111114d1cb8c762494ac195cf84e6425bb3,"KAFKA-7800; Dynamic log levels admin API (KIP-412)

<!--
Is there any breaking changes?  If so this is a major release, make sure '#major' is in at least one
commit message to get CI to bump the major.  This will prevent automatic down stream dependency
bumping / consuming.  For more information about semantic versioning see: https://semver.org/

Suggested PR template: Fill/delete/add sections as needed. Optionally delete any commented block.
-->
What
----
<!--
Briefly describe **what** you have changed and **why**.
Optionally include implementation strategy.
-->

References
----------
[**KIP-412**](https://cwiki.apache.org/confluence/display/KAFKA/KIP-412%3A+Extend+Admin+API+to+support+dynamic+application+log+levels)
[**KAFKA-7800**](https://issues.apache.org/jira/browse/KAFKA-7800)
[**Discussion Thread**](http://mail-archives.apache.org/mod_mbox/kafka-dev/201901.mbox/%3CCANZZNGyeVw8q%3Dx9uOQS-18wL3FEmnOwpBnpJ9x3iMLdXY3gEug%40mail.gmail.com%3E)
[**Vote Thread**](http://mail-archives.apache.org/mod_mbox/kafka-dev/201902.mbox/%3CCANZZNGzpTJg5YX1Gpe5S%3DHSr%3DXGvmxvYLTdA3jWq_qwH-UvorQ%40mail.gmail.com%3E)

<!--
Copy&paste links: to Jira ticket, other PRs, issues, Slack conversations...
For code bumps: link to PR, tag or GitHub `/compare/master...master`
-->

Test&Review
------------
Test cases covered:
* DescribeConfigs
* Alter the log level with and without validateOnly, validate the results with DescribeConfigs

Open questions / Follow ups
--------------------------
If you're a reviewer, I'd appreciate your thoughts on these questions I have open:
1. Should we add synchronization to the Log4jController methods? - Seems like we don't get much value from it
2. Should we instantiate a new Log4jController instead of it having static methods? - All operations are stateless, so I thought static methods would do well
3. A logger which does not have a set value returns ""null"" (as seen in the unit tests). Should we just return the Root logger's level?

Author: Stanislav Kozlovski <familyguyuser192@windowslive.com>

Reviewers: Gwen Shapira

Closes #6903 from stanislavkozlovski/KAFKA-7800-dynamic-log-levels-admin-ap",2019-08-02 11:51:35,Stanislav Kozlovski,Mixed
0b1dc1ca7be3566a4367d7d3aae2c691cf94f48e,"KAFKA-6263; Expose metrics for group and transaction metadata loading duration

[JIRA](https://issues.apache.org/jira/browse/KAFKA-6263)

- Add metrics to provide visibility for how long group metadata and transaction metadata take to load in order to understand some inactivity seen in the consumer groups
- Tests include mocking load times by creating a delay after each are loaded and ensuring the measured JMX metric is as it should be

Author: anatasiavela <anastasiavela@berkeley.edu>

Reviewers: Gwen Shapira, Jason Gustafson

Closes #7045 from anatasiavela/KAFKA-6263",2019-08-03 21:00:46,anatasiavela,Mixed
f70ece26d1cce23556f8f69ca2ccb2bb9e4f4de1,"MINOR: Fix potential bug in LogConfig.getConfigValue and improve test coverage (#7159)

LogConfig.getConfigValue would throw a NoSuchElementException if any log
config was defined without a server default mapping.

Added a unit test for `getConfigValue` and a sanity test for
`toHtml`/`toRst`/`toEnrichedRst`, which were previously not exercised during
the test suite.

Reviewers: Jason Gustafson <jason@confluent.io>, José Armando García Sancio <jsancio@users.noreply.github.com>",2019-08-03 23:59:06,Ismael Juma,Mixed
7663a6c44daae5d72f38cbba79d728416e11167d,"Minor: Refactor methods to add metrics to sensor in `StreamsMetricsImpl` (#7161)

Renames method names in StreamsMetricsImpl to make them consistent.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-08-06 08:51:08,cadonna,Mixed
e4e2dd31ca66330aefdbb226eb25968bb14fee64,"MINOR: some small style fixes to RoundRobinPartitioner

Author: Colin P. Mccabe <cmccabe@confluent.io>

Reviewers: Gwen Shapira

Closes #7058 from cmccabe/rr-style-fixes",2019-08-06 12:25:23,Colin P. Mccabe,Mixed
926fb35d9dcefd45c1e1d276ee7252b15875f23e,"KAFKA-8599: Use automatic RPC generation in ExpireDelegationToken

Author: Mickael Maison <mickael.maison@gmail.com>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Viktor Somogyi <viktorsomogyi@gmail.com>

Closes #7098 from mimaison/KAFKA-8599",2019-08-07 13:32:26,Mickael Maison,Not TDD
e867a58425876767b952e06892c72b5e13066acc,"KAFKA-8179: Part 3, Add PartitionsLost API for resetGenerations and metadata/subscription change (#6884)

1. Add onPartitionsLost into the RebalanceListener, which will be triggered when the consumer found that the generation is reset due to fatal errors in response handling.

2. Semantical behavior change: with COOPERATIVE protocol, if the revoked / lost partitions are empty, do not trigger the corresponding callback at all. For added partitions though, even if it is empty we would still trigger the callback as a way to notify the rebalance event; with EAGER protocol, revoked / assigned callbacks are always triggered.

The ordering of the callback would be the following:

a. Callback onPartitionsRevoked / onPartitionsLost triggered.
b. Update the assignment (both revoked and added).
c. Callback onPartitionsAssigned triggered.

In this way we are assured that users can still access the partitions being revoked, whereas they can also access the partitions being added.

3. Semantical behavior change (KAFKA-4600): if the rebalance listener throws an exception, pass it along all the way to the consumer.poll caller, but still completes the rest of the actions. Also, the newly assigned partitions list does not gets affected with exception thrown since it is just for notifying the users.

4. Semantical behavior change: the ConsumerCoordinator would not try to modify assignor's returned assignments, instead it will validate that assignments and set the error code accordingly: if there are overlaps between added / revoked partitions, it is a fatal error and would be communicated to all members to stop; if revoked is not empty, it is an error indicate re-join; otherwise, it is normal.

5. Minor: with the error code removed from the Assignment, ConsumerCoordinator will request re-join if the revoked partitions list is not empty.

6. Updated ConsumerCoordinatorTest accordingly. Also found a minor bug in MetadataUpdate that removed topic would still be retained with null value of num.partitions.

6. Updated a few other flaky tests that are exposed due to this change.

Reviewers: John Roesler <vvcephei@users.noreply.github.com>, A. Sophie Blee-Goldman <sophie@confluent.io>, Jason Gustafson <jason@confluent.io>",2019-08-08 14:31:22,Guozhang Wang,Mixed
5e543ae10832808a9d7efef363603f07695d4368,"KAFKA-8598: Use automatic RPC generation in RenewDelegationToken

Author: Mickael Maison <mickael.maison@gmail.com>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Viktor Somogyi <viktorsomogyi@gmail.com>

Closes #7038 from mimaison/KAFKA-8598",2019-08-09 12:49:38,Mickael Maison,Not TDD
7511ccf68dc41a78bdef8f34e57d94b600666232,"KAFKA-8550: Fix plugin loading of aliased converters in Connect (#6959)

Connector validation fails if an alias is used for the converter since the validation for that is done via `ConfigDef.validateAll(...)`, which in turn invokes `Class.forName(...)` on the alias. Even though the class is successfully loaded by the DelegatingClassLoader, some Java implementations will refuse to return a class from `Class.forName(...)` whose name differs from the argument provided.

This commit alters `ConfigDef.parseType(...)` to first invoke `ClassLoader.loadClass(...)` on the class using our class loader in order to get a handle on the actual class object to be loaded, then invoke `Class.forName(...)` with the fully-qualified class name of the to-be-loaded class and return the result. The invocation of `Class.forName(...)` is necessary in order to allow static initialization to take place; simply calling `ClassLoader.loadClass(...)` is insufficient.

Also corrected a unit test that relied upon the old behavior.

Author: Chris Egerton <chrise@confluent.io>
Reviewers: Robert Yokota <rayokota@gmail.com>, Randall Hauch <rhauch@gmail.com>",2019-08-11 09:56:05,Chris Egerton,Mixed
558bb1d0692b3ba6cf9c46d7170be6d31656024b,"KAFKA-8782: Close metrics in QuotaManagerTests (#7191)

Since `Metrics` was constructed with `enableExpiration=false`, this was
not a source of flakiness given the current implementation. This could
change in the future, so good to follow the class contract.

Included a few clean-ups with regards to redundant casts and type parameters
as well as usage of try with resources for inline usage of `Metrics`.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2019-08-11 15:31:42,Ismael Juma,Mixed
88087e91dd4eed1ee3c3e12961db84b7b56c34a0,"MINOR: Clean up the sticky partitioner code a bit (#7151)

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Lucas Bradstreet <lucasbradstreet@gmail.com>",2019-08-12 14:17:28,Justine Olshan,Not TDD
794637232cea44ee458839a293091473e81fb01e,"KAFKA-8774: Regex can be found anywhere in config value (#7197)

Corrected the AbstractHerder to correctly identify task configs that contain variables for externalized secrets. The original method incorrectly used `matcher.matches()` instead of `matcher.find()`. The former method expects the entire string to match the regex, whereas the second one can find a pattern anywhere within the input string (which fits this use case more correctly).

Added unit tests to cover various cases of a config with externalized secrets, and updated system tests to cover case where config value contains additional characters besides secret that requires regex pattern to be found anywhere in the string (as opposed to complete match).

Author: Arjun Satish <arjun@confluent.io>
Reviewer: Randall Hauch <rhauch@gmail.com>",2019-08-13 09:40:12,Arjun Satish,Mixed
e2c8612d01f5e6e97476b1656fe728b2f316efef,"KAFKA-7941: Catch TimeoutException in KafkaBasedLog worker thread (#6283)

When calling readLogToEnd(), the KafkaBasedLog worker thread should catch TimeoutException and log a warning, which can occur if brokers are unavailable, otherwise the worker thread terminates.

Includes an enhancement to MockConsumer that allows simulating exceptions not just when polling but also when querying for offsets, which is necessary for testing the fix.

Author: Paul Whalen <pgwhalen@gmail.com>
Reviewers: Randall Hauch <rhauch@gmail.com>, Arjun Satish <arjun@confluent.io>, Ryanne Dolan <ryannedolan@gmail.com>",2019-08-13 10:16:54,Paul,Mixed
e5657bc910bbf82638a8b6c3e96c30101cf27560,"KAFKA-8391; Improved the Connect integration tests to make them less flaky

Added the ability for the connector handles and task handles, which are used by the monitorable source and sink connectors used to verify the functionality of the Connect framework, to record the number of times the connector and tasks have each been started, and to allow a test to obtain a `RestartLatch` that can be used to block until the connectors and/or tasks have been restarted a specified number of types.

Typically, a test will get the `ConnectorHandle` for a connector, and call the `ConnectorHandle.expectedRestarts(int)` method with the expected number of times that the connector and/or tasks will be restarted, and will hold onto the resulting `RestartLatch`. The test will then change the connector (or otherwise cause the connector to restart) one or more times as desired, and then call `RestartLatch.await(long, TimeUnit)` to block the test up to a specified duration for the connector and all tasks to be started the specified number of times.

This commit also increases several of the maximum wait times used in other integration tests. It doesn’t hurt to potentially wait longer, since most test runs will not need to wait the maximum amount of time anyway. However, in the rare cases that do need that extra time, waiting a bit more is fine if we can reduce the flakiness and minimize test failures that happened to time out too early.

Unit tests were added for the new `RestartLatch` and `StopAndStartCounter` utility classes. This PR only affects the tests and does not affect any runtime code or API.

**This should be merged on `trunk` and backported to the `2.3.x` branch.**

Author: Randall Hauch <rhauch@gmail.com>

Reviewers: Konstantine Karantasis, Arjun Satish

Closes #7019 from rhauch/kafka-8391",2019-08-13 11:14:41,Randall Hauch,Mixed
245e9caa4418f9c2241ce1e518d5159ec6e53ad1,"KAFKA-8791: RocksDBTimestampedStore should open in regular mode by default (#7201)

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Bill Bejeck <bill@confluent.io>, Richard Yu <yohan.richard.yu@gmail.com>, Guozhang Wang <guozhang@confluent.io>",2019-08-13 18:37:45,Matthias J. Sax,Mixed
39158bd944f7c64e32634cec8171515b93466ffa,"KAFKA-8765: Remove interface annotations in Streams API (#7174)

Reviewers: Bruno Cadonna <cadonna@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-08-13 22:39:42,Matthias J. Sax,Not TDD
5129ab53ee9a2e46a22a13b1d5300ee139c4999f,"KAFKA-8345: KIP-455: Admin API changes (Part 2) (#7120)

Add the AlterPartitionReassignments and ListPartitionReassignments APIs.  Also remove an unused methodlength suppression for KafkaAdminClient.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Viktor Somogyi <viktorsomogyi@gmail.com>",2019-08-14 09:25:17,Stanislav Kozlovski,Mixed
4d169f5a859ac1d4a34134ef5b6def574769aa43,"KAFKA-7335; Store clusterId locally to ensure broker joins the right cluster (#7189)

This patch stores `clusterId` in the `meta.properties` file. During startup, the broker checks that it joins the correct cluster and fails fast otherwise.

The `meta.properties' is versioned. I have decided to not bump the version because 1) the clusterId is null anyway if not present in the file; and 2) bumping it means that rolling back to a previous version won't work.

I have refactored the way the metadata is read and written as it was strongly coupled with the brokerId bits. Now, the metadata is read independently during the startup and used to 1) check the clusterId and 2) get or generate the brokerId (as before).

Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",2019-08-14 09:56:03,David Jacot,Not TDD
ebf78c04c9aa841f7bd702afdbc782cc07b35ad8,"KAFKA-8788: Optimize client metadata handling with a large number of partitions (#7192)

Credit to @lbradstreet for profiling the producer with a large number of partitions.

Cache `topicMetadata`, `brokers` and `controller` in the `MetadataResponse`
the first time it's needed avoid unnecessary recomputation. We were previously
computing`brokersMap` 4 times per partition in one code path that was invoked from
multiple places. This is a regression introduced via a42f16f980 and first released
in 2.3.0.

The `Cluster` constructor became significantly more allocation heavy due to
2c44e77e2f20, first released in 2.2.0. Replaced `merge` calls with more verbose,
but more efficient code. Added a test to verify that the returned collections are
unmodifiable.

Add `topicAuthorizedOperations` and `clusterAuthorizedOperations` to
`MetadataResponse` and remove `data()` method.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Lucas Bradstreet <lucasbradstreet@gmail.com>, Colin P. McCabe <cmccabe@confluent.io>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Justine Olshan <jolshan@confluent.io>",2019-08-14 19:44:38,Ismael Juma,Mixed
14215d1b84e937c4656e0984c1ce76d9aac65bdd,"MINOR: Use max retries for consumer group tests to avoid flakiness (#7186)

This patch updates ConsumerGroupCommandTest.scala to use the maximum possible number of AdminClient retries. The test runs will still be bounded by the request timeout. This address flakiness in tests such as testResetOffsetsNotExistingGroup and testResetOffsetsExistingTopic, which was caused by group coordinators being intermittently unavailable. 

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2019-08-15 13:47:56,Bob Barrett,Mixed
83a575d4b92a7a49917244dbf7cdee0d2c5aa253,"MINOR: Fix bugs in handling zero-length ImplicitLinkedHashCollections (#7163)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2019-08-15 15:49:28,Mickael Maison,Mixed
bd7d92e0c3dae4841f23f796f50384e6653111a2,"KAFKA-8592; Fix for resolving variables for dynamic config as per KIP-421. (#7031)

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Stanislav Kozlovski <familyguyuser192@windowslive.com>",2019-08-16 08:43:24,Jeff Huang,Not TDD
b8605c9bc1331b876f9d134ebc8fcf9bfc684c8e,"KAFKA-8600: Use RPC generation for DescribeDelegationTokens protocol

Refactors the DescribeDelegationToken to use the generated RPC classes.

Author: Viktor Somogyi-Vass <viktorsomogyi@gmail.com>
Author: Viktor Somogyi <viktorsomogyi@gmail.com>

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #7154 from viktorsomogyi/refactor-describe-dt",2019-08-16 23:05:54,Viktor Somogyi-Vass,Not TDD
33d06082117d971cdcddd4f01392006b543f3c01,"MINOR: Remove Deprecated Scala Procedure Syntax (#7214)

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>",2019-08-16 13:28:10,Justine Olshan,Mixed
b9ffe596864b576d81c3ca0ae060ae4ac9006d0c,"KAFKA-8601: Add UniformStickyPartitioner and tests (#7199)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2019-08-16 16:04:03,Justine Olshan,Mixed
4d1ee26a136997d31dbd6ddca07e09b34c41c77d,"KAFKA-8594: Add version 2.3 to Streams system tests (#7131)

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>, Bill Bejeck <bill@confluent.io>",2019-08-21 10:26:57,Matthias J. Sax,Not TDD
35bc53c55ff317890d13490443a8685adfc33084,"KIP-476: Add new getAdmin method to KafkaClientSupplier (#7162)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Ismael Juma <ismael@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-08-21 19:48:00,Andy Coates,Not TDD
e4215c17846d8790712ee1764f3f852d99d3fc3a,"KAFKA-8325; Remove batch from in-flight requests on MESSAGE_TOO_LARGE errors (#7176)

This patch fixes a bug in the handling of MESSAGE_TOO_LARGE errors. The large batch is split, the smaller batches are re-added to the accumulator, and the batch is deallocated, but it was not removed from the list of in-flight batches. When the batch was eventually expired from the in-flight batches, the producer would try to deallocate it a second time, causing an error. This patch changes the behavior to correctly remove the batch from the list of in-flight requests.

Reviewers: Luke Stephenson, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2019-08-21 23:29:20,Bob Barrett,Mixed
e213608127696dd742752bbc57da209e8eade0f2,"KAFKA-8824: bypass value serde on null (#7235)

In a KTable context, we should not pass null into a user-supplied serde.

Testing: I verified that the change to the test results in test failures without the patch.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>,",2019-08-22 13:35:33,John Roesler,Mixed
c1f2b0ffb820c4af030f24ca50693d8169261f95,"KAFKA-8753; Expose controller topic deletion metrics (KIP-503) (#7156)

This is the implementation for [KIP-503](https://cwiki.apache.org/confluence/display/KAFKA/KIP-503%3A+Add+metric+for+number+of+topics+marked+for+deletion)

When deleting a large number of topics, the Controller can get quite bogged down. One problem with this is the lack of visibility into the progress of the Controller. We can look into the ZK path for topics marked for deletion, but in a production environment this is inconvenient. This PR adds a JMX metric `kafka.controller:type=KafkaController,name=TopicsToDeleteCount` to make it easier to see how many topics are being deleted.

Reviewers: Stanislav Kozlovski <stanislav@confluent.io>, Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-08-23 13:22:41,David Arthur,Not TDD
237e83dea081b38d2af8fa465df4f1914747ba6f,"KAFKA-8586: Fail source tasks when producers fail to send records (#6993)

Changed Connect's `WorkerSourceTask` to capture non-retriable exceptions from the `producer.send(...)` (e.g., authentication or authorization errors) and to fail the connector task when such an error is encountered. Modified the existing unit tests to verify this functionality.

Note that most producer errors are retriable, and Connect will (by default) set up each producer with 1 max in-flight message and infinite retries. This change only affects non-retriable errors.",2019-08-25 15:54:00,Chris Egerton,Mixed
7334222a71d522f2e99ee84622c672a4c5636e1f,"KAFKA-8412: Fix nullpointer exception thrown on flushing before closing producers (#7207)

Prior to this change an NPE is raised when calling AssignedTasks.close
under the following conditions:

1. EOS is enabled
2. The task was in a suspended state

The cause for the NPE is that when a clean close is requested for a
StreamTask the StreamTask tries to commit. However, in the suspended
state there is no producer so ultimately an NPE is thrown for the
contained RecordCollector in flush.

The fix put forth in this commit is to have AssignedTasks call
closeSuspended when it knows the underlying StreamTask is suspended.

Note also that this test is quite involved. I could have just tested
that AssignedTasks calls closeSuspended when appropriate, but that is
testing, IMO, a detail of the implementation and doesn't actually verify
we reproduced the original problem as it was described. I feel much more
confident that we are reproducing the behavior - and we can test exactly
the conditions that lead to it - when testing across AssignedTasks and
StreamTask. I believe this is an additional support for the argument of
eventually consolidating the state split across classes.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-08-26 09:53:36,cpettitt-confluent,Not TDD
d08bcae7f99a863b6d2058a1568384f904e539ed,"KAFKA-8669: Add security providers in kafka security config (#7090)

* Adds custom provider class to security config 
* Implementation of KIP-492
Reviewers: Sriharsha Chintalapani <sriharsha@apache.org> , Jeff Huang",2019-08-26 10:01:01,saisandeep,Mixed
6b24b2e8363180cc9cfbca11dbce9cf60c7013be,"KAFKA-8816: Make offsets immutable to users of RecordCollector.offsets (#7223)

Make offsets immutable to users of RecordCollector.offsets. Fix up an
existing case where offsets could be modified in this way. Add a simple
test to verify offsets cannot be changed externally.

Reviewers: Bruno Cadonna <bruno@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2019-08-26 13:59:49,cpettitt-confluent,Mixed
24547b810ce9aae4389dad7f41cc47caba73046c,"KAFKA-8579: Expose RocksDB metrics (#7209)

RocksDB metrics are added to the Kafka metrics. For each segmented state store only
one set of metrics is exposed rather than one set of metrics for each segment.

The metrics are not computed yet.

Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-08-26 16:28:22,Bruno Cadonna,Mixed
e23a7182d5252a057e053dd19554c515100dc63b,"KAFKA-8745: DumpLogSegments doesn't show keys, when the message is null (#7152)

Make sure to show the message key, even when the message value is null.

This changes the output of one of the tools. Is the output of the tool considered a public API? Does this need a discussion or a KIP?

Testing: Ran the tool on a compacted topic. Previously, the tool did not show any message keys for tombstone messages (messages where the value is null). Now, the tool shows message keys.

Reviewers: Mickael Maison <mimaison@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",2019-08-27 13:01:29,James Cheng,Mixed
cf32a1a6a06df910dd11f26abe7b62e560392e25,"KAFKA-8179: Part 4, add CooperativeStickyAssignor (#7130)

Splits the existing StickyAssignor logic into an AbstractStickyAssignor class, which is extended by the existing (eager) StickyAssignor and by the new CooperativeStickyAssignor which supports incremental cooperative rebalancing.

There is no actual change to the logic -- most methods from StickyAssignor were moved to AbstractStickyAssignor to be shared with CooperativeStickyAssignor, and the abstract MemberData memberData(Subscription) method converts the Subscription to the embedded list of owned partitions for each assignor.

The ""generation"" logic is left in, however this is always Optional.empty() for the CooperativeStickyAssignor as onPartitionsLost should always be called when a generation is missed.

Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-08-27 14:41:33,A. Sophie Blee-Goldman,Mixed
826408e12204d4260c018ee1da7a327193682ada,"MINOR: Initialize BrokerTopicMetrics with no topic tag greedily (#7198)

This patch fixes the quota system test whose JMX tool relies on the existence
of these metrics.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Nikhil Bhatia <nikhil@confluent.io>, Tu V. Tran <tuvtran97@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2019-08-27 21:12:38,Stanislav Kozlovski,Not TDD
d32a2d12757e24311cae8f495a3b6f2150f3e041,"KAFKA-8837: KafkaMetricReporterClusterIdTest may not shutdown ZooKeeperTestHarness (#7255)

- Call `assertNoNonDaemonThreads` in test method instead of tear down method
to avoid situation where parent's class tear down is not invoked.
- Pass the thread prefix in tests that call `assertNoNonDaemonThreads` so that it
works correctly.
- Rename `verifyNonDaemonThreadsStatus` to `assertNoNonDaemonThreads` to
make it clear that it may throw.

Reviewers: Anna Povzner <anna@confluent.io>, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2019-08-27 22:23:19,Anastasia Vela,Not TDD
d18d6b033e09515adff19225f8ec6845ca34c23b,"MINOR: Refactor tag key for store level metrics (#7257)

The tag key for store level metrics specified in StreamsMetricsImpl
is unified with the tag keys on thread and task level.

Reviewers: Sophie Blee-Goldman <sophie@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",2019-08-30 09:46:07,Bruno Cadonna,Mixed
364794866f82d2d99f7a610d699478d5055688f0,"KAFKA-8760; New Java Authorizer API (KIP-504) (#7268)

New Java Authorizer API and a new out-of-the-box authorizer (AclAuthorizer) that implements the new interface.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2019-09-02 14:43:17,Rajini Sivaram,Mixed
88d1b6de1f0e5b5228743f4f54ac01a2a153adf9,"KAFKA-8860: Let SslPrincipalMapper split SSL principal mapping rules

Author: teebee <tb@teebee.de>

Reviewers: Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #7140 from teebee/teebee/ssl-principal-mapping-rules-handling",2019-09-02 23:32:49,teebee,Mixed
8dc80e22973d89090833cb791d9269e9a0598059,"KAFKA-7849: Fix the warning when using GlobalKTable (#7104)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-09-03 23:23:59,Omar Al-Safi,Mixed
8d8e2fb5c94a2287d62fe010c87fe0c8728e88c0,"KAFKA-8729, pt 1: Add 4 new metrics to keep track of various types of invalid record rejections (#7142)

Right now we only have very generic FailedProduceRequestsPerSec and FailedFetchRequestsPerSec metrics that mark whenever a record is failed on the broker side. To improve the debugging UX, I added 4 new metrics in BrokerTopicStats to log various scenarios when an InvalidRecordException is thrown when LogValidator fails to validate a record:

-- NoKeyCompactedTopicRecordsPerSec: counter of failures by compacted records with no key
-- InvalidMagicNumberRecordsPerSec: counter of failures by records with invalid magic number
-- InvalidMessageCrcRecordsPerSec: counter of failures by records with crc corruption
-- NonIncreasingOffsetRecordsPerSec: counter of failures by records with invalid offset

Reviewers: Robert Yokota <rayokota@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2019-09-04 12:46:30,Tu V. Tran,Mixed
b66ea874406c3b4d59b23e47e036cbdd4c843c7a,"KAFKA-8866; Return exceptions as Optional<ApiException> in authorizer API (#7294)

Reviewers: Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy <manikumar.reddy@gmail.com>",2019-09-05 09:21:01,Rajini Sivaram,Mixed
c9318ced19c812c90066af468732d8af8d12f890,"KAFKA-8857; Don't check synonyms while determining if config is readOnly (#7278)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2019-09-05 09:23:11,Rajini Sivaram,Not TDD
deac5d93cef000f408332a7648a3062e4e25e388,"KAFKA-8724; Improve range checking when computing cleanable partitions (#7264)

This patch contains a few improvements on the offset range handling when computing the cleanable range of offsets.

1. It adds bounds checking to ensure the dirty offset cannot be larger than the log end offset. If it is, we reset to the log start offset.
2. It adds a method to get the non-active segments in the log while holding the lock. This ensures that a truncation cannot lead to an invalid segment range.
3. It improves exception messages in the case that an inconsistent segment range is provided so that we have more information to find the root cause.

The patch also fixes a few problems in `LogCleanerManagerTest` due to unintended reuse of the underlying log directory.

Reviewers: Vikas Singh <soondenana@users.noreply.github.com>, Jun Rao <junrao@gmail.com>",2019-09-05 09:10:52,Jason Gustafson,Mixed
ffef0871c2d64bcbc171b129c2057b572c2f41b2,"KAFKA-7149 : Reducing streams assignment data size  (#7185)

* Leader instance uses dictionary encoding on the wire to send topic partitions
* Topic names (most expensive component) are mapped to an integer using the dictionary
* Follower instances receive the dictionary, decode topic names back
* Purely an on-the-wire optimization, no in-memory structures changed
* Test case added for version 5 AssignmentInfo

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-09-05 13:50:55,vinoth chandar,Mixed
c0019e653891182d7a95464175c9b4ef63f8bae1,"KAFKA-8590; Use automated TxnOffsetCommit type and add tests for OffsetCommit  (#6994)

This PR changes the TxnOffsetCommit protocol to auto-generated types, and add more unit test coverage to the plain OffsetCommit protocol.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-09-05 23:07:42,Boyang Chen,Mixed
c65e19ae95549f7dc49eec3e5fd3cc2de84687d9,"MINOR: Use toString in Records implementations only for summary metadata (#7290)

This patch fixes a couple problems with logging of request/response objects which include records data. First, it adds a missing `toString` to `LazyDownConversionRecords`. Second, it changes the `toString` of `MemoryRecords` to not print record-level information. This was always a dangerous practice, but it was especially bad when these objects ended up in request logs. With this patch, implementations use `toString` only to print summary details.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-09-06 00:54:53,Jason Gustafson,Mixed
0f177ea6b826cd96f7a4a687da3691fb786a0a89,"MINOR: Clean up partition assignment logic (#7249)

These are just some ""tidying up"" changes I made when I was preparing to start working on KIP-441.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-09-08 17:06:06,John Roesler,Mixed
e59e4caadc48ee3ba3325d98cbc1fc714ced2b8e,"KAFKA-8222 & KIP-345 part 5: admin request to batch remove members (#7122)

This PR adds supporting features for static membership. It could batch remove consumers from the group with provided group.instance.id list.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-09-09 13:06:47,Boyang Chen,Mixed
18246e509ee39736d38694b98e0c98ee73c6675f,"KAFKA-8878: Fix flaky test AssignedStreamsTasksTest#shouldCloseCleanlyWithSuspendedTaskAndEOS (#7302)

The previous approach to testing KAFKA-8412 was to look at the logs and
determine if an error occurred during close. There was no direct way to
detect than an exception occurred because the exception was eaten in
AssignedTasks.close. In the PR for that ticket (#7207) it was
acknowledged that this was a brittle way to test for the exception. We
now see occasional failures because an unrelated ERROR level log entry
is made while closing the task.

This change eliminates the brittle log checking by rethrowing any time
an exception occurs in close, even when a subsequent unclean close
succeeds. This has the potential benefit of uncovering other supressed
exceptions down the road.

I've verified that even with us rethrowing on closeUnclean that all
tests pass.

Reviewers: Matthias J. Sax <mjsax@apache.org>,  Bill Bejeck <bbejeck@gmail.com>",2019-09-10 16:37:34,cpettitt-confluent,Not TDD
18d4e57f6e8c67ffa7937fc855707d3a03cc165a,"KAFKA-8345 (KIP-455): Controller and KafkaApi changes (part 3/4) (#7128)

Implement the revisions to the controller state machine and reassignment logic needed for KIP-455.

Add the addingReplicas and removingReplicas field to the topics ZNode.

Deprecate the methods initiating a reassignment via direct ZK access in KafkaZkClient.

Add ControllerContextTest, and add some test cases to ReassignPartitionsClusterTest.

Add a note to upgrade.html recommending not initiating reassignments during an upgrade.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Viktor Somogyi <viktorsomogyi@gmail.com>",2019-09-10 22:19:44,Stanislav Kozlovski,Mixed
6882b3b760de3208ee0cca86d6e1a651cc5e5a1f,"KAFKA-8886; Make Authorizer create/delete API asynchronous (#7316)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2019-09-11 16:56:56,Rajini Sivaram,Mixed
6a3a58039943aa047fbd07abfc7eff6431c367a5,"KAFKA-8856: Add Streams config for backward-compatible metrics (#7279)

Reviewers: John Roesler <vvcephei@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",2019-09-11 11:01:39,Bruno Cadonna,Mixed
d3559f628b2ccb23a9faf531796675376ac06abb,"KAFKA-8875; CreateTopic API should check topic existence before replication factor (#7298)

If the topic already exists, `handleCreateTopicsRequest` should return TopicExistsException even given an invalid config (replication factor for instance).

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>",2019-09-11 14:24:27,huxi,Not TDD
23708b77db110bdb20bf4a01b656d1b0ccc0f864,"KAFKA-8355: add static membership to range assignor (#7014)

The purpose of this PR is to add static membership support for range assignor. More details for the motivation in here.

Similar to round robin assignor, if we are capable of persisting member identity across generations, we will reach a much more stable assignment.

Reviewers: John Roesler <vvcephei@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>, Bruno Cadonna <bruno@confluent.io>",2019-09-12 09:57:22,Boyang Chen,Mixed
6530600e6b314565f100b65ae774f3f409ed9828,"MINOR: Add UUID type to Kafka API code generation (#7291)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2019-09-13 11:36:58,John Roesler,Not TDD
83c7c0158fc62c294267f0ae60e9f52945e6a678,"KAFKA-8755: Fix state restore for standby tasks with optimized topology (#7238)

Key changes include:

1. Moves general offset limit updates down to StandbyTask.
2. Updates offsets for StandbyTask at most once per commit and only when we need and updated offset limit to make progress.
3. Avoids writing an 0 checkpoint when StandbyTask.update is called but we cannot apply any of the records.
4. Avoids going into a restoring state in the case that the last checkpoint is greater or equal to the offset limit (consumer committed offset). This needs special attention please. Code is in
StoreChangelogReader.
5. Does update offset limits initially for StreamTask because it provides a way to prevent playing to many records from the changelog (also the input topic with optimized topology).

NOTE: this PR depends on KAFKA-8816, which is under review separately. Fortunately the changes involved are few. You can focus just on the KAFKA-8755 commit if you prefer.

Reviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",2019-09-13 15:45:29,cpettitt-confluent,Mixed
ac385c4c3a770728848438f28f4acb8854ffc868,"KAFKA-8474; Use HTML lists for config layout (#6870)

Replace the `<table>` elements by `<ul>` so the full page width can be used for the configuration descriptions instead of only a very narrow column. I moved the other fields (Type, Default Value, etc) below each entry.

Reviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>",2019-09-13 15:48:36,Mickael Maison,Mixed
e24d0e22abb0fb3e4cb3974284a3dad126544584,"KAFKA-8730; Add API to delete consumer offsets (KIP-496) (#7276)

This adds an administrative API to delete consumer offsets of a group as well as extends the mechanism to expire offsets of consumer groups.

It makes the group coordinator aware of the set of topics a consumer group (protocol type == 'consumer') is actively subscribed to, allowing offsets of topics which are not actively subscribed to by the group to be either expired or administratively deleted. The expiration rules remain the same.

For the other groups (non-consumer), the API allows to delete offsets when the group is empty and the expiration remains the same.

Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",2019-09-13 16:49:25,David Jacot,Mixed
fbd06ec00c42a937ba06943431ae99ea2da31c4b,"MINOR: add unsigned varint support (#7338)

Support reading and writing unsigned varints.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-09-16 13:13:06,Colin Patrick McCabe,Mixed
c5dfb90b46d52112963066295dcd38e10cb61a9d,"MINOR: Cleanup scala warnings (#7335)

This patch removes a few warnings: mainly unused imports or vars.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-09-16 13:26:20,David Jacot,Not TDD
bab3e082dc48bc3db68692694bd114a39b41fa68,"KAFKA-8859: Expose built-in streams metrics version in `StreamsMetricsImpl` (#7323)

The streams config built.in.metrics.version is needed to add metrics in
a backward-compatible way. However, not in every location where metrics are
added a streams config is available to check built.in.metrics.version. Thus,
the config value needs to be exposed through the StreamsMetricsImpl object.

Reviewers: John Roesler <vvcephei@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",2019-09-16 21:48:25,Bruno Cadonna,Mixed
fe2797a9fa9f344dbbdd73a46ec48cf9894a9e80,"MINOR: Update authorizer start-up check to handle end point with ephemeral port

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #7350 from omkreddy/checkstartup",2019-09-19 20:43:28,Manikumar Reddy,Mixed
73c6bd8ac9a63de83162370a20f5364581fc9576,"[KAFKA-7994] Improve Stream time accuracy for restarts and rebalances  (#6694)

Reviewers: Bruno Cadonna <bruno@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2019-09-19 11:50:25,Richard Yu,Mixed
3825ff3866325dcf0e9bff3e557eacb66450a856,"MINOR: Send latest LeaderAndIsr version (#7351)

KIP-455 (18d4e57f6e8c67ffa7937fc855707d3a03cc165a) bumped the LeaderAndIsr version to 3 but did not change the Controller code to actually send the new version. The ControllerChannelManagerTest had a bug which made it assert wrongly, hence why it did not catch it. This patch fixes said test.
Because the new fields in LeaderAndIsr are not used yet, the gap was not caught by integration tests either.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-09-19 14:42:14,Stanislav Kozlovski,Mixed
8aff871b0da5604fe981561467dff7359fb56942,"MINOR: Fix bug where we would incorrectly load partition reassignment info from ZK (#7334)

Reviewers: Ismael Juma <ismael@juma.me.uk>, Colin P. McCabe <cmccabe@apache.org>",2019-09-19 14:50:30,Stanislav Kozlovski,Not TDD
2d0cd2ef54029cfb592ab5762f16214ef5d0101f,"MINOR: Murmur3 Hash with Guava dependency

Part of supporting KIP-213 ( https://cwiki.apache.org/confluence/display/KAFKA/KIP-213+Support+non-key+joining+in+KTable ). Murmur3 hash is used as a hashing mechanism in KIP-213 for the large range of uniqueness. The Murmur3 class and tests are ported directly from Apache Hive, with no alterations to the code or dependencies.

Author: Adam Bellemare <adam.bellemare@wishabi.com>

Reviewers: John Roesler <vvcephei@users.noreply.github.com>, Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>

Closes #7271 from bellemare/murmur3hash",2019-09-19 15:36:32,Adam Bellemare,Mixed
a0470726c44a26a1cbd0cb7f6c29b4e3e28a3af1,MINOR: Move Murmur3 to Streams,2019-09-19 16:38:18,Guozhang Wang,Mixed
c955828095b28d9533b98fc979e4a768c28263d8,"MINOR: the code generator should be able to set the java package (#7355)

Reviewers: Colin P. McCabe <cmcabe@apache.org>",2019-09-20 09:25:19,John Roesler,Mixed
d91a94e7bff7a2ffe94b562ef1108307afce1bc7,"KAFKA-8609: Add consumer rebalance metrics (#7347)

Adding the following metrics in:

1. AbstractCoordinator (for both consumer and connect)
* rebalance-latency-avg
* rebalance-latency-max
* rebalance-total
* rebalance-rate-per-hour
* failed-rebalance-total
* failed-rebalance-rate-per-hour
* last-rebalance-seconds-ago

2. ConsumerCoordinator
* partition-revoked-latency-avg
* partition-revoked-latency-max
* partition-assigned-latency-avg
* partition-assigned-latency-max
* partition-lost-latency-avg
* partition-lost-latency-max

Reviewers: Bruno Cadonna <bruno@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2019-09-20 17:50:12,Guozhang Wang,Mixed
e98e239a0c7fd9a500de606b7a05582f1a384da4,"KAFKA-8859: Refactor cache-level metrics (#7367)

Cache-level metrics are refactor according to KIP-444:

tag client-id changed to thread-id
name hitRatio changed to hit-ratio
made backward compatible by using streams config built.in.metrics.version

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>",2019-09-23 07:12:45,Bruno Cadonna,Mixed
beac4c7534ef0cd7be92514a8d92639bf417221c,"KAFKA-6958: Overload methods for group and windowed stream to allow to name operation name using the new Named class (#6413)

This is the last PR for the KIP-307.
NOTE : PR 6412 should be merge first
Thanks a lot for the review.

Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",2019-09-23 13:11:56,Florian Hussonnois,Mixed
0d31272b350adf40bda09709304721545553d7f8,"KAFKA-8848; Update system tests to use new AclAuthorizer (#7374)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2019-09-24 10:30:17,Rajini Sivaram,Not TDD
bcc023773ff0f5b68f0e808bc7c7aba457a4c472,"KAFKA-8880: Add overloaded function of Consumer.committed (#7304)

1. Add the overloaded functions.
2. Update the code in Streams to use the batch API for better latency (this applies to both active StreamsTask for initialize the offsets, as well as the StandbyTasks for updating offset limits).
3. Also update all unit test to replace the deprecated APIs.

Reviewers: Christopher Pettitt <cpettitt@confluent.io>, Kamal Chandraprakash  <kamal.chandraprakash@gmail.com>, Bill Bejeck <bill@confluent.io>",2019-09-24 13:23:27,Guozhang Wang,Mixed
ad3b8437fd9ecc18fcfa8204e43be9bccb1a6548,"KAFKA-8580: Compute RocksDB metrics (#7263)

A metric recorder runs in it own thread and regularly records RocksDB metrics from
RocksDB's statistics. For segmented state stores the metrics are aggregated over the
segments.

Reviewers: John Roesler <vvcephei@users.noreply.github.com>, A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-09-24 13:29:08,Bruno Cadonna,Mixed
74f8ae13034d90800da5573666dea3bea5d702ce,"KAFKA-8179: do not suspend standby tasks during rebalance (#7321)

Some work needs to be done in Streams before we can incorporate cooperative rebalancing. 

This PR lays the groundwork for it by doing some refactoring, including a behavioral change that affects eager (""normal"") rebalancing as well: will no longer suspend standbys in onPartitionsRevoked, instead we just close any that were reassigned in onPartitionsAssigned

Reviewers: Bruno Cadonna <bruno@confluent.io>, Boyang Chen <boyang@confluent.io>, John Roesler <vvcephei@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",2019-09-24 15:33:03,A. Sophie Blee-Goldman,Mixed
1d7f0b7c58f212d555c4f2ce766c2ca38f93a1cd,"MINOR: Improve the org.apache.kafka.common.protocol code (#7344)

Add UUID to the list of types documented in Type#toHtml.

Type, Protocol, ArrayOf: use Type#isArray and Type#arrayElementType rather than typecasting to handle arrays.  This is cleaner.  It will also make it easier for us to add compact arrays (as specified by KIP-482) as a new array type distinct from the old array type.

Add MessageUtil#byteBufferToArray, as well as a test for it.  We will need this for handling tagged fields of type ""bytes"".

Schema#Visitor: we don't need a separate function overload for visiting arrays. We can just call ""visit(Type field)"".

TestUUID.json: reformat the JSON file to match the others.

ProtocolSerializationTest: improve the error messages on failure.  Check that each type has the name we expect it to have.

Reviewers: David Arthur <mumrah@gmail.com>, José Armando García Sancio <jsancio@gmail.com>, Vikas Singh <soondenana@users.noreply.github.com>",2019-09-25 08:20:51,Colin Patrick McCabe,Mixed
92688ef82ccbeee6014ae9c1db64fb4289b7bdd7,"MINOR: improve the Kafka RPC code generator (#7340)

Move the generator checkstyle suppressions to a special section, rather
than mixing them in with the other sections.  For generated code, do not
complain about variable names or cyclic complexity.

FieldType.java: remove isInteger since it isn't used anywhere.  This way, we
don't have to decide whether a UUID is an integer or not (there are arguments
for both choices).  Add FieldType#serializationIsDifferentInFlexibleVersions
and FieldType#isVariableLength.

HeaderGenerator: add the ability to generate static imports.  Add
IsNullConditional, VersionConditional, and ClauseGenerator as easier ways of
generating ""if"" statements.",2019-09-25 11:58:54,Colin Patrick McCabe,Mixed
70d1bb40d958918ac691ba906a35c4a158815d78,"KAFKA-7273: Extend Connect Converter to support headers (#6362)

Implemented KIP-440 to allow Connect converters to use record headers when serializing or deserializing keys and values. This change is backward compatible in that the new methods default to calling the older existing methods, so existing Converter implementations need not be changed. This changes the WorkerSinkTask and WorkerSourceTask to use the new converter methods, but Connect's existing Converter implementations and the use of converters for internal topics are intentionally not modified. Added unit tests.

Author: Yaroslav Tkachenko <sapiensy@gmail.com>
Reviewers: Ryanne Dolan <ryannedolan@gmail.com>, Ewen Cheslack-Postava <me@ewencp.org>, Randall Hauch <rhauch@gmail.com>",2019-09-25 11:23:03,Yaroslav Tkachenko,Mixed
0566dfd3cedc13e2c0357378cc100c1ec9bd585a,"MINOR: add versioning to request and response headers (#7372)

Add a version number to request and response headers.  The header
version is determined by the first two 16 bit fields read (API key and
API version).  For now, ControlledShutdown v0 has header version 0, and
all other requests have v1.  Once KIP-482 is implemented, there will be
a v2 of the header which supports tagged fields.",2019-09-25 22:35:13,Colin Patrick McCabe,Mixed
666505b72f1baaf5f37fac4f59fa26d93d833f63,"MINOR: Address review comments for KIP-504 authorizer changes (#7379)

Reviewers: Manikumar Reddy <manikumar@confluent.io>",2019-09-26 08:28:05,Rajini Sivaram,Mixed
5d0052fe00c9071095b872b3b6ab6b1b455c9e20,"KAFKA-8907; Return topic configs in CreateTopics response (KIP-525) (#7380)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2019-09-27 13:28:00,Rajini Sivaram,Not TDD
30443af1c8d6c8b9ca327d046c4d4daffe5d43b2,"KAFKA-6883: Add toUpperCase support to sasl.kerberos.principal.to.local rule (KIP-309)

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #7375 from omkreddy/KAFKA-6883-KerberosShortNamer",2019-09-28 00:13:45,Manikumar Reddy,Not TDD
22434e6535c6471b8ac3e9cff1919e5ac15a50be,"KAFKA-8319: Make KafkaStreamsTest a non-integration test class (#7382)

Previous KafkaStreamsTest takes 2min20s on my local laptop, because lots of its integration test which is producing / consuming records, and checking state directory file system takes lots of time. On the other hand, these tests should be well simplified with mocks.

This test reduces the test from a clumsy integration test class into a unit tests with mocks of its internal modules. And some other test functions should not be in KafkaStreamsTest actually and have been moved to other modular test classes. Now it takes 2s.

Also it helps removing the potential flakiness of the following (some of them are claimed resolved only because we have not seen them recently, but after looking at the test code I can verify they are still flaky):

* KAFKA-5818 (the original JIRA ticket indeed exposed a real issue that has been fixed, but the test itself remains flaky)
* KAFKA-6215
* KAFKA-7921
* KAFKA-7990
* KAFKA-8319
* KAFKA-8427

Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Bruno Cadonna <bruno@confluent.io>",2019-09-27 12:08:15,Guozhang Wang,Mixed
66183f730feaa7dca7b4088053f44015a626a6e8,"KAFKA-8471: Replace control requests/responses with automated protocol (#7353)

Replaced UpdateMetadata{Request, Response}, LeaderAndIsr{Request, Response}
and StopReplica{Request, Response} with the automated protocol classes.

Updated the JSON schema for the 3 request types to be more consistent and
less strict (if needed to avoid duplication).

The general approach is to avoid generating new collections in the request
classes. Normalization happens in the constructor to make this possible. Builders
still have to group by topic to maintain the external ungrouped view.

Introduced new tests for LeaderAndIsrRequest and UpdateMetadataRequest to
verify that the new logic is correct.

A few other clean-ups/fixes in code that was touched due to these changes:
* KAFKA-8956: Refactor DelayedCreatePartitions#updateWaiting to avoid modifying
collection in foreach.
* Avoid unnecessary allocation for state change trace logging if trace logging is not enabled
* Use `toBuffer` instead of `toList`, `toIndexedSeq` or `toSeq` as it generally performs
better and it matches the performance characteristics of `java.util.ArrayList`. This is
particularly important when passing such instances to Java code.
* Minor refactoring for clarity and readability.
* Removed usage of deprecated `/:`, unused imports and unnecessary `var`s.
* Include exception in `AdminClientIntegrationTest` failure message.
* Move StopReplicaRequest verification in `AuthorizerIntegrationTest` to the end
to match the comment.

Reviewers: Colin Patrick McCabe <cmccabe@apache.org>",2019-09-28 19:39:45,Ismael Juma,Mixed
ef2fbfda24115fbadc6a55542ec76d3bedff17d5,"KAFKA-8609: Add rebalance-latency-total (#7401)

In addition to the existing metrics added in KAFKA-8609, add the total (cumulative) time spent during rebalances.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-09-30 17:56:12,John Roesler,Mixed
9fbb0de5fc493f9186d23ccdf03b772ccc01e1d4,"KAFKA-8927: Deprecate PartitionGrouper interface (#7376)

Reviewers: Bruno Cadonna <bruno@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-09-30 18:11:37,Matthias J. Sax,Mixed
f6f24c470004063d14fa33d8680d1eff75c4f598,"KAFKA-8729, pt 2: Add error_records and error_message to PartitionResponse (#7150)

As noted in the KIP-467, the updated ProduceResponse is

```
Produce Response (Version: 8) => [responses] throttle_time_ms
  responses => topic [partition_responses]
    topic => STRING
    partition_responses => partition error_code base_offset log_append_time log_start_offset
      partition => INT32
      error_code => INT16
      base_offset => INT64
      log_append_time => INT64
      log_start_offset => INT64
      error_records => [INT32]         // new field, encodes the relative offset of the records that caused error
      error_message => STRING          // new field, encodes the error message that client can use to log itself
    throttle_time_ms => INT32
with a new error code:
```

INVALID_RECORD(86, ""Some record has failed the validation on broker and hence be rejected."", InvalidRecordException::new);

Reviewers: Jason Gustafson <jason@confluent.io>, Magnus Edenhill <magnus@edenhill.se>, Guozhang Wang <wangguoz@gmail.com>",2019-09-30 19:29:36,Tu V. Tran,Mixed
270e6109159f9288b4ed807462d8180a3c92e0da,"KAFKA-8896: Check group state before completing delayed heartbeat (#7377)

This is a defensive fix for KAFKA-8896, which would cause group coordinator crash when the heartbeat member was not found.",2019-10-01 09:19:43,Boyang Chen,Mixed
bfcc17f211834710add79122d7ba3d267931cfb1,"KAFKA-8595: Support deserialization of JSON decimals encoded in NUMERIC  (#7354)

Implemented KIP-481 by adding support for deserializing Connect DECIMAL values encoded in JSON as numbers, in addition to raw byte array (base64) format used previously.

Author: Almog Gavra <almog@confluent.io>
Reviewers: Chris Egerton <chrise@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>",2019-10-01 15:33:06,Almog Gavra,Mixed
3c87c9b5382891c924784828bad3d6a1b32940c6,"KAFKA-8887; Use purgatory for ACL updates using async authorizers (#7404)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2019-10-01 22:25:56,Rajini Sivaram,Mixed
3ca204b427971af161fa3550c46d9ec796e8b401,"MINOR: Shutdown RockDB metrics recording trigger thread (#7417)

added shutdown for thread that triggers recording of RocksDBMetrics
added unit tests to verify the start and shutdown of the thread
refactored a bit of code

Reviewers: Christopher Pettitt <cpettitt@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",2019-10-02 10:54:08,Bruno Cadonna,Mixed
c218aa63ca8cdcd9b0c2c02dd0dae600318fd47c,"KAFKA-8901; Extend consumer group command to use the new Admin API to delete consumer offsets (KIP-496)

It add support to delete offsets in the `kafka-consumer-group`.

*More detailed description of your change,
if necessary. The PR title and PR message become
the squashed commit message, so use a separate
comment to ping reviewers.*

*Summary of testing strategy (including rationale)
for the feature or bug fix. Unit and/or integration
tests are expected for any behaviour change and
system tests should be considered for larger changes.*

Author: David Jacot <djacot@confluent.io>

Reviewers: Gwen Shapira

Closes #7362 from dajac/KAFKA-8901-delete-offsets-command",2019-10-02 08:16:41,David Jacot,Mixed
8da69936a7e7c4da51e45cdf0fa392bcb0eacbbc,"KAFKA-8649: Send latest commonly supported version in assignment (#7423)

Instead of sending the leader's version and having older members try to blindly upgrade.

The only other real change here is that we will also set the VERSION_PROBING error code and return early from onAssignment when we are upgrading our used subscription version (not just downgrading it) since this implies the whole group has finished the rolling upgrade and all members should rejoin with the new subscription version.

Also piggy-backing on a fix for a potentially dangerous edge case, where every thread of an instance is assigned the same set of active tasks.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-10-02 08:54:32,A. Sophie Blee-Goldman,Mixed
1c831c22e13fcc59e7e1a9e6c28fd38048eb3f62,"KAFKA-7772: Dynamically Adjust Log Levels in Connect (#7403)

Implemented KIP-495 to expose a new `admin/loggers` endpoint for the Connect REST API that lists the current log levels and allows the caller to change log levels. 

Author: Arjun Satish <arjun@confluent.io>
Reviewer: Randall Hauch <rhauch@gmail.com>",2019-10-02 17:00:37,Arjun Satish,Mixed
791d0d61bf5a2b7a4fda72d4c50075a1933a6af3,"KAFKA-8804: Secure internal Connect REST endpoints (#7310)

Implemented KIP-507 to secure the internal Connect REST endpoints that are only for intra-cluster communication. A new V2 of the Connect subprotocol enables this feature, where the leader generates a new session key, shares it with the other workers via the configuration topic, and workers send and validate requests to these internal endpoints using the shared key.

Currently the internal `POST /connectors/<connector>/tasks` endpoint is the only one that is secured.

This change adds unit tests and makes some small alterations to system tests to target the new `sessioned` Connect subprotocol. A new integration test ensures that the endpoint is actually secured (i.e., requests with missing/invalid signatures are rejected with a 400 BAD RESPONSE status).

Author: Chris Egerton <chrise@confluent.io>
Reviewed: Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>",2019-10-02 17:06:57,Chris Egerton,Mixed
5b829f2b610d71d3176a7df523b34df807b47f22,"KAFKA-8447: New Metric to Measure Number of Tasks on a Connector (#6843)

Implemented KIP-475 to add new metrics for each worker to expose the number of current tasks per connector and per status.

Author: Cyrus Vafadari <cyrus@confluent.io>
Reviewer: Randall Hauch <rhauch@gmail.com>, Boyang Chen <Boyang Chen <boyang@confluent.io>",2019-10-02 19:42:21,Cyrus Vafadari,Mixed
6925775e63fd33e6a44bbda671b2de7db41d150e,"KAFKA-8558:  Add StreamJoined config object to join (#7285)

Reviewer: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2019-10-02 20:32:18,Bill Bejeck,Mixed
e76770343c8a7b81d04c00d219381814190c8745,"KAFKA-8523 Enabling InsertField transform to be used with tombstone events (#6914)

* KAFKA-8523 Avoiding raw type usage

* KAFKA-8523 Gracefully handling tombstone events in InsertField SMT",2019-10-03 13:51:00,Gunnar Morling,Mixed
ded1fb8c4d7448ffbc939aaacd2d9b475fd58f4e,"KAFKA-6290: Support casting from logical types in cast transform (#7371)

Adds support for the Connect Cast transforms to cast from Connect logical types, such as DATE, TIME, TIMESTAMP, and DECIMAL. Casting to numeric types will produce the underlying numeric value represented in the desired type. For logical types represented by underlying Java Date class, this means the milliseconds since EPOCH. For Decimal, this means the underlying value. If the value does not fit in the desired target type, it may overflow.

Casting to String from Date, Time, and Timestamp types will produce their ISO 8601 representation. Casting to String from Decimal will result in the value represented as a string. e.g. 1234 -> ""1234"".

Author: Nigel Liang <nigel@nigelliang.com>
Reviewer: Randall Hauch <rhauch@gmail.com>",2019-10-03 14:55:52,Nigel Liang,Mixed
c87fe9402cbebc460b42cd3dd7c268e5e6e659d9,"KAFKA-3705 Added a foreignKeyJoin implementation for KTable. (#5527)

https://issues.apache.org/jira/browse/KAFKA-3705

Allows for a KTable to map its value to a given foreign key and join on another KTable keyed on that foreign key. Applies the joiner, then returns the tuples keyed on the original key. This supports updates from both sides of the join.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>, Boyang Chen <boyang@confluent.io>, Christopher Pettitt <cpettitt@confluent.io>, Bill Bejeck <bbejeck@gmail.com>, Jan Filipiak <Jan.Filipiak@trivago.com>, pgwhalen, Alexei Daniline",2019-10-03 18:59:31,Adam Bellemare,Mixed
f98013cc501ab30c43ca707a1fbf46c4e9dc1215,"Part 1 of KIP-511: Collect and Expose Client's Name and Version in the Brokers #7381

Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, David Arthur <mumrah@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",2019-10-04 09:19:18,David Jacot,Mixed
52007e878aaac3f48d0d949dbe428a2ae5e56f57,"KAFKA-8934: Introduce instance-level metrics for streams applications (#7416)

1. Moves StreamsMetricsImpl from StreamThread to KafkaStreams
2. Adds instance-level metrics as specified in KIP-444, i.e.:
-- version
-- commit-id
-- application-id
-- topology-description
-- state

Reviewers: Guozhang Wang <wangguoz@gmail.com>, John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",2019-10-04 17:07:30,Bruno Cadonna,Mixed
0de61a4683b92bdee803c51211c3277578ab3edf,"KAFKA-8885; The Kafka Protocol should Support Optional Tagged Fields (#7325)

This patch implements support for optional (tagged) fields in the Kafka protocol as documented in KIP-482: https://cwiki.apache.org/confluence/display/KAFKA/KIP-482%3A+The+Kafka+Protocol+should+Support+Optional+Tagged+Fields#KIP-482:TheKafkaProtocolshouldSupportOptionalTaggedFields-TypeClasses.

Reviewers: David Jacot <djacot@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2019-10-06 21:13:23,Colin Patrick McCabe,Mixed
a5a6938c69f4310f7ec519036f0df77d8022326a,"KAFKA-8233: TopologyTestDriver test input and output usability improvements (#7378)

Implements KIP-470

Reviewers: Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2019-10-07 01:01:58,Jukka Karvanen,Mixed
4ac892ca783acab8e574b9b24d17e767eedb3d5f,"KAFKA-7500: MirrorMaker 2.0 (KIP-382)

Implementation of [KIP-382 ""MirrorMaker 2.0""](https://cwiki.apache.org/confluence/display/KAFKA/KIP-382%3A+MirrorMaker+2.0)

Author: Ryanne Dolan <ryannedolan@gmail.com>
Author: Arun Mathew <arunmathew88@gmail.com>
Author: In Park <inpark@cloudera.com>
Author: Andre Price <obsoleted@users.noreply.github.com>
Author: christian.hagel@rio.cloud <christian.hagel@rio.cloud>

Reviewers: Eno Thereska <eno.thereska@gmail.com>, William Hammond <william.t.hammond@gmail.com>, Viktor Somogyi <viktorsomogyi@gmail.com>, Jakub Korzeniowski, Tim Carey-Smith, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>, Arun Mathew, Jeremy-l-ford, vpernin, Oleg Kasian <oleg.kasian@gmail.com>, Mickael Maison <mickael.maison@gmail.com>, Qihong Chen, Sriharsha Chintalapani <sriharsha@apache.org>, Jun Rao <junrao@gmail.com>, Randall Hauch <rhauch@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #6295 from ryannedolan/KIP-382",2019-10-07 13:57:54,Ryanne Dolan,Mixed
c06e45a215072b1f909ccc9d1a9a82ae521b4bab,"KAFKA-8985; Add flexible version support to inter-broker APIs (#7453)

This patch adds flexible version support for the following inter-broker APIs: ControlledShutdown, LeaderAndIsr, UpdateMetadata, and StopReplica. Version checks have been removed from `getErrorResponse` methods since they were redundant given the checks in `AbstractRequest` and the respective`*Data` types.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2019-10-07 09:21:14,Jason Gustafson,Mixed
d88f1048da6bdc5670102bbbde7bd92fa7af4ccb,"KAFKA-8179: Part 7, cooperative rebalancing in Streams (#7386)

Key improvements with this PR:

* tasks will remain available for IQ during a rebalance (but not during restore)
* continue restoring and processing standby tasks during a rebalance
* continue processing active tasks during rebalance until the RecordQueue is empty*
* only revoked tasks must suspended/closed
* StreamsPartitionAssignor tries to return tasks to their previous consumers within a client
* but do not try to commit, for now (pending KAFKA-7312)


Reviewers: John Roesler <john@confluent.io>, Boyang Chen <boyang@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-10-07 09:27:09,A. Sophie Blee-Goldman,Mixed
cfa10678bd87f5e35f4934ecd2a40a9a089a5b52,"KAFKA-7245: Deprecate WindowStore#put(key, value) (#7105)

Implements KIP-474.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2019-10-07 14:50:46,Omkar Mestry,Mixed
a9493346aa020747f46eb916e4859dfb7192ffde,"KAFKA-8983; AdminClient deleteRecords should not fail all partitions unnecessarily (#7449)

The deleteRecords API in the AdminClient groups records to be sent by the partition leaders. If one of these requests fails, we currently fail all futures, including those tied to requests sent to other leaders. It would be better to fail only those partitions included in the failed request.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2019-10-08 08:19:07,Jason Gustafson,Mixed
c49775bf072f7265b744fd4f3fbfd123d7a20c49,"KAFKA-7190; Retain producer state until transactionalIdExpiration time passes (#7388)

As described in KIP-360, this patch changes producer state retention so that producer state remains cached even after it is removed from the log. Producer state will only be removed now when the transactional id expiration time has passed. This is intended to reduce the incidence of UNKNOWN_PRODUCER_ID errors for producers when records are deleted or when a topic has a short retention time. Tested with unit tests.

Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-10-08 14:06:36,Bob Barrett,Mixed
e3c2148b207a6ca98c89211d12cb47abdfaa70b3,"KAFKA-8964: Rename tag client-id for thread-level metrics and below (#7429)

* Renamed tag client-id to thread-id for thread-level metrics and below
* Corrected metrics tag keys for state store that had suffix ""-id"" instead of ""state-id""

Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-10-08 15:24:31,Bruno Cadonna,Mixed
1f1179ea64bbaf068d759aae988bd2a6fe966161,"KAFKA-8932; Add tag for CreateTopicsResponse.TopicConfigErrorCode (KIP-525) (#7464)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2019-10-09 09:19:18,Rajini Sivaram,Not TDD
50857b81bbaa3cd3a8ac2c460ff6e93acd3d8220,"KAFKA-8954; Topic existence check is wrongly implemented in the DeleteOffset API (KIP-496) (#7406)

This patch changes the way topic existence is checked in the DeleteOffset API. Previously, it was relying on the committed offsets. Now, it relies on the metadata cache which is better.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-10-09 08:36:49,David Jacot,Mixed
fb9b0dfde5f674e2aa9f9948e2f14bc7698413ae,"MINOR: Augment log4j to add generation number in performAssign (#7451)

Since generation is private in AbstractCoordinator, I need to modify the generation() to let it return the object directly.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Bill Bejeck <bill@confluent.io>",2019-10-09 10:34:19,Guozhang Wang,Mixed
5c4bbf9344d82ebcb98ff1444a5a6e5d8ff05215,"MINOR: fix compatibility-breaking bug in RequestHeader (#7479)

Reviewers: David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2019-10-10 13:52:07,Colin Patrick McCabe,Mixed
f41a5c2c8632bfd0dc50321c1c69418db04f42f6,"KAFKA-8729, pt 3: Add broker-side logic to handle the case when there are record_errors and error_message (#7167)

All the changes are in ReplicaManager.appendToLocalLog and ReplicaManager.appendRecords. Also, replaced LogAppendInfo.unknownLogAppendInfoWithLogStartOffset with LogAppendInfo.unknownLogAppendInfoWithAdditionalInfo to include those 2 new fields.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-10-10 14:44:37,Tu V. Tran,Mixed
fa2a9f09e4042f821d7373e2d9e01b21aede775a,"MINOR: ListPartitionReassignmentsResponse should not be entirely failed when a topic-partition does not exist  (#7486)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2019-10-10 15:12:14,David Jacot,Not TDD
b8d609c207ed3d1e678c2f1eb6f3cae637f92c30,"KAFKA-7981; Add fetcher and log cleaner thread count metrics (#6514)

This patch adds metrics for failed threads as documented in KIP-434: https://cwiki.apache.org/confluence/display/KAFKA/KIP-434%3A+Add+Replica+Fetcher+and+Log+Cleaner+Count+Metrics.

Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",2019-10-11 10:53:32,Viktor Somogyi,Mixed
f771005f40af160e604b65b1f376c3ef2aff5cd1,"KAFKA-8725; Improve LogCleanerManager#grabFilthiestLog error handling (#7475)

KAFKA-7215 improved the log cleaner error handling to mitigate thread death but missed one case. Exceptions in grabFilthiestCompactedLog still cause the thread to die.

This patch improves handling to ensure that errors in that function still mark a partition as uncleanable and do not crash the thread.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-10-11 15:10:29,Stanislav Kozlovski,Mixed
b006205edb57117c5a399647b4352b06953e9e84,"KAFKA-9020: Streams sub-topologies should be sorted by sink -> source relationship (#7495)

Subtopologies are currently ordered alphabetically by source node, which prior to KIP-307 happened to always result in the ""correct"" (ie topological) order. Now that users may name their nodes anything they want, we must explicitly order them so that upstream node groups/subtopologies come first and the downstream ones come after.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>",2019-10-14 16:15:03,A. Sophie Blee-Goldman,Not TDD
c55277cd79f103d9c686b9698f9f63208fdee272,"MINOR: unify calls to get committed offsets and metadata (#7463)

Reviewers: Chris Pettitt <cpettitt@confluent.io>, Bruno Cadonna <bruno@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-10-14 21:22:55,Matthias J. Sax,Mixed
2fce203a54483d9f229304a7ed3e963cc15f983b,"KAFKA-8671: NullPointerException occurs if topic associated with GlobalKTable changes (#7437)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Boyang Chen <boyang@confluent.io>",2019-10-14 21:47:50,Alex Leung,Mixed
176c93412eaf96616890109852a3183b1e2e947d,"KAFKA-8813: Refresh log config if it's updated before initialization (#7305)

A partition log in initialized in following steps:

1. Fetch log config from ZK
2. Call LogManager.getOrCreateLog which creates the Log object, then
3. Registers the Log object

Step #3 enables Configuration update thread to deliver configuration
updates to the log. But if any update arrives between step #1 and #3
then that update is missed. It breaks following use case:

1. Create a topic with default configuration, and immediately after that
2. Update the configuration of topic

There is a race condition here and in random cases update made in
second step will get dropped.

This change fixes it by tracking updates arriving between step #1 and #3
Once a Partition is done initializing log, it checks if it has missed any
update. If yes, then the configuration is read from ZK again.

Added unit tests to make sure a dirty configuration is refreshed. Tested
on local cluster to make sure that topic configuration and updates are
handled correctly.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-10-15 11:22:26,Vikas Singh,Mixed
5e231f1738ab4fec7b3fec3dc72d7f8568991cd4,"KAFKA-9014: Fix AssertionError when SourceTask.poll returns an empty list (#7491)

Author: Konstantine Karantasis <konstantine@confluent.io>
Reviewer: Randall Hauch <rhauch@gmail.com>",2019-10-15 16:08:31,Konstantine Karantasis,Mixed
bcdc6336fc4346f384a742ca88aeb188bd97cb38,"KAFKA-8945/KAFKA-8947: Fix bugs in Connect REST extension API (#7392)

Fix bug in Connect REST extension API caused by invalid constructor parameter validation, and update integration test to play nicely with Jenkins

Fix instantiation of TaskState objects by Connect framework.

Author: Chris Egerton <chrise@confluent.io>
Reviewers: Magesh Nandakumar <mageshn@confluent.io>, Randall Hauch <rhauch@gmail.com>",2019-10-15 17:27:26,Chris Egerton,Not TDD
9c8ab5ce10e16531c6db95b5ad2abafb1ec62d38,"MINOR: Provide better messages when waiting for a condition in test (#7488)

Reviewers: Boyang Chen <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",2019-10-15 17:18:58,Chris Pettitt,Not TDD
3e24495c69175002635fbf4a2ebc249cc920e4af,"KAFKA-8897: Warn about no guaranteed backwards compatibility in RocksDBConfigSetter (#7483)

Reviewer: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2019-10-15 22:39:28,Bruno Cadonna,Mixed
072503527e292ed8aeb19edf7a05089581152007,"KAFKA-9032: Bypass serdes for tombstones (#7518)

In a KTable context, null record values have a special ""tombstone"" significance. We should always bypass the serdes for such tombstones, since otherwise the serde could violate Streams' table semantics.

Added test coverage for this case and fixed the code accordingly.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bill@confluent.io>",2019-10-16 09:34:52,John Roesler,Mixed
8966d066bd2f80c6d8f270423e7e9982097f97b9,"KAFKA-9039: Optimize ReplicaFetcher fetch path (#7443)

Improves the performance of the replica fetcher for high partition count fetch requests, where a majority of the partitions did not update between fetch requests. All benchmarks were run on an r5x.large.

Vanilla
Benchmark (partitionCount) Mode Cnt Score Error Units
ReplicaFetcherThreadBenchmark.testFetcher 100 avgt 15 26491.825 ± 438.463 ns/op
ReplicaFetcherThreadBenchmark.testFetcher 500 avgt 15 153941.952 ± 4337.073 ns/op
ReplicaFetcherThreadBenchmark.testFetcher 1000 avgt 15 339868.602 ± 4201.462 ns/op
ReplicaFetcherThreadBenchmark.testFetcher 5000 avgt 15 2588878.448 ± 22172.482 ns/op

From 100 to 5000 partitions the latency increase is 2588878.448 / 26491.825 = 97.

Avoid gettimeofdaycalls in steady state fetch states
8545888

Benchmark (partitionCount) Mode Cnt Score Error Units
ReplicaFetcherThreadBenchmark.testFetcher 100 avgt 15 22685.381 ± 267.727 ns/op
ReplicaFetcherThreadBenchmark.testFetcher 500 avgt 15 113622.521 ± 1854.254 ns/op
ReplicaFetcherThreadBenchmark.testFetcher 1000 avgt 15 273698.740 ± 9269.554 ns/op
ReplicaFetcherThreadBenchmark.testFetcher 5000 avgt 15 2189223.207 ± 1706.945 ns/op

From 100 to 5000 partitions the latency increase is 2189223.207 / 22685.381 = 97X

Avoid copying partition states to maintain fetch offsets
29fdd60

Benchmark (partitionCount) Mode Cnt Score Error Units
ReplicaFetcherThreadBenchmark.testFetcher 100 avgt 15 17039.989 ± 609.355 ns/op
ReplicaFetcherThreadBenchmark.testFetcher 500 avgt 15 99371.086 ± 1833.256 ns/op
ReplicaFetcherThreadBenchmark.testFetcher 1000 avgt 15 216071.333 ± 3714.147 ns/op
ReplicaFetcherThreadBenchmark.testFetcher 5000 avgt 15 2035678.223 ± 5195.232 ns/op

From 100 to 5000 partitions the latency increase is 2035678.223 / 17039.989 = 119X

Keep lag alongside PartitionFetchState to avoid expensive isReplicaInSync check
0e57e3e

Benchmark (partitionCount) Mode Cnt Score Error Units
ReplicaFetcherThreadBenchmark.testFetcher 100 avgt 15 15131.684 ± 382.088 ns/op
ReplicaFetcherThreadBenchmark.testFetcher 500 avgt 15 86813.843 ± 3346.385 ns/op
ReplicaFetcherThreadBenchmark.testFetcher 1000 avgt 15 193050.381 ± 3281.833 ns/op
ReplicaFetcherThreadBenchmark.testFetcher 5000 avgt 15 1801488.513 ± 2756.355 ns/op

From 100 to 5000 partitions the latency increase is 1801488.513 / 15131.684 = 119X

Fetch session optimizations (mostly presizing the next hashmap, and avoiding making a copy of sessionPartitions, as a deep copy is not required for the ReplicaFetcher)
2614b24

Benchmark (partitionCount) Mode Cnt Score Error Units
ReplicaFetcherThreadBenchmark.testFetcher 100 avgt 15 11386.203 ± 416.701 ns/op
ReplicaFetcherThreadBenchmark.testFetcher 500 avgt 15 60820.292 ± 3163.001 ns/op
ReplicaFetcherThreadBenchmark.testFetcher 1000 avgt 15 146242.158 ± 1937.254 ns/op
ReplicaFetcherThreadBenchmark.testFetcher 5000 avgt 15 1366768.926 ± 3305.712 ns/op

From 100 to 5000 partitions the latency increase is 1366768.926 / 11386.203 = 120

Reviewers: Jun Rao <junrao@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2019-10-16 09:49:53,Lucas Bradstreet,Mixed
ff68b60429b7b3369da411cea127beebed85033b,"KAFKA-8340, KAFKA-8819: Use PluginClassLoader while statically initializing plugins (#7315)

Added plugin isolation unit tests for various scenarios, with a `TestPlugins` class that compiles and builds multiple test plugins without them being on the classpath and verifies that the Plugins and DelegatingClassLoader behave properly. These initially failed for several cases, but now pass since the issues have been fixed.

KAFKA-8340 and KAFKA-8819 are closely related, and this fix corrects the problems reported in both issues.

Author: Greg Harris <gregh@confluent.io>
Reviewers: Chris Egerton <chrise@confluent.io>, Magesh Nandakumar <mageshn@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>",2019-10-16 20:43:00,Greg Harris,Mixed
78f5da914e78958b00af643aed7ce13fb156e59e,"KAFKA-9053: AssignmentInfo#encode hardcodes the LATEST_SUPPORTED_VERSION (#7537)

Also put in some additional logging that makes sense to add, and proved helpful in debugging this particular issue.

Unit tests verifying the encoded supported version were added.

This should get cherry-picked back to 2.1

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-10-16 22:23:15,A. Sophie Blee-Goldman,Mixed
b62f2a1123612af30d29140efa6d3e89091f87dc,"KAFKA-8496: System test for KIP-429 upgrades and compatibility (#7529)

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-10-16 22:29:33,Bill Bejeck,Not TDD
f93c473be1d24774f9c2d29576b063835f8d2737,"KAFKA-9000: fix flaky FK join test by using TTD (#7517)

Migrate this integration test to use TopologyTestDriver instead of running 3 Streams instances.

Dropped one test that was attempting to produce specific interleavings. If anything, these should be verified deterministically by unit testing.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-10-16 22:40:57,John Roesler,Not TDD
00374c3ddf6c4ecc96f58c6685fd107500b976cd,"KAFKA-8104: Consumer cannot rejoin to the group after rebalancing (#7460)

This PR contains the fix of race condition bug between ""consumer thread"" and ""consumer coordinator heartbeat thread"". It reproduces in many production environments.

Condition for reproducing:

1. Consumer thread initiates rejoin to the group because of commit timeout. Call of AbstractCoordinator#joinGroupIfNeeded which leads to sendJoinGroupRequest.
2. JoinGroupResponseHandler writes to the AbstractCoordinator.this.generation new generation data and leaves the synchronized section.
3. Heartbeat thread executes mabeLeaveGroup and clears generation data via resetGenerationOnLeaveGroup.
4. Consumer thread executes onJoinComplete(generation.generationId, generation.memberId, generation.protocol, memberAssignment); with the cleared generation data. This leads to the corresponding exception.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-10-16 22:53:14,Nikolay,Not TDD
f324754852a297319ac8b0ea119e48741a0dd61c,"KAFKA-8884: class cast exception improvement (#7309)

Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2019-10-17 00:00:39,Antony Stubbs,Mixed
ed078bd702e30b300050aefd7a65561fbd75049f,"KAFKA-8874: Add consumer metrics to observe user poll behavior (KIP-517)

https://cwiki.apache.org/confluence/display/KAFKA/KIP-517%3A+Add+consumer+metrics+to+observe+user+poll+behavior

Author: Kevin Lu <kelu@paypal.com>

Reviewers: Sriharsha Chintalapani <sriharsha@apache.org>, Jason Gustafson <jason@confluent.io>

Closes #7395 from KevinLiLu/KIP517-KAFKA8874",2019-10-17 14:46:42,Kevin Lu,Mixed
2cf7b35d90f56e8f5326576d0683128421a37a09,"KAKFA-8950: Fix KafkaConsumer Fetcher breaking on concurrent disconnect (#7511)

The KafkaConsumer Fetcher can sometimes get into an invalid state where it believes that there are ongoing fetch requests, but in fact there are none. This may be caused by the heartbeat thread concurrently handling a disconnection event just after the fetcher thread submits a request which would cause the Fetcher to enter an invalid state where it believes it has ongoing requests to the disconnected node but in fact it does not. This is due to a thread safety issue in the Fetcher where it was possible for the ordering of the modifications to the nodesWithPendingFetchRequests to be incorrect - the Fetcher was adding it after the listener had already been invoked, which would mean that pending node never gets removed again.

This PR addresses that thread safety issue by ensuring that the pending node is added to the nodesWithPendingFetchRequests before the listener is added to the future, ensuring the finally block is called after the node is added.

Reviewers: Tom Lee, Jason Gustafson <jason@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2019-10-17 11:56:41,Will James,Mixed
3cb8ccf63a3f88b4de5a2133b39fb4bf175f3532,"MINOR: AbstractRequestResponse should be an interface (#7513)

AbstractRequestResponse should be an interface, since it has no concrete elements or implementation.  Move AbstractRequestResponse#serialize to RequestUtils#serialize and make it package-private, since it doesn't need to be public.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2019-10-17 09:21:34,Colin Patrick McCabe,Not TDD
d9f0be45231fd19036095ccc544b3df304811724,"KAFKA-9004; Prevent older clients from fetching from a follower (#7531)

With KIP-392, we allow consumers to fetch from followers. This capability is enabled when a replica selector has been provided in the configuration. When not in use, the intent is to preserve current behavior of fetching only from leader. The leader epoch is the mechanism that keeps us honest. When there is a leader change, the epoch gets bumped, consumer fetches fail due to the fenced epoch, and we find the new leader.

However, for old consumers, there is no similar protection. The leader epoch was not available to clients until recently. If there is a preferred leader election (for example), the old consumer will happily continue fetching from the demoted leader until a periodic metadata fetch causes us to discover the new leader. This does not create any problems from a correctness perspective–fetches are still bound by the high watermark–but it is unexpected and may cause unexpected performance characteristics.

This patch fixes this problem by enforcing leader-only fetching for older versions of the fetch request.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-10-17 09:44:14,David Arthur,Mixed
fa2c61e23fdf41be1f19d6c8c60eae9bfe52ff80,"KAFKA-9058: Lift queriable and materialized restrictions on FK Join (#7541)

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2019-10-17 11:42:10,John Roesler,Not TDD
6c0aed2fbe282e88fec618e31dcc8417f5f390b1,"KAFKA-8834; Add reassignment metrics and distinguish URPs (KIP-352) (#7361)

KIP-352 aims to add several new metrics in order to track reassignments much better. We will be able to measure bytes in/out rate and the count of partitions under active reassignment.
We also change the semantic of the UnderReplicatedPartitions metric to cater better for reassignment. Currently it reports under-replicated partitions when during reassignment extra partitions are added as part of the process but this PR changes it so it'll always take the original replica set into account when computing the URP metrics.

The newly added metrics will be: 
- kafka.server:type=ReplicaManager,name=ReassigningPartitions
- kafka.server:type=BrokerTopicMetrics,name=ReassignmentBytesOutPerSec
- kafka.server:type=BrokerTopicMetrics,name=ReassignmentBytesInPerSec

The changed URP metric:
- kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions

Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",2019-10-17 22:54:28,Viktor Somogyi,Mixed
317089663cc7ff4fdfcba6ee434f455e8ae13acd,"KAFKA-8962; Use least loaded node for AdminClient#describeTopics (#7421)

Allow routing of `AdminClient#describeTopics` to any broker in the cluster than just the controller, so that we don't create a hotspot for this API call. `AdminClient#describeTopics` uses the broker's metadata cache which is asynchronously maintained, so routing to brokers other than the controller is not expected to have a significant difference in terms of metadata consistency; all metadata requests are eventually consistent.

This patch also fixes a few flaky test failures.

Reviewers: Ismael Juma <ismael@juma.me.uk>, José Armando García Sancio <jsancio@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-10-17 23:08:34,Dhruvil Shah,Not TDD
4e094217f7360becd3640a38587e25f9a3bfd4b3,"KAFKA-8455: Add VoidSerde to Serdes (#7485)

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2019-10-18 16:54:23,Nikolay,Not TDD
2298c7f84fd0e29b304eb11078bfe76ca5b04a97,"KAFKA-8964: Refactor thread-level metrics depending on built-in metrics version (#7474)

* Made commit-over-tasks sensor and skipped-records sensor optional since they are removed in the latest version
* Refactored methods for sensor creation
* Adapted unit and integration tests

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-10-19 13:45:36,Bruno Cadonna,Mixed
99a4068c5ca61951d70b9e647ead3b08a2af4309,"KAFKA-7689; Add AlterConsumerGroup/List Offsets to AdminClient [KIP-396] (#7296)

This patch implements new AdminClient APIs to list offsets and alter consumer group offsets as documented in KIP-396: https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=97551484.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-10-19 21:30:50,Mickael Maison,Mixed
e20dcffa847648519fa622fc159f8a34580df40a,"KAFKA-8943: Move SecurityProviderCreator to org.apache.kafka.common.security.auth package (#7564)

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2019-10-21 08:48:33,Manikumar Reddy,Mixed
6afe05fe896af3b646d79ff6ec3056e04656d2e7,"MINOR: system test clean up (#7552)

Guozhang Wang <wangguoz@gmail.com>, Sophie Blee-Goldman <sophie@confluent.io>,",2019-10-21 10:51:15,Bill Bejeck,Not TDD
6d8da96ba8c892aab53ec9e1d5a074c5043c2092,"MINOR: Reset timer when all the buffer is drained and empty (#7573)

For scenarios where the incoming traffic of all input partitions are small, there's a pitfall that the enforced processing timer is not reset after we have enforce processed ALL records. The fix itself is pretty simple: we just reset the timer when there's no buffered records.

Reviewers: Javier Holguera <javier.holguera@gmail.com>, Boyang Chen <boyang@confluent.io>, Bill Bejeck <bill@confluent.io>",2019-10-22 09:27:38,Guozhang Wang,Mixed
2efee34b74d4895b504ab541b716edab72b320d1,"MINOR: Check against empty replicas in AlterPartitionReassignments (#7574)

Do not allow an empty replica set to be passed into the reassignment API.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, José Armando García Sancio <jsancio@gmail.com>",2019-10-22 15:26:50,Stanislav Kozlovski,Not TDD
c00bd38ab27ceaee174be8ce803c64000c5730ed,"MINOR: Rename brokers to replicas in the reassignment API (#7570)

Reviewers: Jason Gustafson <jason@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>, Vikas Singh <vikas@confluent.io>, Colin P. McCabe <cmccabe@apache.org>",2019-10-22 15:36:53,José Armando García Sancio,Mixed
0971f66ff546f780b46cf341b41a1513f916398e,"KAFKA-9056; Inbound/outbound byte metrics should reflect incomplete sends/receives (#7551)

Currently we only record completed sends and receives in the selector metrics. If there is a disconnect in the middle of the respective operation, then it is not counted. The metrics will be more accurate if we take into account partial sends and receives.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com",2019-10-23 08:45:08,Jason Gustafson,Mixed
adb2bdb122df0e352a414df4a26158909c25155b,"KAFKA-8584: The RPC code generator should support ByteBuffer. (#7342)

The RPC code generator should support using the ByteBuffer class in addition to byte arrays. By using the ByteBuffer class, we can avoid performing a copy in many situations. Also modify TestByteBufferDataTest to test the new feature.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Guozhang Wang <wangguoz@gmail.com>",2019-10-23 12:39:12,Nikolay,Mixed
6975f1dfa9864728605a7e430cf929b3280aae2b,"KAFKA-8700: Flaky Test QueryableStateIntegrationTest#queryOnRebalance (#7548)

This is not guaranteed to actually fix queryOnRebalance, since the
failure could never be reproduced locally. I did not bump timeouts
because it looks like that has been done in the past for this test
without success. Instead this change makes the following improvements:

It waits for the application to be in a RUNNING state before
proceeding with the test.

It waits for the remaining instance to return to RUNNING state
within a timeout after rebalance. I observed once that we were able to
do the KV queries but the instance was still in REBALANCING, so this
should reduce some opportunity for flakiness.

The meat of this change: we now iterate over all keys in one shot
(vs. one at a time with a timeout) and collect various failures, all of
which are reported at the end. This should help us to narrow down the
cause of flakiness if it shows up again.

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-10-23 12:39:31,Chris Pettitt,Not TDD
c015169aa6ae835978cadbcb1d17a123e8c475f8,"MINOR: Streams upgrade system test cleanup (#7571)

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>,",2019-10-24 10:28:29,Bill Bejeck,Not TDD
28ef7f1d6d7f4cec7e81b8d0641debebefec9104,"MINOR: Re-implement NewPartitionReassignment#of() (#7592)

Re-implement NewPartitionReassignment#of.  It now takes a list rather than a variable-length list of arguments.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Vikas Singh <vikas@confluent.io>",2019-10-24 15:23:54,Stanislav Kozlovski,Not TDD
1df01d258369222e1978016efb20c8a990b13c5c,"KAFKA-9089; Reassignment should be resilient to unexpected errors (#7562)

The purpose of this patch is to make the reassignment algorithm simpler and more resilient to unexpected errors. Specifically, it has the following improvements:

1. Remove `ReassignedPartitionContext`. We no longer need to track the previous reassignment through the context and we now use the assignment state as the single source of truth for the target replicas in a reassignment.
2. Remove the intermediate assignment state when overriding a previous reassignment. Instead, an overriding reassignment directly updates the assignment state and shuts down any unneeded replicas. Reassignments are _always_ persisted in Zookeeper before being updated in the controller context.
3. To fix race conditions with concurrent submissions, reassignment completion for a partition always checks for a zk partition reassignment to be removed. This means the controller no longer needs to track the source of the reassignment.
4. Api reassignments explicitly remove reassignment state from zk prior to beginning the new reassignment. This fixes an inconsistency in precedence. Upon controller failover, zookeeper reassignments always take precedence over any active reassignment. So if we do not have the logic to remove the zk reassignment when an api reassignment is triggered, then we can revert to the older zk reassignment.

Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jun Rao <junrao@gmail.com>",2019-10-24 19:33:16,Jason Gustafson,Mixed
43262d358a489b74dbe0e686f4e87e75ff0324d8,"KAFKA-9038; Allow creating partitions while a reassignment is in progress  (#7582)

Prior to this patch, partition creation would not be allowed for any topic while a reassignment is in progress. The PR makes this a topic level check. As long as a particular topic is not being reassigned, we allow partitions to be increased.

Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",2019-10-24 23:40:02,NIkhil Bhatia,Not TDD
77fc49888938e29ca3e86649611cc3f6996cccd8,"KAFKA-8992; Redefine RemoveMembersFromGroup interface on AdminClient  (#7478)

This PR fixes the inconsistency involved in the `removeMembersFromGroup` admin API calls:

1. Fail the `all()` request when there is sub level error (either partition or member)
2. Change getMembers() to members()
3. Hide the actual Errors from user
4. Do not expose generated MemberIdentity type
5. Use more consistent naming for Options and Result types

Reviewers: Guozhang Wang <wangguoz@gmail.com>, David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>",2019-10-25 00:01:51,Boyang Chen,Mixed
27ba8f5a399cdd799a7eade52c31e6bc21ad18d1,"KAFKA-8968: Refactor task-level metrics (#7566)

Introduces TaskMetrics class
Introduces dropped-records
Replaces skipped-records with dropped-records with latest built-in
metrics version
Does not add standby-process-ratio and active-process-ratio
Does not refactor parent sensors for processor node metrics

Reviewers: Guozhang Wang <wangguoz@gmail.com>, John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",2019-10-25 17:16:25,Bruno Cadonna,Mixed
c5df2082811af3cd3d7bc20974dddd5780a5836e,"KAFKA-9105; Add back truncateHead method to ProducerStateManager (#7599)

The truncateHead method was removed from ProducerStateManager by github.com/apache/kafka/commit/c49775b. This meant that snapshots were no longer removed when the log start offset increased, even though the intent of that change was to remove snapshots but preserve the in-memory mapping. This patch adds the required functionality back.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-10-25 14:40:45,Bob Barrett,Mixed
4bde9bb3ccaf5571be76cb96ea051dadaeeaf5c7,"KAFKA-9102; Increase default zk session timeout and replica max lag [KIP-537] (#7596)

This patch increases the default value of `zookeeper.session.timeout` from 6s to 18s and `replica.lag.time.max.ms` from 10s to 30s. This change was documented in KIP-537: https://cwiki.apache.org/confluence/display/KAFKA/KIP-537%3A+Increase+default+zookeeper+session+timeout.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2019-10-25 22:10:01,Jason Gustafson,Mixed
59a75f4422a68d2e1edc661264058f040139fde5,"KAFKA-9048 Pt1: Remove Unnecessary lookup in Fetch Building (#7576)

Get rid of partitionStates that creates a new PartitionState for each state since all the callers do not require it to be a Seq.

Modify ReplicaFetcherThread constructor to fix the broken benchmark path.

This PR:

Benchmark                                  (partitionCount)  Mode  Cnt        Score       Error  Units
ReplicaFetcherThreadBenchmark.testFetcher               100  avgt   15     9280.953 ±    55.967  ns/op
ReplicaFetcherThreadBenchmark.testFetcher               500  avgt   15    61533.546 ±  1213.559  ns/op
ReplicaFetcherThreadBenchmark.testFetcher              1000  avgt   15   151306.146 ±  1820.222  ns/op
ReplicaFetcherThreadBenchmark.testFetcher              5000  avgt   15  1138547.929 ± 45301.938  ns/op

Trunk:

Benchmark                                  (partitionCount)  Mode  Cnt        Score       Error  Units |   |   |   |   |  
-- | -- | -- | -- | -- | --
ReplicaFetcherThreadBenchmark.testFetcher               100  avgt   15     9305.588 ±    51.886  ns/op |   |   |   |   |  
ReplicaFetcherThreadBenchmark.testFetcher               500  avgt   15    65216.933 ±   939.827  ns/op |   |   |   |   |  
ReplicaFetcherThreadBenchmark.testFetcher              1000  avgt   15   151715.514 ±  1361.009  ns/op |   |   |   |   |  
ReplicaFetcherThreadBenchmark.testFetcher              5000  avgt   15  1231958.103 ± 94


Reviewers: Jason Gustafson <jason@confluent.io>, Lucas Bradstreet <lucasbradstreet@gmail.com>",2019-10-28 07:57:50,Guozhang Wang,Not TDD
56bc5074858e1b8793a74697570ceeb948bdb2ce,"MINOR: improve logging of tasks on shutdown (#7597)

Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2019-10-29 10:15:39,A. Sophie Blee-Goldman,Mixed
465f810730b62e1739d0567da1254ac0167248bb,"KAFKA-8972 (2.4 blocker): correctly release lost partitions during consumer.unsubscribe() (#7441)

Inside onLeavePrepare we would look into the assignment and try to revoke the owned tasks and notify users via RebalanceListener#onPartitionsRevoked, and then clear the assignment.

However, the subscription's assignment is already cleared in this.subscriptions.unsubscribe(); which means user's rebalance listener would never be triggered. In other words, from consumer client's pov nothing is owned after unsubscribe, but from the user caller's pov the partitions are not revoked yet. For callers like Kafka Streams which rely on the rebalance listener to maintain their internal state, this leads to inconsistent state management and failure cases.

Before KIP-429 this issue is hidden away since every time the consumer re-joins the group later, it would still revoke everything anyways regardless of the passed-in parameters of the rebalance listener; with KIP-429 this is easier to reproduce now.

Our fixes are following:

• Inside unsubscribe, first do onLeavePrepare / maybeLeaveGroup and then subscription.unsubscribe. This we we are guaranteed that the streams' tasks are all closed as revoked by then.
• [Optimization] If the generation is reset due to fatal error from join / hb response etc, then we know that all partitions are lost, and we should not trigger onPartitionRevoked, but instead just onPartitionsLost inside onLeavePrepare. This is because we don't want to commit for lost tracks during rebalance which is doomed to fail as we don't have any generation info.

Reviewers: Matthias J. Sax <matthias@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-10-29 10:41:25,Boyang Chen,Mixed
cb5c7313b469b2fcd4bcd5042e74affb28f3616e,"KAFKA-8972 (2.4 blocker): clear all state for zombie task on TaskMigratedException (#7608)

Third bugfix for the failing broker bounce system test with cooperative rebalancing:

tl;dr We need to remove everything associated with a task when it is closed, but in some cases (eg AssignedTasks#commit) on a TaskMigratedExceptionwe would close it as a zombie and then (only) remove the taskId from therunning` map. This left its partitions, restorers, state stores, etc around and in an undefined state, causing exceptions when closing and/or opening the stores again.

Longer explanation:
In AssignedTasks (the abstract class from which the standby and active task variations extend) a commit failure (even due to broker down/unavailable) is treated as a TaskMigratedException after which the failed task is closed as a zombie and removed from running -- the remaining tasks (ie those still in running are then also closed as zombies in the subsequent onPartitionsLost

However we do not remove the closed task from runningByPartition nor do we remove the corresponding changelogs, if restoring, from the StoreChangelogReader since that applies only to active tasks, and AssignedTasks is generic/abstract. The changelog reader then retains a mapping from the closed task's changelog partition to its CompositeRestoreListener (and does not replace this when the new one comes along after the rebalance). The restore listener has a reference to a specific RocksDBStore instance, one which was closed when the task was closed as a zombie, so it accidentally tries to restore to the ""old"" RocksDBStore instance rather than the new one that was just opened.

Although technically this bug existed before KIP-429, it was only uncovered now that we remove tasks and clear their state/partitions/etc one at a time. We don't technically need to cherrypick the fix back earlier as before we just blindly clear all data structures entirely during an eager rebalance.

Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-10-29 21:20:01,A. Sophie Blee-Goldman,Mixed
fc0f82372e1e456cbd43490b9eba957c4a0d3eb5,"KAFKA-8980: Refactor state-store-level streams metrics (#7584)

Refactors metrics according to KIP-444
Introduces StateStoreMetrics as a central provider for state store metrics
Adds metric scope (a.k.a. store type) to the in-memory suppression buffer

Reviewers: Guozhang Wang <wangguoz@gmail.com>,  Bill Bejeck <bbejeck@gmail.com>",2019-10-30 12:24:59,Bruno Cadonna,Mixed
f65c2acad70ef644cf1ce54cfc071ffc7436a8a7,"KAFKA-8972 (2.4 blocker): bug fix for restoring task (#7617)

This is a typo bug which is due to calling a wrong map.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2019-10-31 17:14:28,Boyang Chen,Mixed
4a5155c934b9d2045e1f7af09a0298bc4b413027,"KAFKA-8868: Generate SubscriptionInfo protocol message (#7248)

Rather than maintain hand coded protocol serialization code, Streams could use the same code-generation framework as Clients/Core.

There isn't a perfect match, since the code generation framework includes an assumption that you're generating ""protocol messages"", rather than just arbitrary blobs, but I think it's close enough to justify using it, and improving it over time.

Using the code generation allows us to drop a lot of detail-oriented, brittle, and hard-to-maintain serialization logic in favor of a schema spec.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Boyang Chen <boyang@confluent.io>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-11-01 10:03:55,John Roesler,Mixed
d61b0c131ced14cd3a006ef4ccff39f6d9ad51e8,"KAFKA-8972 (2.4 blocker): TaskManager state should always be updated after rebalance (#7620)

Currently when we identify version probing we return early from onAssignment and never get to updating the TaskManager and general state with the new assignment. Since we do actually give out ""real"" assignments even during version probing, a StreamThread should take real ownership of its tasks/partitions including cleaning them up in onPartitionsRevoked which gets invoked when we call onLeavePrepare as part of triggering the follow-up rebalance.

Every member will always get an assignment encoded with the lowest common version, so there should be no problem decoding a VP assignment. We should just allow onAssignment to proceed as usual so that the TaskManager is in a consistent state, and knows what all its tasks/partitions are when the first rebalance completes and the next one is triggered.

Reviewers: Boyang Chen <boyang@confluent.io>, Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",2019-11-01 16:10:42,A. Sophie Blee-Goldman,Not TDD
7bdbdf19009709e83cb8c679a0c1c0972746555c,"HOTFIX: Try to complete Send even if no bytes were written (#7622)

If there are pending bytes in the transport layer, we may
complete a send even if no bytes were recorded as written.
We assume bytes are written when they are in the netWriteBuffer,
but we only consider the send as completed when it's in
the socket channel buffer.

This fixes a regression introduced via 0971f66ff546. The impact is
that we would sometimes throw the following exception in
`MultiRecordsSend.writeTo`:

```java
if (completed())
    throw new KafkaException(""This operation cannot be invoked on a complete request."");
```

Added unit test verifying the bug fix. While in the area, I simplified one of the
`SslSelectorTest` methods.

Reviewers: Jun Rao <junrao@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2019-11-02 08:42:30,Ismael Juma,Mixed
c552c06aed50b4d4d9a85f73ccc89bc06fa7e094,"KAFKA-9110: Improve efficiency of disk reads when TLS is enabled (#7604)

1. Avoid a buffer allocation and a buffer copy per file read.
2. Ensure we flush `netWriteBuffer` successfully before reading from
disk to avoid wasted disk reads.
3. 32k reads instead of 8k reads to reduce the number of disk reads
(improves efficiency for magnetic drives and reduces the number of
system calls).
4. Update SslTransportLayer.write(ByteBuffer) to loop until the socket
buffer is full or the src buffer has no remaining bytes.
5. Renamed `MappedByteBuffers` to `ByteBufferUnmapper` since it's also
applicable for direct byte buffers.
6. Skip empty `RecordsSend`
7. Some minor clean-ups for readability.

I ran a simple consumer perf benchmark on a 6 partition topic (large
enough not to fit into page cache) starting from the beginning of the
log with TLS enabled on my 6 core MacBook Pro as a sanity check.
This laptop has fast SSDs so it benefits less from the larger reads
than the case where magnetic disks are used. Consumer throughput
was ~260 MB/s before the changes and ~300 MB/s after
(~15% improvement).

Credit to @junrao  for pointing out that this code could be more efficient.

Reviewers: Jun Rao <junrao@confluent.io>, Colin P. McCabe <cmccabe@apache.org>",2019-11-05 04:51:25,Ismael Juma,Mixed
be58580e14be93618f11e609389ff6bb16317702,"MINOR: Rework NewPartitionReassignment public API (#7638)

This patch removes the NewPartitionReassignment#of() method in favor of a simple constructor. Said method was confusing due to breaking two conventions - always returning a non-empty Optional and thus not being used as a static factory method.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Colin P. McCabe <cmccabe@apache.org>",2019-11-05 10:34:11,Stanislav Kozlovski,Not TDD
a4cbdc6a7b3140ccbcd0e2339e28c048b434974e,"KAFKA-9137: Fix incorrect FetchSessionCache eviction logic (#7640)

Fix a bug where the lastUsedMs value in the FetchSessionCache was not getting correctly updated, resulting in spurious evictions.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2019-11-05 17:27:50,Lucas Bradstreet,Mixed
82137ba52e52a7abb652d2774e9b54485ace1612,"MINOR: Fetch only from leader should be respected in purgatory (#7650)

In #7361, we inadvertently reverted a change to enforce leader only fetching for old versions of the protocol. This patch fixes the problem and adds a new test case to cover fetches which hit purgatory.

Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, David Arthur <mumrah@gmail.com>",2019-11-06 09:22:47,Jason Gustafson,Mixed
213270967548bea938f9a77564aea81b43fdc591,"KAFKA-9140: Also reset join future when generation was reset in order to re-join (#7647)

Otherwise the join-group would not be resend and we'd just fall into the endless loop.

Reviewers: Jason Gustafson <jason@confluent.io>, Boyang Chen <boyang@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",2019-11-06 09:47:08,Guozhang Wang,Not TDD
731018222c19a260f2c576b27946bf0a8eb2167e,"[MINOR] Clean up PartitionAssignor for KIP-441 (#7649)

On-the-side cleanups extracted from the PR for KAFKA-9103, so that the actual PR can be as small as possible.
Reviewers: Christopher Pettitt <cpettitt@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",2019-11-06 14:01:26,John Roesler,Mixed
16f1ce12e4a62fd9f4e2f591dc81080eb9651b2b,"KAFKA-8729: Change `PartitionResponse` to include all troubling records (#7612)

Background:
Currently, whenever a batch is dropped because ofInvalidRecordException or InvalidTimestampException, only the culprit record appears in ProduceResponse.PartitionResponse.recordErrors. However, after users try to resend that batch excluding the rejected message, the latter records are not guaranteed to be free of problems.

Changes:
To address this issue, I changed the function signature of validateKey, validateRecord and validateTimestamp to return a Scala's Option object. Specifically, this object will hold the reason/message the current record in iteration fails and leaves to the callers (convertAndAssignOffsetsNonCompressed, assignOffsetsNonCompressed, validateMessagesAndAssignOffsetsCompressed) to gathered all troubling records into one place. Then, all these records will be returned along with the PartitionResponse object. As a result, if a batch contains more than one record errors, users see exactly which records cause the failure. PartitionResponse.recordErrors is a list of RecordError objects introduced by #7167 which include batchIndex denoting the relative position of a record in a batch and message indicating the reason of failure.

Gotchas:
Things are particularly tricky when a batch has records rejected because of both InvalidRecordException and InvalidTimestampException. In this case, the InvalidTimestampException takes higher precedence. Therefore, the Error field in PartitionResponse will be encoded with INVALID_TIMESTAMP.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-11-06 12:59:20,Tu V. Tran,Mixed
54f8d0c3fcd9c61126e005835c4f91756cb399e5,"KAFKA-9150; DescribeGroup uses member assignment as metadata

Author: David Jacot <djacot@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>

Closes #7658 from dajac/KAFKA-9150",2019-11-07 10:16:26,David Jacot,Mixed
1b08fceb7a3c502d2d18dc99796101ed0b4ff8b7,"KAFKA-9101: Create a fetch.max.bytes configuration for the broker (#7595)

Create a fetch.max.bytes configuration for the broker as described by KIP-541.

Reviewers: Gwen Shapira <gwen@confluent.io>",2019-11-07 14:18:32,Colin Patrick McCabe,Not TDD
4283fd640cbad7af9d4d5da25b6a7d4edb985a1e,"MINOR: Return null in key mapping of committed (#7659)

To be consistent with other grouping APIs, and also modified callers accordingly.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-11-08 08:53:38,Guozhang Wang,Mixed
6df058ec150b9c3c8938740ce5ce95d256f4b012,"KAFKA-8677: Simplify the best-effort network client poll to never throw exception (#7613)

Within KafkaConsumer.poll, we have an optimization to try to send the next fetch request before returning the data in order to pipelining the fetch requests; however, this pollNoWakeup should NOT throw any exceptions, since at this point the fetch position has been updated. If an exception is thrown and the callers decide to capture and continue, those records would never be returned again, causing data loss.

Also fix the flaky test itself.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",2019-11-08 09:02:34,Guozhang Wang,Not TDD
4deb80676e66311dc919f97dad1cac6131267885,"KAFKA-9098: When users name repartition topic, use the name for the repartition filter, source and sink node. (#7598)

When users specify a name for a repartition topic, we should use the same name for the repartition filter, source, and sink nodes. With the addition of KIP-307 if users go to the effort of naming every node in the topology having processor nodes with generated names is inconsistent behavior.

Updated tests in the streams test suite.

Reviewers: John Roesler <john@confluent.io>, Christopher Pettitt <cpettitt@confluent.io>",2019-11-08 16:21:13,Bill Bejeck,Not TDD
92dd337688a519e88f2b206fb506f3cd3aad14d2,"KAFKA-9133; Cleaner should handle log start offset larger than active segment base offset (#7662)

This was a regression in 2.3.1. In the case of a DeleteRecords call, the log start offset may be higher than the active segment base offset. The cleaner should allow for this case gracefully.

Reviewers: Jun Rao <junrao@gmail.com>

Co-Authored-By: Tim Van Laer <timvlaer@users.noreply.github.com>",2019-11-08 19:35:22,Jason Gustafson,Mixed
6f0008643db6e7299658442784f1bcc6c96395ed,"KAFKA-9171: Handle ReplicaNotAvailableException during DelayedFetch (#7678)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2019-11-11 20:03:06,Rajini Sivaram,Mixed
9a125a72a285f1b169586bb8c40429369f6a4fe9,"KAFKA-9011: Scala bindings for flatTransform and flatTransformValues in KStream (#7520)

Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",2019-11-12 10:23:24,Alex Kokachev,Mixed
1675115ec193acf4c7d44e68a57272edfec0b455,"MINOR: refactor replica last sent HW updates due to performance regression (#7671)

This change fixes a performance regression due to follower last seen highwatermark
handling introduced in 23beeea. maybeUpdateHwAndSendResponse is expensive for
brokers with high partition counts, as it requires a partition and a replica lookup for every
partition being fetched. This refactor moves the last seen watermark update into the follower
fetch state update where we have already looked up the partition and replica.

I've seen cases where maybeUpdateHwAndSendResponse is responsible 8% of CPU usage, not including the responseCallback call that is part of it.

I have benchmarked this change with `UpdateFollowerFetchStateBenchmark` and it adds 5ns
of overhead to Partition.updateFollowerFetchState, which is a rounding error compared to the
current overhead of maybeUpdateHwAndSendResponse.

Reviewers: David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2019-11-12 21:21:18,Lucas Bradstreet,Mixed
fecb977b257888e2022c1b1e04dd7bf03e18720c,"KAFKA-8710; Allow transactional producers to bump producer epoch [KIP-360] (#7115)

This patch implements the broker-side changes for KIP-360. It adds two new fields to InitProducerId: lastEpoch and producerId. Passing these values allows the TransactionCoordinator to safely bump a producer's epoch after some failures (such as UNKNOWN_PRODUCER_ID and INVALID_PRODUCER_ID_MAPPING). When a producer calls InitProducerId after a failure, the coordinator first checks the producer ID from the request to make sure no other producer has been started using the same transactional ID. If it is safe to continue, the coordinator checks the epoch from the request; if it matches the existing epoch, the epoch is bumped and the producer can safely continue. If it matches the previous epoch, the the current epoch is returned without bumping. Otherwise, the producer is fenced.

Reviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>",2019-11-13 17:40:53,Bob Barrett,Mixed
cac85601a00efd5b0be2f95572739fa2e5b8f719,"KAFKA-9169: fix standby checkpoint initialization (#7681)

Instead of caching the checkpoint map during StandbyTask
initialization, use the latest checkpoints (which would have
been updated during suspend).

Reviewers: Bill Bejeck <bill@confluent.io>",2019-11-13 22:03:44,John Roesler,Mixed
38d243b022336ecaf5cb400ae015c485f56ff978,"KAFKA-9046: Use top-level worker configs for connector admin clients

[Jira](https://issues.apache.org/jira/browse/KAFKA-9046)

The changes here are meant to find a healthy compromise between the pre- and post-KIP-458 functionality of Connect workers when configuring admin clients for use with DLQs. Before KIP-458, admin clients were configured using the top-level worker configs; after KIP-458, they are configured using worker configs with a prefix of `admin.` and then optionally overridden by connector configs with a prefix of `admin.override.`. The behavior proposed here is to use, in ascending order of precedence, the top-level worker configs, worker configs prefixed with `admin.`, and connector configs prefixed with `admin.override.`; essentially, use the pre-KIP-458 behavior by default but allow it to be overridden by the post-KIP-458 behavior.

Author: Chris Egerton <chrise@confluent.io>

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>, Nigel Liang <nigel@nigelliang.com>

Closes #7525 from C0urante/kafka-9046",2019-11-14 14:09:04,Chris Egerton,Mixed
898ad8271ac80d30ae7e1446d3d811996c4b5d9e,"MINOR: Add method `hasMetrics()` to class `Sensor` (#7692)

Sometimes to be backwards compatible regarding metrics the simplest
solution is to create an empty sensor. Recording an empty sensor on
the hot path may negatively impact performance. With hasMetrics()
recordings of empty sensors on the hot path can be avoided without
being to invasive.

Reviewers: Bill Bejeck <bbejeck@gmail.com>",2019-11-14 11:25:11,Bruno Cadonna,Mixed
464b6ed0349f28779a48bdbb50e29d1319848416,"MINOR. Replace Utils::readFileAsString method to read file as stream (#7208)

The current Utils::readFileAsString method creates a FileChannel and
memory maps file and copies its content to a String and returns it. But
that means that we need to know the size of the file in advance. This
precludes us from reading files whose size is not known in advance, i.e.
any file opened with flag S_IFIFO.

This change updates the method to use stream to read the content of the file.
It has couple of practical advantages:

Allows bash process substitution to pass in strings as file. So we can
say `./bin/kafka-reassign-partitions.sh --reassignment-json-file <(echo
""reassignment json"")

When adding systest for commands that take file, we don't have to
create real physical file. Instead we can just dump the content of the
file on the command line.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2019-11-15 14:10:47,Vikas Singh,Mixed
7f496744399adfbe5cd283ae3f49dec7c55b88a1,"KAFKA-8746: Kibosh must handle an empty JSON string from Trogdor (#7155)

When Trogdor wants to clear all the faults injected to Kibosh, it sends the empty JSON object {}. However, Kibosh expects {""faults"":[]} instead.  Kibosh should handle the empty JSON object, since that's consistent with how Trogdor handles empty JSON fields in general (if they're empty, they can be omitted). We should also have a test for this.

Reviewers: David Arthur <mumrah@gmail.com>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>",2019-11-15 15:13:32,Colin Patrick McCabe,Mixed
7eafea0d57522ca391a5c3c91bd251c59f839c3c,"KAFKA-9196; Update high watermark metadata after segment roll (#7695)

When we roll a new segment, the log offset metadata tied to the high watermark may
need to be updated. This is needed when the high watermark is equal to the log end
offset at the time of the roll. Otherwise, we risk exposing uncommitted data early.

Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2019-11-17 14:42:00,Jason Gustafson,Mixed
374e4803527f84001ca4b0d0f5ca411a5e8c45c6,"KAFKA-9200: ListOffsetRequest missing error response for v5 (#7704)

ListOffsetResponse getErrorResponse is missing a a case for version 5, introduced
by 152292994e4 and released in 2.3.0.

```
java.lang.IllegalArgumentException: Version 5 is not valid. Valid versions for ListOffsetRequest are 0 to 5                                                                                                                                                                                                                                                               
        at org.apache.kafka.common.requests.ListOffsetRequest.getErrorResponse(ListOffsetRequest.java:282)                                                                                                                                                                                                                                                                
        at kafka.server.KafkaApis.sendErrorOrCloseConnection(KafkaApis.scala:3062)                                                                                                                                                                                                                                                                                        
        at kafka.server.KafkaApis.sendErrorResponseMaybeThrottle(KafkaApis.scala:3045)                                                                                                                                                                                                                                                                                    
        at kafka.server.KafkaApis.handleError(KafkaApis.scala:3027)                                                                                                                                                                                                                                                                                                       
        at kafka.server.KafkaApis.handle(KafkaApis.scala:209)                                                                                                                                                                                                                                                                                                             
        at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:78)                                                                                                                                                                                                                                                                                             
        at java.lang.Thread.run(Thread.java:748)
```

Reviewers: Ismael Juma <ismael@juma.me.uk>",2019-11-17 19:18:20,Lucas Bradstreet,Not TDD
f98d935b3ef568d780c4f7b9fe2e76dad3dfd5df,"KAFKA-9180: Introduce BrokerMetadataCheckpointTest (#7700)

While investigating KAFKA-9180, I noticed that we had no
unit test coverage. It turns out that the behavior was
correct, so we just fix the test coverage issue.

Also updated .gitignore with jmh-benchmarks/generated.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2019-11-18 08:43:52,Ismael Juma,Not TDD
6ae1af842a3d4bc01ebf1bb72b52f8353c8628f5,"KAFKA-9198; Complete purgatory operations on receiving StopReplica (#7701)

Force completion of delayed operations when receiving a StopReplica request. In the case of a partition reassignment, we cannot rely on receiving a LeaderAndIsr request in order to complete these operations because the leader may no longer be a replica. Previously when this happened, the delayed operations were left to eventually timeout. 

Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Ismael Juma <ismael@juma.me.uk>

Co-Authored-By: Kun Du <kidkun@users.noreply.github.com>",2019-11-18 15:11:42,Jason Gustafson,Mixed
dcf660a2a067c9ba3add5cd2269a036ce76a7758,"HOTFIX: Fix unit tests that failed when executed from IDE (#7707)

Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2019-11-18 16:32:21,Bruno Cadonna,Not TDD
32bf0774e9727e8f92ce168bc568f62d20968386,"MINOR: Remove explicit version checks in getErrorResponse methods (#7708)

This patch removes the explicit version check pattern we used in `getErrorResponse`, which is a pain to maintain (as seen by KAFKA-9200). We already check that requests have a valid version range in the `AbstractRequest` constructor.

Reviewers: Andrew Choi <andrewchoi5@users.noreply.github.com>, Ismael Juma <ismael@juma.me.uk>",2019-11-18 17:32:23,Jason Gustafson,Mixed
d04699486d4203cf53afcc6aeb2abbffdd5e1b9c,"KAFKA-8981 Add rate limiting to NetworkDegradeSpec (#7446)

* Add rate limiting to tc

* Feedback from PR

* Add a sanity test for tc

* Add iperf to vagrant scripts

* Dynamically determine the network interface

* Add some temp code for testing on AWS

* Temp: use hostname instead of external IP

* Temp: more AWS debugging

* More AWS WIP

* More AWS temp

* Lower latency some

* AWS wip

* Trying this again now that ping should work

* Add cluster decorator to tests

* Fix broken import

* Fix device name

* Fix decorator arg

* Remove errant import

* Increase timeouts

* Fix tbf command, relax assertion on latency test

* Fix log line

* Final bit of cleanup

* Newline

* Revert Trogdor retry count

* PR feedback

* More PR feedback

* Feedback from PR

* Remove unused argument",2019-11-18 20:36:00,David Arthur,Not TDD
19681f6b95a5076af7020475f46d0bbe9f6015e1,"KAFKA-9086: Refactor processor-node-level metrics (#7615)

Refactors metrics according to KIP-444
Introduces ProcessorNodeMetrics as a central provider for processor node metrics

Reviewers:  Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>",2019-11-19 13:05:09,Bruno Cadonna,Mixed
41a9e2c7c3f3c0ae48db89178d56d26dff3a2839,"HOTFIX: safely clear all active state in onPartitionsLost (#7691)

After a number of last minute bugs were found stemming from the incremental closing of lost tasks in StreamsRebalanceListener#onPartitionsLost, a safer approach to this edge case seems warranted. We initially wanted to be as ""future-proof"" as possible, and avoid baking further protocol assumptions into the code that may be broken as the protocol evolves. This meant that rather than simply closing all active tasks and clearing all associated state in #onPartitionsLost(lostPartitions) we would loop through the lostPartitions/lost tasks and remove them one by one from the various data structures/assignments, then verify that everything was empty in the end. This verification in particular has caused us significant trouble, as it turns out to be nontrivial to determine what should in fact be empty, and if so whether it is also being correctly updated.

Therefore, before worrying about it being ""future-proof"" it seems we should make sure it is ""present-day-proof"" and implement this callback in the safest possible way, by blindly clearing and closing all active task state. We log all the relevant state (at debug level) before clearing it, so we can at least tell from the logs whether/which emptiness checks were being violated.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bbejeck@gmail.com>, Andrew Choi <andchoi@linkedin.com>",2019-11-19 16:55:03,A. Sophie Blee-Goldman,Mixed
da4337271ef0b72643c0cf47ae51e69f79cf1901,"KAFKA-9051: Prematurely complete source offset read requests for stopped tasks (#7532)

Prematurely complete source offset read requests for stopped tasks, and added unit tests.

Author: Chris Egerton <chrise@confluent.io>
Reviewers: Arjun Satish <arjun@confluent.io>, Nigel Liang <nigel@nigelliang.com>, Jinxin Liu <liukrimhim@gmail.com>, Randall Hauch <rhauch@gmail.com>",2019-11-19 21:18:21,Chris Egerton,Mixed
02df8e1496e25f7b4a2609c6f35a522e59cf7ce0,"KAFKA-8986: Allow null as a valid default for tagged fields. (#7585)

Allow null as a valid default for tagged fields.  Fix a bunch of cases where this would previously result in null pointer dereferences.

Also allow inferring FieldSpec#versions based on FieldSpec#taggedVersions.  Prefix 'key' with an underscore when it is used in the generated code, to avoid potential name collisions if someone names an RPC field ""key"".

Allow setting setting hexadecimal constants and 64-bit contstants.

Add a lot more test cases to SimpleExampleMessage.json.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-11-20 16:40:18,Colin Patrick McCabe,Mixed
4e431246c31170a7f632da8edfdb9cf4f882f6ef,"MINOR: Controller should log UpdateMetadata response errors (#7717)

Create a controller event for handling UpdateMetadata responses and log a message when a response contains an error.

Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Ismael Juma <ismael@juma.me.uk>",2019-11-21 07:41:29,Jason Gustafson,Mixed
f9fc53ea28a9c3e66aadb7d353b6b79317353b68,"MINOR: Controller should process events without rate metrics (#7732)

Fixes #7717, which did not actually achieve its intended effect. The event manager failed to process the new event because we disabled the rate metric, which it expected to be present.

Reviewers: Ismael Juma <ismael@juma.me.uk",2019-11-21 21:58:46,Jason Gustafson,Mixed
9d8ab3a1a29371699da6dcc998117522f4e72ccf,"KAFKA-8509; Add downgrade system test (#7724)

This patch adds a basic downgrade system test. It verifies that producing and consuming continues to work before and after the downgrade.

Reviewers: Ismael Juma <ismael@juma.me.uk>, David Arthur <mumrah@gmail.com>",2019-11-22 10:09:13,Jason Gustafson,Not TDD
b15e05d9257ad981d3b0d337cf3b372abbe185ae,"KAFKA-9123 Test a large number of replicas (#7621)

Two tests using 50k replicas on 8 brokers:
* Do a rolling restart with clean shutdown, delete topics
* Run produce bench and consumer bench on a subset of topics

Reviewed-By: David Jacot <djacot@confluent.io>, Vikas Singh <vikas@confluent.io>, Jason Gustafson <jason@confluent.io>",2019-11-22 19:32:08,David Arthur,Not TDD
b94c7f479b917d4ec602c31a24f11390627c479b,"MINOR: Add ignorable field check to `toStruct` and fix usage (#7710)

If a field is not marked as ignorable, we should raise an exception if it has been set to a non-default value. This check already exists in `Message.write`, so this patch adds it to `Message.toStruct`. Additionally, we fix several fields which should have been marked ignorable and we fix some related test assertions.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy <manikumar.reddy@gmail.com>, Colin Patrick McCabe <cmccabe@apache.org>",2019-11-22 22:05:03,Jason Gustafson,Not TDD
d38b8444d1be7f66c7e09a27fb145a05f3992577,"KAFKA-9229: Fix incompatible change in InitProducerIdRequest (#7746)

Reviewers: Jason Gustafson <jason@confluent.io>, José Armando García Sancio <jsancio@gmail.com>",2019-11-25 16:16:04,Colin Patrick McCabe,Not TDD
ba02e8c6b6802262646a7d6287c7a2c237be65fd,"KAFKA-9244: Update FK reference should unsubscribe old FK (#7758)

Reviewers: Adam Bellemare <adam.bellemare@wishabi.com>, John Roesler <john@confluent.io>",2019-11-29 21:21:06,Matthias J. Sax,Not TDD
0b8ea7e162e68662fbda6893d188862999d9b427,"KAFKA-6049: Add non-windowed Cogroup operator (KIP-150) (#7538)

Reviewer: Matthias J. Sax <matthias@confluent.io>",2019-11-30 19:37:04,wcarlson5,Mixed
38fde81132e0457e983eae60b3d4a9834ad84129,"MINOR: Proactively update producer topic access time. (#7672)

Changes the ProducerMetadata to longer record a sentinel TOPIC_EXPIRY_NEEDS_UPDATE upon topic map emplacement, and instead set the expiry time directly. Previously the expiry time was being updated for all touched topics after a metadata fetch was processed, which could be seconds/minutes in the future.

Additionally propagates the current time further in the Producer, which should reduce the total number of current-time calls.

Reviewers: Ismael Juma <ismael@juma.me.uk>,  Rajini Sivaram <rajinisivaram@googlemail.com>",2019-12-03 12:56:16,Brian Byrne,Mixed
18c13d38ed7090801f125088e3eaec7e3c85c09d,"KAFKA-9231: Streams Threads may die from recoverable errors with EOS enabled (#7748)

Fix three independent causes of threads dying:

1. `ProducerFencedException` isn't properly handed while suspending a task, and leads to the thread dying.
2. `IllegalStateException`: an internal assertion is violated because a store can get orphaned when an exception is thrown during initialization, again leading to the thread dying.
3. `UnknownProducerIdException`: This exception isn't expected by the Streams code, so when we get it, the relevant thread dies. It's not clear whether we always need to catch this, and in the future, we won't expect it at all, but we are catching it now to be sure we're resilient if/when it happens. Important note: this might actually harm performance if the errors turn out to be ignorable, and we will now rebalance instead of ignoring them.

Also, add missing test coverage for the exception handling code.

Reviewers: Boyang Chen <boyang@confluent.io>, Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>, Bill Bejeck <bill@confluent.io>",2019-12-03 19:13:25,John Roesler,Mixed
122941793ee932afccb1bd73d0c341e5946f1f5e,"MINOR: Add test to ensure log metrics are removed after deletion (#7750)

Reviewers: Jason Gustafson <jason@confluent.io>",2019-12-03 18:04:53,Dhruvil Shah,Mixed
d3131a10209ae06eca7840e86f39e98e18b7e1dd,"KAFKA-9258 Check Connect Metrics non-null in task stop (#7768)

Remove nullcheck, and add integration tests for restarting a failed task.

Authors: Cyrus Vafadari <cyrus@confluent.io>, Chris Egerton <chrise@confluent.io>
Reviewers: Arjun Satish <arjun@confluent.io>, Randall Hauch <rhauch@gmail.com>",2019-12-03 21:13:52,Cyrus Vafadari,Not TDD
2accf14ccf9b1f96c9dd8cfb94530c56378fae80,"KAFKA-9265: Fix kafka.log.Log instance leak on log deletion (#7773)

KAFKA-8448 fixes problem with similar leak. The Log objects are being
held in ScheduledExecutor PeriodicProducerExpirationCheck callback. The
fix in KAFKA-8448 was to change the policy of ScheduledExecutor to
remove the scheduled task when it gets canceled (by calling
setRemoveOnCancelPolicy(true)).

This works when a log is closed using close() method. But when a log is
deleted either when the topic gets deleted or when the rebalancing
operation moves the replica away from broker, the delete() operation is
invoked. Log.delete() doesn't close the pending scheduled task and that
leaks Log instance.

Fix is to close the scheduled task in the Log.delete() method too.

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2019-12-04 05:52:29,Vikas Singh,Mixed
0871f7b735856348c7d5bcfc663b4bae8e49ff76,"KAFKA-9190; Close connections with expired authentication sessions (#7723)

This patch fixes a bug in `SocketServer` in the expiration of connections which have not re-authenticated quickly enough. Previously these connections were left hanging, but now they are properly closed and cleaned up. This was one cause of the flaky test failures in `EndToEndAuthorizationTest.testNoDescribeProduceOrConsumeWithoutTopicDescribeAcl`.

Reviewers: Jason Gustafson<jason@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2019-12-04 08:39:39,Ron Dagostino,Mixed
95581f33f3f0a3dfb8769a2aa782cc11ffe1dccd,"MINOR: Adds entity-specific flags to ConfigCommand per KIP-543. (#7667)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2019-12-04 09:11:26,Brian Byrne,Mixed
5b6de9f2d022cf25df73067b9de77ec267b4af8c,"KAFKA-8933; Fix NPE in DefaultMetadataUpdater after authentication failure (#7682)

This patch fixes an NPE in `DefaultMetadataUpdater` due to an inconsistency in event expectations. Whenever there is an authentication failure, we were treating it as a failed update even if was from a separate connection from an inflight metadata request. This patch fixes the problem by making the `MetadataUpdater` api clearer in terms of the events that are handled.

Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2019-12-04 13:12:17,Jason Gustafson,Mixed
b0d89cb6ad8e01de05d7840de754ad45c361173a,"KAFKA-9251; Describing a non consumer group with the Admin API hangs forever (#7763)

If a non-consumer group is specified in `describeConsumerGroup`, the future will hang indefinitely because the future callback is never completed. This patch fixes the problem by completing the future exceptionally with an `IllegalArgumentException`.

Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",2019-12-04 13:33:34,David Jacot,Mixed
91f948763d183607b720625afea71c45a3e71fc3,"Actually run the delete topic command in kafka.py (#7776)

Reviewed-By: Jason Gustafson <jason@confluent.io>",2019-12-04 17:54:37,David Arthur,Not TDD
0e57a3924ee73529e79790c1e7a70c74911777da,"KAFKA-9184: Redundant task creation and periodic rebalances after zombie Connect worker rejoins the group (#7771)

Check connectivity with broker coordinator in intervals and stop tasks if coordinator is unreachable by setting `assignmentSnapshot` to null and resetting rebalance delay when there are no lost tasks. And, because we're now sometimes setting `assignmentSnapshot` to null and reading it from other methods and thread, made this member volatile and used local references to ensure consistent reads.

Adapted existing unit tests to verify additional debug calls, added more specific log messages to `DistributedHerder`, and added a new integration test that verifies the behavior when the brokers are stopped and restarted only after the workers lose their heartbeats with the broker coordinator.

Author: Konstantine Karantasis <konstantine@confluent.io>
Reviewers: Greg Harris <gregh@confluent.io>, Randall Hauch <rhauch@gmail.com>",2019-12-04 17:27:51,Konstantine Karantasis,Mixed
ba365bbb8deb16ec133e0e7983c1c56cef0152aa,"KAFKA-9131: Remove dead code for handling timeout exception (#7635)

Remove in catch clause and move it to the callback.

Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",2019-12-05 12:44:26,gkomissarov,Mixed
1d496a26c998cefc77223a7575980208620dfe2d,"KAFKA-9179; Fix flaky test due to race condition when fetching reassignment state (#7786)

This patch fixes a race condition on reassignment completion. The previous code fetched metadata first and then fetched the reassignment state. It is possible in between those times for the reassignment to complete, which leads to spurious URPs being reported. The fix here is to change the order of these checks and to explicitly check for reassignment completion. 

Note this patch fixes the flaky test `TopicCommandWithAdminClientTest.testDescribeUnderReplicatedPartitionsWhenReassignmentIsInProgress`.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-12-05 16:57:23,Jason Gustafson,Not TDD
fa41521687ebbe429fdc37a11e6512a369a26c21,"KAFKA-9091: Add a metric tracking the number of open connections with a given SSL cipher type (#7588)

Reviewers: Tom Bentley <tbentley@redhat.com>, Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>",2019-12-06 11:20:16,Colin Patrick McCabe,Mixed
5d0cb1419cd1f1cdfb7bc04ed4760d5a0eae0aa1,"KAFKA-9212; Ensure LeaderAndIsr state updated in controller context during reassignment (#7795)

KIP-320 improved fetch semantics by adding leader epoch validation. This relies on
reliable propagation of leader epoch information from the controller. Unfortunately, we
have encountered a bug during partition reassignment in which the leader epoch in the
controller context does not get properly updated. This causes UpdateMetadata requests
to be sent with stale epoch information which results in the metadata caches on the
brokers falling out of sync.

This bug has existed for a long time, but it is only a problem due to the new epoch
validation done by the client. Because the client includes the stale leader epoch in its
requests, the leader rejects them, yet the stale metadata cache on the brokers prevents
the consumer from getting the latest epoch. Hence the consumer cannot make progress
while a reassignment is ongoing.

Although it is straightforward to fix this problem in the controller for the new releases
(which this patch does), it is not so easy to fix older brokers which means new clients
could still encounter brokers with this bug. To address this problem, this patch also
modifies the client to treat the leader epoch returned from the Metadata response as
""unreliable"" if it comes from an older version of the protocol. The client in this case will
discard the returned epoch and it won't be included in any requests.

Also, note that the correct epoch is still forwarded to replicas correctly in the
LeaderAndIsr request, so this bug does not affect replication.

Reviewers: Jun Rao <junrao@gmail.com>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Ismael Juma <ismael@juma.me.uk>",2019-12-08 11:38:50,Jason Gustafson,Mixed
deafc56fed575b82faa6f130e2c10c9efcb94680,"KAFKA-8953: Rename UsePreviousTimeOnInvalidTimestamp to UsePartitionTimeOnInvalidTimestamp (#7633)

Implements KIP-530

Reviewer: Matthias J. Sax <matthias@confluent.io>",2019-12-08 19:23:19,ravowlga123,Mixed
648497a5e5e9373e17f632d0c2d101cc369ff20e,"KAFKA-9241: Some SASL Clients not forced to re-authenticate (#7784)

Brokers are supposed to force SASL clients to re-authenticate (and kill such connections in the absence of a timely and successful re-authentication) when KIP-368 SASL Re-Authentication is enabled via a positive connections.max.reauth.ms configuration value. There was a flaw in the logic that caused connections to not be killed in the absence of a timely and successful re-authentication if the client did not leverage the SaslAuthenticateRequest API (which was defined in KIP-152).

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2019-12-09 18:57:42,Ron Dagostino,Not TDD
bcfe8c76dd5a5b2913813cfd2ff733b7fa94a130,"KAFKA-9230: Refactor user-customizable Streams metrics (#7762)

As proposed in KIP-444, the user customizable metrics shall be refactored. The refactoring consists of:

* adding methods addLatencyRateTotalSensor and addRateTotalSensor to interface StreamMetrics
* implement the newly added methods in StreamsMetricsImpl
* deprecate methods recordThroughput() and recordLatency() in StreamsMetrics

Reviewers: Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2019-12-09 12:23:39,Bruno Cadonna,Mixed
4fea3e4f1ab9ee1f0a714c80297b782ab5b15067,"KAFKA-9288: Do not allow the same object to be inserted multiple times into ImplicitLinkedHashCollection (#7809)

Reviewers: Jason Gustafson <jason@confluent.io>",2019-12-10 16:27:16,Colin Patrick McCabe,Mixed
717ce42a6d68d3ac8d9478451a31423b5d43234e,"KAFKA-9138: Add system test for relational joins (#7664)

Add a system test to verify the new foreign-key join introduced in KIP-213

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-12-11 09:48:23,John Roesler,Not TDD
bd5be8457f7f0d163ff801adecac4687da6d8251,"KAFKA-7925 - Create credentials only once for sun.security.jgss.native (#6337)

When sun.security.jgss.native=true, we currently create a new server credential for every new client connection and add to the private credential set of the server's Subject. This is expensive and can result in an unbounded number of private credentials in the Subject used by the broker. The PR creates a credential immediately after login so that a single credential can be reused.

Reviewers: Guozhang Wang <wangguoz@gmail.com",2019-12-12 09:56:12,Rajini Sivaram,Mixed
ae2e7be20010815c7ceef02d235a6671349ed225,"KAFKA-7588: Pass custom configs to the ChannelBuilder implementations (#1037) (#7794)

Provide custom configs to ChannelBuilders in addition to parsed `values()`

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Andrew Choi <andchoi@linkedin.com",2019-12-12 11:38:10,Manikumar Reddy,Mixed
d1161bf1060efc2d58b9c72997500dae2b59f169,"KAFKA-6049: Add time window support for cogroup (#7774)

Follow up to PR #7538 (KIP-150)

Reviewer: Matthias J. Sax <matthias@confluent.io>",2019-12-12 10:52:24,wcarlson5,Mixed
7a84d936339c0a1a2d8a3c6d319835ffdeb270d8,"KAFKA-8705: Remove parent node after leaving loop to prevent NPE (#7117)

Fixes case where multiple children merged from a key-changing node causes an NPE.

Reviewers:  Matthias J. Sax <mjsax@apache.org>, Boyang Chen <boyang@confluent.io>",2019-12-12 16:24:01,Bill Bejeck,Not TDD
ae38315895659ea3f71a612ba014184c936fd6cc,"KAFKA-8855; Collect and Expose Client's Name and Version in the Brokers (KIP-511 Part 2) (#7749)

Collect and expose the KIP-511 client name and version information the clients now provide to the server as part of ApiVersionsRequests.  Also refactor how we handle selector metrics by creating a ChannelMetadataRegistry class.  This will make it easier for various parts of the networking code to modify channel metrics.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2019-12-13 10:38:17,David Jacot,Mixed
8b57f6cb3a7ea6d27169b91456355433ccfa2974,"KAFKA-6049: Add auto-repartitioning for cogroup (#7792)

Follow up to PR #7538 (KIP-150)

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2019-12-13 14:07:21,wcarlson5,Not TDD
dd8af2b23d7b58ad6d850cf9acc0eaca73681863,"KAFKA-6049: Add session window support for cogroup (#7782)

Follow up to PR #7538 (KIP-150)

Reviewer: Matthias J. Sax <matthias@confluent.io>",2019-12-15 11:44:31,wcarlson5,Mixed
9fefe6aa6cc08937de51aa60af139c93d1dbad76,"KAFKA-9297: CreateTopics API does not work with older version of the request/response (#7829)

The create topic api do not work with older version of the api. It can be reproduced by trying to create a topic with kafka-topics.sh from 2.3. It timeouts.

b94c7f4 has added a check which raises an exception if a field has been set to a non-default value unless the field is marked as ""ignorable"".

The fields added in the version 5 of the response are always set regardless of the version used by the client. If an older version is used, an exception is thrown during the serialization because the fields have non-default values. We should either not set the fields for older versions in the api layer or mark them as ignorable. I have chosen the later in this case because it looks cleaner.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>, Mickael Maison <mickael.maison@gmail.com>",2019-12-16 18:27:32,David Jacot,Not TDD
a87decb9e4df5bfa092c26ae4346f65c426f1321,"KAFKA-9113: Extract clients from tasks to record collectors (#7833)

This is part1 of a series of PRs for task management cleanup:

1. Primarily cleanup MockRecordCollectors: remove unnecessary anonymous inheritance but just consolidate on the NoOpRecordCollector -> renamed to MockRecordCollector. Most relevant changes are unit tests that would be relying on this MockRecordCollector.

2. Let StandbyContextImpl#recordCollector() to return null instead of returning a no-op collector, since in standby tasks we should ALWAYS bypass the logging logic and only use the inner store for restoreBatch. Returning null helps us to realize this assertion failed as NPE as early as possible whereas a no-op collector just hides the bug.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-12-16 16:37:40,Guozhang Wang,Mixed
b50d925e07d5ea5902b723f2ba6e248c7ef86c32,"MINOR: Add compatibility tests for 2.4.0 (#7838)

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2019-12-17 19:44:32,Manikumar Reddy,Not TDD
8c64aa080a9c49f84b62817b6d6a804af34d4f48,"MINOR: trivial cleanups

- Reformat header: `CustomDeserializerTest`, `ReplicaVerificationToolTest`
- Remove unused constructor: `ConsumerGroupDescription`
- Remove unused variables in `TimeOrderedKeyValueBufferTest#shouldRestoreV2Format`
- Remove deprecated `Number` consturctor calls; use `Number#valueOf` instread.

Author: Lee Dongjin <dongjin@apache.org>

Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #7202 from dongjinleekr/cleanup/201908",2019-12-18 21:09:16,Lee Dongjin,Not TDD
e275742f850af4a1b79b0d1bd1ac9a1d2e89c64e,"KAFKA-7251; Add support for TLS 1.3 (#7804)

Adds support for TLSv1.3 in SslTransportLayer. Note that TLSv1.3 is only enabled from Java 11 onwards, so we test the code only when running with Java11 and above.

Tests run on this PR:
  - SslTransportLayerTest: This covers testing of our SslTransportLayer and all tests are run with TLSv1.3 when running with Java 11. These tests are also run with TLSv1.2 for all Java versions.
  - SslFactoryTest: Also run with TLSv1.3 on Java 11 onwards in addition to TLSv1.2 for all Java versions.
  - SslEndToEndAuthorizationTest - Run only with TLSv1.3 on Java 11 onwards and only with TLSv1.2 on earlier Java versions. We have other versions of this test which use SSL that continue to be with TLSv1.2 on Java 11 to avoid reducing test coverage for TLSv1.2

Additional testing for done for TLSv1.3:
  - Most tests that use SSL use TestSslUtils.DEFAULT_TLS_PROTOCOL_FOR_TESTS which is set to TLSv1.2. I have run all clients and core tests with DEFAULT_TLS_PROTOCOL_FOR_TESTS=TLSv1.3 with Java 11.
  - Ran a few system tests locally with TKSv1.3

Reviewers: Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy <manikumar.reddy@gmail.com>",2019-12-19 14:13:03,Rajini Sivaram,Mixed
7e36865541307554ebad410d61c8186f6d641c55,"KAFKA-9306: The consumer must close KafkaConsumerMetrics (#7839)

Reviewers: Vikas Singh <vikas@confluent.io>, Jason Gustafson <jason@confluent.io>, Shailesh Panwar <spanwar@confluent.io>",2019-12-19 09:38:26,Colin Patrick McCabe,Mixed
7f35a6713434dd7f2ccd3897aef825d34582beab,"KIP-543: Expand ConfigCommand's non-ZK functionality (#7780)

Allow ConfigCommand to handle more operations without using direct ZooKeeper access, as described by KIP-543.  Also allow specifying entity type and name via a single flag-- again, as the KIP describes.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2019-12-19 17:05:19,Brian Byrne,Mixed
1d21cf166a8ed7def514a1860318e74b64dd47da,"KAFKA-9305: Add version 2.4 to Streams system tests (#7841)

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2019-12-20 14:21:12,Bruno Cadonna,Not TDD
cdbf40d572c388cb8616a6ffe6b8b2361cee4522,"KAFKA-9310: Handle UnknownProducerId from RecordCollector.send (#7845)

Reviewers:  Matthias J. Sax <mjsax@apache.org>",2019-12-21 12:30:36,John Roesler,Mixed
0f0eb49e35e30c444acee1d95c1e7029f65aaecb,"KAFKA-9307; Make transaction metadata loading resilient to previous errors (#7840)

Allow transaction metadata to be reloaded, even if it already exists as of a previous epoch. This helps with cases where a previous become-follower transition failed to unload corresponding metadata.

Reviewers: Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>",2019-12-23 15:20:40,Dhruvil Shah,Mixed
6b6b36cec043eefc830c5209d5a18bbcb47a31db,"KAFKA-9232; Coordinator new member timeout does not work for JoinGroup v3 and below (#7753)

The v3 JoinGroup logic does not properly complete the initial heartbeat for new members, which then expires after the static 5 minute timeout if the member does not rejoin. The core issue is in the `shouldKeepAlive` method, which returns false when it should return true because of an inconsistent timeout check.

Reviewers: Jason Gustafson <jason@confluent.io>",2019-12-23 15:55:48,A. Sophie Blee-Goldman,Not TDD
6d486eddb5adc1e00d0fbf5b6e690df56628fbd0,"KAFKA-9202: serde in ConsoleConsumer with access to headers (#7736)

The Deserializer interface has two methods, one that gives access to the headers and one that does not. ConsoleConsumer.scala only calls the latter method. It would be nice if it were to call the default method that provides header access, so that custom serde that depends on headers becomes possible.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2019-12-28 15:43:05,huxi,Not TDD
8fd7cd6a439a3914b49f7c6919e84e6937ee5a18,"MINOR: upgrade system test should check for ISR rejoin on each roll (#7827)

The upgrade system test correctly rolls by upgrading the broker and 
leaving the IBP, and then rolling again with the latest IBP version.
Unfortunately, this is not sufficient to pick up many problems in our IBP
gating as we charge through the rolls and after the second roll all of
the brokers will rejoin the ISR and the test will be treated as a
success.

This test adds two new checks:
1. We wait for the ISR to stabilize for all partitions. This is best
practice during rolls, and is enough to tell us if a broker hasn't
rejoined after each roll.
2. We check the broker logs for some common protocol errors. This is a
fail safe as it's possible for the test to be successful even if some
protocols are incompatible and the ISR is rejoined.

Reviewers: Nikhil Bhatia <nikhil@confluent.io>, Jason Gustafson <jason@confluent.io>",2019-12-30 11:02:30,Lucas Bradstreet,Not TDD
b56b848682079052e98ecde9a15a8f6b8860c599,"KAFKA-8928: Logged producer config does not always match actual configured values (#7466)

Some logged producer configs(clientId, acks, retries) might not be reflected the actual values.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-01-01 10:49:21,huxi,Mixed
a09450426785d1d4d051703ea1d86cc7e585ceef,"KAFKA-9293; Fix NPE in DumpLogSegments offsets parser and display tombstone keys (#7820)

Fixes an NPE when UserData in a member's subscription is null and adds similar checks for transaction log parser. Also modifies the output logic so that we show the keys of tombstones for both group and transaction metadata. 

Reviewers: David Arthur <mumrah@gmail.com>",2020-01-03 13:04:10,Jason Gustafson,Mixed
933b982f48cc10873cc3eeba8575eebb0fd5d463,"MINOR: Remove compilation warnings (#7888)

* Warnings
   1. `kafka/core/src/test/scala/integration/kafka/server/DelayedFetchTest.scala:110: local val partition in method testReplicaNotAvailable is never used`
   2. `kafka/core/src/test/scala/unit/kafka/admin/ConfigCommandTest.scala:527: local val alterResourceName in method verifyAlterBrokerConfig is never used`

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2020-01-06 17:19:54,Dae-Ho Kim,Not TDD
bd3bde76232f580477fb457b40258b3bae33788d,"MINOR: Fix failing test case in TransactionLogTest (#7895)

This patch fixes a brittle expectation on the `toString` implementation coming from `Set`. This was failing on jenkins with the following error:
```
java.lang.AssertionError: expected:<Some(producerId:1334,producerEpoch:0,state=Ongoing,partitions=Set(topic-0),txnLastUpdateTimestamp=0,txnTimeoutMs=1000)> but was:<Some(producerId:1334,producerEpoch:0,state=Ongoing,partitions=HashSet(topic-0),txnLastUpdateTimestamp=0,txnTimeoutMs=1000)>
```
Instead we convert the collection to a string directly.

Reviewers: Boyang Chen <boyang@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2020-01-06 09:06:11,Jason Gustafson,Mixed
42b0971e94651c590865ef163543d91722779f88,"KAFKA-9364: Fix misleading consumer logs on throttling (#7894)

When the consumer's fetch request is throttled by the KIP-219 mechanism,
it receives an empty fetch response.  The consumer should not log this
as an error.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-01-06 10:30:42,Colin Patrick McCabe,Mixed
6dc6f6a60ddf7a70c394c147fbed579749d2abcc,"KAFKA-9324: Drop support for Scala 2.11 (KIP-531) (#7859)

* Adjust build and documentation.
* Use lambda syntax for SAM types in `core`, `streams-scala` and
`connect-runtime` modules.
* Remove `runnable` and `newThread` from `CoreUtils` as lambda
syntax for SAM types make them unnecessary.
* Remove stale comment in `FunctionsCompatConversions`,
`KGroupedStream`, `KGroupedTable' and `KStream` about Scala 2.11,
the conversions are needed for Scala 2.12 too.
* Deprecate `org.apache.kafka.streams.scala.kstream.Suppressed`
and use `org.apache.kafka.streams.kstream.Suppressed` instead.
* Use `Admin.create` instead of `AdminClient.create`. Static methods
in Java interfaces can be invoked since Scala 2.12. I noticed that
MirrorMaker 2 uses `AdminClient.create`, but I did not change them
as Connectors have restrictions on newer client APIs.
* Improve efficiency in a few `Gauge` implementations by avoiding
unnecessary intermediate collections.
* Remove pointless `Option.apply` in `ZookeeperClient`
`SessionState` metric.
* Fix unused import/variable and other compiler warnings.
* Reduce visibility of some vals/defs.

Reviewers: Manikumar Reddy <manikumar@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Gwen Shapira <gwen@confluent.io>",2020-01-06 19:51:01,Ismael Juma,Mixed
2ac78ff621b1755b84daa8196197b774865357e7,"MINOR: Propagate LogContext to channel builders and SASL authenticator (#7867)

The log context is useful when debugging applications which have multiple clients. This patch propagates the context to the channel builders and the SASL authenticator.

Reviewers: Ron Dagostino <rndgstn@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2020-01-06 14:27:30,Jason Gustafson,Mixed
8d480c5eed38b2c559f3304db83ffa0bb26df356,"KAFKA-9330: Skip `join` when `AdminClient.close` is called in callback thread (#7866)

The close method calls `Thread.join` to wait for AdminClient thread to
die, but if the close is called in the api completion callback, `join`
waits forever, as the thread calling `join` is same as the thread it
wants to wait to die.

This change checks for this condition and skips the join. The thread
will then return to main loop, where it will check for this condition
and exit.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-01-07 11:07:32,Vikas Singh,Mixed
1513c817d4437300865b06bde2ae33210ae05ff9,"KAFKA-6614: configure internal topics with message.timestamp.type=CreateTime by default (#7889)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2020-01-07 12:52:40,A. Sophie Blee-Goldman,Mixed
618226c544f35a02d606342d984bb60c6e1371d7,"KAFKA-9065; Fix endless loop when loading group/transaction metadata (#7554)

The current coordinator loading logic causes an infinite loop when there is a gap between the last record in the log and the log end offset. This is possible because of compaction if the active segment is empty. The patch fixes the problem by breaking from the loading loop when a read from the log returns no additional data.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-01-07 14:03:08,David Jacot,Mixed
1adf0ee889f6f221bc41da41b25a653db5dcda60,"KAFKA-9335: Fix StreamPartitionAssignor regression in repartition topics counts (#7904)

This PR fixes the regression introduced in 2.4 from 2 refactoring PRs:
#7249
#7419

The bug was introduced by having a logical path leading numPartitionsCandidate to be 0, which is assigned to numPartitions and later being checked by setNumPartitions. In the subsequent check we will throw illegal argument if the numPartitions is 0.

This bug is both impacting new 2.4 application and upgrades to 2.4 in certain types of topology. The example in original JIRA was imported as a new integration test to guard against such regression. We also verify that without the bug fix application will still fail by running this integration test.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-01-07 14:59:27,Boyang Chen,Not TDD
1ccca5c6a99df5d1e398b098c733bad93f29d1f7,"KAFKA-6049: extend Kafka Streams Scala API for cogroup (KIP-150) (#7847)

Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>",2020-01-08 15:28:51,Matthias J. Sax,Mixed
e63becb83d68e0d8f33271d9212886e60508c34d,"KAFKA-8988; Replace CreatePartitions Request/Response with automated protocol (#7493)

This change updates the CreatePartitions request and response api objects
to use the generated protocol classes.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-01-08 15:47:27,Vikas Singh,Mixed
a024e679c7207aee2242d72aef53dc441c60ca27,"MINOR: Update dependencies for Kafka 2.5 (#7909)

Noteworthy:
* zstd decompression speed improvement of ~10%:
https://github.com/facebook/zstd/releases/tag/v1.4.4
* EasyMock, PowerMock and Mockito: improved support for Java 13.
* Replace usage of method deprecated by Mockito.
* Gradle plugins updated to versions that require Gradle 5.x, this is
fine since we no longer depend on the installed Gradle version.
* Fixed build not to depend on methods deprecated in Gradle 5.x
(fixes KAFKA-8786).
* Reflections 0.9.12 no longer depends on Guava (fixes KAFKA-3061).
* Updated `OptimizedKTableIntegrationTest` to pass with new version
of Hamcrest.
* Several Jetty improvements and bug fixes:
   - https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.21.v20190926
   - https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.22.v20191022
   - https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.23.v20191118
   - https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.24.v20191120
   - https://github.com/eclipse/jetty.project/releases/tag/jetty-9.4.25.v20191220

Note that I did not upgrade lz4 due to https://github.com/lz4/lz4-java/issues/156.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>

Co-authored-by: Ismael Juma <ismael@juma.me.uk>
Co-authored-by: Aljoscha <aljoscha.poertner@posteo.de>",2020-01-08 16:25:20,Ismael Juma,Not TDD
e9cde112cd47d88c3e256881a70035c0fd31c022,"KAFKA-9383: Expose consumer group metadata (#7906)

Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-01-09 09:34:59,Boyang Chen,Mixed
dbbe0fcf9299b9625dadcf21aa183987539b5877,"KAFKA-9287; Fix unneeded delay before failing pending transaction commit (#7799)

It is possible for the user to call `commitTransaction` before a pending `AddPartitionsToTxn` call has returned. If the `AddPartitionsToTxn` call returns an abortable error, we need to cancel any pending batches in the accumulator and we need to fail the pending commit. The problem in this case is that `Sender.runOnce`, after failing the batches, enters `NetworkClient.poll` before it has a chance to cancel the commit. Since there are no pending requests at this time, this will block unnecessarily and prevent completion of the doomed commit. This patch fixes the problem by returning from `runOnce` if any batches have been aborted, which allows the commit to also fail without the delay.

Note that this was the cause of the delay executing `AuthorizerIntegrationTest.testTransactionalProducerTopicAuthorizationExceptionInCommit` compared to other tests in this class. After fixing the bug, the delay is gone and the test time is similar to other test cases in the class.

Reviewers:  Guozhang Wang <wangguoz@gmail.com>",2020-01-09 11:11:23,Jason Gustafson,Not TDD
dbc9cd638f3524dacca4753b25e9f6566fd4560a,"KAFKA-9144; Track timestamp from txn markers to prevent early producer expiration (#7687)

Existing producer state expiration uses timestamps from data records only and not from transaction markers. This can cause premature producer expiration when the coordinator times out a transaction because we drop the state from existing batches. This in turn can allow the coordinator epoch to revert to a previous value, which can lead to validation failures during log recovery. This patch fixes the problem by also leveraging the timestamp from transaction markers. 

We also change the validation logic so that coordinator epoch is verified only for new marker appends. When replicating from the leader and when recovering the log, we only log a warning if we notice that the coordinator epoch has gone backwards. This allows recovery from previous occurrences of this bug.

Finally, this patch fixes one minor issue when loading producer state from the snapshot file. When the only record for a given producer is a control record, the ""last offset"" field will be set to -1 in the snapshot. We should check for this case when loading to be sure we recover the state consistently.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>",2020-01-09 13:47:26,Jason Gustafson,Mixed
e94f5dcc802f8e786e84a58754c800c0fbad5ab4,"KAFKA-9294: Add tests for Named parameter (#7874)

Part 1 -- tests for stateless KStream operators only

Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>",2020-01-09 15:38:09,Matthias J. Sax,Mixed
505e8240cd29fe3f0effa96d794bc711d5c8423b,"KAFKA-8421: Still return data during rebalance (#7312)

Not wait until updateAssignmentMetadataIfNeeded returns true, but only call it once with 0 timeout. Also do not return empty if in rebalance.

Trim the pre-fetched records after long polling since assignment may have been changed.

Also need to update SubscriptionState to retain the state in assignFromSubscribed if it already exists (similar to assignFromUser), so that we do not need the transition of INITIALIZING to FETCHING.

Unit test: this actually took me the most time :)

Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>, Bruno Cadonna <bruno@confluent.io>, Sophie Blee-Goldman <sophie@confluent.io>, Jason Gustafson <jason@confluent.io>, Richard Yu <yohan.richard.yu@gmail.com>, dengziming <dengziming1993@gmail.com>",2020-01-09 15:52:19,Guozhang Wang,Mixed
63576dde57109092c6103420fe60a1a983307cf8,"KAFKA-8617: Use automated protocol for `EndTxn` API (#7029)

Reviewers: Jason Gustafson <jason@confluent.io>",2020-01-09 17:08:16,Boyang Chen,Mixed
36805b8ba9803a44775a5eb711ac9d763c71598e,"MINOR: Remove `updatePartitionReplicaAssignment` from `ControllerContext` (#7924)

The method updatePartitionReplicaAssignment allows the user to directly
modify the replicas assigned to a partition without also modifying the
addingReplicas and removingReplicas fields. This is not a safe operation
for all inputs. Clients should instead use updatePartitionFullReplicaAssignment.

Reviewers: Vikas Singh <vikas@confluent.io>, Jason Gustafson <jason@confluent.io>",2020-01-10 20:21:45,José Armando García Sancio,Mixed
655447140ea5d3a59743f4bf77c0af7e34e2d96e,"MINOR: Cleanup generic & throw syntax in connect (#7892)

Reviewers: Jason Gustafson <jason@confluent.io>",2020-01-11 10:11:29,Seungha Lee,Not TDD
eb09efa9ac79efa484307bdcf03ac8eb8a3a94e2,"KAFKA-7639: Read one request at a time from socket to avoid OOM (#5920)

Prior to this commit, broker's Selector used to read all requests available on the socket when the socket is ready for read. These are queued up as staged receives. This can result in excessive memory usage when socket read buffer size is large. We mute the channel and stop reading any more data until all the staged requests are processed. This behaviour is slightly inconsistent since for the initial read we drain the socket buffer, allowing it to get filled up again, but if data arrives slighly after the initial read, then we dont read from the socket buffer until pending requests are processed.

To avoid holding onto requests for longer than required, this commit removes staged receives and reads one request at a time even if more data is available in the socket buffer. This is especially useful for produce requests which may be large and may take long to process. Additional data read from the socket for SSL is limited to the pre-allocated intermediate SSL buffers.

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2020-01-13 09:43:10,Rajini Sivaram,Mixed
4fe324b5a696d47ae8414cf030ae36b83a2cf163,"KAFKA-9352: Use 'roundrobin' to assign topic-partitions to mirroring tasks (#7880)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ryanne Dolan <ryannedolan@gmail.com>",2020-01-13 18:06:29,ning2008wisc,Mixed
39278d3089dfab4377051ed1ff47edf75dbf8583,"KAFKA-9159: The caller of sendListOffsetRequest need to handle retriable InvalidMetadata (#7665)

Loop call Consumer.endOffsets Throw TimeoutException: Failed to get offsets by times in 30000ms after a leader change.

Reviewers: Steven Lu, Guozhang Wang <wangguoz@gmail.com>",2020-01-13 19:17:08,zzccctv,Mixed
6da70f9b95d2f7cc1f32de4e405661a8015bfa7e,"KAFKA-9346: Consumer back-off logic when fetching pending offsets (#7878)

Let consumer back-off and retry offset fetch when the specific offset topic has pending commits.
The major change lies in the broker side offset fetch logic, where a request configured with flag WaitTransaction to true will be required to back-off when some pending transactional commit is ongoing. This prevents any ongoing transaction being modified by third party, thus guaranteeing the correctness with input partition writer shuffling.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-01-13 19:21:00,Boyang Chen,Mixed
d6ace7b2d7c4ad721dd8247fb2b3eff9f67fbfee,"KAFKA-7538: Reduce lock contention for Partition ISR lock (#5866)

Check for ISR updates using ISR read lock and acquire ISR write lock only if ISR needs to be updated. This avoids lock contention between request handler threads processing log appends on the leader holding the ISR read lock and request handler threads processing replica fetch requests that check/update ISR.

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2020-01-14 14:51:30,Rajini Sivaram,Not TDD
0a2569e2b9907a1217dd50ccbc320f8ad0b42fd0,"KAFKA-9420; Add flexible version support for converted protocols (#7931)

This patch bumps the following APIs in order to enable flexible version support:

- SaslAuthenticate
- SaslHandshake
- CreatePartitions
- DescribeDelegationToken
- ExpireDelegationToken
- RenewDelegationToken

This change was documented and approved in KIP-482: https://cwiki.apache.org/confluence/display/KAFKA/KIP-482%3A+The+Kafka+Protocol+should+Support+Optional+Tagged+Fields.

Reviewers: Colin Patrick McCabe <cmccabe@apache.org>",2020-01-14 11:36:34,Jason Gustafson,Not TDD
81fcb809249e9f7152232ec8aa66a79155327e6f,"KAFKA-9294: Add tests for Named parameter (#7927)

Part 2 -- tests for stateful KStream operators

Reviewers: Bill Bejeck <bill@confluent.io>",2020-01-14 13:50:36,Matthias J. Sax,Mixed
06e296be9b8d1ce777074b0e4953b6ad66105d55,"KAFKA-8764: LogCleanerManager endless loop while compacting/cleaning (#7932)

This fix makes the LogCleaner tolerant of gaps in the offset sequence. Previously, this could lead to endless loops of cleaning which required manual intervention. 

Reviewers: Jun Rao <junrao@gmail.com>, David Arthur <mumrah@gmail.com>",2020-01-14 17:03:44,Tomislav,Mixed
ed7c071e07f1f90e4c2895582f61ca090ced3c42,"KAFKA-9365: Add server side change  to include consumer group information within transaction commit (#7897)

To be able to correctly fence zombie producer txn commit, we propose to add (member.id, group.instance.id, generation) into the transaction commit protocol to raise the same level of correctness guarantee as consumer commit.

Major changes involve:

1. Upgrade transaction commit protocol with (member.id, group.instance.id, generation). The client will fail if the broker is not supporting the new protocol.
2. Refactor group coordinator logic to handle new txn commit errors such as FENCED_INSTANCE_ID, UNKNOWN_MEMBER_ID and ILLEGAL_GENERATION. We loose the check on transaction commit when the member.id is set to empty. This is because the member.id check is an add-on safety for producer commit, and we also need to consider backward compatibility for old producer clients without member.id information. And if producer equips with group.instance.id, then it must provide a valid member.id (not empty definitely), the same as a consumer commit.

Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-01-14 15:04:18,Boyang Chen,Mixed
71c5729a41330702ff0592776e2fe7f67e472b2c,"KAFKA-6144: Add KeyQueryMetadata APIs to KafkaStreams (#7960)

Deprecate existing metadata query APIs in favor of new
ones that include standby hosts as well as partition
information.

Closes: #7960
Implements: KIP-535
Co-authored-by: Navinder Pal Singh Brar <navinder_brar@yahoo.com>
Reviewed-by: John Roesler <vvcephei@apache.org>",2020-01-15 09:39:02,vinoth chandar,Mixed
0c76fbbbedb5d342080dcaf0207602c158d3116d,"KAFKA-6144: IQ option to query standbys (#7962)

Add a new overload of KafkaStreams#store that allows users
to query standby and restoring stores in addition to active ones.

Closes: #7962
Implements: KIP-535
Co-authored-by: Navinder Pal Singh Brar <navinder_brar@yahoo.com>
Reviewed-by: John Roesler <vvcephei@apache.org>",2020-01-15 13:47:40,vinoth chandar,Mixed
fbe2e604cc5b5a82afa3ec6eda956294fe5fea17,"KAFKA-9235; Ensure transaction coordinator is stopped after replica deletion (#7963)

During a reassignment, it can happen that the current leader of a partition is demoted and removed from the replica set at the same time. In this case, we rely on the StopReplica request in order to stop replica fetchers and to clear the group coordinator cache. This patch adds similar logic to ensure that the transaction coordinator state cache also gets cleared.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2020-01-16 13:50:24,Jason Gustafson,Mixed
bbd3348dcbcb01017914b64dbe6f16c00c1b7b61,"KAFKA-9431: Expose API in KafkaStreams to fetch all local offset lags (#7961)

Add a new method to KafkaStreams to return an estimate of the lags for
all partitions of all local stores.

Implements: KIP-535
Co-authored-by: Navinder Pal Singh Brar <navinder_brar@yahoo.com>
Reviewed-by: John Roesler <vvcephei@apache.org>",2020-01-16 16:25:48,vinoth chandar,Mixed
dbeaba5d9e45846d89835c1d30c138147528d0f4,"KAFKA-8847; Deprecate and remove usage of supporting classes in kafka.security.auth (#7966)

Removes references to the old scala Acl classes from kafka.security.auth (Acl, Operation, ResourceType, Resource etc.) and replaces these with the Java API. Only the old SimpleAclAuthorizer, AuthorizerWrapper used to wrap legacy authorizer instances and tests using SimpleAclAuthorizer continue to use the old API. Deprecates the old scala API.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2020-01-17 13:20:34,Rajini Sivaram,Mixed
a88703255b25eda2a75ca9a876fa8c8c5e7bfb6f,"KAFKA-9218: MirrorMaker 2 can fail to create topics (#7745)

When the scheduled refreshTopicPartitions runs, check existing topics in
both source and target clusters in order to compute topic partitions to
be created on target.

If a temporary failure to create the target topic is encountered (e.g.
insufficient number of brokers), on the next refresh the target topic
creation will be re-attempted.

Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>
Co-authored-by: Mickael Maison <mickael.maison@uk.ibm.com>
Reviewers: Ryanne Dolan <ryannedolan@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2020-01-17 13:44:18,Edoardo Comar,Mixed
9eface2e731ac53037bfa29b191171dae8c44d41,"KAFKA-9449; Adds support for closing the producer's BufferPool. (#7967)

The producer's BufferPool may block allocations if its memory limit has hit capacity. If the producer is closed, it's possible for the allocation waiters to wait for max.block.ms if progress cannot be made, even when force-closed (immediate), which can cause indefinite blocking if max.block.ms is particularly high. 

This patch fixes the problem by adding a `close()` method to `BufferPool`, which wakes up any waiters that have pending allocations and throws an exception.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-01-17 14:27:31,Brian Byrne,Mixed
9b312c401c0fe66039be28815218d28fae37dc0d,"KAFKA-9329; KafkaController::replicasAreValid should return error message (#7865)

The `KafkaController::replicasAreValid` method currently returns a
boolean indicating if replicas are valid or not. But the failure
condition loses any context on why replicas are not valid. This change
updates the metod to return the error conition if validation fails. This
allows caller to report the error to the client.

The change also renames the `replicasAreValid` method to
`validateReplicas` to reflect updated semantics.

Reviewers: Sean Li <seanli-rallyhealth@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",2020-01-17 14:34:00,Vikas Singh,Not TDD
faf46de5156ac8e0f02cc98227ed449ddcdea307,"KAFKA-9338; Fetch session should cache request leader epoch (#7970)

Since the leader epoch was not maintained in the fetch session cache, no validation would be done except for the initial (full) fetch request. This patch adds the leader epoch to the session cache and addresses the testing gaps.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Colin Patrick McCabe <cmccabe@apache.org>",2020-01-17 14:36:04,Jason Gustafson,Mixed
58a0b99e92f9caba16003256ee7db771939bb956,"KAFKA-9083: Various fixes/improvements for Connect's Values class (#7593)

Author: Chris Egerton <chrise@confluent.io>
Reviewers: Greg Harris <gregh@confluent.io>, Randall Hauch <rhauch@gmail.com>",2020-01-21 13:33:50,Chris Egerton,Mixed
c8c0ec6ac994a071224b151253a95d0e48868ecf,"KAFKA-7204: Avoid clearing records for paused partitions on poll of MockConsumer (#7505)

The previous version of MockConsumer does not allow the clients to test consecutive calls to poll while consuming only from a partial set of partitions due to the fact that it clears all the records after each call. This change makes MockConsumer clearing the records only for the partitions that are not paused (whose records are actually returned by the poll). The remaining paused partitions will retain the records.

Unit test added accordingly.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-01-21 11:46:13,Eduardo Pinto,Mixed
28f013708ffe8e48e46f408c7f570bf2cd5c54b2,"KAFKA-9024: Better error message when field specified does not exist (#7819)

Author: Nigel Liang <nigel@nigelliang.com>
Reviewer: Randall Hauch <rhauch@gmail.com>",2020-01-21 14:25:35,Nigel Liang,Mixed
de90175fc24357e20306c5a4de4f0f8ec8675ad2,"KAFKA-9418; Add new sendOffsetsToTransaction API to KafkaProducer (#7952)

This patch adds a new API to the producer to implement transactional offset commit fencing through the group coordinator as proposed in KIP-447. This PR mainly changes on the Producer end for compatible paths to old `sendOffsetsToTxn(offsets, groupId)` vs new `sendOffsetsToTxn(offsets, groupMetadata)`.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",2020-01-22 13:48:36,Boyang Chen,Mixed
df13fc93d0aebfe0ecc40dd4af3c5fb19b35f710,"KAFKA-7737; Use single path in producer for initializing the producerId (#7920)

Previously the idempotent producer and transactional producer use separate logic when initializing the producerId. This patch consolidates the two paths. We also do some cleanup in `TransactionManagerTest` to eliminate brittle expectations on `Sender`.

Reviewers: Bob Barrett <bob.barrett@confluent.io>, Viktor Somogyi <viktorsomogyi@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2020-01-23 08:14:31,Jason Gustafson,Mixed
a565d1a182cc69c9994c4512b5e9877e97f06cdf,"KAFKA-9181; Maintain clean separation between local and group subscriptions in consumer's SubscriptionState (#7941)

Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-01-24 10:38:21,Rajini Sivaram,Mixed
57b2f6807d332f4e6de4dc4ad18aa24686d304de,"KAFKA-7317: Use collections subscription for main consumer to reduce metadata (#7969)

Also addresses KAFKA-8821

Note that we still have to fall back to using pattern subscription if the user has added any regex-based source nodes to the topology. Includes some minor cleanup on the side

Reviewers: Bill Bejeck <bbejeck@gmail.com>",2020-01-24 14:30:47,A. Sophie Blee-Goldman,Mixed
2e351e06b3557ed63a54946f33fd1c0f0f136b50,"KAFKA-9152; Improve Sensor Retrieval (#7928)

This ticket shall improve two aspects of the retrieval of sensors:
https://issues.apache.org/jira/browse/KAFKA-9152

Currently, when a sensor is retrieved with *Metrics.*Sensor() (e.g. ThreadMetrics.createTaskSensor()) after it was created with the same method *Metrics.*Sensor(), the sensor is added again to the corresponding queue in Sensors (e.g. threadLevelSensors) in StreamsMetricsImpl. Those queues are used to remove the sensors when removeAllLevelSensors() is called. Having multiple times the same sensors in this queue is not an issue from a correctness point of view. However, it would reduce the footprint to only store a sensor once in those queues.

When a sensor is retrieved, the current code attempts to create a new sensor and to add to it again the corresponding metrics. This could be avoided.

Both aspects could be improved by checking whether a sensor already exists by calling getSensor() on the Metrics object and checking the return value.

Reviewers: Bruno Cadonna <bruno@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",2020-01-24 16:55:50,highluck,Mixed
a3509c0870230bcc1af4efbfafcf9f69d7cf55fd,"MINOR: MiniKdc JVM shutdown hook fix (#7946)

Also made all shutdown hooks consistent and added tests

Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>",2020-01-24 22:21:12,Ron Dagostino,Mixed
790a39e353d957632b8296346890dbc8d4694255,"KAFKA-9254; Overridden topic configs are reset after dynamic default change (#7870)

Currently, when a dynamic change is made to the broker-level default log configuration, existing log configs will be recreated with an empty overridden configs. In such case, when updating dynamic broker configs a second round, the topic-level configs are lost. This can cause unexpected data loss, for example, if the cleanup policy changes from ""compact"" to ""delete.""

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>",2020-01-24 14:47:22,huxi,Not TDD
172409c44b8551e2315bd93044a8a95ccda4699f,"KAFKA-9460: Enable only TLSv1.2 by default and disable other TLS protocol versions (KIP-553) (#7998)

Reviewers: Ron Dagostino <rndgstn@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2020-01-28 18:57:23,Nikolay,Not TDD
40b35178e8dc8f6d243f985a3f1f93a79aacd8d1,"KAFKA-9026: Use automatic RPC generation in DescribeAcls (#7560)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2020-01-29 12:45:15,Mickael Maison,Mixed
bd5a1c4d368b9e91398e48400965d30d3045062e,"KAFKA-4203: Align broker default for max.message.bytes with Java producer default (#4154)

Also: Improve error message, Add test, Minor code quality fixes
Verified that the test fails if the broker default for max message bytes is lower or higher than the currently set value.

Reviewers: Andrew Choi <andchoi@linkedin.com>, Viktor Somogyi <viktorsomogyi@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2020-01-29 13:03:35,Ismael Juma,Not TDD
8494fdb50a53099b4a80fe0cea75de0b78b20e52,"KAFKA-9040; Add --all option to config command (#7607)

Implement --all option for describing all configs (both dynamic and static) as documented in KIP-524 (https://cwiki.apache.org/confluence/display/KAFKA/KIP-524%3A+Allow+users+to+choose+config+source+when+describing+configs.

Reviewers: Brian Byrne <bbyrne@confluent.io>, Jason Gustafson <jason@confluent.io>",2020-01-29 16:14:41,Raymond Ng,Mixed
7746301c2643e0037bff3bcb84c41d512937e4c9,"KAFKA-9422: Track the set of topics a connector is using (KIP-558) (#8017)

This feature corresponds to KIP-558 and extends how the internal status topic (set via `status.storage.topic` distributed worker config) is used to include information that allows Kafka Connect to keep track which topics a connector is using.

The set of topics a connector is actively using, is exposed via a new endpoint that is added to the REST API of Connect workers.
* A `GET /connectors/{name}/topics` request will return the set of topics that have been recorded as active since a connector started or since the set of topics was reset for this connector.

An additional endpoints allows users to reset the set of active topics for a connector via the second endpoint that this feature is adding:
* A `PUT /connectors/{name}/topics/reset` request clears the set of active topics. An operator may enable or disable this feature by setting `topic.tracking.enable` (true by default).

The `topic.tracking.enable` worker config property (true by default) allows an operator to enable/disable the entire feature. Or if the feature is enabled, the `topic.tracking.allow.reset` worker config property (true by default) allows an operator to control whether reset requests submitted to the Connect REST API are allowed.

Author: Konstantine Karantasis <konstantine@confluent.io>
Reviewer: Randall Hauch <rhauch@gmail.com>",2020-01-29 23:54:21,Konstantine Karantasis,Mixed
05b2361c0412be25877cb106e9847e9a8a4f622a,"KAFKA-9445: Allow adding changes to allow serving from a specific partition (#7984)

Implements KIP-562.

Reviewers: Vinoth Chandar <vchandar@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-01-29 23:45:47,Navinder Pal Singh Brar,Mixed
6b86af3a2703dfbb9685b4440ba7538091ca3e73,"KAFKA-7658: Add KStream#toTable to the Streams DSL (#7985)

Implements KIP-523.

Reviewer: Matthias J. Sax <matthias@confluent.io>",2020-01-29 23:57:10,high.lee,Mixed
f217752bed75a79d9bfdf9195721d0b05cebbf79,"KAFKA-9360: Allow disabling MM2 heartbeat and checkpoint emissions (#7887)

`emit.heartbeats.enabled` and `emit.checkpoints.enabled` are supposed to
be the knobs to control if the heartbeat message or checkpoint message
will be sent or not to the topics respectively. In our experiments,
setting them to false will not suspend the activity in their SourceTasks,
e.g. MirrorHeartbeatTask, MirrorCheckpointTask.

The observations are, when setting those knobs to false, huge volume of
`SourceRecord` are being sent without interval, causing significantly high
CPU usage and GC time  of MirrorMaker 2 instance and congesting the single
partition of the heartbeat topic and checkpoint topic.

The proposed fix in the following PR is to (1) explicitly check if `interval`
is set to negative (e.g. -1), when the `emit.heartbeats.enabled` or
`emit.checkpoints.enabled` is off. (2) if `interval` is indeed set to negative,
no task is created.

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ryanne Dolan <ryannedolan@gmail.com>",2020-01-30 10:43:34,ning2008wisc,Mixed
57cef765f55fa1b9bab99cf4c71cf40f64533656,"KAFKA-9474: Adds 'float64' to the RPC protocol types (#8012)

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2020-01-30 04:54:27,Brian Byrne,Mixed
43576562d3def25c913ffdc2371a0c6c937a6eb4,"KAFKA-9408: Use StandardCharsets.UTF-8 instead of ""UTF-8"" (#7940)

Reviewers: Ron Dagostino <rdagostino@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2020-01-30 04:58:53,belugabehr,Not TDD
4317325fbcb29d1f5ab828821b8e0714e10ed981,"KAFKA-8503; Add default api timeout to AdminClient (KIP-533) (#8011)

This PR implements `default.api.timeout.ms` as documented by KIP-533. This is a rebased version of #6913 with some additional test cases and small cleanups.

Reviewers: David Arthur <mumrah@gmail.com>

Co-authored-by: huxi <huxi_2b@hotmail.com>",2020-01-30 22:48:51,Jason Gustafson,Mixed
c8d97c6d51bf8872eb5c0e5a123a8ee0ba6cfd6b,"KAFKA-9375: Add names to all Connect threads (#7901)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ryanne Dolan <ryannedolan@gmail.com>, gcsaba2",2020-01-31 18:21:21,Karan Kumar,Mixed
96c4ce4803c39f669a7f539481be76c67979faf0,"KAFKA-9437; Make the Kafka Protocol Friendlier with L7 Proxies [KIP-559] (#7994)

This PR implements the KIP-559: https://cwiki.apache.org/confluence/display/KAFKA/KIP-559%3A+Make+the+Kafka+Protocol+Friendlier+with+L7+Proxies
- it adds the Protocol Type and the Protocol Name fields in JoinGroup and SyncGroup API;
- it validates that the fields are provided by the client when the new version of the API is used and ensure that they are consistent. it errors out otherwise;
- it validates that the fields are consistent in the client and errors out otherwise;
- it adds many tests related to the API changes but also extends the testing coverage of the requests/responses themselves.
- it standardises the naming in the coordinator. now, `ProtocolType` and `ProtocolName` are used across the board in the coordinator instead of having a mix of protocol type, protocol name, subprotocol, protocol, etc.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-01-31 13:54:07,David Jacot,Mixed
738e14edb833f3efdf807c506531b3eed4ee7137,"KAFKA-9027, KAFKA-9028: Convert create/delete acls requests/response to use generated protocol (#7725)

Also add support for flexible versions to both protocol types.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Colin Patrick McCabe <cmccabe@apache.org>

Co-authored-by: Rajini Sivaram <rajinisivaram@googlemail.com>
Co-authored-by: Jason Gustafson <jason@confluent.io>",2020-02-03 07:12:00,Ismael Juma,Mixed
281ed90cd8f6d5221b4a87def8019a5b881898c8,"KAFKA-9492; Ignore record errors in ProduceResponse for older versions (#8030)

Fixes NPE in brokers when processing record errors in produce response for older versions.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-02-04 17:01:08,Rajini Sivaram,Mixed
dd7a314591c54af67d769f78d85c10be063cb909,"KAFKA-9074: Correct Connect’s `Values.parseString` to properly parse a time and timestamp literal (#7568)

* KAFKA-9074: Correct Connect’s `Values.parseString` to properly parse a time and timestamp literal

Time and timestamp literal strings contain a `:` character, but the internal parser used in the `Values.parseString(String)` method tokenizes on the colon character to tokenize and parse map entries. The colon could be escaped, but then the backslash character used to escape the colon is not removed and the parser fails to match the literal as a time or timestamp value.

This fix corrects the parsing logic to properly parse timestamp and time literal strings whose colon characters are either escaped or unescaped. Additional unit tests were added to first verify the incorrect behavior and then to validate the correction.

Author: Randall Hauch <rhauch@gmail.com>
Reviewers: Chris Egerton <chrise@confluent.io>, Nigel Liang <nigel@nigelliang.com>, Jason Gustafson <jason@confluent.io>",2020-02-04 11:15:04,Randall Hauch,Mixed
b029902b129333f0bafa2d0776cc827004e2532b,"KAFKA-9491; Increment high watermark after full log truncation (#8037)

When a follower's fetch offset is behind the leader's log start offset, the
follower will do a full log truncation. When it does so, it must update both
its log start offset and high watermark. The previous code did the former,
but not the latter. Failure to update the high watermark in this case can lead
to out of range errors if the follower becomes leader before getting the latest
high watermark from the previous leader. The out of range errors occur when
we attempt to resolve the log position of the high watermark in DelayedFetch
in order to determine if a fetch is satisfied.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2020-02-04 11:22:33,Jason Gustafson,Mixed
4090f9a2b0a95e4da127e4786007542276d97520,"KAFKA-9113: Clean up task management and state management (#7997)

This PR is collaborated by Guozhang Wang and John Roesler. It is a significant tech debt cleanup on task management and state management, and is broken down by several sub-tasks listed below:

Extract embedded clients (producer and consumer) into RecordCollector from StreamTask.
guozhangwang#2
guozhangwang#5

Consolidate the standby updating and active restoring logic into ChangelogReader and extract out of StreamThread.
guozhangwang#3
guozhangwang#4

Introduce Task state life cycle (created, restoring, running, suspended, closing), and refactor the task operations based on the current state.
guozhangwang#6
guozhangwang#7

Consolidate AssignedTasks into TaskManager and simplify the logic of changelog management and task management (since they are already moved in step 2) and 3)).
guozhangwang#8
guozhangwang#9

Also simplified the StreamThread logic a bit as the embedded clients / changelog restoration logic has been moved into step 1) and 2).
guozhangwang#10

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Bruno Cadonna <bruno@confluent.io>, Boyang Chen <boyang@confluent.io>",2020-02-04 21:06:39,Guozhang Wang,Mixed
bdd0a9299f8004cc82c7128b02acb6b843101c32,"MINOR: Fixing null handilg in ValueAndTimestampSerializer (#7679)

Since ValueAndTimestampSerializer wraps an unknown Serializer, the output of that Serializer can be null. In which case the line

.allocate(rawTimestamp.length + rawValue.length)
will throw a NullPointerException.

This pull request returns null instead.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-02-04 21:16:54,Daniel Beskin,Mixed
ae0c6e58e5a2c545ba54eea5fb4d5dd103d237ff,"KAFKA-9261; Client should handle unavailable leader metadata (#7770)

The client caches metadata fetched from Metadata requests. Previously, each metadata response overwrote all of the metadata from the previous one, so we could rely on the expectation that the broker only returned the leaderId for a partition if it had connection information available. This behavior changed with KIP-320 since having the leader epoch allows the client to filter out partition metadata which is known to be stale. However, because of this, we can no longer rely on the request-level guarantee of leader availability. There is no mechanism similar to the leader epoch to track the staleness of broker metadata, so we still overwrite all of the broker metadata from each response, which means that the partition metadata can get out of sync with the broker metadata in the client's cache. Hence it is no longer safe to validate inside the `Cluster` constructor that each leader has an associated `Node`

Fixing this issue was unfortunately not straightforward because the cache was built to maintain references to broker metadata through the `Node` object at the partition level. In order to keep the state consistent, each `Node` reference would need to be updated based on the new broker metadata. Instead of doing that, this patch changes the cache so that it is structured more closely with the Metadata response schema. Broker node information is maintained at the top level in a single collection and cached partition metadata only references the id of the broker. To accommodate this, we have removed `PartitionInfoAndEpoch` and we have altered `MetadataResponse.PartitionMetadata` to eliminate its `Node` references.

Note that one of the side benefits of the refactor here is that we virtually eliminate one of the hotspots in Metadata request handling in `MetadataCache.getEndpoints` (which was renamed to `maybeFilterAliveReplicas`). The only reason this was expensive was because we had to build a new collection for the `Node` representations of each of the replica lists. This information was doomed to just get discarded on serialization, so the whole effort was wasteful. Now, we work with the lower level id lists and no copy of the replicas is needed (at least for all versions other than 0).

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>",2020-02-05 09:13:11,Jason Gustafson,Mixed
5380938f8bb0cc2dcaab187e381f369361dcbf79,"MINOR: Add timer for update limit offsets (#8047)

Instead of always try to update committed offset limits as long as there are buffered records for standby tasks, we leverage on the commit interval to reduce our consumer.committed frequency.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, John Roesler <john@confluent.io>",2020-02-06 15:28:18,Guozhang Wang,Mixed
f698f3f8401845e0f73b104c0f96c54d2851b67a,"MINOR: further InternalTopologyBuilder cleanup  (#8046)

Followup to KAFKA-7317 and KAFKA-9113, there's some additional cleanup we can do in InternalTopologyBuilder. Mostly refactors the subscription code to make the initialization more explicit and reduce some duplicated code in the update logic.

Also some minor cleanup of the build method.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-02-06 19:20:52,A. Sophie Blee-Goldman,Mixed
a6c9e96bd396cea58da3e9d206b0bd907e8c7543,"HOTFIX: Fix two test failures in JDK11 (#8063)

1. StoreChangelogReaderTest.shouldRequestCommittedOffsetsAndHandleTimeoutException[1] This is due to stricter ternary operator type casting

2. KStreamImplTest.shouldSupportTriggerMaterializedWithKTableFromKStream
This is added recently where String typed values for <String, Integer>, in J8 it is allowed but in J11 it is not allowed.

Reviewers: John Roesler <john@confluent.io>",2020-02-07 13:51:37,Guozhang Wang,Not TDD
7a2a198d1e8755ec367a3d95c68aaf35b8ad9ede,"KAFKA-9507; AdminClient should check for missing committed offsets (#8057)

Addresses exception being thrown by `AdminClient` when `listConsumerGroupOffsets` returns a negative offset. A negative offset indicates the absence of a committed offset for a requested partition, and should result in a null in the returned offset map.

Reviewers: Anna Povzner <anna@confluent.io>, Jason Gustafson <jason@confluent.io>",2020-02-07 16:43:51,David Mao,Mixed
342f13a838b22464cb6297869d75eb04fd0617f3,"KAFKA-8843: KIP-515: Zookeeper TLS support

Signed-off-by: Ron Dagostino <rdagostinoconfluent.io>

Author: Ron Dagostino <rdagostino@confluent.io>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #8003 from rondagostino/KAFKA-8843",2020-02-08 21:16:48,Ron Dagostino,Mixed
059a81e3c95fd89a3cb444aa9ffd3578648b4549,"KAFKA-7658: Follow up to original PR (#8027)

Follow up to original PR #7985 for KIP-523 (adding `KStream#toTable()` operator)
  - improve JavaDocs
  - add more unit tests
  - fix bug for auto-repartitioning
  - some code cleanup

Reviewers: High Lee <yello1109@daum.net>, John Roesler <john@confluent.io>",2020-02-08 21:39:27,Matthias J. Sax,Mixed
0f8698a3292333ca527248d5cb08bf1a3f6b5def,"KAFKA-8904: Improve producer's topic metadata fetching. (#7781)

When the producer encouteres new topic(s), it now only fetches the metadata for the new topics. For cases where a producer interacts with a lot of topics, this reduces the cost for the topic being evicted from the cache, and during startup when populating the topic cache.

Additionally adds a new producer configuration variable 'metadata.max.idle.ms', which controls how long topic metadata may be idle (i.e. not produced to) before it's finally discarded from the metadata cache.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, dengziming <dengziming1993@gmail.com>",2020-02-10 14:54:04,Brian Byrne,Mixed
3b1c61385be7fb31b75f1352248bc00fa52d4a44,"KAFKA-9423: Refine layout of configuration options on website and make individual settings directly linkable (#7955)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2020-02-10 18:05:17,Sönke Liebau,Not TDD
d76fa1b22d4b06e1f1a7700272ca963091f13931,"KAFKA-9487: Follow-up PR of Kafka-9445 (#8033)

Follows up on the original PR for KAFKA-9445 to address a final round of feedback

Reviewers: John Roesler <vvcephei@apache.org>, Matthias J. Sax <matthias@confluent.io>",2020-02-10 12:09:27,Navinder Pal Singh Brar,Mixed
41fdae35df6f3913b6f92841aa9cc743d9f01c6d,"MINOR: Update schema field names in DescribeAcls Request/Response

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Colin Patrick McCabe <cmccabe@apache.org>

Closes #8075 from omkreddy/KAFKA-9026-Fix",2020-02-11 00:41:48,Manikumar Reddy,Mixed
e70e5d913a1d2295cdf47742a2cc89ec9acdacf4,"KAFKA-9505: Only loop over topics-to-validate in retries (#8039)

Found this bug from the repeated flaky runs of system tests, it seems to be long lurking but also would only happen if there are frequent rebalances / topic creation within a short time, which is exactly the case in some of our smoke system tests.

Also added a unit test.

Reviewers: Boyang Chen <boyang@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-02-10 12:59:14,Guozhang Wang,Mixed
3dfc6c15e41950cba41329d6ecffb933ea29b6df,"KAFKA-9480: Fix bug that prevented to measure task-level process-rate (#8018)

Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-02-10 13:06:06,Bruno Cadonna,Mixed
520a76155c66486cbcd0c519ef2980359964fd7c,"KAFKA-9517: Fix default serdes with FK join (#8061)

During the KIP-213 implementation and verification, we neglected to test the
code path for falling back to default serdes if none are given in the topology.

Reviewer: Bill Bejeck <bbejeck@gmail.com>",2020-02-10 15:33:23,John Roesler,Not TDD
5727b245091cdd20be335b5044f070ef4aecff0c,"KAFKA-7052 Avoiding NPE in ExtractField SMT in case of non-existent fields (#8059)

Author: Gunnar Morling <gunnar.morling@googlemail.com>
Reviewer: Randall Hauch <rhauch@gmail.com>",2020-02-11 13:48:22,Gunnar Morling,Mixed
0f14aef8cbc959551b8dd393cb47517c0479dc5e,"MINOR: Start using Response and replace IOException in EmbeddedConnectCluster for failures (#8055)

Changed `EmbeddedConnectCluster` to add utility methods that return `Response`, throw `ConnectException` instead of `IOException` for failures, and deprecate the old methods that returned primitive types rather than `Response`. 

Also introduce common assertions for embedded clusters under `EmbeddedConnectClusterAssertions`.

Author: Konstantine Karantasis <konstantine@confluent.io>
Reviewer: Randall Hauch <rhauch@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2020-02-11 14:49:26,Konstantine Karantasis,Not TDD
dc89c86d4339875085298b47e85e574d6d698dd0,"KAFKA-9483: Add Scala KStream#toTable to the Streams DSL (#8024)

Part of KIP-523

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, John Roesler <john@confluent.io>",2020-02-11 14:15:43,high.lee,Mixed
e16859dc48c679b3c7d9735438df046479b8ec4a,"KAFKA-9390: Make serde pseudo-topics unique (#8054)

During the discussion for KIP-213, we decided to pass ""pseudo-topics""
to the internal serdes we use to construct the wrapper serdes for
CombinedKey and hashing the left-hand-side value. However, during
the implementation, this strategy wasn't fully implemented, and we wound
up using the same topic name for a few different data types.

Reviewers: Guozhang Wang <guozhang@confluent.io>",2020-02-11 17:34:00,John Roesler,Mixed
cde6d18983b5d58199f8857d8d61d7efcbe6e54a,"KAFKA-9355: Fix bug that removed RocksDB metrics after failure in EOS (#7996)

* Added init() method to RocksDBMetricsRecorder
* Added call to init() of RocksDBMetricsRecorder to init() of RocksDB store
* Added call to init() of RocksDBMetricsRecorder to openExisting() of segmented state stores
* Adapted unit tests
* Added integration test that reproduces the situation in which the bug occurred

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-02-11 17:31:13,Bruno Cadonna,Mixed
998f1520f9af2dddfec9a9ac072f8dcf9d9004fd,"KAKFA-9503: Fix TopologyTestDriver output order (#8065)

Migrates TopologyTestDriver processing to be closer to the same processing/ordering
semantics as KafkaStreams. This corrects the output order for recursive topologies
as reported in KAFKA-9503, and also works similarly in the case of task idling.",2020-02-11 21:00:17,John Roesler,Not TDD
1681c78f60a3a75e69e2222be0649cd61f02f042,"KAFKA-9500: Fix FK Join Topology (#8015)

Corrects a flaw leading to an exception while building topologies that include both:

* A foreign-key join with the result not explicitly materialized
* An operation after the join that requires source materialization

Also corrects a flaw in TopologyTestDriver leading to output records being enqueued in the wrong order under some (presumably rare) circumstances.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-02-11 22:38:05,John Roesler,Not TDD
0a5dec0b3a3e1b027230ba766fee0c08b70cc63c,"MINOR: Fix unnecessary metadata fetch before group assignment (#8095)

The recent increase in the flakiness of one of the offset reset tests (KAFKA-9538) traces back to https://github.com/apache/kafka/pull/7941. After investigation, we found that following this patch, the consumer was sending an additional metadata request prior to performing the group assignment. This slight timing difference was enough to trigger the test failures. The problem turned out to be due to a bug in `SubscriptionState.groupSubscribe`, which no longer counted the local subscription when determining if there were new topics to fetch metadata for. Hence the extra metadata update. This patch restores the old logic.

Without the fix, we saw 30-50% test failures locally. With it, I could no longer reproduce the failure. However, #6561 is probably still needed to improve the resilience of this test.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2020-02-12 11:45:06,Jason Gustafson,Mixed
2cbd3d7519fd9cc6a7e74c20cd058cc833952c90,"KAFKA-9499; Improve deletion process by batching more aggressively (#8053)

This PR speeds up the deletion process by doing the following:
- Batch whenever possible to minimize the number of requests sent out to other brokers;
- Refactor `onPartitionDeletion` to remove the usage of `allLiveReplicas`.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-02-12 11:46:54,David Jacot,Mixed
aa0d0ec32ac53099ddf33e04be2a1701e539dffa,"KAFKA-6607: Commit correct offsets for transactional input data (#8091)

Reviewers: Guozhang Wang <guozhang@confluent.io>",2020-02-12 12:19:34,Matthias J. Sax,Mixed
07db26c20fcbccbf758591607864f7fd4bd8975f,"KAFKA-9417: New Integration Test for KIP-447 (#8000)

This change mainly have 2 components:

1. extend the existing transactions_test.py to also try out new sendTxnOffsets(groupMetadata) API to make sure we are not introducing any regression or compatibility issue
  a. We shrink the time window to 10 seconds for the txn timeout scheduler on broker so that we could trigger expiration earlier than later

2. create a completely new system test class called group_mode_transactions_test which is more complicated than the existing system test, as we are taking rebalance into consideration and using multiple partitions instead of one. For further breakdown:
  a. The message count was done on partition level, instead of global as we need to visualize 
the per partition order throughout the test. For this sake, we extend ConsoleConsumer to print out the data partition as well to help message copier interpret the per partition data.
  b. The progress count includes the time for completing the pending txn offset expiration
  c. More visibility and feature improvements on TransactionMessageCopier to better work under either standalone or group mode.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-02-12 12:34:12,Boyang Chen,Not TDD
c8f1ee9cd994c08056df67d22c30a5893e0901a2,"KAFKA-9192: fix NPE when for converting optional json schema in structs (#7733)

Author: Lev Zemlyanov <lev@confluent.io>
Reviewers: Greg Harris <gregh@confluent.io>, Randall Hauch <rhauch@gmail.com>",2020-02-12 15:44:23,Lev Zemlyanov,Mixed
f51e1e654812105c26693e318d20cfbe417f88fb,"allow ReplaceField SMT to handle tombstone records (#7731)

Signed-off-by: Lev Zemlyanov <lev@confluent.io>",2020-02-12 16:36:06,Lev Zemlyanov,Mixed
97d2c726f1eee137eaad0ccb8f6f71a8e10c8c23,"MINOR: Small Connect integration test fixes (#8100)

Author: Konstantine Karantasis <konstantine@confluent.io>
Reviewer: Randall Hauch <rhauch@gmail.com>",2020-02-12 17:40:37,Konstantine Karantasis,Not TDD
7e1c39f75abc443281f31f3c2f1e4829e738619d,"KAFKA-9106 make metrics exposed via jmx configurable (#7674)

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Rajini Sivaram <rajinisivaram@googlemail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2020-02-13 10:21:14,Xavier Léauté,Mixed
96c69da8c164966c1281df7001d5d239053442fd,"KAFKA-8507; Unify connection name flag for command line tool [KIP-499] (#8023)

This change updates ConsoleProducer, ConsumerPerformance, VerifiableProducer, and VerifiableConsumer classes to add and prefer the --bootstrap-server flag for defining the connection point of the Kafka cluster. This change is part of KIP-499: https://cwiki.apache.org/confluence/display/KAFKA/KIP-499+-+Unify+connection+name+flag+for+command+line+tool.

Reviewers: Ron Dagostino <rdagostino@confluent.io>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>,  Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",2020-02-13 13:44:51,Mitch,Mixed
9da6823a3a5cef7305d72788c295ada2fd1c0c88,"HOTFIX: Fix breakage in `ConsumerPerformanceTest` (#8113)

Test cases in `ConsumerPerformanceTest` were failing and causing a system exit rather than throwing the expected exception following #8023. We didn't catch this because the tests were marked as skipped and not failed.

Reviewers: Guozhang Wang <guozhang@confluent.io>",2020-02-13 18:20:15,Jason Gustafson,Mixed
8d0b069b0fbda0826ad447accbf93a19f6e813fe,"KAFKA-9557: correct thread process-rate sensor to measure throughput (#8112)

Correct the process-rate (and total) sensor to measure throughput (and total record processing count).

Reviewers: Guozhang Wang <guozhang@confluent.io>",2020-02-14 15:54:39,John Roesler,Mixed
16ee326755e3f13914a0ed446c34c84e65fc0bc4,"KAFKA-9556; Fix two issues with KIP-558 and expand testing coverage (#8085)

Correct the Connect worker logic to properly disable the new topic status (KIP-558) feature when `topic.tracking.enable=false`, and fix automatic topic status reset after a connector is deleted.

Also adds new `ConnectorTopicsIntegrationTest` and expanded unit tests.

Reviewers: Randall Hauch <rhauch@gmail.com>",2020-02-14 14:34:34,Konstantine Karantasis,Mixed
d8756e81c57040130ec163e63798663d62298589,"KAFKA-9274: Gracefully handle timeout exception (#8060)

1. Delay the initialization (producer.initTxn) from construction to maybeInitialize; if it times out we just swallow and retry in the next iteration.

2. If completeRestoration (consumer.committed) times out, just swallow and retry in the next iteration.

3. For other calls (producer.partitionsFor, producer.commitTxn, consumer.commit), treat the timeout exception as fatal.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2020-02-14 17:28:14,Guozhang Wang,Mixed
937f1f741c026767b6b71ce0b0e63ae7ebe6e936,"KAFKA-8805; Bump producer epoch on recoverable errors (#7389)

This change is the client-side part of KIP-360. It identifies cases where it is safe to abort a transaction, bump the producer epoch, and allow the application to continue without closing the producer. In these cases, when KafkaProducer.abortTransaction() is called, the producer sends an InitProducerId following the transaction abort, which causes the producer epoch to be bumped. The application can then start a new transaction and continue processing.

For recoverable errors in the idempotent producer, the epoch is bumped locally. In-flight requests for partitions with an error are rewritten to reflect the new epoch, and in-flights of all other partitions are allowed to complete using the old epoch. 

Reviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>",2020-02-15 22:47:10,Bob Barrett,Mixed
863b534f83aad50528828a30857e1ff56ac93f27,"KAFKA-9535; Update metadata before retrying partitions when fetching offsets (#8088)

Today if we attempt to list offsets with a fenced leader epoch, consumer will retry without updating the metadata until the timeout is reached. This affects synchronous APIs such as `offsetsForTimes`, `beginningOffsets`, and `endOffsets`. The fix in this patch is to trigger the metadata update call whenever we see a retriable error before additional attempts.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-02-16 12:06:33,Boyang Chen,Mixed
97c5dc1c134def07360a7f65405c3b0587f2d44d,"KAFKA-9545: Fix subscription bugs from Stream refactoring (#8109)

This PR fixes two bugs related to stream refactoring:

1. The subscribed topics are not updated correctly when topic gets removed from broker.
2. The remainingPartitions computation doesn't account the case when one task has a pattern subscription of multiple topics. Then the input partition change will not be assumed as containsAll

The bugs are exposed from integration test testRegexMatchesTopicsAWhenDeleted and could be used to verify the fix works.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-02-16 15:54:59,Boyang Chen,Not TDD
72122fc0696720495ae06e72ed40d8fd289b1425,"KAFKA-6266: Repeated occurrence of WARN Resetting first dirty offset (#8089)

Previously, checkpointed offsets for a log were only updated if the log was chosen for cleaning once the cleaning job completes. This caused issues in cases where logs with invalid checkpointed offsets would repeatedly emit warnings if the log with an invalid cleaning checkpoint wasn't chosen for cleaning.

Proposed fix is to update the checkpointed offset for logs with invalid checkpoints regardless of whether it gets chosen for cleaning.

Reviewers: Anna Povzner <anna@confluent.io>, Jun Rao <junrao@gmail.com>",2020-02-18 14:35:32,David Mao,Mixed
eb7dfef2452bf7975cde4e44baa0c9b9ea193401,"KAFKA-9558; Fix retry logic in KafkaAdminClient listOffsets (#8119)

This PR is to fix the retry logic for `getListOffsetsCalls`. Previously, if there were partitions with errors, it would only pass in the current call object to retry after a metadata refresh. However, if there's a leader change, the call object never gets updated with the correct leader node to query. This PR fixes this by making another call to `getListOffsetsCalls` with only the error topic partitions as the next calls to be made after the metadata refresh. In addition there is an additional test to test the scenario where a leader change occurs.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-02-19 09:11:45,Sanjana Kaundinya,Mixed
a41d3d86c13a55a75e67b1635bc74361ebe6d7af,"KAFKA-9533: ValueTransform forwards `null` values (#8108)

Fixes a bug where KStream#transformValues would forward null values from the provided ValueTransform#transform operation.

A test was added for verification KStreamTransformValuesTest#shouldEmitNoRecordIfTransformReturnsNull. A parallel test for non-key ValueTransformer was not added, as they share the same code path.

Reviewers: Bruno Cadonna <bruno@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",2020-02-19 16:20:35,Michael Viamari,Mixed
0d16c26e3c0affadfada1ce91faa617dc065dbcd,"HOTFIX: don't try to remove uninitialized changelogs from assignment & don't prematurely mark task closed (#8140)

This fixes two issues which together caused the soak to crash/some test to fail occasionally.

What happened was: In the main StreamThread loop we initialized a new task in TaskManager#checkForCompletedRestoration which includes registering, but not initializing, its changelogs. We then complete the loop and call poll, which resulted in a rebalance that revoked the newly-initialized task. In TaskManager#handleAssignment we then closed the task cleanly and go to remove the changelogs from the StoreChangelogReader only to get an IllegalStateException because the changelog partitions were not in the restore consumer's assignment (due to being uninitialized).

This by itself should^ be a recoverable error, as we catch exceptions here and retry closing the task as unclean. Of course the task actually was successfully closed (clean) so we now get an unexpected exception Illegal state CLOSED while closing active task

The fix(es) I'd propose are:

1. Keep the restore consumer's assignment in sync with the registered changelogs, ie the set ChangelogReader#changelogs but pause them until they are initialized edit: since the consumer does still perform some actions (gg fetches) on paused partitions, we should avoid adding uninitialized changelogs to the restore consumer's assignment. Instead, we should just skip them when removing.
2. Move the StoreChangelogReader#remove call to before the task.closeClean so that the task is only marked as closed if everything was successful. We should do so regardless, as we should (attempt to) remove the changelogs even if the clean close failed and we must do unclean.

Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-02-20 13:24:38,A. Sophie Blee-Goldman,Mixed
3b6573c150527efb3e90b2b3d1a059ac5c2db80b,"KAFKA-9481: Graceful handling TaskMigrated and TaskCorrupted (#8058)

1. Removed task field from TaskMigrated; the only caller that encodes a task id from StreamTask actually do not throw so we only log it. To handle it on StreamThread we just always enforce rebalance (and we would call onPartitionsLost to remove all tasks as dirty).

2. Added TaskCorruptedException with a set of task-ids. The first scenario of this is the restoreConsumer.poll which throws InvalidOffset indicating that the logs are truncated / compacted. To handle it on StreamThread we first close the corresponding tasks as dirty (if EOS is enabled we would also wipe out the state stores), and then revive them into the CREATED state.

3. Also fixed a bug while investigating KAFKA-9572: when suspending / closing a restoring task we should not commit the new offsets but only updating the checkpoint file.

4. Re-enabled the unit test.",2020-02-20 16:14:45,Guozhang Wang,Mixed
84c4025fdd13fb6943568ebaf78d7ea2faa35540,"KAFKA-9206; Throw KafkaException on CORRUPT_MESSAGE error in Fetch response (#8111)

If a completed fetch has an error code signifying a _corrupt message_, throw a `KafkaException` that notes the fetch offset and the topic-partition.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-02-21 10:03:09,Agam Brahma,Mixed
003dce5d51c8b74040ac22f0697f25b581f920c9,"MINOR: Standby task commit needed when offsets updated (#8146)

This is a minor fix of a regression introduced in the refactoring PR: in current trunk standbyTask#commitNeeded always return false, which would cause standby tasks to never be committed until closed. To go back to the old behavior we would return true when new data has been applied and offsets being updated.

Reviewers: Boyang Chen <boyang@confluent.io>, John Roesler <john@confluent.io>",2020-02-21 12:08:00,Guozhang Wang,Mixed
97d107a270d3e9b795b42d209f838f2f81009ce8,"KAFKA-9441: Add internal TransactionManager (#8105)

Upfront refactoring for KIP-447.

Introduces `StreamsProducer` that allows to share a producer over multiple tasks and track the TX status.

Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2020-02-22 06:40:28,Matthias J. Sax,Mixed
1a8dcffe4adb61f6073c8fb2514a7fdd49b50716,"KAFKA-9577; SaslClientAuthenticator incorrectly negotiates SASL_HANDSHAKE version (#8142)

The SaslClientAuthenticator incorrectly negotiates supported SaslHandshakeRequest version and  uses the maximum version supported by the broker whether or not the client supports it. 

This bug was exposed by a recent version bump in https://github.com/apache/kafka/commit/0a2569e2b9907a1217dd50ccbc320f8ad0b42fd0.

This PR rolls back the recent SaslHandshake[Request,Response] bump, fixes the version negotiation, and adds a test to prevent anyone from accidentally bumping the version without a workaround such as a new ApiKey. The existing key will be difficult to support for clients < 2.5 due to the incorrect negotiation.

Reviewers: Ron Dagostino <rdagostino@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>, Colin P. McCabe <cmccabe@apache.org>, Jason Gustafson <jason@confluent.io>",2020-02-21 21:49:11,Lucas Bradstreet,Not TDD
1de9981fe38f3e46dcc98cd8b5d3378f7ce0f6a8,"KAFKA-9581: Remove rebalance exception withholding (#8145)

The rebalance exception withholding is no longer necessary as we have better mechanism for catching and wrapping these exceptions. Throw them directly should be fine and simplify our current error handling.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-02-24 08:49:56,Boyang Chen,Mixed
9d53ad794de45739093070306f44df2a2f31e9e4,"KAFKA-9567: Docs, system tests for ZooKeeper 3.5.7

These changes depend on [KIP-515: Enable ZK client to use the new TLS supported authentication](https://cwiki.apache.org/confluence/display/KAFKA/KIP-515%3A+Enable+ZK+client+to+use+the+new+TLS+supported+authentication), which was only added to 2.5.0. The upgrade to ZooKeeper 3.5.7 was merged to both 2.5.0 and 2.4.1 via https://issues.apache.org/jira/browse/KAFKA-9515, but this change must only be merged to 2.5.0 (it will break the system tests if merged to 2.4.1).

Author: Ron Dagostino <rdagostino@confluent.io>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Andrew Choi <li_andchoi@microsoft.com>

Closes #8132 from rondagostino/KAFKA-9567",2020-02-25 19:59:55,Ron Dagostino,Not TDD
9639ff494a511e9af81c2e4f4d6463969bccc984,"Revert ""KAFKA-9533: ValueTransform forwards `null` values (#8108)"" (#8167)

This reverts commit a41d3d8.

Reviewers: Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>",2020-02-25 13:24:58,Bill Bejeck,Mixed
90640266393b530107db8256d38ec5aeba4805e1,"KAFKA-8147: Add changelog topic configuration to KTable suppress (#8029)

Implements: KIP-446

Reviewers: John Roesler <vvcephei@apache.org>",2020-02-25 13:23:25,high.lee,Mixed
a28447a06582bf8e6de427f047f3d3ba4e2219a1,"MINOR: don't assign standby tasks with no logged state (#8147)

Right now the task assignor just blindly assigns N standby tasks per active task (where N = num.standbys) and attempts to distribute them evenly across all instances/threads. But only standby tasks that are stateful, and whose stores are changelog-enabled, will ever actually be created.

This can result in a less-balanced assignment, and should be cleaned up in particular before implementing KIP-441 to remove the noise of ghost standbys.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-02-25 15:28:01,A. Sophie Blee-Goldman,Mixed
dd22b3f01b6bab41dce4d608f405ec6c78f7759e,"KAFKA-9498; Topic validation during the topic creation triggers unnecessary TopicChange events (#8062)

This PR avoids generating unnecessary TopicChange events during the topic validation. It does so by adding a registerWatch field in the GetChildrenRequest request. This allows to not register the watch when topics are queried from the topic validation logic.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>, Jun Rao <junrao@gmail.com>",2020-02-25 17:45:12,David Jacot,Mixed
0dc0b71d5d1b92c72ca3e5d7382b2a335e278748,"KAFKA-9602: Close the stream internal producer only in EOS (#8166)

This bug reproduces through the trunk stream test, the producer was closed unexpectedly when EOS is not turned on.

Will work on adding unit test to guard this logic.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-02-25 20:12:11,Boyang Chen,Mixed
922a95a18d6cf7ead03642bd422409fe922cccfc,"KAFKA-9594: Add a separate lock to pause the follower log append while checking if the log dir could be replaced.

This PR adds new lock is used to prevent the follower replica from being updated while ReplicaAlterDirThread is executing maybeReplaceCurrentWithFutureReplica() to replace follower replica with the future replica.

Now doAppendRecordsToFollowerOrFutureReplica() doesn't need to hold the lock on leaderIsrUpdateLock for local replica updation and ongoing log appends on the follower will not delay the makeFollower() call.

**Benchmark results for Partition.makeFollower() **
Old:
```
Benchmark                                        Mode  Cnt     Score    Error  Units
PartitionMakeFollowerBenchmark.testMakeFollower  avgt    15  2046.967 ? 22.842  ns/op
```

New:
```
Benchmark                                        Mode  Cnt     Score   Error  Units
PartitionMakeFollowerBenchmark.testMakeFollower  avgt    15  1278.525 ? 5.354  ns/op
```

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>

Closes #8153 from omkreddy/KAFKA-9594-LAISR",2020-02-26 10:55:48,Manikumar Reddy,Mixed
dfef2a3ec2f69a5159cc6d1def3130197dba9cf9,"KAFKA-9614: Not initialize topology twice in StreamTask (#8173)

We only initialize topology when transiting from restoring -> running.

Also tighten some unit tests for this fix:
a. restoring -> suspended should just write checkpoint file without committing.
b. suspended -> restoring should not need any inner updates.
c. restoring -> running should always try to fetch committed offsets, and forward timeout exceptions.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <john@confluent.io>, Boyang Chen <boyang@confluent.io>",2020-02-26 14:03:16,Guozhang Wang,Mixed
a983545d3c8a059d290db832e1bfcf9c9e38b1ce,"KAFKA-9610: do not throw illegal state when remaining partitions are not empty (#8169)

For handleRevocation, it is possible that previous onAssignment callback has cleaned up the stream tasks, which means no corresponding task could be found for given partitions. We should not throw here as this is expected behavior.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-02-26 14:05:42,Boyang Chen,Mixed
39d5534f8d1b6113d23e9cd38f40ab5495ce3286,"MINOR: Remove tag from metric to measure process-rate on source nodes (#8175)

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-02-26 15:33:18,Bruno Cadonna,Mixed
bafdf8630e7e66c2ff4405ff3ec75aa75105e837,"KAFKA-9607: Do not clear partition queues during close (#8168)

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-02-26 17:47:13,Boyang Chen,Mixed
399d18fd8ee47bee533ee4f4e4f8d9bbaf703b90,"HOTFIX: testInitTransactionTimeout should use prepareResponse instead of respond (#8179)

We have seen a flaky behavior due to using #respond instead of #prepareResponse call for the txn test.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-02-27 09:05:55,Boyang Chen,Not TDD
ede07306a70689f51fbca4f13d3b65a2326bfa43,"KAFKA-9620: Do not throw in the middle of consumer user callbacks (#8187)

One way of fixing it forward.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-02-28 12:06:58,Boyang Chen,Mixed
e0551acce434985acbbf28e441aa2d4af033b1b5,"KAFKA-9623: Keep polling until the task manager is no longer rebalancing in progress (#8190)

This bug is found via the flaky SmokeTestDriverIntegrationTest. Without this PR the test fails every 3-4 times, after this issue is fixed we've run the test 20+ locally without error.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <john@confluent.io>",2020-02-28 14:15:55,Guozhang Wang,Mixed
72a5aa8b0758f23b42c6e4453d6dc6c4861aa1ad,"MINOR: add wait_for_assigned_partitions to console-consumer (#8192)

what/why
the throttling_test was broken by this PR (#7785) since it depends on the consumer having partitions-assigned before starting the producer

this PR provides the ability to wait for partitions to be assigned in the console consumer before considering it started.

caveat
this does not support starting up the JmxTool inside the console-consumer for custom metrics while using this wait_until_partitions_assigned flag since the code assumes one JmxTool running per node.

I think a proper fix for this would be to make JmxTool its own standalone single-node service

alternatives
we could use the EndToEnd test suite which uses the verifiable producer/consumer under the hood but I found that there were more changes necessary to get this working unfortunately (specifically doesn't seem like this test suite plays nicely with the ProducerPerformanceService)

Reviewers: Mathew Wong <mwong@confluent.io>, Bill Bejeck <bbejeck.com>",2020-02-29 19:43:51,Brian Bushree,Not TDD
a1f2ece323e59a751a55386bf06beb5724c56545,"KAFKA-9525: add enforceRebalance method to Consumer API (#8087)

As described in KIP-568.

Waiting on acceptance of the KIP to write the tests, on the off chance something changes. But rest assured unit tests are coming ⚡️

Will also kick off existing Streams system tests which leverage this new API (eg version probing, sometimes broker bounce)

Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-02-29 18:44:22,A. Sophie Blee-Goldman,Mixed
ea0c02753140cacbac5893874f623441073b3837,"MINOR: Clean up process rate and latency metrics test (#8172)

Reviewers: John Roesler <vvcephei@apache.org>",2020-03-02 10:22:01,Bruno Cadonna,Mixed
c2ec974e81f1c65aa2f2e43f7f4dc820b1957bca,"KAFKA-9618: Directory deletion failure leading to error task RocksDB open (#8186)

We should have the following order:

1) close state stores
2) wipe out local directory
3) release directory lock

to avoid the issue. There's an known problem that with some FS one cannot delete the lock file while the calling thread still grabs the file lock, and this would be fixed in another ticket.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-03-03 21:45:11,Boyang Chen,Mixed
f35e6496aa003dc0667dc338001a5b51be78fe76,"KAFKA-9632; Fix MockScheduler synchronization for safe use in Log/Partition tests (#8209)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2020-03-04 09:36:06,Rajini Sivaram,Mixed
bd53249796f9ea90a56f1641d39a9b8d835ce2db,KAFKA-9661: Propagate includeSynonyms option to AdminClient in ConfigCommand (#8229),2020-03-05 11:46:37,David Arthur,Mixed
78374a15492cfb6df49353bd166d8c45ac9abdb2,"KAFKA-9615: Clean up task/producer create and close (#8213)

* Consolidate task/producer management. Now, exactly one component manages
  the creation and destruction of Producers, whether they are per-thread or per-task.
* Add missing test coverage on TaskManagerTest

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Boyang Chen <boyang@confluent.io>",2020-03-05 14:20:46,John Roesler,Mixed
674360f5b3a7e5e05b626fd55c277f7c03f27b9e,"KAFKA-6145: Encode task positions in SubscriptionInfo (#8121)

* Replace Prev/Standby task lists with a representation of the current poasition
  of all tasks, where each task is encoded as the sum of the positions of all the
  changelogs in that task.
* Only the protocol change is implemented, not actual positions, and the
  assignor is updated to translate the new protocol back to lists of Prev/Standby
  tasks so that the current assignment protocol still functions without modification.

Implements: KIP-441

Reviewers: John Roesler <vvcephei@apache.org>, Bruno Cadonna <bruno@confluent.io>",2020-03-06 09:19:04,A. Sophie Blee-Goldman,Mixed
ca90a8480183bf287d07baf6b3794bc51f76b89e,"KAFKA-9668: Iterating over KafkaStreams.getAllMetadata() results in ConcurrentModificationException (#8233)

`KafkaStreams.getAllMetadata()` returns `StreamsMetadataState.getAllMetadata()`. All the latter methods is `synchronized` it returns a reference to internal mutable state.  Not only does this break encapsulation, but it means any thread iterating over the returned collection when the metadata gets rebuilt will encounter a `ConcurrentModificationException`.

This change:
 * switches from clearing and rebuild `allMetadata` when `onChange` is called to building a new list and swapping this in. This is thread safe and has the benefit that the returned list is not empty during a rebuild: you either get the old or the new list.
 * removes synchronisation from `getAllMetadata` and `getLocalMetadata`. These are returning member variables. Synchronisation adds nothing.
 * changes `getAllMetadata` to wrap its return value in an unmodifiable wrapper to avoid breaking encapsulation.
 * changes the getters in `StreamsMetadata` to wrap their return values in unmodifiable wrapper to avoid breaking encapsulation.

Co-authored-by: Andy Coates <big-andy-coates@users.noreply.github.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-03-06 13:08:52,Andy Coates,Mixed
d3c067f35d184ca75e8cc59bedd56689cbc8269b,"MINOR: Check store directory empty to decide whether throw task corrupted exception with EOS (#8180)

Before we register the stores (and hence create the store dirs), we check if the task dir is empty except the lock / checkpoint files. Then later when loading the checkpoint files if we do not find the offsets AND the store dirs are not empty, meaning that the stores may be not empty, we treat it as task corrupted.

Reviewers: John Roesler <vvcephei@apache.org>",2020-03-06 15:38:55,Guozhang Wang,Mixed
e7f6c1e1a7590244cca88622c9e1f6b3545b1dc1,"MINOR: fix ClassCastException handling (#8156)

Reviewers: John Roesler <john@confluent.io>",2020-03-06 23:27:04,Matthias J. Sax,Mixed
fe0b704285ebc916ce5080a5248d91b4dc3c60e0,"KAFKA-9645: Fallback to unsubscribe during Task Migrated (#8220)

After #7312, we could still return data during the rebalance phase, which means it could be possible to find records without corresponding tasks. We have to fallback to the unsubscribe mode during task migrated as the assignment should be cleared out to keep sync with task manager state.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-03-07 08:08:23,Boyang Chen,Mixed
f081f3bd7619194e567daaa53b52216b75925adf,"MINOR: Reset `streamTime` on clear (#8250)

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-03-07 08:22:55,Matthias J. Sax,Mixed
cdd5ef3a5063a83f67f49b51fadffa524ab9cbaf,"MINOR: Remove throttling logic from RecordAccumulator (#7195)

This is redundant since `Sender` and `NetworkClient` handle throttling. It's
also confusing since the `RecordAccumulator` logic only applies when
`max.in.flight.requests.per.connection=1`.

In `Sender.sendProducerData`, the following code handles throttling:

```java
while (iter.hasNext()) {
    Node node = iter.next();
    if (!this.client.ready(node, now)) {
        iter.remove();
        notReadyTimeout = Math.min(notReadyTimeout, this.client.pollDelayMs(node, now));
    }
}
```

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2020-03-09 18:05:15,Ismael Juma,Mixed
dcfb641add650073f46fe8d8370c72f0284e62d7,"KAFKA-9176: Do not update limit offset if we are in RESTORE_ACTIVE mode (#8235)

Previously we may be updating the standby's limit offset as committed offsets to those source changelogs, and then inside the inner method we check if the state is in RESTORE_ACTIVE or not, which is a bug.

We should, instead, just check on the caller that we can skip restoring if:

1. we are in RESTORE_ACTIVE mode.
2. there're no source changelog partitions.
3. those partitions do not have any buffered records.

Also updated the unit test for this coverage.

Reviewers: Boyang Chen <boyang@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-03-09 17:48:44,Guozhang Wang,Mixed
fc9d91a6323baf4b79177db14f7f9af50e3c87a3,"KAFKA-9686: MockConsumer#endOffsets should be idempotent (#8255)

Fixed issue with MockConsumer#updateEndOffsets where the input offsets were appended to existing ones instead of overwriting them. 

Since there's no use for adding to existing end offsets currently, MockConsumer#updateEndOffsets is simplified and MockConsumer#getEndOffset is removed after changing the value type of the member field map 'endOffsets' to Long in MockConsumer

Details in: https://issues.apache.org/jira/browse/KAFKA-9686

The following flaky is fixed by this PR
1. KafkaBasedLogTest.testSendAndReadToEnd

Reviewers: Jason Gustafson <jason@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>",2020-03-10 08:42:59,Chia-Ping Tsai,Mixed
33f6e1a1cd4c38728112ca697bb04293d65cd968,"HOTFIX: Task#dirtyClose should not throw (#8258)

We need to swallow exceptions from StateManagerUtil#close in dirtyClose for both active and standby tasks.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-03-10 10:13:40,A. Sophie Blee-Goldman,Mixed
97fc6a52216a3da1c76771ddc37e25fed102551c,"KAFKA-9658; Fix user quota removal (#8232)

Adding (add-config) default user, user, or <user, client-id> quota and then removing it via delete-config does not update quota bound in ClientQuotaManager.Metrics for existing users or <user,client-id>. This causes brokers to continue to throttle with the previously set quotas until brokers restart (or <user,client> stops sending traffic for sometime and sensor expires). This happens only when removing the user or user,client-id where there are no more quotas  to fall back to. Common example where the issue happens: Initial no quota state --> add default user quota --> remove default user quota. 

The cause of the issue was `DefaultQuotaCallback.quotaLimit` was returning `null` when no default user quota set, which caused `ClientQuotaManager.updateQuotaMetricConfigs` to skip updating the appropriate sensor, which left it unchanged with the previous quota. Since `null` is an acceptable return value for `ClientQuotaCallback.quotaLimit`, which is already treated as unlimited quota in other parts of the code, this PR ensures that `ClientQuotaManager.updateQuotaMetricConfigs` updates the quotas for which  `ClientQuotaCallback.quotaLimit` returns `null` to unlimited quota.

Reviewers: Jason Gustafson <jason@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2020-03-10 12:30:58,Anna Povzner,Mixed
b0fd308b2bb8b199811b1d37e4582c2898093e54,"KAFKA-9344: Override default values inside ConsumerConfigs (#7876)

Similar to KAFKA-8928, during consumer construction, some configs might be overridden (client.id for instance), but the actual values will not be reflected in the info log. It'd better display the overridden values for those configs.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-03-10 14:19:33,huxi,Mixed
71113b4aac43a3a6f13625e25171ef8f2233fe7d,"MINOR: Code cleanup to improve generic typing (#8251)

Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",2020-03-10 16:43:07,Matthias J. Sax,Mixed
d3c7ef251a1ff9dfa94cd462d736a9f6592106dd,"KAFKA-9451: Update MockConsumer to support ConsumerGroupMetadata

Reviewers: Boyang Chan <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2020-03-11 15:22:44,Matthias J. Sax,Mixed
f19a79800833acda0379898fd08911c4d96d2c6c,"KAFKA-9605; Do not attempt to abort batches when txn manager is in fatal error (#8177)

We detected a bug in soak where the producer batches shall be failed in sender loop before the produce response callback. This shall trigger an illegal state exception on the producer batch as it is already aborted. 

The impact is not severe since sender is on its own thread but should be fixed to avoid unnecessary critical exception.

Reviewers: Bob Barrett <bob.barrett@confluent.io>, Jason Gustafson <jason@confluent.io>",2020-03-11 15:23:59,Boyang Chen,Mixed
8a80d942e65a40f6ee70154de25eff733d6da54e,"KAFKA-9695; Handle null config values for createTopics, alterConfigs (#8266)

Throw InvalidRequestException if null configs are specified for CreateTopics, AlterConfigs or IncrementalAlterConfigs.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2020-03-12 10:44:15,Rajini Sivaram,Not TDD
0c256e16ab33b58c8306502401e2c992018a1781,"KAFKA-9675: Fix bug that prevents RocksDB metrics to be updated (#8256)

Reviewers: John Roesler <vvcephei@apache.org>",2020-03-12 13:51:33,Bruno Cadonna,Not TDD
c1901c023191df70d4c97156d8b8544e37245ebb,"KAFKA-9644: Handle non-existent configs in incrementalAlterConfigs APPEND/SUBTRACT

Problem
----
The `incrementalAlterConfigs` API supports OpType.APPEND and OpType.SUBTRACT for configuration properties of LIST type. If an APPEND or SUBTRACT OpType is submitted for a config property which currently has no value, then the operation fails with a NullPointerException on the broker side (conveyed as an ""unknown server error"" to the client).

This is because the alter code does a `getProperty` of the existing configuration value
with no concern as to whether or not the property actually exists.

This change handles the case of existing null properties.

Testing
-----
This change includes 2 test cases in the unit test that demonstrate the issue for OpType.SUBTRACT and OpType.APPEND.

Author: Steve Rodrigues <srodrigues@confluent.io>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Bob Barrett <bob.barrett@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #8216 from steverod/steverod.kafka-9644",2020-03-13 06:50:13,Steve Rodrigues,Not TDD
2d2311d75c081745c7a24f7da7c8ec14feddd259,"KAFKA-9657: Throw upon offset fetch unsupported stable flag protocol  (#8265)

This PR tries to add an internal flag to throw if we hit an unexpected protocol version for offset fetch. It could be used together with EOS_BETA flag so that if server side downgrades unexpectedly, we shall fail the application ASAP.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-03-12 22:28:52,Boyang Chen,Mixed
f869e33ab240008050edb9a390892294344f13de,"KAFKA-8768: DeleteRecords request/response automated protocol (#7957)


Also add version 2 to make use of flexible versions, per KIP-482.

Reviewers: Mickael Maison <mickael.maison@gmail.com>",2020-03-13 17:48:47,Tom Bentley,Mixed
f165cdc325388883541db381c4bdfd30da089b3b,"KAFKA-9718; Don't log passwords for AlterConfigs in request logs (#8294)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2020-03-13 18:24:03,Rajini Sivaram,Mixed
454c3cf6171d151a1ecf37d28a800ae254d375ca,"KAFKA-9714; Eliminate unused reference to IBP in `TransactionStateManager` (#8293)

Reviewers: Jason Gustafson <jason@confluent.io>",2020-03-13 13:16:45,Kowshik Prakasam,Mixed
542853d99b9e0d660a9cf9317be8a3f8fce4c765,"KAFKA-6145: Pt 2. Include offset sums in subscription (#8246)

KIP-441 Pt. 2: Compute sum of offsets across all stores/changelogs in a task and include them in the subscription.

Previously each thread would just encode every task on disk, but we now need to read the changelog file which is unsafe to do without a lock on the task directory. So, each thread now encodes only its assigned active and standby tasks, and ignores any already-locked tasks.

In some cases there may be unowned and unlocked tasks on disk that were reassigned to another instance and haven't been cleaned up yet by the background thread. Each StreamThread makes a weak effort to lock any such task directories it finds, and if successful is then responsible for computing and reporting that task's offset sum (based on reading the checkpoint file)

This PR therefore also addresses two orthogonal issues:

1. Prevent background cleaner thread from deleting unowned stores during a rebalance
2. Deduplicate standby tasks in subscription: each thread used to include every (non-active) task found on disk in its ""standby task"" set, which meant every active, standby, and unowned task was encoded by every thread.

Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",2020-03-13 22:56:59,A. Sophie Blee-Goldman,Mixed
7945cbc73bec5529c3c6915809379f00f8604a77,"MINOR: reuse pseudo-topic in FKJoin (#8296)

Reuse the same pseudo-topic for serializing the LHS value in the foreign-key join resolver as
we originally used to serialize it before sending the subscription request.

Reviewers: Boyang Chen <boyang@confluent.io>",2020-03-13 23:04:14,John Roesler,Mixed
78554e73f66e0cdf7d289e64b4f8b13b68c48acf,"KAFKA-9677: Fix consumer fetch with small consume bandwidth quotas (#8290)

When we changed quota communication with KIP-219, fetch requests get throttled by returning empty response with the delay in throttle_time_ms and Kafka consumer retries again after the delay. With default configs, the maximum fetch size could be as big as 50MB (or 10MB per partition). The default broker config (1-second window, 10 full windows of tracked bandwidth/thread utilization usage) means that < 5MB/s consumer quota (per broker) may block consumers from being able to fetch any data.

This PR ensures that consumers cannot get blocked by quota by capping fetchMaxBytes in KafkaApis.handleFetchRequest() to quota window * consume bandwidth quota. In the example of default configs (10-second quota window) and 1MB/s consumer bandwidth quota, fetchMaxBytes would be capped to 10MB.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2020-03-14 20:45:50,Anna Povzner,Mixed
605d55dc173156471fb05c40d715ab318ce74952,"KAFKA-6647: Do note delete the lock file while holding the lock (#8267)

1. Inside StateDirectory#cleanRemovedTasks, skip deleting the lock file (and hence the parent directory) until releasing the lock. And after the lock is released only go ahead and delete the parent directory if manualUserCall == true. That is, this is triggered from KafkaStreams#cleanUp and users are responsible to make sure that Streams instance is not started and hence there are no other threads trying to grab that lock.

2. As a result, during scheduled cleanup the corresponding task.dir would not be empty but be left with only the lock file, so effectively we still achieve the goal of releasing disk spaces. For callers of listTaskDirectories like KIP-441 (cc @ableegoldman to take a look) I've introduced a new listNonEmptyTaskDirectories which excludes such dummy task.dirs with only the lock file left.

3. Also fixed KAFKA-8999 along the way to expose the exception while traversing the directory.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <vvcephei@apache.org>",2020-03-14 13:49:08,Guozhang Wang,Mixed
227a7322b77840e08924b9486e4bda2f3dfc1f1a,"KIP-546: Implement describeClientQuotas and alterClientQuotas. (#8083)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2020-03-14 23:03:13,Brian Byrne,Mixed
045c6c3c48244c43cf5db2506827c20b01c353c8,"MINOR: enforce non-negative invariant for checkpointed offsets (#8297)

While discussing KIP-441 we realize we don't strictly enforce that all checkpointed offset sums are positive (or 0, though there's not much point to checkingpoint a 0 offset is there)?

Rather than awkwardly try handle this within every user/reader of the checkpoint file, we should just make a guarantee that all returned checkpointed offsets are positive.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-03-15 09:30:40,A. Sophie Blee-Goldman,Mixed
31659c3ee1868ec2ae82868e3976836a160440f1,"MINOR: fix Scala 2.13 build error introduced in #8083 (#8301)

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Brian Byrne <bbyrne@confluent.io>",2020-03-16 08:56:47,Chia-Ping Tsai,Not TDD
a0e14078202febbe4df726078a179d66e908fb32,"KAFKA-9670; Reduce allocations in Metadata Response preparation (#8236)

This PR removes  intermediate  conversions between `MetadataResponse.TopicMetadata` => `MetadataResponseTopic` and `MetadataResponse.PartitionMetadata` => `MetadataResponsePartition` objects.

There is 15-20% reduction in object allocations and 5-10% improvement in metadata request performance.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson<jason@confluent.io>",2020-03-16 09:30:48,Manikumar Reddy,Mixed
569cf994b0b36c871ca2e575a7f72d069cd409eb,"KAFKA-9712: Catch and handle exception thrown by reflections scanner (#8289)

This commit works around a bug in version v0.9.12 of the upstream `reflections` library by catching and handling the exception thrown.

The reflections issue is tracked by:
https://github.com/ronmamo/reflections/issues/273

New unit tests were introduced to test the behavior.

* KAFKA-9712: Catch and handle exception thrown by reflections scanner

* Update connect/runtime/src/main/java/org/apache/kafka/connect/runtime/isolation/DelegatingClassLoader.java

Co-Authored-By: Konstantine Karantasis <konstantine@confluent.io>

* Move result initialization back to right before it is used

* Use `java.io.File` in tests

* Fix checkstyle

Co-authored-by: Konstantine Karantasis <konstantine@confluent.io>

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2020-03-16 14:43:10,Nigel Liang,Mixed
dffc7f8c30824cb6bf38c05838a466488cbb1f81,"MINOR: Fix build and JavaDoc warnings (#8291)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, @SoontaekLim, Bill Bejeck <bill@confluent.io>",2020-03-16 18:23:21,Matthias J. Sax,Not TDD
673018504f6653141cc5d1c997a165f0c03d8239,"MINOR: cleanup and add tests to StateDirectoryTest (#8304)

Adds tests for edge conditions of listAllTaskDirectories
Also includes some minor cleanup of the StateDirectoryTest class

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-03-16 21:59:02,A. Sophie Blee-Goldman,Mixed
6a88d32b9fe3cb320088dec72fce30992b89ef28,"KAFKA-8803: Remove timestamp check in completeTransitionTo (#8278)

In prepareAddPartitions the txnStartTimestamp could be updated as updateTimestamp, which is assumed to be always larger then the original startTimestamp. However, due to ntp time shift the timer may go backwards and hence the newStartTimestamp be smaller than the original one. Then later in completeTransitionTo the time check would fail with an IllegalStateException, and the txn would not transit to Ongoing.

An indirect result of this, is that this txn would NEVER be expired anymore because only Ongoing ones would be checked for expiration.

We should do the same as in #3286 to remove this check.

Also added test coverage for both KAFKA-5415 and KAFKA-8803.

Reviewers: Jason Gustafson<jason@confluent.io>",2020-03-17 14:40:02,Guozhang Wang,Mixed
d38e97e319b1ca90ce951b8a153fa51953bba43e,"MINOR: clean up required setup for StreamsPartitionAssignorTest (#8306)

No logical or behavioral changes, just a bit of cleanup in this class before we have to write and fix a lot of these tests for KIP-441:

* Moved creation of streamsMetadata mock to setUp (in exactly one test it will be overwritten with a strict mock)
* Tried to clean up the use of helper methods for configuring the assignor.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-03-17 22:14:00,A. Sophie Blee-Goldman,Mixed
5fc3cd61fcb73da8b52f34b72fe6bb7457f46ce2,"KAFKA-9625: Fix altering and describing dynamic broker configurations (#8260)

* Broker throttles were incorrectly marked as sensitive configurations.  Fix this, so that their values can be returned via DescribeConfigs as expected.

* Previously, changes to broker configs that consisted only of deletions were ignored by the brokers because of faulty delta calculation logic that didn't consider deletions as changes, only alterations as changes.  Fix this and add a regression test.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2020-03-17 23:02:33,Sanjana Kaundinya,Not TDD
34a7ba56a161c066aeacaf88c1ead6109a111d8a,"KAFKA-9047; AdminClient group operations should respect retries and backoff (#8161)

Previously, `AdminClient` group operations did not respect a `Call`'s number of configured tries and retry backoff. This could lead to tight retry loops that put a lot of pressure on the broker. This PR introduces fixes that ensures for all group operations the `AdminClient` respects the number of tries and the backoff a given `Call` has.

Reviewers: Vikas Singh <vikas@confluent.io>, Jason Gustafson <jason@confluent.io>",2020-03-18 12:19:40,Sanjana Kaundinya,Mixed
b586283c53ba235f2194ca4923266ad0653064b4,"KAFKA-9656; Return COORDINATOR_NOT_AVAILABLE for older producer clients (#8253)

The `TxnOffsetCommit` API suffers from a bug affecting older client versions which treat `COORDINATOR_LOAD_IN_PROGRESS` errors as fatal. This PR changes the handling on the broker to instead return `COORDINATOR_NOT_AVAILABLE` in this case so that clients won't crash upon doing txn commit. 

Reviewers: Jason Gustafson <jason@confluent.io>",2020-03-18 12:25:36,Boyang Chen,Mixed
85c96f523090cce5fd8767c0fd3505ee4885f63d,"KAFKA-9568: enforce rebalance if client endpoint has changed (#8299)

Since the assignment info includes a map with all member's host info, we can just check the received map to make sure our endpoint is contained. If not, we need to force the group to rebalance and get our updated endpoint info.

Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-03-18 18:37:38,A. Sophie Blee-Goldman,Mixed
c7164a3866ab6a28eb5ae158ff29ac806f4f3d54,"KAFKA-8618: Replace Txn marker with automated protocol (#7039)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2020-03-19 14:26:41,Boyang Chen,Mixed
4f1e8331ff9479e40a1a76f2c9b28a631d51bf80,"KAFKA-9435: DescribeLogDirs automated protocol (#7972)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2020-03-19 15:26:18,Tom Bentley,Mixed
9ee8277cdd4bc02257f5ff6cffd67d823485562d,"KAFKA-6145: Add new assignment configs

Add 4 new assignor configs in preparation for the new assignment algorithm:
1. acceptable.recovery.lag
2. balance.factor
3. max.warmup.replicas
4. probing.rebalance.interval.ms

Implements: KIP-441
Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",2020-03-19 13:19:14,A. Sophie Blee-Goldman,Mixed
89cd2f2a0b21368297323437fd15ba6341e4707b,"KAFKA-9441: Unify committing within TaskManager (#8218)

 - part of KIP-447
 - commit all tasks at once using non-eos (and eos-beta in follow up work)
 - unified commit logic into TaskManager
 - split existing methods of Task interface in pre/post parts

Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2020-03-19 11:31:51,Matthias J. Sax,Mixed
21cfd0b453c878780236f623249b3b5ddec52e6e,"MINOR: Fix generic types in StreamsBuilder and Topology (#8273)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",2020-03-19 14:29:15,Matthias J. Sax,Mixed
c27f629e953025d726f722c15bd18c78f5f6cb66,"KAFKA-9654; Update epoch in `ReplicaAlterLogDirsThread` after new LeaderAndIsr  (#8223)

Currently when there is a leader change with a log dir reassignment in progress, we do not update the leader epoch in the partition state maintained by `ReplicaAlterLogDirsThread`. This can lead to a FENCED_LEADER_EPOCH error, which results in the partition being marked as failed, which is a permanent failure until the broker is restarted. This patch fixes the problem by updating the epoch in `ReplicaAlterLogDirsThread` after receiving a new LeaderAndIsr request from the controller.

Reviewers: Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>",2020-03-19 16:49:35,Chia-Ping Tsai,Mixed
56051e763965d439f11f20f876475732eed7b307,"KAFKA-8820: kafka-reassign-partitions.sh should support the KIP-455 API (#8244)

Rewrite ReassignPartitionsCommand to use the KIP-455 API when possible, rather
than direct communication with ZooKeeper.  Direct ZK access is still supported,
but deprecated, as described in KIP-455.

As specified in KIP-455, the tool has several new flags.  --cancel stops
an assignment which is in progress.  --preserve-throttle causes the
--verify and --cancel commands to leave the throttles alone.
--additional allows users to execute another partition assignment even
if there is already one in progress.  Finally, --show displays all of
the current partition reassignments.

Reorganize the reassignment code and tests somewhat to rely more on unit
testing using the MockAdminClient and less on integration testing.  Each
integration test where we bring up a cluster seems to take about 5 seconds, so
it's good when we can get similar coverage from unit tests.  To enable this,
MockAdminClient now supports incrementalAlterConfigs, alterReplicaLogDirs,
describeReplicaLogDirs, and some other APIs.  MockAdminClient is also now
thread-safe, to match the real AdminClient implementation.

In DeleteTopicTest, use the KIP-455 API rather than invoking the reassignment
command.",2020-03-19 20:44:34,Colin Patrick McCabe,Mixed
24d05aa601e05ec92948364f72e1d5f92998475d,"KAFKA-9553; Improve measurement for loading groups and transactions (#8155)

This patch modifies the loading time metric to account for time spent waiting for the loading time task to be scheduled.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-03-19 23:35:16,Agam Brahma,Mixed
960b2162903dd7d07f20c162aa536b1e67b6477e,"KAFKA-9734: Fix IllegalState in Streams transit to standby (#8319)

Consolidate ChangelogReader state management inside of StreamThread to avoid having to reason about all execution paths in both StreamThread and TaskManager.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-03-20 10:17:51,John Roesler,Mixed
cbdd0d6cf1c7033dde6cd51f41d52034fd59c59d,"KAFKA-6145: Add constrained balanced assignment algorithm (#8262)

Adds a currently unused component of the new Streams assignment algorithm.

Implements: KIP-441
Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <vvcephei@apache.org>",2020-03-20 13:51:24,Bruno Cadonna,Mixed
c249ea8e5d9dad5e74b804a6f062b059517d6a8d,"KAFKA-9727: cleanup the state store for standby task dirty close and check null for changelogs (#8307)

This PR fixes three things:

* the state should be closed when standby task is restoring as well
* the EOS standby task should also wipe out state under dirty close
* the changelog reader should check for null as well

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-03-20 15:26:13,Boyang Chen,Mixed
c75dc5e2e09cee4ba47a9b6c484cb225acdb086e,"KAFKA-9701 (fix): Only check protocol name when generation is valid (#8324)

This bug was incurred by #7994 with a too-strong consistency check. It is because a reset generation operation could be called in between the joinGroupRequest -> joinGroupResponse -> SyncGroupRequest -> SyncGroupResponse sequence of events, if user calls unsubscribe in the middle of consumer#poll().

Proper fix is to avoid the protocol name check when the generation is invalid.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-03-20 21:26:57,Boyang Chen,Mixed
635b5fd47c86809401dd8f3c0e9a225526f96555,"KAFKA-9741: Update ConsumerGroupMetadata before calling onPartitionsRevoked() (#8325)

If partitions are revoked, an application may want to commit the current offsets.

Using transactions, committing offsets would be done via the producer passing in the current ConsumerGroupMetadata. If the metadata is not updates before the callback, the call to commitTransaction(...) fails as and old generationId would be used.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-03-20 21:34:08,Matthias J. Sax,Mixed
6cf27c9c771900baf43cc47f9b010dbf7a86fa22,"KAFKA-6145: Pt 2.5 Compute overall task lag per client (#8252)

Once we have encoded the offset sums per task for each client, we can compute the overall lag during assign by fetching the end offsets for all changelog and subtracting.

If the listOffsets request fails, we simply return a ""completely sticky"" assignment, ie all active tasks are given to previous owners regardless of balance.

Builds (but does not yet use) the statefulTasksToRankedCandidates map with the ranking:
Rank -1: active running task
Rank 0: standby or restoring task whose overall lag is within acceptableRecoveryLag
Rank 1: tasks whose lag is unknown (eg during version probing)
Rank 1+: all other tasks are ranked according to their actual total lag

Implements: KIP-441
Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",2020-03-21 13:40:34,A. Sophie Blee-Goldman,Mixed
4f6907947a95db48876dd331133d349236d5152a,"MINOR: fix linking errors in javadoc (#8198)

This improvement fixes several linking errors to classes and methods from within javadocs. 

Related to #8291

Reviewers: Konstantine Karantasis <konstantine@confluent.io>",2020-03-22 10:15:18,Chia-Ping Tsai,Not TDD
f8173c2df573ae9b53ab7ea6e5d6700acf8e0cf4,"MINOR: Update Connect error message to point to the correct config validation REST endpoint (#7991)

When incorrect connector configuration is detected, the returned exception message suggests to check the connector's configuration against the `{connectorType}/config/validate` endpoint. 

Changing the error message to refer to the exact REST endpoint which is `/connector-plugins/{connectorType}/config/validate` 

This aligns the exception message with the documentation at: https://kafka.apache.org/documentation/#connect_rest 

Reviewers: Konstantine Karantasis <konstantine@confluent.io>",2020-03-22 12:42:45,nicolasguyomar,Not TDD
1ad5f346cb88072c419142c86c3d897aad2de996,"KAFKA-9451: Enable producer per thread for Streams EOS (#8318)

- KIP-447
- add new configs to enable producer per thread EOS
- updates TaskManager to use single shared producer for eos-beta

Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2020-03-22 13:50:07,Matthias J. Sax,Mixed
f538caf13819c79b37fcdd300d7dacd724180197,"KAFKA-9742: Fix broken StandbyTaskEOSIntegrationTest (#8330)

Relax the requirement that tasks' reported offsetSum is less than the endOffsetSum for those
tasks. This was surfaced by a test for corrupted tasks, but it can happen with real corrupted
tasks. Rather than throw an exception on the leader, we now de-prioritize the corrupted task.
Ideally, that instance will not get assigned the task and the stateDirCleaner will make
the problem ""go away"". If it does get assigned the task, then it will detect the corruption and
delete the task directory before recovering the entire changelog. Thus, the estimate we provide
accurately reflects the amount of lag such a corrupted task would have to recover (the whole log).

Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bruno Cadonna <bruno@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2020-03-23 17:58:14,John Roesler,Mixed
cc7061410567be3e5f2aae199b67e943409fd215,"KAFKA-9743: Catch commit offset exception to eventually close dirty tasks (#8327)

Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-03-24 09:26:14,Boyang Chen,Mixed
1b36e11967e7a459d6401ba5ea740a659fc1994b,"MINOR: Restore and global consumers should never have group.instance.id (#8322)

And hence restore / global consumers should never expect FencedInstanceIdException.

When such exception is thrown, it means there's another instance with the same instance.id taken over, and hence we should treat it as fatal and let this instance to close out instead of handling as task-migrated.

Reviewers: Boyang Chen <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-03-24 10:10:23,Guozhang Wang,Mixed
4c96b7deba53976ae9fdc961d93e5dc3ce754d72,"KAFKA-9749; Transaction coordinator should treat KAFKA_STORAGE_ERROR as retriable (#8336)

When handling a WriteTxnResponse, the TransactionMarkerRequestCompletionHandler throws an IllegalStateException when the remote broker responds with a KAFKA_STORAGE_ERROR and does not retry the request. This leaves the transaction state stuck in PendingAbort or PendingCommit, with no way to change that state other than restarting the broker, because both EndTxnRequest and InitProducerIdRequest return CONCURRENT_TRANSACTIONS if the state is PendingAbort or PendingCommit. This patch changes the error handling behavior in TransactionMarkerRequestCompletionHandler to retry KAFKA_STORAGE_ERRORs. This matches the existing client behavior, and makes sense because KAFKA_STORAGE_ERROR causes the host broker to shut down, meaning that the partition being written to will move its leadership to a new, healthy broker.

Reviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>",2020-03-24 14:27:53,Bob Barrett,Mixed
8012f47e2cb955ddecc3bd58240a84d021ed571c,"MINOR: move some client methods to new ClientUtils (#8328)

* move to new ClientUtils

* checkstyle

* fix KafkaStreamsTest

* checkstyle again",2020-03-24 16:28:08,A. Sophie Blee-Goldman,Mixed
1fbddd853da8b36b0c84197ceab936465f0b4f7c,"KAFKA-6145: Add balanced assignment algorithm (#8334)

This algorithm assigns tasks to clients and tries to
- balance the distribution of the  partitions of the
  same input topic over stream threads and clients,
  i.e., data parallel workload balance
- balance the distribution of work over stream threads.
The algorithm does not take into account potentially existing states
on the client.

The assignment is considered balanced when the difference in
assigned tasks between the stream thread with the most tasks and
the stream thread with the least tasks does not exceed a given
balance factor.

The algorithm prioritizes balance over stream threads
higher than balance over clients.

Reviewers: John Roesler <vvcephei@apache.org>",2020-03-24 17:49:12,Bruno Cadonna,Mixed
a5c257890e843ea7d755aee8ecde2e4e4f89d0ab,"MINOR: Add method to Herder to control logging of connector configs during validation (#8263)

* The Herder interface is extended with a default method that allows choosing whether to log all the connector configurations during connector validation or not. 

* The `PUT /connector-plugins/{connector-type}/config/validate` is modified to stop logging the connector's configurations when a validation request is hitting this endpoint. Validations during creation or reconfiguration of a connector are still logging all the connector configurations at the INFO level, which is useful in general and during troubleshooting in particular. 

Co-authored-by: Konstantine Karantasis <konstantine@confluent.io>

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Ismael Juma <github@juma.me.uk>",2020-03-24 16:41:58,Chia-Ping Tsai,Mixed
b8e508c823517c857c9cfa8a3de77ab374549fde,"KAFKA-9711 The authentication failure caused by SSLEngine#beginHandshake is not properly caught and handled (#8287)

SSLEngine#beginHandshake is possible to throw authentication failures (for example, no suitable cipher suites) so we ought to catch SSLException and then convert it to SslAuthenticationException so as to process authentication failures correctly.

Reviewers: Jun Rao <junrao@gmail.com>",2020-03-24 18:45:05,Chia-Ping Tsai,Mixed
b5409b9c04d7aa102ab9ca0f8fdea46235da8554,"KAFKA-9700: Fix negative estimatedCompressionRatio (#8285)

There are cases where `currentEstimation` is less than
`COMPRESSION_RATIO_IMPROVING_STEP` causing
`estimatedCompressionRatio` to be negative. This, in turn,
may result in `MESSAGE_TOO_LARGE`.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2020-03-24 20:48:50,jiameixie,Mixed
e1cbefef600ea7186ffb92cf2f13c4c87b7769b3,"HOTFIX: fix log message in version probing system test (#8341)

Reviewer: Matthias J. Sax <matthias@confluent.io>",2020-03-24 21:46:37,A. Sophie Blee-Goldman,Not TDD
ef1cd3490a591d6a2436a847688b317fe3d48344,"KAFKA-9752; New member timeout can leave group rebalance stuck (#8339)

Older versions of the JoinGroup rely on a new member timeout to keep the group from growing indefinitely in the case of client disconnects and retrying. The logic for resetting the heartbeat expiration task following completion of the rebalance failed to account for an implicit expectation that shouldKeepAlive would return false the first time it is invoked when a heartbeat expiration is scheduled. This patch fixes the issue by making heartbeat satisfaction logic explicit.

Reviewers:  Chia-Ping Tsai <chia7712@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2020-03-24 22:16:49,Jason Gustafson,Mixed
befd80b38d3ccb1aa0c6d99a899129fd5cf27774,"KAFKA-9573: Fix JVM options to run early versions of Kafka on the latest JVMs (#8138)

Startup scripts for the early version of Kafka contain removed JVM options like `-XX:+PrintGCDateStamps` or `-XX:UseParNewGC`. 
When system tests run on JVM that doesn't support these options we should set up
environment variables with correct options.

Reviewers: Guozhang Wang <guozhang@confluent.io>, Ron Dagostino <rdagostino@confluent.io>, Ismael Juma <ismael@juma.me.uk",2020-03-25 10:31:07,Nikolay,Not TDD
8cf781ef0196995ef99d875612b6b7e9adcb912b,"MINOR: Improve performance of checkpointHighWatermarks, patch 1/2 (#6741)

This PR works to improve high watermark checkpointing performance.

`ReplicaManager.checkpointHighWatermarks()` was found to be a major contributor to GC pressure, especially on Kafka clusters with high partition counts and low throughput.

Added a JMH benchmark for `checkpointHighWatermarks` which establishes a
performance baseline. The parameterized benchmark was run with 100, 1000 and
2000 topics. 

Modified `ReplicaManager.checkpointHighWatermarks()` to avoid extra copies and cached
the Log parent directory Sting to avoid frequent allocations when calculating
`File.getParent()`.

A few clean-ups:
* Changed all usages of Log.dir.getParent to Log.parentDir and Log.dir.getParentFile to
Log.parentDirFile.
* Only expose public accessor for `Log.dir` (consistent with `Log.parentDir`)
* Removed unused parameters in `Partition.makeLeader`, `Partition.makeFollower` and `Partition.createLogIfNotExists`.

Benchmark results:

| Topic Count | Ops/ms | MB/sec allocated |
|-------------|---------|------------------|
| 100               | + 51%    |  - 91% |
| 1000             | + 143% |  - 49% |
| 2000            | + 149% |   - 50% |

Reviewers: Lucas Bradstreet <lucas@confluent.io>. Ismael Juma <ismael@juma.me.uk>

Co-authored-by: Gardner Vickers <gardner@vickers.me>
Co-authored-by: Ismael Juma <ismael@juma.me.uk>",2020-03-25 20:53:42,Gardner Vickers,Mixed
222726d6f97f624711e64487c8e48114aca7526e,"KAFKA-9373: Reduce shutdown time by avoiding unnecessary loading of indexes (#8346)

KAFKA-7283 enabled lazy mmap on index files by initializing indices
on-demand rather than performing costly disk/memory operations when
creating all indices on broker startup. This helped reducing the startup
time of brokers. However, segment indices are still created on closing
segments, regardless of whether they need to be closed or not.

This is a cleaned up version of #7900, which was submitted by @efeg. It
eliminates unnecessary disk accesses and memory map operations while
deleting, renaming or closing offset and time indexes.

In a cluster with 31 brokers, where each broker has 13K to 20K segments,
@efeg and team observed up to 2 orders of magnitude faster LogManager
shutdown times - i.e. dropping the LogManager shutdown time of each
broker from 10s of seconds to 100s of milliseconds.

To avoid confusion between `renameTo` and `setFile`, I replaced the
latter with the more restricted updateParentDir` (it turns out that's
all we need).

Reviewers: Jun Rao <junrao@gmail.com>, Andrew Choi <a24choi@edu.uwaterloo.ca>

Co-authored-by: Adem Efe Gencer <agencer@linkedin.com>
Co-authored-by: Ismael Juma <ismael@juma.me.uk>",2020-03-26 04:26:51,Ismael Juma,Mixed
0b230910662e36337a81b7300c04599e68e97c79,"MINOR: Don't process sasl.kerberos.principal.to.local.rules on client-side (#8362)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2020-03-26 15:30:51,Rajini Sivaram,Mixed
008a3b21f6c3670f4030da2280596155e57241b0,"KAFKA-9707: Fix InsertField.Key should apply to keys of tombstone records (#8280)

* KAFKA-9707: Fix InsertField.Key not applying to tombstone events

* Fix typo that hardcoded .value() instead of abstract operatingValue
* Add test for Key transform that was previously not tested

Signed-off-by: Greg Harris <gregh@confluent.io>

* Add null value assertion to tombstone test

* Remove mis-named function and add test for passing-through a null-keyed record.

Signed-off-by: Greg Harris <gregh@confluent.io>

* Simplify unchanged record assertion

Signed-off-by: Greg Harris <gregh@confluent.io>

* Replace assertEquals with assertSame

Signed-off-by: Greg Harris <gregh@confluent.io>

* Fix checkstyleTest indent issue

Signed-off-by: Greg Harris <gregh@confluent.io>",2020-03-26 10:21:11,Greg Harris,Mixed
9d9b59fccc1d3a71758dfb7dc6d2325d4fba9955,"KAFKA-9756: Process more than one record of one task at a time (#8358)

1. Within a single while loop, process the tasks in AAABBBCCC instead of ABCABCABC. This also helps the follow-up PR to time the per-task processing ratio to record less time, hence less overhead.

2. Add thread-level process / punctuate / poll / commit ratio metrics.

3. Fixed a few issues discovered (inline commented).

Reviewers: John Roesler <vvcephei@apache.org>",2020-03-26 22:54:08,Guozhang Wang,Mixed
c595470713be1fd2daf93816a5dbf0e245a707a0,"KAFKA-9770: Close underlying state store also when flush throws (#8368)

When a caching state store is closed it calls its flush() method.
If flush() throws an exception the underlying state store is not closed.

This commit ensures that state stores underlying a wrapped state stores
are closed even when preceding operations in the close method throw.

Co-authored-by: John Roesler <vvcephei@apache.org>
Reviewers: John Roesler <vvcephei@apache.org>, Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <matthias@confluent.io>",2020-03-27 20:36:10,Bruno Cadonna,Mixed
88bc0fdf822aeadb10f875aecb55322b11854f5a,"KAFKA-9600; EndTxn should enforce strict epoch checking if from client (#8164)

This PR enhances the epoch checking logic for endTransaction call in TransactionCoordinator. Previously it relaxes the checking by allowing a producer epoch bump, which is error-prone since there is no reason to see a producer epoch bump from client.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-03-28 10:55:13,Boyang Chen,Mixed
68ac551966e2be5b13adb2f703a01211e6f7a34b,"MINOR: Add missing @Override annotation and simplify Thread declarations with lambdas (#8363)

Add missing @Override annotations and use lambdas when declaring threads to suppress warnings in IDEs and improve readability. 

Reviewers: Ron Dagostino <rdagostino@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>",2020-03-28 16:38:12,17hao,Mixed
2c969b14d358f902ef7037395a4f8a0a2b79a611,"KAFKA-9706: Handle null in keys or values when Flatten transformation is used (#8279)

* Fixed DataException thrown when handling tombstone events with null value
* Passes through original record when finding a null key when it's configured for keys or a null value when it's configured for values. 
* Added unit tests for schema and schemaless data",2020-03-30 15:09:27,Greg Harris,Mixed
6ad540735037bcc668dd94c65d4203d0e2f63dba,"KAFKA-9719: Streams with EOS-beta should fail fast for older brokers (#8367)

Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2020-03-30 15:21:27,Matthias J. Sax,Mixed
75e8ee1d1add308095d11bcf6d7ea8c499d92fc9,"KAFKA-9777; Remove txn purgatory to fix race condition on txn completion (#8389)

This patch addresses a locking issue with DelayTxnMarker completion. Because of the reliance on the shared read lock in TransactionStateManager and the deadlock avoidance algorithm in `DelayedOperation`, we cannot guarantee that a call to checkAndComplete will offer an opportunity to complete the job. This patch removes the reliance on this lock in two ways:

1. We replace the transaction marker purgatory with a map of transaction with pending markers. We were not using purgatory expiration anyway, so this avoids the locking issue and simplifies usage.
2. We were also relying on the read lock for the `DelayedProduce` completion when calling `ReplicaManager.appendRecords`. As far as I can tell, this was not necessary. The lock order is always 1) state read/write lock, 2) txn metadata locks. Since we only call `appendRecords` while holding the read lock, a deadlock does not seem possible. 

Reviewers: Jun Rao <junrao@gmail.com>",2020-03-30 17:47:04,Jason Gustafson,Mixed
353aa6206d43b4923d21510797709bbbb210f6b6,"KAFKA-9753: Add active tasks process ratio (#8370)

Measure the percentage ratio the stream thread spent on processing each task among all assigned active tasks (KIP-444). Also add unit tests to cover the added metrics in this PR and the previous #8358. Also trying to fix the flaky test reported in KAFKA-5842

Co-authored-by: John Roesler <vvcephei@apache.org>

Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",2020-03-31 16:39:28,Guozhang Wang,Mixed
6a49ede9475a8bb50e85d10a5c1b60179f8a0888,"KAFKA-9441: Cleanup Streams metrics for removed task commit latency metrics (#8356)

Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Bruno Cadonna <bruno@confluent.io>",2020-03-31 20:07:18,Matthias J. Sax,Mixed
90bbeedf52f4b6a411e9630dd132583afa4cd428,"MINOR: Fix Scala 2.13 compiler warnings (#8390)

Once Scala 2.13.2 is officially released, I will submit a follow up PR
that enables `-Xfatal-warnings` with the necessary warning
exclusions. Compiler warning exclusions were only introduced in 2.13.2
and hence why we have to wait for that. I used a snapshot build to
test it in the meantime.

Changes:
* Remove Deprecated annotation from internal request classes
* Class.newInstance is deprecated in favor of
Class.getConstructor().newInstance
* Replace deprecated JavaConversions with CollectionConverters
* Remove unused kafka.cluster.Cluster
* Don't use Map and Set methods deprecated in 2.13:
    - collection.Map +, ++, -, --, mapValues, filterKeys, retain
    - collection.Set +, ++, -, --
* Add scala-collection-compat dependency to streams-scala and
update version to 2.1.4.
* Replace usages of deprecated Either.get and Either.right
* Replace usage of deprecated Integer(String) constructor
* `import scala.language.implicitConversions` is not needed in Scala 2.13
* Replace usage of deprecated `toIterator`, `Traversable`, `seq`,
`reverseMap`, `hasDefiniteSize`
* Replace usage of deprecated alterConfigs with incrementalAlterConfigs
where possible
* Fix implicit widening conversions from Long/Int to Double/Float
* Avoid implicit conversions to String
* Eliminate usage of deprecated procedure syntax
* Remove `println`in `LogValidatorTest` instead of fixing the compiler
warning since tests should not `println`.
* Eliminate implicit conversion from Array to Seq
* Remove unnecessary usage of 3 argument assertEquals
* Replace `toStream` with `iterator`
* Do not use deprecated SaslConfigs.DEFAULT_SASL_ENABLED_MECHANISMS
* Replace StringBuilder.newBuilder with new StringBuilder
* Rename AclBuffers to AclSeqs and remove usage of `filterKeys`
* More consistent usage of Set/Map in Controller classes: this also fixes
deprecated warnings with Scala 2.13
* Add spotBugs exclusion for inliner artifact in KafkaApis with Scala 2.12.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2020-04-01 06:20:48,Ismael Juma,Mixed
9eeffdfb7d47a2f25b9b08fc9a2d25b8d1589220,"KAFKA-9233: Fix IllegalStateException in Fetcher retrieval of beginning or end offsets for duplicate TopicPartition values (#7755)

Co-authored-by: Andrew Olson <aolson1@cerner.com>

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Guozhang Wang <wangguoz@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2020-04-01 17:45:45,Andrew Olson,Mixed
cc59150f408de6ffea277267ec7d2e3920fbe6b5,"KAFKA-9748: extend EosIntegrationTest for EOS-beta (#8331)

Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2020-04-01 13:20:27,Matthias J. Sax,Mixed
f0ad03069a70a9248a44782dddbc42fd0462bb3e,"MINOR: System test ZooKeeper upgrades (#8384)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2020-04-02 23:23:48,Ron Dagostino,Not TDD
2322bc0a6fdf8b26619b6aa9f09355d6c25e6298,"KAFKA-6145: Pt. 5 Implement high availability assignment (#8337)

Adds a new TaskAssignor implementation, currently hidden behind an internal feature flag, that implements the high availability algorithm of KIP-441.

Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",2020-04-02 13:36:03,A. Sophie Blee-Goldman,Mixed
dfdb49f26aff256ebe28ab55d11604619bfa66b1,"KAFKA-9778: Add methods to validate and assert connector configurations in integration tests with EmbeddedConnectCluster (#8359)

* Add validateConnector functionality to the EmbeddedConnectCluster
* PR Revision - added ConnectException conversion, validateConnectorConfig calls to ExampleConnectIntegrationTest
* PR revision - Added method to EmbeddedConnectClusterAssertions

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2020-04-02 16:52:56,Daniel,Not TDD
6ddbf4d800403de33e08273e92fb0e7159bd9f22,"KAFKA-9809: Shrink transaction timeout for streams (#8407)

As documented in the KIP:

We shall set `transaction.timout.ms` default to 10000 ms (10 seconds) on Kafka Streams. 

Reviewer: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-04-02 19:53:14,Boyang Chen,Mixed
7f640f13b4d486477035c3edb28466734f053beb,"KAFKA-9776: Downgrade TxnCommit API v3 when broker doesn't support (#8375)

Revert the decision for the sendOffsetsToTransaction(groupMetadata) API to fail with old version of brokers for the sake of making the application easier to adapt between versions. This PR silently downgrade the TxnOffsetCommit API when the build version is small than 3.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-04-02 21:48:37,Boyang Chen,Mixed
9783b85fdd947fe55fa80c724c8b4ae9a7eb63c3,"KAFKA-9739: Fixes null key changing child node (#8400)

For some context, when building a streams application, the optimizer keeps track of the key-changing operations and any repartition nodes that are descendants of the key-changer. During the optimization phase (if enabled), any repartition nodes are logically collapsed into one. The optimizer updates the graph by inserting the single repartition node between the key-changing node and its first child node. This graph update process is done by searching for a node that has the key-changing node as one of its direct parents, and the search starts from the repartition node, going up in the parent hierarchy.

The one exception to this rule is if there is a merge node that is a descendant of the key-changing node, then during the optimization phase, the map tracking key-changers to repartition nodes is updated to have the merge node as the key. Then the optimization process updates the graph to place the single repartition node between the merge node and its first child node.

The error in KAFKA-9739 occurred because there was an assumption that the repartition nodes are children of the merge node. But in the topology from KAFKA-9739, the repartition node was a parent of the merge node. So when attempting to find the first child of the merge node, nothing was found (obviously) resulting in StreamException(Found a null keyChangingChild node for..)

This PR fixes this bug by first checking that all repartition nodes for optimization are children of the merge node.

This PR includes a test with the topology from KAFKA-9739.

Reviewers: John Roesler <john@confluent.io>",2020-04-03 12:04:44,Bill Bejeck,Not TDD
9a154c6505954d521b597faeff2d5e61fd802fd7,"KAFKA-9775: Fix IllegalFormatConversionException in ToolsUtils

The runtime type of Metric.metricValue() needn't always be a Double,
for example, if it's a gauge from IntGaugeSuite.
Since it's impossible to format non-double values with 3 point precision
IllegalFormatConversionException resulted.

Author: Tom Bentley <tbentley@redhat.com>
Author: Tom Bentley <tombentley@users.noreply.github.com>

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Ismael Juma <ismael@juma.me.uk>

Closes #8373 from tombentley/KAFKA-9775-IllegalFormatConversionException",2020-04-03 22:34:44,Tom Bentley,Mixed
62dcfa196e7819f7fb77aa181d96767988cbe908,"KAFKA-9750; Fix race condition with log dir reassign completion (#8412)

There is a race on receiving a LeaderAndIsr request for a replica with an active log dir reassignment. If the reassignment completes just before the LeaderAndIsr handler updates epoch information, it can lead to an illegal state error since no future log dir exists. This patch fixes the problem by ensuring that the future log dir exists when the fetcher is started. Removal cannot happen concurrently because it requires access the same partition state lock.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Arthur <mumrah@gmail.com>

Co-authored-by: Chia-Ping Tsai <chia7712@gmail.com>",2020-04-03 11:51:04,Jason Gustafson,Mixed
6e0d553350cef876f4fd2de0e3b8e6e40ce6be44,"MINOR: clean up Streams assignment classes and tests (#8406)

First set of cleanup pushed to followup PR after KIP-441 Pt. 5. Main changes are:

1. Moved `RankedClient` and the static `buildClientRankingsByTask` to a new file
2. Moved `Movement` and the static `getMovements` to a new file (also renamed to `TaskMovement`)
3. Consolidated the many common variables throughout the assignment tests to the new `AssignmentTestUtils` 
4. New utility to generate comparable/predictable UUIDs for tests, and removed the generic from `TaskAssignor` and all related classes

Reviewers: John Roesler <vvcephei@apache.org>, Andrew Choi <a24choi@edu.uwaterloo.ca>",2020-04-03 13:53:51,A. Sophie Blee-Goldman,Mixed
d4eb406f01e02f42d433caaa4752c66c9c792076,"KAFKA-9807; Protect LSO reads from concurrent high-watermark updates (#8418)

If the high-watermark is updated in the middle of a read with the `read_committed` isolation level, it is possible to return data above the LSO. In the worst case, this can lead to the read of an aborted transaction. The root cause is that the logic depends on reading the high-watermark twice. We fix the problem by reading it once and caching the value.

Reviewers: David Arthur <mumrah@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2020-04-03 13:56:42,Jason Gustafson,Mixed
ab5e4f52ecb072df55c7f5cd8941122a135cdf79,"MINOR: Refactor StreamsProducer (#8380)

Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Andrew Choi <a24choi@edu.uwaterloo.ca>",2020-04-03 19:17:57,Matthias J. Sax,Mixed
712ac5203e6ce199bed8804f6173acf33d79a173,"KAFKA-9793: Expand the try-catch for task commit in HandleAssignment (#8402)

As title suggests, we would like to broaden this check so that we don't fail to close a doom-to-cleanup task.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-04-05 22:50:26,Boyang Chen,Mixed
82dff1db5486647b27e5297e4c839bd2a905c1d9,"KAFKA-9753: A few more metrics to add (#8371)

Instance-level:
* number of alive stream threads

Thread-level:
* avg / max number of records polled from the consumer per runOnce, INFO
* avg / max number of records processed by the task manager (i.e. across all tasks) per runOnce, INFO

Task-level:
* number of current buffered records at the moment (i.e. it is just a dynamic gauge), DEBUG.

Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <john@confluent.io>",2020-04-06 15:30:29,Guozhang Wang,Mixed
588e8a5be83037225716a78358d0203a9e070168,"KAFKA-9815; Ensure consumer always re-joins if JoinGroup fails (#8420)

On metadata change for assigned topics, we trigger rebalance, revoke partitions and send JoinGroup. If metadata reverts to the original value and JoinGroup fails, we don't resend JoinGroup because we don't set `rejoinNeeded`. This PR sets `rejoinNeeded=true` when rebalance is triggered due to metadata change to ensure that we retry on failure.

Reviewers: Boyang Chen <boyang@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",2020-04-06 17:00:11,Rajini Sivaram,Mixed
f1850162de9174faab68c6674548dc40fb6a352f,"MINOR: Should cleanup the tasks after dirty close (#8433)

Some tasks get closed inside HandleAssignment and did not remove from the task manager bookkeep list. The next time they would be re-closed which is illegal state.

Reviewers: John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-04-06 20:44:14,Boyang Chen,Mixed
cd1e46c8bb46f1e5303c51f476c74e33b522fce8,"MINOR: Pass one action per unique resource name in KafkaApis.filterAuthorized (#8432)

90bbeedf52f introduced a regression resulting in passing an action per resource
name to the `Authorizer` instead of passing one per unique resource name. Refactor
the signatures of both `filterAuthorized` and `authorize` to make them easier to test
and add a test for each.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2020-04-07 06:26:18,David Jacot,Mixed
29e08fd2c2d3349ba5cbd8fe5a9d35a0cea02b85,"KAFKA-8410: Part 1: processor context bounds (#8414)

Add type bounds to the ProcessorContext, which bounds the types that can be forwarded to child nodes.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2020-04-07 13:11:02,John Roesler,Mixed
94ef25ab9128030de8692b6e690787ec8012830a,"KAFKA-9801: Still trigger rebalance when static member joins in CompletingRebalance phase (#8405)

Fix the direct cause of the observed issue on the client side: when heartbeat getting errors and resetting generation, we only need to set it to UNJOINED when it was not already in REBALANCING; otherwise, the join-group handler would throw the retriable UnjoinedGroupException to force the consumer to re-send join group unnecessarily.

Fix the root cause of the issue on the broker side: we should still trigger rebalance when static member joins in CompletingRebalance phase; otherwise the member.ids would be changed when the assignment is received from the leader, hence causing the new member.id's assignment to be empty.

Reviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>",2020-04-07 20:46:46,Guozhang Wang,Mixed
9ba49b806ad0dcdb72a3a80393175a143f181382,KAFKA-8890: Make SSL context/engine configuration extensible (KIP-519) (#8338),2020-04-08 15:20:32,maulin-vasavada,Mixed
98ea773a22f84eb21c318fa1da78d2e6b323e8de,"KAFKA-6145: KIP-441 Pt. 6 Trigger probing rebalances until group is stable (#8409)

Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",2020-04-08 13:02:30,A. Sophie Blee-Goldman,Mixed
778b1e3f5435c5b98fb52a4e15fc32d5cfa2c92c,"KAFKA-9835; Protect `FileRecords.slice` from concurrent write (#8451)

A read from the end of the log interleaved with a concurrent write can result in reading data above the expected read limit. In particular, this would allow a read above the high watermark. The root of the problem is consecutive calls to `sizeInBytes` in `FileRecords.slice` which do not account for an increase in size due to a concurrent write. This patch fixes the problem by using a single call to `sizeInBytes` and caching the result.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2020-04-08 11:31:27,Jason Gustafson,Mixed
ed3a7157e0d1ecfddf5a0cd9d839635cc78f3e60,"KAFKA-6145: KIP-441 Move tasks with caught-up destination clients right away (#8425)

Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",2020-04-08 20:08:40,A. Sophie Blee-Goldman,Mixed
c84e6ab491f5344554333c6ce021a4564e9dc64b,"KAFKA-9433: Use automated protocol for AlterConfigs request and response (#8315)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Boyang Chen <boyang@confluent.io>",2020-04-09 14:59:25,Tom Bentley,Not TDD
bf6dffe93bbe0fe33ad076ebccebb840d66b936d,"KAFKA-9309: Add the ability to translate Message classes to and from JSON (#7844)

Reviewers: David Arthur <mumrah@gmail.com>, Ron Dagostino <rdagostino@confluent.io>",2020-04-09 13:11:36,Colin Patrick McCabe,Mixed
e131a9963484e46f45a7302267507ed54dab6871,"KAFKA-8611: Add KStream#repartition operation (#7170)

Implements KIP-221.

Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",2020-04-09 16:52:41,Levani Kokhreidze,Mixed
ea1e634664197c89a0e98e4f5717933ef8499109,"KAFKA-6145: KIP-441: avoid unnecessary movement of standbys (#8436)

Reviewers: John Roesler <vvcephei@apache.org>",2020-04-10 13:42:54,A. Sophie Blee-Goldman,Mixed
20e4a74c3579837df7b46ce1a5dcea37b6e1e452,"KAFKA-9832: Extend Streams system tests for EOS-beta (#8443)

Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2020-04-10 11:55:01,Matthias J. Sax,Mixed
a276c546375994300dcd4d257993cd4c75ec4e3b,"MINOR: Allow a single struct to be a field in the protocol spec (#8413)

Remove the restriction in the protocol generation code that a structure
field needs to be part of an array.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2020-04-10 13:15:05,Vikas Singh,Mixed
e032a360708cec2284f714e4cae388066064d61c,"KAFKA-3720: Change TimeoutException to BufferExhaustedException when no memory can be allocated for a record within max.block.ms (#8399)

Change TimeoutException to BufferExhaustedException when no memory can be allocated for a record within max.block.ms

Refactored BufferExhaustedException to be a subclass of TimeoutException so existing code that catches TimeoutExceptions keeps working.

Added handling to count these Exceptions in the metric ""buffer-exhausted-records"".

Test Strategy
There were existing test cases to check this behavior, which I refactored.
I then added an extra case to check whether the expected Exception is actually thrown, which was not covered by current tests.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",2020-04-10 16:48:29,Sönke Liebau,Mixed
430e00ea95da959d6d8308dd49c4ed1cdffa7914,"KAFKA-8436: use automated protocol for AddOffsetsToTxn  (#7015)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2020-04-11 12:54:53,Boyang Chen,Mixed
37f20c6924bc2b2d861508cdb79b78152cc01b60,"HOTFIX: need to cleanup any tasks closed in TaskManager (#8463)

We were hitting an IllegalStateException: There is already a changelog registered for ... in trunk-eos due to failing to call TaskManager#cleanup on unrevoekd tasks that we end up closing in handleAssignment after failing to batch commit.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-04-13 15:01:19,A. Sophie Blee-Goldman,Mixed
799183b3f8d5e8d4c955e7d3ce654b97f8309aad,"KAFKA-9842; Add test case for OffsetsForLeaderEpoch grouping in Fetcher (#8457)

This is a follow-up to #8077. The bug exposed a testing gap in how we group partitions. This patch adds a test case which reproduces the reported problem.

Reviewers: David Arthur <mumrah@gmail.com>",2020-04-13 17:20:01,Jason Gustafson,Mixed
ea47a885b1fe47dfb87c1dc86db1b0e7eb8a273c,"MINOR: remove stream simple benchmark suite (#8353)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2020-04-14 09:49:03,Boyang Chen,Not TDD
7c7d55dbd8d42f6378d13ba02d62633366a7ede8,"KAFKA-9539; Add leader epoch in StopReplicaRequest (KIP-570) (#8257)

This PR adds the leader epoch field to `StopReplicaRequest` as documented in KIP-570. 

Reviewers: Jason Gustafson <jason@confluent.io>",2020-04-14 11:39:56,David Jacot,Mixed
b8c292c36187d3feda8ae0ce22d58604115b8507,"[KAFKA-9826] Handle an unaligned first dirty offset during log cleaning. (#8469)

In KAFKA-9826, a log whose first dirty offset was past the start of the active segment and past the last cleaned point resulted in an endless cycle of picking the segment to clean and discarding it. Though this didn't interfere with cleaning other log segments, it kept the log cleaner thread continuously busy (potentially wasting CPU and impacting other running threads) and filled the logs with lots of extraneous messages.

This was determined to be because the active segment was getting mistakenly picked for cleaning, and because the logSegments code handles (start == end) cases only for (start, end) on a segment boundary: the intent is to return a null list, but if they're not on a segment boundary, the routine returns that segment.

This fix has two parts:

It changes logSegments to handle start==end by returning an empty List always.

It changes the definition of calculateCleanableBytes to not consider anything past the UncleanableOffset; previously, it would potentially shift the UncleanableOffset to match the firstDirtyOffset even if the firstDirtyOffset was past the firstUncleanableOffset. This has no real effect now in the context of the fix for (1) but it makes the code read more like the model that the code is attempting to follow.

These changes require modifications to a few test cases that handled this particular test case; they were introduced in the context of KAFKA-8764. Those situations are now handled elsewhere in code, but the tests themselves allowed a DirtyOffset in the active segment, and expected an active segment to be selected for cleaning.

Reviewer: Jun Rao <junrao@gmail.com>",2020-04-14 22:27:50,Steve Rodrigues,Mixed
7da13024b4b42c7fe1e82792a5d85c77d4e93037,"MINOR: avoid autoboxing in FetchRequest.PartitionData.equals

FetchRequest.PartitionData.equals unnecessarily uses Object.equals generating a lot of allocations due to boxing, even though primitives are being compared. This is shown in the allocation profile below. Note that the CPU overhead is negligble.
￼
![image](https://user-images.githubusercontent.com/252189/79079019-46686300-7cc1-11ea-9bc9-44fd17bae888.png)

Author: Lucas Bradstreet <lucasbradstreet@gmail.com>

Reviewers: Chia-Ping Tsai, Gwen Shapira

Closes #8473 from lbradstreet/avoid-boxing-partition-data-equals",2020-04-15 08:31:09,Lucas Bradstreet,Mixed
4ac2ad3a2bea9db1e4835a9dffc4b029dc1d9fcd,"MINOR: Eliminate unnecessary partition lookups (#8484)

There are two cases in the fetch pass where a partition is unnecessarily looked up
from the partition Pool, when one is already accessible. This will be a fairly minor
improvement on high partition count clusters, but could be worth 1% from some
profiles I have seen.

More importantly, the code is cleaner this way.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2020-04-15 09:24:30,Lucas Bradstreet,Mixed
17f98792617a6de39cbd0d651a03fc40a06e0ff6,"KAFKA-9832: extend Kafka Streams EOS system test (#8440)

Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2020-04-15 13:13:23,Matthias J. Sax,Mixed
640be46ef5555d6e957589ab8cb67cc31fb5a4b9,"HOTFIX: don't close or wipe out someone else's state (#8478)

When it comes to actually closing a task we now treat all states exactly the same, and call StateManagerUtil#closeStateManager regardless of whether it's in CREATED or RESTORING or RUNNING

Unfortunately StateManagerUtil doesn't actually check to make sure that we actually own the lock for this task's state. During a dirty close with eos enabled, we wipe the state -- but in some cases, this means deleting the state out from under another StreamThread who is still in the process of revoking this task.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-04-15 14:17:47,A. Sophie Blee-Goldman,Mixed
f646c9c0bc1ed7d2c57dc72a9a290f29b1e6757c,"MINOR: KafkaApis#handleOffsetDeleteRequest does not group result correctly (#8485)

`KafkaApis#handleOffsetDeleteRequest` does not build the response correctly because `topics.add` is not in the correct loop. Fortunately, due to how the response is processed by the admin client, it works but sends redundant information on the wire.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",2020-04-15 14:23:15,David Jacot,Mixed
f7d2b1baf7745b0f505edd186e1731cc5c9f382c,"KAFKA-7885: TopologyDescription violates equals-hashCode contract. (#6210)

Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>",2020-04-15 15:50:39,Piotr Fras,Not TDD
df41713d64b4c71e95f7153edc879d7eb213b1d5,"KAFKA-9779: Add Stream system test for 2.5 release (#8378)

Reviewer: Matthias J. Sax <matthias@confluent.io>",2020-04-15 15:59:03,Boyang Chen,Not TDD
413c4b55b56838cf5ec8d0e0fa758a955f84404e,"KAFKA-9838; Add log concurrency test and fix minor race condition (#8476)

The patch adds a new test case for validating concurrent read/write behavior in the `Log` implementation. In the process of verifying this, we found a race condition in `read`. The previous logic checks whether the start offset is equal to the end offset before collecting the high watermark. It is possible that the log is truncated in between these two conditions which could cause the high watermark to be equal to the log end offset. When this happens, `LogSegment.read` fails because it is unable to find the starting position to read from.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-04-15 17:18:30,Jason Gustafson,Not TDD
93123720fcd34d61a80c5a255808cd103b35f337,"KAFKA-9854 Re-authenticating causes mismatched parse of response (#8471)

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ron Dagostino <rdagostino@confluent.io>",2020-04-16 13:26:30,Chia-Ping Tsai,Mixed
9a36d9f913e3474a3c4c83e91699759c5fa848a2,"KAFKA-9796; Ensure broker shutdown is not stuck when Acceptor is waiting on connection queue (#8448)

This commit reworks the SocketServer to always start the acceptor threads after the processor threads and to always stop the acceptor threads before the processor threads. It ensures that the acceptor shutdown is not blocked waiting on the processors to be fully shutdown by decoupling the shutdown signal and the awaiting. It also ensure that the processor threads drain its newConnection queue to unblock acceptors that may be waiting. However, the acceptors still bind during the startup, only the processing of new connections and requests is further delayed.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2020-04-16 17:14:02,David Jacot,Mixed
770b095e917b8976b9ba67de3aad052ea5cd2606,"KAFKA-9819: Fix flaky test in StoreChangelogReaderTest (#8488)

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>, John Roesler <john@confluent.io>",2020-04-17 07:49:50,Matthias J. Sax,Not TDD
a0173ec45d83a38512c724b801d8c176c1f510db,"KAFKA-9881: Convert integration test to verify measurements from RocksDB to unit test (#8501)

The integration test RocksDBMetricsIntegrationTest takes pretty long to complete.
Most of the runtime is spent in the two tests that verify whether the RocksDB
metrics get actual measurements from RocksDB. Those tests need to wait for the thread
that collects the measurements of the RocksDB metrics to trigger the first recordings
of the metrics.

This PR adds a unit test that verifies whether the Kafka Streams metrics get the
measurements from RocksDB and removes the two integration tests that verified it
before. The verification of the creation and scheduling of the RocksDB metrics
recording trigger thread is already contained in KafkaStreamsTest and consequently
it is not part of this PR.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-04-17 10:49:40,Bruno Cadonna,Mixed
0f8dc1fcd720fbb7eb6152ef40ecaafdd6b04e15,"KAFKA-6145: KIP-441: Add test scenarios to ensure rebalance convergence (#8475)

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>",2020-04-17 16:03:39,John Roesler,Not TDD
065415e5244b7ca3a01c3840a55be8b41222c1a5,"MINOR: Upgrade gradle plugins and test libraries for Java 14 support (#8519)

Also:
* Remove deprecated `=` in resolutionStrategy.
* Replace `AES/GCM/PKCS5Padding` with `AES/GCM/NoPadding`
in `PasswordEncoderTest`. The former is invalid and JDK 14 rejects it,
see https://bugs.openjdk.java.net/browse/JDK-8229043.

With these changes, the build works with Java 14 and Scala 2.12. The
same will apply to Scala 2.13 when Scala 2.13.2 is released (should
happen within 1-2 weeks).

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Matthias J. Sax <matthias@confluent.io>",2020-04-20 13:55:20,Ismael Juma,Not TDD
11d8ef76ff5348a48eb1c37cddf244e399666d59,"MINOR: Improve usage of LogCaptureAppender (#8508)

Reviewers: Ismael Juma <ismael@confluent.io>, John Roesler <john@confluent.io>",2020-04-21 09:25:45,Matthias J. Sax,Mixed
5c548e5dfc223371f3109de14eddf0918b8dcad2,"KAFKA-6145: KIP-441: Build state constrained assignment from balanced one (#8497)

Implements: KIP-441
Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",2020-04-21 17:09:59,A. Sophie Blee-Goldman,Mixed
fbd8cf0d861dec5b7bac237e8221cfae51bec14a,"KAFKA-9388: Refactor integration tests to always use different application ids (#8530)

When debugging KAFKA-9388, I found the reason that the second test method test takes much longer (10s) than the previous one (~500ms) is because they used the same app.id. When the previous clients are shutdown, they would not send leave-group and hence we are still depending on the session timeout (10s) for the members to be removed out of the group.

When the second test is triggered, they will join the same group because of the same application id, and the prepare-rebalance phase would would for the full rebalance timeout before it kicks out the previous members.

Setting different application ids could resolve such issues for integration tests --- I did a quick search and found some other integration tests have the same issue. And after this PR my local unit test runtime reduced from about 14min to 7min.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, John Roesler <john@confluent.io>",2020-04-22 14:29:23,Guozhang Wang,Not TDD
c5ae154a3fdcf20d388405361da37feed0c64ad9,"MINOR: Enable fatal warnings with scala 2.13 (#8429)

* Upgrade to Scala 2.13.2 which introduces the ability to suppress warnings.
* Upgrade to scala-collection-compat 2.1.6 as it introduces the
@nowarn annotation for Scala 2.12.
* While at it, also update scala-java8-compat to 0.9.1.
* Fix compiler warnings and add @nowarn for the unfixed ones.

Scala 2.13.2 highlights (besides @nowarn):

* Rewrite Vector (using ""radix-balanced finger tree vectors""),
for performance. Small vectors are now more compactly
represented. Some operations are now drastically faster on
large vectors. A few operations may be a little slower.
* Matching strings makes switches in bytecode.

https://github.com/scala/scala/releases/tag/v2.13.2

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2020-04-23 00:44:03,Ismael Juma,Mixed
2ecdca2814e232e038909c562fbfd667935ab69e,"KAFKA-9883: Add better error message when REST API forwards a request and leader is not known (#8536)

When the Connect worker forwards a REST API request to the leader, it might get back a `RequestTargetException` that suggests the worker should forward the request to a different worker. This can happen when the leader changes, and the worker that receives the original request forwards the request to the worker that it thinks is the current leader, but that worker is not the current leader. In this case. In most cases, the worker that received the forwarded request includes the URL of the current leader, but it is possible (albeit rare) that the worker doesn’t know the current leader and will include a null leader URL in the resulting `RequestTargetException`.

When this rare case happens, the user gets a null pointer exception in their response and the NPE is logged. Instead, the worker should catch this condition and provide a more useful error message that is similar to other existing error messages that might occur.

Added a unit test that verifies this corner case is caught and this particular NPE does not occur.

Author: Randall Hauch <rhauch@gmail.com>
Reviewer: Konstantine Karantasis <konstantine@confluent.io>",2020-04-23 13:37:45,Randall Hauch,Mixed
5c0fd36ee53052fa8a92dac1266fee3aaf16d7a1,"KAFKA-9823: Remember the sent generation for the coordinator request (#8445)

For join / sync / commit / heartbeat request, we would remember the sent generation in the created handler object, and then upon getting the error code, we could check whether the sent generation still matches the current generation. If not, it means that the member has already reset its generation or has participated in a new rebalance already. This means:

1. For join / sync-group request, we do not need to call reset-generation any more for illegal-generation / unknown-member. But we would still set the error since at a given time only one join/sync round-trip would be in flight, and hence we should not be participating in a new rebalance. Also for fenced instance error we still treat it as fatal since we should not be participating in a new rebalance, so this is still not expected.

2. For commit request, we do not set the corresponding error for illegal-generation / unknown-member / fenced-instance but raise rebalance-in-progress. For commit-sync it would be still thrown to user, while for commit-async it would be logged and swallowed.

3. For heartbeat request, we do not treat illegal-generation / unknown-member / fenced-instance errors and just consider it as succeeded since this should be a stale heartbeat which can be ignored.

Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>",2020-04-23 12:25:02,Guozhang Wang,Mixed
85e81d48c81a11f8e32a734703c2103c655a4cc9,"KAFKA-9844; Fix race condition which allows more than maximum number of members(#8454)

This patch fixes a race condition in the join group request handling which sometimes results in not enforcing the maximum number of members allowed in a group. 

Reviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>",2020-04-23 13:37:19,David Jacot,Not TDD
1d55127d976c1c3db119fc13ce88128f13522713,"MINOR: equals() should compare all fields for generated classes (#8539)

Reviewers: Jason Gustafson <jason@confluent.io>",2020-04-23 21:11:42,Colin Patrick McCabe,Mixed
f3c8bff311b0e4c4d0e316ac949fe4491f9b107f,"KAFKA-8639: Replace AddPartitionsToTxn with Automated Protocol  (#8326)

Part of the protocol automation effort.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-04-23 21:39:11,Boyang Chen,Mixed
d63eaaaa0181bb7b9b4f5ed088abc00d7b32aeb0,"MINOR: Partition is under reassignment when adding and removing (#8364)

A partition is under reassignment if the either the set of adding
replicas or set removing replicas is non-empty.

Fix the test assertion such that it prints stdout on failure.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2020-04-25 19:31:41,José Armando García Sancio,Mixed
2ca19cf603d457b0ec25e5e0f4769560b4c52d6d,"KAKFA-9612: Add an option to kafka-configs.sh to add configs from a prop file (KIP-574)

Add an option to kafka-configs.sh `--add-config-file` that adds the configs from a properties file.
Testing: Added new tests to ConfigCommandTest.scala

Author: Aneel Nazareth <aneel@confluent.io>

Reviewers: David Jacot <djacot@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #8184 from WanderingStar/KAFKA-9612",2020-04-27 23:40:34,Aneel Nazareth,Mixed
bd17085ec10c767bc82e6b19a3016cf5d50dad92,"KAFKA-9839; Broker should accept control requests with newer broker epoch (#8509)

A broker throws IllegalStateException if the broker epoch in the LeaderAndIsr/UpdateMetadataRequest/StopReplicaRequest is larger than its current broker epoch. However, there is no guarantee that the broker would receive the latest broker epoch before the controller: when the broker registers with ZK, there are few more instructions to process before this broker ""knows"" about its epoch, while the controller may already get notified and send UPDATE_METADATA request (as an example) with the new epoch. This will result in clients getting stale metadata from this broker. 

With this PR, a broker accepts LeaderAndIsr/UpdateMetadataRequest/StopReplicaRequest if the broker epoch is newer than the current epoch.

Reviewers: David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>",2020-04-27 12:41:30,Anna Povzner,Mixed
db9e55a50f93d82e4aad5e4f82a13fac0e93759e,"KAFKA-9866: Avoid election for topics where preferred leader is not in ISR (#8524)

In this commit we made sure that the auto leader election only happens after the newly starter broker is in the isr.

No accompany tests are added due to the fact that:

this is a change to the private method and no public facing change is made
it is hard to create tests for this change without considerable effort

Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jun Rao <junrao@gmail.com>",2020-04-27 13:51:10,Leonard Ge,Not TDD
c5d13dcb6ca2a7564cb5b707941b7c68d3de9289,"KAFKA-9885; Evict last members of a group when the maximum allowed is reached (#8525)

This PR updates the algorithm which limits the number of members within a group (`group.max.size`) to fix the following two issues:
1. As described in KAFKA-9885, we found out that multiple members of a group can be evicted if the leader of the consumer offset partition changes before the group is persisted. This happens because the current eviction logic always evict the first member rejoining the group.
2. We also found out that dynamic members, when required to have a known member id, are not always limited. The caveat is that the current logic only considers unknown members and uses the group size, which does not include the so called pending members, to accept or reject a member. In this case, when they rejoins, they are not unknown member anymore and thus could bypass the limit. See `testDynamicMembersJoinGroupWithMaxSizeAndRequiredKnownMember` for the whole scenario.

This PR changes the logic to address the above two issues and extends the tests coverage to cover all the member types.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-04-27 14:43:29,David Jacot,Mixed
6a5946282cbc6b24b185a1a1297110198fd9e97c,"KAFKA-9921: disable caching on stores configured to retain duplicates (#8564)

These two options are essentially incompatible, as caching will do nothing to reduce downstream traffic and writes when it has to allow non-unique keys (skipping records where the value is also the same is a separate issue, see KIP-557). But enabling caching on a store that's configured to retain duplicates is actually more than just ineffective, and currently causes incorrect results.

We should just log a warning and disable caching whenever a store is retaining duplicates to avoid introducing a regression. Maybe when 3.0 comes around we should consider throwing an exception instead to alert the user more aggressively.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, John Roesler <john@confluent.io>",2020-04-28 11:33:41,A. Sophie Blee-Goldman,Mixed
5bb3415c77cc61b7d1591ccfe028d10bbf9f2a7a,"KAFKA-6145: KIP-441: Add TaskAssignor class config (#8541)

* add a config to set the TaskAssignor
* set the default assignor to HighAvailabilityTaskAssignor
* fix broken tests (with some TODOs in the system tests)

Implements: KIP-441
Reviewers: Bruno Cadonna <bruno@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",2020-04-28 15:57:11,John Roesler,Mixed
f7edf46a5e5c30310542c00eb2d771bd72f42fd3,"KAFKA-9823: Follow-up, check state for handling commit error response (#8548)

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <john@confluent.io>",2020-04-28 14:44:11,Guozhang Wang,Mixed
b5de44937768304ba17351e7e742f4258533a150,"KAFKA-9127: don't create StreamThreads for global-only topology (#8540)

Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <vvcephei@apache.org>",2020-04-28 22:34:17,A. Sophie Blee-Goldman,Mixed
7907b5a6e921cec3b5fad2a4f84a78a851140755,"KAFKA-9832: fix attempt to commit non-running tasks (#8580)

KAFKA-9832: fix attempt to commit non-running tasks

Reviewers: Matthias J. Sax <matthias@confluent.io>",2020-04-29 09:24:23,John Roesler,Mixed
688f2e9c0f1b7a493d16da41d96dc7cd17195502,"KAFKA-9925: decorate pseudo-topics with app id (#8574)

Reviewers: Boyang Chen <boyang@confluent.io>, Kin Siu",2020-04-29 16:17:34,John Roesler,Mixed
7edbff33946328fafe1fe1138308fc62e3d66ff9,"KAFKA-9932: Don't load configs from ZK when the log has already been loaded (#8582)

If a broker contains 8k replicas, we would previously issue 8k ZK calls to retrieve topic
configs when processing the first LeaderAndIsr request. That should translate to 0 after
these changes.

Credit to @junrao for identifying the problem.

Reviewers: Jun Rao <junrao@gmail.com>",2020-04-29 14:33:10,Ismael Juma,Mixed
0ee19e87d2b1e5e94323ca8bcac5089bf4b3f1af,"KAFKA-9830: Implement AutoCloseable in ErrorReporter and subclasses (#8442)

* The DeadLetterQueueReporter has a KafkaProducer that it must close to clean up resources
* Currently, the producer and its threads are leaked every time a task is stopped
* Responsibility for cleaning up ErrorReporters is transitively assigned to the
    ProcessingContext, RetryWithToleranceOperator, and WorkerSinkTask/WorkerSinkTask classes
* One new unit test in ErrorReporterTest asserts that the producer is closed by the dlq reporter

Reviewers: Arjun Satish <arjun@confluent.io>, Chris Egerton <chrise@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>",2020-04-29 17:07:01,Greg Harris,Mixed
322b10964ce71eac81da9e574be7dec59c0fc93d,"KAFKA-9652: Fix throttle metric in RequestChannel and request log due to KIP-219 (#8567)

After KIP-219, responses are sent immediately and we rely on a combination
of clients and muting of the channel to throttle. The result of this is that
we need to track `apiThrottleTimeMs` as an explicit value instead of
inferring it. On the other hand,  we no longer need
`apiRemoteCompleteTimeNanos`.

Extend `BaseQuotaTest` to verify that throttle time in the request channel
metrics are being set. Given the nature of the throttling numbers, the test
is not particularly precise.

I included a few clean-ups:
* Pass KafkaMetric to QuotaViolationException so that the caller doesn't
have to retrieve it from the metrics registry.
* Inline Supplier in SocketServer (use SAM).
* Reduce redundant `time.milliseconds` and `time.nanoseconds`calls.
* Use monotonic clock in ThrottledChannel and simplify `compareTo` method.
* Simplify `TimerTaskList.compareTo`.
* Consolidate the number of places where we update `apiLocalCompleteTimeNanos`
and `responseCompleteTimeNanos`.
* Added `toString` to ByteBufferSend` and `MultiRecordsSend`.
* Restrict access to methods in `QuotaTestClients` to expose only what we need
to.

Reviewers: Jun Rao <junrao@gmail.com>",2020-04-29 20:09:17,Ismael Juma,Mixed
f92cc85c9f018f353da69a24d950bc281f721781,"KAFKA-9633: Ensure ConfigProviders are closed (#8204)

ConfigProvider extends Closeable, but were not closed in the following contexts:
* AbstractConfig
* WorkerConfigTransformer
* Worker

This commit ensures that ConfigProviders are close in the above contexts. 

It also adds MockFileConfigProvider.assertClosed()
Gradle executes test classes concurrently, so MockFileConfigProvider
can't simply use a static field to hold its closure state.
Instead use a protocol whereby the MockFileConfigProvider is configured
with some unique ket identifying the test which also used when calling
assertClosed().

Reviewers: Konstantine Karantasis <konstantine@confluent.io>",2020-04-30 10:33:10,Tom Bentley,Mixed
e5217d6cb5eaebaf13bd4e1f98c21ad174d8afb3,"KAFKA-6145: Remove check to reuse previous assignment (#8590)

Since we cannot guarantee to reassign the correct number of
stand-by tasks when reusing the previous assignment and the
reassignment is rather a micro-optimization, it is removed
to keep the algorithm correct and simple.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <vvcephei@apache.org>",2020-04-30 21:15:00,Bruno Cadonna,Mixed
95edaba8615d4ca2d623722eee38eb78fc24d317,"KAFKA-6145: KIP 441 remove balance factor (#8597)

Reviewers: John Roesler <vvcephei@apache.org>",2020-05-01 09:59:08,A. Sophie Blee-Goldman,Mixed
fd095aaafdd207162cddf293b17f249875b9a532,"KAFKA-8410: Revert Part 1: processor context bounds (#8414) (#8595)

This reverts commit 29e08fd2c2d3349ba5cbd8fe5a9d35a0cea02b85.
There turned out to be more than expected problems with adding the generic parameters.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2020-05-01 14:26:36,John Roesler,Mixed
794648aa554b5566268ff3eb650b14610a34091c,"KAFKA-9939; Fix overcounting delayed fetches in request rate metrics (#8586)

Fetches which hit purgatory are currently counted twice in fetch request rate metrics. This patch moves the metric update into `fetchMessages` so that they are only counted once. 

Reviewers: Ismael Juma <ismael@juma.me.uk>",2020-05-01 15:29:49,Jason Gustafson,Mixed
945356724147549421727eb52a4ac33efa920b2e,"MINOR: Improve Sensor recording efficiency (#8593)

1. Added a recordInternal function to let all other public functions trigger, so that shouldRecord would only be checked once.

2. In Streams, pass along the current wall-clock time inside InternalProcessorContext when process / punctuate which can be passed in to the record function to reduce the calling frequency of SystemTime.milliseconds().

Reviewers: John Roesler <vvcephei@apache.org>",2020-05-01 17:11:26,Guozhang Wang,Mixed
b2a5633a2c7e5d6de45a46d406f08a968916ab7f,"KAFKA-9918; SslEngineFactory is NOT closed when channel is closing (#8551)

This patch ensures that `SslEngineFactory` is closed. The default implementation (**DefaultSslEngineFactory**) does not have any releasable object so we didn't notice this issue. However, it would be better to fix this issue for custom engine factories.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-05-04 10:25:49,Chia-Ping Tsai,Mixed
7cb1600d6ae7245bfa717fa93502d28f17096ea8,"MINOR: Clean up some test dependencies on ConfigCommand and TopicCommand (#8527)

Avoid calling into ConfigCommand and TopicCommand from tests that are not related
to these commands.  It's better to just invoke the admin APIs.

Change a few cases where we were testing the deprecated --zookeeper flag to testing
the --bootstrap-server flag instead.  Unless we're explicitly testing the deprecated code
path, we should be using the non-deprecated flags.

Move testCreateWithUnspecifiedReplicationFactorAndPartitionsWithZkClient from
TopicCommandWithAdminClientTest.scala into TopicCommandWithZKClientTest.scala,
since it makes more sense in the latter.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2020-05-04 14:34:23,THREE LEVEL HELMET,Not TDD
fbfda2c4ad889c731aa52b5214e0521f187f8db6,"KAFKA-9731: Disable immediate fetch response for hw propagation if replica selector is not defined (#8607)

In the case described in the JIRA, there was a 50%+ increase in the total fetch request rate in
2.4.0 due to this change.

I included a few additional clean-ups:
* Simplify `findPreferredReadReplica` and avoid unnecessary collection copies.
* Use `LongSupplier` instead of `Supplier<Long>` in `SubscriptionState` to avoid unnecessary boxing.

Added a unit test to ReplicaManagerTest and cleaned up the test class a bit including
consistent usage of Time in MockTimer and other components.

Reviewers: Gwen Shapira <gwen@confluent.io>, David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",2020-05-04 21:38:53,Ismael Juma,Mixed
1daa8f638bfc8034d8499525d569660a050194f8,"KAFKA-9748: Add Streams eos-beta integration test (#8496)

Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2020-05-04 22:45:54,Matthias J. Sax,Mixed
3b6bf8053097200349ecb143148255e02efd1431,"KAFKA-9946; Partition deletion event should only be sent if deletion was requested in the StopReplica request (#8609)

This patch fixes a regression in the `StopReplica` response handling. We should only send the event on receiving the `StopReplica` response if we had requested deletion in the request.

Reviewers: Lucas Bradstreet <lucas@confluent.io>, Jason Gustafson <jason@confluent.io>",2020-05-05 18:38:09,David Jacot,Mixed
d70dacb54ad894d188e6ed97e0ce61d10110db20,"KAFKA-6342; Remove unused workaround for JSON parsing of non-escaped strings (#8591)

Previously we had fallback logic when parsing ACLs to handle older entries which may contain non-escaped characters. This code became dead after 1.1 since it was no longer used in the parsing of ACLs. This patch removes the fallback logic.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2020-05-06 12:39:34,Viktor Somogyi,Mixed
074ab2ebf6856628219d4c4ee95d57ff69d29bf3,"KAFKA-9419: Fix possible integer overflow in CircularIterator (#7950)

The CircularIterator class uses a wrapping index-based approach to iterate over a list. This can be a performance problem O(n^2) for a LinkedList. Also, the index counter itself is never reset, a modulo is applied to it for every list access. At some point, it may be possible that the index counter overflows to a negative value and therefore may cause a negative index read and an ArrayIndexOutOfBoundsException.

This fix changes the implementation to avoid these two scenarios. Uses the Collection Iterator classes to avoid using an index counter and it avoids having to seek to the correct index every time, this avoiding the LinkedList performance issue.

I have added unit tests to validate the new implementation.

* KAFKA-9419: Integer Overflow Possible with CircularIterator
* Added JavaDoc. Support null values in the underlying collection
* Always return true for hasNext(). Add more JavaDoc
* Use an advance method to load next value and always return true in hasNext()
* Simplify test suite
* Use assertThrows in tests and remove redundant 'this' identifier

Co-authored-by: David Mollitor <dmollitor@apache.org>
Co-authored-by: Konstantine Karantasis <konstantine@confluent.io>

Reviewers: Ron Dagostino <rdagostino@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>",2020-05-06 16:02:26,belugabehr,Mixed
29dd1148c831ff0007ef3f1df54eee6298da99de,"KAFKA-9768: Fix handling of rest.advertised.listener config (#8360)

The rest.advertised.listener config is currently broken as setting it to http when listeners are configured for both https and http will cause the framework to choose whichever of the two listeners is listed first. The changes here attempt to fix this by checking not only that ServerConnector::getName begins with the specified protocol, but also that that protocol is immediately followed by an underscore, which the framework uses as a delimiter between the protocol and the remainder of the connector name.

An existing unit test for the RestServer::advertisedUrl method has been expanded to include a case that fails with the framework in its current state and passes with the changes in this commit. 

* KAFKA-9768: Fix handling of rest.advertised.listener config
* KAFKA-9768: Add comments on server connector names
* KAFKA-9768: Update RestServerTest comment

Co-authored-by: Randall Hauch <rhauch@gmail.com>

Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, Andrew Choi <andchoi@linkedin.com>",2020-05-06 18:09:47,Chris Egerton,Mixed
4f61b00fcd49b58e2cc806c0dea86d8ffb14ca20,"KAFKA-9667: Connect JSON serde strip trailing zeros (#8230)

This change turns on exact decimal processing in JSON Converter for deserializing decimals, meaning trailing zeros are maintained. Serialization was already using the decimal scale to output the right value, so this change means a value of `1.2300` can now be serialized to JSON and deserialized back to Connect without any loss of information.

Author: Andy Coates <big-andy-coates@users.noreply.github.com>
Reviewers: Randall Hauch <rhauch@gmail.com>, Almog Gavra <almog@confluent.io>",2020-05-07 16:21:08,Andy Coates,Mixed
5583089df03ac6def37418e6b7c16f4e78ca010d,"KAFKA-9942: ConfigCommand fails to set client quotas for default users with --bootstrap-server. (#8628)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2020-05-10 05:54:08,Brian Byrne,Mixed
847ff8f55735568fe879d490af297e047b994f5e,"MINOR: Use `forEach` and `ifPresent` to simplify Scala code (#8642)

* Use `forEach` instead of `asScala.foreach` for Java Iterables.
* Use `ifPresent` instead of `asScala.foreach` for Java Optionals.
* Use `forEach` instead of `entrySet.forEach` for Java maps.
* Keep `asScala.foreach` for `Properties` as the Scala implementation
has a better interface (keys and values are of type `String`).
* A few clean-ups: unnecessary `()`, `{}`, `new`, etc.

Reviewers: Manikumar Reddy <manikumar@confluent.io>",2020-05-11 07:26:34,Ismael Juma,Mixed
fe2742e1b23158ca697cdf00cd027031403f979d,"KAFKA-9972: Only commit tasks with valid states (#8632)

We spotted a case in the soak test where a standby task could be in CREATED state during commit, which causes an illegal state exception. To prevent this from happening, the solution is to always enforce a state check.

Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <vvcephei@apache.org>, Guozhang Wang <wangguoz@gmail.com>",2020-05-11 12:12:52,Boyang Chen,Mixed
391ad90112fb2e9a85bf76250d57863bbf33b383,"KAFKA-9956: Authorizer APIs may be invoked more than once for a given request (#8643)

* Fix describeConfigs and alterConfigs not to invoke authorizer more
than once
* Add tests to KafkaApisTest to verify the fixes
* Rename `filterAuthorized` to `filterByAuthorized`
* Tweak `filterByAuthorized` to take resources instead of resource
names and improve implementation
* Introduce `partitionMapByAuthorized` and `partitionSeqByAuthorized`
and simplify code by using it
* Replace List with Seq in some AdminManager methods
* Remove stray `println` in `KafkaApisTest`

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2020-05-11 13:38:05,Ismael Juma,Mixed
72d72a974c660db7851c1f053ae4a64dfc913837,"KAFKA-9921: explicit handling of null values with retainDuplicates (#8626)

Reviewer: Matthias J. Sax <matthias@confluent.io>",2020-05-11 16:35:02,A. Sophie Blee-Goldman,Not TDD
f54cece73e6116566979bcf6a865d803b7c18974,"KAFKA-8770: KIP-557: Drop idempotent KTable source updates (#8254)

Drops idempotent updates from KTable source operators.
Specifically, drop updates in which the value is unchanged,
and the timestamp is the same or larger.

Implements: KIP-557
Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",2020-05-12 13:19:32,Richard Yu,Mixed
81cf3fa5f2391c39e550a19874d50fcf18cdfd34,"KAFKA-9669; Loosen validation of inner offsets for older message formats (#8647)

Prior to KAFKA-8106, we allowed the v0 and v1 message formats to contain non-consecutive inner offsets. Inside `LogValidator`, we would detect this case and rewrite the batch. After KAFKA-8106, we changed the logic to raise an error in the case of the v1 message format (v0 was still expected to be rewritten). This caused an incompatibility for older clients which were depending on the looser validation. This patch reverts the old logic of rewriting the batch to fix the invalid inner offsets.

Note that the v2 message format has always had stricter validation. This patch also adds a test case for this.

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Ismael Juma <ismael@juma.me.uk>",2020-05-12 12:06:08,Jason Gustafson,Mixed
58f7a973149f66b980f99c3f2bd688d70b06b2eb,"KAFKA-9821: consolidate Streams rebalance triggering mechanisms (#8596)

Persist followup rebalance in assignment and consolidate rebalance triggering mechanisms

Reviewers: John Roesler <vvcephei@apache.org>",2020-05-12 15:57:18,A. Sophie Blee-Goldman,Mixed
778d04d4f94636771cf1765633c53426ae7e1b89,"MINOR: Fix ProcessorContext JavaDocs and stream-time computation (#8603)

Reviewer: John Roesler <john@confluent.io>",2020-05-12 15:19:46,Matthias J. Sax,Mixed
53875bb043c9062078887453a5c09216ae12e89c,"KAFKA-9966: add internal assignment listener to stabilize eos-beta upgrade test (#8648)

Reviewer: Matthias J. Sax <matthias@confluent.io>",2020-05-13 14:50:10,A. Sophie Blee-Goldman,Mixed
14e426c9a820f992cc34f67c1f6e885c6e81ca53,"MINOR: Add a duplicate() method to Message classes (#8556)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",2020-05-13 15:26:50,Colin Patrick McCabe,Mixed
43a9e39983bc3fc2363723b9c555e49b016c1ae2,"KAFKA-9850 Move KStream#repartition operator validation during Topolo… (#8550)

Reviewers: Boyang Chen <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-05-13 17:35:56,zhaohaidao,Not TDD
fad8db67bb74d1ebffdde22fd4e8ec6666fd1881,"MINOR: add option to rebuild source for system tests (#6656)

Reviewers: Jason Gustafson <jason@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-05-13 17:54:43,Boyang Chen,Not TDD
d62f6ebdfe38adf894187e76546eedf13ee98432,"KAFKA-6145: KIP-441: Improve assignment balance (#8588)

Validate that the assignment is always balanced wrt:
* active assignment balance
* stateful assignment balance
* task-parallel balance

Reviewers: Bruno Cadonna <bruno@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",2020-05-14 08:32:08,John Roesler,Mixed
873e9446ef8426061e2f1b6cd21815b270e27f03,"KAFKA-9650: include human readable units in ms and bytes configs (#8222)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2020-05-14 19:56:13,Tom Bentley,Mixed
4e722021a916a2a4183210dae70e6c95df2b5593,"MINOR: skip listOffsets request for newly created changelog topics (#8662)

A small hotfix to avoid an extra probing rebalance the first time an application is launched.
This should particularly improve the testing experience.

Reviewer: Matthias J. Sax <matthias@confluent.io>, John Roesler <vvcephei@apache.org>",2020-05-14 15:53:28,A. Sophie Blee-Goldman,Mixed
f50bd5f80e33598e7fd70290f0c0e809443bc9a0,"KAFKA-9984 Should fail the subscription when pattern is empty (#8665)

Reviewers: Boyang Chen <boyang@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Matthias J. Sax <matthias@confluent.io>",2020-05-14 14:18:15,zhaohaidao,Mixed
b558287c0b6cfb8ac11548048ae12ca6b5c63257,"MINOR: Handle task migrated inside corruption path (#8667)

Reviewers: John Roesler <vvcephei@apache.org>",2020-05-14 19:31:49,Boyang Chen,Mixed
924cee29542129a8ff4b371e43c24890b6a3a510,"KAFKA-9537 - Cleanup error messages for abstract transformations (#8090)

Added check if the transformation is abstract. If so throw an error message with guidance for the user. Ensure that the child classes are also not abstract.

Author: Jeremy Custenborder <jcustenborder@gmail.com>
Reviewer: Randall Hauch <rhauch@gmail.com>",2020-05-15 12:14:20,Jeremy Custenborder,Mixed
d534b5d81771148b3b1db2db837ef72c84b2f61d,"KAFKA-10001: Should trigger store specific callback if it is also a listener (#8670)

The store's registered callback could also be a restore listener, in which case it should be triggered along with the user specified global listener as well.

Reviewers: Boyang Chen <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-05-15 11:27:02,Guozhang Wang,Mixed
62fa8fc9a95d738780d1f73d2d758d7329828feb,"KAFKA-9955: Prevent SinkTask::close from shadowing other exceptions (#8618)

* If two exceptions are thrown the `closePartitions` exception is suppressed
* Add unit tests that throw exceptions in put and close to verify that
  the exceptions are propagated and suppressed appropriately out of WorkerSinkTask::execute

Reviewers: Chris Egerton <chrise@confluent.io>, Nigel Liang <nigel@nigelliang.com>, Konstantine Karantasis <konstantine@confluent.io>",2020-05-15 17:53:32,Greg Harris,Mixed
78e18b575c6b4724afe6107371d70c46fb57d3d9,"KAFKA-9617 Replica Fetcher can mark partition as failed when max.message.bytes is changed (#8659)

Skip to check the size of record if the record is already accepted by leader.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-05-16 10:05:17,Chia-Ping Tsai,Mixed
1f2ff73b28ddb538c4fda263c31b56368787970d,"KIP-551: Expose disk read and write metrics (#8569)

Reviewers: David Arthur <mumrah@gmail.com>, Mickael Maison <mickael.maison@gmail.com>",2020-05-18 14:18:16,Colin Patrick McCabe,Mixed
392e49b1eddd2fcd8d09177cc80abc8a51f5c991,"MINOR: consolidate processor context for active/standby (#8669)

This is a prerequisite for KAFKA-9501 and will also be useful for KAFKA-9603

There should be no logical changes here: the main difference is the removal of StandbyContextImpl in preparation for contexts to transition between active and standby.

Also includes some minor cleanup, eg pulling the ReadOnly/ReadWrite decorators out into a separate file.

Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>, Guozhang Wang <wangguoz@gmail.com>",2020-05-18 14:50:54,A. Sophie Blee-Goldman,Mixed
ad0850659f5d536d43f09221c941022fc273e6d5,"KAFKA-10004: ConfigCommand fails to find default broker configs without ZK (#8675)

Reviewers: Brian Byrne <bbyrne@confluent.io>, Colin P. McCabe <cmccabe@apache.org>",2020-05-18 18:43:45,showuon,Mixed
76e0233c93db0301832a7d22ddbcb58f05319f30,"KAFKA-10011: Remove task id from lockedTaskDirectories during handleLostAll (#8682)

As stated, we couldn't wait for handleRebalanceComplete in the case of handleLostAll, as we already closed the active task as dirty, and could potentially require its offset in the next thread.runOnce call.

Co-authored-by: Guozhang Wang <wangguoz@gmail.com>

Reviewers: A. Sophie Blee-Goldman <ableegoldman@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2020-05-19 14:00:13,Boyang Chen,Mixed
7c7d88339bf36a0a4c046f5dfd57e83a35a8e1e1,"KAFKA-10010: Should make state store registration idempotent (#8681)

Standby task could also at risk of getting into illegal state when not being closed during HandleLostAll:

1. The standby task was initializing as CREATED state, and task corrupted exception was thrown from registerStateStores
2. The task corrupted exception was caught, and do a non-affected task commit
3. The task commit failed due to task migrated exception
4. The handleLostAll didn't close the standby task, leaving it as CREATED state
5. Next rebalance complete, the same task was assigned back as standby task.
6. Illegal Argument exception caught as state store already registered

Reviewers: A. Sophie Blee-Goldman <ableegoldman@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2020-05-19 15:02:55,Boyang Chen,Mixed
affb270bbc0629822857e7558ab96bbe9f1b4582,"MINOR: Fix redundant typos in comments and javadocs (#8693)

* MINOR: Fix typo in RecordAccumulator
* MINOR: Fix typo in several files

Reviewers: Ron Dagostino <rdagostino@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>",2020-05-19 23:53:32,Okada Haruki,Not TDD
67770072da1bd13762af978faaa278c4039167a2,"KAFKA-9859 / kafka-streams-application-reset tool doesn't take into account topics generated by KTable foreign key join operation (#8671)

This PR fixes kafka-streams-application-reset tool. Before, kafka-streams-application-reset tool wasn't taking into account topics generated by KTable foreign key join operation.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-05-20 10:03:57,Levani Kokhreidze,Mixed
9a47d7e35fb2849ae58d7443a5b854c37cc34479,"KAFKA-9603: Do not turn on bulk loading for segmented stores on stand-by tasks (#8661)

Segmented state stores turn on bulk loading of the underlying RocksDB
when restoring. This is correct for segmented state stores that
are in restore mode on active tasks and the onRestoreStart() and
onRestoreEnd() in RocksDBSegmentsBatchingRestoreCallback take care
of toggling bulk loading mode on and off. However, restoreAll()
in RocksDBSegmentsBatchingRestoreCallback might also turn on bulk loading
mode. When this happens on a stand-by task bulk loading mode is never
turned off. That leads to steadily increasing open file decriptors
in RocksDB because in bulk loading mode RocksDB creates continuously new
files but never compacts them (which is the intended behaviour).

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-05-20 15:11:15,Bruno Cadonna,Mixed
82f5efabc9249e0accf530a6a82afc2f32e65ec6,"KAFKA-8869: Remove task configs for deleted connectors from config snapshot (#8444)

Currently, if a connector is deleted, its task configurations will remain in the config snapshot tracked by the KafkaConfigBackingStore. This causes issues with incremental cooperative rebalancing, which utilizes that config snapshot to determine which connectors and tasks need to be assigned across the cluster. Specifically, it first checks to see which connectors are present in the config snapshot, and then, for each of those connectors, queries the snapshot for that connector's task configs.

The lifecycle of a connector is for its configuration to be written to the config topic, that write to be picked up by the workers in the cluster and trigger a rebalance, the connector to be assigned to and started by a worker, task configs to be generated by the connector and then written to the config topic, that write to be picked up by the workers in the cluster and trigger a second rebalance, and finally, the tasks to be assigned to and started by workers across the cluster.

There is a brief period in between the first time the connector is started and when the second rebalance has completed during which those stale task configs from a previously-deleted version of the connector will be used by the framework to start tasks for that connector. This fix aims to eliminate that window by preemptively clearing the task configs from the config snapshot for a connector whenever it has been deleted.

An existing unit test is modified to verify this behavior, and should provide sufficient guarantees that the bug has been fixed.

Reviewers: Nigel Liang <nigel@nigelliang.com>, Konstantine Karantasis <konstantine@confluent.io>",2020-05-20 20:15:43,Chris Egerton,Mixed
ab4b4d73727e401e5fce46030b80ec70ba927b0c,"KAFKA-9950: Construct new ConfigDef for MirrorTaskConfig before defining new properties (#8608)

`MirrorTaskConfig` class mutates the `ConfigDef` by defining additional properties, which leads to a potential `ConcurrentModificationException` during worker configuration validation and unintended inclusion of those new properties in the `ConfigDef` for the connectors which in turn is then visible via the REST API's `/connectors/{name}/config/validate` endpoint.

The fix here is a one-liner that just creates a copy of the `ConfigDef` before defining new properties.

Reviewers: Ryanne Dolan <ryannedolan@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>",2020-05-20 21:14:40,Chris Egerton,Not TDD
f6781f42ff35b7ca597f889f96b28c5b2da62d4a,"MINOR: Added unit tests for ConnectionQuotas (#8650)

Reviiewers: David Jacot <djacot@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2020-05-21 17:21:04,Anna Povzner,Not TDD
d9e9a18a196bb13fe8406d7110d38bedee3cc262,"KAFKA-9980: Fix bug where alterClientQuotas could not set default client quotas (#8658)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2020-05-21 17:50:21,Brian Byrne,Not TDD
27824baa210b9744074ac1fcdabbf1c8ff1b42ca,"KAFKA-10003: Mark KStream.through() as deprecated and update Scala API (#8679)

 - part of KIP-221

Co-authored-by: John Roesler <john@confluent.io>",2020-05-22 08:41:28,Matthias J. Sax,Mixed
9fdd87715ed1c725e268caa14d8415d4f1428ebc,"KAFKA-6145: KIP-441: Enforce Standby Task Stickiness (#8696)

We should treat standbys similarly to active stateful tasks and
re-assign them to instances that are already caught-up on them
while we warm them up on the desired destination, instead of
immediately moving them to the destination.

Reviewers: Bruno Cadonna <bruno@confluent.io>",2020-05-22 11:41:15,John Roesler,Mixed
713f305172b64e8cb9e2d5e3047b53a018e0c195,"MINOR: Fix join group request timeout lower bound (#8702)

If the request timeout is larger than the rebalance timeout, we should use the former as the JoinGroup request timeout. This patch also includes some minor improvements to request/response logging in `NetworkClient` including adding the request timeout to the log message.

Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-05-22 11:52:59,Jason Gustafson,Mixed
981ef5166d2c95cacb6cdc1d52ed0c866b473868,"KAFKA-9931: Implement KIP-605 to expand support for Connect worker internal topic configurations (#8654)

Added support for -1 replication factor and partitions for distributed worker internal topics by expanding the allowed values for the internal topics’ replication factor and partitions from positive values to also include -1 to signify that the broker defaults should be used.

The Kafka storage classes were already constructing a `NewTopic` object (always with a replication factor and partitions) and sending it to Kafka when required. This change will avoid setting the replication factor and/or number of partitions on this `NewTopic` if the worker configuration uses -1 for the corresponding configuration value.

Also added support for extra settings for internal topics on distributed config, status, and offset internal topics.

Quite a few new tests were added to verify that the `TopicAdmin` utility class is correctly using the AdminClient, and that the `DistributedConfig` validators for these configurations are correct. Also added integration tests for internal topic creation, covering preexisting functionality plus the new functionality.

Author: Randall Hauch <rhauch@gmail.com>
Reviewer: Konstantine Karantasis <konstantine@confluent.io>",2020-05-23 09:00:32,Randall Hauch,Mixed
40ee580ed23c876dec45eca4770e834d9aed76da,"KAFKA-9888: Copy connector configs before passing to REST extensions (#8511)

The changes made in KIP-454 involved adding a `connectorConfig` method to the ConnectClusterState interface that REST extensions could use to query the worker for the configuration of a given connector. The implementation for this method returns the Java `Map` that's stored in the worker's view of the config topic (when running in distributed mode). No copying is performed, which causes mutations of that `Map` to persist across invocations of `connectorConfig` and, even worse, propagate to the worker when, e.g., starting a connector.

In this commit the map is copied before it's returned to REST extensions.

An existing unit test is modified to ensure that REST extensions receive a copy of the connector config, not the original.

Reviewers: Nigel Liang <nigel@nigelliang.com>, Konstantine Karantasis <konstantine@confluent.io>",2020-05-23 15:35:43,Chris Egerton,Mixed
2988eac0822022578bd2c6c5626bfbda3e8c73a6,"KAFKA-9944: Added supporting customized HTTP response headers for Kafka Connect. (#8620)

Added support for customizing the HTTP response headers for Kafka Connect as described in KIP-577.

Author: Jeff Huang <jeff.huang@confluent.io>
Reviewer: Randall Hauch <rhauch@gmail.com>",2020-05-24 08:56:27,Jeff Huang,Mixed
85ed123ac65d7459df5049b75178cf7bcc9c9e79,"KAFKA-9767: Add logging to basic auth rest extension (#8357)

Add logging to basic auth rest extension.

Author: Chris Egerton <chrise@confluent.io>
Reviewers: Magesh Nandakumar <magesh.n.kumar@gmail.com>, Randall Hauch <rhauch@gmail.com>",2020-05-24 09:09:40,Chris Egerton,Mixed
9aeb78b99003f39f2d9194c3cc376cabb25ab8b1,"KAFKA-6755: Allow literal value for MaskField SMT (#6284)

Implemented KIP-437 by adding a new optional configuration property for the `MaskField` transformation that allows users to define a replacement literal for specific fields in matching records.

Author: Valeria Vasylieva <valeria.vasylieva@gmail.com>
Reviewer: Randall Hauch <rhauch@gmail.com>",2020-05-24 09:22:40,Valeria,Mixed
45383f75b3b343ac2695f0722b794947ee37098c,"KAFKA-10022:console-producer supports the setting of client.id (#8698)

""console-producer"" supports the setting of ""client.id"", which is a reasonable requirement, and the way ""console consumer"" and ""console producer"" handle ""client.id"" can be unified. ""client.id"" defaults to ""console-producer""

Co-authored-by: xinzhuxiansheng <xinzhuxiansheng@autohome.com.cn>

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-05-24 17:10:43,阿洋,Mixed
3818770d7fcd6ccdd373cdcd3aa6952ea08c901c,"KAFKA-4794: Add access to OffsetStorageReader from SourceConnector (#2604)

Added access to OffsetStorageReader from SourceConnector per KIP-131. 

Added two interfaces SinkConnectorContext/SourceConnectContext that extend ConnectorContext in order to expose an OffsetStorageReader instance.

Added unit tests for Connector, SinkConnector and SourceConnector default methods

Author: Florian Hussonnois <florian.hussonnois@gmail.com>, Randall Hauch <rhauch@gmail.com>
Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>",2020-05-24 20:09:54,Florian Hussonnois,Mixed
de6468ae5915298279e229dc64721e01e7d14fab,"KAFKA-9472: Remove deleted Connect tasks from status store (#8118)

Although the statuses for tasks are removed from the status store when their connector is deleted, their statuses are not removed when only the task is deleted, which happens in the case that the number of tasks for a connector is reduced.

This commit adds logic for deleting the statuses for those tasks from the status store whenever a rebalance has completed and the leader of a distributed cluster has detected that there are recently-deleted tasks. Standalone is also updated to accomplish this.

Unit tests for the `DistributedHerder` and `StandaloneHerder` classes are updated and an integration test has been added.

Reviewers: Nigel Liang <nigel@nigelliang.com>, Konstantine Karantasis <konstantine@confluent.io>",2020-05-25 09:10:03,Chris Egerton,Mixed
c95b45d04f504734224421ce59378c29137290dd,"MINOR: Add reason to log message when incrementing the log start offset (#8701)

Sometimes logging leaves us guessing at the cause of an increment to the log start offset. Since this results in deletion of user data, we should provide the reason explicitly.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2020-05-26 13:52:19,Jason Gustafson,Mixed
371f14c3c12d2e341ac96bd52393b43a10acfa84,"KAFKA-5295: Allow source connectors to specify topic-specific settings for new topics (KIP-158) (#8722)

Kafka Connect workers have been able to create Connect's internal topics using the new admin client for some time now (see KAFKA-4667 for details). However, tasks of source connectors are still relying upon the broker to auto-create topics with default config settings if they don't exist, or expect these topics to exist before the connector is deployed, if their configuration needs to be specialized. 

With the implementation of KIP-158 here, if `topic.creation.enable=true`, Kafka Connect will supply the source tasks of connectors that are configured to create topics with an admin client that will allow them to create new topics on-the-fly before writing the first source records to a new topic. Additionally, each source connector has the opportunity to customize the topic-specific settings of these new topics by defining groups of topic configurations. 

This feature is tested here via unit tests (old tests that have been adjusted and new ones) as well as integration tests.

Reviewers: Randall Hauch <rhauch@gmail.com>",2020-05-26 22:07:34,Konstantine Karantasis,Mixed
ac3043cff089b8ae7fdc37cf453d426932c1c738,"MINOR: Remove unused `Json.legacyEncodeAsString` (#8726)

Updated a couple of test usages not to rely on it and removed
the tests for the removed method.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2020-05-27 05:50:58,Ismael Juma,Mixed
99115cba00ae35f19ae4ba8bbd77b471d7e33ac4,"KAFKA-9561: Update task input partitions after rebalance (#8221)

Co-authored-by: Vyacheslav Stepanenko <vstepanenko@aligntech.com>
Co-authored-by: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-05-27 10:40:41,avalsa,Mixed
075bbcfec40a46c58ba38b58d8a9235e2eb1395d,"KAFKA-7523: Add ConnectedStoreProvider to Processor API (#6824)

Implements KIP-401:
 - Add ConnectedStoreProvider interface
 - let Processor/[*]Transformer[*]Suppliers extend ConnectedStoreProvider
 - allows to add and connect state stores to processors/transformers implicitly

Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>",2020-05-27 10:57:14,Paul,Mixed
2cff1fab3f1c20f464f75f32b6138707050199b5,"KAFKA-6145: KIP-441: Fix assignor config passthough (#8716)

Also fixes a system test by configuring the HATA to perform a one-shot balanced assignment

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Bruno Cadonna <bruno@confluent.io>",2020-05-27 13:50:12,John Roesler,Mixed
cec6202369315d183c410ff7145ae414678b0763,"KAFKA-9298: reuse mapped stream error in joins (#8504)

Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>",2020-05-27 11:54:41,Bill Bejeck,Not TDD
1672a75e1f04ce3b7cd4fa202942a8887cf811e1,"KAFKA-9724 Newer clients not always sending fetch request to older brokers (#8376)

Newer clients were getting stuck entering the validation phase even when a broker didn't support it. This commit will bypass the AWAITING_VALIDATION state when the broker is on an older version of the OffsetsForLeaderEpoch RPC.",2020-05-27 16:37:22,David Arthur,Mixed
83c616f70694637627edb6b1215738c78b74a50d,"KAFKA-9983: KIP-613: add INFO level e2e latency metrics (#8697)

Add e2e latency metrics at the beginning and end of task topologies
as INFO-level processor-node-level metrics.

Implements: KIP-613
Reviewers: John Roesler <vvcephei@apache.org>, Andrew Choi <a24choi@edu.uwaterloo.ca>, Bruno Cadonna <cadonna@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-05-27 15:55:29,A. Sophie Blee-Goldman,Mixed
2cbf6be54a364bfc95db00594775941d1fb45041,"KAFKA-9952; Remove immediate fetch completion logic on high watermark updates (#8709)

For KIP-392, we added logic to make sure that high watermark changes are propagated to followers without delay in order to improve end to end latency when fetching from followers. The downside of this change is that it can increase the rate of fetch requests from followers which can have a noticeable impact on performance (see KAFKA-9731). 

To fix that problem, we have previously modified the code so that we only propagate high watermark changes immediately when a replica selector is used (which is not the default). However, leaving this logic around means that it is risky to enable follower fetching since it changes the follower request rate, which can have a big impact on overall broker performance. 

This patch disables immediate propagation of the high watermark more generally. Instead, users can use the max wait time in order to control the worst-case latency. Note that this is typically only a problem anyway for low-throughput clusters since otherwise we will always have a steady rate of high watermark updates.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2020-05-27 14:41:49,Jason Gustafson,Mixed
9c833f665f349e5c292228f75188f5521282835d,"KAFKA-9960: implement KIP-606 to add metadata context to MetricsReporter (#8691)

Implemented KIP-606 to add metadata context to MetricsReporter.

Author: Xiaodong Du <xdu@confluent.io>
Reviewers: David Arthur <mumrah@gmail.com>, Randall Hauch <rhauch@gmail.com>, Xavier Léauté <xavier@confluent.io>, Ryan Pridgeon <ryan.n.pridgeon@gmail.com>",2020-05-27 20:18:36,xiaodongdu,Mixed
90045f63ea357a0ef3ea11464371e12a942ec5b3,"KAFKA-9146: Add option to force delete active members in StreamsResetter (#8589)

Implements KIP-571

Reviewers: Boyang Chen <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-05-27 18:41:00,feyman2016,Mixed
d9fe30dab0fc56318b012731c348ed1ddae2ec04,"KAFKA-9802; Increase transaction timeout in system tests to reduce flakiness (#8736)

We have been seeing increased flakiness in transaction system tests. I believe the cause might be due to KIP-537, which increased the default zk session timeout from 6s to 18s and the default replica lag timeout from 10s to 30s. In the system test, we use the default transaction timeout of 10s. However, since the system test involves hard failures, the Produce request could be blocking for as long as the max of these two in order to wait for an ISR shrink. Hence this patch increases the timeout to 30s.

Note this patch also includes a minor logging fix in `Partition`. Previously we would see messages like the following:
```
[Broker id=3] Leader output-topic-0 starts at leader epoch 0 from offset 0 with high watermark 0 ISR 3,2,1 addingReplicas  removingReplicas .Previous leader epoch was -1.
```
This patch fixes the log to print as the following:
```
[Broker id=3] Leader output-topic-0 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [3,2,1] addingReplicas []  removingReplicas []. Previous leader epoch was -1.
```

Reviewers: Bob Barrett <bob.barrett@confluent.io>, Ismael Juma <github@juma.me.uk>",2020-05-27 20:54:09,Jason Gustafson,Not TDD
c89f040d45a688d2dd3d244e176e2acd9f9418ac,"KAFKA-10052: Harden assertion of topic settings in Connect integration tests (#8735)

A recently added assertion in Connect integration tests uses `KafkaConsumer#partitionsFor` to verify that a topic was created with the expected number of partitions and replicas. However, probably because of metadata propagation delays, this call doesn't always return a valid `PartitionInfo` for the topic that has just been created and the test is terminated with a NPE. 

This commit changes the assertion to perform retries in order to verify the topic settings and uses the admin client to describe the topics instead.

Tests have been adjusted to use the new assertion. 

Reviewers: Randall Hauch <rhauch@gmail.com>",2020-05-27 21:14:55,Konstantine Karantasis,Not TDD
38c1e96d2c2084c7f3c3f9e5309ca91953e7c88f,"KAFKA-9971: Error Reporting in Sink Connectors (KIP-610) (#8720)

Implementation for KIP-610: https://cwiki.apache.org/confluence/display/KAFKA/KIP-610%3A+Error+Reporting+in+Sink+Connectors based on which sink connectors can now report errors at the final stages of the stream that exports records to the sink system.
 
This PR adds the `ErrantRecordReporter` interface as well as its implementation - `WorkerErrantRecordReporter`. The `WorkerErrantRecordReporter` is created in `Worker` and brought up through `WorkerSinkTask` to `WorkerSinkTaskContext`. 

An integration test and unit tests have been added.

Reviewers: Lev Zemlyanov <lev@confluent.io>, Greg Harris <gregh@confluent.io>, Chris Egerton <chrise@confluent.io>, Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>",2020-05-27 23:49:57,Aakash Shah,Mixed
1c4eb1a5757df611735cfac9b709e0d80d0da4b3,"KAFKA-9673: Filter and Conditional SMTs (#8699)

Implemented KIP-585 to support Filter and Conditional SMTs. Added unit tests and integration tests.

Author: Tom Bentley <tbentley@redhat.com>
Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>",2020-05-28 08:54:30,Tom Bentley,Mixed
36ca33f9cf1902399afe7494f88c6bbd16022b56,"MINOR: remove unnecessary timeout for admin request (#8738)

Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-05-28 18:01:01,A. Sophie Blee-Goldman,Mixed
1fd195e5c21806d3e597cf666d7132ff829f775c,"KAFKA-10029; Don't update completedReceives when channels are closed to avoid ConcurrentModificationException (#8705)

Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>",2020-05-29 09:32:57,Rajini Sivaram,Mixed
277e4cd3bb7759978256be76f055363f66516d17,"KAFKA-10056; Ensure consumer metadata contains new topics on subscription change (#8739)

Reviewers: Jason Gustafson <jason@confluent.io>",2020-05-29 17:03:49,Rajini Sivaram,Mixed
9d52deca247d9e16cf530d655891b2bbe474ffae,"KAFKA-9501: convert between active and standby without closing stores (#8248)

This PR has gone through several significant transitions of its own, but here's the latest:

* TaskManager just collects the tasks to transition and refers to the active/standby task creator to handle closing & recycling the old task and creating the new one. If we ever hit an exception during the close, we bail and close all the remaining tasks as dirty.

* The task creators tell the task to ""close but recycle state"". If this is successful, it tells the recycled processor context and state manager that they should transition to the new type.

* During ""close and recycle"" the task just does a normal clean close, but instead of closing the state manager it informs it to recycle itself: maintain all of its store information (most importantly the current store offsets) but unregister the changelogs from the changelog reader

* The new task will (re-)register its changelogs during initialization, but skip re-registering any stores. It will still read the checkpoint file, but only use the written offsets if the store offsets are not already initialized from pre-transition

* To ensure we don't end up with manual compaction disabled for standbys, we have to call the state restore listener's onRestoreEnd for any active restoring stores that are switching to standbys

Reviewers: John Roesler <vvcephei@apache.org>, Guozhang Wang <wangguoz@gmail.com>",2020-05-29 10:48:03,A. Sophie Blee-Goldman,Mixed
fe948d39e54cf2d57e9b9e0e2a203890dc8ce86d,"KAFKA-9130; KIP-518 Allow listing consumer groups per state (#8238)

Implementation of KIP-518: https://cwiki.apache.org/confluence/display/KAFKA/KIP-518%3A+Allow+listing+consumer+groups+per+state. 

Reviewers: David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>

Co-authored-by: Mickael Maison <mickael.maison@gmail.com>
Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>",2020-05-29 11:25:20,Mickael Maison,Mixed
af3b8b50f2b79b41c1bc3a518942f3df1c5b64f9,"KAFKA-9494; Include additional metadata information in DescribeConfig response (KIP-569) (#8723)

Adds documentation and type of ConfigEntry in version 3 of DescribeConfigsResponse

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2020-05-29 23:18:50,Shailesh Panwar,Mixed
d4c1ef4a100857659ff4ff055bb743dc0471560e,"MINOR: Align the constructor of KafkaConsumer to KafkaProducer (#8605)

1. Move KafkaProducer#propsToMap to Utils#propsToMap
2. Apply Utils#propsToMap to constructor of KafkaConsumer

Reviewers: Noa Resare <noa@resare.com>, Ismael Juma <ismael@juma.me.uk>",2020-05-31 14:36:27,Chia-Ping Tsai,Mixed
36aa3664343ee8a72b27d4ee6b1ccc8ce323d421,"KAFKA-10060 GroupMetadataManager should not log if there are no offsets to expire (#8767)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2020-05-31 14:59:40,Chia-Ping Tsai,Mixed
66fdb59ed0482f430ee59dcbfeccfab75f3cd948,"KAFKA-9392; Clarify deleteAcls javadoc and add test for create/delete timing (#7956)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2020-06-01 16:38:21,Rajini Sivaram,Mixed
c6633a157eec1712116d294eb3785a96cba4e331,"KAFKA-9987: optimize sticky assignment algorithm for same-subscription case (#8668)

Motivation and pseudo code algorithm in the ticket.

Added a scale test with large number of topic partitions and consumers and 30s timeout.
With these changes, assignment with 2,000 consumers and 200 topics with 2,000 each completes within a few seconds.

Porting the same test to trunk, it took 2 minutes even with a 100x reduction in the number of topics (ie, 2 minutes for 2,000 consumers and 2 topics with 2,000 partitions)

Should be cherry-picked to 2.6, 2.5, and 2.4

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-06-01 15:57:15,A. Sophie Blee-Goldman,Mixed
88d996f9fae62e48c6b326103f555d08bbd97d4e,"MINOR: Code cleanup and assertion message fixes in Connect integration tests (#8750)

1. Remove redundant connect#stop from test in InternalTopicsIntegrationTest since we'll do it after each test case in the @After method
2. Refine the error message in topic assertions to make it better explain the errors

Reviewers: Konstantine Karantasis <konstantine@confluent.io>",2020-06-01 17:04:34,showuon,Not TDD
ec67788d9d50151f98d6c8ad88d1ce5b7ea173e4,"KAFKA-10030: Allow fetching a key from a single partition (#8706)

Reviewers: Navinder Pal Singh Brar <navinder_brar@yahoo.com>, Boyang Chen <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-06-01 18:06:28,Dima Reznik,Mixed
07f66765396bffa7e45edeb141726a9a55ead7e0,"MINOR: ChangelogReader should poll for duration 0 for standby restore (#8773)

Co-authored-by: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-06-01 22:33:22,Rohan,Mixed
8b22b8159673bfe22d8ac5dcd4e4312d4f2c863c,"KAFKA-9320: Enable TLSv1.3 by default (KIP-573) (#8695)

1. Enables `TLSv1.3` by default with Java 11 or newer.
2. Add unit tests that cover the various TLSv1.2 and TLSv1.3 combinations.
3. Extend `benchmark_test.py` and `replication_test.py` to run with 'TLSv1.2'
or 'TLSv1.3'.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2020-06-02 15:34:43,Nikolay,Mixed
ea6d373a93205bad41b42ad9a2b2bec717c11c93,"KAFKA-9945: TopicCommand should support --if-exists and --if-not-exists when --bootstrap-server is used (#8737)

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Stanislav Kozlovski <stanislav_kozlovski@outlook.com>",2020-06-02 16:17:05,vinoth chandar,Not TDD
0ffbc6e75fffb39d0dc387db534a51ce613f52af,"KAFKA-10080; Fix race condition on txn completion which can cause duplicate appends (#8782)

The method `maybeWriteTxnCompletion` is unsafe for concurrent calls. This can cause duplicate attempts to write the completion record to the log, which can ultimately lead to illegal state errors and possible to correctness violations if another transaction had been started before the duplicate was written. This patch fixes the problem by ensuring only one thread can successfully remove the pending completion from the map.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2020-06-03 10:37:53,Jason Gustafson,Mixed
98cd4b8cab9f44ad27c6d538c21707d70d5f61af,"KAFKA-10089 The stale ssl engine factory is not closed after reconfigure (#8792)

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2020-06-03 19:04:21,Chia-Ping Tsai,Mixed
6074f864b99b9df9ab7ac850046bd66e2b3962d9,"KAFKA-10069: Correctly remove user-defined ""predicate"" and ""negate"" configs from transformation properties (#8755)

With the recent introduction of predicated SMTs, properties named ""predicate"" and ""negate"" should be ignored and removed in case they are present in transformation configs. 
This commit fixes the equality check to be with the key of the config to apply proper removal. 

Reviewers: Tom Bentley <tbentley@redhat.com>, Konstantine Karantasis <konstantine@confluent.io>",2020-06-03 22:13:50,Chia-Ping Tsai,Mixed
50c30128909a6714c64518d84642e8c45478668a,"KAFKA-9313: Set `use_all_dns_ips` as the new default for `client.dns.lookup` (KIP-602) (#8644)

This applies to the producer, consumer, admin client, connect worker
and inter broker communication.

`ClientDnsLookup.DEFAULT` has been deprecated and a warning
will be logged if it's explicitly set in a client config.

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2020-06-04 06:21:52,Badai Aqrandista,Mixed
78e8a49cda651002549e6e992660f0cfd77ce6e1,"KAFKA-9434: automated protocol for alterReplicaLogDirs (#8311)


Reviewers: David Jacot <djacot@confluent.io>, Mickael Maison <mickael.maison@gmail.com>",2020-06-04 15:36:37,Tom Bentley,Mixed
f1b093144792dc07b14dd5261565bdfcd70a9fd2,"KAFKA-10033: Throw UnknownTopicOrPartitionException if altering configs of non-existing topic

Fixes KAFKA-10033.

Replace AdminOperationException with UnknownTopicOrPartitionException if topic does not exist when validating topic configs in AdminZkClient.

Author: gnkoshelev <gnkoshelev@gmail.com>
Author: Gregory <gnkoshelev@gmail.com>

Reviewers: Brian Byrne <bbyrne@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #8715 from gnkoshelev/KAFKA-10033",2020-06-05 00:02:43,gnkoshelev,Not TDD
7867c24a40ab0a8d1e7b0d9bcb7776d1335ad3ea,"KAFKA-10040; Make computing the PreferredReplicaImbalanceCount metric more efficient (#8724)

This PR changes the way `PreferredReplicaImbalanceCount` is computed. It moves from re-computing after the processing of each event in the controller, which requires a full pass over all partitions, to incrementally maintaining the count as assignments and leaders are changing.

Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Jason Gustafson <jason@confluent.io>",2020-06-04 17:31:18,David Jacot,Mixed
9774c73e43dc2f628b9fb07a30ab4a595c0ee0a8,"KAFKA-9441: Improve Kafka Streams task management (#8776)

 - make task manager agnostic to task state
 - make tasks state transitions idempotent

Reviewers: Boyang Chen <boyang@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2020-06-05 10:40:59,Matthias J. Sax,Mixed
7a876ec9dea931af0f17d6a856a5932091ef5056,"MINOR: fix backwards incompatibility in JmxReporter introduced by KIP-606

cc omkreddy this should also get backported to 2.6.x

Author: Xavier Léauté <xvrl@apache.org>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #8813 from xvrl/fix-jmx-reset",2020-06-06 01:30:48,Xavier Léauté,Mixed
b44ce35fe95af079cec99320128a4dde31d4c9c4,"KAFKA-10110: Corrected potential NPE when null label value added to KafkaMetricsContext (#8811)

Also added a new unit test to verify the functionality and expectations.

Author: Randall Hauch <rhauch@gmail.com>
Reviewer: Konstantine Karantasis <konstantine@confluent.io>",2020-06-05 15:19:23,Randall Hauch,Mixed
2d9376c8bb129d1f880887169890149b914e3a32,"KAFKA-9570: Define SSL configs in all worker config classes, not just distributed (#8135)

Define SSL configs in all worker config classes, not just distributed

Author: Chris Egerton <chrise@confluent.io>
Reviewers: Nigel Liang <nigel@nigelliang.com>, Randall Hauch <rhauch@gmail.com>",2020-06-05 16:02:17,Chris Egerton,Not TDD
5a0e65ed394da76ddebf387739f9dec8687a9485,"KAFKA-8011: Fix flaky RegexSourceIntegrationTest (#8799)

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2020-06-05 14:38:08,Matthias J. Sax,Not TDD
910f3179960067135ec8ad4ab83d4582ff3847b5,"KAFKA-9840; Skip End Offset validation when the leader epoch is not reliable (#8486)

This PR provides two fixes:
1. Skip offset validation if the current leader epoch cannot be reliably determined.
2. Raise an out of range error if the leader returns an undefined offset in response to the OffsetsForLeaderEpoch request.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Jason Gustafson <jason@confluent.io>",2020-06-05 15:53:13,Boyang Chen,Mixed
464aca362707f792eaa1d1111fd4b66a577c2123,"KAFKA-9851: Revoking Connect tasks due to connectivity issues should also clear the running assignment (#8804)

Until recently revocation of connectors and tasks was the result of a rebalance that contained a new assignment. Therefore the view of the running assignment was kept consistent outside the call to `RebalanceListener#onRevoke`. However, after KAFKA-9184 the need appeared for the worker to revoke tasks voluntarily and proactively without having received a new assignment. 

This commit will allow the worker to restart tasks that have been stopped as a result of voluntary revocation after a rebalance reassigns these tasks to the work. 

The fix is tested by extending an existing integration test.

Reviewers: Randall Hauch <rhauch@gmail.com>",2020-06-05 15:56:02,Konstantine Karantasis,Not TDD
4eb3f75556b31b866384a58f4300294624d71bc1,"MINOR: improve code encapsulation between StreamThread and TaskManager (#8819)

Reviewers: Boyang Chen <boyang@confluent.io>, John Roesler <john@confluent.io>",2020-06-05 20:29:50,Matthias J. Sax,Mixed
dd7c0369560c815482e6efc0a7ad08e0fcdf640f,"KAFKA-10033: Throw UnknownTopicOrPartitionException when modifying a non-existent topic's config

Author: Brian Byrne <bbyrne@confluent.io>

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Boyang Chan <boyang@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #8717 from bdbyrne/KAFKA-10033",2020-06-06 21:04:04,Brian Byrne,Not TDD
d4ef46c69dbc525f55a6d9ae5c9ae6da795f98fb,"KAFKA-10097: Internalize checkpoint data (#8820)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2020-06-06 17:34:03,Boyang Chen,Mixed
9a0b694a6686d0dc165d7dab54be0f77535582fa,"KAFKA-9216: Enforce internal config topic settings for Connect workers during startup (#8270)

Currently, Kafka Connect creates its config backing topic with a fire and forget approach.
This is fine unless someone has manually created that topic already with the wrong partition count.

In such a case Kafka Connect may run for some time. Especially if it's in standalone mode and once switched to distributed mode it will almost certainly fail.

This commits adds a check when the KafkaConfigBackingStore is starting.
This check will throw a ConfigException if there is more than one partition in the backing store.

This exception is then caught upstream and logged by either:
- DistributedHerder#run
- ConnectStandalone#main

A unit tests was added in KafkaConfigBackingStoreTest to verify the behaviour.

Author: Evelyn Bayes <evelyn@confluent.io>
Co-authored-by: Randall Hauch <rhauch@gmail.com>

Reviewer: Konstantine Karantasis <konstantine@confluent.io>",2020-06-07 12:42:00,Evelyn Bayes,Mixed
6a30b4e38502f3821d3e500bb8fa6f00ec39aa92,"MINOR: equals() should check _unknownTaggedFields (#8640)

_unknownTaggedFields contains tagged fields which we don't understand
with the current schema.  However, we still want to keep the data around
for various purposes. For example, if we are printing out a JSON form of
the message we received, we want to include a section containing the
tagged fields that couldn't be parsed. To leave these out would give an
incorrect impression of what was sent over the wire.  Since the unknown
tagged fields represent real data, they should be included in the fields
checked by equals().

Reviewers: Ismael Juma <ismael@juma.me.uk>, Boyang Chen <boyang@confluent.io>",2020-06-08 12:57:48,Colin Patrick McCabe,Mixed
ad4b12a18cd82660c329feb0eac95ff3dda0839d,"KAFKA-10005: Decouple RestoreListener from RestoreCallback (#8676)

And remove bulk loading mechanism inside RocksDB.

Reviewers: John Roesler <vvcephei@apache.org>, A. Sophie Blee-Goldman <sophie@confluent.io>",2020-06-08 14:17:45,Guozhang Wang,Mixed
aed7ba9f164ec35adbab948afd1ff8b20ccd8283,"MINOR: Remove unused isSticky assert out from tests only do constrainedAssign (#8788)

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-06-08 14:25:20,showuon,Mixed
5bcd7cca2263b4c7909c46a9fce2bd8aec2c3835,"KAFKA-10102: update ProcessorTopology instead of rebuilding it (#8803)

Reviewers: Boyang Chen  <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-06-08 15:55:16,A. Sophie Blee-Goldman,Mixed
8d3d2742b39980e7c0c0ee0713a25dbb14abc148,"KAFKA-10063; UnsupportedOperation when querying cleaner metrics after shutdown (#8783)

Some `LogCleaner` metrics have an unsafe call to `max` over the collection of cleaner threads, which could be empty after shutdown. This leads to an `UnsupportedOperationException`. This patch fixes the problem by changing the computation to use `foldLeft`.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-06-08 16:47:22,Chia-Ping Tsai,Mixed
09b22e7e67e3ddfa319b723e00105fb0af2bd48b,"KAFKA-9848: Avoid triggering scheduled rebalance delay when task assignment fails but Connect workers remain in the group (#8805)

In the first version of the incremental cooperative protocol, in the presence of a failed sync request by the leader, the assignor was designed to treat the unapplied assignments as lost and trigger a rebalance delay. 

This commit applies optimizations in these cases to avoid the unnecessary activation of the rebalancing delay. First, if the worker that loses the sync group request or response is the leader, then it detects this failure by checking the what is the expected generation when it performs task assignments. If it's not the expected one, it resets its view of the previous assignment because it wasn't successfully applied and it doesn't represent a correct state. Furthermore, if the worker that has missed the assignment sync is an ordinary worker, then the leader is able to detect that there are lost assignments and instead of triggering a rebalance delay among the same members of the group, it treats the lost tasks as new tasks and reassigns them immediately. If the lost assignment included revocations that were not applied, the leader reapplies these revocations again. 

Existing unit tests and integration tests are adapted to test the proposed optimizations. 

Reviewers: Randall Hauch <rhauch@gmail.com>",2020-06-09 09:41:11,Konstantine Karantasis,Mixed
b2d37cc74e9b694713a561d307f52cc0ddf08fe6,"KAFKA-9849: Fix issue with worker.unsync.backoff.ms creating zombie workers when incremental cooperative rebalancing is used (#8827)

When Incremental Cooperative Rebalancing is enabled and a worker fails to read to the end of the config topic, it needs to voluntarily revoke its locally running tasks on time, before these tasks get assigned to another worker, creating a situation where redundant tasks are running in the Connect cluster. 

Additionally, instead of using the delay `worker.unsync.backoff.ms` that was defined for the eager rebalancing protocol and has a long default value (which coincidentally is equal to the default value of the rebalance delay of the incremental cooperative protocol), the worker should quickly attempt to re-read the config topic and backoff for a fraction of the rebalance delay. After this fix, the worker will retry for a maximum time of 5 times before it revokes its running assignment and for a cumulative delay less than the configured `scheduled.rebalance.max.delay.ms`.

Unit tests are added to cover the backoff logic with incremental cooperative rebalancing. 

Reviewers: Randall Hauch <rhauch@gmail.com>",2020-06-09 13:02:35,Konstantine Karantasis,Mixed
84051e0e886de46b8320e3ee222d380b00459b26,"MINOR: Print all removed dynamic members during join complete (#8816)

For better visibility on the group rebalance, we are trying to print out the evicted members inside the group coordinator during rebalance complete.

Reviewers: David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-06-09 17:33:43,Boyang Chen,Mixed
0f68dc7a640b26a8edea154ea4ea2b6d93b5104b,"KAFKA-10079: improve thread-level stickiness (#8775)

Uses a similar (but slightly different) algorithm as in KAFKA-9987 to produce a maximally sticky -- and perfectly balanced -- assignment of tasks to threads within a single client. This is important for in-memory stores which get wiped out when transferred between threads.

Reviewers: John Roesler <vvcephei@apache.org>",2020-06-10 09:56:06,A. Sophie Blee-Goldman,Mixed
164db1a6611224e0289df15215344ce6d600d7b1,"KAFKA-10014; Always try to close all channels in Selector#close (#8685)

Ensure all channels get closed in `Selector.close`, even if some of them raise errors.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2020-06-10 12:24:31,Chia-Ping Tsai,Mixed
7d8e62b3b6d5a4f414211eb9cd5caa0e77d72cfb,"KAFKA-9969: Exclude ConnectorClientConfigRequest from class loading isolation (#8630)

This fix excludes `ConnectorClientConfigRequest` and its inner class from class loading isolation in a similar way that KAFKA-8415 excluded `ConnectorClientConfigOverridePolicy`.

Reviewer: Konstantine Karantasis <konstantine@confluent.io>",2020-06-10 15:04:36,Greg Harris,Mixed
3e9ba2236ab67ca48a3ce6af085f08acf54ee689,"KAFKA-7833: Add Global/StateStore name conflict check (#8825)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2020-06-10 17:06:22,Rob Meng,Mixed
8e083e1b8879e732522bb9a560c82ff84b176cc9,"KAFKA-9441: remove prepareClose() to simplify task management (#8833)

Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",2020-06-10 17:53:43,Matthias J. Sax,Mixed
45fb78edd42057f3fc8c28892b8948c3f36cf017,"KAFKA-9985: Sink connector may exhaust broker when writing in DLQ (#8663)

* Validate topic name against DQL topic in Sink connector config

* Adding parseTopicsList method

* Suppress warning

* KAFKA-9985: Minor changes to improve readability of exception messages

Co-authored-by: Randall Hauch <rhauch@gmail.com>",2020-06-10 19:58:00,Mario Molina,Not TDD
6abb913c6449113141582921340994c0d5e50839,"KAFKA-9841: Revoke duplicate connectors and tasks when zombie workers return with an outdated assignment (#8453)

With Incremental Cooperative Rebalancing, if a worker returns after it's been out of the group for sometime (essentially as a zombie worker) and hasn't voluntarily revoked its own connectors and tasks in the meantime, there's the possibility that these assignments have been distributed to other workers and redundant connectors and tasks might be running now in the Connect cluster. 

This PR complements previous fixes such as KAFKA-9184, KAFKA-9849 and KAFKA-9851 providing a last line of defense against zombie tasks: if at any rebalance round the leader worker detects that there are duplicate assignments in the group, it revokes them completely and resolves duplication with a correct assignment in the rebalancing round that will follow task revocation. 

Author: Wang <ywang50@ebay.com>

Reviewer: Konstantine Karantasis <konstantine@confluent.io>",2020-06-10 17:59:32,Lucent-Wong,Mixed
775f0d484b6fccc3d985a9d53d86d7a3710c0b22,"KAFKA-9066: Retain metrics for failed tasks (#8502)

Author: Chris Egerton <chrise@confluent.io>
Reviewers: Nigel Liang <nigel@nigelliang.com>, Randall Hauch <rhauch@gmail.com>",2020-06-10 22:03:25,Chris Egerton,Mixed
eef5d494329a4526783c16e7b5711b04bfbd01b2,"KAFKA-7833: Add missing test (#8847)

Reviewers: Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",2020-06-10 20:05:10,Matthias J. Sax,Mixed
48b56e533b3ff22ae0e2cf7fcc649e7df19f2b06,"KAFKA-9216: Enforce that Connect’s internal topics use `compact` cleanup policy (#8828)

This change adds a check to the KafkaConfigBackingStore, KafkaOffsetBackingStore, and KafkaStatusBackingStore to use the admin client to verify that the internal topics are compacted and do not use the `delete` cleanup policy.

Connect already will create the internal topics with `cleanup.policy=compact` if the topics do not yet exist when the Connect workers are started; the new topics are created always as compacted, overwriting any user-specified `cleanup.policy`. However, if the topics already exist the worker did not previously verify the internal topics were compacted, such as when a user manually creates the internal topics before starting Connect or manually changes the topic settings after the fact.

The current change helps guard against users running Connect with topics that have delete cleanup policy enabled, which will remove all connector configurations, source offsets, and connector & task statuses that are older than the retention time. This means that, for example, the configuration for a long-running connector could be deleted by the broker, and this will cause restart issues upon a subsequent rebalance or restarting of Connect worker(s).

Connect behavior requires that its internal topics are compacted and not deleted after some retention time. Therefore, this additional check is simply enforcing the existing expectations, and therefore does not need a KIP.

Author: Randall Hauch <rhauch@gmail.com>
Reviewer: Konstantine Karantasis <konstantine@confluent.io>, Chris Egerton <chrise@confluent.io>",2020-06-10 22:39:52,Randall Hauch,Mixed
a6ca7ad31015b7395247290179ae24ce51894b50,"KAFKA-10115: Incorporate errors.tolerance with the Errant Record Reporter (#8829)

Make sure that the Errant Record Reporter recently added in KIP-610 adheres to the  `errors.tolerance` policy.

Author: Aakash Shah <ashah@confluent.io>
Reviewers: Arjun Satish <arjunconfluent.io>, Randall Hauch <rhauch@gmail.com>",2020-06-10 22:53:50,Aakash Shah,Mixed
5f7b07b5140adb9f606c71ae1c261466ccacad74,"MINOR: reduce sizeInBytes for percentiles metrics (#8835)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, John Roesler <john@confluent.io>",2020-06-11 01:05:18,A. Sophie Blee-Goldman,Mixed
7f4fc76e968a6b2cf4a73364c93bfdea03f81af3,"KAFKA-9374: Make connector interactions asynchronous (#8069)

These changes allow herders to continue to function even when a connector they are running hangs in its start, stop, initialize, validate, and/or config methods.

The main idea is to make these connector interactions asynchronous and accept a callback that can be invoked upon the completion (successful or otherwise) of these interactions. The distributed herder handles any follow-up logic by adding a new herder request to its queue in that callback, which helps preserve some synchronization and ordering guarantees provided by the current tick model.

If any connector refuses to shut down within a graceful timeout period, the framework will abandon it and potentially start a new connector in its place (in cases such as connector restart or reconfiguration).

Existing unit tests for the distributed herder and worker have been modified to reflect these changes, and a new integration test named `BlockingConnectorTest` has been added to ensure that they work in practice.

Reviewers: Greg Harris <gregh@confluent.io>, Nigel Liang <nigel@nigelliang.com>, Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>",2020-06-11 01:29:23,Chris Egerton,Mixed
e8e9fe82daa4b0604d039be6f408256b66f97072,"KAFKA-10086: Integration test for ensuring warmups are effective (#8818)

Add an integration test for the task assignor.
* ensure we see proper scale-out behavior with warmups
* ensure in-memory stores are properly recycled and not restored through the scale-out process

Fix two bugs revealed by the test:

Bug 1: we can't remove active tasks in the cooperative algorithm, because this causes their state to get discarded (definitely for in-memory stores, and maybe for persistent ones, depending on the state cleaner). Instead, we convert them to standbys so they can keep warm.

Bug 2: tasks with only in-memory stores weren't reporting their offset positions

Reviewers: Matthias J. Sax <matthias@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",2020-06-11 08:31:20,John Roesler,Mixed
42f46abb34a2b29993b1a8e6333a400a00227e30,"KAFKA-10085: correctly compute lag for optimized source changelogs (#8787)

Split out the optimized source changelogs and fetch the committed offsets rather than the end offset for task lag computation

Reviewers: John Roesler <vvcephei@apache.org>",2020-06-11 09:47:48,A. Sophie Blee-Goldman,Mixed
4f96c5b424956355339dd3216c426c1c0388fe9e,"KAFKA-10027: Implement read path for feature versioning system (KIP-584) (#8680)

In this PR, I have implemented various classes and integration for the read path of the feature versioning system (KIP-584). The ultimate plan is that the cluster-wide finalized features information is going to be stored in ZK under the node /feature. The read path implemented in this PR is centered around reading this finalized features information from ZK, and, processing it inside the Broker.

Here is a summary of what's in this PR (a lot of it is new classes):

A facility is provided in the broker to declare its supported features, and advertise its supported features via its own BrokerIdZNode under a features key.
A facility is provided in the broker to listen to and propagate cluster-wide finalized feature changes from ZK.
When new finalized features are read from ZK, feature incompatibilities are detected by comparing against the broker's own supported features.
ApiVersionsResponse is now served containing supported and finalized feature information (using the newly added tagged fields).

Reviewers: Boyang Chen <boyang@confluent.io>, Jun Rao <junrao@gmail.com>",2020-06-11 11:28:57,Kowshik Prakasam,Mixed
bcf45b09d34607d53e17d1f75a3097f3a8157903,"KAFKA-10049: Fixed FKJ bug where wrapped serdes are set incorrectly when using default StreamsConfig serdes (#8764)

Bug Details:
Mistakenly setting the value serde to the key serde for an internal wrapped serde in the FKJ workflow.

Testing:
Modified the existing test to reproduce the issue, then verified that the test passes.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, John Roesler <vvcephei@apache.org>",2020-06-12 10:00:38,Adam Bellemare,Not TDD
9a4f00f78bf37041006ae8b6432d194f603ac6cc,"KAFKA-9432: automated protocol for DescribeConfigs (#8312)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2020-06-12 21:19:35,Tom Bentley,Mixed
03ed08d0d17a10ca4f96c8cc0a8694834ae01e6d,"KAFKA-10144: clean up corrupted standby tasks before attempting a commit (#8849)

We need to make sure that corrupted standby tasks are actually cleaned up upon a TaskCorruptedException. However due to the commit prior to invoking handleCorruption, it's possible to throw a TaskMigratedException before actually cleaning up any of the corrupted tasks.

This is fine for active tasks since handleLostAll will finish up the job, but it does nothing with standby tasks. We should make sure that standby tasks are handled before attempting to commit (which we can do, since we don't need to commit anything for the corrupted standbys)

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-06-12 16:21:57,A. Sophie Blee-Goldman,Mixed
2239004907b29e00811fee9ded5a790172701a03,"KAFKA-10150: task state transitions/management and committing cleanup (#8856)

* KAFKA-10150: always transition to SUSPENDED during suspend, no matter the current state only call prepareCommit before closing if task.commitNeeded is true

* Don't commit any consumed offsets during handleAssignment -- revoked active tasks (and any others that need committing) will be committed during handleRevocation so we only need to worry about cleaning them up in handleAssignment

* KAFKA-10152: when recycling a task we should always commit consumed offsets (if any), but don't need to write the checkpoint (since changelog offsets are preserved across task transitions)

* Make sure we close all tasks during shutdown, even if an exception is thrown during commit

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-06-16 16:30:37,A. Sophie Blee-Goldman,Mixed
147ffb9a968d62ef78ac6b330a20023ed49ddbb8,"KAFKA-10165: Remove Percentiles from e2e metrics (#8882)

* Remove problematic Percentiles measurements until the implementation is fixed
* Fix leaking e2e metrics when task is closed
* Fix leaking metrics when tasks are recycled

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>",2020-06-17 09:24:07,John Roesler,Mixed
446196d6e9d66f45c64b483e3d375aaeaca28e3b,"KAFKA-10123; Fix incorrect value for AWAIT_RESET#hasPosition (#8841)

## Background

When a partition subscription is initialized it has a `null` position and is in the INITIALIZING state. Depending on the consumer, it will then transition to one of the other states. Typically a consumer will either reset the offset to earliest/latest, or it will provide an offset (with or without offset metadata). For the reset case, we still have no position to act on so fetches should not occur.

Recently we made changes for KAFKA-9724 (#8376) to prevent clients from entering the AWAIT_VALIDATION state when targeting older brokers. New logic to bypass offset validation as part of this change exposed this new issue.

## Bug and Fix

In the partition subscriptions, the AWAIT_RESET state was incorrectly reporting that it had a position. In some cases a position might actually exist (e.g., if we were resetting offsets during a fetch after a truncation), but in the initialization case no position had been set. We saw this issue in system tests where there is a race between the offset reset completing and the first fetch request being issued.

Since AWAIT_RESET#hasPosition was incorrectly returning `true`, the new logic to bypass offset validation was transitioning the subscription to FETCHING (even though no position existed).

The fix was simply to have AWAIT_RESET#hasPosition to return `false` which should have been the case from the start. Additionally, this fix includes some guards against NPE when reading the position from the subscription.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",2020-06-17 20:23:45,David Arthur,Mixed
d8cc6fe8e36329c647736773d9d66de89c447409,"KAFKA-10167: use the admin client to read end-offset (#8876)

Since admin client allows use to use flexible offset-spec, we can always set to use read-uncommitted regardless of the EOS config.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Bruno Cadonna <bruno@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-06-18 11:28:49,Guozhang Wang,Mixed
f3c00ae1c86a48ad36fa42e8e7e1d2b448790e99,"KAFKA-10113; Specify fetch offsets correctly in `LogTruncationException` (#8822)

This patch fixes a bug in the constructor of `LogTruncationException`. We were passing the divergent offsets to the super constructor as the fetch offsets. There is no way to fix this without breaking compatibility, but the harm is probably minimal since this exception was not getting raised properly until KAFKA-9840 anyway.

Note that I have also moved the check for unknown offset and epoch into `SubscriptionState`, which ensures that the partition is still awaiting validation and that the fetch offset hasn't changed. Finally, I made some minor improvements to the logging and exception messages to ensure that we always have the fetch offset and epoch as well as the divergent offset and epoch included.

Reviewers: Boyang Chen <boyang@confluent.io>, David Arthur <mumrah@gmail.com>",2020-06-18 18:10:05,Jason Gustafson,Mixed
3c43adff1d4562c6b33732f399691c9e2f887903,"KAFKA-9891: add integration tests for EOS and StandbyTask (#8890)

Ports the test from #8886 to trunk -- this should be merged to 2.6 branch.

One open question. In 2.6 and trunk we rely on the active tasks to wipe out the store if it crashes. However, assume there is a hard JVM crash and we don't call closeDirty() the store would not be wiped out. Thus, I am wondering, if we would need to fix this (for both active and standby tasks) and do a check on startup if a local store must be wiped out?

The current test passes, as we do a proper cleanup after the exception is thrown.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-06-19 09:05:54,Matthias J. Sax,Not TDD
68db063aa4918ac7dc40cb5c0be48ec731c160f7,"KAFKA-10185: Restoration info logging (#8896)

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-06-19 14:17:58,John Roesler,Mixed
712cc5d073da7595dab836c95372c13fc61047ee,"KAFKA-10168: fix StreamsConfig parameter name variable (#8865)

Implements KIP-626.

Reviewers: Boyang Chen <boyang@confluent.io>, John Roesler <john@confluent.io>",2020-06-19 17:41:06,Matthias J. Sax,Mixed
448e7d7f0f46db1eae14d4fe7a1d25b7af894b09,"KAFKA-10169: swallow non-fatal KafkaException and don't abort transaction during clean close (#8900)

If there's any pending data and we haven't flushed the producer when we abort a transaction, a KafkaException is returned for the previous send. This is a bit misleading, since the situation is not an unrecoverable error and so the Kafka Exception is really non-fatal. For now, we should just catch and swallow this in the RecordCollector (see also: KAFKA-10169)

The reason we ended up aborting an un-flushed transaction was due to the combination of
a. always aborting the ongoing transaction when any task is closed/revoked
b. only committing (and flushing) if at least one of the revoked tasks needs to be committed (regardless of whether any non-revoked tasks have data/transaction in flight)

Given the above, we can end up with an ongoing transaction that isn't committed since none of the revoked tasks have any data in the transaction. We then abort the transaction anyway, when those tasks are closed. So in addition to the above (swallowing this exception), we should avoid unnecessarily aborting data for tasks that haven't been revoked.

We can handle this by splitting the RecordCollector's close into a dirty and clean flavor: if dirty, we need to abort the transaction since it may be dirty due to the commit attempt failing. But if clean, we can skip aborting the transaction since we know that either we just committed and thus there is no ongoing transaction to abort, or else the transaction in flight contains no data from the tasks being closed

Note that this means we still abort the transaction any time a task is closed dirty, so we must close/reinitialize any active task with pending data (that was aborted).

In sum:

* hackily check the KafkaException message and swallow
* only abort the transaction during a dirty close
* refactor shutdown to make sure we don't closeClean a task whose data was actually aborted

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Boyang Chen <boyang@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-06-23 18:08:26,A. Sophie Blee-Goldman,Mixed
3348fc49d8824155e737b866f633e14684da5fe9,"KAFKA-10198: guard against recycling dirty state (#8924)

We just needed to add the check in StreamTask#closeClean to closeAndRecycleState as well. I also renamed closeAndRecycleState to closeCleanAndRecycleState to drive this point home: it needs to be clean.

This should be cherry-picked back to the 2.6 branch

Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>, Guozhang Wang <wangguoz@gmail.com>,",2020-06-24 18:57:38,A. Sophie Blee-Goldman,Mixed
9c9a79b459d2b34218b46da4c54113c500255bbb,"KAFKA-9076: support consumer sync across clusters in MM 2.0 (#7577)

In order to make the Kafka consumer and stream application migrate from source to target cluster
transparently and conveniently, e.g. in event of source cluster failure, a background job is proposed
to periodically sync the consumer offsets from the source to target cluster, so that when the
consumer and stream applications switche to the target cluster, they will resume to consume from
where they left off at source cluster.

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ryanne Dolan <ryannedolan@gmail.com>, Thiago Pinto, Srinivas Boga",2020-06-26 16:17:29,Ning Zhang,Mixed
7f90a58b69cd0eb63ba122b41e6ef6195b0a5d98,"MINOR: Update Scala to 2.13.3 (#8931)

I had to fix several compiler errors due to deprecation of auto application of `()`. A related
Xlint config (`-Xlint:nullary-override`) is no longer valid in 2.13, so we now only enable it
for 2.12. The compiler flagged two new inliner warnings that required suppression and
the semantics of `&` in `@nowarn` annotations changed, requiring a small change in
one of the warning suppressions.

I also removed the deprecation of a number of methods in `KafkaZkClient` as
they should not have been deprecated in the first place since `KafkaZkClient` is an
internal class and we still use these methods in the Controller and so on. This
became visible because the Scala compiler now respects Java's `@Deprecated`
annotation.

Finally, I included a few minor clean-ups (eg using `toBuffer` instead `toList`) when fixing
the compilation warnings.

Noteworthy bug fixes in Scala 2.13.3:

* Fix 2.13-only bug in Java collection converters that caused some operations to perform an extra pass
* Fix 2.13.2 performance regression in Vector: restore special cases for small operands in appendedAll and prependedAll
* Increase laziness of #:: for LazyList
* Fixes related to annotation parsing of @Deprecated from Java sources in mixed compilation

Full release notes:
https://github.com/scala/scala/releases/tag/v2.13.3

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2020-06-26 10:19:04,Ismael Juma,Mixed
30df089631cf3c7667b609e2b9689cb02230c64e,"KAFKA-10166: always write checkpoint before closing an (initialized) task (#8926)

This should address at least some of the excessive TaskCorruptedExceptions we've been seeing lately. Basically, at the moment we only commit tasks if commitNeeded is true -- this seems obvious by definition. But the problem is we do some essential cleanup in postCommit that should always be done before a task is closed:

* clear the PartitionGroup
* write the checkpoint

The second is actually fine to skip when commitNeeded = false with ALOS, as we will have already written a checkpoint during the last commit. But for EOS, we only write the checkpoint before a close -- so even if there is no new pending data since the last commit, we have to write the current offsets. If we don't, the task will be assumed dirty and we will run into our friend the TaskCorruptedException during (re)initialization.

To fix this, we should just always call prepareCommit and postCommit at the TaskManager level. Within the task, it can decide whether or not to actually do something in those methods based on commitNeeded.

One subtle issue is that we still need to avoid checkpointing a task that was still in CREATED, to avoid potentially overwriting an existing checkpoint with uninitialized empty offsets. Unfortunately we always suspend a task before closing and committing, so we lose the information about whether the task as in CREATED or RUNNING/RESTORING by the time we get to the checkpoint. For this we introduce a special flag to keep track of whether a suspended task should actually be checkpointed or not

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-06-26 15:11:56,A. Sophie Blee-Goldman,Mixed
831938952e47d4e65ae40c389e74756c596c6989,"KAFKA-10173: Fix suppress changelog binary schema compatibility (#8905)

We inadvertently changed the binary schema of the suppress buffer changelog
in 2.4.0 without bumping the schema version number. As a result, it is impossible
to upgrade from 2.3.x to 2.4+ if you are using suppression.

* Refactor the schema compatibility test to use serialized data from older versions
as a more foolproof compatibility test.
* Refactor the upgrade system test to use the smoke test application so that we
actually exercise a significant portion of the Streams API during upgrade testing
* Add more recent versions to the upgrade system test matrix
* Fix the compatibility bug by bumping the schema version to 3

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2020-06-26 21:41:51,John Roesler,Mixed
4be4420b3da781265032d651a9dd20087d67a83f,"KAFKA-10212: Describing a topic with the TopicCommand fails if unauthorised to use ListPartitionReassignments API

Since https://issues.apache.org/jira/browse/KAFKA-8834, describing topics with the TopicCommand requires privileges to use ListPartitionReassignments or fails to describe the topics with the following error:

> Error while executing topic command : Cluster authorization failed.

This is a quite hard restriction has most of the secure clusters do not authorize non admin members to access ListPartitionReassignments.

This patch catches the `ClusterAuthorizationException` exception and gracefully fails back. We already do this when the API is not available so it remains consistent.

Author: David Jacot <djacot@confluent.io>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #8947 from dajac/KAFKA-10212",2020-06-30 06:27:42,David Jacot,Not TDD
55b5b248cd0974f48e8bf261f61227722cb47570,"KAFKA-9893: Configurable TCP connection timeout and improve the initial metadata fetch (KIP-601) (#8683)

Reviewers: David Jacot <djacot@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2020-06-30 12:15:17,Cheng Tan,Mixed
0e6c8a55b93d66dbf666ca8625fbe6e1ef919552,"KAFKA-10200: Fix testability of PAPI with windowed stores (#8927)

It's currently not possible to unit-test custom processors that use windowed stores,
because the provided windowed store implementations cast the context to
InternalProcessorContext.

This change adds a public API example using windowed stores, and fixes the
casts internally that would make that example fail previously.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Bruno Cadonna <bruno@confluent.io>",2020-06-30 11:59:47,John Roesler,Mixed
cf1ebcbbbde0430663afd20d4f9753583ed35d81,"KAFKA-10006: Don't create internal topics when LeaderNotAvailableException (#8712)

1. return the topicsNotReady to makeReady including tempUnknownTopics, and not create topic to wait for next retry
2. tempUnknownTopics will be created each retry since we count the tempUnknownTopics as part of topicsNotReady
3. add 2 more tests to total test 3 cases:
  3.1 shouldCreateTopicWhenTopicLeaderNotAvailableAndThenTopicNotFound
  3.2 shouldCompleteValidateWhenTopicLeaderNotAvailableAndThenDescribeSuccess
  3.3 shouldThrowExceptionWhenKeepsTopicLeaderNotAvailable

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>",2020-07-02 13:57:38,showuon,Mixed
3b2ae7b95a27176a22e5356160a9df468c483778,"KAFKA-10173: Use SmokeTest for upgrade system tests (#8938)

Replaces the previous upgrade test's trivial Streams app
with the commonly used SmokeTest, exercising many more
features. Also adjust the test matrix to test upgrading
from each released version since 2.2 to the current branch.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-07-02 18:14:46,John Roesler,Not TDD
caa806cd82fb9fa88510c81de53e69ac9846311d,"KAFKA-10232: MirrorMaker2 internal topics Formatters KIP-597 (#8604)

This PR includes 3 MessageFormatters for MirrorMaker2 internal topics:
- HeartbeatFormatter
- CheckpointFormatter
- OffsetSyncFormatter

This also introduces a new public interface org.apache.kafka.common.MessageFormatter that users can implement to build custom formatters.

Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>, Ryanne Dolan <ryannedolan@gmail.com>, David Jacot <djacot@confluent.io>

Co-authored-by: Mickael Maison <mickael.maison@gmail.com>
Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>",2020-07-03 10:41:45,Mickael Maison,Mixed
cdf68a4dae284ef021ae4ed26c5e0128c0cd7224,"KAFKA-10166: checkpoint recycled standbys and ignore empty rocksdb base directory (#8962)

Two more edge cases I found producing extra TaskcorruptedException while playing around with the failing eos-beta upgrade test (sadly these are unrelated problems, as the test still fails with these fixes in place).

* Need to write the checkpoint when recycling a standby: although we do preserve the changelog offsets when recycling a task, and should therefore write the offsets when the new task is itself closed, we do NOT write the checkpoint for uninitialized tasks. So if the new task is ultimately closed before it gets out of the CREATED state, the offsets will not be written and we can get a TaskCorruptedException
* We do not write the checkpoint file if the current offset map is empty; however for eos the checkpoint file is not only used for restoration but also for clean shutdown. Although skipping a dummy checkpoint file does not actually violate any correctness since we are going to re-bootstrap from the log-start-offset anyways, it throws unnecessary TaskCorruptedException which has an overhead itself.

Reviewers: John Roesler <vvcephei@apache.org>, Guozhang Wang <wangguoz@gmail.com>",2020-07-06 17:16:12,A. Sophie Blee-Goldman,Mixed
18f2589c1e087654c0cdd46d2473246f37f0b66a,"KAFKA-10239: Make GroupInstanceId ignorable in DescribeGroups (#8989)

* make GroupInstanceId ignorable in DescribeGroup

* tests and cleanups

* add throttle test coverage",2020-07-06 18:50:40,Boyang Chen,Not TDD
47cbbf2752affc2a511cbe5cb926692d74e6a9cf,"KAFKA-10243; ConcurrentModificationException while processing connection setup timeouts (#8990)

This PR fixes a bug introduced in #8683.

While processing connection set up timeouts, we are iterating through the connecting nodes to process timeouts and we disconnect within the loop, removing the entry from the set in the loop that it iterating over the set. That raises a ConcurrentModificationException exception. The current unit test did not catch this because it was using only one node.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2020-07-07 16:48:44,David Jacot,Mixed
69531611258ca732c93a8cded95c0c776cd28643,"KAFKA-10191 fix flaky StreamsOptimizedTest (#8913)

Call KafkaStreams#cleanUp to reset local state before starting application up the second run.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>, John Roesler <john@confluent.io>",2020-07-07 12:48:36,Chia-Ping Tsai,Not TDD
6f3ceea5c61d90d4075ed5c5a22bde33142f7ec7,"KAFKA-10134: Use long poll if we do not have fetchable partitions (#8934)

The intention of using poll(0) is to not block on rebalance but still return some data; however, `updateAssignmentMetadataIfNeeded` have three different logic: 1) discover coordinator if necessary, 2) join-group if necessary, 3) refresh metadata and fetch position if necessary. We only want to make 2) to be non-blocking but not others, since e.g. when the coordinator is down, then heartbeat would expire and cause the consumer to fetch with timeout 0 as well, causing unnecessarily high CPU.

Since splitting this function is a rather big change to make as a last minute blocker fix for 2.6, so I made a smaller change to make updateAssignmentMetadataIfNeeded has an optional boolean flag to indicate if 2) above should wait until either expired or complete, otherwise do not wait on the join-group future and just poll with zero timer.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-07-08 09:51:50,Guozhang Wang,Mixed
38877c0025a84ae02394d7542957f522514da94e,"MINOR; alterReplicaLogDirs should not fail all the futures when only one call fails (#8985)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2020-07-08 12:31:14,David Jacot,Mixed
dd79579c718d069b985897ca7837dc211b39092a,"KAFKA-10220: Add null check for configurationKey in AdminManager.describeConfigs()

Add null check for configurationKey to avoid NPE, and add test for it.

Author: Luke Chen <showuon@gmail.com>

Reviewers: Tom Bentley <tbentley@redhat.com>, huxi <huxi_2b@hotmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #8966 from showuon/KAFKA-10220",2020-07-09 14:29:12,Luke Chen,Mixed
f5e970df1d18ba999f1d4c2c227127f741e80604,"KAFKA-10109: Fix double AdminClient creation in AclCommand

Author: Tom Bentley <tbentley@redhat.com>

Reviewers: David Jacot <djacot@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #8808 from tombentley/KAFKA-10109-AclComment-multiple-AdminClients",2020-07-09 14:59:05,Tom Bentley,Mixed
813f92c21ad4bd7ffdd8acc66c20d31927e7a67f,"KAFKA-10179: Pass correct changelog topic to state serdes (#8902)

Until now we always passed the default changelog topic name
to the state serdes. However, for optimized source tables
and global tables the changelog topic is the source topic.

Most serdes do not use the topic name passed to them.
However, if the serdes actually use the topic name for
(de)serialization a
org.apache.kafka.common.errors.SerializationException is thrown.

This commits passed the correct changelog topic to the state
serdes of the metered state stores.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>, John Roesler <vvcephei@apache.org>",2020-07-09 13:50:31,Bruno Cadonna,Mixed
888f83c2c3d03084629256f9f993072a22da74c0,"KAFKA-10249: don't try to read un-checkpointed offsets of in-memory stores (#8996)

Fixes an asymmetry in which we avoid writing checkpoints for non-persistent stores, but still expected to read them, resulting in a spurious TaskCorruptedException.

Reviewers: Matthias J. Sax <mjsax@apache.org>, John Roesler <vvcephei@apache.org>",2020-07-09 20:49:20,A. Sophie Blee-Goldman,Mixed
f209b3c5c1efbd80d709244a41f55c19c5c1c4de,"KAFKA-10263: Do not assign standby for revoking stateless tasks (#9005)

Also piggy-back a small fix to use TreeMap other than HashMap to preserve iteration ordering.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <vvcephei@apache.org>",2020-07-10 16:51:00,Guozhang Wang,Mixed
f2db8d5318e099e492e44effbfcea57005c1cf94,"KAFKA-10262: Ensure that creating task directory is thread safe (#9010)

Reviewers: A. Sophie Blee-Goldman <sohpie@confluent.io>, John Roesler <john@confluent.io>",2020-07-11 11:11:06,Matthias J. Sax,Mixed
cec5f377b59443a52ed1895d4e76e6f31cd46d66,"KAFKA-10247: Correctly reset state when task is corrupted (#8994)

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-07-11 11:39:23,John Roesler,Mixed
f40aa33de792f74c3bc8078c61d5cac67df963ba,"MINOR; KafkaAdminClient#describeLogDirs should not fail all the futures when only one call fails (#8998)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2020-07-13 08:00:51,David Jacot,Mixed
ffdec02e25bb3be52ee5c06fe76d388303f6ea43,"KAFKA-10044 Deprecate ConsumerConfig#addDeserializerToConfig and Prod… (#9013)

deprecate ConsumerConfig#addDeserializerToConfig and ProducerConfig#addSerializerToConfig.

Create internal use cases instead: appendDeserializerToConfig and appendSerializerToConfig

Reviewers: Boyang Chen <boyang@confluent.io>",2020-07-13 16:23:18,Chia-Ping Tsai,Mixed
43d43e6c7bbfbc87d0288f7b934d5b6e0ebf1913,"KAFKA-10002; Improve performances of StopReplicaRequest with large number of partitions to be deleted (#8672)

Update checkpoint files once for all deleted partitions instead of updating them for each deleted partitions. With this, a stop replica requests with 2000 partitions to be deleted takes ~2 secs instead of ~40 secs previously.

Refactor the checkpointing methods to not compute the logsByDir all the time. It is now reused as much as possible.

Refactor the exception handling. Some checkpointing methods were handling IOException but the underlying write process already catches them and throws KafkaStorageException instead.

Reduce the logging in the log cleaner manager. It does not log anymore when a partition is deleted as it is not a useful information.

Reviewers:  Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",2020-07-13 17:49:13,David Jacot,Mixed
4cd6dfc825b934e8e360bdd586c41931b0b3b8e6,"KAFKA-10240: Suppress WakeupExceptions during sink task shutdown (#9003)

A benign `WakeupException` can be thrown by a sink task's consumer if the task is scheduled for shutdown by the worker. This is caught and handled gracefully if the exception is thrown when calling `poll` on the consumer, but not if calling `commitSync`, which is invoked by a task during shutdown and also when its partition assignment is updated.

If thrown during a partition assignment update, the `WakeupException` is caught and handled gracefully as part of the task's `iteration` loop. If thrown during shutdown, however, it is not caught and instead leads to the misleading log message ""Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted."".

These changes catch the `WakeupException` during shutdown and handle it gracefully with a `TRACE`-level log message.

A unit test is added to verify this behavior by simulating a thrown `WakeupException` during `Consumer::commitSync`, running through the `WorkerSinkTask::execute` method, and confirming that it does not throw a `WakeupException` itself.

Reviewers: Greg Harris <gregh@confluent.io>, Nigel Liang <nigel@nigelliang.com>, Konstantine Karantasis <k.karantasis@gmail.com>",2020-07-13 20:55:12,Chris Egerton,Mixed
2eeae09ca3e5a9af89e1f15c0d772413ddc489ec,"KAFKA-9666; Don't increase producer epoch when trying to fence if the log append fails (#8239)

When fencing producers, we currently blindly bump the epoch by 1 and write an abort marker to the transaction log. If the log is unavailable (for example, because the number of in-sync replicas is less than min.in.sync.replicas), we will roll back the attempted write of the abort marker, but still increment the epoch in the transaction metadata cache. During periods of prolonged log unavailability, producer retires of InitProducerId calls can cause the epoch to be increased to the point of exhaustion, at which point further InitProducerId calls fail because the producer can no longer be fenced. With this patch, we track whenever we have failed to write the bumped epoch, and when that has happened, we don't bump the epoch any further when attempting to fence. This is safe because the in-memory epoch is still causes old producers to be fenced.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>",2020-07-15 14:16:06,Bob Barrett,Mixed
99c64822a723c6f87e3319a2def82f2c0c99f5f4,"MINOR: Filter out quota configs for ConfigCommand using --bootstrap-server (#9030)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, David Jacot <djacot@confluent.io>, Ron Dagostino <rdagostino@confluent.io>",2020-07-17 08:55:53,Rajini Sivaram,Mixed
715df0d27122e0799c68daa78ab5f9ce0ab6b594,"MINOR: Improve log4j for per-consumer assignment (#8997)

Add log4j entry summarizing the assignment (previous owned and assigned) at the consumer level.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>",2020-07-17 12:02:37,Guozhang Wang,Mixed
9c8f75c4b624084c954b4da69f092211a9ac4689,"KAFKA-10223; Use NOT_LEADER_OR_FOLLOWER instead of non-retriable REPLICA_NOT_AVAILABLE for consumers (#8979)

Brokers currently return NOT_LEADER_FOR_PARTITION to producers and REPLICA_NOT_AVAILABLE to consumers if a replica is not available on the broker during reassignments. Non-Java clients treat REPLICA_NOT_AVAILABLE as a non-retriable exception, Java consumers handle this error by explicitly matching the error code even though it is not an InvalidMetadataException. This PR renames NOT_LEADER_FOR_PARTITION to NOT_LEADER_OR_FOLLOWER and uses the same error for producers and consumers. This is compatible with both Java and non-Java clients since all clients handle this error code (6) as retriable exception. The PR also makes ReplicaNotAvailableException a subclass of InvalidMetadataException.
    - ALTER_REPLICA_LOG_DIRS continues to return REPLICA_NOT_AVAILABLE. Retained this for compatibility since this request never returned NOT_LEADER_FOR_PARTITION earlier. 
   -  MetadataRequest version 0 also returns REPLICA_NOT_AVAILABLE as topic-level error code for compatibility. Newer versions filter these out and return Errors.NONE, so didn't change this.
   - Partition responses in MetadataRequest return REPLICA_NOT_AVAILABLE to indicate that one of the replicas is not available. Did not change this since NOT_LEADER_FOR_PARTITION is not suitable in this case.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>, Bob Barrett <bob.barrett@confluent.io>",2020-07-17 20:05:11,Rajini Sivaram,Mixed
cd6850b4108892d565b94f7cb9150d07f6116511,"MINOR: Fixed some resource leaks. (#8922)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2020-07-19 20:36:12,Leonard Ge,Not TDD
f77e250b99888aaf7907b92e5be853171f178c8d,"KAFKA-10189: reset event queue time histogram when queue is empty (#8935)

add a timeout for event queue time histogram;
reset eventQueueTimeHist when the controller event queue is empty;

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Igor Soarez <i@soarez.me>, Jun Rao <junrao@gmail.com>",2020-07-20 17:55:21,Jeff Kim,Mixed
6162a1532673dd12485c8df0c6f00725cc7d134a,"KAFKA-10279; Allow dynamic update of certificates with additional SubjectAltNames (#9044)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2020-07-21 10:36:39,Rajini Sivaram,Not TDD
c38825ab976e5187d14c10503a5b403fc41c8d5c,"KAFKA-9432:(follow-up) Set `configKeys` to null in `describeConfigs()` to make it backward compatible with older Kafka versions.

- After #8312, older brokers are returning empty configs,  with latest `adminClient.describeConfigs`.  Old brokers  are receiving empty configNames in `AdminManageer.describeConfigs()` method. Older brokers does not handle empty configKeys. Due to this old brokers are filtering all the configs.
- Update ClientCompatibilityTest to verify describe configs
- Add test case to test describe configs with empty configuration Keys

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #9046 from omkreddy/KAFKA-9432",2020-07-21 17:32:11,Manikumar Reddy,Not TDD
194c56fce2e1b35b518f54ff0d2e5a1104a8126a,"KAFKA-9274: Mark `retries` config as deprecated and add new `task.timeout.ms` config (#8864)

 - part of KIP-572
 - deprecates producer config `retries` (still in use)
 - deprecates admin config `retries` (still in use)
 - deprecates Kafka Streams config `retries` (will be ignored)
 - adds new Kafka Streams config `task.timeout.ms` (follow up PRs will leverage this new config)

Reviewers: John Roesler <john@confluent.io>, Jason Gustafson <jason@confluent.io>, Randall Hauch <randall@confluent.io>",2020-07-21 12:19:13,Matthias J. Sax,Mixed
a5ffd1ca44caf4e4117c09cb99acd42084ea0fa8,"KAFKA-10163; Throttle Create Topic, Create Partition and Delete Topic Operations (KIP-599, Part I, Broker Changes) (#8933)

This PR implements the broker side changes of KIP-599, except the changes of the Rate implementation which will be addressed separately. The PR changes/introduces the following:
  - It introduces the protocol changes.
  - It introduces a new quota manager ControllerMutationQuotaManager which is another specialization of the ClientQuotaManager.
  - It enforces the quota in the KafkaApis and in the AdminManager. This part handles new and old clients as described in the KIP.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2020-07-22 16:38:55,David Jacot,Mixed
d9168970dd9cfd815b72db176baa62a9849fcb47,"KAFKA-10164; Throttle Create Topic, Create Partition and Delete Topic Operations (KIP-599, Part II, Admin Changes) (#8968)

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2020-07-22 19:12:26,David Jacot,Mixed
2d791712851701bee29e373c7db607a58c3fa44a,"KAFKA-5876: Add new exception types for Interactive Queries (#8200)

- part of KIP-216
- adds new sub-classes of InvalidStateStoreException

Reviewers: Navinder Pal Singh Brar <navinder_brar@yahoo.com>, Matthias J. Sax <matthias@confluent.io>",2020-07-22 19:53:51,Vito Jeng,Not TDD
1c439da590771c604ba25f4776ba9deb1670a891,"KAFKA-10268: dynamic config like ""--delete-config log.retention.ms"" doesn't work (#9051)

* KAFKA-10268: dynamic config like ""--delete-config log.retention.ms"" doesn't work

https://issues.apache.org/jira/browse/KAFKA-10268

Currently, ConfigCommand --delete-config API does not restore the config to default value, no matter at broker-level or broker-default level. Besides, Admin.incrementalAlterConfigs API also runs into this problem. This patch fixes it by removing the corresponding config from the newConfig properties when reconfiguring dynamic broker config.",2020-07-24 09:33:22,huxi,Not TDD
fa6e5b892227db24568e2cec0a0a0969bc1ec4b5,"KAFKA-10301: Do not clear Partition#remoteReplicasMap during partition assignment updates (#9065)

We would previously update the map by adding the new replicas to the map and then removing the old ones.
During a recent refactoring, we changed the logic to first clear the map and then add all the replicas to it.

While this is done in a write lock, not all callers that access the map structure use a lock. It is safer to revert to
the previous behavior of showing the intermediate state of the map with extra replicas, rather than an
intermediate state of the map with no replicas.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2020-07-24 12:03:10,Stanislav Kozlovski,Mixed
206b69af8b1267a5022d22d1535bd1db02702be1,"KAFKA-10305: Print usage when parsing fails for ConsumerPerformance (#9071)

https://issues.apache.org/jira/browse/KAFKA-10305

When `kafka-consumer-perf-test.sh` is executed without required options or no options at all, only the error message is displayed. It's better off showing the usage as well like what we did for kafka-console-producer.sh.",2020-07-25 19:04:16,huxi,Mixed
483fbd812d3d59bc8332eaeb12f1360a916332b3,"KAFKA-10246 : AbstractProcessorContext topic() throws NPE (#9034)

AbstractProcessorContext topic() throws NullPointerException when modifying a state store within the DSL from a punctuator. Reorder the check to avoid the NPE.

Co-authored-by: Ashish Roy <v-ashish.r@turvo.com>
Reviewers: Boyang Chen <boyang@confluent.io>",2020-07-25 08:51:51,Ashish Roy,Mixed
99472c54f01e1f654a3ccb774a7857f10d69e2e3,"KAFKA-10158: Fix flaky testDescribeUnderReplicatedPartitionsWhenReassignmentIsInProgress (#9022)

Set `replica.fetch.max.bytes` to `1` and produce multiple record batches to allow
for throttling to take place. This helps avoid a race condition where the
reassignment would complete more quickly than expected causing an
assertion to fail some times.

Reviewers: Lucas Bradstreet <lucas@confluent.io>, Jason Gustafson <jason@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2020-07-26 08:28:47,Brian Byrne,Not TDD
0d47c69a9351ae258ad6165841840a65f0301d86,"KAFKA-10306: GlobalThread should fail on InvalidOffsetException (#9075)

* KAFKA-10306: GlobalThread should fail on InvalidOffsetException

* Update streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateUpdateTask.java

Co-authored-by: John Roesler <vvcephei@users.noreply.github.com>

* Update streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateUpdateTask.java

Co-authored-by: John Roesler <vvcephei@users.noreply.github.com>

* Update streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.java

Co-authored-by: John Roesler <vvcephei@users.noreply.github.com>

* Update streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.java

Co-authored-by: John Roesler <vvcephei@users.noreply.github.com>",2020-07-26 11:58:40,Matthias J. Sax,Mixed
de2e6938c8648f02254a645a8fff9c2fa8364ef1,"KAFKA-10270: A broker to controller channel manager (#9012)

Add a broker to controller channel manager for use cases such as redirection and AlterIsr.

Reviewers: David Arthur <mumrah@gmail.com>, Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>

Co-authored-by: Viktor Somogyi <viktorsomogyi@gmail.com>
Co-authored-by: Boyang Chen <boyang@confluent.io>",2020-07-29 11:40:14,Boyang Chen,Mixed
783a6451f5f8c50dbe151caf5e76b74917690364,"KAFKA-10309: KafkaProducer's sendOffsetsToTransaction should not block infinitively (#9081)

Modified KafkaProducer.sendOffsetsToTransaction() to be affected with max.block.ms, and added timeout test for blocking methods

Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Xi Hu <huxi_2b@hotmail.com>",2020-07-29 15:38:27,Sasaki Toru,Not TDD
2f64f6deb906cdfe4d006e530edeff2e79c05f76,"KAFKA-10321: fix infinite blocking for global stream thread startup (#9095)

The start() function for global stream thread only checks whether the thread is not running, as it needs to block until it finishes the initialization. This PR fixes this behavior by adding a check whether the thread is already in error state as well.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, John Roesler <vvcephei@apache.org>",2020-07-29 21:04:21,Boyang Chen,Mixed
819cd454f9b3078515a86e43a4486794df0a7971,"KAFKA-10120: Deprecate DescribeLogDirsResult.all() and .values() (#9007)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, David Jacot <djacot@confluent.io>, Lee Dongjin <dongjin@apache.org>, Chia-Ping Tsai <chia7712@gmail.com>",2020-07-30 14:10:30,Tom Bentley,Mixed
96e0719e421a91b5fa289dc0d23276977655633e,"KAFKA-10319: Skip unknown offsets when computing sum of changelog offsets (#9066) (#9097)

In PR #8962 we introduced a sentinel UNKNOWN_OFFSET to mark unknown offsets in checkpoint files. The sentinel was set to -2 which is the same value used for the sentinel LATEST_OFFSET that is used in subscriptions to signal that state stores have been used by an active task. Unfortunately, we missed to skip UNKNOWN_OFFSET when we compute the sum of the changelog offsets.

If a task had only one state store and it did not restore anything before the next rebalance, the stream thread wrote -2 (i.e., UNKNOWN_OFFSET) into the subscription as sum of the changelog offsets. During assignment, the leader interpreted the -2 as if the stream run the task as active although it might have run it as standby. This misinterpretation of the sentinel value resulted in unexpected task assignments.

Ports: KAFKA-10287 / #9066

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, John Roesler <vvcephei@apache.org>, Matthias J. Sax <mjsax@apache.org>",2020-07-30 09:54:37,Bruno Cadonna,Mixed
4cd2396db31418c90005c998d9107ad40df055b2,"KAFKA-9629 Use generated protocol for Fetch API (#9008)

Refactored FetchRequest and FetchResponse to use the generated message classes for serialization and deserialization. This allows us to bypass unnecessary Struct conversion in a few places. A new ""records"" type was added to the message protocol which uses BaseRecords as the field type. When sending, we can set a FileRecords instance on the message, and when receiving the message class will use MemoryRecords. 

Also included a few JMH benchmarks which indicate a small performance improvement for requests with high partition counts or small record sizes.

Reviewers: Jason Gustafson <jason@confluent.io>, Boyang Chen <boyang@confluent.io>, David Jacot <djacot@confluent.io>, Lucas Bradstreet <lucas@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Colin P. McCabe <cmccabe@apache.org>",2020-07-30 13:29:39,David Arthur,Mixed
36b273370dd840cc2bb6307f311f8952b886b323,"KAFKA-10282; Remove Log metrics immediately when deleting log

Currently, we remove the Log metrics when asynchronous deletion of the log is triggered. However, we attempt to register the metrics immediately upon log creation. If a Log object is re-created for a partition that is pending deletion (because a topic was quickly re-created or because a partition was moved off and back onto a broker), the registration of the new metrics can happen before the asyncrhonous deletion. In this case, the metrics are removed after the second registration, leading to missing Log metrics.

To fix this, this patch changes the log deletion behavior to remove the metrics when the log is first marked for deletion, rather than when the files are deleted. This removes the window in which metrics registration can occur before metrics removal. This is justifiable because the log should be logically deleted when a delete request or partition movement finishes, rather than when the files are actually removed. Tested with unit tests.

Author: Bob Barrett <bob.barrett@confluent.io>

Reviewers: David Jacot, Dhruvil Shah, Vikas Singh, Gwen Shapira

Closes #9054 from bob-barrett/KAFKA-10282",2020-07-30 19:11:56,Bob Barrett,Mixed
5c2991aff66e58c4ab6a04bef85e1cac4ef8f5f6,"KAFKA-10163; Define `controller_mutation_rate` as a Double instead of a Long (#9092)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2020-08-03 10:44:42,David Jacot,Mixed
1112fd47238abd0254ceb11d699478d4451278f7,"KAFKA-10341: Add 2.6.0 to system tests and streams upgrade tests (#9116)

Author: Randall Hauch <rhauch@gmail.com>
Reviewer: Matthias J. Sax <matthias@confluent.io>",2020-08-04 18:04:52,Randall Hauch,Not TDD
26a217c8e75b238bbba5f1799b7d91b5b4910123,"MINOR: Streams integration tests should not call exit (#9067)

- replace System.exit with Exit.exit in all relevant classes
- forbid use of System.exit in all relevant classes and add exceptions for others

Co-authored-by: John Roesler <vvcephei@apache.org>
Co-authored-by: Matthias J. Sax <matthias@confluent.io>

Reviewers: Lucas Bradstreet <lucas@confluent.io>, Ismael Juma <ismael@confluent.io>",2020-08-05 13:52:50,John Roesler,Not TDD
b351493543b7e26aa345df3b568d0dc08a8c8d91,"KAFKA-9274: Remove `retries` for global task (#9047)

 - part of KIP-572
 - removed the usage of `retries` in `GlobalStateManger`
 - instead of retries the new `task.timeout.ms` config is used

Reviewers: John Roesler <john@confluent.io>, Boyang Chen <boyang@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2020-08-05 14:14:18,Matthias J. Sax,Mixed
b5f90daf13b4945305951ca0eecdb454a4dcafc2,"KAFKA-10162; Use Token Bucket algorithm for controller mutation quota (KIP-599, Part III) (#9114)

Based on the discussion in #9072, I have put together an alternative way. This one does the following:

Instead of changing the implementation of the Rate to behave like a Token Bucket, it actually use two different metrics: the regular Rate and a new Token Bucket. The latter is used to enforce the quota.
The Token Bucket algorithm uses the rate of the quota as the refill rate for the credits and compute the burst based on the number of samples and their length (# samples * sample length * quota).
The Token Bucket algorithm used can go under zero in order to handle unlimited burst (e.g. create topic with a number of partitions higher than the burst). Throttling kicks in when the number of credits is under zero.
The throttle time is computed as credits under zero / refill rate (or quota).
Only the controller mutation uses it for now.
The remaining number of credits in the bucket is exposed with the tokens metrics per user/clientId.

Reviewers: Anna Povzner <anna@confluent.io>, Jun Rao <junrao@gmail.com>",2020-08-06 09:11:55,David Jacot,Mixed
e7316f35d933d8bf738caa1a01e8477f74021677,"KAFKA-10316: Consider renaming getter method for Interactive Queries (#9120)

 - implements KIP-648
 - Deprecated the existing getters and added new getters without `get` prefix to `KeyQueryMetadata`

Co-authored-by: johnthotekat <Iabon1989*>

Reviewers: Navinder Pal Singh Brar <navinder_brar@yahoo.com>, Matthias J. Sax <matthias@confluent.io>",2020-08-06 11:15:35,John Thomas,Not TDD
990301323cc5a774e17b0a5d373aff8439cda489,"KAFKA-9274: Remove `retries` from InternalTopicManager (#9060)

 - part of KIP-572
 - replace `retries` in InternalTopicManager with infinite retires plus a new timeout, based on consumer config MAX_POLL_INTERVAL_MS

Reviewers: David Jacot <djacot@confluent.io>, Boyang Chen <boyang@confluent.io>",2020-08-06 11:28:07,Matthias J. Sax,Mixed
680e68413b4648f8539dc175f7e8dabab59ec5e3,"KAFKA-10193: Add preemption for controller events that have callbacks

JIRA: https://issues.apache.org/jira/browse/KAFKA-10193
* add `preempt(): Unit` method for all `ControllerEvent` so that all events (and future events) must implement it
* for events that have callbacks, move the preemption from individual methods to `preempt()`
* add preemption for `ApiPartitionReassignment` and `ListPartitionReassignments`
* add integration tests:
1. test whether `preempt()` is called when controller shuts down
2. test whether the events with callbacks have the correct error response (`NOT_CONTROLLER`)
* explicit typing for `ControllerEvent` methods

Author: jeff kim <jeff.kim@confluent.io>

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>,Stanislav Kozlovski <stanislav@confluent.io>, David Arthur <mumrah@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #9050 from jeffkbkim/KAFKA-10193-controller-events-add-preemption",2020-08-07 22:49:16,jeff kim,Not TDD
92828d53b18703000159f4dd7dc8b3170667db25,"KAFKA-10261: Introduce the KIP-478 apis with adapters (#9004)

Adds the new Processor and ProcessorContext interfaces
as proposed in KIP-478. To integrate in a staged fashion
with the code base, adapters are included to convert back
and forth between the new and old APIs.

ProcessorNode is converted to the new APIs.

Reviewers: Boyang Chen <boyang@confluent.io>",2020-08-09 21:05:25,John Roesler,Mixed
7915d5e5f826a71c11e1c9183c84702410f7209a,"KAFKA-9450: Decouple flushing state from commiting (#8964)

In Kafka Streams the source-of-truth of a state store is in its changelog, therefore when committing a state store we only need to make sure its changelog records are all flushed and committed, but we do not actually need to make sure that the materialized state have to be flushed and persisted since they can always be restored from changelog when necessary.

On the other hand, flushing a state store too frequently may have side effects, e.g. rocksDB flushing would gets the memtable into an L0 sstable, leaving many small L0 files to be compacted later, which introduces larger overhead.

Therefore this PR decouples flushing from committing, such that we do not always flush the state store upon committing, but only when sufficient data has been written since last time flushed. The checkpoint file would then also be overwritten only along with flushing the state store indicating its current known snapshot. This is okay since: a) if EOS is not enabled, then it is fine if the local persisted state is actually ahead of the checkpoint, b) if EOS is enabled, then we would never write a checkpoint file until close.

Here's a more detailed change list of this PR:

1. Do not always flush state stores when calling pre-commit; move stateMgr.flush into post-commit to couple together with checkpointing.

2. In post-commit, we checkpoint when: a) The state store's snapshot has progressed much further compared to the previous checkpoint, b) When the task is being closed, in which case we enforce checkpointing.

3. There are some tricky obstacles that I'd have to work around in a bit hacky way: for cache / suppression buffer, we still need to flush them in pre-commit to make sure all records sent via producers, while the underlying state store should not be flushed. I've decided to introduce a new API in CachingStateStore to be triggered in pre-commit.

I've also made some minor changes piggy-backed in this PR:

4. Do not delete checkpoint file upon loading it, and as a result simplify the checkpointNeeded logic, initializing the snapshotLastFlush to the loaded offsets.

5. In closing, also follow the commit -> suspend -> close ordering as in revocation / assignment.

6. If enforceCheckpoint == true during RUNNING, still calls maybeCheckpoint even with EOS since that is the case for suspending / closing.

Reviewers: John Roesler <john@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-08-11 20:21:41,Guozhang Wang,Mixed
89e12f3c6b4f37c405455d5cb0fca60f2be3ff92,"KAFKA-10388; Fix struct conversion logic for tagged structures (#9166)

The message generator was missing conversion logic for tagged structures. This led to casting errors when either `fromStruct` or `toStruct` were invoked. This patch also adds missing null checks in the serialization of tagged byte arrays, which was found from improved test coverage.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2020-08-12 08:29:59,Jason Gustafson,Not TDD
b937ec75677f8af13bf6fda686f07e9c62cdd20f,"KAFKA-9911: Add new PRODUCER_FENCED error code (#8549)

Add a separate error code as PRODUCER_FENCED to differentiate INVALID_PRODUCER_EPOCH. On broker side, replace INVALID_PRODUCER_EPOCH with PRODUCER_FENCED when the request version is the latest, while still returning INVALID_PRODUCER_EPOCH to older clients. On client side, simply handling INVALID_PRODUCER_EPOCH the same as PRODUCER_FENCED if from txn coordinator APIs.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-08-12 08:54:01,Boyang Chen,Mixed
d0800b3f7c135c97ec8632c247fc02946527c0a2,"KAFKA-10391: Overwrite checkpoint in task corruption to remove corrupted partitions (#9170)

In order to do this, I also removed the optimization such that once enforced checkpoint is set to true, we always checkpoint unless the state stores are not initialized at all (i.e. the snapshot is null).

Reviewers: Boyang Chen <boyang@confluent.io>, A. Sophie Blee-Goldman <ableegoldman@gmail.com>",2020-08-12 21:20:53,Guozhang Wang,Mixed
3a189ad868151b71b0bdcc6ffd428a9bc25cd531,"KAFKA-10386; Fix flexible version support for `records` type (#9163)

This patch fixes the generated serde logic for the 'records' type so that it uses the compact byte array representation consistently when flexible versions are enabled.

Reviewers: David Arthur <mumrah@gmail.com>",2020-08-13 09:52:23,Jason Gustafson,Mixed
5645d906fa319206a9270c080926a21dfddc852a,"KAFKA-9924: Prepare RocksDB and metrics for RocksDB properties recording (#9098)

Refactor the RocksDB store and the metrics infrastructure in Streams
in preparation of the recordings of the RocksDB properties specified in KIP-607.

The refactoring includes:
* wrapper around BlockedBasedTableConfig to make the cache accessible to the
  RocksDB metrics recorder
* RocksDB metrics recorder now takes also the DB instance and the cache in addition
  to the statistics
* The value providers for the metrics are added to the RockDB metrics recorder also if
  the recording level is INFO.
* The creation of the RocksDB metrics recording trigger is moved to StreamsMetricsImpl

Reviewers: Guozhang Wang <wangguoz@gmail.com>, John Roesler <vvcephei@apache.org>",2020-08-13 14:40:40,Bruno Cadonna,Mixed
e034fedbd369461c7a673fa877b67638c7b1d952,"KAFKA-10387: Fix inclusion of transformation configs when topic creation is enabled in Connect (#9172)

Addition of configs for custom topic creation with KIP-158 created a regression when transformation configs are also included in the configuration of a source connector. 

To experience the issue, just enabling topic creation at the worker is not sufficient. A user needs to supply a source connector configuration that contains both transformations and custom topic creation properties. 

The issue is that the enrichment of configs in `SourceConnectorConfig` happens on top of an `AbstractConfig` rather than a `ConnectorConfig`. Inheriting from the latter allows enrichment to be composable for both topic creation and transformations. 

Unit tests and integration tests are written to test these combinations. 

Reviewers: Randall Hauch <rhauch@gmail.com>",2020-08-16 21:12:50,Konstantine Karantasis,Not TDD
e8b2dcdee6f25e9344d52b84e86328ec616bf819,"KAFKA-10023: Enforce broker-wide and per-listener connection creation… (#8768)

Implements the part of KIP-612 that adds broker configurations for broker-wide and per-listener connection creation rate limits and enforces these limits.

Reviewers: David Jacot <djacot@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2020-08-17 14:35:27,Anna Povzner,Mixed
21dc5231ce9c7398c7ede4dbefa2f2202e06b2d4,"KAFKA-9705 part 1: add KIP-590 request header fields (#9144)

Reviewers: Colin P. McCabe <cmccabe@apache.org>, David Jacot <david.jacot@gmail.com>",2020-08-18 13:38:59,Boyang Chen,Mixed
88d4bc4641064d21a481ba3b8562a4c97703d64d,"KAFKA-10379: Implement the KIP-478 StreamBuilder#addGlobalStore() (#9148)

From KIP-478, implement the new StreamBuilder#addGlobalStore() overload
that takes a stateUpdateSupplier fully typed Processor<KIn, VIn, Void, Void>.

Where necessary, use the adapters to make the old APIs defer to the new ones,
as well as limiting the scope of this change set.

Reviewers: Boyang Chen <boyang@apache.org>",2020-08-20 14:06:16,John Roesler,Mixed
1a9697430a8a6da575fdc7e96c1aa9a5640295df,"KAFKA-8806 Reduce calls to validateOffsetsIfNeeded (#7222)

Only check if positions need validation if there is new metadata. 

Also fix some inefficient java.util.stream code in the hot path of SubscriptionState.",2020-08-21 10:25:52,David Arthur,Mixed
89d06780a0f5f27a7420fc2cd8063294367f6693,"KAFKA-9929: Support reverse iterator on KeyValueStore (#9137)

Add new methods to KeyValueStore interfaces to support reverse iteration.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <vvcephei@apache.org>",2020-08-21 20:29:40,Jorge Esteban Quilcate Otoya,Mixed
8b94e6229548cc4fc015b2dc1e756ce86b5e84bb,"KAFKA-10211: Add DirectoryConfigProvider (#9136)

See KIP-632: https://cwiki.apache.org/confluence/display/KAFKA/KIP-632%3A+Add+DirectoryConfigProvider

Reviewers: Mickael Maison <mickael.maison@gmail.com>, David Jacot <david.jacot@gmail.com>",2020-08-22 17:10:48,Tom Bentley,Mixed
8af7b96bfbffb2455191beac41ec8db4f6d24e3b,"KAFKA-10367: Allow running the Streams demo app with a config file (#9131)

Update the 3 WordCount demos to accept a configuration file.

Reviewers: Matthias J. Sax <mjsax@apache.org>",2020-08-22 18:00:00,Mickael Maison,Mixed
f19cd6ca48ccd2971948c9589279bb8ee20e5d88,"KAFKA-10312; Fix error code returned in Metadata response when leader is not available (#9112)

MetadataCache#getPartitionMetadata returns an error when the topic's leader Id
is present at MetadataCache but listener endpoint is not present for this leader.
For older versions, LEADER_NOT_AVAILABLE is returned while LISTENER_NOT_FOUND is
returned for new metadata versions.

The problem is that getPartitionMetadata was looking up MetadataCache's host brokerId rather
than the topic's leader id while determining what error to return. This
could result in the call returning LISTENER_NOT_FOUND when it should
have returned LEADER_NOT_AVAILABLE. This commit corrects this behavior.

Unit tests were already present to test out the error codes returned
under different situations but they were giving out a false positive.
The test was using same broker id for both the MetadataCache's host as
well as for the topic's leader. Error manifests when the MetadataCache's
host id is changed. Improved the test.

This commit also consolidated couple of related tests to reduce code
duplication.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-08-24 11:18:59,Raman Verma,Mixed
22bcd9fac3c988c15862d0b6c01930814b676253,"KAFKA-10054: KIP-613, add TRACE-level e2e latency metrics (#9094)

Adds avg, min, and max e2e latency metrics at the new TRACE level. Also adds the missing avg task-level metric at the INFO level.

I think where we left off with the KIP, the TRACE-level metrics were still defined to be ""stateful-processor-level"". I realized this doesn't really make sense and would be pretty much impossible to define given the DFS processing approach of Streams, and felt that store-level metrics made more sense to begin with. I haven't updated the KIP yet so I could get some initial feedback on this

Reviewers: Bruno Cadonna <bruno@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-08-24 17:37:49,A. Sophie Blee-Goldman,Mixed
b6ba67482f9365ec982f88e4b456859696099e33,"KAFKA-10384: Separate converters from generated messages (#9194)

For the generated message code, put the JSON conversion functionality
in a separate JsonConverter class.

Make MessageDataGenerator simply another generator class, alongside the
new JsonConverterGenerator class.  Move some of the utility functions
from MessageDataGenerator into FieldSpec and other places, so that they
can be used by other generator classes.

Use argparse4j to support a better command-line for the generator.

Reviewers: David Arthur <mumrah@gmail.com>",2020-08-26 15:10:09,Colin Patrick McCabe,Mixed
9da32b6bd014f1bdeeee5da8fcd00995a5916323,"KAFKA-9924: Add RocksDB metric num-entries-active-mem-table (#9177)

* Add the first RocksDB metric that exposes a RocksDB property: num-entries-active-mem-table.
* Add code StreamsMetricsImpl in support of exposing RocksDB properties
* unit tests and intergration tests

This commit only contains one metric to keep the PR at a reasonable size.
All other RocksDB metrics described in KIP-607 will be added in other PRs.

Implements: KIP-607
Reviewers: Guozhang Wang <guozhang@apache.org>, John Roesler <vvcephei@apache.org>",2020-08-27 18:04:28,Bruno Cadonna,Mixed
85b6545b8159885c57ab67e08b7185be8a607988,"KAFKA-5636: SlidingWindows (KIP-450) (#9039)

Add SlidingWindows API, implementation, and tests.
An edge case and an optimization are left to follow-on work.

Implements: KIP-450

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <mjsax@apache.org>, John Roesler <vvcephei@apache.org>",2020-08-31 17:22:00,leah,Mixed
d0111d3bcdc6f86d9d9daf2f75b89e32e28a7541,"KAFKA-10020: Create a new version of a scala Serdes without name clash (KIP-616) (#8955)

Wildcard import of the old org.apache.kafka.streams.scala.Serdes leads
to a name clash because some of implicits has the same names as types
from the scala's std lib. The new oak.streams.scala.serialization.Serdes is
the same as the old Serdes, but without name clashes.
The old one is marked as deprecated.

Also, add missing serdes for UUID, ByteBuffer and Short types in
the new Serdes.

Implements: KIP-616

Reviewers: John Roesler <vvcephei@apache.org>",2020-09-01 16:48:40,Yuriy Badalyantc,Mixed
4f06d9e7d083c30912c810f9deadea809fd74edf,"KAFKA-9929: Support backward iterator on WindowStore (#9138)

Implements KIP-617 on WindowStore that depends on #9137.

Testing strategy: extend existing tests to validate reverse operations are supported.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-09-02 15:17:07,Jorge Esteban Quilcate Otoya,Mixed
c04000cab1e98c206c5410ef68d00df1d9129182,"KAFKA-9924: Add remaining property-based RocksDB metrics as described in KIP-607 (#9232)

This commit adds the remaining property-based RocksDB metrics as described in KIP-607, except for num-entries-active-mem-table, which was added in PR #9177.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-09-02 15:32:17,Bruno Cadonna,Mixed
1e31354557f49ab4a887aac0b71916da53b22d50,"KAFKA-10355: Throw error when source topic was deleted (#9191)

Before this commit, Kafka Streams would gracefully shut down the whole application when a source topic is deleted. The graceful shutdown does not give the user the possibility to react on the deletion of the source topic in the uncaught exception handler.

This commit changes this behavior and throws an error when a source topic is deleted.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@apache.org>, John Roesler <vvcephei@apache.org>",2020-09-03 14:16:14,Bruno Cadonna,Mixed
23cade850678eeae1bc1227a2a2a4bc09b02f2fc,"KAFKA-10314: KafkaStorageException on reassignment when offline log directories exist (#9122)

Make sure that we set the isNew field in LeaderAndIsrRequest correctly for brokers
that gets added to the replica set on reassignment.

This is tested by creating a variant of ControllerIntergationTest.testPartitionReassignment()
that makes one of the log directories on the target broker offline before initiating the
reassignment. Without the change to the way isNew is set, this fails after a timeout. With
the change, it succeeds.

To facilitate calling causeLogDirFailure() both from ControllerIntegrationTest and
LogDirFailureTest, the method was moved to TestUtils along with the other helper
methods that deals with interacting with KafkaServer instances for test cases.

Reviewers: Mickael Maison <mickael.maison@gmail.com>",2020-09-04 17:34:31,Noa Resare,Not TDD
e8524ccd8fca0caac79b844d87e98e9c055f76fb,"KAFKA-10259: KIP-554 Broker-side SCRAM Config API (#9032)

Implement the KIP-554 API to create, describe, and alter SCRAM user configurations via the AdminClient.  Add ducktape tests, and modify JUnit tests to test and use the new API where appropriate.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Rajini Sivaram <rajinisivaram@googlemail.com>",2020-09-04 13:05:01,Ron Dagostino,Mixed
d2521855b8eb8a0dbb6f94cd9bb5093276fb7db2,"KAFKA-10432; LeaderEpochCache is incorrectly recovered for leader epoch 0 (#9219)

The leader epoch cache is incorrectly recovered for epoch 0 as the
assignment is skipped when epoch == 0. This check was likely intended to
prevent negative epochs from being applied or there was an assumption
that epochs started at 1.

A test has been added to LogSegmentTest to show the LogSegment
recovery path works for the epoch cache. This was a test gap as none of the 
recover calls supply a leader epoch cache to recover.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-09-08 12:43:36,Lucas Bradstreet,Mixed
4ea709dc454a2c2635ef65ebf835025d82f177de,"KAFKA-10403: Replace Scala collection by Java collection in Log4jController (#9182)

This removes the need to have the Scala library in the classpath
when deserializing the MBean.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2020-09-09 07:44:04,Chia-Ping Tsai,Not TDD
09d1498e3065eccc26a2d396ea13e7c8b553b974,"KAFKA-10436: Implement KIP-478 Topology changes (#9221)

Convert Topology#addProcessor and #addGlobalStore
Also, convert some of the internals in support of addProcessor

Reviewers: Bill Bejeck <bbejeck@apache.org>",2020-09-09 12:37:21,John Roesler,Mixed
dd2b9eca5d6eee507d3c5baaf0647554e201fe18,"KAFKA-5636: Improve handling of ""early"" records in sliding windows (#9157)

Update for KIP-450 to handle ""early"" records.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-09-09 12:02:19,leah,Mixed
c2273adc25b2bab0a3ac95bf7844fedf2860b40b,"KAFKA-8334 Make sure the thread which tries to complete delayed reque… (#8657)

The main changes of this PR are shown below.

1. replace tryLock by lock for DelayedOperation#maybeTryComplete
2. complete the delayed requests without holding group lock

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",2020-09-09 14:42:37,Chia-Ping Tsai,Mixed
86013dc9f8cf02813418f41c3c49c745f9ee6ea5,"MINOR: add ImplicitLinkedHashCollection#moveToEnd (#9269)

Add ImplicitLinkedHashCollection#moveToEnd.

Refactor ImplicitLinkedHashCollectionIterator to be a little bit more
robust against concurrent modifications to the map (which admittedly
should not happen.)

Reviewers: Jason Gustafson <jason@confluent.io>",2020-09-09 17:29:12,Colin Patrick McCabe,Mixed
6bba661e24d0a133bfbccef841fcd8f1e057ef6b,"MINOR: remove DelayedOperations.checkAndCompleteFetch (#9278)

Reviewers: Jun Rao <junrao@gmail.com>",2020-09-10 08:50:28,Chia-Ping Tsai,Mixed
e7f1cffd97fdf9f1186877cfc7e082153e483eae,"MINOR: Fix JSON generation of nested structs with non-matching type/name (#9277)

The schema specification allows a struct type name to differ from the field name. This works with the generated `Message` classes, but not with the generated JSON converter. The patch fixes the problem, which is that the type name is getting replaced with the field name when the struct is registered in the `StructRegistry`.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2020-09-10 13:27:20,Jason Gustafson,Mixed
5ee3ecb1e3bb4f6a8f8e344229c1a88b1d230e73,"MINOR: Add debug logs for StreamThread (#9267)

Add debug logs to see when Streams calls poll, process, commit, etc.

Reviewers: Walker Carlson <wcarlson@confluent.io>, Guozhang Wang <guozhang@apache.org>",2020-09-10 15:47:16,John Roesler,Mixed
7e7bb184d2abe34280a7f0eb0f0d9fc0e32389f2,"KAFKA-10134: Enable heartbeat during PrepareRebalance and Depend On State For Poll Timeout (#8834)

1. Split the consumer coordinator's REBALANCING state into PREPARING_REBALANCE and COMPLETING_REBALANCE. The first is when the join group request is sent, and the second is after the join group response is received. During the first state we should still not send hb since it shares the same socket with the join group request and the group coordinator has disabled timeout, however when we transit to the second state we should start sending hb in case leader's assign takes long time. This is also for fixing KAFKA-10122.

2. When deciding coordinator#timeToNextPoll, do not count in timeToNextHeartbeat if the state is in UNJOINED or PREPARING_REBALANCE since we would disable hb and hence its timer would not be updated.

3. On the broker side, allow hb received during PREPARING_REBALANCE, return NONE error code instead of REBALANCE_IN_PROGRESS. However on client side, we still need to ignore REBALANCE_IN_PROGRESS if state is COMPLETING_REBALANCE in case it is talking to an old versioned broker.

4. Piggy-backing a log4j improvement on the broker coordinator for triggering rebalance reason, as I found it a bit blurred during the investigation. Also subsumed #9038 with log4j improvements.

The tricky part for allowing hb during COMPLETING_REBALANCE is in two parts: 1) before the sync-group response is received, a hb response may have reset the generation; also after the sync-group response but before the callback is triggered, a hb response can still reset the generation, we need to handle both cases by checking the generation / state. 2) with the hb thread enabled, the sync-group request may be sent by the hb thread even if the caller thread did not call poll yet.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>, John Roesler <john@confluent.io>",2020-09-10 14:34:38,Guozhang Wang,Mixed
7d0086e0c35d827a46e82956f42af57f6a6539f1,"KAFKA-10447: Migrate tools module to JUnit 5 (#9231)

This change sets the groundwork for migrating other modules incrementally.

Main changes:
- Replace `junit` 4.13 with `junit-jupiter` and `junit-vintage` 5.7.0-RC1.
- All modules except for `tools` depend on `junit-vintage`.
- `tools` depends on `junit-jupiter`.
- Convert `tools` tests to JUnit 5.
- Update `PushHttpMetricsReporterTest` to use `mockito` instead of `powermock` and `easymock`
(powermock doesn't seem to work well with JUnit 5 and we don't need it since mockito can mock
static methods).
- Update `mockito` to 3.5.7.
- Update `TestUtils` to use JUnit 5 assertions since `tools` depends on it.

Unrelated clean-ups:
- Remove `unit` from package names in a few `core` tests.
- Replace `try/catch/fail` with `assertThrows` in a number of places.
- Tag `CoordinatorTest` as integration test.
- Remove unnecessary type parameters when invoking methods and constructors.

Tested with IntelliJ and gradle. Verified that the following commands work as expected:
* ./gradlew tools:unitTest
* ./gradlew tools:integrationTest
* ./gradlew tools:test
* ./gradlew core:unitTest
* ./gradlew core:integrationTest
* ./gradlew clients:test

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2020-09-10 16:14:38,Ismael Juma,Not TDD
2194ccba5b95657ff7d6a4739edc98cf70f4472b,"Adding reverse iterator usage for sliding windows processing (extending KIP-450) (#9239)

Add a backwardFetch call to the window store for sliding window
processing. While the implementation works with the forward call
to the window store, using backwardFetch allows for the iterator
to be closed earlier, making implementation more efficient.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <vvcephei@apache.org>",2020-09-11 16:38:17,leah,Mixed
77a0bba140cbf2b249194ac7ba962813cf69fe0c,"KAFKA-8362: fix the old checkpoint won't be removed after alter log dir (#9178)

In KIP-113, we support replicas movement between log directories. But while the directory change, we forgot to remove the topicPartition offset data in old directory, which will cause there are more than 1 checkpoint copy stayed in the logs for the altered topicPartition. And it'll let the LogCleaner get stuck due to it's possible to always get the old topicPartition offset data from the old checkpoint file.

I added one more parameter topicPartitionToBeRemoved in updateCheckpoints() method. So, if the update parameter is None (as before), we'll do the remove action to remove the topicPartitionToBeRemoved data in dir, otherwise, update the data as before.

Reviewers: Jun Rao <junrao@gmail.com>",2020-09-14 08:50:45,Luke Chen,Mixed
94e61c3979dbdd4884772bd41a0acca7dd5b1712,"KAFKA-10458; Updating controller quota does not work since Token Bucket (#9272)

This PR fixes two issues that have been introduced by #9114.
- When the metric was switched from Rate to TokenBucket in the ControllerMutationQuotaManager, the metrics were mixed up. That broke the quota update path.
- When a quota is updated, the ClientQuotaManager updates the MetricConfig of the KafkaMetric. That update was not reflected into the Sensor so the Sensor was still using the MetricConfig that it has been created with.

Reviewers: Anna Povzner <anna@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2020-09-14 19:48:47,David Jacot,Mixed
ebd64b5d558f5500f419e7e66499ba9ffc30dc04,"KAFKA-10131: Remove use_zk_connection flag from ducktape (#9274)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2020-09-14 15:56:21,Ron Dagostino,Mixed
634c9175054cc69d10b6da22ea1e95edff6a4747,"KAFKA-10435; Fetch protocol changes for KIP-595 (#9275)

This patch bumps the `Fetch` protocol as specified by KIP-595: https://cwiki.apache.org/confluence/display/KAFKA/KIP-595%3A+A+Raft+Protocol+for+the+Metadata+Quorum. The main differences are the following:

- Truncation detection 
- Leader discovery through the response
- Flexible version support

The most notable change is truncation detection. This patch adds logic in the request handling path to detect truncation, but it does not change the replica fetchers to make use of this capability. This will be done separately.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2020-09-15 13:38:16,Jason Gustafson,Mixed
aa5263fba903c85812c0c31443f7d49ee371e9db,"KAFKA-10487; Fetch response should return diverging epoch and end offset (#9290)

This patch changes the Fetch response schema to include both the diverging epoch and its end offset rather than just the offset. This allows for more accurate truncation on the follower. This is the schema that was originally specified in KIP-595, but we altered it during the discussion.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2020-09-16 09:05:08,Jason Gustafson,Mixed
97d1a3248a4184da1e8ef47c1b94986665b941bf,"MINOR: Fix common struct `JsonConverter` and `Schema` generation (#9279)

This patch fixes a couple problems with the use of the `StructRegistry`. First, it fixes registration so that it is consistently based on the typename of the struct. Previously structs were registered under the field name which meant that fields which referred to common structs resulted in multiple entries. Second, the patch fixes `SchemaGenerator` so that common structs are considered first.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2020-09-17 14:37:51,Jason Gustafson,Mixed
59c1d4ece309311dc670c280eea37953049ed19d,"MINOR: Generator config-specific HTML ids (#8878)

Currently the docs have HTML ids for each config key. That doesn't work
correctly for config keys like bootstrap.servers which occur across
producer, consumer, admin configs: We generate duplicate ids. So arrange
for each config to prefix the ids it generates with the HTML id of its
section heading.

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2020-09-19 17:05:13,Tom Bentley,Mixed
4b6d8da9fd5bbc7e90c062c4d2131437183349a0,"KAFKA-10438: Lazy initialization of record header to reduce memory usage (#9223)

There are no checks on the header key so instantiating key (bytes to string) is unnecessary.
One implication is that conversion failures will be detected a bit later, but this is consistent
with how we handle the header value.

**JMH RESULT**

1. ops: +12%
1. The optimization of memory usage is very small as the cost of creating extra ```ByteBuffer``` is
almost same to byte array copy (used to construct ```String```). Using large key results in better
improvement but I don't think large key is common case.

**BEFORE**
```
Benchmark                                                                     (bufferSupplierStr)  (bytes)  (compressionType)  (headerKeySize)  (maxBatchSize)  (maxHeaderSize)  (messageSize)  (messageVersion)   Mode  Cnt        Score      Error   Units
RecordBatchIterationBenchmark.measureValidation                                        NO_CACHING   RANDOM               NONE               10             200                5           1000                 2  thrpt   15  2035938.174 ± 1653.566   ops/s
RecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm                    NO_CACHING   RANDOM               NONE               10             200                5           1000                 2  thrpt   15     2040.000 ±    0.001    B/op
```

```
Benchmark                                                                     (bufferSupplierStr)  (bytes)  (compressionType)  (headerKeySize)  (maxBatchSize)  (maxHeaderSize)  (messageSize)  (messageVersion)   Mode  Cnt        Score      Error   Units
RecordBatchIterationBenchmark.measureValidation                                        NO_CACHING   RANDOM               NONE               30             200                5           1000                 2  thrpt   15  1979193.376 ± 1239.286   ops/s
RecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm                    NO_CACHING   RANDOM               NONE               30             200                5           1000                 2  thrpt   15     2120.000 ±    0.001    B/op
```


**AFTER**

```
Benchmark                                                                     (bufferSupplierStr)  (bytes)  (compressionType)  (headerKeySize)  (maxBatchSize)  (maxHeaderSize)  (messageSize)  (messageVersion)   Mode  Cnt        Score      Error   Units
RecordBatchIterationBenchmark.measureValidation                                        NO_CACHING   RANDOM               NONE               10             200                5           1000                 2  thrpt   15  2289115.973 ± 2661.856   ops/s
RecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm                    NO_CACHING   RANDOM               NONE               10             200                5           1000                 2  thrpt   15     2032.000 ±    0.001    B/op
```

```
Benchmark                                                                     (bufferSupplierStr)  (bytes)  (compressionType)  (headerKeySize)  (maxBatchSize)  (maxHeaderSize)  (messageSize)  (messageVersion)   Mode  Cnt        Score     Error   Units
RecordBatchIterationBenchmark.measureValidation                                        NO_CACHING   RANDOM               NONE               30             200                5           1000                 2  thrpt   15  2222625.706 ± 908.358   ops/s
RecordBatchIterationBenchmark.measureValidation:·gc.alloc.rate.norm                    NO_CACHING   RANDOM               NONE               30             200                5           1000                 2  thrpt   15     2040.000 ±   0.001    B/op
```

Reviewers: Ismael Juma <ismael@juma.me.uk>",2020-09-21 08:03:49,Chia-Ping Tsai,Mixed
5cf5cc2fc0141eedc6a3204162b99ca67df27109,"KAFKA-10401; Ensure `currentStateTimeStamp` is set correctly by group coordinator (#9202)

Fix the `currentStateTimeStamp` doesn't get set in `GROUP_METADATA_VALUE_SCHEMA_V3`, and did a small refactor to use the `GROUP_VALUE_SCHEMAS.size - 1` replace the default hard-coded max version number. Also add test for it.

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2020-09-21 13:35:16,Luke Chen,Mixed
ac89e49bf217941d436e2160732f8c045d2a4d3b,"MINOR: Use `Map.forKeyValue` to avoid tuple allocation in Scala 2.13 (#9299)

`forKeyValue` invokes `foreachEntry` in Scala 2.13 and falls back to
`foreach` in Scala 2.12.

This change requires a newer version of scala-collection-compat, so
update it to the latest version (2.2.0).

Finally, included a minor clean-up in `GetOffsetShell` to use `toArray`
before `sortBy` since it's more efficient.

Reviewers: Jason Gustafson <jason@confluent.io>, David Jacot <djacot@confluent.io>, José Armando García Sancio <jsancio@users.noreply.github.com>, Chia-Ping Tsai <chia7712@gmail.com>",2020-09-21 16:04:19,Ismael Juma,Not TDD
90517d15c0fb09f09168e77aff7ad30f234b1091,"KAFKA-10068: add task assignment performance tests (#8892)

Add tests to bound the performance of the various Streams task assignors
when making assignments over large clusters/tasks.

Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",2020-09-22 09:20:46,A. Sophie Blee-Goldman,Mixed
285328420c4fd9c025a34fe2ce0583136809c5db,"MINOR: Fix log message when tasks directory is cleaned manually (#9262)

Currently when a task directory is cleaned manually the message
for the state dir cleaner is logged instead of the message for
the manual cleanup. This is because the code checks the elapsed
time since the last update before it checks whether the cleanup
is a manual call. This commit changes the order of the checks.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Matthias J. Sax <mjsax@apache.org>, Walker Carlson <wcarlson@confluent.io>, John Roesler <vvcephei@apache.org>",2020-09-22 11:12:25,Bruno Cadonna,Mixed
b7c8490cf47b0c18253d6a776b2b35c76c71c65d,"KAFKA-10492; Core Kafka Raft Implementation (KIP-595) (#9130)

This is the core Raft implementation specified by KIP-595: https://cwiki.apache.org/confluence/display/KAFKA/KIP-595%3A+A+Raft+Protocol+for+the+Metadata+Quorum. We have created a separate ""raft"" module where most of the logic resides. The new APIs introduced in this patch in order to support Raft election and such are disabled in the server until the integration with the controller is complete. Until then, there is a standalone server which can be used for testing the performance of the Raft implementation. See `raft/README.md` for details.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Boyang Chen <boyang@confluent.io>

Co-authored-by: Boyang Chen <boyang@confluent.io>
Co-authored-by: Guozhang Wang <wangguoz@gmail.com>",2020-09-22 11:32:44,Jason Gustafson,Mixed
bc7674fe1bd50bfa8e6b568ab84d112412b1d3e5,"KAFKA-10505: Fix parsing of generation log string. (#9312)

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",2020-09-23 14:24:02,Nikolay,Not TDD
7abed3dbb092fdbd0c7a3afd1bd4081f2ba63bc4,"KAFKA-9450: Follow-up; Forbid process after closed (#9083)

A few cleanup and tighten screws:
* When a processor is closed (due to topology-closure), we should not allow processing more records.
* Let all built-in processors to extend from AbstractProcessor.
* Remove duplicated override functions.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>",2020-09-23 14:36:56,Guozhang Wang,Mixed
51957de80606609232d5346a0aa86a945173317d,"MINOR: Use JUnit 5 in raft module (#9331)

I also removed a test class with no tests currently (Jason filed KAFKA-10519 for
filling the test gap).

Reviewers: Jason Gustafson <jason@confluent.io>",2020-09-24 02:37:17,Ismael Juma,Not TDD
785de1e3d459b26c3ce383986827719388be7c6f,"KAFKA-9627: Replace ListOffset request/response with automated protocol (#8295)


Reviewers: Boyang Chen <reluctanthero104@gmail.com>, David Jacot <djacot@confluent.io>

Co-authored-by: Mickael Maison <mickael.maison@gmail.com>
Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>",2020-09-24 15:53:59,Mickael Maison,Mixed
bca2a4e0d36139b5816edd935537324eb2b30233,"MINOR: clarify variables for skipping idempotent source updates (#9316)

Reviewers: Guozhang Wang <guozhang@apache.org>",2020-09-24 09:25:35,John Roesler,Mixed
57de67db22eb373f92ec5dd449d317ed2bc8b8d1,"KAFKA-8836; Add `AlterISR` RPC and use it for ISR modifications (#9100)

This patch implements [KIP-497](https://cwiki.apache.org/confluence/display/KAFKA/KIP-497%3A+Add+inter-broker+API+to+alter+ISR), which introduces an asynchronous API for partition leaders to update ISR state.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-09-24 16:28:25,David Arthur,Mixed
89485fe137588531744752bd772aabe78cd4f374,"KAFKA-10516; Disable automatic retry of `THROTTLING_QUOTA_EXCEEDED` errors in the `kafka-topics` command (KIP-599) (#9334)

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2020-09-25 15:57:19,David Jacot,Not TDD
ac8acec65380bb97d1de6696c7ac870c2156c115,"KAFKA-10519; Add missing unit test for `VotedState` (#9337)

Add a simple unit test for `VotedState`. 

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-09-25 09:12:56,Jason Gustafson,Mixed
466f8fd21c6651ea5daa50154239e85fa629dbb4,"MINOR: Use the automated protocol for the Consumer Protocol's subscriptions and assignments (#8897)

This PR moves the consumer protocol to using the automated protocol instead of using plain old structs.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-09-25 09:21:22,David Jacot,Mixed
dc81d442dfc5c3d8d9c069942f6b00e2de377a3c,"KAFKA-10077: Filter downstream of state-store results in spurious tombstones (#9156)

Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-09-25 13:58:04,Andy Coates,Mixed
ae2304f27c5a099b52cc9dd707fc237576deada0,"KAFKA-10509: Added throttle connection accept rate metric (KIP-612) (#9317)

This commit adds metric to track throttle time of connection accept rate (when hitting connection attempt rate quota), which is a part of KIP-612. Also does 2 fixes:
  - Ensures that per-listener connection quotas are configured on broker startup (from static broker config, if one is set).
  - Reduces quota values used in testDynamicListenerConnectionCreationRateQuota test, and the duration of verifyConnectionRate (that creates connections and verifies rate). We observed once that this test exhausted ephemeral port count. I reduced quotas used in this test by half, since this does not change the correctness of the test, while it also reduces the number of connections made by this test.

Reviewers: David Jacot <djacot@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2020-09-28 20:30:25,Anna Povzner,Not TDD
340cd07bab7ea0f9caeb0cbf50987bbe38cf126f,"KAFKA-9584: Fix Headers ConcurrentModificationException in Streams (#8181)

Avoid forwarding a shared reference to the record context in punctuate calls.
Note, this fix isn't airtight, since all processors triggered by a single punctuate
call will still see the same reference to the record context. It's also not a terribly
principled approach, since the context is still technically not defined, but this
is about the best we can do without significant refactoring. We will probably
follow up with a more comprehensive solution, but this should avoid the issue
for most programs.

Reviewers: Matthias J. Sax <mjsax@apache.org>, John Roesler <vvcephei@apache.org>",2020-09-28 14:56:36,Micah Paul Ramos,Mixed
17fa3d92967c8d3493e4636a7e394db371afb18f,"KAFKA-10218: Stop reading config topic in every subsequent tick if catchup fails once (#8973)

Add logic to reset the existing `canReadConfigs` in `DistributedHerder` once the herder is able to successfully read the configs again. Added unit test to verify the functionality.

Author: Chris Egerton <chrise@confluent.io>
Reviewer: Nigel Liang <nigel@nigelliang.com>, Randall Hauch <rhauch@gmail.com>",2020-09-28 18:30:01,Chris Egerton,Mixed
dbe3e4a4cccce06836b59c2f3853669e008eb58f,"KAFKA-10511; Ensure monotonic start epoch/offset updates in `MockLog` (#9332)

There is a minor difference in behavior between the epoch caching logic in `MockLog` from the behavior in `LeaderEpochFileCache`. The latter ensures that every new epoch/start offset entry added to the cache increases monotonically over the previous entries. This patch brings the behavior of `MockLog` in line. 

It also simplifies the `assignEpochStartOffset` api in `ReplicatedLog`. We always intend to use the log end offset, so this patch removes the start offset parameter.

Reviewers: Boyang Chen <boyang@confluent.io>",2020-09-28 17:16:55,Jason Gustafson,Mixed
a0fec75d3cee3d23bd517fe0acc65270a6cb0f88,"MINOR; Preserve ThrottlingQuotaExceededException when request timeouts after being retried due to a quota violation (KIP-599) (#9344)

This PR adds the logic to preserve the ThrottlingQuotaExceededException when topics are retried. The throttleTimeMs is also adjusted accordingly as the request could remain pending or in-flight for quite a long time.

Have run various tests on clusters with enabled quotas and I, indeed, find it better to preserve the exception. Otherwise, the caller does not really understand what is going on. This allows the caller to take the appropriate measure and also to take the throttleTimeMs into consideration.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2020-09-29 15:17:37,David Jacot,Mixed
821c1ac6641845aeca96a43bc2b946ecec5cba4f,"KAFKA-10479; Throw exception if users try to update non-reconfigurable configs of existing listeners (#9284)

The previous dynamic configuration validation did not actually compare new configs to original configs as intended, so the expected exception was not thrown.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>, Jason Gustafson <jason@confluent.io>",2020-09-29 12:15:08,Chia-Ping Tsai,Mixed
fda67018375ce3f6b90658e1ae9c30ab463e0240,"KAFKA-10469: Resolve logger levels hierarchically (#9266)

Previous to root logger level was used, ignoring intervening loggers with
different levels.

Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Lee Dongjin <dongjin@apache.org>, Ismael Juma <ismael@juma.me.uk>",2020-09-30 06:51:02,Tom Bentley,Not TDD
2fda4458b4d8e65cee255879f1a0a9cf858506a3,"KAFKA-6585: Consolidate duplicated logic on reset tools (#9255)

Reviewers: Navinder Pal Singh Brar <navinder_brar@yahoo.com>, Matthias J. Sax <matthias@confluent.io>",2020-09-30 10:13:01,manijndl7,Mixed
6e0a10b41ab1a5e68fc1d5b972a91dd43a86c40e,"KAFKA-10277: Allow null keys with non-null mappedKey in KStreamKGlobalTable join (#9186)

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-09-30 11:59:11,JoelWee,Not TDD
d1c82a9baf5f3a0d3bde3ec35157358f7a62ecc8,"KAFKA-10205: Documentation and handling of non deterministic Topologies (#9064)

Reviewers: John Roesler <john@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-09-30 12:06:11,Igor Soarez,Mixed
a15387f34d142684859c2a57fcbef25edcdce25a,"KAFKA-9274: Revert deprecation of `retries` for producer and admin clients (#9333)

Reviewer: John Roesler <john@confluent.io>",2020-09-30 12:13:34,Matthias J. Sax,Mixed
95986a8f48da47645659556e2b03149e138d1d4e,"MINOR: Fix KStreamKTableJoinTest and StreamTaskTest (#9357)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-09-30 20:07:23,leah,Not TDD
b8090add335903e6daf38ea99d0f94be5a5e6ed4,"KAFKA-10326: Both serializer and deserializer should be able to see generated ID (#9102)

Reviewers: Boyang Chen <boyang@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-09-30 20:23:07,Chia-Ping Tsai,Mixed
901bf57c0825f4ae88d057a99020344b4b26baab,"KAFKA-10503: MockProducer doesn't throw ClassCastException when no partition for topic exists (#9309)

Reviewer: Matthias J. Sax <matthias@confluent.io>",2020-09-30 22:31:07,Gonzalo Muñoz,Mixed
ad17ea10890872ddd1264681d61e2c5a40382590,"KAFKA-10556: NPE if sasl.mechanism is unrecognized (#9356)

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2020-10-01 09:20:25,Ron Dagostino,Not TDD
3bc2df7651d8b9029d2478a3f39b3b223c0532b7,"KAFKA-10134 Follow-up: Set the re-join flag in heartbeat failure (#9354)

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Boyang Chen <boyang@confluent.io>",2020-10-01 17:57:00,Guozhang Wang,Not TDD
57c221689998d99a200d91320a1c33d37169b7dd,"KAFKA-10478: Allow duplicated ports in advertised.listeners (#9281)

Remove the requirement for unique port numbers for the advertised.listener parameters.
This restriction makes for the listeners parameter but there's not reason to apply the
same logic for advertised.listeners.

Being able to do this opens possibilities for some practical applications when using
Kerberos authentication. For example, when configuring Kafka using Kerberos authentication
and a Load Balancer we need to have two SASL_SSL listeners: (A) one running with the
kafka/hostname principal and (B) another using kafka/lb_name, which is necessary for
proper authentication when using the LB FQDN. After bootstrap, though, the client receives
the brokers' addresses with the actual host FQDNs advertised by the brokers. To connect
to the brokerd using the hostnames the client must connect to the listener A to be able to
authenticate successfully with Kerberos.

Author: Andre Araujo <asdaraujo@gmail.com>

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>, Tom Bentley <tbentley@redhat.com>",2020-10-02 10:59:15,Andre Araujo,Mixed
3edb94eb231f33b42e3420541632b38fb349d9c2,"KAFKA-10557: Missing docs when describing topic configs including (#9360)


Reviewers: Rajini Sivaram <rajinisivaram@gmail.com>

Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>
Co-authored-by: Mickael Maison <mickael.maison@gmail.com>",2020-10-02 11:09:10,Edoardo Comar,Mixed
ca559a2dcf1a2a29f635401111c743b5da1bd81d,"KAFKA-10477: Fix JsonConverter regression to treat MISSING nodes as NULL nodes (#9306)

Fixes a regression introduced in `JsonConverter` with previous upgrades from Jackson Databind 2.9.x to 2.10.x. Jackson Databind version 2.10.0 included a backward-incompatible behavioral change to use `JsonNodeType.MISSING` (and `MissingNode`, the subclass of `JsonNode` that has a type of `MISSING`) instead of `JsonNodeType.NULL` / `NullNode`. See https://github.com/FasterXML/jackson-databind/issues/2211 for details of this change.

This change makes recovers the older `JsonConverter` behavior of returning null on empty input.

Added two unit tests for this change. Both unit tests were independently tested with earlier released versions and passed on all versions that used Jackson 2.9.x and earlier, and failed on all versions that used 2.10.x and that did not have the fixed included in the PR. Both of the new unit tests pass with this fix to `JsonConverter`.

Author: Shaik Zakir Hussain <zhussain@confluent.io>
Reviewer: Randall Hauch <rhauch@gmail.com>",2020-10-02 09:21:11,Shaik Zakir Hussain,Mixed
6b95f1ec57c303b758f0bea4cc96943108adce2c,"KAFKA-10048: Possible data gap for a consumer after a failover when using MM2 (#8730)

Ensure that the MM2 checkpoint mirror task replicates consumer offsets even when they are
zero to avoid issues with consumers after failovers.

Author: Andre Araujo <asdaraujo@gmail.com>

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ryanne Dolan <ryannedolan@gmail.com>, Edoardo Comar <ecomar@uk.ibm.com>, heritamas",2020-10-02 18:34:50,Andre Araujo,Not TDD
69790a1463bafc1f63e3c288a6636b3f4586c1b4,"KAFKA-10535: Split ProcessorContext into Processor/StateStore/Record Contexts (#9361)

Migrate different components of the old ProcessorContext interface
into separate interfaces that are more appropriate for their usages.
See KIP-478 for the details.

Reviewers: Guozhang Wang <guozhang@apache.org>, Paul Whalen <pgwhalen@gmail.com>",2020-10-02 18:49:12,John Roesler,Mixed
e0f215bbd3d1da21e97ad03c4375f4e7225b1a82,"MINOR: Add proper checks to KafkaConsumer.groupMetadata (#9349)

Add following checks to `KafkaConsumer.groupMetadata`:

1. null check of coordinator (replace NPE by `InvalidGroupIdException` which is same to other methods)
2. concurrent check (`groupMetadata` is not thread-safe so concurrent check is necessary)

Reviewers: Jason Gustafson <jason@confluent.io>",2020-10-05 14:14:51,Chia-Ping Tsai,Mixed
06a5a68a933a2f03619382f191c53720f8359e72,"KAFKA-10439: Connect's Values to parse BigInteger as Decimal with zero scale. (#9320)

The `org.apache.kafka.connect.data.Values#parse` method parses integers, which are larger than `Long.MAX_VALUE` as `double` with `Schema.FLOAT64_SCHEMA`.

That means we are losing precision for these larger integers.

For example:
`SchemaAndValue schemaAndValue = Values.parseString(""9223372036854775808"");`
returns:
`SchemaAndValue{schema=Schema{FLOAT64}, value=9.223372036854776E18}`

Also, this method parses values that can be parsed as `FLOAT32` to `FLOAT64`.

This PR changes parsing logic, to use `FLOAT32`/`FLOAT64` for numbers that don't have fraction part(`decimal.scale()!=0`) only, and use an arbitrary-precision `org.apache.kafka.connect.data.Decimal` otherwise.
Also, it updates the method to parse numbers, that can be represented as `float` to `FLOAT64`.

Added unit tests, that cover parsing `BigInteger`, `Byte`, `Short`, `Integer`, `Long`, `Float`, `Double` types.

Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>",2020-10-05 17:24:44,Alex Diachenko,Mixed
c77183dbb323d1aa4b72ebcfedeac9947c3c76d0,"KAFKA-6733: Printing additional ConsumerRecord fields in DefaultMessageFormatter (#9099)

Implementation of KIP-431 - Support of printing additional ConsumerRecord fields in DefaultMessageFormatter

https://cwiki.apache.org/confluence/display/KAFKA/KIP-431%3A+Support+of+printing+additional+ConsumerRecord+fields+in+DefaultMessageFormatter

Reviewers: David Jacot <djacot@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",2020-10-06 10:50:06,Badai Aqrandista,Mixed
53a35c1de3970513e75517fb4e776c961dc2aff5,"MINOR: Refactor unit tests around RocksDBConfigSetter (#9358)

* Extract the mock RocksDBConfigSetter into a separate class.
* De-dup unit tests covering RocksDBConfigSetter.

Reviewers: Boyang Chen <boyang@confluent.io>",2020-10-06 09:09:54,Guozhang Wang,Not TDD
05f9803d72ba2eeedd10901ebf3a39ed2240f092,"KAFKA-10527; Voters should not reinitialize as leader in same epoch (#9348)

One of the invariants that the raft replication protocol relies on is that each record is uniquely identified by leader epoch and offset. This can be violated if a leader remains elected with the same epoch between restarts since unflushed data could be lost.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-10-06 10:11:56,Jason Gustafson,Mixed
7be8bd8cbfea5cc19f815a142c4689e97728ea4b,"KAFKA-10338; Support PEM format for SSL key and trust stores (KIP-651) (#9345)

Adds support for SSL key and trust stores to be specified in PEM format either as files or directly as configuration values.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2020-10-06 19:13:43,Rajini Sivaram,Mixed
4c6b96296db0d5fea2e7cf85ac14c9cc783b8d54,KAFKA-10188: Prevent SinkTask::preCommit from being called after SinkTask::stop (#8910),2020-10-06 13:18:54,Chris Egerton,Mixed
75e53585255a0c2737dee84ddbad39094c5e8500,"Revert ""KAFKA-10469: Resolve logger levels hierarchically (#9266)""

This reverts commit fda67018375ce3f6b90658e1ae9c30ab463e0240.

It includes changes in the specified behavior, so a KIP must be
submitted and approved before we can make the change.",2020-10-07 07:12:16,Ismael Juma,Not TDD
40a23cc0c2e1efa8632f59b093672221a3c03c36,"KAFKA-10186; Abort transaction with pending data with TransactionAbortedException (#9280)

If a transaction is aborted with no underlying exception, throw a new kind of exception - `TransactionAbortedException` to
distinguish this from other fatal exceptions.

This API change is documented in KIP-654: https://cwiki.apache.org/confluence/display/KAFKA/KIP-654:+Aborted+transaction+with+non-flushed+data+should+throw+a+non-fatal+exception.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Jason Gustafson <jason@confluent.io>",2020-10-07 09:34:39,Gokul Srinivas,Mixed
4e65030e055104a7526e85b563a11890c61d6ddf,"KAFKA-10402: Upgrade system tests to python3 (#9196)

For now, Kafka system tests use python2 which is outdated and not supported.
This PR upgrades python to the third version.

Reviewers: Ivan Daschinskiy, Mickael Maison <mickael.maison@gmail.com>, Magnus Edenhill <magnus@edenhill.se>, Guozhang Wang <wangguoz@gmail.com>",2020-10-07 09:41:30,Nikolay,Mixed
fb4f297207ef62f71e4a6d2d0dac75752933043d,"KAFKA-10028: Implement write path for feature versioning system (KIP-584) (#9001)

Summary:
In this PR, I have implemented the write path of the feature versioning system (KIP-584). Here is a summary of what's in this PR:

New APIs in org.apache.kafka.clients.admin.Admin interface, and their client and server implementations. These APIs can be used to describe features and update finalized features. These APIs are: Admin#describeFeatures and Admin#updateFeatures.
The write path is provided by the Admin#updateFeatures API. The corresponding server-side implementation is provided in KafkaApis and KafkaController classes. This can be a good place to start the code review.
The write path is supplemented by Admin#describeFeatures client API. This does not translate 1:1 to a server-side API. Instead, under the hood the API makes an explicit ApiVersionsRequest to the Broker to fetch the supported and finalized features.
Implemented a suite of integration tests in UpdateFeaturesTest.scala that thoroughly exercises the various cases in the write path.

Other changes:

The data type of the FinalizedFeaturesEpoch field in ApiVersionsResponse has been modified from int32 to int64. This change is to conform with the latest changes to the KIP explained in the voting thread.
Along the way, the class SupportedFeatures has been renamed to be called BrokerFeatures, and, it now holds both supported features as well as default minimum version levels.
For the purpose of testing, both the BrokerFeatures and FinalizedFeatureCache classes have been changed to be no longer singleton in implementation. Instead, these are now instantiated once and maintained in KafkaServer. The singleton instances are passed around to various classes, as needed.

Reviewers: Boyang Chen <boyang@confluent.io>, Jun Rao <junrao@gmail.com>",2020-10-07 10:23:16,Kowshik Prakasam,Mixed
a8b5f5a430412aa6536beb2a93237a1b768693c5,"KAFKA-10362: When resuming Streams active task with EOS, the checkpoint file is deleted (#9247)

Deleted the checkpoint file before the transition from SUSPENDED state to RESTORING state

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-10-07 11:20:06,Sharath Bhat,Mixed
65c29a9dec3c8b14775344c2edf5c929ec5d1694,"KAFKA-9274: fix incorrect default value for `task.timeout.ms` config (#9385)

 - part of KIP-572
 - also add handler method to trigger/reset the timeout on a task

Reviewer: John Roesler <john@confluent.io>",2020-10-07 12:17:47,Matthias J. Sax,Mixed
250c71b532605172693ada6ac93a68909fe0b2b6,"KAFKA-10564: only process non-empty task directories when internally cleaning obsolete state stores (#9373)

Avoid continuous repeated logging by not trying to clean empty task directories, which are longer fully deleted during internal cleanup as of https://issues.apache.org/jira/browse/KAFKA-6647.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2020-10-07 15:48:35,Michael Bingham,Mixed
8d4bbf22ad1918dd03300fa48221b71563286f8e,"MINOR: trivial cleanups, javadoc errors, omitted StateStore tests, etc. (#8130)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-10-07 19:08:31,Lee Dongjin,Mixed
2804257fe221f37e5098bd3f633a5d76ca890634,"KAFKA-10562: Properly invoke new StateStoreContext init (#9388)

* all wrapping stores should pass StateStoreContext init through to the same
  method on the wrapped store and not translate it to ProcessorContext init
* base-level stores should handle StateStoreContext init so that callers passing
  a non-InternalProcessorContext implementation will be able to initialize the store
* extra tests are added to verify the desired behavior

Reviewers: Guozhang Wang <guozhang@apache.org>",2020-10-07 23:06:53,John Roesler,Mixed
d0e6943bdd048aa6e0a4dbbdad3c8da460db16dc,"KAFKA-9929: Support backward iterator on SessionStore (#9139)

Implements KIP-617 for `SessionStore`

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, John Roesler <vvcephei@apache.org>",2020-10-08 08:08:24,Jorge Esteban Quilcate Otoya,Mixed
de546ba827d7e8286e4157e83ee271a7b3681d6b,"MINOR: correct package of LinuxIoMetricsCollector (#9271)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Lee Dongjin <dongjin@apache.org>",2020-10-08 16:58:50,Chia-Ping Tsai,Mixed
de4183485b0be534738010b19944edf3388cf49b,"KAFKA-10028: Minor fixes to describeFeatures and updateFeatures apis (#9393)

In this PR, I have addressed the review comments from @chia7712 in #9001 which were provided after #9001 was merged. The changes are made mainly to KafkaAdminClient:

Improve error message in updateFeatures api when feature name is empty.
Propagate top-level error message in updateFeatures api.
Add an empty-parameter variety for describeFeatures api.
Minor documentation updates to @param and @return to make these resemble other apis.

Reviewers: Chia-Ping Tsai chia7712@gmail.com, Jun Rao junrao@gmail.com",2020-10-08 10:05:29,Kowshik Prakasam,Mixed
cc54000e722f2b258ad6e04643189327bebc5b77,"KAFKA-10271: Performance regression while fetching a key from a single partition (#9020)

StreamThreadStateStoreProvider excessive loop over calling internalTopologyBuilder.topicGroups(), which is synchronized, thus causing significant performance degradation to the caller, especially when store has many partitions.

Reviewers: John Roesler <vvcephei@apache.org>, Guozhang Wang <wangguoz@gmail.com>",2020-10-08 10:12:33,Dima Reznik,Mixed
5fc3f73f087a0c85a79e39a9a4b85e827c570c2d,"KAFKA-7334: Suggest changing config for state.dir in case of FileNotFoundException (#9380)

Add additional warning logs and improve existing log messages for `FileNotFoundException` and if /tmp is used as state directory.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-10-08 12:20:21,voffcheg109,Mixed
4ab72780dd95c788a3b4fc22906543ae7cf1948d,"KAFKA-10571; Replace blackout with backoff for KIP-629

This replaces code and comment occurrences as described in the KIP

Author: Xavier Léauté <xvrl@apache.org>

Reviewers: Gwen Shapira, Mickael Maison

Closes #9366 from xvrl/kafka-10571",2020-10-08 15:54:59,Xavier Léauté,Mixed
7947c18b5788fd12841de649a662336f7d3d14d8,"MINOR update comments and docs to be gender-neutral

While this is not technically part of KIP-629, I believe this makes our codebase more inclusive as well.

cc gwenshap

Author: Xavier Léauté <xvrl@apache.org>

Reviewers: Gwen Shapira

Closes #9398 from xvrl/neutral-term",2020-10-08 17:05:15,Xavier Léauté,Not TDD
147a19036ee4bce9091575f23e1338527c618290,"MINOR: ACLs for secured cluster system tests (#9378)

This PR adds missing broker ACLs required to create topics and SCRAM credentials when ACLs are enabled for a system test. This PR also adds support for using PLAINTEXT as the inter broker security protocol when using SCRAM from the client in a system test with a secured cluster-- without this it would always be necessary to set both the inter-broker and client mechanisms to a SCRAM mechanism. Also contains some refactoring to make assumptions clearer.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2020-10-09 15:34:53,Ron Dagostino,Not TDD
24290de82821d16f7d163d086f5cfa88cec2b976,"KAFKA-9393: DeleteRecords may cause extreme lock contention for large partition directories (#7929)

This PR avoids a performance issue with DeleteRecords when a partition directory contains high numbers of files. Previously, DeleteRecords would iterate the partition directory searching for producer state snapshot files. With this change, the iteration is removed in favor of keeping a 1:1 mapping between producer state snapshot file and segment file. A segment files corresponding producer state snapshot file is now deleted when the segment file is deleted.

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",2020-10-09 14:25:01,Gardner Vickers,Mixed
1f8ac6e6fee3aa404fc1a4c01ac2e0c48429a306,"KAFKA-10598: Improve IQ name and type checks (#9408)

Previously, we would throw a confusing error, ""the store has migrated,""
when users ask for a store that is not in the topology at all, or when the
type of the store doesn't match the QueryableStoreType parameter.

Adds an up-front check that the requested store is registered and also
a better error message when the QueryableStoreType parameter
doesn't match the store's type.

Reviewers: Guozhang Wang <guozhang@apache.org>",2020-10-12 09:34:32,John Roesler,Mixed
0a93d2b1af68ebe4601802cb366f57f20eb2a466,"KAFKA-10574: Fix infinite loop in Values::parseString (#9375)

Fix infinite loop in Values::parseString

Author: Chris Egerton <chrise@confluent.io>
Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Randall Hauch <rhauch@gmail.com>",2020-10-12 11:42:42,Chris Egerton,Mixed
aba9036eb681597911343510e246de4fc547a479,"KAFKA-10143; Improve test coverage for throttle changes during reassignment (#8891)

In KIP-455, we changed the behavior of the reassignment tool so that the `--additional` flag is required in order to use the command to alter the throttle. This patch improves the documentation to make this clearer and adds some integration tests to validate the behavior.

This patch also contains a few minor code quality improvements:

- Factor out a helper `calculateCurrentMoveMap` from `calculateMoveMap` to compute the current move map, which makes the logic easier to follow
- Rename `calculateMoveMap` to `calculateProposedMoveMap` to make intention clearer
- Split `modifyBrokerThrottles` into two methods `modifyLogDirThrottle` and `modifyInterBrokerThrottle`
- Move logic to compute leader and follower throttles into a new method `modifyReassignmentThrottle`, which takes it out of the execution path when log dir throttles are changed
- Minor stylistic improvements such as replacing `.map.flatten` with `.flatMap`

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",2020-10-12 12:36:46,Jason Gustafson,Not TDD
a72f0c1eac67d531a4725d3e48dcab4dce361b95,"KAFKA-10533; KafkaRaftClient should flush log after appends (#9352)

This patch adds missing flush logic to `KafkaRaftClient`. The initial flushing behavior is simplistic. We guarantee that the leader will not replicate above the last flushed offset and we guarantee that the follower will not fetch data above its own flush point. More sophisticated flush behavior is proposed in KAFKA-10526.

We have also extended the simulation test so that it covers flush behavior. When a node is shutdown, all unflushed data is lost. We were able to confirm that the monotonic high watermark invariant fails without the added `flush` calls.

This patch also piggybacks a fix to the `TestRaftServer` implementation. The initial check-in contained a bug which caused `RequestChannel` to fail sending responses because the disabled APIs did not have metrics registered. As a result of this, it is impossible to elect leaders.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-10-13 08:59:02,Jason Gustafson,Mixed
27b0e35e7a98f94c341a10a58e20dee177054712,"KAFKA-10437: Implement new PAPI support for test-utils (#9396)

Implements KIP-478 for the test-utils module:
* adds mocks of the new ProcessorContext and StateStoreContext
* adds tests that all stores and store builders are usable with the new mock
* adds tests that the new Processor api is usable with the new mock
* updates the demonstration Processor to the new api

Reviewers: Guozhang Wang <guozhang@apache.org>",2020-10-13 11:15:22,John Roesler,Mixed
40ad4fe0ae9c687ed3c4d35fb5f5830cb1a867b8,"KAFKA-10494: Eager handling of sending old values (#9415)

Nodes that are materialized should not forward requests to `enableSendingOldValues` to parent nodes, as they themselves can handle fulfilling this request. However, some instances of `KTableProcessorSupplier` were still forwarding requests to parent nodes, which was causing unnecessary materialization of table sources.

The following instances of `KTableProcessorSupplier` have been updated to not forward `enableSendingOldValues` to parent nodes if they themselves are materialized and can handle sending old values downstream:

 * `KTableFilter`
 * `KTableMapValues`
 * `KTableTransformValues`

Other instances of `KTableProcessorSupplier` have not be modified for reasons given below:
 * `KTableSuppressProcessorSupplier`: though it has a `storeName` field, it didn't seem right for this to handle sending old values itself. Its only job is to suppress output.
 * `KTableKTableAbstractJoin`: doesn't have a store name, i.e. it is never materialized, so can't handle the call itself.
 * `KTableKTableJoinMerger`: table-table joins already have materialized sources, which are sending old values. It would be an unnecessary performance hit to have this class do a lookup to retrieve the old value from its store.
 * `KTableReduce`: is always materialized and already handling the call without forwarding
 * `KTableAggregate`: is always materialized and already handling the call without forwarding

Reviewer: Matthias J. Sax <matthias@confluent.io>",2020-10-13 11:19:05,Andy Coates,Mixed
f46d4f4fce341326c06c0aa8b2d0d64982573658,"KAFKA-10570; Rename JMXReporter configs for KIP-629

* rename whitelist/blacklist to include/exclude
* add utility methods to translate deprecated configs

Author: Xavier Léauté <xvrl@apache.org>

Reviewers: Gwen Shapira

Closes #9367 from xvrl/kafka-10570",2020-10-13 12:33:05,Xavier Léauté,Mixed
0c044a77cb6a93130bf2f357f478c00344e0aad6,"MINOR rename kafka.utils.Whitelist to IncludeList

rename internal classes, methods, and related constants for KIP-629

Author: Xavier Léauté <xvrl@apache.org>

Reviewers: Gwen Shapira

Closes #9400 from xvrl/rename-topic-includelist",2020-10-13 12:36:52,Xavier Léauté,Mixed
26e9058aa0426102117aa00f1bbb41fae66ff4ed,"MINOR internal KIP-629 changes to methods and variables

cc gwenshap

Author: Xavier Léauté <xvrl@apache.org>

Reviewers: Gwen Shapira

Closes #9405 from xvrl/minor-kip-629-vars",2020-10-13 14:52:04,Xavier Léauté,Not TDD
eab61cad2c418786ab5e58aa1267f689d82a61d1,"KAFKA-10573 Update connect transforms configs for KIP-629 (#9403)

Changes the Connect `ReplaceField` SMT's configuration properties, deprecating and replacing `blacklist` with `exclude`, and `whitelist` with `include`. The old configurations are still allowed (ensuring backward compatibility), but warning messages are written to the log to suggest users change to `include` and `exclude`.

This is part of KIP-629.

Author: Xavier Léauté <xvrl@apache.org>
Reviewer: Randall Hauch <rhauch@gmail.com>",2020-10-13 18:13:44,Xavier Léauté,Mixed
8118b6c9f9c3a8cc77dca2f6a516254f03a43d5e,"KAFKA-10521; Skip partition watch registration when `AlterIsr` is expected (#9353)

Before `AlterIsr` which was introduced in KIP-497, the controller would register watches in Zookeeper for each reassigning partition so that it could be notified immediately when the ISR was expanded and the reassignment could be completed. This notification is not needed with the latest IBP when `AlterIsr` is enabled because the controller will execute all ISR changes itself.

There is one subtle detail. If we are in the middle of a roll in order to bump the IBP, then it is possible for the controller to be on the latest IBP while some of the brokers are still on the older one. In this case, the brokers on the older IBP will not send `AlterIsr`, but we can still rely on the delayed notification through the `isr_notifications` path to complete reassignments. This seems like a reasonable tradeoff since it should be a short window before the roll is completed.

Reviewers: David Jacot <djacot@confluent.io>, Jun Rao <junrao@gmail.com>",2020-10-13 17:53:47,Jason Gustafson,Not TDD
7f9beeaaafdb1bc74a5f0c1386f7e01f5f831d6b,"MINOR: fix a bug in removing elements from an ImplicitLinkedHashColle… (#9428)

Fix a bug that was introduced by change 86013dc that resulted in incorrect behavior when
deleting through an iterator.

The bug is that the hash table relies on a denseness invariant... if you remove something,
you might have to move some other things. Calling removeElementAtSlot will do this.
Calling removeFromList is not enough.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-10-14 14:53:30,Colin Patrick McCabe,Mixed
c40985049fd02601913c95a71fcaa2481d57d403,"KAFKA-10613: Only set leader epoch when list-offset version >= 4 (#9438)

The leader epoch field is added in version 4, and the auto-generated protocol code would throw unsupported version exception if the field is set to any non-default values for version < 4. This would cause older versioned clients to never receive list-offset results.

Reviewers: Boyang Chen <boyang@confluent.io>",2020-10-15 10:01:51,Guozhang Wang,Not TDD
775a08876a636cc9f4b6cfd89e305b8becf44670,"KAFKA-10602: Make RetryWithToleranceOperator thread safe (#9422)

ErrantRecordReporter uses a RetryWithToleranceOperator instance, which is necessarily stateful, having a ProcessingContext of which there's supposed to be one per task. That ProcessingContext is used by both RetryWithToleranceOperator.executeFailed() and execute(), so it's not enough to just synchronize executeFailed().

So make all public methods of RetryWithToleranceOperator synchronized so that RetryWithToleranceOperator is now threadsafe.

Tested with the addition of a multithreaded test case that fails consistently if the methods are not properly synchronized. 

Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>",2020-10-15 11:54:46,Tom Bentley,Mixed
a85802faa1d5e050e921e35739b7aefe43b0f372,"KAFKA-10559: Not letting TimeoutException shutdown the app during internal topic validation (#9432)

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-10-15 15:10:21,vamossagar12,Mixed
e8ad80ebe152a2ae55272b538282e407acab5cc4,"MINOR: remove explicit passing of AdminClient into StreamsPartitionAssignor (#9384)

Currently, we pass multiple object reference (AdminClient,TaskManager, and a few more) into StreamsPartitionAssignor. Furthermore, we (miss)use TaskManager#mainConsumer() to get access to the main consumer (we need to do this, to avoid a cyclic dependency).

This PR unifies how object references are passed into a single ReferenceContainer class to
 - not ""miss use"" the TaskManager as reference container
 - unify how object references are passes

Note: we need to use a reference container to avoid cyclic dependencies, instead of using a config for each passed reference individually.

Reviewers: John Roesler <john@confluent.io>",2020-10-15 16:10:27,Matthias J. Sax,Mixed
fcc7c2de391cadad8edecb108d978ea50afd428d,"MINOR: Handle lastFetchedEpoch/divergingEpoch in FetchSession and DelayedFetch (#9434)

In 2.7, we added lastFetchedEpoch to fetch requests and divergingEpoch to fetch responses. We are not using these for truncation yet, but in order to use these for truncation with IBP 2.7 onwards in the next release, we should make sure that we handle these in all the supporting classes even in 2.7.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-10-16 09:58:01,Rajini Sivaram,Mixed
9e0bf0bd2a1a2ce3bb667b0568732ec2c7cdb39b,"KAFKA-10600: Connect should not add error to connector validation values for properties not in connector’s ConfigDef (#9425)

Connect should not always add an error to configuration values in validation results that don't have a `ConfigKey` defined in the connector's `ConfigDef`, and any errors on such configuration values included by the connector should be counted in the total number of errors. Added more unit tests for `AbstractHerder.generateResult(...)`.

Author: Randall Hauch <rhauch@gmail.com>
Reviewer: Konstantine Karantasis <konstantine@confluent.io>",2020-10-16 09:14:43,Randall Hauch,Mixed
cf202cb6acf38c64a3e8b9e541673a12ee55eaaa,"MINOR: Fix consumer/producer properties override (#9313)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ryanne Dolan <ryannedolan@gmail.com>",2020-10-16 18:17:03,Samuel Cantero,Mixed
50bcb34d8dd8bf97fe0cf9b9faccf705054b8c8b,"MINOR: fix potential NPE in PartitionData.equals (#9391)

the field metadata is nullable (see https://github.com/apache/kafka/blob/trunk/clients/src/main/resources/common/message/OffsetFetchResponse.json#L50)

Reviewers: David Jacot <david.jacot@gmail.com>",2020-10-18 21:29:13,Chia-Ping Tsai,Mixed
270881cd65fa9d6e12c4a6b755c5abe2ae852dc1,"KAFKA-10332: Update MM2 refreshTopicPartitions() logic (#9343)

Trigger task reconfiguration when:
- topic-partitions are created or deleted on source cluster
- topic-partitions are missing on target cluster

Authors: Mickael Maison <mickael.maison@gmail.com>, Edoardo Comar <ecomar@uk.ibm.com>
Reviewer: Randall Hauch <rhauch@gmail.com>",2020-10-19 10:51:44,Mickael Maison,Mixed
d99fe49234d94bbd7893c130edbb8c7138a180c2,"KAFKA-10599: Implement basic CLI tool for feature versioning system (#9409)

This PR implements a basic CLI tool for feature versioning system. The KIP-584 write up has been updated to suit this PR. The following is implemented in this PR:

--describe:
Describe supported and finalized features.
Usage: $> ./bin/kafka-features.sh --bootstrap-server host1:port1, host2:port2 --describe [--from-controller] [--command-config <path_to_java_properties_file>]
Optionally, use the --from-controller option to get features from the controller.
--upgrade-all:
Upgrades all features known to the tool to their highest max version levels.
Usage: $> ./bin/kafka-features.sh --bootstrap-server host1:port1, host2:port2 --upgrade-all [--dry-run] [--command-config <path_to_java_properties_file>]
Optionally, use the --dry-run CLI option to preview the feature updates without actually applying them.
--downgrade-all:
Downgrades existing finalized features to the highest max version levels known to this tool.
Usage: $> ./bin/kafka-features.sh --bootstrap-server host1:port1, host2:port2 --downgrade-all [--dry-run] [--command-config <path_to_java_properties_file>].
Optionally, use the --dry-run CLI option to preview the feature updates without actually applying them.

Reviewers: Boyang Chen <boyang@confluent.io>, Jun Rao <junrao@gmail.com>",2020-10-19 09:24:26,Kowshik Prakasam,Mixed
aef6cd6e9995b42db2cefa7d715321d0edee5628,"KAFKA-9274: Add timeout handling for state restore and StandbyTasks (#9368)

* Part of KIP-572
* If a TimeoutException happens during restore of active tasks, or updating standby tasks, we need to trigger task.timeout.ms timeout.

Reviewers: John Roesler <john@confluent.io>",2020-10-19 11:07:56,Matthias J. Sax,Mixed
4d14d6a96c952a3e71a3b8e1c6d9c68e8dd4568b,"KAFKA-10455: Ensure that probing rebalances always occur (#9383)

Add dummy data to subscriptionUserData to make sure that
it is different each time a member rejoins.

Reviewers: A. Sophie Blee-Goldman <ableegoldman@apache.org>, John Roesler <vvcephei@apache.org>",2020-10-19 13:29:35,leah,Mixed
659b05f78a500aa5bf9cfb482a1df0fce8a46101,"KAFKA-10605: Deprecate old PAPI registration methods (#9448)

Add deprecation annotations to the methods replaced in KIP-478.

Reviewers: Bill Bejeck <bbejeck@apache.org>",2020-10-19 15:29:27,John Roesler,Mixed
8339d78ad2ded67bd2c8fcbe1989c9c842c5add7,"MINOR: the top-level error message of AlterPartitionReassignmentsResponseData does not get propagated correctly (#9392)

Reviewers: David Jacot <djacot@confluent.io>",2020-10-20 10:54:14,Chia-Ping Tsai,Mixed
e3d6344ed7feadae119a57ce658fe7dc0505ca06,"MINOR; Return timed out connections as a List instead of a Set (#8999)

Using a Set is not necessary as the caller only cares about having the list of timed out connections/nodes.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2020-10-20 08:36:22,David Jacot,Not TDD
f8e3b84ec068a9678c5389df11c74ad8ebf886f4,"MINOR: Use `PartitionResponse.errorMessage` in exceptions in KafkaProducer (#9450)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2020-10-20 10:15:01,Rajini Sivaram,Mixed
60d002f9ebfe8576dc900acfac97bcd29a3d2973,"KAFKA-10572 mirror-maker config changes for KIP-629 (#9429)

Author: Xavier Léauté <xavier@confluent.io>
Reviewer: Randall Hauch <rhauch@gmail.com>",2020-10-20 09:15:14,Xavier Léauté,Mixed
bb47519a42cd3cf157aa5be4687ff4592a3faee4,"KAFKA-10515: Properly initialize nullable Serdes with default values (#9338)

Also introduced the notion of WrappingNullableSerdes (aligned to the concept
of WrappingNullableSerializer and WrappingNullableDeserializer) and centralized
initialization in WrappingNullables.

The added integeration test KTableKTableForeignKeyJoinDistributedTest tests
whether all serdes are now correctly set on all stream clients.

Reviewers: John Roesler <vvcephei@apache.org>",2020-10-20 17:03:39,Thorsten Hake,Mixed
d87cd00f5acc3d48181b4b9f084bbc638184c903,"KAFKA-10454 / Update copartitionSourceGroups when optimization algorithm is triggered (#9237)

Fix KAFKA-10454 bug

Main issue was that when optimization algorithm was removing repartition nodes, corresponding copartitionSourceGroups was never updated. As a result, copartition enforcer wasn't able to do the checks and set proper number of partitions.

Test ensures that whenever optimization is set, changelog topic for the table is not created. And whenever optimization is turned off, appropriate changelog topic for the table is created.

Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",2020-10-20 18:39:37,Levani Kokhreidze,Not TDD
50a5671135df80209ea3c781acf9d77456b6b88c,"MINOR: Clean-up streams javadoc warnings (#9461)

Reviewers: Matthias J. Sax <mjsax@apache.org>,  John Roesler <john@confluent.io>",2020-10-20 19:30:49,Bill Bejeck,Not TDD
67bc4f08feb50ac135a4d8e1d469747102aad3a6,"KAFKA-10618: Add UUID class, use in protocols (part of KIP-516) (#9454)

In order to support topic IDs, we need to create a public UUID class. This class will be used in protocols. This PR creates the class, modifies code to use the class in the message protocol and changes the code surrounding the existing messages/json that used the old UUID class.

SimpleExampleMessage was used only for testing, so all usages of UUID have been switched to the new class.

SubscriptionInfoData uses UUID for processId extensively. It also utilizes java.util.UUID implementation of Comparable so that UUIDs can be ordered. This functionality was not necessary for the UUIDs used for topic IDs converted to java.util.UUID on the boundary of SubscriptionInfoData. Sorting was used only for testing, though, so this still may be changed.

Also added tests for the methods of the new UUID class. The existing SimpleExampleMessage tests should be sufficient for testing the new UUID class in message protocols.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2020-10-21 10:17:12,Justine Olshan,Mixed
5dc94b1ff4fc580c240def5bd65daef3840041e0,"MINOR: distinguish between missing source topics and internal assignment errors (#9446)

Introduce an ASSIGNMENT_ERROR code to distinguish from INCOMPLETE_SOURCE_TOPIC_METADATA and shut down all members in case of an unexpected exception during task assignment.

Reviewers: Matthias J. Sax <mjsax@apache.org>,  John Roesler <vvcephei@apache.org>",2020-10-21 09:06:25,A. Sophie Blee-Goldman,Mixed
1d26391368d146fc0b7be9abfcf98d3475d7a834,"KAFKA-10520; Ensure transactional producers poll if leastLoadedNode not available with max.in.flight=1 (#9406)

We currently stop polling in `Sender` in a transactional producer if there is only one broker in the bootstrap server list and `max.in.flight.requests.per.connection=1` and Metadata response is pending when InitProducerId request is ready to be sent. In this scenario, we attempt to send FindCoordinator to `leastLoadedNode`, but since that is blocked due to `max.in.flight=1` as a result of the pending metadata response, we never unblock unless we poll. This PR ensures we poll in this case.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>, David Jacot <djacot@confluent.io>",2020-10-21 12:07:27,Rajini Sivaram,Mixed
c283886b8edf65d1bf9fb10b5288929152d82af6,"MINOR: simplify implementation of ConsumerGroupOperationContext.hasCo… (#9449)

Reviewers: David Jacot <djacot@confluent.io>",2020-10-22 17:02:13,Chia-Ping Tsai,Mixed
58bd0a6ee383b54ad8f1f9c7213d0978108150b8,"MINOR: TopologyTestDriver should not require dummy parameters (#9477)

TopologyTestDriver comes with a paper cut that it passes through a
config requirement that application.id and bootstrap.servers must be
configured. But these configs are not required in the context of
TopologyTestDriver specifically. This change relaxes the requirement.

Reviewers: Boyang Chen <boyang@apache.org>, Matthias J. Sax <mjsax@apache.org>",2020-10-22 08:19:01,John Roesler,Mixed
7ca299b8c0f2f3256c40b694078e422350c20d19,"KAFKA-10284: Group membership update due to static member rejoin should be persisted (#9270)

Reviewers: Boyang Chen <boyang@apache.org>, John Roesler <vvcephei@apache.org>",2020-10-22 09:55:52,feyman2016,Mixed
17e30a8dbcca1493a5c27c0c576d5a12eb20bf03,"Handle ProducerFencedException on offset commit (#9479)

The transaction manager does currently not handle producer fenced errors returned from a offset commit request.

Adds the handling of the producer fenced errors.

Reviewers: Boyang Chen <boyang@apache.org>, John Roesler <vvcephei@apache.org>",2020-10-22 14:23:01,Bruno Cadonna,Mixed
25c10c8722bff22121f5d011f773e3af9b1b4fe0,"MINOR: Fix NPE in KafkaAdminClient.describeUserScramCredentials (#9374)

`KafkaAdminClient.describeUserScramCredentials` should not fail with a NPE when `users` is `null` as `null` means that all the users must be returned.

Reviewers: Ron Dagostino <rdagostino@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>",2020-10-26 17:22:04,Richard Fussenegger,Mixed
8f02b92fcf1bf33609cbe01ffdec5ba63e1023dc,"MINOR; DescribeUserScramCredentialsRequest API should handle request with users equals to `null` (#9504)

DescribeUserScramCredentialsRequest states that all users are described when Users is empty or null. null is not handled at the moment and throws an NPE.

Reviewers: Ron Dagostino <rdagostino@confluent.io>, Colin P. McCabe <cmccabe@apache.org>",2020-10-26 17:28:03,David Jacot,Not TDD
f1a7097ccd79ecba2c0640766d64ba0f1e3e313d,"KAFKA-10616: Always call prepare-commit before suspending for active tasks (#9464)

Today for active tasks we the following active task suspension:

1. closeAndRevive in handleTaskCorruption.
2. closeClean in assignor#onAssignment.
3. closeClean in shutdown.
4. closeDirty in assignor#onAssignment.
5. closeDirty in listener#onPartitionsLost.
6. closeDirty in shutdown.
7. suspend in listener#onPartitionsRevoked.

Among those, 1/4/5/6 do not call prepareCommit which would stateManager#flushCache and may cause illegal state manager. This PR would require a prepareCommit triggered before suspend.

Reviewers: A. Sophie Blee-Goldman <ableegoldman@apache.org>",2020-10-26 14:24:05,Guozhang Wang,Mixed
aa287acb2eed07cf6d75c10e71f051f538a57872,"KAFKA-10647; Only serialize owned partitions when consumer protocol version >= 1 (#9506)

A regression got introduced by https://github.com/apache/kafka/commit/466f8fd21c6651ea5daa50154239e85fa629dbb4. The owned partition field must be ignored for version < 1 otherwise the serialization fails with an unsupported version exception.

Reviewers: Jason Gustafson <jason@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2020-10-27 11:11:24,David Jacot,Mixed
927edfece3db8aab7d01850955f9a65e5c110da5,"KAFKA-10601; Add support for append linger to Raft implementation (#9418)

The patch adds `quorum.append.linger.ms` behavior to the raft implementation. This gives users a powerful knob to tune the impact of fsync.  When an append is accepted from the state machine, it is held in an accumulator (similar to the producer) until the configured linger time is exceeded. This allows the implementation to amortize fsync overhead at the expense of some write latency.

The patch also improves our methodology for testing performance. Up to now, we have relied on the producer performance test, but it is difficult to simulate expected controller loads because producer performance is limited by other factors such as the number of producer clients and head-of-line blocking. Instead, this patch adds a workload generator which runs on the leader after election.

Finally, this patch brings us nearer to the write semantics expected by the KIP-500 controller. It makes the following changes:

- Introduce `RecordSerde<T>` interface which abstracts the underlying log implementation from `RaftClient`. The generic type is carried over to `RaftClient<T>` and is exposed through the read/write APIs.
- `RaftClient.append` is changed to `RaftClient.scheduleAppend` and returns the last offset of the expected log append.
- `RaftClient.scheduleAppend` accepts a list of records and ensures that the full set are included in a single batch.
- Introduce `RaftClient.Listener` with a single `handleCommit` API which will eventually replace `RaftClient.read` in order to surface committed data to the controller state machine. Currently `handleCommit` is only used for records appended by the leader.

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",2020-10-27 12:10:13,Jason Gustafson,Mixed
9f26906fcc2fd095b7d27c504e342b9a8d619b4b,"Revert ""KAFKA-9705 part 1: add KIP-590 request header fields (#9144)"" (#9523)

This reverts commit 21dc5231ce9c7398c7ede4dbefa2f2202e06b2d4 as we decide to use Envelope for redirection instead of initial principal.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-10-28 22:57:10,Boyang Chen,Mixed
933a813950b1ae06e19ead23734fa6bdf1f32e3f,"KAFKA-10638: Fix QueryableStateIntegrationTest (#9521)

This test has been observed to have flaky failures.
Apparently, in the failed runs, Streams had entered a rebalance
before some of the assertions were made. We recently made
IQ a little stricter on whether it would return errors instead of
null responses in such cases:
KAFKA-10598: Improve IQ name and type checks (#9408)

As a result, we have started seeing failures now instead of
silently executing an invalid test (I.e., it was asserting the
return to be null, but the result was null for the wrong
reason).

Now, if the test discovers that Streams is no longer running,
it will repeat the verification until it actually gets a valid
positive or negative result.

Reviewers: Chia-Ping Tsai <chia7712@apache.org>",2020-10-29 11:57:31,John Roesler,Not TDD
cf78fbe41ed387e08dcb1b071c28f6dea03a5778,"MINOR: improve `null` checks for headers (#9513)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Luke Chen @showuon",2020-10-29 16:45:43,Matthias J. Sax,Mixed
92e947c3a11409e830fe2cc145c01973a11da756,"KAFKA-10664: Delete existing checkpoint when writing empty offsets (#9534)

Delete the existing checkpoint file if told to write empty offsets map to ensure that corrupted offsets are not re-initialized from

Reviewers: Bruno Cadonna <bruno@confluent.io>, Guozhang Wang <guozhang@apache.org>",2020-10-30 13:28:31,A. Sophie Blee-Goldman,Mixed
c75fd668751e7852f151661976bfaaae807d1cfe,"KAFKA-10651: read  offsets directly from checkpoint for uninitialized tasks (#9515)

Read offsets directly from the checkpoint file if a task is uninitialized or closed

Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",2020-10-30 13:36:35,A. Sophie Blee-Goldman,Mixed
236d7dc890e82c9b146579a8be801c1c7f54feb9,"KAFKA-10669: Make CurrentLeaderEpoch field ignorable and set MaxNumOffsets field default to 1

Couple of failures observed after KAFKA-9627: Replace ListOffset request/response with automated protocol (https://github.com/apache/kafka/pull/8295)

1. Latest consumer fails to consume from 0.10.0.1 brokers. Below system tests are failing
kafkatest.tests.client.client_compatibility_features_test.ClientCompatibilityFeaturesTest
kafkatest.tests.client.client_compatibility_produce_consume_test.ClientCompatibilityProduceConsumeTest

Solution: Current default value for MaxNumOffsets is 0. because to this brokers are not returning offsets for v0 request. Set default value for MaxNumOffsets field to 1.  This is similar to previous [approach]
(https://github.com/apache/kafka/blob/2.6/clients/src/main/java/org/apache/kafka/common/requests/ListOffsetRequest.java#L204)

2. In some scenarios, latest consumer fails with below error when connecting to a Kafka cluster which consists of newer and older (<=2.0) Kafka brokers
`org.apache.kafka.common.errors.UnsupportedVersionException: Attempted to write a non-default currentLeaderEpoch at version 3`

Solution: After #8295, consumer can set non-default CurrentLeaderEpoch value for v3 and below requests. One solution is to make CurrentLeaderEpoch ignorable.

Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: David Jacot <djacot@confluent.io>

Closes #9540 from omkreddy/fix-listoffsets",2020-11-02 23:39:03,Manikumar Reddy,Not TDD
be4c45286945ea91d703660e86811bd24f561aaa,"KAFKA-10471 Mark broker crash during log loading as unclean shutdown (#9364)

LogManager writes a clean shutdown file when the broker shuts down. The
presence of this file indicates that the broker had a clean shutdown and
log recovery is not needed upon the next boot up.

Earlier, LogManager would check for this file at the start of log loading workflow,
and delete it after the log has been loaded. If the broker were to crash
while loading logs, the file would not be deleted and mislead LogManager when it
tries to load logs upon next boot up. Hence, a crash during log loading
will not be considered a hard reset of broker.

As part of this fix, we delete the clean shutdown file as soon as we
look it up, at the start of log loading workflow. Thereafter, we maintain a boolean
flag to indicate if broker underwent clean shutdown or not. So, if the
broker were to crash while logs are being loaded, LogManager will be
able to detect this as a hard reset.

Reviewers: Jun Rao <junrao@gmail.com>",2020-11-02 13:07:14,Raman Verma,Mixed
21a65e10436fc81cac0518dd4babb9612eeaf667,"KAFKA-10632; Raft client should push all committed data to state machines (#9482)

In #9418, we add a listener to the `RaftClient` interface. In that patch, we used it only to send commit notifications for writes from the leader. In this PR, we extend the `handleCommit` API to accept all committed data and we remove the pull-based `read` API. Additionally, we add two new callbacks to the listener interface in order to notify the state machine when the raft client has claimed or resigned leadership.

Finally, this patch allows the `RaftClient` to support multiple listeners. This is necessary for KIP-500 because we will have one listener for the controller role and one for the broker role.

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Boyang Chen <boyang@confluent.io>",2020-11-02 15:06:58,Jason Gustafson,Mixed
b9e2a89c0f48f8fa0849b173a2846d3689201dd6,"MINOR: KIP-584: Remove admin client facility to read features from controller (#9536)

In this PR, I have eliminated the facility in Admin#describeFeatures API and it's implementation to be able to optionally send a describeFeatures request to the controller. This feature was not seen to be particularly useful, and besides it also poses some hindrance to post KIP-500 world where no client would be able to access the controller directly.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jun Rao <junrao@gmail.com>",2020-11-02 17:16:52,Kowshik Prakasam,Mixed
b3e77dfad93b9e4d2798ecf84e777c99905d380f,"KAFKA-10036: Improve handling and documentation of Suppliers (#9000)

Reviewer: Matthias J. Sax <matthias@confluent.io>",2020-11-03 17:30:15,Igor Soarez,Mixed
e847f057e31cbd50db854f12f2eafe0d1a865068,"KAFKA-10679: [Streams] migrate kafka-site updated docs to kafka/docs (#9554)

During the AK website upgrade, changes made to kafka-site weren't migrated back to kafka-docs.

This PR is an attempt at porting the streams changes to kafka/docs

For the most part, the bulk of the changes in the PR are cosmetic.

For testing:

I reviewed the PR diffs
Rendered the changes locally

Reviewers: John Roesler <john@confluent.io>",2020-11-04 08:30:10,Bill Bejeck,Mixed
5df8457e05f6808145e90f5637d7f8a4aed548d9,"KAFKA-7987: Reinitialize ZookeeperClient after auth failures (#7751)

Schedules client reinitialization if Zookeeper auth failure is encountered. This allows for reconnections when transient network errors are encountered during connection establishment. The Zookeeper client doesn't expose details of the auth failure so we can't determine whether an error is retriable or not, so all auth failures are retried.

Co-authored-by: Rajini Sivaram <rajinisivaram@googlemail.com>

Reviewers: Jun Rao <junrao@gmail.com>",2020-11-04 19:54:26,parafiend,Mixed
0814e4f645880a3c63102fc197c8912c63846ad5,"KAFKA-10181: Use Envelope RPC to do redirection for (Incremental)AlterConfig, AlterClientQuota and CreateTopics (#9103)

This PR adds support for forwarding of the following RPCs:

AlterConfigs
IncrementalAlterConfigs
AlterClientQuotas
CreateTopics

Co-authored-by: Jason Gustafson <jason@confluent.io>
Reviewers: Jason Gustafson <jason@confluent.io>",2020-11-04 14:21:44,Boyang Chen,Mixed
c3d0140a5577f85ee64f739f5f8832f54612de22,"KAFKA-10500: Makes the Stream thread list resizable (#9543)

Change the StreamThreads to be held in a List so that we
can dynamically change the number of threads easily.

Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",2020-11-05 15:02:00,Walker Carlson,Mixed
ff48edbed46f23600ab434deee57e3ef2da8ed28,"KAFKA-10624: For FeatureZNodeStatus, use sealed trait instead of Enumeration (#9561)

This is a follow-up to initial KIP-584 development. In this PR, I've switched the FeatureZNodeStatus enum to be a sealed trait. In Scala, we prefer sealed traits over Enumeration since the former gives you exhaustiveness checking. With Scala enumeration, you don't get a warning if you add a new value that is not handled in a given pattern match.

Reviewers: Jun Rao <junrao@gmail.com>",2020-11-05 15:55:13,Kowshik Prakasam,Not TDD
8e211eb72f9a45897cc37fed394a38096aa47feb,"MINOR: Always return partitions with diverging epochs in fetch response (#9567)

Reviewers: Jason Gustafson <jason@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2020-11-06 08:51:14,Rajini Sivaram,Mixed
f49c6c203f6ce5c4eb643907c7f164b47db65989,"KAFKA-10661; Add new resigned state for graceful shutdown/initialization (#9531)

When initializing the raft state machine after shutting down as a leader, we were previously entering the ""unattached"" state, which means we have no leader and no voted candidate. This was a bug because it allowed a reinitialized leader to cast a vote for a candidate in the same epoch that it was already the leader of. This patch fixes the problem by introducing a new ""resigned"" state which allows us to retain the leader state so that we cannot change our vote and we will not accept additional appends.

This patch also revamps the shutdown logic to make use of the new ""resigned"" state. Previously we had a separate path in `KafkaRaftClient.poll` for the shutdown logic which resulted in some duplication. Instead now we incorporate shutdown behavior into each state's respective logic.

Finally, this patch changes the shutdown logic so that `EndQuorumEpoch` is only sent by resigning leaders. Previously we allowed this request to be sent by candidates as well.

Reviewers: dengziming <dengziming1993@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2020-11-09 12:52:28,Jason Gustafson,Mixed
960e64072592bc1ad939518b58dbdfb17068680d,"KAFKA-10469: Respect logging hierarchy (KIP-676) (#9266)

Previously the root logger level was used, ignoring intervening loggers with
different levels.

This was initially applied via fda67018375 and reverted via 75e53585255a0
due to the fact that the previous behavior was specified in KIP-412. It
has been been reapplied since KIP-676 has been approved.

Reviewers: Stanislav Kozlovski <stanislav_kozlovski@outlook.com>, Lee Dongjin <dongjin@apache.org>, Ismael Juma <ismael@juma.me.uk>",2020-11-10 06:19:36,Tom Bentley,Not TDD
ab64e58320b82aed7c30a5cca5b816dd605b7963,"migrate remaining RPCs (#9558)

This PR follows up 0814e4f to migrate the remaining RPCs which need forwarding, including:
CreateAcls/DeleteAcls/CreateDelegationToken/RenewDelegationToken/ExpireDelegationToken/AlterPartitionReassignment/CreatePartition/DeleteTopics/UpdateFeatures/Scram

Reviewers: David Arthur <mumrah@gmail.com>",2020-11-10 09:18:40,Boyang Chen,Mixed
bb34c5c8cc32d1b769a34329e34b83cda040aafc,"KAFKA-10350: add forwarding manager implementation with metrics (#9580)

add forwarding manager implementation with metrics

Reviewers: David Arthur <mumrah@gmail.com>",2020-11-11 23:21:10,Boyang Chen,Mixed
0b9c7512bf20da2b7123e0e14ec38790906651b8,"KAFKA-10705: Make state stores not readable by others (#9583)

Change permissions on the folders for the state store so they're no readable or writable by ""others"", but still accessible by owner and group members.

Reviewers: Bruno Cadonna <bruno@confluent.io>,  Walker Carlson <wcarlson@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2020-11-13 10:44:09,leah,Mixed
cb3dc6785bc8263d8e1fc695e499e1eeb9df52a4,"KAFKA-6687: rewrite topology to allow reading the same topic multiple times in the DSL (#9582)

Rewrite DSL topology to allow reading a topic or pattern multiple times

Reviewers: Bruno Cadonna <cadonna@confluent.io>, Leah Thomas <lthomas@confluent.io>",2020-11-13 14:35:26,A. Sophie Blee-Goldman,Mixed
e14e7086713b2d65e8db0fb1a2daf2717fe7d13c,"KAFKA-10684; Avoid additional envelope copies during network transmission (#9563)

This patch creates a new `SendBuilder` class which allows us to avoid copying ""zero copy"" types when transmitting an api message over the network. This generalizes the pattern that was previously used only for `FetchResponse`. Initially we only apply this optimization to the `Envelope` types and `FetchResponse`, but in the future, it can be the default implementation for `toSend`.

The patch also contains a few minor cleanups such as moving envelope parsing logic into `RequestContext`.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2020-11-14 13:16:30,Jason Gustafson,Mixed
7a23e592f447725dbbbdc91e8062ef4a60a06031,"KAFKA-10685: strictly parsing the date/time format (#9576)

Reviewer: Matthias J. Sax <matthias@confluent.io>",2020-11-17 11:32:01,Luke Chen,Mixed
e71cb7ab11f85ce793aa337f185a20866ed3dc20,"KAFKA-10689: fix windowed FKJ topology and put checks in assignor to avoid infinite loops (#9568)

Fix infinite loop in assignor when trying to resolve the number of partitions in a topology with a windowed FKJ. Also adds a check to this loop to break out and fail the application if we detect that we are/will be stuck in an infinite loop

Reviewers: Matthias Sax <matthias@confluent.io>",2020-11-17 16:57:53,A. Sophie Blee-Goldman,Mixed
e7090173eeb72ba5c125ded2ec1cbf63cb5c0674,"KAFKA-10687: make ProduceRespone only returns INVALID_PRODUCER_EPOCH (#9569)

Ensures INVALID_PRODUCER_EPOCH recognizable from client side, and ensure the ProduceResponse always uses the old error code as INVALID_PRODUCER_EPOCH.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-11-17 19:56:38,Boyang Chen,Mixed
6bbf69fb009bd7c4d6f1a39ec71b514db87de440,"KAFKA-10497 Convert group coordinator metadata schemas to use generat… (#9318)

Reviewers: David Jacot <djacot@confluent.io>",2020-11-18 14:49:04,Chia-Ping Tsai,Mixed
5899f5fc4a9557c33e466e58d7555990ee742a2b,"KAFKA-9331: Add a streams specific uncaught exception handler (#9487)

This PR introduces a streams specific uncaught exception handler that currently has the option to close the client or the application. If the new handler is set as well as the old handler (java thread handler) will be ignored and an error will be logged.
The application shutdown is achieved through the rebalance protocol.

Reviewers: Bruno Cadonna <cadonna@confluent.io>, Leah Thomas <lthomas@confluent.io>, John Roesler <john@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2020-11-17 22:55:09,Walker Carlson,Mixed
28c57b273a3620c18be0bba6d5f74f981d9ef47d,"KAFKA-10618: Rename UUID to Uuid and make it more efficient (#9566)

As decided in KIP-516, the UUID class should be named Uuid. Change all instances of
org.apache.kafka.common.UUID to org.apache.kafka.common.Uuid.

Also modify Uuid so that it stores two `long` fields instead of wrapping java.util.UUID
to reduce memory usage.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2020-11-18 00:58:20,Justine Olshan,Mixed
30bc21ca35b165f04c472b4ce794893843809ccc,"KAFKA-9628; Replace Produce request/response with automated protocol (#9401)

This patch rewrites `ProduceRequest` and `ProduceResponse` using the generated protocols. We have also added several new benchmarks to verify no regression in performance. A summary of results is included below:

### Benchmark

1. loop **30** times
1. calculate average

#### kafkatest.benchmarks.core.benchmark_test.Benchmark.test_producer_throughput

> @cluster(num_nodes=5)
> @parametrize(acks=-1, topic=TOPIC_REP_THREE)

- +0.3144915325 %
- 28.08766667 ->  28.1715625 (mb_per_sec)

> @cluster(num_nodes=5)
> @matrix(acks=[1], topic=[TOPIC_REP_THREE], message_size=[100000],compression_type=[""none""], security_protocol=['PLAINTEXT'])

- +4.220730323 %
- 157.145 -> 163.7776667 (mb_per_sec)

> @cluster(num_nodes=7)
> @parametrize(acks=1, topic=TOPIC_REP_THREE, num_producers=3)

- +5.996241145%
- 57.64166667 -> 61.098 (mb_per_sec)

> @cluster(num_nodes=5)
> @parametrize(acks=1, topic=TOPIC_REP_THREE)

- +0.3979572536%
- 44.05833333 -> 44.23366667 (mb_per_sec)

> @cluster(num_nodes=5)
> @parametrize(acks=1, topic= TOPIC_REP_ONE)

- +2.228235226%
- 69.23266667 -> 70.77533333 (mb_per_sec)

### JMH results

In short, most ops performance are regression since we have to convert data to protocol data. The cost is inevitable (like other request/response) before we use protocol data directly.

### JMH for ProduceRequest

1. construction regression:
    - 281.474 -> 454.935 ns/op
    - 296.000 -> 1888.000 B/op
1. toErrorResponse regression:
    - 41.942 -> 107.528 ns/op
    - 1216.000 -> 1616.000 B/op
1. toStruct improvement:
    - 255.185 -> 90.728 ns/op
    - 864.000 -> 304.000 B/op

**BEFORE**
```
Benchmark                                                                        Mode  Cnt     Score    Error   Units
ProducerRequestBenchmark.constructorErrorResponse                                avgt   15    41.942 ±  0.036   ns/op
ProducerRequestBenchmark.constructorErrorResponse:·gc.alloc.rate                 avgt   15  6409.263 ±  5.478  MB/sec
ProducerRequestBenchmark.constructorErrorResponse:·gc.alloc.rate.norm            avgt   15   296.000 ±  0.001    B/op
ProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Eden_Space        avgt   15  6416.420 ± 76.071  MB/sec
ProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Eden_Space.norm   avgt   15   296.331 ±  3.539    B/op
ProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Old_Gen           avgt   15     0.002 ±  0.002  MB/sec
ProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Old_Gen.norm      avgt   15    ≈ 10⁻⁴             B/op
ProducerRequestBenchmark.constructorErrorResponse:·gc.count                      avgt   15   698.000           counts
ProducerRequestBenchmark.constructorErrorResponse:·gc.time                       avgt   15   378.000               ms
ProducerRequestBenchmark.constructorProduceRequest                               avgt   15   281.474 ±  3.286   ns/op
ProducerRequestBenchmark.constructorProduceRequest:·gc.alloc.rate                avgt   15  3923.868 ± 46.303  MB/sec
ProducerRequestBenchmark.constructorProduceRequest:·gc.alloc.rate.norm           avgt   15  1216.000 ±  0.001    B/op
ProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Eden_Space       avgt   15  3923.375 ± 59.568  MB/sec
ProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Eden_Space.norm  avgt   15  1215.844 ± 11.184    B/op
ProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Old_Gen          avgt   15     0.004 ±  0.001  MB/sec
ProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Old_Gen.norm     avgt   15     0.001 ±  0.001    B/op
ProducerRequestBenchmark.constructorProduceRequest:·gc.count                     avgt   15   515.000           counts
ProducerRequestBenchmark.constructorProduceRequest:·gc.time                      avgt   15   279.000               ms
ProducerRequestBenchmark.constructorStruct                                       avgt   15   255.185 ±  0.069   ns/op
ProducerRequestBenchmark.constructorStruct:·gc.alloc.rate                        avgt   15  3074.889 ±  0.823  MB/sec
ProducerRequestBenchmark.constructorStruct:·gc.alloc.rate.norm                   avgt   15   864.000 ±  0.001    B/op
ProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Eden_Space               avgt   15  3077.737 ± 31.537  MB/sec
ProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Eden_Space.norm          avgt   15   864.800 ±  8.823    B/op
ProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Old_Gen                  avgt   15     0.003 ±  0.001  MB/sec
ProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Old_Gen.norm             avgt   15     0.001 ±  0.001    B/op
ProducerRequestBenchmark.constructorStruct:·gc.count                             avgt   15   404.000           counts
ProducerRequestBenchmark.constructorStruct:·gc.time                              avgt   15   214.000               ms
```

**AFTER**
```
Benchmark                                                                        Mode  Cnt     Score    Error   Units
ProducerRequestBenchmark.constructorErrorResponse                                avgt   15   107.528 ±  0.270   ns/op
ProducerRequestBenchmark.constructorErrorResponse:·gc.alloc.rate                 avgt   15  4864.899 ± 12.132  MB/sec
ProducerRequestBenchmark.constructorErrorResponse:·gc.alloc.rate.norm            avgt   15   576.000 ±  0.001    B/op
ProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Eden_Space        avgt   15  4868.023 ± 61.943  MB/sec
ProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Eden_Space.norm   avgt   15   576.371 ±  7.331    B/op
ProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Old_Gen           avgt   15     0.005 ±  0.001  MB/sec
ProducerRequestBenchmark.constructorErrorResponse:·gc.churn.G1_Old_Gen.norm      avgt   15     0.001 ±  0.001    B/op
ProducerRequestBenchmark.constructorErrorResponse:·gc.count                      avgt   15   639.000           counts
ProducerRequestBenchmark.constructorErrorResponse:·gc.time                       avgt   15   339.000               ms
ProducerRequestBenchmark.constructorProduceRequest                               avgt   15   454.935 ±  0.332   ns/op
ProducerRequestBenchmark.constructorProduceRequest:·gc.alloc.rate                avgt   15  3769.014 ±  2.767  MB/sec
ProducerRequestBenchmark.constructorProduceRequest:·gc.alloc.rate.norm           avgt   15  1888.000 ±  0.001    B/op
ProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Eden_Space       avgt   15  3763.407 ± 31.530  MB/sec
ProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Eden_Space.norm  avgt   15  1885.190 ± 15.594    B/op
ProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Old_Gen          avgt   15     0.004 ±  0.001  MB/sec
ProducerRequestBenchmark.constructorProduceRequest:·gc.churn.G1_Old_Gen.norm     avgt   15     0.002 ±  0.001    B/op
ProducerRequestBenchmark.constructorProduceRequest:·gc.count                     avgt   15   494.000           counts
ProducerRequestBenchmark.constructorProduceRequest:·gc.time                      avgt   15   264.000               ms
ProducerRequestBenchmark.constructorStruct                                       avgt   15    90.728 ±  0.695   ns/op
ProducerRequestBenchmark.constructorStruct:·gc.alloc.rate                        avgt   15  3043.140 ± 23.246  MB/sec
ProducerRequestBenchmark.constructorStruct:·gc.alloc.rate.norm                   avgt   15   304.000 ±  0.001    B/op
ProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Eden_Space               avgt   15  3047.251 ± 59.638  MB/sec
ProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Eden_Space.norm          avgt   15   304.404 ±  5.034    B/op
ProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Old_Gen                  avgt   15     0.003 ±  0.001  MB/sec
ProducerRequestBenchmark.constructorStruct:·gc.churn.G1_Old_Gen.norm             avgt   15    ≈ 10⁻⁴             B/op
ProducerRequestBenchmark.constructorStruct:·gc.count                             avgt   15   400.000           counts
ProducerRequestBenchmark.constructorStruct:·gc.time                              avgt   15   205.000               ms
```
### JMH for ProduceResponse

1. construction regression:
    - 3.293 -> 303.226 ns/op
    - 24.000 -> 1848.000 B/op
1. toStruct improvement:
    - 825.889 -> 311.725 ns/op
    - 2208.000 -> 896.000 B/op

**BEFORE**

```
Benchmark                                                                          Mode  Cnt     Score    Error   Units
ProducerResponseBenchmark.constructorProduceResponse                               avgt   15     3.293 ±  0.004   ns/op
ProducerResponseBenchmark.constructorProduceResponse:·gc.alloc.rate                avgt   15  6619.731 ±  9.075  MB/sec
ProducerResponseBenchmark.constructorProduceResponse:·gc.alloc.rate.norm           avgt   15    24.000 ±  0.001    B/op
ProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Eden_Space       avgt   15  6618.648 ±  0.153  MB/sec
ProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Eden_Space.norm  avgt   15    23.996 ±  0.033    B/op
ProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Old_Gen          avgt   15     0.003 ±  0.002  MB/sec
ProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Old_Gen.norm     avgt   15    ≈ 10⁻⁵             B/op
ProducerResponseBenchmark.constructorProduceResponse:·gc.count                     avgt   15   720.000           counts
ProducerResponseBenchmark.constructorProduceResponse:·gc.time                      avgt   15   383.000               ms
ProducerResponseBenchmark.constructorStruct                                        avgt   15   825.889 ±  0.638   ns/op
ProducerResponseBenchmark.constructorStruct:·gc.alloc.rate                         avgt   15  2428.000 ±  1.899  MB/sec
ProducerResponseBenchmark.constructorStruct:·gc.alloc.rate.norm                    avgt   15  2208.000 ±  0.001    B/op
ProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Eden_Space                avgt   15  2430.196 ± 55.894  MB/sec
ProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Eden_Space.norm           avgt   15  2210.001 ± 51.009    B/op
ProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Old_Gen                   avgt   15     0.003 ±  0.001  MB/sec
ProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Old_Gen.norm              avgt   15     0.002 ±  0.001    B/op
ProducerResponseBenchmark.constructorStruct:·gc.count                              avgt   15   319.000           counts
ProducerResponseBenchmark.constructorStruct:·gc.time                               avgt   15   166.000               ms
```

**AFTER**

```
Benchmark                                                                          Mode  Cnt     Score    Error   Units
ProducerResponseBenchmark.constructorProduceResponse                               avgt   15   303.226 ±  0.517   ns/op
ProducerResponseBenchmark.constructorProduceResponse:·gc.alloc.rate                avgt   15  5534.940 ±  9.439  MB/sec
ProducerResponseBenchmark.constructorProduceResponse:·gc.alloc.rate.norm           avgt   15  1848.000 ±  0.001    B/op
ProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Eden_Space       avgt   15  5534.046 ± 51.849  MB/sec
ProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Eden_Space.norm  avgt   15  1847.710 ± 18.105    B/op
ProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Old_Gen          avgt   15     0.007 ±  0.001  MB/sec
ProducerResponseBenchmark.constructorProduceResponse:·gc.churn.G1_Old_Gen.norm     avgt   15     0.002 ±  0.001    B/op
ProducerResponseBenchmark.constructorProduceResponse:·gc.count                     avgt   15   602.000           counts
ProducerResponseBenchmark.constructorProduceResponse:·gc.time                      avgt   15   318.000               ms
ProducerResponseBenchmark.constructorStruct                                        avgt   15   311.725 ±  3.132   ns/op
ProducerResponseBenchmark.constructorStruct:·gc.alloc.rate                         avgt   15  2610.602 ± 25.964  MB/sec
ProducerResponseBenchmark.constructorStruct:·gc.alloc.rate.norm                    avgt   15   896.000 ±  0.001    B/op
ProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Eden_Space                avgt   15  2613.021 ± 42.965  MB/sec
ProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Eden_Space.norm           avgt   15   896.824 ± 11.331    B/op
ProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Old_Gen                   avgt   15     0.003 ±  0.001  MB/sec
ProducerResponseBenchmark.constructorStruct:·gc.churn.G1_Old_Gen.norm              avgt   15     0.001 ±  0.001    B/op
ProducerResponseBenchmark.constructorStruct:·gc.count                              avgt   15   343.000           counts
ProducerResponseBenchmark.constructorStruct:·gc.time                               avgt   15   194.000               ms
```

Reviewers: David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>",2020-11-18 13:44:21,Chia-Ping Tsai,Mixed
77a46b1f4d4e962d1b416d20c9ff76ec6fbaab68,"KAFKA-10545: Create topic IDs in ZooKeeper and Controller (#9473)

Topic IDs must be created for all new topics and all existing topics that do not yet have a topic ID. In ZooKeeper, the ID is written to the TopicZNode, and in the controller, it is stored in a map.

This is a preliminary change before the second part, which will propagate these IDs to brokers.

Reviewers: Lucas Bradstreet <lucas@confluent.io>, dengziming <dengziming1993@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2020-11-18 22:51:06,Justine Olshan,Mixed
d12fbb7c0077fba23282adb84ff87635d6e44e5e,"KAFKA-10500: Allow resizing of StreamThread state store caches (#9572)

 - part of KIP-663

Reviewer: Bruno Cadonna <bruno@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-11-18 15:45:40,Walker Carlson,Mixed
192db666c913c3fb2bfe3568ac51aa4ddb010a25,"KAFKA-9274: Handle TimeoutException on commit (#9570)

- part of KIP-572
 - when KafkaStreams commits a task, a TimeoutException should not kill
   the thread but `task.timeout.ms` should be triggered and the commit
   should be retried in the next loop

Reviewer: John Roesler <john@confluent.io>",2020-11-18 16:23:43,Matthias J. Sax,Mixed
179ecdf49e947a30d1bf5a277470cc2147cc35e4,"KAFKA-10628: remove all the unnecessary parameters from the tests which are using TopologyTestDriver (#9507)

1. remove unneeded javadoc content.
2. Replace containsKey/setProperty with putIfAbsent
3. refactor the constructor of TopologyTestDriverTest

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2020-11-19 11:23:41,Luke Chen,Not TDD
51c833e7959bd6ab7fbb043f76933456b40ecae4,"KAFKA-9630; Replace OffsetsForLeaderEpoch request/response with automated protocol (#9547)

This PR migrates the OffsetsForLeaderEpoch request/response to the automated protocol. It also refactors the OffsetsForLeaderEpochClient to use directly the internal structs generated by the automated protocol. It relies on the existing tests.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",2020-11-19 11:41:50,David Jacot,Mixed
1625984149491c33b6b1c815acccaefcd0f6a959,"MINOR: Allow Checkpoints for consumers using static partition assignments (#9545)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2020-11-19 15:01:22,Samuel Cantero,Mixed
91679f247a0fcc2d25fecd88e1b126c7459d36fe,"KAFKA-10692: Add delegation.token.secret.key, deprecate ...master.key (#9623)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2020-11-19 15:26:25,Tom Bentley,Mixed
1841e9f49788fa41b6a2e2ab29bb8ebf948d2625,"KAFKA-10024: Add dynamic configuration and enforce quota for per-IP connection rate limits (KIP-612, part 2) (#9386)

This PR implements the part of KIP-612 for adding IP throttling enforcement, and a ZK entity for configuring dynamic IP throttles.

Reviewers: Anna Povzner <anna@confluent.io>, David Jacot <djacot@confluent.io>",2020-11-19 16:32:22,David Mao,Mixed
dcbd28da53bfc6edb78fd1735993163fc6f4c7c7,"KAFKA-10723: Fix LogManager shutdown error handling (#9596)

The asynchronous shutdown in LogManager has the shortcoming that if during shutdown any of the internal futures fail, then we do not always ensure that all futures are completed before LogManager.shutdown returns. This is because, this line in the finally clause shuts down the thread pools asynchronously. As a result, despite the shut down completed message from KafkaServer is seen in the error logs, some futures continue to run from inside LogManager attempting to close some logs. This is misleading during debugging. Also sometimes it introduces an avoidable post-shutdown activity where resources (such as file handles) are released or persistent state is checkpointed in the Broker.

In this PR, we fix the above behavior such that we prevent leakage of threads. If any of the futures throw an error, we skip creating of checkpoint and clean shutdown file only for the affected log directory. We continue to wait for all futures to complete for all the directories.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",2020-11-19 10:52:18,Kowshik Prakasam,Mixed
438749bb5d78f2ca34aaf306739f210794f8e3f9,"MINOR: Factor out common response parsing logic (#9617)

This patch factors out some common parsing logic from `NetworkClient.parseResponse` and `AbstractResponse.parseResponse`. As a result of this refactor, we are now verifying the correlationId in forwarded requests. This patch also adds a test case to verify handling in this case.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Boyang Chen <boyang@confluent.io>",2020-11-19 19:00:52,Jason Gustafson,Mixed
407808964a140cb27e5d745db32a471db11e235a,"KAFKA-10607: Consistent behaviour for response errorCounts() (#9433)

Reviewers: Lee Dongjin <dongjin@apache.org>, Chia-Ping Tsai <chia7712@gmail.com>",2020-11-20 15:30:03,Tom Bentley,Mixed
351a22a12ecb79a1e1070bf1129f2e168e4e0670,"KAFKA-10755: Should consider commit latency when computing next commit timestamp (#9634)

Reviewer: Guozhang Wang <guozhang@confluent.io>",2020-11-20 18:55:40,Matthias J. Sax,Mixed
bc96a8feb5dcd7f034a2c8f30282485a1fde5c67,"KAFKA-10706; Ensure leader epoch cache is cleaned after truncation to end offset (#9633)

This patch fixes a liveness bug which prevents follower truncation from completing after a leader election. If there are consecutive leader elections without writing any data entries, then the leader and follower may have conflicting epoch entries at the end of the log.

The problem is the shortcut return in `Log.truncateTo` when the truncation offset is larger than or equal to the end offset, which prevents the conflicting entries from being resolved. Here we change this case to ensure `LeaderEpochFileCache.truncateFromEnd` is still called.

Reviewers: Jun Rao <junrao@gmail.com>",2020-11-21 09:25:54,Jason Gustafson,Mixed
72918a98161ba71ff4fa8116fdf8ed02b09a0580,"MINOR: change default TX timeout only if EOS is enabled (#9618)

Reviewer: Boyang Chen <boyang@confluent.io>",2020-11-22 14:00:31,Matthias J. Sax,Mixed
ed8659b4a09a4affff6798b8077ed2d8fb94b6da,"KAFKA-10727; Handle Kerberos error during re-login as transient failure in clients (#9605)

We use a background thread for Kerberos to perform re-login before tickets expire. The thread performs logout() followed by login(), relying on the Java library to clear and then populate credentials in Subject. This leaves a timing window where clients fail to authenticate because credentials are not available. We cannot introduce any form of locking since authentication is performed on the network thread. So this commit treats NO_CRED as a transient failure rather than a fatal authentication exception in clients.

Reviewers: Ron Dagostino <rdagostino@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>",2020-11-23 09:04:16,Rajini Sivaram,Not TDD
a5986bd32df94465b6202db02a52580aec0f348d,"MINOR: Update build and test dependencies (#9645)

The spotbugs upgrade means we can re-enable
RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE and RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE.
These uncovered one bug, one unnecessary null check and one
false positive. Addressed them all, including a test for the bug.

* gradle (6.7.0 -> 6.7.1): minor fixes.
* gradle versions plugin (0.29.0 -> 0.36.0): minor fixes.
* grgit (4.0.2 -> 4.1.0): a few small fixes and dependency bumps.
* owasp dependency checker plugin (5.3.2.1 -> 6.0.3): improved db
schema, data and several fixes. 
* scoverage plugin (4.0.2 -> 5.0.0): support Scala 2.13.
* shadow plugin (6.0.0 -> 6.1.0): require Java 8, support for Java 16.
* spotbugs plugin (4.4.4 -> 4.6.0): support SARIF reporting standard.
* spotbugs (4.0.6 -> 4.1.4): support for Java 16 and various fixes including
try with resources false positive.
* spotless plugin (5.1.0 -> 5.8.2): minor fixes.
* test retry plugin (1.1.6 -> 1.1.9): newer gradle and java version compatibility
fixes.
* mockito (3.5.7 -> 3.6.0): minor fixes.
* powermock (2.0.7 -> 2.0.9): minor fixes.

Release notes links:
* https://docs.gradle.org/6.7.1/release-notes.html
* https://github.com/spotbugs/spotbugs/blob/4.1.4/CHANGELOG.md
* https://github.com/scoverage/gradle-scoverage/releases/tag/5.0.0
* https://github.com/johnrengelman/shadow/releases/tag/6.1.0
* https://github.com/spotbugs/spotbugs-gradle-plugin/releases/tag/4.6.0
* https://github.com/spotbugs/spotbugs-gradle-plugin/releases/tag/4.6.0
* https://github.com/spotbugs/spotbugs-gradle-plugin/releases/tag/4.5.0
* https://github.com/ben-manes/gradle-versions-plugin/releases
* https://github.com/ajoberstar/grgit/releases/tag/4.1.0
* https://github.com/jeremylong/DependencyCheck/blob/main/RELEASE_NOTES.md#version-603-2020-11-03
* https://github.com/powermock/powermock/releases/tag/powermock-2.0.8
* https://github.com/powermock/powermock/releases/tag/powermock-2.0.9
* https://github.com/mockito/mockito/blob/v3.6.0/doc/release-notes/official.md
* https://github.com/gradle/test-retry-gradle-plugin/releases
* https://github.com/diffplug/spotless/blob/main/plugin-gradle/CHANGES.md

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2020-11-24 06:20:05,Ismael Juma,Mixed
cbf8ad277a515b9a3e42dc63658fb60e6e6146b6,"MINOR: Upgrade to Scala 2.13.4 (#9643)

Scala 2.13.4 restores default global `ExecutionContext` to 2.12 behavior
(to fix a perf regression in some use cases) and improves pattern matching
(especially exhaustiveness checking). Most of the changes are related
to the latter as I have enabled the newly introduced `-Xlint:strict-unsealed-patmat`.

More details on the code changes:
* Don't swallow exception in `ReassignPartitionsCommand.topicDescriptionFutureToState`.
* `RequestChannel.Response` should be `sealed`.
* Introduce sealed ClientQuotaManager.BaseUserEntity to avoid false positive
exhaustiveness warning.
* Handle a number of cases where pattern matches were not exhaustive:
either by marking them with @unchecked or by adding a catch-all clause.
* Workaround scalac bug related to exhaustiveness warnings in ZooKeeperClient
* Remove warning suppression annotations related to the optimizer that are no
longer needed in ConsumerGroupCommand and AclAuthorizer.
* Use `forKeyValue` in `AclAuthorizer.acls` as the scala bug preventing us from
using it seems to be fixed.
* Also update scalaCollectionCompat to 2.3.0, which includes minor improvements.

Full release notes:
* https://github.com/scala/scala/releases/tag/v2.13.4
* https://github.com/scala/scala-collection-compat/releases/tag/v2.3.0

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2020-11-24 10:28:53,Ismael Juma,Mixed
2a409200dc9d1fa3198908e231161988affa1754,"KAFKA-10754: fix flaky tests by waiting kafka streams be in running state before assert (#9629)

The flaky test is because we didn't wait for the streams become RUNNING before verifying the state becoming ERROR state. This fix explicitly wait for the streams become RUNNING state. Also, put the 2nd stream into try resource block so it will be closed after the test.

Reviewers: Walker Carlson <wcarlson@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2020-11-24 13:59:16,Luke Chen,Not TDD
dbf4e63ae7e4c637917124c148d5f21193d395b1,"KAFKA-10758: ProcessorTopology should only consider its own nodes when updating regex source topics (#9648)

 We should ignore any source nodes that aren't part of the ProcessorTopology's subtopology when updating its source topics after a change in the topic metadata.

Reviewers: Bruno Cadonna <cadonna@confluent.io>, Matthias J. Sax <mjsax@confluent.io>",2020-11-24 17:59:29,A. Sophie Blee-Goldman,Mixed
8a59a228817df221ac9acc7cce4f6c9dd702e9ef,"KAFKA-10713: Stricter protocol parsing in hostnames (#9593)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2020-11-26 14:59:04,Tom Bentley,Mixed
e7de280b0f1c7a924293dba79be77f56a08d0e15,"KAFKA-10702; Skip bookkeeping of empty transactions (#9632)

Compacted topics can accumulate a large number of empty transaction markers as the data from the transactions gets cleaned. For each transaction, there is some bookkeeping that leaders and followers must do to keep the transaction index up to date. The cost of this overhead can degrade performance when a replica needs to catch up if the log has mostly empty or small transactions. This patch improves the cost by skipping over empty transactions since these will have no effect on the last stable offset and do not need to be reflected in the transaction index.

Reviewers: Lucas Bradstreet <lucas@confluent.io>, Jun Rao <junrao@gmail.com>",2020-11-30 14:48:28,Jason Gustafson,Mixed
cc1aa3b83d22dfe45fab945c3958325d87858a8f,"KAFKA-10770: Remove duplicate defination of Metrics#getTags (#9659)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2020-12-01 13:10:22,ArunParthiban-ST,Mixed
9211ff6ffd06485a4c3bc41185be22bac0d961d8,"MINOR: Increase unit test coverage of method ProcessorTopology#updateSourceTopics() (#9654)

The unit tests for method ProcessorTopology#updateSourceTopics() did not cover all
code paths.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2020-12-01 10:58:57,Bruno Cadonna,Mixed
dc55be2d92922dbee28d010bec464fcf0e90a350,"KAFKA-6687: restrict DSL to allow only Streams from the same source topics (#9609)

Followup to PR #9582, need to restrict DSL so only KStreams can be created from the same set of topic(s)s but not KTables, which can be tackled as followup work

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bruno Cadonna <cadonna@confluent.io>",2020-12-01 11:26:16,A. Sophie Blee-Goldman,Mixed
85f94d50271c952c3e9ee49c4fc814c0da411618,"KAFKA-10729; Bump remaining RPC's to use tagged fields. (#9601)

As a follow-up from [KIP-482](https://cwiki.apache.org/confluence/display/KAFKA/KIP-482%3A+The+Kafka+Protocol+should+Support+Optional+Tagged+Fields), this PR bumps the version for several
RPC's to enable tagged fields via the flexible versioning mechanism.

Additionally, a new IBP version `KAFKA_2_8_IV0` is introduced to
allow replication to take advantage of these new RPC versions for
OffsetForLeaderEpoch and ListOffset.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2020-12-01 15:55:07,Gardner Vickers,Mixed
e63f591ec4d4664608286072c31127323371cb96,"KAFKA-10090 Misleading warnings: The configuration was supplied but i… (#8826)

Reviewers: Jun Rao <junrao@gmail.com>",2020-12-03 10:34:27,Chia-Ping Tsai,Mixed
7ecc3a579a4b13e0cef4bd3129982ea3bc1a9341,"KAFKA-10554; Perform follower truncation based on diverging epochs in Fetch response (#9382)

From IBP 2.7 onwards, fetch responses include diverging epoch and offset in fetch responses if lastFetchedEpoch is provided in the fetch request. This PR uses that information for truncation and avoids the additional OffsetForLeaderEpoch requests in followers when lastFetchedEpoch is known.

Co-authored-by: Jason Gustafson <jason@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>, Nikhil Bhatia <rite2nikhil@gmail.com>",2020-12-03 10:12:06,Rajini Sivaram,Mixed
9de16bd2e64431b1b25d7a34aae78c6c98795143,"KAFKA-10460: ReplicaListValidator format checking is incomplete (#9326)


Co-authored-by: akumar <akumar@cloudera.com>
Reviewers: Mickael Maison <mickael.maison@gmail.com>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>",2020-12-03 14:36:48,Ankit Kumar,Not TDD
10364e4b0c1f3757d9291d4ac11978cd5f7d08a3,"KAFKA-10739; Replace EpochEndOffset with automated protocol (#9630)

This patch follows up https://github.com/apache/kafka/pull/9547. It refactors KafkaApis, ReplicaManager and Partition to use `OffsetForLeaderEpochResponseData.EpochEndOffset` instead of `EpochEndOffset`. In the mean time, it removes `OffsetsForLeaderEpochRequest#epochsByTopicPartition` and `OffsetsForLeaderEpochResponse#responses` and replaces their usages to use the automated protocol directly. Finally, it removes old constructors in `OffsetsForLeaderEpochResponse`. The patch relies on existing tests.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",2020-12-03 18:50:29,David Jacot,Mixed
633f7cff190385a693486ddb88eaf5e84b3c13ed,"KAFKA-10799 AlterIsr utilizes ReplicaManager ISR metrics (#9677)

Add small interface to Partition.scala that allows AlterIsr and ZK code paths to update the ISR metrics managed by ReplicaManager. This opens the door for consolidating even more code between the two ISR update code paths.",2020-12-03 16:11:07,David Arthur,Mixed
155f2c06fbadc7a1a7a15cd2a2d5c2b7e72de0eb,"KAFKA-10803: Fix improper removal of bad dynamic config (#9682)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2020-12-04 11:59:39,Prateek Agarwal,Mixed
4cc6d204ec5cb21841a2f8f21e6333bb688cd892,"KAFKA-10500: Add failed-stream-threads metric for adding + removing stream threads (#9614)

Part of KIP-663.

Reviewer: Bruno Cadonna <bruno@confluent.io>, Walker Carlson <wcarlson@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-12-04 00:56:11,leah,Mixed
4f2f08eb006cdf3dc848b34b4b17cf27a023e9da,"KAFKA-10792: Prevent source task shutdown from blocking herder thread (#9669)

Changes the `WorkerSourceTask` class to only call `SourceTask::stop` from the task thread when the task is actually stopped (via `Source:task::close` just before `WorkerTask::run` completes), and only if an attempt has been made to start the task (which will not be the case if it was created in the paused state and then shut down before being started). This prevents `SourceTask::stop` from being indirectly invoked on the herder's thread, which can have adverse effects if the task is unable to shut down promptly.

Unit tests are tweaked where necessary to account for this new logic, which covers some edge cases mentioned in PR #5020 that were unaddressed up until now.

The existing integration tests for blocking connectors are expanded to also include cases for blocking source and sink tasks. Full coverage of every source/sink task method is intentionally omitted from these expanded tests in order to avoid inflating test runtime (each one adds an extra 5 seconds at minimum) and because the tests that are added here were sufficient to reproduce the bug with source task shutdown.

Author: Chris Egerton <chrise@confluent.io>
Reviewers: Nigel Liang <nigel@nigelliang.com>, Tom Bentley <tbentley@redhat.com>, Randall Hauch <rhauch@gmail.com>",2020-12-04 11:48:23,Chris Egerton,Not TDD
9ece7fe372230e848920d843af2d0d5c2fbaac4d,"KAFKA-10500: Allow people to add new StreamThread at runtime (#9615)

Part of KIP-663.

Reviewers: Bruno Cadonna <bruno@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-12-04 12:21:03,Walker Carlson,Mixed
8db3b1a09af0bad274e07161336994610d616b35,"KAFKA-10811: Correct the MirrorConnectorsIntegrationTest to correctly mask the exit procedures (#9698)

Normally the `EmbeddedConnectCluster` class masks the `Exit` procedures using within the Connect worker. This normally works great when a single instance of the embedded cluster is used. However, the `MirrorConnectorsIntegrationTest` uses two `EmbeddedConnectCluster` instances, and when the first one is stopped it would reset the (static) exit procedures, and any problems during shutdown of the second embedded Connect cluster would cause the worker to shut down the JVM running the tests.

Instead, the `MirrorConnectorsIntegrationTest` class should mask the `Exit` procedures and instruct the `EmbeddedConnectClusters` instances (via the existing builder method) to not mask the procedures.

Author: Randall Hauch <rhauch@gmail.com>
Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2020-12-07 09:34:34,Randall Hauch,Not TDD
b8ebcc2a93a4e0525afb4f5ff6690ef5b7529c57,"KAFKA-10798; Ensure response is delayed for failed SASL authentication with connection close delay (#9678)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2020-12-07 16:12:18,Rajini Sivaram,Not TDD
ab0807dd858887d934d2be520608d20bf765b609,"KAFKA-10394: Add classes to read and write snapshot for KIP-630 (#9512)

This PR adds support for generating snapshot for KIP-630.

1. Adds the interfaces `RawSnapshotWriter` and `RawSnapshotReader` and the implementations `FileRawSnapshotWriter` and `FileRawSnapshotReader` respectively. These interfaces and implementations are low level API for writing and reading snapshots. They are internal to the Raft implementation and are not exposed to the users of `RaftClient`. They operation at the `Record` level. These types are exposed to the `RaftClient` through the `ReplicatedLog` interface.

2. Adds a buffered snapshot writer: `SnapshotWriter<T>`. This type is a higher-level type and it is exposed through the `RaftClient` interface. A future PR will add the related `SnapshotReader<T>`, which will be used by the state machine to load a snapshot.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-12-07 14:06:25,José Armando García Sancio,Mixed
6f27bb02da0dec63a16c0c6aa456b47ba416eb19,"KAFKA-10818: Skip conversion to `Struct` when serializing generated requests/responses (#7409)

Generated request/response classes have code to serialize/deserialize directly to
`ByteBuffer` so the intermediate conversion to `Struct` can be skipped for them.
We have recently completed the transition to generated request/response classes,
so we can also remove the `Struct` based fallbacks.

Additional noteworthy changes:
* `AbstractRequest.parseRequest` has a more efficient computation of request size that
relies on the received buffer instead of the parsed `Struct`.
* Use `SendBuilder` for `AbstractRequest/Response` `toSend`, made the superclass
implementation final and removed the overrides that are no longer necessary.
* Removed request/response constructors that assume latest version as they are unsafe
outside of tests.
* Removed redundant version fields in requests/responses.
* Removed unnecessary work in `OffsetFetchResponse`'s constructor when version >= 2.
* Made `AbstractResponse.throttleTimeMs()` abstract.
* Using `toSend` in `SaslClientAuthenticator` instead of `serialize`.
* Various changes in Request/Response classes to make them more consistent and to
rely on the Data classes as much as possible when it comes to their state.
* Remove the version argument from `AbstractResponse.toString`.
* Fix `getErrorResponse` for `ProduceRequest` and `DescribeClientQuotasRequest` to
use `ApiError` which processes the error message sent back to the clients. This was
uncovered by an accidental fix to a `RequestResponseTest` test (it was calling
`AbstractResponse.toString` instead of `AbstractResponse.toString(short)`).

Rely on existing protocol tests to ensure this refactoring does not change 
observed behavior (aside from improved performance).

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2020-12-07 15:39:57,Ismael Juma,Mixed
41ea0775e0360eeb60376fb19bbd3941ed67676d,"KAFKA-10667: add timeout for forwarding requests (#9564)

add total timeout for forwarding, including the underlying broker-to-controller channel timeout setting.

Reviewers: David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",2020-12-08 11:12:30,Boyang Chen,Mixed
99b5e4f4ab62b40efdbd311a9e455ccbe50ce069,"KAFKA-10634; Adding LeaderId to voters list in LeaderChangeMessage along with granting voters (#9539)

This patch ensures that the leader is included among the voters in the `LeaderChangeMessage`. It also adds an additional field for the set of granting voters, which was originally specified in KIP-595.

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",2020-12-08 17:37:48,vamossagar12,Mixed
00f7341a8236fe4d9c0956b07fc5931056a841cf,"Revert ""KAFKA-10713: Stricter protocol parsing in hostnames (#9593)""

This reverts commit 8a59a228817df221ac9acc7cce4f6c9dd702e9ef since it breaks
client configurations like `bootstrap.servers=SASL_PLAINTEXT://localhost:49767`.
A KIP will be submitted to discuss the details and an adjusted change will
be submitted depending on the outcome of that.",2020-12-09 06:33:43,Ismael Juma,Mixed
ff88874e0de4aa1ce177330869e0ddf4a4ba2732,"KAFKA-10606: Disable auto topic creation for fetch-all-topic-metadata request (#9435)

Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>",2020-12-09 23:31:04,Lincong Li,Mixed
1f98112e993bc4ae098936b1b0661fdb2c4b1880,"MINOR: Remove connection id from Send and consolidate request/message utils (#9714)

Connection id is now only present in `NetworkSend`, which is now
the class used by `Selector`/`NetworkClient`/`KafkaChannel` (which
works well since `NetworkReceive` is the class used for
received data).

The previous `NetworkSend` was also responsible for adding a size
prefix. This logic is already present in `SendBuilder`, but for the
minority of cases where `SendBuilder` is not used (including
a number of tests), we now have `ByteBufferSend.sizePrefixed()`.

With regards to the request/message utilities:
* Renamed `toByteBuffer`/`toBytes` in `MessageUtil` to
`toVersionPrefixedByteBuffer`/`toVersionPrefixedBytes` for clarity.
* Introduced new `MessageUtil.toByteBuffer` that does not include
the version as the prefix.
* Renamed `serializeBody` in `AbstractRequest/Response` to
`serialize` for symmetry with `parse`.
* Introduced `RequestTestUtils` and moved relevant methods from
`TestUtils`.
* Moved `serializeWithHeader` methods that were only used in
tests to `RequestTestUtils`.
* Deleted `MessageTestUtil`.

Finally, a couple of changes to simplify coding patterns:
* Added `flip()` and `buffer()` to `ByteBufferAccessor`.
* Added `MessageSizeAccumulator.sizeExcludingZeroCopy`.
* Used lambdas instead of `TestCondition`.
* Used `Arrays.copyOf` instead of `System.arraycopy` in `MessageUtil`.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",2020-12-09 11:15:58,Ismael Juma,Mixed
a8b668b37caf9dd8211e97ccebcc70d074a2c646,"KAFKA-10826; Ensure raft io thread respects linger timeout (#9716)

When there are no pending operations, the raft IO thread can block indefinitely waiting for a network event. We rely on asynchronous wakeups in order to break the blocking wait in order to respond to a scheduled append. The current logic already does this, but only for the case when the linger time has been completed during the call to `scheduleAppend`. It is possible instead that after making one call to `scheduleAppend` to start the linger timer, the application does not do any additional appends. In this case, we still need the IO thread to wakeup when the linger timer expires. This patch fixes the problem by ensuring that the IO thread gets woken up after the first append which begins the linger timer.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2020-12-09 13:33:28,Jason Gustafson,Mixed
6e15937feb65e664ae4dc694246e1e486ff26567,"KAFKA-10289; Fix failed connect_distributed_test.py (ConnectDistributedTest.test_bounce) (#9673)

In Python 3, `filter` functions return iterators rather than `list` so it can traverse only once. Hence, the following loop will only see ""empty"" and then validation fails.

```python
        src_messages = self.source.committed_messages() # return iterator
        sink_messages = self.sink.flushed_messages()) # return iterator
        for task in range(num_tasks):
            # only first task can ""see"" the result. following tasks see empty result
            src_seqnos = [msg['seqno'] for msg in src_messages if msg['task'] == task]
```

Reference: https://portingguide.readthedocs.io/en/latest/iterators.html#new-behavior-of-map-and-filter.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-12-09 13:38:17,Chia-Ping Tsai,Not TDD
310e240abd6acb6ad27dea8b5aae01c1a7674ca4,"throw corresponding invalid producer epoch (#9700)

As suggested, ensure InvalidProducerEpoch gets caught properly on stream side.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2020-12-09 20:15:43,Boyang Chen,Mixed
404062d2b66498951eeddfcb14072545982584ec,"KAFKA-10747: Extend DescribeClientQuotas and AlterClientQuotas APIs to support IP connection rate quota (KIP-612) (#9628)

This PR adds support for IP entities to the `DescribeClientQuotas` and `AlterClientQuotas` APIs. This PR also adds support for describing/altering IP quotas via `kafka-configs` tooling.

Reviewers: Brian Byrne <bbyrne@confluent.io>, Anna Povzner <anna@confluent.io>, David Jacot <djacot@confluent.io>",2020-12-10 09:53:32,David Mao,Mixed
b44d32dffedb368b888e3431257d68abb1e62b9f,"KAFKA-10748: Add IP connection rate throttling metric (KIP-612) (#9685)

This PR adds the IP throttling metric as described in KIP-612.

Reviewers: Anna Povzner <anna@confluent.io>, David Jacot <djacot@confluent.io>",2020-12-10 12:24:45,David Mao,Not TDD
125d5ea0fb80a82ee23fe3e354981b75db1a4756,"KAFKA-10677; Complete fetches in purgatory immediately after resigning (#9639)

This patch adds logic to complete fetches immediately after resigning by returning the BROKER_NOT_AVAILABLE error. This ensures that the new election cannot be delayed by fetches which are stuck in purgatory. 

Reviewers: Jason Gustafson <jason@confluent.io>",2020-12-10 09:25:04,dengziming,Mixed
d5dc7dfe00b3a9c9934ba6627b892c2c76732e1b,"KAFKA-10810: Replace stream threads (#9697)

StreamThreads can now be replaced in the streams uncaught exception handler

Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>, Leah Thomas <lthomas@confluent.io>",2020-12-11 15:08:21,Walker Carlson,Not TDD
4401f52d17b41bc560b04f0883d2cb57c3c983aa,"MINOR: Make Log.recordVersion private and other small cleanups (#9731)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2020-12-14 15:20:20,Kowshik Prakasam,Not TDD
5e5daf47ef0de74c0662063e975dd1f52993be7b,"KAFKA-10852: AlterIsr should not be throttled (#9747)

Set it as a cluster action and update the handler in KafkaApis. We keep the `throttleTimeMs` field
since we intend to enable throttling in the future (especially relevant when we switch to the
built-in quorum mode).

Reviewers: David Arthur <mumrah@gmail.com>",2020-12-14 22:28:47,Ismael Juma,Mixed
1a10c3445e157da1d2fd670c043f19c385465eb0,"KAFKA-10525: Emit JSONs with new auto-generated schema (KIP-673) (#9526)

This patch updates the request logger to output request and response payloads in JSON. Payloads are converted to JSON based on their auto-generated schema.

Reviewers:  Lucas Bradstreet <lucas@confluent.io>, David Mao <dmao@confluent.io>, David Jacot <djacot@confluent.io>",2020-12-15 14:33:36,Anastasia Vela,Mixed
1aac64667f99e1b7513d7e0a653112a0ac88f35e,"KAFKA-6084: Propagate JSON parsing errors in ReassignPartitionsCommand (#4090)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2020-12-15 10:05:40,Viktor Somogyi-Vass,Mixed
793117d45587ddcaed1629b7bb446df93268f27e,"KAFKA-10417: Update Cogrouped processor to work with suppress() and joins (#9727)

Correct the implementation of the Cogroup
processor to implement KTableProcessorSupplier.

Change the cogrouped processor from PassThrough to
KTablePassThrough to allow for sending old values.
KTablePassThrough extends KTableProcessorSupplier instead of
ProcessorSupplier to implement sending old values and the view() method.

Reviewers: Walker Carlson <wcarlson@confluent.io>, John Roesler <vvcephei@apache.org>",2020-12-15 14:53:56,leah,Not TDD
d072be6d9002cf3650e21d7005bf5adc6ae70454,"KAFKA-10855; Fix non-local return in `KafkaApis.handle` (#9753)

The non-local return when `maybeHandleInvalidEnvelope` returns true causes the default error handler to execute after a response has already been sent. This patch rewrites the check as a local return.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2020-12-15 13:07:48,Jason Gustafson,Mixed
ea8ae976504e7a3f5c6f4a7efa5069d03316b093,"KAFKA-10839; improve consumer group coordinator unavailable message (#9729)

When a consumer encounters an issue that triggers marking it to mark coordinator as unknown, the error message it prints does not give much context about the error that triggered it. This change includes the response error that triggered the transition or any other cause if not triggered by an error code in a response.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-12-15 14:38:18,Lucas Bradstreet,Mixed
d84a82c32db94be9c5dbdc155c38a3775e6882eb,"MINOR: make Send and Receive work with TransferableChannel rather than Gat… (#9516)

This PR introduces a new interface 'TransferableChannel' to replace GatheringByteChannel to avoid casting in write path. `TransferableChannel ` extends GatheringByteChannel with the minimal set of methods required by the Send interface. Supporting TLS and efficient zero copy transfers are the main reasons for the additional methods.

Co-authored-by: Ismael Juma <ismael@juma.me.uk>

Reviewers: Ismael Juma <ismael@juma.me.uk>",2020-12-16 08:51:40,Chia-Ping Tsai,Mixed
782175dfbc4a6694ae9a3970cd92ebd20647bc7e,"MINOR: Simplify ApiKeys by relying on ApiMessageType (#9748)

* The naming for `ListOffsets` was inconsistent, in some places it was `ListOffset` and in others
it was `ListOffsets`. Picked the latter since it was used in metrics and the protocol documentation
and made it consistent.
* Removed unused methods in ApiKeys.
* Deleted `CommonFields`.
* Added `lowestSupportedVersion` and `highestSupportedVersion` to `ApiMessageType`
* Removed tests in `MessageTest` that are no longer relevant.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2020-12-16 06:33:10,Ismael Juma,Mixed
f4272fd5d38fdc3145f9b0a78f4ab7f0692aecd5,"KAFKA-9126: KIP-689: StreamJoined changelog configuration (#9708)

Add withLoggingEnabled and withLoggingDisabled for StreamJoined
to give StreamJoined the same flexibility as Materialized

Reviewers: Bruno Cadonna <bruno@confluent.io>, John Roesler <vvcephei@apache.org>",2020-12-16 16:19:33,leah,Not TDD
02a30a51ebaace6f42d1fd9027fcf3345179a52e,"KAFKA-10740; Replace OffsetsForLeaderEpochRequest.PartitionData with automated protocol (#9689)

This patch follows up https://github.com/apache/kafka/pull/9547. It refactors AbstractFetcherThread and its descendants to use `OffsetForLeaderEpochRequestData.OffsetForLeaderPartition` instead of `OffsetsForLeaderEpochRequest.PartitionData`. The patch relies on existing tests.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",2020-12-17 17:40:37,David Jacot,Mixed
67150b815ef33a03994bce6210643fd1dcc2855f,"KAFKA-10846: Grow buffer in FileSourceStreamTask only when needed (#9735)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2020-12-18 12:01:38,Tom Bentley,Mixed
ae3a6ed990f91708686d27c6023bac050c422248,"KAKFA-10619: Idempotent producer will get authorized once it has a WRITE access to at least one topic (KIP-679) (#9485)

Includes:
- New API to authorize by resource type
- Default implementation for the method that supports super users and ACLs
- Optimized implementation in AclAuthorizer that supports ACLs, super users and allow.everyone.if.no.acl.found
- Benchmarks and tests
- InitProducerIdRequest authorized for Cluster:IdempotentWrite or WRITE to any topic, ProduceRequest authorized only for topic even if idempotent

Reviewers: Lucas Bradstreet <lucas@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2020-12-18 18:08:46,Cheng Tan,Mixed
baef516789f0d80ce1faba5d257a905ecb27e6fe,"Add ConfigurableProducerSpec to Trogdor for improved E2E latency tracking. (#9736)

Reviewer: Colin P. McCabe <cmccabe@apache.org>",2020-12-18 13:03:59,Scott Hendricks,Mixed
5c921afa4a593478f7d1c49e5db9d787558d0d5e,"KAFKA-10547; Add TopicId in MetadataResponse (#9622)

Includes:
- Bump the version of MetadataRequest and MetadataResponse, add topicId in MetadataResponse
- Alter describeTopic in AdminClientTopicService and ZookeeperTopicService
- TopicMetadata is cached in MetadataCache, so we need to add topicId to MetadataCache
- MetadataCache is updated by UpdateMetadataRequest, bump the version of UpdateMetadataReq and UpdateMetadataResp, add topicId in UpdateMetadataReq.

Reviewers: Justine Olshan <jolshan@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2020-12-18 21:30:52,dengziming,Mixed
1dd1e7f945d7a8c1dc177223cd88800680f1ff46,"KAFKA-10545: Create topic IDs and propagate to brokers (#9626)

This change propagates topic ids to brokers in LeaderAndIsr Request. It also removes the topic name from the LeaderAndIsr Response, reorganizes the response to be sorted by topic, and includes the topic ID.

In addition, the topic ID is persisted to each replica in Log as well as in a file on disk. This file is read on startup and if the topic ID exists, it will be reloaded.

Reviewers: David Jacot <djacot@confluent.io>, dengziming <dengziming1993@gmail.com>, Nikhil Bhatia <rite2nikhil@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2020-12-18 22:19:50,Justine Olshan,Mixed
4e7c789118fed28ee99275e3e84a626fe912c79a,"MINOR: refactor SelectingIterator by scala iterator (#9755)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2020-12-21 16:11:51,Chia-Ping Tsai,Mixed
167036223606ace089966ce2cf3dd74e0eb19a68,"MINOR: Replace Collection.toArray(new T[size]) by Collection.toArray(new T[0]) (#9750)

This PR is based on the research of https://shipilev.net/blog/2016/arrays-wisdom-ancients

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2020-12-21 17:38:33,APaMio,Not TDD
d3f19e4bb047338840d380d2253dc92cf56b0a0f,"KAFKA-10825 ZooKeeper ISR manager (#9713)

ISR-related cleanup in ReplicaManager and Partition. Removes ISR change logic from ReplicaManager and adds a new ZkIsrManager class which adheres to a new AlterIsrManager trait. Unifies all of the ISR logic in Partition so we don't have separate code paths for ZK vs AlterIsr. Also removes PartitionStateStore",2020-12-21 14:44:02,David Arthur,Mixed
eb9fe411bbbfca1baf5e0900ee9cfb9147e5099e,"KAFKA-10842; Use `InterBrokerSendThread` for raft's outbound network channel (#9732)

This patch contains the following improvements:

- Separate inbound/outbound request flows so that we can open the door for concurrent inbound request handling
- Rewrite `KafkaNetworkChannel` to use `InterBrokerSendThread` which fixes a number of bugs/shortcomings
- Get rid of a lot of boilerplate conversions in `KafkaNetworkChannel` 
- Improve validation of inbound responses in `KafkaRaftClient` by checking correlationId. This fixes a bug which could cause an out of order Fetch to be applied incorrectly.

Reviewers: David Arthur <mumrah@gmail.com>",2020-12-21 18:15:15,Jason Gustafson,Mixed
d5151f6f095896799296aecaa483a76981425ed5,"KAFKA-10828; Replacing endorsing with acknowledging for voters  (#9737)

This PR replaces the terms endorsing with acknowledging for voters which have recognised the current leader.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-12-22 10:05:07,vamossagar12,Mixed
b6891f6729e9997b18ffca2515cb0265520a1874,"MINOR: Kafka Streams updates for 2.7.0 release (#9773)

Reviewer: Matthias J. Sax <matthias@confluent.io>",2020-12-22 14:34:59,Bill Bejeck,Not TDD
2023aed59d863278a6302e03066d387f994f085c,"KAFKA-10427:  Fetch snapshot API (#9553)

Implements the code necessary for the leader to response to fetch snapshot requests and for the follower to fetch snapshots. This API is described in more detail in KIP-630: https://cwiki.apache.org/confluence/display/KAFKA/KIP-630%3A+Kafka+Raft+Snapshot.  More specifically, this patch includes the following changes:

Leader Changes:
1. Raft leader response to FetchSnapshot request by reading the local snapshot and sending the requested bytes in the response. This implementation currently copies the bytes to memory. This will be fixed in a future PR.

Follower Changes:
1. Raft followers will start fetching snapshot if the leader sends a Fetch response that includes a SnapshotId.

2. Raft followers send FetchSnapshot requests if there is a pending download. The same timer is used for both Fetch and FetchSnapshot requests.

3. Raft follower handle FetchSnapshot responses by comping the bytes to the pending SnapshotWriter. This implementation doesn't fix the replicated log after the snapshot has been downloaded. This will be implemented in a future PR.

Reviewers: Jason Gustafson <jason@confluent.io>",2020-12-28 18:37:08,José Armando García Sancio,Mixed
3ebd32b2a563440645de45ecb578d8a8dccbee95,"MINOR: Use top-level error in `UpdateFeaturesRequest.getErrorResponse` (#9781)

The current `getErrorResponse` sets all of the feature errors, but does not set a top-level error. It seems like the whole point of having the top-level error is so that it could be used in cases like this. This patch also updates `errorCounts` in `UpdateFeaturesResponse` so that the top-level error is included.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2020-12-29 13:41:56,Jason Gustafson,Mixed
bdb29e42cb19ff108c671f05cf0d2732fab0a2d8,"KAFKA-10768 Make ByteBufferInputStream.read(byte[], int, int) to follow the contract (#9761)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-01-03 15:09:31,bertber,Mixed
e3ce4a6e11dd8f3d8e08f39c22c4f19f30ff65b8,"KAFKA-10870; Handle REBALANCE_IN_PROGRESS error in JoinGroup (#9792)

Handle REBALANCE_IN_PROGRESS error in JoinGroup, which is possible if there is a replication timeout while persisting the group state after the rebalance completes.

Reviewers: Boyang Chen <boyang@confluent.io>, Jason Gustafson <jason@confluent.io>",2021-01-04 14:20:24,Luke Chen,Mixed
daad1cbf5555d20579953244481279594be1c845,"KAFKA-10894; Ensure PartitionInfo replicas are not null in client quota callback (#9802)

Previously offline replicas were included as `null` in the array of replicas in `PartitionInfo` when populated by the `MetadataCache` for the purpose of the client quota callback. This patch instead initializes empty non-null nodes, which is consistent with how `PartitionInfo` is constructed by the clients in `MetadataResponse`.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-01-05 13:02:55,Jason Gustafson,Mixed
b80cf9c240989b5c7c742ef7594411eb24a3cf9f,"MINOR: make sure all dir jobs are completed (#9728)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-01-06 14:52:15,Chia-Ping Tsai,Mixed
bf55afecdab9fe00c9defcec04adb27856df93cc,"KAFKA-10778; Fence appends after write failure (#9676)

This patch improves append fencing after an IO error. Previously there was a window between the time of an IO error and the time the log is taken offline in which additional appends can be attempted. This is due to the asynchronous propagation of the IO error. This patch tightens the fencing so that no additional appends will be accepted after a previous append failed with an IO error.

Reviewers: Guozhang Wang <guozhang@apache.org>, Jason Gustafson <jason@confluent.io>",2021-01-06 10:06:56,Tom Bentley,Mixed
393139064f79ee664b6d8507ea1f974dad84c82e,"MINOR: code cleanup for Kafka Streams task interface (#9801)

Reviewer: John Roesler <john@confluent.io>",2021-01-06 13:51:07,Matthias J. Sax,Mixed
22e8e71156762b40ac93e2cbd42eacba00dbfb0c,"KAFKA-9274: Fix commit-TimeoutException handling for EOS (#9800)

If EOS is enabled and the TX commit fails with a timeout,
we should not process more messages (what is ok for non-EOS)
because we don't really know the status of the TX.
If the commit was indeed successful, we won't have an open TX
can calling send() would fail with an fatal error.

Instead, we should retry the (idempotent) commit of the TX,
and start a new TX afterwards.

Reviewers: Boyang Chen <boyang@confluent.io>, John Roesler <john@confluent.io>",2021-01-06 14:01:02,Matthias J. Sax,Mixed
52652a0dca647009a59ac9ed125e571a0e99af60,"KAFKA-10779; Reassignment tool sets throttles incorrectly when overriding a reassignment (#9807)

This patch fixes a bug when overriding a reassignment in `ReassignPartitionsCommand` due to the invalid assumption that adding replicas are not included in the full replica set. It also simplifies the logic to construct the move maps and makes some stylistic improvements.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-01-07 15:11:21,dengziming,Not TDD
ea459d1457084d162860452a7e2166b2b4d2f878,"KAFKA-12153; Update producer state before updating start/end offsets after truncation (#9838)

When we truncate the log, the first unstable offset might become valid. On the other hand, the logic in `updateHighWatermarkMetadata` assumes that the first stable offset remains at a valid position. Since this method can be reached through either `updateLogStartOffset` or `updateLogEndOffset` in the truncation paths, we need to ensure that the first unstable offset first reflects the truncated state.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Jun Rao <junrao@gmail.com>",2021-01-08 17:38:40,Jason Gustafson,Mixed
f06dff11030b3eebc9baa8e7ff95a1ce0c8f5997,"KAFKA-10887 Migrate log4j-appender module to JUnit 5 (#9785)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-01-10 14:59:31,Geordie,Not TDD
f62c2b26cc5f6fd7c0df7eb39eb834dc82ed576c,"MINOR: Factor `RaftManager` out of `TestRaftServer` (#9839)

This patch factors out a `RaftManager` class from `TestRaftServer` which will be needed when we integrate this layer into the server. This class encapsulates the logic to build `KafkaRaftClient` as well as its IO thread. 

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-01-11 09:28:12,Jason Gustafson,Mixed
aedb53a4e6313398ed9626fbd2fbd7106e2ce94e,"KAFKA-10500: Add KafkaStreams#removeStreamThread (#9695)

Add the ability to remove running threads

Reviewers: Bruno Cadonna <cadonna@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-01-11 12:38:02,Walker Carlson,Mixed
7455b701028337b53fe434e4ff16a2881975584e,"KAFKA-10895: Attempt to prevent JAAS config from being overwritten for basic auth filter in Connect (#9806)

If a connector, converter, etc. invokes [Configuration::setConfiguration](https://docs.oracle.com/javase/8/docs/api/javax/security/auth/login/Configuration.html#setConfiguration-javax.security.auth.login.Configuration-), it will cause the Connect basic auth filter to use that JAAS config instead of the one configured at startup with the `-Djava.security.auth.login.config` JVM property. This can cause requests to the worker to succeed initially but start to be rejected after the JVM's global JAAS config is altered.

To alleviate this the current PR instructs the Connect Worker to cache the JVM's global JAAS configuration at the beginning (as soon as the `BasicAuthSecurityRestExtension` class is loaded), and use that for all future authentication. 

Existing tests for the JAAS basic auth filter are modified to work with the new internal logic. The `testEmptyCredentialsFile` test is corrected to actually operate on an empty credentials file (instead of a non-existent credentials file, which it currently operates on). A new test is added to ensure that, even if the global JAAS config is overwritten, the basic auth filter will use the first one it could find.

Reviewers: Greg Harris <gregh@confluent.io>, Konstantine Karantasis <k.karantasis@gmail.com>",2021-01-11 21:20:57,Chris Egerton,Mixed
1e4d33524510769aff819ac9ef780ae1f904c3bc,"KAFKA-12180: Implement the KIP-631 message generator changes

* Implement the uint16 type
* Implement MetadataRecordType and MetadataJsonConverters

Reviewers: Jason Gustafson <jason@confluent.io>",2021-01-12 12:43:59,Colin P. Mccabe,Mixed
474ad1eebd7d80f5cfa2e5f783e6fd6aafcf388b,"KAFKA-12168; Move envelope request parsing out of SocketServer (#9850)

Prior to this patch, envelope handling was a shared responsibility between `SocketServer` and `KafkaApis`.  The former was responsible for parsing and validation, while the latter was responsible for authorization. This patch consolidates logic in `KafkaApis` so that envelope requests follow the normal request flow.

Reviewers: David Jacot <djacot@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2021-01-12 13:32:43,Jason Gustafson,Mixed
bed4c6a33b16b96c1a20f47d818f7a44eea33fa9,"KAFKA-12172 Migrate streams:examples module to JUnit 5 (#9857)

This PR includes following changes.
1. replace org.junit.Assert by org.junit.jupiter.api.Assertions
2. replace org.junit by org.junit.jupiter.api
3. replace Before by BeforeEach
4. replace After by AfterEach

Reviewers: Ismael Juma <ismael@confluent.io>",2021-01-13 21:02:13,Chia-Ping Tsai,Not TDD
94a0aac81d2d021826b52db1285c6b13b5ee2838,"MINOR: Add restoration time tracking (#9830)

Add Stream restoration time tracking log

Reviewers: John Roesler <vvcephei@apache.org>",2021-01-13 09:05:23,Boyang Chen,Mixed
ee08b0b32ad6af82ecdfac04134dbf52996374d8,"Only schedule AlterIsr thread when we have an ISR change (#9749)

This patch removes the periodic scheduling of a thread to send AlterISR requests and instead sends a request as soon as an ISR update is ready to send. When a response is received, the callback checks for any unsent items and will schedule another request if necessary.",2021-01-13 13:52:38,David Arthur,Mixed
52b8aa0fdce1872b5b525b62dc3ac2241cfaa379,"KAFKA-7340: Migrate clients module to JUnit 5 (#9874)

* Use the packages/classes from JUnit 5
* Move description in `assert` methods to last parameter
* Convert parameterized tests so that they work with JUnit 5
* Remove `hamcrest`, it didn't seem to add much value
* Fix `Utils.mkEntry` to have correct `equals` implementation
* Add a missing `@Test` annotation in `SslSelectorTest` override
* Adjust regex in `SaslAuthenticatorTest` due to small change in the
assert failure string in JUnit 5

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-01-13 16:17:45,Ismael Juma,Mixed
04827dad51583390a3b718a52a5d6f5931e8020c,"KAFKA-12171: Migrate streams:test-utils module to JUnit 5 (#9856)

* replace `org.junit.Assert` by `org.junit.jupiter.api.Assertions`
* replace `org.junit` by `org.junit.jupiter.api`
* replace `org.junit.runners.Parameterized` by `org.junit.jupiter.params.ParameterizedTest`
* replace `org.junit.runners.Parameterized.Parameters` by `org.junit.jupiter.params.provider.{Arguments, MethodSource}`
* replace `Before` by `BeforeEach`
* replace `After` by `AfterEach`

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-01-13 21:23:48,Chia-Ping Tsai,Not TDD
2cde6f61b8a3b4a13a771099c2a35f3013c46e70,"KAFKA-10304: Refactor MM2 integration tests (#9224)

Co-authored-by: Ning Zhang <nzhang1220@fb.com>
Reviewers: Mickael Maison <mickael.maison@gmail.com>",2021-01-14 14:48:17,Ning Zhang,Not TDD
217334b0f412e801bb3a3f5b10c71c1e33a2227a,"KAFKA-12183: Add the KIP-631 metadata record definitions (#9876)

Add the metadata gradle module, which will contain the metadata record
definitions, and other metadata-related broker-side code.

Add MetadataParser, MetadataParseException, etc.

Reviewers: José Armando García Sancio <jsancio@gmail.com>, Ismael Juma <ismael@juma.me.uk>, David Arthur <mumrah@gmail.com>",2021-01-14 09:58:52,Colin Patrick McCabe,Mixed
a68c14190e8e4654d75c01e2f2c2fad536332b6b,"KAFKA-12201: Migrate connect:basic-auth-extensio module to JUnit 5 (#9892)

Also:
* Remove unused powermock dependency
* Remove ""examples"" from the JUnit 4 list since one module was already
converted and the other has no tests

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-01-14 15:43:47,Ismael Juma,Not TDD
c49f660c621fc688a7998655e991b056bfde94a3,"MINOR: Initialize QuorumState lazily in RaftClient.initialize() (#9881)

It is helpful to delay initialization of the `RaftClient` configuration including the voter string until after construction. This helps in integration test cases where the voter ports may not be known until sockets are bound.

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",2021-01-14 17:31:54,Alok Nikhil,Mixed
0c92b8398dc1625e4cf601f170b262380fe3adf0,"KAFKA-12203 Migrate connect:mirror-client module to JUnit 5 (#9889)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-01-15 13:42:07,Chia-Ping Tsai,Not TDD
c9f3d5e7c455b66667f6cbc5b1dff4e40ff0b095,"KAFKA-12206: o.a.k.common.Uuid should implement Comparable (#9896)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2021-01-15 05:41:26,Colin Patrick McCabe,Mixed
9361a43cfa07ab8589336ddf831070284099be62,"MINOR: remove unused flag 'hasIdempotentRecords' (#9884)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-01-16 00:53:14,Chia-Ping Tsai,Mixed
3e6c6f595016e808906d59c8c845654e2b46e637,"KAFKA-12198: Migrate connect:json module to JUnit 5 (#9890)

Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>",2021-01-16 03:14:08,dengziming,Not TDD
ba1e16f0c02aeeaba54600c1a828f6cd13acf1a4,"MINOR: Upstream ApisUtils from kip-500 (#9715)

In the [KIP-500 development branch](https://github.com/confluentinc/kafka/tree/kip-500),
we have a separate ControllerApis that shares a lot of functionality with KafkaApis. We
introduced a utility class ApisUtils to pull out the common code. Some things were moved
to RequestChannel as well.

We'd like to upstream this work now so we don't continue to diverge (since KafkaApis is
a frequently modified class). There should be no logical changes in this PR, only shuffling
code around.

Reviewers: Jason Gustafson <jason@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Jose Sancio <jsancio@users.noreply.github.com>, Ismael Juma <ismael@juma.me.uk>",2021-01-15 12:28:43,David Arthur,Mixed
b5c107363fda42def9d750f8015542ecc187b6fc,"KAFKA-12208: Rename AdminManager to ZkAdminManager (#9900)

Rename AdminManager to ZkAdminManager to emphasize the fact that it is not used by the KIP-500 code paths.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Boyang Chen <boyang@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2021-01-15 12:56:09,Colin Patrick McCabe,Mixed
7ac06065f1e25158688fc3be316ce9571dc51335,"KAFKA-12161; Support raft observers with optional id (#9871)

We would like to be able to use `KafkaRaftClient` for tooling/debugging use cases. For this, we need the localId to be optional so that the client can be used more like a consumer. This is already supported in the `Fetch` protocol by setting `replicaId=-1`, which the Raft implementation checks for. We just need to alter `QuorumState` so that the `localId` is optional. The main benefit of doing this is that it saves tools the need to generate an arbitrary id (which might cause conflicts given limited Int32 space) and it lets the leader avoid any local state for these observers (such as `ReplicaState` inside `LeaderState`).

Reviewers: Ismael Juma <ismael@juma.me.uk>, Boyang Chen <boyang@confluent.io>",2021-01-15 14:10:17,Jason Gustafson,Mixed
06c9a391011251a38b0941c81cc2bc1f37922e01,"KAFKA-12214: Generated code does not include UUID or struct fields in its toString output (#9914)

Reviewers: Justine Olshan <jolshan@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2021-01-15 16:32:55,Colin Patrick McCabe,Not TDD
8f063c15da51d77a40aa63f110e48c5eeeaf5dfc,"MINOR: Generalize server startup to make way for KIP-500 (#9883)

This patch attempts to generalize server initialization for KIP-500. It adds a `Server` trait which `KafkaServer` extends for the legacy Zookeeper server, and a new `KafkaRaftServer` for the new server. I have also added stubs for `KafkaRaftBroker` and `KafkaRaftController` to give a clearer idea how this will be used.

Note that this patch removes `KafkaServerStartable`, which was intended to enable custom startup logic, but was not codified into an official API and is not planned to be supported after KIP-500. 

Reviewers: Ismael Juma <ismael@juma.me.uk>, Colin P. McCabe <cmccabe@apache.org>",2021-01-15 17:30:29,Jason Gustafson,Mixed
bfc96efa3a9a004f963cd4913fb2875c84bc9cb8,"KAFKA-10674: Controller API version bond with forwardable APIs (#9600)

Get controller api version intersection setup for client queries. When the unsupported exception was hit in the EnvelopeResponse, close the client connection to let it rediscover the api version.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-01-15 20:36:25,Boyang Chen,Mixed
6f9e73cfd87d551a27fbd6d68ce2a0cf94e857b1,"MINOR: Move a few more methods to AuthHelper (#9913)

And move some tests to `AuthHelperTest`.

Reviewers: David Arthur <mumrah@gmail.com>",2021-01-16 06:44:02,Ismael Juma,Mixed
4126cfd0492c0d97b3a0525c01ada1733800ec59,"KAFKA-12197: Migrate connect:transforms module to JUnit 5 (#9907)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-01-16 07:17:37,dengziming,Not TDD
e0ebb1d202e8865ccfa31ed066ed50b7198312f4,"KAFKA-12202 Migrate connect:mirror module to JUnit 5 (#9894)

1. Replace junit 4 APIs by junit 5
2. Remove the dependencies of junit 4 from `EmbeddedKafkaCluster`

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-01-16 09:30:04,Chia-Ping Tsai,Not TDD
962b69b5b31273d6072cc192fda60a89ef112f09,"KAFKA-12200: Migrate connect:file module to JUnit 5 (#9917)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2021-01-17 17:01:51,CHUN-HAO TANG,Not TDD
462be6da9b36b3e29268c94c1582f3b06c5d92c7,"KAFKA-12196: Migrate connect:api module to JUnit 5 (#9909)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2021-01-17 19:17:47,Geordie,Not TDD
5a4bbb9f91f583a9c27a2f64f28547033da4f4fb,"KAFKA-7341 Migrate core module to JUnit 5 (#9855)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-01-19 00:00:32,Chia-Ping Tsai,Not TDD
f2ac0c62ef19566b4303e23f8c817e157a3fc14f,"KAFKA-12221 remove PowerMock from connect-json module and connect-transforms module (#9924)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-01-19 00:05:44,Chia-Ping Tsai,Mixed
6752f2825444ad652930d708c6665c5e49a9b69a,"KAFKA-12195 Fix synchronization issue happening in KafkaStreams (#9887)

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2021-01-19 17:54:34,Chia-Ping Tsai,Not TDD
f7c0b0d1728c0d5ccac90776be86d2c4740633cc,"MINOR: Replace ApiVersion by auto-generated protocol (#9746)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-01-20 00:37:45,Chia-Ping Tsai,Mixed
302eee63c479fd4b955c44f1058a5e5d111acb57,"KAFKA-12204; Implement DescribeCluster API in the broker (KIP-700) (#9903)

This PR implements the DescribeCluster API in the broker.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>",2021-01-19 18:43:36,David Jacot,Mixed
0158e1d7196748aa346da90f688048a32f75c2d1,"MINOR: Add 'task container' class to KafkaStreams TaskManager (#9835)

Kafka Streams' TaskManager is a central class that grew quite big. This
PR breaks out a new 'task container' class to descope what TaskManager
does. In follow up PRs, we plan to move more methods from TaskManager
to the new 'Tasks.java' class and also improve task-type type safety.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>",2021-01-19 19:28:46,Matthias J. Sax,Mixed
287b600cf712a4a7e9139e15e1151768f67eec75,"KAFKA-12210; AdminClient should use DescribeCluster API when available (KIP-700) (#9905)

This PR updates the AdminClient to use the DescribeCluster API when available. The clients fails back to the Metadata API otherwise.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2021-01-20 17:45:45,David Jacot,Mixed
462c89e0b436abd56864bea8bbcaf1ab70b7f66e,"KAFKA-12211: don't change perm for base/state dir when no persistent store (#9904)

 If a user doesn't have Persistent Stores, we won't create base dir and state dir and should not try to set permissions on them.

Reviewers: Bruno Cadonna <cadonna@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-01-20 11:37:56,Luke Chen,Mixed
86b9fdef2b9e6ef3429313afbaa18487d6e2906e,"KAFKA-10869: Gate topic IDs behind IBP 2.8 (KIP-516) (#9814)

Topics processed by the controller and topics newly created will only be given topic IDs if the inter-broker protocol version on the controller is greater than 2.8. This PR also adds a kafka config to specify whether the IBP is greater or equal to 2.8. System tests have been modified to include topic ID checks for upgrade/downgrade tests. This PR also adds a new integration test file for requests/responses that are not gated by IBP (ex: metadata) 

Reviewers: dengziming <dengziming1993@gmail.com>, Lucas Bradstreet <lucas@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2021-01-20 22:32:06,Justine Olshan,Mixed
484c99e200cb16ee950ebb5e35b37a40e46163ca,"KAFKA-12175 Migrate generator module to junit5 (#9926)

Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>",2021-01-21 11:42:47,bertber,Not TDD
62860fa0a15a474130d63a9459b5ddb5335b5987,"MINOR: Remind user index file is empty when dumping LogSegment index file (#9891)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-01-21 12:06:35,17hao,Mixed
eb026fcf82db3daccb9e4108c0347fa6d5af187c,"KAFKA-12152; Idempotent Producer does not reset the sequence number of partitions without in-flight batches (#9832)

When a `OutOfOrderSequenceException` error is received by an idempotent producer for a partition, the producer bumps its epoch, adjusts the sequence number and the epoch of the in-flight batches of the partitions affected by the `OutOfOrderSequenceException` error. This happens in `TransactionManager#bumpIdempotentProducerEpoch`.

The remaining partitions are treated separately. When the last in-flight batch of a given partition is completed, the sequence number is reset. This happens in `TransactionManager#handleCompletedBatch`.

However, when a given partition does not have in-flight batches when the producer epoch is bumped, its sequence number is not reset. Similarly, when a in-flight batch eventually fails after the producer epoch is bumped, the batch is discarded and sequence number for its partition is not reset. In both cases, it results in having subsequent producer request to use the new producer epoch with the old sequence number and to be rejected by the broker.

With this patch, the producer id/epoch is now stored in the partition state. This ensure that the producer id/epoch of a given partition remains consistent with its sequence number. When the producer epoch is bumped, the producer epoch of the partition is lazily updated and its sequence number is reset accordingly. This happens only when all the in-flight batches have been resolved.

Reviewers: Bob Barrett <bob.barrett@confluent.io>, Jason Gustafson <jason@confluent.io>",2021-01-21 09:38:19,David Jacot,Mixed
92e72f7bf96841d7991f1d71f440c2da06dd89cf,"KAFKA-12185: fix ConcurrentModificationException in newly added Tasks container class (#9940)

Reviewers: Guozhang Wang <guozhand@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",2021-01-21 08:52:34,Matthias J. Sax,Not TDD
fea2f65929e7283df09bdc1c82dd248abc4cdd45,"MINOR: Import RaftConfig config definitions into KafkaConfig (#9916)

This patch moves Raft config definitions from `RaftConfig` to `KafkaConfig`, where they are re-defined as internal configs until we are ready to expose them. It also adds the missing ""controller"" prefix that was added by KIP-631.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-01-21 10:26:23,Alok Nikhil,Mixed
9689a313f52a7b45f38faecddf018dc8ab02dc62,"MINOR: Drop enable.metadata.quorum config (#9934)

The primary purpose of this patch is to remove the internal `enable.metadata.quorum` configuration. Instead, we rely on `process.roles` to determine if the self-managed quorum has been enabled. As a part of this, I've done the following:

1. Replace the notion of ""disabled"" APIs with ""controller-only"" APIs. We previously marked some APIs which were intended only for the KIP-500 as ""disabled"" so that they would not be unintentionally exposed. For example, the Raft quorum APIs were disabled. Marking them as ""controller-only"" carries the same effect, but makes the intent that they should be only exposed by the KIP-500 controller clearer.
2. Make `ForwardingManager` optional in `KafkaServer` and `KafkaApis`. Previously we used `null` if forwarding was enabled and relied on the metadata quorum check.
3. Make `zookeeper.connect` an optional configuration if `process.roles` is defined.
4. Update raft README to remove reference to `zookeeper.conntect`

Reviewers: Colin Patrick McCabe <cmccabe@confluent.io>, Boyang Chen <boyang@confluent.io>",2021-01-21 15:16:15,Jason Gustafson,Mixed
7a1d1d9a69a241efd68e572badee999229b3942f,"KAFKA-12212; Bump Metadata API version to remove `ClusterAuthorizedOperations` fields (KIP-700) (#9945)

This patch bumps the version of the Metadata API and removes the `IncludeClusterAuthorizedOperations` and the `IncludeClusterAuthorizedOperations` fields from version 11 and onward.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2021-01-22 09:06:37,David Jacot,Not TDD
019cd4ab80f21f8234f96d151fc0e649916bf4ab,"KAFKA-10357: Extract setup of repartition topics from Streams partition assignor (#9848)

KIP-698: extract the code for the setup of the repartition topics from the Streams partition assignor so that it can also be called outside of a rebalance.

Reviewers: Leah Thomas <lthomas@confluent.io> , Guozhang Wang <guozhang@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-01-22 10:03:39,Bruno Cadonna,Mixed
6d411620ddb731fd5eb5b05280b89d31ac52ee3d,"MINOR: A few small group coordinator cleanups (#9952)

A few small cleanups in `GroupCoordinator` and related classes:

- Remove redundant `groupId` field from `MemberMetadata`
- Remove redundant `isStaticMember` field from `MemberMetadata`
- Fix broken log message in `GroupMetadata.loadGroup` and apply it to all loaded members
- Remove ancient TODOs and no-op methods from `GroupCoordinator`
- Move removal of static members into `GroupMetadata.remove`

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>",2021-01-23 13:07:31,Jason Gustafson,Mixed
411ac7d4c0df9359eec9068018da60ffb02cbb50,"MINOR: Remove `toStruct` and `fromStruct` methods from generated protocol classes (#9960)

Update few classes that were still using the removed methods (including
tests that are no longer required).

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-01-25 04:41:30,Ismael Juma,Mixed
e1a4dccc15676713ca4a9a47096975bc8dd38b8b,"KAFKA-12190: Fix setting of file permissions on non-POSIX filesystems (#9947)

Previously, StateDirectory used PosixFilePermissions to configure its directories' permissions which fails on Windows as its file system is not POSIX-compliant. This PR updates StateDirectory to fall back to the File API on non-POSIX-compliant file systems. 

Reviewers: Luke Chen <43372967+showuon@users.noreply.github.com>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-01-25 11:33:05,Andy Wilkinson,Mixed
45b7a0a334970dadb842dbc4e781606b54288485,"KAFKA-12229: Restore original class loader in integration tests using EmbeddedConnectCluster during shutdown  (#9942)

Fixes errors such as: 
```
java.lang.NullPointerException at 
org.apache.kafka.connect.mirror.MirrorSourceConnector.listTopics(MirrorSourceConnector.java:348) at 
org.apache.kafka.connect.mirror.MirrorSourceConnector.findSourceTopicPartitions(MirrorSourceConnector.java:192) at 
org.apache.kafka.connect.mirror.MirrorSourceConnectorTest.testRefreshTopicPartitionsTopicOnTargetFirst(MirrorSourceConnectorTest.java:222)
```

It was a difficult to debug issue due to class loading interference between the Connect worker and Mockito. Digging into the Mockito, found it's not about JUnit 5, it's because of the class loader. In Mockito, we rely on the class loader to generate the proxy instance ([source](https://github.com/mockito/mockito/blob/release/3.x/src/main/java/org/mockito/internal/creation/bytebuddy/SubclassBytecodeGenerator.java#L91)) to intercept the method call, and if the class loader is not expected, we'll generate the wrong proxy instance (with wrong class path). We set the class loader during connector start to resolve conflicting dependencies ([KIP-146](https://cwiki.apache.org/confluence/display/KAFKA/KIP-146+-+Classloading+Isolation+in+Connect)), so we should set it back to the original class loader after connector stop in tests (`EmbeddedConnectCluster` is only used in tests) for the following Mockito works as expected.

So, there's an interference of integration tests with unit tests when Connect integration tests run before the MM2 unit tests, and that will cause the Mockito used in unit tests not work as expected.

Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>",2021-01-25 19:36:57,Luke Chen,Not TDD
f572545611b3e5daa71bd7b3f0c20cba01dfb46d,"KAFKA-10763: Fix incomplete cooperative rebalances preventing connector/task revocations (#9765)

When two cooperative rebalances take place soon after one another, a prior rebalance may not complete before the next rebalance is started.
Under Eager rebalancing, no tasks would have been started, so the subsequent onRevoked call is intentionally skipped whenever rebalanceResolved was false.
Under Incremental Cooperative rebalancing, the same logic causes the DistributedHerder to skip stopping all of the connector/task revocations which occur in the second rebalance.
The DistributedHerder still removes the revoked connectors/tasks from its assignment, so that the DistributedHerder and Worker have different knowledge of running connectors/tasks.
This causes the connector/task instances that would have been stopped to disappear from the rebalance protocol, and left running until their workers are halted, or they fail.
Connectors/Tasks which were then reassigned to other workers by the rebalance protocol would be duplicated, and run concurrently with zombie connectors/tasks.
Connectors/Tasks which were reassigned back to the same worker would encounter exceptions in Worker, indicating that the connector/task existed and was already running.

* Added test for revoking and then reassigning a connector under normal circumstances
* Added test for revoking and then reassigning a connector following an incomplete cooperative rebalance
* Changed expectRebalance to make assignment fields mutable before passing them into the DistributedHerder
* Only skip revocation for the Eager protocol, and never skip revocation for incremental cooperative protocols

Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>",2021-01-26 10:17:05,Greg Harris,Mixed
a26db2a1ec931fa43b350b37639e6116b7ccffc4,"KAFKA-10694; Implement zero copy for FetchSnapshot (#9819)

This patch adds zero-copy support for the `FetchSnapshot` API. Unlike the normal `Fetch` API, records are not assumed to be offset-aligned in `FetchSnapshot` responses. Hence this patch introduces a new `UnalignedRecords` type which allows us to use most of the existing logic to support zero-copy while preserving type safety in the snapshot APIs.

Reviewers: José Armando García Sancio <jsancio@gmail.com>, Jason Gustafson <jason@confluent.io>",2021-01-26 10:33:36,dengziming,Mixed
647c609cef3914f7cf2923314c4e99714d86ca25,"KAFKA-10555: Improve client state machine (#9720)

Implements KIP-696: Add new state PENDING_ERROR to KafkaStreams client.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bruno Cadonna <bruno@confluent.io>",2021-01-26 11:43:49,Walker Carlson,Mixed
91c504c55a04e6d3a3d7623b5e02633440ec53d3,"KAFKA-12233: Align the length passed to FileChannel by `FileRecords.writeTo` (#9970)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-01-27 12:51:28,dengziming,Mixed
8bdab2e4cf0d6a1d4ff3bb3b30f9db22c146bd8c,"MINOR: Remove outdated comment in Connect's WorkerCoordinator (#9805)

Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2021-01-27 14:50:01,Chris Egerton,Mixed
fdcf8fbf72bee9e672d0790cdbe5539846f7dc8e,"KAFKA-10866: Add metadata to ConsumerRecords (#9836)

Expose fetched metadata via the ConsumerRecords
object as described in KIP-695.

Reviewers: Guozhang Wang <guozhang@apache.org>",2021-01-27 18:18:38,John Roesler,Mixed
4d28391480fd8c547a63af119bba67fceb5d2ede,"KAFKA-10867: Improved task idling (#9840)

Use the new ConsumerRecords.metadata() API to implement
improved task idling as described in KIP-695

Reviewers: Guozhang Wang <guozhang@apache.org>",2021-01-27 21:57:20,John Roesler,Mixed
923dea34b8b778a17080a3d8a4d9d9f36410e1ba,"KAFKA-10658 ErrantRecordReporter.report always return completed futur… (#9525)

Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>",2021-01-28 14:12:54,Chia-Ping Tsai,Mixed
550d8b82609ed3771f15d908bcf00fade2d2511e,"KAFKA-8744: Update Scala API to give names to processors (#9738)

As it's only API extension to match the java API with Named object with lots of duplication, I only tested the logic once.

Reviewers: Bill Bejeck <bbejeck@apache.org>",2021-01-28 09:57:18,mathieu,Mixed
a63094930fe38c6d8ef2d6a2c820460c255eb046,"KAFKA-10710; MM2 - Create herders only if source->target.enabled=true and heartbeats are disabled (#9589)

By default Mirror Maker 2 creates herders for all the possible combinations even if the ""links"" are not enabled.

This is because the beats are emitted from the ""opposite"" herder.
If there is a replication flow from A to B and heartbeats are required, 2 herders are needed :

- A->B for the MirrorSourceConnector
- B->A for the MirrorHeartbeatConnector

The MirrorHeartbeatConnector on B->A emits beats into topic heartbeats on cluster A.
The MirrorSourceConnector on A->B then replicates whichever topic is configured as well as heartbeats.

In cases with multiple clusters (10 and more), this leads to an incredible amount of connections, file descriptors and configuration topics created in every target clusters that are not necessary.

With this code change, we will leverage the top level property ""emit.heartbeats.enabled"" which defaults to ""true"".
We skip creating the A->B herder whenever A->B.emit.heartbeats.enabled=false (defaults to true) and A->B.enabled=false (defaults to false). 

Existing users will not see any change and if they depend on these ""opposites"" herders for their monitoring, it will still work.
New users with more complex use case can change this property and fine tune their heartbeat generation.

Reviewers: Ryanne Dolan <ryannedolan@gmail.com>,  Sanjana Kaundinya <skaundinya@gmail.com>, Jason Gustafson <jason@confluent.io>",2021-01-28 14:52:51,Julien Chanaud,Mixed
27a998e8a06461145dfa8016f7fcd379debd3cbb,"KAFKA-12237; Support lazy initialization of quorum voter addresses (#9985)

With KIP-595, we previously expect `RaftConfig` to specify the quorum voter endpoints upfront on startup. In the general case, this works fine. However, for testing where the bound port is not known ahead of time, we need a lazier approach that discovers the other voters in the quorum after startup. 

In this patch, we take the voter endpoint initialization out of `KafkaRaftClient.initialize` and move it to `RaftManager`. We use a special address to indicate that the voter addresses will be provided later This approach also lends itself well to future use cases where we might discover voter addresses through an external service (for example).

Reviewers: Jason Gustafson <jason@confluent.io>",2021-01-28 17:14:56,Alok Nikhil,Mixed
e3ff4b087050b5a4b3f819a9535fb8275a380e23,"KAFKA-10604: Fix Streams default state.dir (#9420)

Make the default state store directory location to follow
OS-specific temporary directory settings or java.io.tmpdir
JVM parameter, with Utils#getTempDir.

Reviewers: Matthias J. Sax <mjsax@apache.org>, John Roesler <vvcephei@apache.org>",2021-01-29 09:45:13,Lee Dongjin,Mixed
4f588f7ca2a1c5e8dd845863da81425ac69bac92,"KAFKA-10764: Add support for returning topic IDs on create, supplying topic IDs for delete (#9684)

Updated CreateTopicResponse, DeleteTopicsRequest/Response and added some new AdminClient methods and classes. Now the newly created topic ID will be returned in CreateTopicsResult and found in TopicAndMetadataConfig, and topics can be deleted by supplying topic IDs through deleteTopicsWithIds which will return DeleteTopicsWithIdsResult.

Reviewers: dengziming <dengziming1993@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2021-01-29 19:40:16,Justine Olshan,Mixed
bd6c212538984399e78ab6a3493a15270b38eca9,"KAFKA-12247: add timeout and static group rebalance to remove thread (#9984)

Add timeout to remove thread, and trigger thread to explicitly leave the group even in case of static membership

Reviewers: Bruno Cadonna <bruno@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-01-29 12:35:34,Walker Carlson,Mixed
5b3351e10b339f5ef43fa4ec9e23544acad298c3,"KAFKA-10761; Kafka Raft update log start offset (#9816)

Adds support for nonzero log start offsets.

Changes to `Log`:
1. Add a new ""reason"" for increasing the log start offset. This is used by `KafkaMetadataLog` when a snapshot is generated.
2. `LogAppendInfo` should return if it was rolled because of an records append. A log is rolled when a new segment is created. This is used by `KafkaMetadataLog` to in some cases delete the created segment based on the log start offset.

Changes to `KafkaMetadataLog`:
1. Update both append functions to delete old segments based on the log start offset whenever the log is rolled.
2. Update `lastFetchedEpoch` to return the epoch of the latest snapshot whenever the log is empty.
3. Add a function that empties the log whenever the latest snapshot is greater than the replicated log. This is used when first loading the `KafkaMetadataLog` and whenever the `KafkaRaftClient` downloads a snapshot from the leader.

Changes to `KafkaRaftClient`:
1. Improve `validateFetchOffsetAndEpoch` so that it can handle fetch offset and last fetched epoch that are smaller than the log start offset. This is in addition to the existing code that check for a diverging log. This is used by the raft client to determine if the Fetch response should include a diverging epoch or a snapshot id. 
2. When a follower finishes fetching a snapshot from the leader fully truncate the local log.
3. When polling the current state the raft client should check if the state machine has generated a new snapshot and update the log start offset accordingly.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-01-29 14:06:01,José Armando García Sancio,Mixed
e9edf104866822d9e6c3b637ffbf338767b5bf27,"KAFKA-12238; Implement `DescribeProducers` API from KIP-664 (#9979)

Implements the `DescribeProducers` API specified by KIP-664: https://cwiki.apache.org/confluence/display/KAFKA/KIP-664%3A+Provide+tooling+to+detect+and+abort+hanging+transactions.

Reviewers: David Jacot <djacot@confluent.io>",2021-01-29 17:00:14,Jason Gustafson,Mixed
7205cd36e41d1beb3d8f375e1cfdf3c80e0ef06c,"KAFKA-12236; New meta.properties logic for KIP-500 (#9967)

This patch contains the new handling of `meta.properties` required by the KIP-500 server as specified in KIP-631. When using the self-managed quorum, the `meta.properties` file is required in each log directory with the new `version` property set to 1. It must include the `cluster.id` property and it must have a `node.id` matching that in the configuration.

The behavior of `meta.properties` for the Zookeeper-based `KafkaServer` does not change. We treat `meta.properties` as optional and as if it were `version=0`. We continue to generate the clusterId and/or the brokerId through Zookeeper as needed.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>",2021-01-30 17:05:31,Jason Gustafson,Mixed
db73d86ea65413af73a95268f1a10787079f79d9,"KAFKA-10636; Bypass log validation and offset assignment for writes from the raft leader (#9739)

Since the Raft leader is already doing the work of assigning offsets and the leader epoch, we can skip the same logic in `Log.appendAsLeader`. This lets us avoid an unnecessary round of decompression.

Reviewers: dengziming <dengziming1993@gmail.com>, Jason Gustafson <jason@confluent.io>",2021-02-01 10:05:47,feyman2016,Mixed
62218a05d3c1564fadd1cb64daf4932107f10819,"MINOR: Factor out controller node provider `BrokerToControllerChannelManager` (#10015)

This patch factors out a trait to allow for other ways to provide the controller `Node` object to `BrokerToControllerChannelManager`. In KIP-500, the controller will be provided from the Raft client and not the metadata cache.

Reviewers: David Arthur <david.arthur@confluent.io>",2021-02-01 14:30:53,Jason Gustafson,Not TDD
f5a2fbac6d26fc1613ec34d9764a1e86732f0a45,"KAFKA-10366 & KAFKA-9649: Implement KIP-659 to allow TimeWindowedDeserializer and TimeWindowedSerde to handle window size (#9253)

See KIP details and discussions here: https://cwiki.apache.org/confluence/display/KAFKA/KIP-659%3A+Improve+TimeWindowedDeserializer+and+TimeWindowedSerde+to+handle+window+size

Deprecates methods that allow users to skip setting a window size when one is needed. Adds a window size streams config to allow the timeWindowedDeserializer to calculate window end time.

Reviewers: Walker Carlson <wcarlson@confluent.io>, John Roesler <vvcephei@apache.org>, Guozhang Wang <wangguoz@gmail.com>",2021-02-01 16:20:35,leah,Mixed
a022072df3c8175950c03263d2bbf2e3ea7a7a5d,"KAFKA-12248; Add BrokerHeartbeat/BrokerRegistration RPCs for KIP-500 (#9994)

This patch adds the schemas and request/response objects for the `BrokerHeartbeat` and `BrokerRegistration` APIs that were added as part of KIP-631. These APIs are only exposed by the KIP-500 controller and not advertised by the broker.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-02-01 21:59:30,Alok Nikhil,Mixed
5c562efb2d76407011ea88c1ca1b2355079935bc,"KAFKA-10700 - Support mutual TLS authentication for SASL_SSL listeners (KIP-684) (#10007)

mTLS is enabled if listener-prefixed ssl.client.auth is configured for SASL_SSL listeners. Broker-wide ssl.client.auth is not applied to SASL_SSL listeners as before, but we now print a warning.

Reviewers: David Jacot <djacot@confluent.io>",2021-02-02 14:56:23,Rajini Sivaram,Mixed
1711cfa4ebe325b2445d7bf00cf3e8b93377e4b1,"KAFKA-12209: Add the timeline data structures for the KIP-631 controller (#9901)

Reviewers: Jun Rao <junrao@gmail.com>",2021-02-02 11:33:55,Colin Patrick McCabe,Mixed
e260f64a9c763f30df13e6694893cdcc15a1acfe,"KAFKA-10413: Allow for even distribution of lost/new tasks when multiple Connect workers join at the same time (#9319)

First issue: When more than one workers join the Connect group the incremental cooperative assignor revokes and reassigns at most average number of tasks per worker.
Side-effect: This results in the additional workers joining the group stay idle and would require more future rebalances to happen to have even distribution of tasks.
Fix: As part of task assignment calculation following a deployment, the reassignment of tasks are calculated by revoking all the tasks above the rounded up (ceil) average number of tasks.

Second issue: When more than one worker is lost and rejoins the group at most one worker will be re assigned with the lost tasks from all the workers that left the group.
Side-effect: In scenarios where more than one worker is lost and rejoins the group only one among them gets assigned all the partitions that were lost in the past. The additional workers that have joined would not get any task assigned to them until a rebalance that happens in future.
Fix: As part fo lost task re assignment all the new workers that have joined the group would be considered for task assignment and would be assigned in a round robin fashion with the new tasks.

Testing strategy : 
* System testing in a Kubernetes environment completed
* New integration tests to test for balanced tasks
* Updated unit tests. 

Co-authored-by: Rameshkrishnan Muthusamy <rameshkrishnan_muthusamy@apple.com>
Co-authored-by: Randall Hauch <rhauch@gmail.com>
Co-authored-by: Konstantine Karantasis <konstantine@confluent.io>

Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <k.karantasis@gmail.com>",2021-02-02 12:04:06,Ramesh Krishnan M,Mixed
2ab5301085fa4ad5db778953505c317875e299a2,"MINOR: Upstream QuotaConfigs

This PR moves static property definitions for user client quotas into a
new class called QuotaConfigs in the clients module under the
o.a.k.common.config.internals package. This is needed to support the
client quotas work in the quorum based controller.

Reviewers: Colin McCabe <cmccabe@apache.org>",2021-02-02 21:29:51,Colin P. Mccabe,Mixed
e31d3d46427e59cca9e3df19bf0bd79bc827b7d3,"MINOR: Add HostedPartition.Deferred state in ReplicaManager (#10003)

Brokers receive metadata from the Raft metadata quorum very differently than they do from
ZooKeeper today, and this has implications for ReplicaManager.  In particular, when a broker
reads the metadata log it may not arrive at the ultimate state for a partition until it reads multiple
messages.  In normal operation the multiple messages associated with a state change will all
appear in a single batch, so they can and will be coalesced and applied together.  There are
circumstances where messages associated with partition state changes will appear across
multiple batches and we will be forced to coalesce these multiple batches together.  The
circumstances when this occurs are as follows:

- When the broker restarts it must ""catch up"" on the metadata log, and it is likely that the
broker will see multiple partition state changes for a single partition across different
batches while it is catching up.  For example, it will see the `TopicRecord` and the
`PartitionRecords` for the topic creation, and then it will see any `IsrChangeRecords`
that may have been recorded since the creation.  The broker does not know the state of
the topic partitions until it reads and coalesces all the messages.
- The broker will have to ""catch up"" on the metadata log if it becomes fenced and then
regains its lease and resumes communication with the metadata quorum.
- A fenced broker may ultimately have to perform a ""soft restart"" if it was fenced for so
long that the point at which it needs to resume fetching the metadata log has been
subsumed into a metadata snapshot and is no longer independently fetchable.  A soft
restart will entail some kind of metadata reset based on the latest available snapshot
plus a catchup phase to fetch after the snapshot end point.

The first case -- during startup -- occurs before clients are able to connect to the broker.
Clients are able to connect to the broker in the second case.  It is unclear if clients will be
able to to connect to the broker during a soft restart (the third case).

We need a way to defer the application of topic partition metadata in all of the above cases,
and while we are deferring the application of the metadata the broker will not service clients
for the affected partitions.

As a side note, it is arguable if the broker should be able to service clients while catching up
or not.  The decision to not service clients has no impact in the startup case -- clients can't
connect yet at that point anyway.  In the third case it is not yet clear what we are going to do,
but being unable to service clients while performing a soft reset seems reasonable.  In the
second case it is most likely true that we will catch up quickly; it would be unusual to
reestablish communication with the metadata quorum such that we gain a new lease and
begin to catch up only to lose our lease again.

So we need a way to defer the application of partition metadata and make those partitions
unavailable while deferring state changes.  This PR adds a new internal partition state to
ReplicaManager to accomplish this.  Currently the available partition states are simple
`Online`, `Offline` (meaning a log dir failure) and `None` (meaning we don't know about it). 
We add a new `Deferred` state.  We also rename a couple of methods that refer to
""nonOffline"" partitions to instead refer to ""online"" partitions.

**The new `Deferred` state never happens when using ZooKeeper for metadata storage.**
Partitions can only enter the `Deferred` state when using a KIP-500 Raft metadata quorum
and one of the above 3 cases occurs.  The testing strategy is therefore to leverage existing
tests to confirm that there is no functionality change in the ZooKeeper case.  We will add
the logic for deferring/applying/reacting to deferred partition state in separate PRs since
that code will never be invoked in the ZooKeeper world.

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2021-02-03 01:19:36,Ron Dagostino,Mixed
3f36f9a7ca153a9d221f6bedeb7d1503aa18eff1,"KAFKA-12249: Add client-side Decommission Broker RPC (KIP-500) (#9996)

Reviewers: Jason Gustafson <jason@confluent.io>",2021-02-03 05:46:46,Alok Nikhil,Mixed
49f9229ea61bc0a79df32dd71685b2b2d2d55a0a,"MINOR: Introduce ProducerIdGenerator trait (#10009)

`ProducerIdManager` is an existing class that talks to ZooKeeper directly.  We won't have ZooKeeper
when using a Raft-based metadata quorum, so we need an abstraction for the functionality of
generating producer IDs.  This PR introduces `ProducerIdGenerator` for this purpose, and we pass
an implementation when instantiating `TransactionCoordinator` rather than letting
`TransactionCoordinator.apply()` itself always create a ZooKeeper-based instance.

Reviewers: David Arthur <mumrah@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2021-02-03 08:11:22,Ron Dagostino,Mixed
51833bf37c7ab5ce24aed82749d45f5c8550d12f,"KAFKA-10648: Add Prefix Scan support to State Stores (#9508)

Add prefix scan support to State stores. Currently, only RocksDB and InMemory key value stores are being supported.

Reviewers: Bruno Cadonna <bruno@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2021-02-03 10:26:30,vamossagar12,Mixed
3acc1938534131c6e84a0be4e8839c33bc034bfe,"MINOR: Add mock implementation of `BrokerToControllerChannelManager` (#10026)

Tests involving `BrokerToControllerChannelManager` are simplified by being able to leverage `MockClient`. This patch introduces a `MockBrokerToControllerChannelManager` implementation which makes that possible.

The patch updates `ForwardingManagerTest` to use `MockBrokerToControllerChannelManager`. We also add a couple additional timeout cases, which exposed a minor bug. Previously we were using the wrong `TimeoutException`, which meant that expected timeout errors were in fact translated to `UNKNOWN_SERVER_ERROR`.

Reviewers: David Arthur <david.arthur@confluent.io>",2021-02-03 10:30:20,Jason Gustafson,Mixed
772f2cfc828d9da56559968a8eed06f2c8c43062,"MINOR: Replace BrokerStates.scala with BrokerState.java (#10028)

Replace BrokerStates.scala with BrokerState.java, to make it easier to use from Java code if needed.  This also makes it easier to go from a numeric type to an enum.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-02-03 13:41:38,Colin Patrick McCabe,Mixed
0fe9fde376cb1dc63184fea9d1fdc7ebc0c8531f,"KAFKA-10895: Gracefully handle invalid JAAS configs (follow up fix) (#9987)

Fixes a regression introduced by https://github.com/apache/kafka/pull/9806 in the original fix for KAFKA-10895

It was discovered that if an invalid JAAS config is present on the worker, invoking Configuration::getConfiguration throws an exception. The changes from #9806 cause that exception to be thrown during plugin scanning, which causes the worker to fail even if it is not configured to use the basic auth extension at all.

This follow-up handles invalid JAAS configurations more gracefully, and only throws them if the worker is actually configured to use the basic auth extension, at the time that the extension is instantiated and configured.

Two unit tests are added.

Reviewers: Greg Harris <gregh@confluent.io>, Konstantine Karantasis <k.karantasis@gmail.com>",2021-02-03 13:51:03,Chris Egerton,Mixed
e119ea66cb1458637039c16169728c9e9989ec52,"KAFKA-12271 Immutable container classes to support new MetadataCache (#10018)

Three new classes are added to support the upcoming changes to MetadataCache
required for handling Raft metadata records.

Reviewers: Jason Gustafson <jason@confluent.io>

Co-authored-by: David Arthur <mumrah@gmail.com>",2021-02-03 17:08:13,Colin P. Mccabe,Mixed
c64241f9c2b066f68ddbab2a21650daa856838dc,"KAFKA-12259: Use raw config to infer the connector type when returning a connector status response (#10040)

Problem: when calling the connect status endpoint, a 500 error is returned, e.g.
```
{
  ""error_code"": 500,
  ""message"": ""Could not read properties from file /tmp/somefile.properties""
}
```
when any of the connectors has an exception from the config provider. This is because the `AbstractHerder` is trying to use the resolved config to infer the type of the connector. However, only the `connector.class` is needed from the config to infer if a specific connector is of source or sink type. The endpoint should still return the status of the connector instead of a 500 error.

This change uses the raw config from the config backing store to retrieve the connector class to avoid any variable resolution.

Unit tests have been updated to reflect this change.

Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>",2021-02-03 15:39:32,Yilong Chang,Mixed
f58c2acf2676e1375fbca6f421f321549619c558,"KAFKA-12250; Add metadata record serde for KIP-631 (#9998)

This patch adds a `RecordSerde` implementation for the metadata record format expected by KIP-631. 

Reviewers: Colin McCabe <cmccabe@apache.org>, Ismael Juma <mlists@juma.me.uk>",2021-02-03 16:16:35,Jason Gustafson,Mixed
5eb8a238e29184b84f0b675eec3df538572c973c,"KAFKA-12270: Handle race condition when Connect tasks attempt to create topics (#10032)

When a source connector is configured to create missing topics has multiple tasks that generate records for the same topic, it is possible that multiple tasks may simultaneously describe the topic, find it does not exist, and attempt to create the task. One of those create topic requests will succeed, and the other concurrent tasks will receive the response from the topic admin as having not created the task and will fail unnecessarily.

This change corrects the logic by moving the `TopicAdmin` logic to create a topic to a new `createOrFindTopics(…)` method that returns the set of created topic names and the set of existing topic names. This allows the existing `createTopics(…)` and `createTopic(…)` methods to retain the same behavior, but also allows the `WorkerSourceTask` to know from its single call to this new method whether the topic was created or was found to exist.

This adds one unit test and modifies several unit tests in `WorkerSourceTaskWithTopicCreationTest` that use mocks to verify the behavior, and modifies several existing unit tests for `TopicAdminTest` to ensure the logic of the new method is as expected.

Author: Randall Hauch <rhauch@gmail.com>
Reviewer: Konstantine Karantasis <konstantine@confluent.io>",2021-02-03 18:29:55,Randall Hauch,Mixed
706f5097b70ce140e6a0473ad55342b514b6db04,"KAFKA-10716: persist UUID in state directory for stable processId across restarts (#9978)

To stabilize the task assignment across restarts of the JVM we need some way to persist the process-specific UUID. We can just write it to a file in the state directory, and initialize it from there or create a new one if no prior UUID exists.

Reviewers: Walker Carlson <wcarlson@confluent.io>, Leah Thomas <lthomas@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2021-02-03 18:01:26,A. Sophie Blee-Goldman,Mixed
131d4753cfed65ed6dee0a8c754765c97c3d513f,"KAFKA-12193: Re-resolve IPs after a client disconnects (#9902)

This patch changes the NetworkClient behavior to resolve the target node's hostname after disconnecting from an established connection, rather than waiting until the previously-resolved addresses are exhausted. This is to handle the scenario when the node's IP addresses have changed during the lifetime of the connection, and means that the client does not have to try to connect to invalid IP addresses until it has tried each address.

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Satish Duggana <satishd@apache.org>, David Jacot <djacot@confluent.io>",2021-02-04 11:42:43,Bob Barrett,Mixed
c19a35d1b740c85559a7ff4e882fc95b4737808d,"KAFKA-10835: Replace Runnable and Callable overrides with lambdas in Connect (#9867)

Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>",2021-02-04 09:15:49,Lev Zemlyanov,Mixed
ca29727d2afd85156ab8e48771785193270f28a1,"MINOR: Introduce KafkaBroker trait for use in dynamic reconfiguration (#10019)

Dynamic broker reconfiguration needs to occur for both ZooKeeper-based
brokers and brokers that use a Raft-based metadata quorum.  DynamicBrokerConfig
currently operates on KafkaServer, but it needs to operate on BrokerServer
(the broker implementation that will use the Raft metadata log) as well.
This PR introduces a KafkaBroker trait to allow dynamic reconfiguration to
work with either implementation.

Reviewers: José Armando García Sancio <jsancio@gmail.com>, Colin Patrick McCabe <cmccabe@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2021-02-04 10:48:04,Ron Dagostino,Not TDD
c4ea6fb0a7cce5cf54e8ddd32bb14e99e639b8df,"MINOR: Add ConfigRepository, use in Partition and KafkaApis (#10005)

`Partition` objects are able to retrieve topic configs when creating their log, and currently they do so with an implementation of `trait TopicConfigFetcher` that uses ZooKeeper.  ZooKeeper is not available when using a Raft-based metadata log, so we need to abstract the retrieval of configs so it can work either with or without ZooKeeper.  This PR introduces `trait ConfigRepository` with `ZkConfigRepository` and `CachedConfigRepository` implementations.  `Partition` objects now use a provided `ConfigRepository` to retrieve topic configs, and we eliminate `TopicConfigFetcher` as it is no longer needed.

`ReplicaManager` now contains an instance of `ConfigRepository` so it can provide it when creating `Partition` instances.

`KafkaApis` needs to be able to handle describe-config requests; it currently delegates that to `ZkAdminManager`, which of course queries ZooKeeper.  To make this work with or without ZooKeeper we move the logic from `ZkAdminManager` into a new `ConfigHelper` class that goes through a `ConfigRepository` instance.  We provide `KafkaApis` with such an instance, and it creates an instance of the helper so it can use that instead of going through `ZkAdminManager`.

Existing tests are sufficient to identify bugs and regressions in `Partition`, `ReplicaManager`, `KafkaApis`, and `ConfigHelper`.  The `ConfigRepository` implementations have their own unit tests.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-02-04 12:58:26,Ron Dagostino,Mixed
d98df7fc4d968e46a130d23e2c01ef861924d7d9,"MINOR: Add KafkaEventQueue (#10030)

Add KafkaEventQueue, which is used by the KIP-500 controller to manage its event queue.
Compared to using an Executor, KafkaEventQueue has the following advantages:

* Events can be given ""deadlines."" If an event lingers in the queue beyond the deadline, it
will be completed with a timeout exception. This is useful for implementing timeouts for
controller RPCs.

* Events can be prepended to the queue as well as appended.

* Events can be given tags to make them easier to manage. This is especially useful for
rescheduling or cancelling events which were previously scheduled to execute in the future.

Reviewers: Jun Rao <junrao@gmail.com>, José Armando García Sancio <jsancio@gmail.com>",2021-02-04 14:46:57,Colin Patrick McCabe,Mixed
5552da3a20ca432626d62b0e892bd25501484689,"KAFKA-5488: Add type-safe split() operator (#9107)

Implements KIP-418, that deprecated the `branch()` operator in favor of the newly added and type-safe `split()` operator.

Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>",2021-02-04 16:23:35,Ivan Ponomarev,Mixed
b78fa9cea24b9f0abff45ca873a49cdb7370430d,"KAFKA-10833: Expose task configurations in Connect REST API (KIP-661) (#9726)

This PR adds a new REST endpoint to Connect: GET /{connector}/tasks-config, that returns the configuration of all tasks for the connector.

Details in: 
https://cwiki.apache.org/confluence/display/KAFKA/KIP-661%3A+Expose+task+configurations+in+Connect+REST+API

Co-authored-by: Mickael Maison <mickael.maison@gmail.com>
Co-authored-by: Oliver Dineen <dineeno@uk.ibm.com>

Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>",2021-02-04 17:01:07,Mickael Maison,Mixed
07843cfbf4e3e7a2d26d63904bbf0da0fcd07ca2,"KAFKA-10834: Remove redundant type casts in Connect (#10053)

Cleanup up to remove redundant type casts in Connect and use the diamond operator when needed 

Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>",2021-02-04 17:08:56,Lev Zemlyanov,Mixed
c8dc74e16deb59bab7e6adb08d9e1281af51ddd0,"MINOR: Word count should account for extra whitespaces between words (#10044)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2021-02-04 18:54:08,Arjun Satish,Mixed
470e6f2b9ac45fc32bdeb77d0bf4c72d26c6f3fd,"KAFKA-9274: Add timeout handling for `StreamPartitioner` (#9997)

 Part of KIP-572: When a custom `StreamPartitioner` is used, we need to get the number of partitions of output topics from the producer. This `partitionFor(topic)` call may through a `TimeoutException` that we now handle gracefully.

Reviewers: John Roesler <john@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",2021-02-04 19:02:56,Matthias J. Sax,Mixed
d01d97ed665c14e7289ede0ccebbc5921d6fc86e,"MINOR: add docs for KIP-680 (#10048)

Reviewers: Bill Bejeck <bill@confluent.io>, Jim Galasyn <jim.galasyn@confluent.io>",2021-02-04 20:18:20,Matthias J. Sax,Not TDD
a3305c4b8b29c9fb4eede11aea4dd6fd60e445dc,"MINOR: Remove ZK dependency for coordinator topics' partition counts (#10008)

The group coordinator and the transaction state manager query ZooKeeper 
to retrieve the partition count for the topics they manager. Since ZooKeeper
won't be available when the broker is using a Raft-based metadata quorum,
this PR changes the startup function to provide an accessor function instead.
This will allow the ZK-based broker to continue using ZK, while the kip-500
broker will query the metadata provided by the metadata log.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, David Arthur <david.arthur@confluent.io>

Co-authored-by: Ismael Juma <ismael@juma.me.uk>",2021-02-05 08:51:00,Ron Dagostino,Mixed
acf39fe94ad6a666e7ddd88dbcc6ddf5173fe56c,"MINOR: Allow KafkaApis to be configured for Raft controller quorums (#10045)

`KafkaApis` is configured differently when it is used in a broker with a Raft-based controller quorum vs. a ZooKeeper quorum.  For example, when using Raft, `ForwardingManager` is required rather than optional, and there is no `AdminManager`, `KafkaController`, or `KafkaZkClient`.  This PR introduces `MetadataSupport` to abstract the two possibilities: `ZkSupport` and `RaftSupport`.  This provides a fluent way to decide what to do based on the type of support that `KafkaApis` has been configured with.  Certain types of requests are not supported when using raft (`AlterIsrRequest`, `UpdateMetadataRequest`, etc.), and `MetadataSupport` gives us an intuitive way to identify the constraints and requirements associated with the different configurations and react accordingly.

Existing tests are sufficient to detect bugs and regressions.

Reviewers: José Armando García Sancio <jsancio@gmail.com>, Jason Gustafson <jason@confluent.io>",2021-02-05 12:57:44,Ron Dagostino,Mixed
242f65e5ba8a546cff6d85e663d27282a93bfd6a,"Refactor the MetadataCache into two implementations (#10049)

Refactor the MetadataCache into two implementations that both implement a common trait.  This will let us
continue to use the existing implementation when using ZK, but use the new implementation when in kip-500 mode.

Reviewers: Colin McCabe <cmccabe@apache.org>, Justine Olshan <jolshan@confluent.io>, Jason Gustafson <jason@confluent.io>",2021-02-05 16:25:26,David Arthur,Mixed
0bc394cc1d19f1e41dd6646e9ac0e09b91fb1398,"KAFKA-9274: handle TimeoutException on task reset (#10000)

Part of KIP-572: We move the offset reset for the internal ""main consumer"" when we revive a corrupted task, from the ""task cleanup"" code path, to the ""task init"" code path. For this case, we have already logic in place to handle TimeoutException that might be thrown by consumer#committed() method call.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>",2021-02-05 17:25:50,Matthias J. Sax,Mixed
d2cb2dc45d536ae124e3da25d6d5a4e932a23a27,"KAFKA-9751: Forward CreateTopicsRequest for FindCoordinator/Metadata when topic creation is needed (#9579)

Consolidate auto topic creation logic to either forward a CreateTopicRequest or handling the creation directly as AutoTopicCreationManager, when handling FindCoordinator/Metadata request.

Co-authored-by: Jason Gustafson <jason@confluent.io>

Reviewers: Jason Gustafson <jason@confluent.io>",2021-02-06 13:04:30,Boyang Chen,Mixed
42a9355e606bd2bbdb7fd0dd348805e6666dc189,"MINOR: Defer log recovery until LogManager startup (#10039)

Currently log recovery begins as soon as we instantiate `LogManager`, but when using a
Raft-based metadata quorum we won't have configs until after we catch up on the metadata
log.  We therefore defer log recovery until we actually invoke `startup()` on the `LogManager`
instance.  This timing difference has no effect when using ZooKeeper because we
immediately invoke `startup()` on the instantiated instance, but it gives us the necessary
flexibility for accurate log recovery with updated configs when using a Raft-based metadata
quorum.

The `LogCleaner` is currently instantiated during construction just after log recovery
completes, and then it is started in `startup()`.  As an extra precaution, since we are
no longer performing recovery during construction, we both instantiate and start the
log cleaner in `startup()` after log recovery completes.

We also convert `LogManager` to use a `ConfigRepository` to load topic configs
(which can override the default log configs) instead of having a hard-coded
dependency on ZooKeeper.  We retrieve the topic configs when we invoke `startup()`
-- which again is effectively no different from a timing perspective than what we do
today for the ZooKeeper case.

One subtlety is that currently we create the log configs for every topic at this point
-- if a topic has no config overrides then we associate a copy of the default
configuration with the topic inside a map, and we retrieve the log configs for that
topic's partitions from from that map during recovery.  This PR makes a change to
this series of events as follows.  We do not associate a copy of the the default
configuration with a topic in the map if the topic has no configs set when we query
for them.  This saves some memory -- we don't unnecessarily copy the default
config many times -- but it also means we have use the default log configs for
that topic later on when recovery for each of its partitions begins.

The difference is that the default configs are dynamically reconfigurable, and they
could potentially change between the time when we invoke `startup()` and when
log recovery begins (log recovery can begin quite some time after `startup()` is
invoked if shutdown was unclean).  Prior to this patch such a change would not
be used; with this patch they could be if they happen before recovery begins.
This actually is better -- we are performing log recovery with the most recent
known defaults when a topic had no overrides at all. Also, `Partition.createLog`
has logic to handle missed config updates, so the behavior is eventually the same.

The transition of the broker state from `STARTING` to `RECOVERY` currently
happens within the `LogManager`, and it only occurs if the shutdown was
unclean.  We move this transition into the broker as it avoids passing a
reference to the broker state into the `LogManager`.  We also now always
transition the broker into the `RECOVERY` state as dictated by [the KIP-631 broker state machine](https://cwiki.apache.org/confluence/display/KAFKA/KIP-631%3A+The+Quorumbased+Kafka+Controller#KIP631:TheQuorumbasedKafkaController-TheBrokerStateMachine).

Finally, a few clean-ups were included. One worth highlighting is that `Partition`
no longer requires a `ConfigRepository`.

Reviewers: David Arthur <david.arthur@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2021-02-07 15:46:41,Ron Dagostino,Mixed
1d3e293c08b8073f992cdc8c240dfae7e036efd1,"MINOR: Add ClusterTool as specified in KIP-631 (#10047)

Add ClusterTool as specified in KIP-631. It can report the current cluster ID, and also send the new RPC for removing broker registrations.

Reviewers: David Arthur <mumrah@gmail.com>",2021-02-08 12:07:39,Colin Patrick McCabe,Mixed
1f508ea8c33726f6a4690b4eabe9713b277a7dd8,"MINOR: Add StorageTool as specified in KIP-631 (#10043)

Add StorageTool as specified in KIP-631. It can format and describe storage directories.  Fix a bug in `ZkMetaProperties#toString`.

Reviewers: David Arthur <mumrah@gmail.com>",2021-02-08 12:42:40,Colin Patrick McCabe,Mixed
3769bc21b5e4b48785b2c795ade8458d849ceda5,"MINOR: replace hard-coding utf-8 with StandardCharsets.UTF_8 (#10079)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-02-09 10:06:01,dengziming,Mixed
1bfce16de5a2d3957e2af3548a256d1dae09f0d1,"MINOR: add Utils.isBlank to check whitespace character string and empty string (#10012)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-02-09 11:34:26,CHUN-HAO TANG,Mixed
e7e4252b0ff2add9acbc8cd61cef2cae94c0c2ff,"JUnit extensions for integration tests (#9986)

Adds JUnit 5 extension for running the same test with different types of clusters. 
See core/src/test/java/kafka/test/junit/README.md for details",2021-02-09 11:49:33,David Arthur,Mixed
982ea2f6a471c217c7400a725c9504d9d8348d02,"KAFKA-10021: Changed Kafka backing stores to use shared admin client to get end offsets and create topics (#9780)

The existing `Kafka*BackingStore` classes used by Connect all use `KafkaBasedLog`, which needs to frequently get the end offsets for the internal topic to know whether they are caught up. `KafkaBasedLog` uses its consumer to get the end offsets and to consume the records from the topic.

However, the Connect internal topics are often written very infrequently. This means that when the `KafkaBasedLog` used in the `Kafka*BackingStore` classes is already caught up and its last consumer poll is waiting for new records to appear, the call to the consumer to fetch end offsets will block until the consumer returns after a new record is written (unlikely) or the consumer’s `fetch.max.wait.ms` setting (defaults to 500ms) ends and the consumer returns no more records. IOW, the call to `KafkaBasedLog.readToEnd()` may block for some period of time even though it’s already caught up to the end.

Instead, we want the `KafkaBasedLog.readToEnd()` to always return quickly when the log is already caught up. The best way to do this is to have the `KafkaBackingStore` use the admin client (rather than the consumer) to fetch end offsets for the internal topic. The consumer and the admin API both use the same `ListOffset` broker API, so the functionality is ultimately the same but we don't have to block for any ongoing consumer activity.

Each Connect distributed runtime includes three instances of the `Kafka*BackingStore` classes, which means we have three instances of `KafkaBasedLog`. We don't want three instances of the admin client, and should have all three instances of the `KafkaBasedLog` share a single admin client instance. In fact, each `Kafka*BackingStore` instance currently creates, uses and closes an admin client instance when it checks and initializes that store's internal topic. If we change `Kafka*BackingStores` to share one admin client instance, we can change that initialization logic to also reuse the supplied admin client instance.

The final challenge is that `KafkaBasedLog` has been used by projects outside of Apache Kafka. While `KafkaBasedLog` is definitely not in the public API for Connect, we can make these changes in ways that are backward compatible: create new constructors and deprecate the old constructors. Connect can be changed to only use the new constructors, and this will give time for any downstream users to make changes.

These changes are implemented as follows:
1. Add a `KafkaBasedLog` constructor to accept in its parameters a supplier from which it can get an admin instance, and deprecate the old constructor. We need a supplier rather than just passing an instance because `KafkaBasedLog` is instantiated before Connect starts up, so we need to create the admin instance only when needed. At the same time, we'll change the existing init function parameter from a no-arg function to accept an admin instance as an argument, allowing that init function to reuse the shared admin instance used by the `KafkaBasedLog`. Note: if no admin supplier is provided (in deprecated constructor that is no longer used in AK), the consumer is still used to get latest offsets.
2. Add to the `Kafka*BackingStore` classes a new constructor with the same parameters but with an admin supplier, and deprecate the old constructor. When the classes instantiate its `KafkaBasedLog` instance, it would pass the admin supplier and pass an init function that takes an admin instance.
3. Create a new `SharedTopicAdmin` that lazily creates the `TopicAdmin` (and underlying Admin client) when required, and closes the admin objects when the `SharedTopicAdmin` is closed.
4. Modify the existing `TopicAdmin` (used only in Connect) to encapsulate the logic of fetching end offsets using the admin client, simplifying the logic in `KafkaBasedLog` mentioned in #1 above. Doing this also makes it easier to test that logic.
5. Change `ConnectDistributed` to create a `SharedTopicAdmin` instance (that is `AutoCloseable`) before creating the `Kafka*BackingStore` instances, passing the `SharedTopicAdmin` (which is an admin supplier) to all three `Kafka*BackingStore objects`, and finally always closing the `SharedTopicAdmin` upon termination. (Shutdown of the worker occurs outside of the `ConnectDistributed` code, so modify `DistributedHerder` to take in its constructor additional `AutoCloseable` objects that should be closed when the herder is closed, and then modify `ConnectDistributed` to pass the `SharedTopicAdmin` as one of those `AutoCloseable` instances.)
6. Change `MirrorMaker` similarly to `ConnectDistributed`.
7. Change existing unit tests to no longer use deprecated constructors.
8. Add unit tests for new functionality.

Author: Randall Hauch <rhauch@gmail.com>
Reviewer: Konstantine Karantasis <konstantine@confluent.io>",2021-02-09 11:09:41,Randall Hauch,Mixed
ad541b9759168844065bb1ef95ded4cbb2c1b7ed,"MINOR: KafkaBroker.brokerState should be volatile instead of AtomicReference (#10080)

We don't need or use the additional functionality provided by
AtomicReference.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Arthur <mumrah@gmail.com>",2021-02-10 07:12:06,Ismael Juma,Not TDD
06dce721ec0185d49fac37775dbf191d0e80e687,"MINOR: Rename DecommissionBrokers to UnregisterBrokers (#10084)

Rename DecommissionBrokers to UnregisterBrokers. Fix an incorrect JavaDoc comment
for the Admin API. Make sure that UNREGISTER_BROKER is marked as forwardable and
not as a controller-only API (since it can received by brokers).

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2021-02-10 12:44:47,Colin Patrick McCabe,Mixed
3a3af5e20069f245113f4ff12a0259d6420e89cc,"MINOR: Add ClientQuotaMetadataManager for processing QuotaRecord  (#10101)

This PR brings in the new broker metadata processor for handling QuotaRecord-s coming from the metadata log. Also included is a new cache class to allow for fast lookups of quotas on the broker for handling DescribeClientQuotaRequest.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-02-10 14:04:22,David Arthur,Mixed
31a647f5adf0d1ff8f190cccc0da900cfbaf2756,"MINOR: Add RaftReplicaManager (#10069)

This adds the logic to apply partition metadata when consuming from the Raft-based
metadata log.

RaftReplicaManager extends ReplicaManager for now to minimize changes to existing
code for the 2.8 release. We will likely adjust this hierarchy at a later time (e.g. introducing
a trait and adding a helper to refactor common code). For now, we expose the necessary
fields and methods in ReplicaManager by changing their scope from private to protected,
and we refactor out a couple of pieces of logic that are shared between the two
implementation (stopping replicas and adding log dir fetchers).

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",2021-02-10 14:37:16,Ron Dagostino,Mixed
39dcdeffd7075b8cbb018c5a4bfdd17e7828d75b,"MINOR: Prevent creating partition.metadata until ID can be written (#10041)

Currently the partition.metadata file is created when the log is created. However, clusters with older inter-broker protocols will never use this file. This PR moves the creation of the file to when we write to the file.

This PR also deletes the partition.metadata file on startup if the IBP version is lower than 2.8.

Reviewers: Jun Rao <junrao@gmail.com>",2021-02-10 15:22:15,Justine Olshan,Mixed
202ff6336faa010f9452c55e8eb71a6cabe83936,"KAFKA-5235: GetOffsetShell: Support for multiple topics and consumer configuration override (KIP-635) (#9430)

This patch implements KIP-635 which mainly adds support for querying offsets of multiple topics/partitions.

Reviewers: David Jacot <djacot@confluent.io>",2021-02-11 12:06:21,Dániel Urbán,Mixed
6b3a4553f91d737b0e26a9ae028b7a85e0fc475a,"MINOR: Introduce the KIP-500 Broker lifecycle manager (#10095)

Add the KIP-500 broker lifecycle manager.  It owns the broker state.  Its inputs are
messages passed in from other parts of the broker and from the controller: requests to start
up, or shut down, for example. Its output are the broker state and various futures that can
be used to wait for broker state transitions to occur.

The lifecycle manager handles registering the broker with the controller, as described in
KIP-631. After registration is complete, it handles sending periodic broker heartbeats and
processing the responses.

Reviewers: David Arthur <mumrah@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Ron Dagostino <rdagostino@confluent.io>",2021-02-11 08:32:38,Colin Patrick McCabe,Mixed
bf5e1f1cc0d7f7b1f54c879fbb5f415d30fa9c06,"MINOR: add the MetaLogListener, LocalLogManager, and Controller interface. (#10106)

Add MetaLogListener, LocalLogManager, and related classes. These
classes are used by the KIP-500 controller and broker to interface with the
Raft log.

Also add the Controller interface. The implementation will be added in a separate PR.

Reviewers: Ron Dagostino <rdagostino@confluent.io>, David Arthur <mumrah@gmail.com>",2021-02-11 08:42:59,Colin Patrick McCabe,Mixed
25555b89f5155e4c9cbd474674cc6f24b0121b29,"MINOR: Add BrokerMetadataListener (#10111)

This adds BrokerMetadataListener which is responsible for processing metadata records received by the broker when running in Raft mode.

This also moves some classes that were added to the wrong folder in trunk

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ron Dagostino <rdagostino@confluent.io>",2021-02-11 12:43:21,David Arthur,Not TDD
d4de383f5fe8e0d35bdb82f85d71aaaea77d8e90,"KAFKA-12272: Fix commit-interval metrics (#10102)

Reviewer: A. Sophie Blee-Goldman <sophie@confluent.io>",2021-02-11 16:49:05,Matthias J. Sax,Mixed
1adb580faae89e0a298c0cb4ba08b238d91f9d03,"MINOR: KIP-631 KafkaConfig fixes and improvements (#10114)

Add the new KIP-631 configs to KafkaConfigTest to fix the test failure.

Rename InitialBrokerRegistrationTimeoutMs to
InitialBrokerRegistrationTimeoutMsProp for consistency with the other
properties.

Add ControllerListenerNamesProp as specified in KIP-631.

Give nodeId and brokerId the same value in KafkaConfig.

Reviewers: David Arthur <mumrah@gmail.com",2021-02-11 21:35:24,Colin Patrick McCabe,Mixed
2294d1040504f871290293131f2b98a76f1d93d3,"KAFKA-12321 the comparison function for uuid type should be 'equals' rather than '==' (#10098)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-02-13 00:07:19,Chia-Ping Tsai,Not TDD
b3313b8636f8b6abad6389c99aa6d62a8976482a,"KAFKA-12297: Make MockProducer return RecordMetadata with values as per contract

This is a simple change to MockProducer as per request in KAFKA-12297.
MockProducer currently returns a null RecordMetadata on Exception. The fix will make MockProducer return the right value as per specification.

This only impacts clients which use send with a custom callback and try to then use the RecordMetadata inspite of getting an exception. This should mostly impact customer unit and integration tests as the mock end point was never intended for use in a real Kafka cluster.

Author: Akhilesh Dubey <adubey@confluent.io>
Author: Manikumar Reddy <manikumar.reddy@gmail.com>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>

Closes #10110 from aadubey/trunk",2021-02-13 23:18:10,Akhilesh Dubey,Mixed
744d05b12897267803f46549e8bca3d31d57be4c,"KAFKA-12327: Remove MethodHandle usage in CompressionType (#10123)

We don't really need it and it causes problems in older Android versions
and GraalVM native image usage (there are workarounds for the latter).

Move the logic to separate classes that are only invoked when the
relevant compression library is actually used. Place such classes
in their own package and enforce via checkstyle that only these
classes refer to compression library packages.

To avoid cyclic dependencies, moved `BufferSupplier` to the `utils`
package.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-02-14 08:12:25,Ismael Juma,Mixed
fb7da1a245ff24a3d538e011ab3ec4e96ef86d28,"Fixed README and added clearer error message. (#10133)

The script `test-raft-server-start.sh` requires the config to be specified with `--config`. I've included this in the README and added an error message for this specific case.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-02-16 15:12:29,Justine Olshan,Not TDD
f5c2f608b05c8094a898c14a6c4a3238f6388df1,"MINOR: use 'mapKey' to avoid unnecessary grouped data (#10082)

1. add 'mapKey=true' to DescribeLogDirsRequest
2. rename PartitionIndex to Partitions for DescribeLogDirsRequest
3. add 'mapKey=true' to ElectLeadersRequest
4. rename PartitionId to Partitions for ElectLeadersRequest
5. add 'mapKey=true' to ConsumerProtocolAssignment

Reviewers: David Jacot <djacot@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2021-02-17 12:14:08,Chia-Ping Tsai,Not TDD
a30f92bf59cf31fc1dd36eadc2b9e554e0aef900,"MINOR: Add KIP-500 BrokerServer and ControllerServer (#10113)

This PR adds the KIP-500 BrokerServer and ControllerServer classes and 
makes some related changes to get them working.  Note that the ControllerServer 
does not instantiate a QuorumController object yet, since that will be added in
PR #10070.

* Add BrokerServer and ControllerServer

* Change ApiVersions#computeMaxUsableProduceMagic so that it can handle
endpoints which do not support PRODUCE (such as KIP-500 controller nodes)

* KafkaAdminClientTest: fix some lingering references to decommissionBroker
that should be references to unregisterBroker.

* Make some changes to allow SocketServer to be used by ControllerServer as
we as by the broker.

* We now return a random active Broker ID as the Controller ID in
MetadataResponse for the Raft-based case as per KIP-590.

* Add the RaftControllerNodeProvider

* Add EnvelopeUtils

* Add MetaLogRaftShim

* In ducktape, in config_property.py: use a KIP-500 compatible cluster ID.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, David Arthur <mumrah@gmail.com>",2021-02-17 21:35:13,Ron Dagostino,Mixed
b58b944e70780029806a6004114bba43ce5b9483,"KAFKA-12303: Fix handling of null values by Flatten SMT (#10073)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Greg Harris <gregh@confluent.io>",2021-02-18 15:01:49,Chris Egerton,Mixed
698319b8e2c1f6cb574f339eede6f2a5b1919b55,"KAFKA-12278; Ensure exposed api versions are consistent within listener (#10666)

Previously all APIs were accessible on every listener exposed by the broker, but
with KIP-500, that is no longer true.  We now have more complex requirements for
API accessibility.

For example, the KIP-500 controller exposes some APIs which are not exposed by
brokers, such as BrokerHeartbeatRequest, and does not expose most client APIs,
such as JoinGroupRequest, etc.  Similarly, the KIP-500 broker does not implement
some APIs that the ZK-based broker does, such as LeaderAndIsrRequest and
UpdateFeaturesRequest.

All of this means that we need more sophistication in how we expose APIs and
keep them consistent with the ApiVersions API. Up until now, we have been
working around this using the controllerOnly flag inside ApiKeys, but this is
not rich enough to support all of the cases listed above.  This PR introduces a
new ""listeners"" field to the request schema definitions.  This field is an array
of strings which indicate the listener types in which the API should be exposed.
We currently support ""zkBroker"", ""broker"", and ""controller"".  (""broker""
indicates the KIP-500 broker, whereas zkBroker indicates the old broker).

This PR also creates ApiVersionManager to encapsulate the creation of the
ApiVersionsResponse based on the listener type.  Additionally, it modifies
SocketServer to check the listener type of received requests before forwarding
them to the request handler.

Finally, this PR also fixes a bug in the handling of the ApiVersionsResponse
prior to authentication. Previously a static response was sent, which means that
changes to features would not get reflected. This also meant that the logic to
ensure that only the intersection of version ranges supported by the controller
would get exposed did not work. I think this is important because some clients
rely on the initial pre-authenticated ApiVersions response rather than doing a
second round after authentication as the Java client does.

One final cleanup note: I have removed the expectation that envelope requests
are only allowed on ""privileged"" listeners.  This made sense initially because
we expected to use forwarding before the KIP-500 controller was available. That
is not the case anymore and we expect the Envelope API to only be exposed on the
controller listener. I have nevertheless preserved the existing workarounds to
allow verification of the forwarding behavior in integration testing.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",2021-02-18 16:25:51,Jason Gustafson,Mixed
e29f7a36dbbd316ae03008140a1a0d282a26b82d,"KAFKA-12331: Use LEO for the base offset of LeaderChangeMessage batch (#10138)

The `KafkaMetadataLog` implementation of `ReplicatedLog` validates that batches appended using `appendAsLeader` and `appendAsFollower` have an offset that matches the LEO. This is enforced by `KafkaRaftClient` and `BatchAccumulator`. When creating control batches for the `LeaderChangeMessage` the default base offset of `0` was being used instead of using the LEO. This is fixed by:

1. Changing the implementation for `MockLog` to validate against this and throw an `RuntimeException` if this invariant is violated.
2. Always create a batch for `LeaderChangeMessage` with an offset equal to the LEO.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-02-18 16:44:40,José Armando García Sancio,Mixed
c8112b5ecdda6b62d34ad97fcebbf5c7fec3de53,"KAFKA-9524: increase retention time for window and grace periods longer than one day (#10091)

Reviewers: Victoria Xia <victoria.xia@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2021-02-18 18:18:53,Marco Aurelio Lotz,Mixed
9243c10161eb10631353f34a821a8dfb8cab51ed,"KAFKA-12258; Add support for splitting appending records (#10063)

1. Type `BatchAccumulator`. Add support for appending records into one or more batches.
2. Type `RaftClient`. Rename `scheduleAppend` to `scheduleAtomicAppend`.
3. Type `RaftClient`. Add a new method `scheduleAppend` which appends records to the log using as many batches as necessary.
4. Increase the batch size from 1MB to 8MB.

Reviewers: David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",2021-02-18 19:46:23,José Armando García Sancio,Mixed
d030dc55ab4e94b4bb049b91474d5a8f533fb3bb,"KAFKA-12332; Error partitions from topics with invalid IDs in LISR requests (#10143)

Changes how invalid IDs are handled in LeaderAndIsr requests. The ID check now occurs before leader epoch. If the ID exists and is invalid, the partition is ignored and a new `INCONSISTENT_TOPIC_ID` error is returned in the response.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-02-19 11:08:00,Justine Olshan,Mixed
1c31176ae1ef49071b0d3e717e5f3037492b5b30,"KAFKA-12343: Handle exceptions better in TopicAdmin, including UnsupportedVersionException (#10158)

Refactored the KafkaBasedLog logic to read end offsets into a separate method to make it easier to test. Also changed the TopicAdmin.endOffsets method to throw the original UnsupportedVersionException, LeaderNotAvailableException, and TimeoutException rather than wrapping, to better conform with the consumer method and how the KafkaBasedLog retries those exceptions.

Added new tests to verify various scenarios and errors.

Author: Randall Hauch <rhauch@gmail.com>
Reviewers: Konstantine Karantasis <konstantine@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2021-02-19 14:43:32,Randall Hauch,Mixed
b35ca4349dabb199411cb6bc4c80ef89f19d9328,"KAFKA-9274: Throw TaskCorruptedException instead of TimeoutException when TX commit times out (#10072)

Part of KIP-572: follow up work to PR #9800. It's not save to retry a TX commit after a timeout, because it's unclear if the commit was successful or not, and thus on retry we might get an IllegalStateException. Instead, we will throw a TaskCorruptedException to retry the TX if the commit failed.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>",2021-02-19 13:36:07,Matthias J. Sax,Mixed
bbf145b1b163bada0b20cea42b29d91443161170,"KAFKA-10817; Add clusterId validation to raft Fetch handling (#10129)

This patch adds clusterId validation in the `Fetch` API as documented in KIP-595. A new error code `INCONSISTENT_CLUSTER_ID` is returned if the request clusterId does not match the value on the server. If no clusterId is provided, the request is treated as valid.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-02-19 14:43:14,David Jacot,Mixed
45b7a2a2ac697636cb4810a8c9357527361babd6,"KAFKA-12339: Add retry to admin client's listOffsets (#10152)

`KafkaAdmin.listOffsets` did not handle topic-level errors, hence the UnknownTopicOrPartitionException on topic-level can obstruct a Connect worker from running when the new internal topic is NOT synced to all brokers. The method did handle partition-level retriable errors by retrying, so this changes to handle topic-level retriable errors in the same way.

This allows a Connect worker to start up and have the admin client retry when the worker is trying to read to the end of the newly-created internal topics until the internal topic metadata is synced to all brokers.

Author: Chia-Ping Tsai <chia7712@gmail.com>
Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>",2021-02-19 17:02:09,Chia-Ping Tsai,Not TDD
690f72dd69d31589655c84d3cc1a6eec006bcab5,"KAFKA-12334: Add the KIP-500 metadata shell

The Kafka Metadata shell is a new command which allows users to
interactively examine the metadata stored in a KIP-500 cluster.
It can examine snapshot files that are specified via --snapshot.

The metadata tool works by replaying the log and storing the state into
in-memory nodes.  These nodes are presented in a fashion similar to
filesystem directories.

Reviewers: Jason Gustafson <jason@confluent.io>, David Arthur <mumrah@gmail.com>, Igor Soarez <soarez@apple.com>",2021-02-19 15:46:34,Colin P. Mccabe,Mixed
5eac5a822fe4eb8691d2411fb25fcba1d4203b55,"KAFKA-12276: Add the quorum controller code (#10070)

The quorum controller stores metadata in the KIP-500 metadata log, not in Apache
ZooKeeper. Each controller node is a voter in the metadata quorum. The leader of the
quorum is the active controller, which processes write requests. The followers are standby
controllers, which replay the operations written to the log. If the active controller goes away,
a standby controller can take its place.

Like the ZooKeeper-based controller, the quorum controller is based on an event queue
backed by a single-threaded executor. However, unlike the ZK-based controller, the quorum
controller can have multiple operations in flight-- it does not need to wait for one operation
to be finished before starting another. Therefore, calls into the QuorumController return
CompleteableFuture objects which are completed with either a result or an error when the
operation is done. The QuorumController will also time out operations that have been
sitting on the queue too long without being processed. In this case, the future is completed
with a TimeoutException.

The controller uses timeline data structures to store multiple ""versions"" of its in-memory 
state simultaneously. ""Read operations"" read only committed state, which is slightly older
than the most up-to-date in-memory state. ""Write operations"" read and write the latest
in-memory state. However, we can not return a successful result for a write operation until
its state has been committed to the log. Therefore, if a client receives an RPC response, it
knows that the requested operation has been performed, and can not be undone by a
controller failover.

Reviewers: Jun Rao <junrao@gmail.com>, Ron Dagostino <rdagostino@confluent.io>",2021-02-19 18:03:23,Colin Patrick McCabe,Mixed
954c090ffc378a63ce3c3c9a72b87724fcd2cd6c,"MINOR: apply Utils.isBlank to code base (#10124)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-02-20 11:44:29,CHUN-HAO TANG,Mixed
95f51539c8d0b88bd7f285011d42e2d1117107de,"MINOR: Raft request thread should discover api versions (#10157)

We do not plan to rely on the IBP in order to determine API versions for raft requests. Instead, we want to discover them through the ApiVersions API. This patch enables the flag to do so. 

In addition, this patch adds unsupported version as well as authentication version checking to all of the derivatives of `InterBrokerSendThread` which rely on dynamic api version discovery. Test cases for these checks have been added.

Reviewers:  Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>, Boyang Chen <boyang@confluent.io>",2021-02-22 10:16:48,Jason Gustafson,Mixed
0711d1558250c60807dfa815d46907eac8bb4b98,"MINOR: Test the new KIP-500 quorum mode in ducktape (#10105)

Add the necessary test annotations to test the new KIP-500 quorum broker mode
in many of our ducktape tests. This mode is tested in addition to the classic
Apache ZooKeeper mode.

This PR also adds a new sanity_checks/bounce_test.py system test that runs
through a simple produce/bounce/produce series of events.

Finally, this PR adds @cluster annotations to dozens of system tests that were
missing them. The lack of this annotation was causing these tests to grab the
entire cluster of nodes.  Adding the @cluster annotation dramatically reduced
the time needed to run these tests.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",2021-02-22 13:57:17,Ron Dagostino,Mixed
f5e01f743be2276c1c0365b4e3e6639de32b985a,"KAFKA-12273 InterBrokerSendThread#pollOnce throws FatalExitError even… (#10024)

Reviewers: David Jacot <djacot@confluent.io>",2021-02-23 10:54:14,Chia-Ping Tsai,Mixed
23b85417b3ed53bf092877baef42608f7b778843,"MINOR: Move `RequestChannel.Response` creation logic into `RequestChannel` (#9912)

This patch moves some common response creation logic from `RequestHandlerHelper` and into `RequestChannel`. This refactor has the following benefits:

- It allows us to get rid of some logic that was previously duplicated in both `RequestHandlerHelper` and `TestRaftRequestHandler`. 
- It ensures that we do not need to rely on the caller to ensure that `updateErrorMetrics` gets called since this is handled internally in `RequestChannel`.
- It provides better encapsulation of the quota workflow which relies on custom `Response` objects. Previously it was quite confusing for `KafkaApis` to handle this directly through the `sendResponse` API.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-02-22 20:34:25,Jason Gustafson,Mixed
bc04c335fc6c39a507f14d0cda71c8a2780a53cf,"KAFKA-12361; Use default request.timeout.ms value for Connect producers (#10178)

Connect uses a high request timeout as a holdover from the days prior to KIP-91 when this was required to guarantee records would not get timed out in the accumulator. Having a high request timeout makes it harder for the producer to gracefully handle unclean connection terminations, which might happen in the case of sudden broker death.

Reducing that value to the default of 30 seconds should address that issue, without compromising the existing delivery guarantees of the Connect framework. Since the delivery timeout is still set to a very-high value, this change shouldn't make it more likely for `Producer::send` to throw an exception and fail the task.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-02-23 18:32:42,Chris Egerton,Mixed
f75efb96fae99a22eb54b5d0ef4e23b28fe8cd2d,"KAFKA-12323: Set timestamp in record context when punctuate (#10170)

We need to preserve the timestamp when punctuating so that downstream operators would retain it via context.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2021-02-23 20:41:02,Guozhang Wang,Not TDD
3f09fb97b6943c0612488dfa8e5eab8078fd7ca0,"KAFKA-12267; Implement `DescribeTransactions` API (#10183)

This patch implements the `DescribeTransactions` API as documented in KIP-664: https://cwiki.apache.org/confluence/display/KAFKA/KIP-664%3A+Provide+tooling+to+detect+and+abort+hanging+transactions. This is only the server-side implementation and does not contain the `Admin` API.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-02-24 12:50:18,Jason Gustafson,Mixed
a8eda3c785104615fa7144d6722a91223ecfea58,"KAFKA-12367; Ensure partition epoch is propagated to `Partition` state (#10200)

This patch fixes two problem with the AlterIsr handling of the quorum controller:

- Ensure that partition epoch is updated correctly after partition change records and is
propagated to Partition

- Ensure that AlterIsr response includes partitions that were successfully updated

As part of this patch, I've renamed BrokersToIsrs.TopicPartition to
BrokersToIsrs.TopicIdPartition to avoid confusion with the TopicPartition object which is
used virtually everywhere. I've attempted to address some of the testing gaps as welll.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-02-25 14:17:19,Jason Gustafson,Mixed
7f90eda04720274a0e4f7ec32a7340245f493e9e,"KAFKA-8562; SaslChannelBuilder - Avoid (reverse) DNS lookup while building SslTransportLayer (#10059)

This patch moves the `peerHost` helper defined in `SslChannelBuilder` into `SslFactor`. `SaslChannelBuilder` is then updated to use a new `createSslEngine` overload which relies on `peerHost` when building its `SslEngine`. The purpose is to avoid the reverse DNS in `getHostName`.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Manikumar Reddy <manikumar.reddy@gmail.com>, Jason Gustafson <jason@confluent.io>",2021-02-25 17:02:40,Davor Poldrugo,Not TDD
74dfe80bb8b63b3916560143ce2c85f8b41f0f2e,"KAFKA-12365; Disable APIs not supported by KIP-500 broker/controller (#10194)

This patch updates request `listeners` tags to be in line with what the KIP-500 broker/controller support today. We will re-enable these APIs as needed once we have added the support.

I have also updated `ControllerApis` to use `ApiVersionManager` and simplified the envelope handling logic.

Reviewers: Ron Dagostino <rdagostino@confluent.io>, Colin P. McCabe <cmccabe@apache.org>",2021-02-25 19:38:21,Jason Gustafson,Mixed
5dae3648abdb64969680ad2313756277a63530c1,"MINOR: Clean up group instance id handling in `GroupCoordinator` (#9958)

This is a continuation of a refactor started in #9952. The logic in `GroupCoordinator` is loose and inconsistent in the handling of the `groupInstanceId`. In some cases, such as in the JoinGroup hander, we verify that the groupInstanceId from the request is mapped to the memberId precisely. In other cases, such as Heartbeat, we check the mapping, but only to validate fencing. The patch consolidates the member validation so that all handlers follow the same logic. 

A second problem is that many of the APIs where a `groupInstanceId` is expected use optional arguments. For example:
```scala
def hasStaticMember(groupInstanceId: Option[String]): Boolean

def addStaticMember(groupInstanceId: Option[String], newMemberId: String): Unit
```
If `groupInstanceId` is `None`, then `hasStaticMember` is guaranteed to return `false` while `addStaticMember` raises an `IllegalStateException`. So the APIs suggest a generality which is not supported and does not make sense.

Finally,  the patch attempts to introduce stronger internal  invariants inside `GroupMetadata`. Currently it is possible for an inconsistent `groupInstanceId` to `memberId` mapping to exist because we expose separate APIs to modify `members` and `staticMembers`. We rely on the caller to ensure this doesn't happen.  Similarly, it is possible for a member to be in the `pendingMembers` set as well as the stable `members` map. The patch fixes this by consolidating the paths to addition and removal from these collections and adding assertions to ensure that invariants are maintained. 

Reviewers: David Jacot <djacot@confluent.io>",2021-02-26 11:26:43,Jason Gustafson,Mixed
32e6a5b320194c40824ac3cdd5ecc015b0254cce,"MINOR: Add cluster-metadata-decoder to DumpLogSegments (#10212)

Add the --cluster-metadata-decoder and --skip-record-metadata options to
the DumpLogSegments command-line tool, as described in KIP-631.

Co-authored-by: David Arthur <mumrah@gmail.com>
Reviewers: Jason Gustafson <jason@confluent.io>",2021-02-26 11:28:11,Colin Patrick McCabe,Mixed
a66f154370980783add1973954cff120cf3825e1,"KAFKA-12235: Fix a bug where describeConfigs does not work on 2+ config keys (#9990)

Fix a bug where if more than one configuration key is supplied, describeConfigs fails to return any results at all.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-02-26 11:33:21,Ivan Yurchenko,Not TDD
068d8fedcb34dcb2d07a6375bd267d3323c7e06c,"KAFKA-10101: Fix edge cases in Log.recoverLog and LogManager.loadLogs (#8812)

1. Don't advance recovery point in `recoverLog` unless there was a clean
shutdown.
2. Ensure the recovery point is not ahead of the log end offset.
3. Clean and flush leader epoch cache and truncate produce state manager
if deleting segments due to log end offset being smaller than log start
offset.
4. If we are unable to delete clean shutdown file that exists, mark the
directory as offline (this was the intent, but the code was wrong).

Updated one test that was failing after this change to verify the new behavior.

Reviewers: Jun Rao <junrao@gmail.com>, Jason Gustafson <jason@confluent.io>",2021-02-26 14:40:46,Ismael Juma,Mixed
5d37901500d554cc5602ae141a98fd87bda3dcbf,"KAFKA-12374: Add missing config sasl.mechanism.controller.protocol (#10199)

Fix some cases where we were erroneously using the configuration of the inter broker
listener instead of the controller listener.  Add the sasl.mechanism.controller.protocol
configuration key specified by KIP-631.  Add some ducktape tests.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, David Arthur <mumrah@gmail.com>, Boyang Chen <boyang@confluent.io>",2021-02-26 16:56:11,Ron Dagostino,Mixed
cc088c5abe367989e833e444171dd546370c356f,"KAFKA-12254: Ensure MM2 creates topics with source topic configs (#10217)

MM2 creates new topics on the destination cluster with default configurations. It has an async periodic task to refresh topic configurations from the source to destination. However, this opens up a window where the destination cluster has data produced to it with default configurations. In the worst case, this could cause data loss if the destination topic is created without the right cleanup.policy. This commit fixes the above issue by ensuring that the right configurations are supplied to AdminClient#createTopics when MM2 creates topics on the destination cluster.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2021-03-01 09:30:30,Dhruvil Shah,Mixed
d78a923a16d5a211b2bc984aa8026cd4441c4da9,"KAFKA-12329; kafka-reassign-partitions command should give a better error message when a topic does not exist (#10141)

This patch updates `kafka-reassign-partitions` to provide a meaningful error message to the user when a topic does not exist.

Reviewers:  Chia-Ping Tsai <chia7712@gmail.com>",2021-03-01 14:59:54,David Jacot,Not TDD
a63e5be4195e97e5b825b5912291144d2d0283a3,"KAFKA-10340: Proactively close producer when cancelling source tasks (#10016)

Close the producer in `WorkerSourceTask` when the latter is cancelled. If the broker do not autocreate the topic, and the connector is not configured to create topics written by the source connector, then the `WorkerSourceTask` main thread will block forever until the topic is created, and will not stop if cancelled or scheduled for shutdown by the worker.

Expanded an existing unit test for the WorkerSourceTask class to ensure that the producer is closed when the task is abandoned, and added a new integration test that guarantees that tasks are still shut down even when their producers are trying to write to topics that do not exist.

Author: Chris Egerton <chrise@confluent.io>
Reviewed: Greg Harris <gregh@confluent.io>, Randall Hauch <rhauch@gmail.com>",2021-03-01 10:03:34,Chris Egerton,Mixed
e2bffb9086823230c60c4838d38f32917dd8d03d,"MINOR: Word count should account for extra whitespaces between words (#10229)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2021-03-01 11:02:28,dengziming,Mixed
a92b986c855592d630fbabf49d1e9a160ad5b230,"KAFKA-12268: Implement task idling semantics via currentLag API (#10137)

Implements KIP-695

Reverts a previous behavior change to Consumer.poll and replaces
it with a new Consumer.currentLag API, which returns the client's
currently cached lag.

Uses this new API to implement the desired task idling semantics
improvement from KIP-695.

Reverts fdcf8fbf72bee9e672d0790cdbe5539846f7dc8e / KAFKA-10866: Add metadata to ConsumerRecords (#9836)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Guozhang Wang <guozhang@apache.org>",2021-03-02 08:20:47,John Roesler,Mixed
b2075a094688855be4e0cb37504c87bb09d4a576,"KAFKA-12289: Adding test cases for prefix scan in InMemoryKeyValueStore (#10052)

Co-authored-by: Bruno Cadonna <bruno@confluent.io>

Reviewers: Bruno Cadonna <cadonna@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2021-03-02 09:53:27,vamossagar12,Not TDD
a4ba73270cbdcb31e92fc54fc8c9858abf4be552,"KAFKA-12394; Return `TOPIC_AUTHORIZATION_FAILED` in delete topic response if no describe permission (#10223)

We now accept topicIds in the `DeleteTopic` request. If the client principal does not have `Describe` permission, then we return `TOPIC_AUTHORIZATION_FAILED`. This is justified because the topicId is not considered sensitive. However, in this case, we should not return the name of the topic in the response since we do consider it sensitive.

Reviewers: David Jacot <djacot@confluent.io>, dengziming <dengziming1993@gmail.com>, Justine Olshan <jolshan@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2021-03-02 10:20:07,Jason Gustafson,Mixed
a848e0c4208318e5db305876d14af4be0c3ce5fc,"KAFKA-10357: Extract setup of changelog from Streams partition assignor (#10163)

To implement the explicit user initialization of Kafka Streams as
described in KIP-698, we first need to extract the code for the
setup of the changelog topics from the Streams partition assignor
so that it can also be called outside of a rebalance.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Guozhang Wang <guozhang@confluent.io>",2021-03-02 12:00:00,Bruno Cadonna,Mixed
3708a7c6c1ecf1304f091dda1e79ae53ba2df489,"KAFKA-12369; Implement `ListTransactions` API (#10206)

This patch implements the `ListTransactions` API as documented in KIP-664: https://cwiki.apache.org/confluence/display/KAFKA/KIP-664%3A+Provide+tooling+to+detect+and+abort+hanging+transactions.

Reviewers: Tom Bentley <tbentley@redhat.com>, Chia-Ping Tsai <chia7712@gmail.com>",2021-03-02 13:01:35,Jason Gustafson,Mixed
36d61650f4437a40ee599f2d36ad05570c4786f6,"KAFKA-12177: apply log start offset retention before time and size based retention (#10216)

Log start offset retention is the cheapest retention to evaluate and does not require access to maxTimestamp fields for segments, nor segment sizes. In addition, it may unblock other types of retention such as time based retention. Without this change retention is not idempotent. It's possible for one deleteOldSegments call to delete segments due to log start offset retention, and a follow up call to delete due to time based retention, even if the time has not changed.

Reviewers: Jun Rao <junrao@gmail.com>",2021-03-02 13:11:16,Lucas Bradstreet,Mixed
23b61ba3837e92f1cde9cbbcbb172c545b1ae6da,"KAFKA-12375: don't reuse thread.id until a thread has fully shut down (#10215)

Always grab a new thread.id and verify that a thread has fully shut down to DEAD before removing from the `threads` list and making that id available again

Reviewers: Walker Carlson <wcarlson@confluent.io>, Bruno Cadonna <cadonna@confluent.io>",2021-03-02 16:28:15,A. Sophie Blee-Goldman,Mixed
0d9a95a7d0ab06aecc4480901707e29dd2a3147e,"KAFKA-9548 Added SPIs and public classes/interfaces introduced in KIP-405 for tiered storage feature in Kafka. (#10173)

KIP-405 introduces tiered storage feature in Kafka. With this feature, Kafka cluster is configured with two tiers of storage - local and remote. The local tier is the same as the current Kafka that uses the local disks on the Kafka brokers to store the log segments. The new remote tier uses systems, such as HDFS or S3 or other cloud storages to store the completed log segments. Consumers fetch the records stored in remote storage through the brokers with the existing protocol.

We introduced a few SPIs for plugging in log/index store and remote log metadata store.

This involves two parts
1. Storing the actual data in remote storage like HDFS, S3, or other cloud storages.
2. Storing the metadata about where the remote segments are stored. The default implementation uses an internal Kafka topic.

You can read KIP for more details at https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage

Reviewers: Jun Rao <junrao@gmail.com>",2021-03-03 08:55:13,Satish Duggana,Not TDD
f06a47a7bba9baf035691feadbfeb3ff21802e82,"KAFKA-12170: Fix for Connect Cast SMT to correctly transform a Byte array into a string (#9950)

Cast SMT transformation for bytes -> string.
Without this fix, the conversion becomes ByteBuffer.toString(), which always gives this useless result:
    ""java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]""

With this change, the byte array is converted into a base64 string of the byte buffer content.

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <k.karantasis@gmail.com>",2021-03-03 22:17:49,Sven Erik Knop,Mixed
3ef39e13658be2ea0c79d44fba241fdf9257e51c,"MINOR; Clean up LeaderAndIsrResponse construction in `ReplicaManager#becomeLeaderOrFollower` (#10234)

This patch refactors the code, which constructs the `LeaderAndIsrResponse` in `ReplicaManager#becomeLeaderOrFollower`, to improve the readability and to remove unnecessary operations.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-03-04 10:31:35,David Jacot,Mixed
8205051e90e3ea16165f8dc1f5c81af744bb1b9a,"MINOR: remove FetchResponse.AbortedTransaction and redundant construc… (#9758)

1. rename INVALID_HIGHWATERMARK to INVALID_HIGH_WATERMARK
2. replace FetchResponse.AbortedTransaction by FetchResponseData.AbortedTransaction
3. remove redundant constructors from FetchResponse.PartitionData
4. rename recordSet to records
5. add helpers ""recordsOrFail"" and ""recordsSize"" to FetchResponse to process record casting

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-03-04 18:06:50,Chia-Ping Tsai,Mixed
be1476869fc93553b3099d387d26bfd0092a9d65,"MINOR: make sure all generated data tests cover all versions (#10078)

Reviewers: David Jacot <djacot@confluent.io>",2021-03-05 00:22:57,Chia-Ping Tsai,Not TDD
96a2b7aac4f1c4a9e020ccc08dadc7a71b460abc,KAFKA-12376: Apply atomic append to the log (#10253),2021-03-04 13:55:43,José Armando García Sancio,Mixed
eebc6f279e61bcd9a331a3a0b305b57ffdc1ab66,"MINOR: Enable topic deletion in the KIP-500 controller (#10184)

This patch enables delete topic support for the new KIP-500 controller. Also fixes the following:
- Fix a bug where feature level records were not correctly replayed.
- Fix a bug in TimelineHashMap#remove where the wrong type was being returned.

Reviewers: Jason Gustafson <jason@confluent.io>, Justine Olshan <jolshan@confluent.io>, Ron Dagostino <rdagostino@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Jun Rao <junrao@gmail.com>

Co-authored-by: Jason Gustafson <jason@confluent.io>",2021-03-04 11:28:20,Colin Patrick McCabe,Mixed
60a097ae406bf2b263d7651ead762ccf1845b14b,"HOTFIX: Controller topic deletion should be atomic (#10264)

Topic deletions should be atomic. This fixes a build error caused by merging of both https://github.com/apache/kafka/pull/10253 and https://github.com/apache/kafka/pull/10184 at about the same time. 

Reviewers: David Arthur <mumrah@gmail.com>",2021-03-04 12:19:34,Jason Gustafson,Mixed
0685b9dcd5e47ea1d543c475e3af6f833b4bb633,"MINOR: Raft max batch size needs to propagate to log config (#10256)

This patch ensures that the constant max batch size defined in `KafkaRaftClient` is propagated to the constructed log configuration in `KafkaMetadataLog`. We also ensure that the fetch max size is set consistently with appropriate testing. 

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Arthur <mumrah@gmail.com>",2021-03-04 14:40:31,Jason Gustafson,Mixed
207bb0826be1be91c12ceb30f525f73aa9519463,"KAFKA-12347: updating TaskMetadata (#10211)

added committed offset, high watermark and idle duration to the taskMetadata.

Reviewers: Boyang Chen <boyang@confluent.io>",2021-03-05 11:27:25,Walker Carlson,Mixed
17851da66791361e9fb0250325da236988149100,"KAFKA-12381: remove live broker checks for forwarding topic creation (#10240)

Removed broker number checks for invalid replication factor when doing the forwarding, in order to reduce false alarms for clients.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-03-05 15:55:14,Boyang Chen,Mixed
31a121c3b7088527e7926392de8f3511e3a76afa,"KAFKA-12403; Ensure local state deleted on `RemoveTopicRecord` received (#10252)

This patch implements additional handling logic for `RemoveTopic` records:

- Update `MetadataPartitions` to ensure addition of deleted partitions to `localRemoved` set
- Ensure topic configs are removed from `ConfigRepository`
- Propagate deleted partitions to `GroupCoordinator` so that corresponding offset commits can be removed

This patch also changes the controller topic id generation logic to use `Uuid.randomUuid` rather than `Random`.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>",2021-03-08 11:21:42,Jason Gustafson,Mixed
e6f8f5d0ae7777f15fb4a6d7744cd58c195aac31,"MINOR: Remove unused variables, methods, parameters, unthrown exceptions, and fix typos (#9457)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com",2021-03-10 13:21:30,Lee Dongjin,Not TDD
029f5a136ae2c74f7f93e716bcc30ce90d8241ad,"KAFKA-10062: Add a methods to retrieve the current timestamps as known by the Streams app (#9744)

Implements KIP-622.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2021-03-10 14:26:24,Rohit Deshpande,Mixed
50518fa8e05827bb4bd9d96278f90015525a1527,"KAFKA-12441: remove deprecated method StreamsBuilder#addGlobalStore (#10284)

The method StreamsBuilder#addGlobalStore was simplified via KIP-233 in 1.1.0 release. This PR removes the old and deprecated overload.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2021-03-10 16:14:44,Matthias J. Sax,Mixed
c534bf45cecb8c06abea699b62084d6aee74705c,"KAFKA-12287: Add WARN logging on consumer-groups when reset-offsets by timestamp or duration can't find an offset and defaults to latest (#10092)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2021-03-10 17:25:59,Jorge Esteban Quilcate Otoya,Not TDD
800d9b5abc50e38a8137dc2912cc4b924d1d372d,"KAFKA-10357: Add validation method for internal topics (#10266)

For KIP-698, we need a way to validate internal topics before we create them. This PR adds a validation method to the InternalTopicManager for that purpose.

Reviewers: Rohan Desai <rohan@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2021-03-11 09:55:30,Bruno Cadonna,Mixed
0e5591beda058e93c959ee78021dc30f6c004a30,"KAFKA-12205; Delete snapshots less than the snapshot at the log start (#10021)

This patch adds logic to delete old snapshots. There are three cases we handle:

1. Remove old snapshots after a follower completes fetching a snapshot and truncates the log to the latest snapshot
2. Remove old snapshots after a new snapshot is created.
3. Remove old snapshots during recovery after the node is restarted.

Reviewers: Cao Manh Dat<caomanhdat317@gmail.com>, José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",2021-03-11 10:10:27,dengziming,Mixed
0dbafce8dd0954b822c17eac8951aee35bbef0bc,"MINOR: Add missing unit tests for Mirror Connect (#10192)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>",2021-03-12 11:32:17,bmaidics,Mixed
4e60ad72fb280926f1d98bcde187a399b577310d,"MINOR: Improve error message in MirrorConnectorsIntegrationBaseTest (#10268)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2021-03-12 12:14:53,Luke Chen,Not TDD
b519117b22e80b0b5597de1ce1e0eb4e4a74878b,"KAFKA-10357: Add missing repartition topic validation (#10305)

Reviewers: Rohan Desai <rohan@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2021-03-12 08:59:41,Bruno Cadonna,Mixed
c6a0f760737bf609409eb928c00cef9e4ba1015d,"KAFKA-12460; Do not allow raft truncation below high watermark (#10310)

Initially we want to be strict about the loss of committed data for the `@metadata` topic. This patch ensures that truncation below the high watermark is not allowed. Note that `MockLog` already had the logic to do so, so the patch adds a similar check to `KafkaMetadataLog`. 

Reviewers: David Jacot <djacot@confluent.io>, Boyang Chen <boyang@confluent.io>",2021-03-12 16:31:51,Jason Gustafson,Mixed
2387d191fcbcc6ae33fe5c48a933e6b14da7aaa5,"KAFKA-12352: Make sure all rejoin group and reset state has a reason (#10232)

1. Create a reason string to be used for INFO log entry whenever we request re-join or reset generation state.
2. Some minor cleanups.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>",2021-03-15 09:24:38,Guozhang Wang,Mixed
eee0045b06758509e61580d64fad06a09f9fc636,"MINOR; Various code cleanups (#10319)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-03-16 17:00:04,David Jacot,Not TDD
bf639905f66acb86d04c33165cd9e232dba66b80,"KAFKA-12427: Don't update connection idle time for muted connections (#10267)

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2021-03-16 19:18:28,David Mao,Not TDD
d80a87f2abe24095729d8a33bad6fef6ca0e642e,"KAFKA-12330; FetchSessionCache may cause starvation for partitions when FetchResponse is full (#10318)

The incremental FetchSessionCache sessions deprioritizes partitions where a response is returned. This may happen if log metadata such as log start offset, hwm, etc is returned, or if data for that partition is returned.

When a fetch response fills to maxBytes, data may not be returned for partitions even if the fetch offset is lower than the fetch upper bound. However, the fetch response will still contain updates to metadata such as hwm if that metadata has changed. This can lead to degenerate behavior where a partition's hwm or log start offset is updated resulting in the next fetch being unnecessarily skipped for that partition. At first this appeared to be worse, as hwm updates occur frequently, but starvation should result in hwm movement becoming blocked, allowing a fetch to go through and then becoming unstuck. However, it'll still require one more fetch request than necessary to do so. Consumers may be affected more than replica fetchers, however they often remove partitions with fetched data from the next fetch request and this may be helping prevent starvation.

Reviewers: Lucas Bradstreet <lucas@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2021-03-16 19:24:08,David Jacot,Mixed
b96fc7892f1e885239d3290cf509e1d1bb41e7db,"KAFKA-12455: Fix OffsetValidationTest.test_broker_rolling_bounce failure with Raft (#10322)

This test was failing when used with a Raft-based metadata quorum but succeeding with a
ZooKeeper-based quorum. This patch increases the consumers' session timeouts to 30 seconds,
which fixes the Raft case and also eliminates flakiness that has historically existed in the
Zookeeper case.

This patch also fixes a minor logging bug in RaftReplicaManager.endMetadataChangeDeferral() that
was discovered during the debugging of this issue, and it adds an extra logging statement in RaftReplicaManager.handleMetadataRecords() when a single metadata batch is applied to mirror
the same logging statement that occurs when deferred metadata changes are applied.

In the Raft system test case the consumer was sometimes receiving a METADATA response with just
1 alive broker, and then when that broker rolled the consumer wouldn't know about any alive nodes.
It would have to wait until the broker returned before it could reconnect, and by that time the group
coordinator on the second broker would have timed-out the client and initiated a group rebalance. The
test explicitly checks that no rebalances occur, so the test would fail. It turns out that the reason why
the ZooKeeper configuration wasn't seeing rebalances was just plain luck. The brokers' metadata
caches in the ZooKeeper configuration show 1 alive broker even more frequently than the Raft
configuration does. If we tweak the metadata.max.age.ms value on the consumers we can easily
get the ZooKeeper test to fail, and in fact this system test has historically been flaky for the
ZooKeeper configuration. We can get the test to pass by setting session.timeout.ms=30000 (which
is longer than the roll time of any broker), or we can increase the broker count so that the client
never sees a METADATA response with just a single alive broker and therefore never loses contact
with the cluster for an extended period of time. We have plenty of system tests with 3+ brokers, so
we choose to keep this test with 2 brokers and increase the session timeout.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-03-16 13:57:29,Ron Dagostino,Not TDD
8ef1619f3e7e6eb9e350424b0320cb0a11886aaa,"KAFKA-12459; Use property testing library for raft event simulation tests (#10323)

This patch changes the raft simulation tests to use jqwik, which is a property testing library. This provides two main benefits:

- It simplifies the randomization of test parameters. Currently the tests use a fixed set of `Random` seeds, which means that most builds are doing redundant work. We get a bigger benefit from allowing each build to test different parameterizations.
- It makes it easier to reproduce failures. Whenever a test fails, jqwik will report the random seed that failed. A developer can then modify the `@Property` annotation to use that specific seed in order to reproduce the failure.

This patch also includes an optimization for `MockLog.earliestSnapshotId` which reduces the time to run the simulation tests dramatically.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>, José Armando García Sancio <jsancio@gmail.com>, David Jacot <djacot@confluent.io>",2021-03-17 19:20:07,Jason Gustafson,Not TDD
bca29e29000d9f223c4289002c8565cf9779e807,"KAFKA-12454: Add ERROR logging on kafka-log-dirs when given brokerIds do not  exist in current kafka cluster (#10304)

When non-existent brokerIds value are given, the kafka-log-dirs tool will have a timeout error:

Exception in thread ""main"" java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment. Call: describeLogDirs
at org.apache.kafka.common.internals.KafkaFutureImpl.wrapAndThrow(KafkaFutureImpl.java:45)
at org.apache.kafka.common.internals.KafkaFutureImpl.access$000(KafkaFutureImpl.java:32)
at org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:89)
at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:260)
at kafka.admin.LogDirsCommand$.describe(LogDirsCommand.scala:50)
at kafka.admin.LogDirsCommand$.main(LogDirsCommand.scala:36)
at kafka.admin.LogDirsCommand.main(LogDirsCommand.scala)
Caused by: org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment. Call: describeLogDirs

When the brokerId entered by the user does not exist, an error message indicating that the node is not present should be printed.

Reviewers: David Jacot <djacot@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2021-03-18 16:15:43,wenbingshen,Mixed
4be0033e622b760ec0387b6a316ca8b3763b54b2,"KAFKA-10357: Add setup method to internal topics (#10317)

For KIP-698, we need a way to setup internal topics without validating them. This PR adds a setup method to the InternalTopicManager for that purpose.

Reviewers: Rohan Desai <rohan@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2021-03-18 09:52:08,Bruno Cadonna,Mixed
f6884cc6ddb6b938443512d029c7beacfc7a3ffc,"MINOR: Fix BaseHashTable sizing (#10334)

The array backing BaseHashTable is intended to be sized as a power of
two.  Due to a bug, the initial array size was calculated incorrectly
in some cases.

Also make the maximum array size the largest possible 31-bit power of
two.  Previously it was a smaller size but this was due to a typo.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jose Sancio <jsancio@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2021-03-18 09:58:49,Colin Patrick McCabe,Mixed
94f319d9bbeca70ef59b351834ac19a057d09c5e,"MINOR: Start the broker-to-controller channel for request forwarding (#10340)

Also use different log prefixes for the different channels",2021-03-18 14:03:06,David Arthur,Not TDD
4abdb59d71e6dcc25dd093f425d3b39857587554,"KAFKA-10697: Remove ProduceResponse.responses (#10332)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-03-19 10:04:56,CHUN-HAO TANG,Mixed
1fb8bd9c44749bc0045dce0e156fea04652f0524,"KAFKA-10070: parameterize Connect unit tests to remove code duplication (#10299)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Konstantine Karantasis <k.karantasis@gmail.com>",2021-03-19 14:03:36,Lev Zemlyanov,Not TDD
d9bb2ef596343da9402bff4903b129cff1f7c22b,"MINOR: The new KIP-500 code should treat cluster ID as a string (#10357)

Cluster ID has traditionally been treated as a string by the Kafka protocol (for example,
AdminClient returns it as a string).  The new KIP-500 code should continue this practice.  If
we don't do this, upgrading existing clusters may be harder to do.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Jason Gustafson <jason@confluent.io>",2021-03-19 09:56:04,Ron Dagostino,Mixed
a19806f2628e79baa2dbf84ea307787af7ca186f,"KAFKA-12253: Add tests that cover all of the cases for ReplicatedLog's validateOffsetAndEpoch (#10276)

Improves test coverage of `validateOffsetAndEpoch`. 

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",2021-03-19 10:09:38,Rohit Deshpande,Not TDD
69eebbf968b520097c9e8441e5b18eac9f1fc075,"KAFKA-12440; ClusterId validation for Vote, BeginQuorum, EndQuorum and FetchSnapshot (#10289)

Previously we implemented ClusterId validation for the Fetch API in the Raft implementation. This patch adds ClusterId validation to the remaining Raft RPCs. 

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",2021-03-19 10:27:47,dengziming,Mixed
ca166ea61b6a05b09178370656b6a5c7625970a0,"KAFKA-9189: Use MetadataCache instead of ZK during controlled shutdown to avoid hang (#10361)

This avoids hanging during shutdown if ZK is unavailable. We could change ZK
calls to get the controller id and the broker information to have a timeout, but I
think this approach is better.

The downside is that the metadata cache may be slightly out of date, but we will
retry as per the controlled shutdown configuration. If this broker is partitioned
away from the Controller and is not receiving metadata updates, then we want
to shutdown asap anyway.

I added a test that timed out without this change and included a couple of clean-ups
in `ServerShutdownTest`:
* Removed `testCleanShutdownWithDeleteTopicEnabled`, which is redundant
since delete topics is enabled by default.
* Removed redundant method arguments

Reviewers: David Jacot <djacot@confluent.io>, Jun Rao <junrao@gmail.com>",2021-03-19 11:19:56,Ismael Juma,Not TDD
5dfbefcb3765efd9253795d16b518a84bf6c9a24,"KAFKA-12508: Emit records with same value and same timestamp (#10360)

Emit on change introduced in Streams with KIP-557 might lead to
data loss if a record is put into a source KTable and emitted
downstream and then a failure happens before the offset could be
committed. After Streams rereads the record, it would find a record
with the same key, value and timestamp in the KTable (i.e. the same
record that was put into the KTable before the failure) and not
forward it downstreams. Hence, the record would never be processed
downstream of the KTable which breaks at-least-once and exactly-once
processing guarantees.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-03-19 15:51:19,Bruno Cadonna,Not TDD
7c7e8078e4f91712e44c002b2f67d8d3abb95a31,"MINOR: Use self-managed mode instead of KIP-500 and nozk (#10362)

KIP-500 is not particularly descriptive. I also tweaked the readme text a bit.

Tested that the readme for self-managed still works after these changes.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ron Dagostino <rdagostino@confluent.io>, Jason Gustafson <jason@confluent.io>",2021-03-19 16:42:37,Ismael Juma,Mixed
13b4ca87954160c73db787fd9f9d1af5e21edcb1,"KAFKA-12500: fix memory leak in thread cache (#10355)

Need to exclude threads in PENDING_SHUTDOWN from the num live threads computation used to compute the new cache size per thread. Also adds some logging to help follow what's happening when a thread is added/removed/replaced.

Reviewers: Bruno Cadonna <cadonna@confluent.io>, Walker Carlson <wcarlson@confluent.io>, John Roesler <john@confluent.io>",2021-03-19 18:11:07,A. Sophie Blee-Goldman,Not TDD
a290c8e1df371a5605d1eb2ed527f6021f2766b6,"KAFKA-3745: Add access to read-only key in value joiner (#10150)

This PR implements adding read-only access to the key for KStream.join as described in KIP-149

This PR as it stands does not affect the Streams Scala API. Updating the Streams Scala API will be done in a follow-up PR.
Additionally, the original KIP did not include the KTable API, but I don't see any reason why we wouldn't want the same functionality there as well, this will be done in an additional follow-up PR after updating the existing KIP.

Reviewers: Matthias J. Sax <mjsax@apache.org>",2021-03-20 22:19:01,Bill Bejeck,Mixed
2bfe7a9d1ec7a39bb6cb290ed91644f6ad14cb3f,"KAFKA-12514: Fix NPE in SubscriptionState (#10369)

Return null for partitionLag if there is no current position.
This was the desired semantics, the lack of the check was an
oversight.

Patches: KIP-695
Patches: a92b986c855592d630fbabf49d1e9a160ad5b230

Reviewers: Walker Carlson <wcarlson@confluent.io>, A. Sophie Blee-Goldman <ableegoldman@apache.org>",2021-03-21 20:56:16,John Roesler,Mixed
e820eb42b2c7cb812c9db25c4788347029fd7119,"KAFKA-12383: Get RaftClusterTest.java and other KIP-500 junit tests working (#10220)

Introduce ""testkit"" package which includes KafkaClusterTestKit class for enabling integration tests of self-managed clusters. Also make use of this new integration test harness in the ClusterTestExtentions JUnit extension. 

Adds RaftClusterTest for basic self-managed integration test. 

Reviewers: Jason Gustafson <jason@confluent.io>, Colin P. McCabe <cmccabe@apache.org>

Co-authored-by: Colin P. McCabe <cmccabe@apache.org>",2021-03-22 11:45:56,David Arthur,Mixed
80f373d34f7716a54fa9ec1e37a27c65cbbae0f2,"(Cherry-pick) KAFKA-9274: handle TimeoutException on task reset (#10000) (#10372)

This PR was removed by accident in trunk and 2.8, bringing it back.

Co-authored-by: Matthias J. Sax <matthias@confluent.io>
Reviewers: Matthias J. Sax <matthias@confluent.io>",2021-03-22 13:39:29,Boyang Chen,Mixed
f5f66b982d98a98558809edc51685c3b0a12a958,"KAFKA-12181; Loosen raft fetch offset validation of remote replicas (#10309)

Currently the Raft leader raises an exception if there is a non-monotonic update to the fetch offset of a replica. In a situation where the replica had lost it disk state, this would prevent the replica from being able to recover. In this patch, we relax the validation to address this problem. It is worth pointing out that this validation could not be relied on to protect from data loss after a voter has lost committed state.

Reviewers: José Armando García Sancio <jsancio@gmail.com>, Boyang Chen <boyang@confluent.io>",2021-03-22 16:05:07,Jason Gustafson,Mixed
e0cbd0fa664feddd412b23d75e12fa5862b24696,"MINOR: Remove duplicate definition about 'the' from kafka project (#10370)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-03-23 10:44:55,wenbingshen,Not TDD
3d0b4d910b681df7d873c8a0285eaca01d6c173a,"MINOR: use new method to get number of topics in DeleteTopicsRequest (#10351)

Reviewers: David Jacot <djacot@confluent.io>",2021-03-23 08:29:17,Justine Olshan,Mixed
e3f60c254c66d7021d3e0b61968a59a70e00cb39,"KAFKA-12479: Batch partition offset requests in ConsumerGroupCommand (#10371)

Reviewers: David Jacot <djacot@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2021-03-23 09:56:56,Rajini Sivaram,Not TDD
9af81955c497b31b211b1e21d8323c875518df39,"KAFKA-12173 Migrate streams:streams-scala module to JUnit 5 (#9858)

1. replace org.junit.Assert by org.junit.jupiter.api.Assertions
2. replace org.junit by org.junit.jupiter.api
3. replace Before by BeforeEach
4. replace After by AfterEach
5. remove ExternalResource from all scala modules
6. add explicit AfterClass/BeforeClass to stop/start EmbeddedKafkaCluster

Noted that this PR does not migrate stream module to junit 5 so it does not introduce callback of junit 5 to deal with beforeAll/afterAll. The next PR of migrating stream module can replace explicit beforeAll/afterAll by junit 5 extension. Or we can keep the beforeAll/afterAll if it make code more readable.

Reviewers: John Roesler <vvcephei@apache.org>",2021-03-25 01:04:39,Chia-Ping Tsai,Not TDD
11f0ea3a5e692f7b68e05f287e73ffc0f7fd073c,"KAFKA-12432: AdminClient should time out nodes that are never ready (#10281)

Previously, if we assigned one or more calls to a remote node, but it
never became available, AdminClient would block until the calls hit
their the API timeout.  This was particularly unfortunate in the case
where the calls could have been sent to a different node in the cluster.
This PR fixes this behavior by timing out pending connections to
remote nodes if they take longer than the request timeout.

There are a few other small cleanups in this PR: it removes the
unecessary Call#aborted, sets Call#curNode to null after the call has
failed to avoid confusion when debugging or logging, and adds a
""closing"" boolean rather than setting newCalls to null when the client
is closed.  Also, it increases the log level of the log message that
indicates that we timed out some calls because AdminClient closed,
and simplifies the type of callsInFlight.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-03-24 11:10:19,Colin Patrick McCabe,Mixed
9bf5c579973f842ce892c0131923fb6e009c10de,"KAFKA-12435: Fix javadoc errors (#10392)

There were errors while generating javadoc for the streams:test-utils module
because the included TopologyTestDriver imported some excluded classes.

This fixes the errors by inlining the previously excluded packages.

Reviewers: Chia-Ping Tsai <chia7712@apache.org>, Ismael Juma <ijuma@apache.org>",2021-03-24 13:55:27,John Roesler,Mixed
3ab9ab6b6ffea700753309d5b9074b45f97b0aa7,"KAFKA-12434; Admin support for `DescribeProducers` API (#10275)

This patch adds the new `Admin` API to describe producer state as described by KIP-664: https://cwiki.apache.org/confluence/display/KAFKA/KIP-664%3A+Provide+tooling+to+detect+and+abort+hanging+transactions.

The three new APIs added by KIP-664 require different lookup and request patterns:

- DescribeProducers: send to partition leaders
- DescribeTransactions: send to coordinators
- ListTransactions: send to all brokers

Our method of handling complex workflows such as these in `KafkaAdminClient` by chaining together `Call` instances has been clumsy and error-prone at best. I have attempted to introduce a new pattern which separates the lookup stage (e.g. finding partition leaders) from the fulfillment stage (e.g. sending `DescribeProducers`). The lookup stage is implemented by `AdminApiLookupStrategy` and the fulfillment stage is implemented by `AdminApiHandler`. There is a new class `AdminApiDriver` which manages the bookkeeping for these two stages. See the corresponding javadocs for more detail. 

This PR provides an example of usage through `DescribeProducersHandler`, which is an implementation of `AdminApiHandler`. It relies on `PartitionLeaderStrategy` which implements `AdminApiLookupStrategy`. In addition to allowing for easier reuse of lookup strategies, this approach provides a more convenient way for testing since all of the logic is not crammed into `KafkaAdminClient`. Follow-up PRs for the rest of KIP-664 will flesh out additional lookup strategies such as for coordinator APIs.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>",2021-03-24 20:15:58,Jason Gustafson,Mixed
9ef52dd2dba51f01f856560132056ebe4bacd51a,"KAFKA-12508: Disable KIP-557 (#10397)

A major issue has been raised that this implementation of
emit-on-change is vulnerable to a number of data-loss bugs
in the presence of recovery with dirty state under at-least-once
semantics. This should be fixed in the future when we implement
a way to avoid or clean up the dirty state under at-least-once,
at which point it will be safe to re-introduce KIP-557 and
complete it.

Reviewers: A. Sophie Blee-Goldman <ableegoldman@apache.org>",2021-03-25 14:42:26,John Roesler,Mixed
03f13d1c41c033432f5a605b557cc832a18f1790,"KAFKA-12452: Remove deprecated overloads of ProcessorContext#forward (#10300)

ProcessorContext#forward was changed via KIP-251 in 2.0.0 release. This PR removes the old and deprecated overloads.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>",2021-03-25 19:49:18,Matthias J. Sax,Mixed
f91d592a270dc4254978fbdb51e9cd479426b931,"KAFKA-12537: fix application shutdown corner case with only one thread (#10387)

When in EOS the run loop terminates on that thread before the shutdown can be called. This is a problem for EOS single thread applications using the application shutdown feature.

I changed it so in all cases with a single thread, the dying thread will spin up a new thread to communicate the shutdown and terminate the dying thread. Also @ableegoldman refactored the catch blocks in runloop.

Co-authored-by: A. Sophie Blee-Goldman <ableegoldman@gmail.com>

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-03-26 19:55:27,Walker Carlson,Mixed
b8058829bbc2eaaebba3ca959e9e601e112516ab,"KAFKA-12562: Remove deprecated APIs in KafkaStreams and returned state classes (#10412)

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>",2021-03-28 12:20:31,Guozhang Wang,Not TDD
d5fd491bf7e92e4b07a0a371dfa766161ac301d2,"KAFKA-7106: remove deprecated Windows APIs (#10378)

1. Remove all deprecated APIs in KIP-328.
2. Remove deprecated APIs in Windows in KIP-358.

Reviewers: John Roesler <vvcephei@apache.org>",2021-03-28 12:33:40,Guozhang Wang,Mixed
fb2eef94a4ae91501d869e2075c511b433877099,"KAFKA-12523: handle TaskCorruption and TimeoutException during handleCorruption  and handleRevocation (#10407)

Need to handle TaskCorruptedException and TimeoutException that can be thrown from offset commit during handleRevocation or handleCorruption

Reviewers: Matthias J. Sax <mjsax@confluent.org>, Guozhang Wang <guozhang@confluent.io>",2021-03-29 14:06:22,A. Sophie Blee-Goldman,Mixed
16b2d4f3a7864aabb7c438268eeea8d602b9299c,"MINOR: Self-managed -> KRaft (Kafka Raft) (#10414)

`Self-managed` is also used in the context of Cloud vs on-prem and it can
be confusing.

`KRaft` is a cute combination of `Kafka Raft` and it's pronounced like `craft`
(as in `craftsmanship`).

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Jose Sancio <jsancio@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>, Ron Dagostino <rdagostino@confluent.io>",2021-03-29 15:39:10,Ismael Juma,Mixed
0018c3c0890407bb18788174c9c8fb584becd83e,"KAFKA-12573; Remove deprecated `Metric#value` (#10425)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-03-30 09:28:48,David Jacot,Not TDD
d92d464b124f7e94cc240f062c6f96813ecb76d7,"KAFKA-12552: Introduce LogSegments class abstracting the segments map (#10401)

This PR is a precursor to the recovery logic refactor work (KAFKA-12553).

In this PR, I've extracted the behavior surrounding segments map access within kafka.log.Log class into a new class: kafka.log.LogSegments. This class encapsulates a thread-safe navigable map of kafka.log.LogSegment instances and provides the required read and write behavior on the map. The Log class now encapsulates an instance of the LogSegments class.

Couple advantages of this PR:

Makes the Log class a bit more modular as it moves out certain private behavior thats otherwise within the Log class.
This is a precursor to refactoring the recovery logic (KAFKA-12553). In the future, the logic for recovery and loading of segments from disk (during Log) init will reside outside the Log class. Such logic would need to instantiate and access an instance of the newly added LogSegments class.
Tests:
Added a new test suite: kafka.log.LogSegmentsTest covering the APIs of the newly introduced class.

Reviewers: Satish Duggana <satishd@apache.org>, Dhruvil Shah <dhruvil@confluent.io>, Jun Rao <junrao@gmail.com>",2021-03-30 09:51:49,Kowshik Prakasam,Mixed
d22c49217e3635c9aea919470d30ed924723821a,"MINOR: Fix newly added client side timeout tests in `KafkaAdminClientTest` (#10398)

This patch fixes a race condition between the background thread calling `ready` and the call to `MockTime.sleep` in the test. If the call to `sleep` happens first, then the test hangs. I fixed it by giving `MockClient` a way to listen to `ready` calls. This combined with a latch fixes the race. 

This patch also fixes a similar race condition in `testClientSideTimeoutAfterFailureToReceiveResponse`. After the disconnect, there is a race between the background thread sending the retry request and the foreground sleeping for the needed backoff delay.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, David Arthur <mumrah@gmail.com>",2021-03-30 15:45:08,Jason Gustafson,Not TDD
0189298d8667f770a69fb453d99971475f56af4b,"KAFKA-12288: remove task-level filesystem locks (#10342)

The filesystem locks don't protect access between StreamThreads, only across different instances of the same Streams application. Running multiple processes in the same physical state directory is not supported, and as of PR #9978 it's explicitly guarded against), so there's no reason to continue locking the task directories with anything heavier than an in-memory map.

Reviewers: Rohan Desai <rodesai@confluent.io>, Walker Carlson <wcarlson@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2021-03-30 17:02:42,A. Sophie Blee-Goldman,Mixed
b35704a8431a5ea99b4da3ae3b344da92c42859c,"KAFKA-12571: Eliminate LeaderEpochFileCache constructor dependency on logEndOffset (#10426)

This PR is a precursor to the recovery logic refactor work (KAFKA-12553).

Problems:
For refactoring the recovery logic (KAFKA-12553), we would like to move the logic to initialize LeaderEpochFileCache out of the Log class and into a separate static function. In the future, once we successfully initialize LeaderEpochFileCache outside Log, we will be able pass it as a dependency into both the Log recovery module and Log class constructor. However, currently the LeaderEpochFileCache constructor takes a dependency on logEndOffset (via a callback), which poses the following problems:

Blocks the instantiation of LeaderEpochFileCache outside Log class. Because, outside Log the logEndOffset is unavailable to be passed into LeaderEpochFileCache constructor. As a result, this situation blocks the recovery logic (KAFKA-12553) refactor work.
It turns out the logEndOffset dependency is used only in 1 of the LeaderEpochFileCache methods: LeaderEpochFileCache.endOffsetFor, and just for 1 particular case. Therefore, it is overkill to pass it in the constructor as a dependency. Also a callback is generally not a neat way to access dependencies and it poses code readability problems too.

Solution:
This PR modifies the code such that we only pass the logEndOffset as a parameter into LeaderEpochFileCache.endOffsetFor whenever the method is called, thus eliminating the constructor dependency. This will also unblock the recovery logic refactor work (KAFKA-12553).

Tests:
I have modified the existing tests to suit the above refactor.

Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Jun Rao <junrao@gmail.com>",2021-03-30 17:31:27,Kowshik Prakasam,Mixed
3eff8d39f144644eea31687cf36c8e181fb6405e,"HOTFIX: move rebalanceInProgress check to skip commit during handleCorrupted (#10444)

Minor followup to #10407 -- we need to extract the rebalanceInProgress check down into the commitAndFillInConsumedOffsetsAndMetadataPerTaskMap method which is invoked during handleCorrupted, otherwise we may attempt to commit during a a rebalance which will fail

Reviewers: Matthias J. Sax <mjsax@confluent.io>",2021-03-30 18:55:38,A. Sophie Blee-Goldman,Mixed
e8754ba7a01f33ba503ef79de66a5f644cc2ced8,"KAFKA-12578: Remove deprecated security classes/methods for 3.0 (#10435)

More specifically, remove deprecated:
- Constants in SslConfigs
- Constants in SaslConfigs
- AclBinding constructor
- AclBindingFilter constructor
- PrincipalBuilder and DefaultPrincipalBuilder classes
- ResourceFilter

Also simplify tests and code that no longer have to handle the removed `PrincipalBuilder`.

These removals seem non controversial. There is a straightforward alternative. The
deprecations happened in 1.0.0 and 2.0.0.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-03-30 22:02:16,Ismael Juma,Mixed
3829df103e99cba8a54c8591d9e32a969af47a02,"MINOR Replaced File with Path in LogSegmentData. (#10424)

Replaced File with Path in LogSegment Data.

This is a followup of #10173

Reviewers: Kowshik Prakasam <kprakasam@confluent.io>, Jun Rao <junrao@gmail.com>",2021-03-31 10:43:10,Satish Duggana,Not TDD
6d7a9012dc25ced4884441ab6ff42a7658f5c15b,"KAFKA-8405; Remove deprecated `kafka-preferred-replica-election` command (#10443)

The `kafka-preferred-replica-election` command was deprecated in 2.4. This path removes it for 3.0. `kafka-leader-election` can be used instead.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>, Jason Gustafson <jason@confluent.io>",2021-03-31 20:45:18,David Jacot,Mixed
2342ec1d1cc03f4f244fc2921978534af63ae54f,"KAFKA-12600: Remove deprecated config value `default` for client config `client.dns.lookup` (#10458)

The config has been deprecated since Kafka 2.6 (released ~1 year before
3.0), but it was the default before it got deprecated. As such, it's
reasonably unlikely that people would have set it explicitly.

Given the confusing `default` name even though it's _not_ the default, I
think we should remove it in 3.0.

Also remove `ClientDnsLookup.DEFAULT` (not public API), which unlocks
a number of code simplications.

Reviewers: David Jacot <djacot@confluent.io>",2021-04-01 07:59:59,Ismael Juma,Mixed
4ed7f2cd01deabca5cf81383d8c9ee68609f8b45,"KAFKA-12593: Fix Apache License headers (#10452)

* Standardize license headers in scala, python, and gradle files.
* Relocate copyright attribution to the NOTICE.
* Add a license header check to `spotless` for scala files.

Reviewers: Ewen Cheslack-Postava <ewencp@apache.org>, Matthias J. Sax <mjsax@apache.org>, A. Sophie Blee-Goldman <ableegoldman@apache.org",2021-04-01 10:38:37,John Roesler,Mixed
aea059a07bf82697635caccb208313163ff89f10,"KAFKA-12474: Handle failure to write new session keys gracefully (#10396)

If a distributed worker fails to write (or read back) a new session key to/from the config topic, it dies. This fix softens the blow a bit by instead restarting the herder tick loop anew and forcing a read to the end of the config topic until the worker is able to successfully read to the end.

At this point, if the worker was able to successfully write a new session key in its first attempt, it will have read that key back from the config topic and will not write a new key during the next tick iteration. If it was not able to write that key at all, it will try again to write a new key (if it is still the leader).

Verified with new unit tests for both cases (failure to write, failure to read back after write).

Author: Chris Egerton <chrise@confluent.io>
Reviewers: Greg Harris <gregh@confluent.io>, Randall Hauch <rhauch@gmail.com>",2021-04-01 12:26:01,Chris Egerton,Mixed
40f001cc537d6ff2efa71e609c2f84c6b934994d,"KAFKA-12426: Missing logic to create partition.metadata files in RaftReplicaManager (#10282)

KIP-516 introduced partition.metadata file to persist the topic ID on the broker. It is created through handling the LeaderAndIsrRequest in ReplicaManager. (See https://github.com/apache/kafka/pull/10143 for the code path.) RaftReplicaManager was missing the analogue code path for Kip-500 code. Like in ReplicaManager, RaftReplicaManager will now check the partition.metadata file when handling metadata records.

However, since we know that all raft topics will have topic IDs, we can simply set the ID in the log upon the log's creation.
Updated the ReplicaManager path to do the same on newly created topics.

There are also some tweaks to the checking logic to better handle the scenario when the log exists but is not yet associated to Partition (for example, upon startup after a shutdown).

Tests added to ensure the file is created and that the correct error is thrown when the id is inconsistent.
Added tests for creating the log with the new topic ID parameter.

Also adds a few methods to get topic ID from MetadataImageBuilder as this is the most convenient way to get topic ID from RaftReplicaManager.

Reviewers: Ron Dagostino <rdagostino@confluent.io>, Jason Gustafson <jason@confluent.io>",2021-04-01 15:42:21,Justine Olshan,Mixed
ec38dcb72f8a056c8f71ad8f577f539356827b74,"MINOR: support ImplicitLinkedHashCollection#sort (#10456)

Support sorting the elements in ImplicitLinkedHashCollection.
This is useful sometimes in unit tests for comparing collections.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-04-01 18:30:53,Colin Patrick McCabe,Mixed
66b0c5c64f2969dc62362b9f169ad1d18f64efe9,"KAFKA-3968: fsync the parent directory of a segment file when the file is created (#10405)

Kafka does not call fsync() on the directory when a new log segment is created and flushed to disk.

The problem is that following sequence of calls doesn't guarantee file durability:

fd = open(""log"", O_RDWR | O_CREATE); // suppose open creates ""log""
write(fd);
fsync(fd);

If the system crashes after fsync() but before the parent directory has been flushed to disk, the log file can disappear.

This PR is to flush the directory when flush() is called for the first time.

Reviewers: Jun Rao <junrao@gmail.com>",2021-04-02 17:31:56,Cong Ding,Mixed
976e78e405d57943b989ac487b7f49119b0f4af4,"KAFKA-12590: Remove deprecated kafka.security.auth.Authorizer, SimpleAclAuthorizer and related classes in 3.0 (#10450)

These were deprecated in Apache Kafka 2.4 (released in December 2019) to be replaced
by `org.apache.kafka.server.authorizer.Authorizer` and `AclAuthorizer`.

As part of KIP-500, we will implement a new `Authorizer` implementation that relies
on a topic (potentially a KRaft topic) instead of `ZooKeeper`, so we should take the chance
to remove related tech debt in 3.0.

Details on the issues affecting the old Authorizer interface can be found in the KIP:
https://cwiki.apache.org/confluence/display/KAFKA/KIP-504+-+Add+new+Java+Authorizer+Interface

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ron Dagostino <rdagostino@confluent.io>",2021-04-03 08:23:26,Ismael Juma,Mixed
4f47a565e29539d1c252c36c59f5f24d105cec4b,"KAFKA-12539; Refactor KafkaRaftCllient handleVoteRequest to reduce cyclomatic complexity (#10393)

1. Add `canGrantVote` to `EpochState`
2. Move the if-else in `KafkaRaftCllient.handleVoteRequest` to `EpochState`
3. Add unit tests for `canGrantVote`

Reviewers: Jason Gustafson <jason@confluent.io>",2021-04-05 09:27:50,dengziming,Mixed
66ba91733c58ddc3e9465a5b1b234be0b2b06be4,"KAFKA-12548; Propagate record error messages to application (#10445)

KIP-467 added a field in the produce response to allow the broker to indicate which specific records failed validation. This patch adds the logic to propagate this message up to the application.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2021-04-05 11:50:54,Jason Gustafson,Mixed
cad514bff9140b75a3da18c56efaf26df68310c7,"KAFKA-12294; forward auto topic request within envelope on behalf of clients (#10142)

When auto-creating topics in KIP-500, the broker will send a `CreateTopics` request to the controller. It is useful in this case to preserve the original principal from the corresponding `Metadata` request by wrapping the `CreateTopics` request in an envelope so that the controller may repeat the authorization and to improve auditability. This follows a similar pattern to how standard `CreateTopics` requests are forwarded to the controller.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-04-05 15:54:57,Boyang Chen,Mixed
2f3600198722dd5a01a210bc78b7d43b33967c7f,"KAFKA-12579: Remove various deprecated clients classes/methods for 3.0 (#10438)

* Remove `ExtendedSerializer` and `ExtendedDeserializer`, deprecated since 2.1.
The extra functionality was also made available in `Serializer` and `Deserializer`.
* Remove `close(long, TimeUnit)` from the producer, consumer and admin client,
deprecated since 2.0 for the consumer and 2.2 for the rest. The replacement is `close(Duration)`.
* Remove `ConsumerConfig.addDeserializerToConfig` and `ProducerConfig.addSerializerToConfig`,
deprecated since 2.7 with no replacement. These methods were not intended to be public API
and are likely not used much (if at all).
* Remove `NoOffsetForPartitionException.partition()`, deprecated since 0.11. `partitions()`
should be used instead.
* Remove `MessageFormatter.init(Properties)`, deprecated since 2.7. The `configure(Map)`
method should be used instead.
* Remove `kafka.common.MessageFormatter`, deprecated since 2.7.
`org.apache.kafka.common.MessageFormatter` should be used instead.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>",2021-04-06 08:54:53,Ismael Juma,Mixed
137491c7248c90327b72eda88fa26d18c4a589f0,"MINOR: Support ExponentialBackoff without jitter (#10455)

It is useful to allow ExponentialBackoff to be configured to work
without jitter, in order to make unit tests more repeatable.

Reviewers: David Arthur <mumrah@gmail.com>",2021-04-06 09:49:14,Colin Patrick McCabe,Mixed
7bc84d6ced71056dbb4cecdc9abbdbd7d8a5aa10,"KAFKA-12467: Implement QuorumController snapshot generation (#10366)

Implement controller-side snapshot generation.Implement QuorumController snapshot
generation.  Note that this PR does not handle KRaft integration, just the internal 
snapshot record generation and consumption logic.

Reading a snapshot is relatively straightforward.  When the  QuorumController
starts up, it loads the most recent snapshot.  This is just a series of records
that we replay, plus a log offset (""snapshot epoch"") that we advance to.

Writing a snapshot is more complex.  There are several components:
the SnapshotWriter which persists the snapshot, the SnapshotGenerator
which manages writing each batch of records, and the SnapshotGeneratorManager
which interfaces the preceding two classes with the event queue.

Controller snapshots are done incrementally.  In order to avoid blocking the
controller thread for a long time, we pull a few record batches at a time from
our record batch iterators.  These iterators are implemented by controller
manager classes such as ReplicationControlManager, ClusterControlManager, etc.

Finally, this PR adds ControllerTestUtils#deepSortRecords and
ControllerTestUtils#assertBatchIteratorContains, which make it easier to write
unit tests.  Since records are often constructed from unsorted data structures,
it is often useful to sort them before comparing them.

Reviewers: David Arthur <mumrah@gmail.com>",2021-04-06 10:18:06,Colin Patrick McCabe,Mixed
be592dfbed716f2ce39e8f8e719a70d0a9d56ae1,"KAFKA-10769 Remove JoinGroupRequest#containsValidPattern as it is dup… (#9851)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-04-07 11:39:48,high.lee,Mixed
999fcba3ec16526c32949836549ae8059ea61ffa,"MINOR: refactor ControllerApis#createTopics (#10465)

Refactor ControllerApis#createTopics to be easier to unit test.  Add
unit tests for various invalid request and permission denied scenarios.
In ControllerApisTest, statically import all the Errors enums.
Implement MockController#createTopics.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-04-07 10:34:51,Colin Patrick McCabe,Mixed
37493d1e18d9ec85b392e852032c85a57bbc3d28,"KAFKA-10847: Add new RocksDBTimeOrderedWindowStore that persists (time-key)-value records (#10331)

This new store is more efficient when calling range queries with only time parameters, like `fetch(from, to)`. For range queries using key ranges, then the current RocksDBWindowStore should be used.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2021-04-07 13:35:12,Sergio Peña,Mixed
00ec646c5a1762bdce28ed9878cfa46961de37b6,"KAFKA-7785: move internal DefaultPartitionGrouper (#10302)

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2021-04-07 13:36:39,high.lee,Mixed
6e1723b4834b75bc0e16749afe31e5b690bec698,"MINOR Moved tiered storage API classes from clients module to a new storage-api wmodule. (#10489)

Moved tiered storage API classes from clients module to a new storage-api module.
Created storage and storage-api modules. All the remote storage API classes are moved to storage-api module. All the remote storage implementation classes will be added to storage module.

Reviewers: Jun Rao <junrao@gmail.com>",2021-04-07 13:52:50,Satish Duggana,Not TDD
3ca5a3bb78ec2324391c026d3dd1b6773cf9c772,"KAFKA-12568: Remove deprecated APIs in KStream, KTable and Joined (#10421)

This is related to KIP-307 / KIP-372 / KIP-479.

Reviewers: John Roesler <vvcephei@apache.org>",2021-04-07 17:38:43,Guozhang Wang,Mixed
c2ea0c2e1d44332639214b921ddf3dc1edf478c0,"KAFKA-12457; Add sentinel ID to metadata topic (#10492)

KIP-516 introduces topic IDs to topics, but there is a small issue with how the KIP-500 metadata topic will interact with topic IDs. 

For example, https://github.com/apache/kafka/pull/9944 aims to replace topic names in the Fetch request with topic IDs. In order to get these IDs, brokers must fetch from the metadata topic. This leads to a sort of ""chicken and the egg"" problem concerning how we find out the metadata topic's topic ID. 

This PR adds the a special sentinel topic ID for the metadata topic, which gets around this problem.
More information can be found in the [JIRA](https://issues.apache.org/jira/browse/KAFKA-12457) and in [KIP-516](https://cwiki.apache.org/confluence/display/KAFKA/KIP-516%3A+Topic+Identifiers).

Reviewers: Jason Gustafson <jason@confluent.io>",2021-04-08 10:24:23,Justine Olshan,Mixed
d2c06c9c3c35803b9f5f0b6060b242789657f008,"KAFKA-12619; Raft leader should expose hw only after committing LeaderChange (#10481)

KIP-595 describes an extra condition on commitment here: https://cwiki.apache.org/confluence/display/KAFKA/KIP-595%3A+A+Raft+Protocol+for+the+Metadata+Quorum#KIP595:ARaftProtocolfortheMetadataQuorum-Fetch. In order to ensure that a newly elected leader's committed entries cannot get lost, it must commit one record from its own epoch. This guarantees that its latest entry is larger (in terms of epoch/offset) than any previously written record which ensures that any future leader must also include it. This is the purpose of the `LeaderChange` record which is written to the log as soon as the leader gets elected.

Although we had this check implemented, it was off by one. We only ensured that replication reached the epoch start offset, which does not reflect the appended `LeaderChange` record. This patch fixes the check and clarifies the point of the check. The rest of the patch is just fixing up test cases.

Reviewers: dengziming <swzmdeng@163.com>, Guozhang Wang <wangguoz@gmail.com>",2021-04-08 10:42:30,Jason Gustafson,Mixed
5964401bf9aab611bd4a072941bd1c927e044258,KAFKA-12406 Integrate client quotas with KRaft broker (#10254),2021-04-08 13:56:21,David Arthur,Mixed
ff3b2d67a1049c75b300547ca6ecf074b6a3ab28,"KAFKA-12591; Remove deprecated `quota.producer.default` and `quota.consumer.default` configurations (#10427)

`quota.producer.default` and `quota.consumer.default` were deprecated in AK 0.11.0.0. Dynamic default quotas must be used instead. This patch removes them for AK 3.0. 

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>",2021-04-09 18:11:34,David Jacot,Mixed
db0323e9ba3f767614415d833a2081a33825a284,"KAFKA-12449: Remove deprecated WindowStore#put (#10293)

Removes `WindowStore#put(K,V)` that was deprecated via KIP-474.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2021-04-09 11:49:37,Jorge Esteban Quilcate Otoya,Mixed
f76b8e493832fe7374e58dff460b81eee6245ce5,"KAFKA-9831: increase max.poll.interval.ms to avoid unexpected rebalance (#10301)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2021-04-09 12:19:14,Luke Chen,Not TDD
c9cab2beb8159ca83e6e2c930514ba97282e1ae9,"KAFKA-8410: Migrate KStream Stateless operators to new Processor API (#10381)

Migrate KStream stateless operators to new Processor API.
Following PRs will complete migration of KStream stateful operators and KTable.
No expected functionality changes.

Reviewers: John Roesler <vvcephei@apache.org>",2021-04-09 14:49:54,Jorge Esteban Quilcate Otoya,Mixed
10308b7a528e9da1e8c6dba6cff0596729d3c1fb,"KAFKA-9988: Suppress uncaught exceptions in log messages during Connect task shutdown (#10503)

Uncaught exceptions logged during task stop were misleading because the task is already on its way of being shutdown.

The suppression of exception causes a change in behavior as the caller method now calls `statusListener.onShutdown` instead of `statusListener.onFailure` which is the right behavior. A new test was added to test the right behavior for uncaught exception during shutdown and existing test was modified to test uncaught exception during normal execution.

Reviewers: Chris Egerton <chrise@confluent.io>, Konstantine Karantasis <k.karantasis@gmail.com>",2021-04-12 08:06:18,kpatelatwork,Not TDD
e677782112743d16eca411dd1e1f905f67956da1,"KAFKA-9527: fix NPE when using time-based argument for Stream Resetter Tool (#10042)

Reviewers: Jorge Esteban Quilcate Otoya <quilcate.jorge@gmail.com>, Matthias J. Sax <matthias@confluent.io>",2021-04-12 09:28:23,Marco Aurelio Lotz,Mixed
c608d8480edad982bd121fc8b70cd8347eff2e60,"KAFKA-7606: Remove deprecated options from StreamsResetter (#10411)

Remove deprecated --zookeeper and --execute flags

Reviewers: Matthias J. Sax <mjsax@confluent.io>",2021-04-12 18:24:18,A. Sophie Blee-Goldman,Not TDD
88eb24db40cc47786b6c72fa9f77032281f6e1b0,"KAFKA-12637: Remove deprecated PartitionAssignor interface (#10512)

Remove PartitionAssignor and related classes, update docs and move unit test

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-04-12 18:37:01,dengziming,Mixed
327809024fab07c44cd6d87985db5b9d14fd43bb,"KAFKA-12368: Added inmemory implementations for RemoteStorageManager and RemoteLogMetadataManager. (#10218)

KAFKA-12368: Added inmemory implementations for RemoteStorageManager and RemoteLogMetadataManager.

Added inmemory implementation for RemoteStorageManager and RemoteLogMetadataManager. A major part of inmemory RLMM will be used in the default RLMM implementation which will be based on topic storage. These will be used in unit tests for tiered storage.
Added tests for both the implementations and their supported classes.
This is part of tiered storage implementation, KIP-405.

Reivewers:  Kowshik Prakasam <kprakasam@confluent.io>, Jun Rao <junrao@gmail.com>",2021-04-13 10:14:03,Satish Duggana,Mixed
a8a6952e4a0b6f161dee4caa3eb0cb0fbf23091c,"KAFKA-12471: Implement createPartitions in KIP-500 mode (#10343)

Implement the createPartitions RPC which adds more partitions to a topic
in the KIP-500 controller.  Factor out some of the logic for validating
manual partition assignments, so that it can be shared between
createTopics and createPartitions.  Add a startPartition argument to the
replica placer.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-04-13 11:00:22,Colin Patrick McCabe,Mixed
89933f21f204abf75336464d3ac24a4fdd254628,"KAFKA-12612: Remove `checksum` from ConsumerRecord/RecordMetadata for 3.0 (#10470)

The methods have been deprecated since 0.11 without replacement since
message format 2 moved the checksum to the record batch (instead of the
record).

Unfortunately, we did not deprecate the constructors that take a checksum
(even though we intended to) so we cannot remove them. I have deprecated
them for removal in 4.0 and added a single non deprecated constructor to
`ConsumerRecord` and `RecordMetadata` that take all remaining parameters.
`ConsumerRecord` could do with one additional convenience constructor, but
that requires a KIP and hence should be done separately.

Also:
* Removed `ChecksumMessageFormatter`, which is technically not public
API, but may have been used with the console consumer.
* Updated all usages of `ConsumerRecord`/`RecordMetadata` constructors
to use the non deprecated ones.
* Added tests for deprecated `ConsumerRecord/`RecordMetadata`
constructors.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>",2021-04-14 14:38:37,Ismael Juma,Mixed
31b4ba8c5a77b7fc5b92fce5228a872f860b0f18,"MINOR: fix some bugs in ControllerApis.scala (#10505)

Fix some cases where ControllerApis was blocking on the controller
thread.  This should not be necessary, since the controller thread can
just interface directly with the network threads.

Fix some cases where ControllerApis wasn't doing authorization
correctly.  Since the previous release of KRaft did not support
authorizers, this bug is not as severe as it could have been, but it
still needs to be fixed.  Add authorization unit tests for each API.

Add support for the deprecated ALTER_CONFIGS API in ControllerApis.  It
was already supported in QuorumController, but wasn't exposed
previously.

Fix how we validate duplicate config resources and unknown config
resource types in ControllerApis.  Duplicates should yield an
INVALID_REQUEST error, and unknown resource types should give an error
with the corresponding numerical resource type and UNSUPPORTED_VERSION.
Fix some redaction code in RequestChannel that was throwing an exception
when duplicate config resources were present in the request.

Fix a comment in ControllerApis#deleteTopics that no longer reflects
what the code is doing when we don't have ""describe"" permission.

Add function stubs for the KIP-455 reassignment APIs in ControllerApis
and QuorumController.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Arthur <mumrah@gmail.com>",2021-04-15 10:45:24,Colin Patrick McCabe,Mixed
fc405d792de12a50956195827eaf57bbf64444c9,"Minor: Move trogdor out of tools and into its own gradle module (#10539)

Move Trogdor out of tools and into its own gradle module.  This allows us to minimize
the dependencies of the tools module.  We still keep Trogdor in the CLASSPATH
created by kafka-run-class.sh.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-04-15 11:37:15,Shay Elkin,Mixed
f8f1769256de2a1afa92794309ecee475cd80b79,"KIP-145: Add SMTs, HeaderFrom, DropHeaders and InsertHeader (#9549)

These SMTs were originally specified in KIP-145 but never implemented
at the time.

HeaderTo is not included since its original specification doesn't deal with
the fact that there can be >1 header with the same name, but a field can only
have a single value (which could be an array, but not if the headers for
the given name had different schemas).

Reviewers: Chris Egerton <chrise@confluent.io>, Mickael Maison <mickael.maison@gmail.com>",2021-04-16 15:11:25,Tom Bentley,Mixed
035449eb5576bf97df888a85edaaf4428b9a19e5,"KAFKA-12633: Remove deprecated APIs in TopologyTestDriver (#10508)

As well as related test classes.

Reviewers: John Roesler <vvcephei@apache.org>",2021-04-18 10:46:01,Guozhang Wang,Mixed
15c24da888bc0a2582fd84d89fa1b84354fede64,"KAFKA-10847: Delete Time-ordered duplicated records using deleteRange() internally (#10537)

This PR changes the TimeOrderedKeySchema composite key from time-seq-key -> time-key-seq to allow deletion of duplicated time-key records using the RocksDB deleteRange API. It also removes all duplicates when put(key, null) is called. Currently, the put(key, null) was a no-op, which was causing problems because there was no way to delete any keys when duplicates are allowed.

The RocksDB deleteRange(keyFrom, keyTo) deletes a range of keys from keyFrom (inclusive) to keyTo (exclusive). To make keyTo inclusive, I incremented the end key by one when calling the RocksDBAccessor.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2021-04-18 11:18:09,Sergio Peña,Mixed
937054bb5e424d07075a758aad46abea129d0b24,"MINOR: remove `checksumOrNull` and `isValid` from Record (#10498)

1. rewrite the checksum of DumpLogSegments
2. remove checksumOrNull and isValid from Record

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-04-19 21:40:07,Chia-Ping Tsai,Not TDD
0b464419e2e4f28444fca653ae5aa8dd7feae9ba,"KAFKA-12553: Refactor recovery logic to introduce LogLoader (#10478)

In this PR, I have refactored the recovery logic code introducing a new class kafka.log.LogLoader responsible for all activities related with recovery of log segments from disk. With this change, the recovery logic has been moved out of the Log class and into the new LogLoader class.

Advantages:
This refactor has the following advantages over the existing code:

As such, the recovery logic is invoked once only during Log instantiation. Some parts of the recovery logic are fairly independent from the rest of the Log class. By moving the independent private logic to a separate LogLoader class, the existing Log class has become more modular, and the constructor behavior is a lot simpler now. Therefore, this makes the code more maintainable.
This PR takes us a step closer towards the Log layer reactor work (KAFKA-12554). The Log recovery logic reads and writes to LeaderEpochFileCache and ProducerStateManager instances, so as such the logic does not fit very well into the definition of a ""local log"". By extracting it out of the Log class, in the future this will make it much easier to clearly define the separation of concerns between LocalLog and UnifiedLog.

Reviewers: Satish Duggana <satishd@apache.org>, Jun Rao <junrao@gmail.com>",2021-04-20 09:20:40,Kowshik Prakasam,Mixed
d3538ed0ab7a97cf596a366accd0a81518841e5d,"MINOR: Remove unthrown exceptions, fix typo, etc. (#10402)

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Ryanne Dolan <ryannedolan@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2021-04-21 10:40:01,Lee Dongjin,Not TDD
72236f343d644569c8699b2337b0b99b2c8d2752,"KAFKA-12691: Add case where task can be considered idling (#10565)

Reviewers: Matthias J. Sax <matthias@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>",2021-04-21 19:43:18,Walker Carlson,Mixed
2a1b240829ed4c28708df50da281f6f4d5cfe59c,"KAFKA-12586; Add `DescribeTransactions` Admin API (#10483)

This patch contains the `Admin` implementation of the `DescribeTransactions` APIs described in KIP-664: https://cwiki.apache.org/confluence/display/KAFKA/KIP-664%3A+Provide+tooling+to+detect+and+abort+hanging+transactions.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>",2021-04-22 09:34:11,Jason Gustafson,Mixed
105243afb11883cf0dbbe46e3e783b7fa697836a,"KAFKA-10283; Consolidate client-level and consumer-level assignment within ClientState (#9640)

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2021-04-23 10:06:55,high.lee,Mixed
c972ac929edaa32f30dae19714180cdd23addeeb,"KAFKA-5876: Apply UnknownStateStoreException for Interactive Queries (#9821)

KIP-216: IQ should throw different exceptions for different errors, Part 2

Reviewers: Matthias J. Sax <mjsax@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Bruno Cadonna <cadonna@confluent.io>",2021-04-23 12:09:32,Vito Jeng,Mixed
031b7208b3b54ab03c6d93fa617967d2f1f8abe5,"KAFKA-12684: Fix noop set is incorrectly replaced with succeeded set from LeaderElectionCommand (#10558)

Reviewers: David Jacot <djacot@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2021-04-25 21:15:50,wenbingshen,Mixed
d949f1094e2dc270ecbdd7b84aa8470690c697e4,"KAFKA-12344 Support SlidingWindows in the Scala API (#10519)

Support SlidingWindows in the Scala API

Reviewers: Leah Thomas <lthomas@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-04-26 11:38:48,ketulgupta1995,Not TDD
0ea440b2af07fe0d6465f76afc948b28509606b5,"KAFKA-6435: KIP-623 Add internal topics option to streamResetter (#8923)

Allow user to specify subset of internal topics to clean up with application reset tool

Reviewers: Boyang Chen <boyang@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Walker Carlson <wcarlson@confluent.io>",2021-04-27 15:44:53,JoelWee,Mixed
56c7eb68d2cd03c256236779a3e8d53b885f6b17,"KAFKA-12716; Add `Admin` API to abort transactions (#10599)

This patch adds the Admin API to abort transactions from KIP-664: https://cwiki.apache.org/confluence/display/KAFKA/KIP-664%3A+Provide+tooling+to+detect+and+abort+hanging+transactions. The `WriteTxnMarker` API needs to be sent to partition leaders, so we are able to reuse `PartitionLeaderStrategy`, which was introduced when support for `DescribeProducers` was added.

Reviewers: David Jacot <djacot@confluent.io>",2021-04-28 07:58:55,Jason Gustafson,Mixed
ab06aef2b8507768413c9d2525b8d1f6ed68f28c,"KAFKA-12284: increase request timeout to make tests reliable (#10547)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-04-28 23:56:48,Luke Chen,Not TDD
3805f3706f8f3ebba81b80915c9259590525fb05,"KAFKA-12574: KIP-732, Deprecate eos-alpha and replace eos-beta with eos-v2 (#10573)

Deprecates the following 

1. StreamsConfig.EXACTLY_ONCE
2. StreamsConfig.EXACTLY_ONCE_BETA
3. Producer#sendOffsetsToTransaction(Map offsets, String consumerGroupId)

And introduces a new StreamsConfig.EXACTLY_ONCE_V2 config. Additionally, this PR replaces usages of the term ""eos-beta"" throughout the code with the term ""eos-v2""

Reviewers: Matthias J. Sax <mjsax@confluent.io>",2021-04-28 13:22:15,A. Sophie Blee-Goldman,Mixed
bf359f8e2924ee03b34a6f7e7eaf80bef55f9d98,"KAFKA-10847: Fix spurious results on left/outer stream-stream joins (#10462)

Fixes the issue with https://issues.apache.org/jira/browse/KAFKA-10847.

To fix the above problem, the left/outer stream-stream join processor uses a buffer to hold non-joined records for some time until the window closes, so they are not processed if a join is found during the join window time. If the window of a record closes and a join was not found, then this should be emitted and processed by the consequent topology processor.

A new time-ordered window store is used to temporary hold records that do not have a join and keep the records keys ordered by time. The KStreamStreamJoin has a reference to this new store . For every non-joined record seen, the processor writes it to this new state store without processing it. When a joined record is seen, the processor deletes the joined record from the new state store to prevent further processing.

Records that were never joined at the end of the window + grace period are emitted to the next topology processor. I use the stream time to check for the expiry time for determinism results . The KStreamStreamJoin checks for expired records and emit them every time a new record is processed in the join processor.

The new state store is shared with the left and right join nodes. The new store needs to serialize the record keys using a combined key of <joinSide-recordKey>. This key combination helps to delete the records from the other join if a joined record is found. Two new serdes are created for this, KeyAndJoinSideSerde which serializes a boolean value that specifies the side where the key is found, and ValueOrOtherValueSerde that serializes either V1 or V2 based on where the key was found.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2021-04-28 17:57:28,Sergio Peña,Mixed
eaa14a8a688c8a6c23eb8d081dbee9f53fd8dc03,"KAFKA-12730; Avoid duplicate logout if Kerberos login fails (#10611)

From Java 9 onwards, LoginContext#logout() throws an NPE if invoked multiple times due to https://bugs.openjdk.java.net/browse/JDK-8173069. KerberosLogin currently attempts logout followed by login in a background refresh thread. If login fails we retry the same sequence. As a result, a single login failure prevents subsequent re-login. And clients will never be able to authenticate successfully after the first failure, until the process is restarted. The commit checks if logout is necessary before invoking LoginContext#logout(). Also adds a test for this case.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2021-04-29 14:32:50,Rajini Sivaram,Not TDD
a855f6ac37149d6908499c68df46671a2754d21a,"KAFKA-12265; Move the BatchAccumulator in KafkaRaftClient to LeaderState (#10480)

The KafkaRaftClient has a field for the BatchAccumulator that is only used and set when it is the leader. In other cases, leader specific information was stored in LeaderState. In a recent change EpochState, which LeaderState implements, was changed to be a Closable. QuorumState makes sure to always close the previous state before transitioning to the next state. This redesign was used to move the BatchAccumulator to the LeaderState and simplify some of the handling in KafkaRaftClient.

Reviewers: José Armando García Sancio <jsancio@gmail.com>, Jason Gustafson <jason@confluent.io>",2021-04-29 09:25:21,Ryan,Mixed
8d38189eddd66d8ae53749f15bfff557f102a936,"MINOR: clean up some replication code (#10564)

Centralize leader and ISR changes in generateLeaderAndIsrUpdates.
Consolidate handleNodeDeactivated and handleNodeActivated into this
function.

Rename BrokersToIsrs#noLeaderIterator to BrokersToIsrs#partitionsWithNoLeader.
Create BrokersToIsrs#partitionsLedByBroker, BrokersToIsrs#partitionsWithBrokerInIsr

In ReplicationControlManagerTest, createTestTopic should be a member
function of ReplicationControlTestContext.  It should invoke
ReplicationControlTestContext#replay so that records are applied to all
parts of the test context.

Reviewers: Jun Rao <junrao@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2021-04-29 11:20:30,Colin Patrick McCabe,Mixed
9dbf2226cdae4a30e44340a552613446c5053d87,"MINOR: clean up some remaining locking stuff in StateDirectory (#10608)

Minor followup to #10342 that I noticed while working on the NamedTopology stuff. Cleans up a few things:

We no longer need locking for the global state directory either, since it's contained within the top-level state directory lock. Definitely less critical than the task directory locking, since it's less vulnerable to IOExceptions given that it's just locked and unlocked once during the application lifetime, but nice to have nonetheless
Clears out misc. usages of the LOCK_FILE_NAME that no longer apply. This has the awesome side effect of finally being able to actually delete obsolete task directories, whereas previously we had to leave behind the empty directory due to a ridiculous Windows bug (though I'm sure they would claim ""it's not a bug it's a feature"" 😉 )
Lazily delete old-and-now-unused lock files in the StateDirectory#taskDirIsEmpty method to clean up the state directory for applications that upgraded from an older version that still used task locking

Reviewers: Walker Carlson <wcarlson@confluent.io>",2021-04-29 12:30:48,A. Sophie Blee-Goldman,Mixed
e454becb33faac0851b7d145452992f183cbff76,"KAFKA-12396: added null check for state stores key (#10548)

Reviewers: Bruno Cadonna <bruno@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2021-04-29 19:47:26,Valery Kokorev,Mixed
16b2ce7da72e60d88b6ca8a3eff853a28a1458f9,"KAFKA-12648: basic skeleton API for NamedTopology (#10615)

Just the API for NamedTopology.

Reviewers: Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",2021-04-30 22:46:00,A. Sophie Blee-Goldman,Not TDD
1f4207c7c187b201fa3fc47f5752b7ee3df681bd,"MINOR: system test spelling/pydoc/dead code fixes (#10604)

Reviewers: Kamal Chandraprakash <kamal@nmsworks.co.in>, Chia-Ping Tsai <chia7712@gmail.com>",2021-05-01 23:22:46,Ron Dagostino,Not TDD
3ec6317ee67de0774a6c8c2b48faf0b38b8643d9,"KAFKA-12683: Remove deprecated UsePreviousTimeOnInvalidTimestamp (#10557)

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-05-01 08:31:41,Guozhang Wang,Mixed
bee3cf7d98645af5460f3483acf81cf1c60de08e,"MINOR: Remove unused Utils.delete (#10622)

Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-05-01 08:32:14,Guozhang Wang,Not TDD
6203bf8b94c7c340671c1729f4a8e4fcc302605e,"KAFKA-12154; Raft Snapshot Loading API (#10085)

Implement Raft Snapshot loading API.

1. Adds a new method `handleSnapshot` to `raft.Listener` which is called whenever the `RaftClient` determines that the `Listener` needs to load a new snapshot before reading the log. This happens when the `Listener`'s next offset is less than the log start offset also known as the earliest snapshot.

2.  Adds a new type `SnapshotReader<T>` which provides a `Iterator<Batch<T>>` interface and de-serializes records in the `RawSnapshotReader` into `T`s

3.  Adds a new type `RecordsIterator<T>` that implements an `Iterator<Batch<T>>` by scanning a `Records` object and deserializes the batches and records into `Batch<T>`. This type is used by both `SnapshotReader<T>` and `RecordsBatchReader<T>` internally to implement the `Iterator` interface that they expose. 

4. Changes the `MockLog` implementation to read one or two batches at a time. The previous implementation always read from the given offset to the high-watermark. This made it impossible to test interesting snapshot loading scenarios.

5. Removed `throws IOException` from some methods. Some of types were inconsistently throwing `IOException` in some cases and throwing `RuntimeException(..., new IOException(...))` in others. This PR improves the consistent by wrapping `IOException` in `RuntimeException` in a few more places and replacing `Closeable` with `AutoCloseable`.

6. Updated the Kafka Raft simulation test to take into account snapshot. `ReplicatedCounter` was updated to generate snapshot after 10 records get committed. This means that the `ConsistentCommittedData` validation was extended to take snapshots into account. Also added a new invariant to ensure that the log start offset is consistently set with the earliest snapshot.

Reviewers: dengziming <swzmdeng@163.com>, David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",2021-05-01 10:05:45,José Armando García Sancio,Mixed
e73731d8486735c882a721b92df450eb4be59f15,"KAFKA-12661 ConfigEntry#equal does not compare other fields when value is NOT null (#10446)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-05-02 13:07:08,Chia-Ping Tsai,Mixed
325cb8853b7682bfe065a96d8b7808f0ef6cb89e,"MINOR: Clean up some redundant code from ReplicaManager (#10623)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-05-03 00:44:32,wenbingshen,Mixed
816f5c3b86ce94b1872f0d9d4bac9fdaa37b390f,"KAFKA-5876: KIP-216 Part 3, Apply StreamsNotStartedException for Interactive Queries (#10597)

KIP-216 Part 3: Throw StreamsNotStartedException if KafkaStreams state is CREATED

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-05-03 13:53:35,Vito Jeng,Mixed
62221edaff412ca18cf32d81e82fd1f68752eaf6,"KAFKA-10847: Add internal flag to disable KAFKA-10847 fix (#10612)

Adds an internal flag that can be used to disable the fixes in KAFKA-10847. It defaults to true if the flag is not set or has an invalid boolean value.

The flag is named __enable.kstreams.outer.join.spurious.results.fix__. This flag is considered internal only. It is a temporary flag that will be used to help users to disable the join fixes while they do a transition from the previous semantics of left/outer joins. The flag may be removed in future releases.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2021-05-03 14:10:05,Sergio Peña,Mixed
45f24c41954e5bfeeec5b7050ee8fb873dd8104a,"KAFKA-12450: Remove deprecated methods from ReadOnlyWindowStore (#10294)

Implement first part of https://cwiki.apache.org/confluence/display/KAFKA/KIP-667%3A+Remove+deprecated+methods+from+ReadOnlyWindowStore.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2021-05-04 09:23:30,Jorge Esteban Quilcate Otoya,Mixed
a1367f57f52e7c5bdb2fadf14f3b124dd7148213,"KAFKA-12429: Added serdes for the default implementation of RLMM based on an internal topic as storage. (#10271)

KAFKA-12429: Added serdes for the default implementation of RLMM based on an internal topic as storage. This topic will receive events of RemoteLogSegmentMetadata, RemoteLogSegmentUpdate, and RemotePartitionDeleteMetadata. These events are serialized into Kafka protocol message format.
Added tests for all the event types for that topic.

This is part of the tiered storaqe implementation KIP-405.

Reivewers:  Kowshik Prakasam <kprakasam@confluent.io>, Jun Rao <junrao@gmail.com>",2021-05-05 07:48:52,Satish Duggana,Mixed
d915ce58d2adcfd6113f961ecbf337770dbe760b,"KAFKA-10847: Set shared outer store to an in-memory store when in-memory stores are supplied (#10613)

When users supply in-memory stores for left/outer joins, then the internal shared outer store must be switch to in-memory store too. This will allow users who want to keep all stores in memory to continue doing so.

Added unit tests to validate topology and left/outer joins work fine with an in-memory shared store.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2021-05-05 10:21:43,Sergio Peña,Not TDD
9ba583f6d6677a48685b37eb4b2bef2a711c94b7,"KAFKA-12252 and KAFKA-12262: Fix session key rotation when leadership changes (#10014)

Author: Chris Egerton <chrise@confluent.io>
Reviewers: Greg Harris <gregh@confluent.io>, Randall Hauch <rhauch@gmail.com>",2021-05-05 16:11:15,Chris Egerton,Mixed
6a5992a814364a41ce7ad34aa6b27cc44d0eb78c,"KAFKA-8531: Change default replication factor config (#10532)

Implements KIP-733

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>",2021-05-05 16:16:06,Matthias J. Sax,Mixed
79225504ed920e63b2a31a968b7d50f88af5ada2,"KAFKA-12464: enhance constrained sticky Assign algorithm (#10509)

1. Make code simpler and cleaner
2. After the PR: the testLargeAssignmentAndGroupWithUniformSubscription (1 million partitions) will run from ~2600 ms down to ~1400 ms, improves 46% of performance, almost 2x faster!!

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Guozhang Wang <guozhang@confluent.io>",2021-05-05 18:44:59,Luke Chen,Mixed
90fc875e24121fd0a39143983ce9eb8a93849d7e,"KAFKA-8897: Upgrade RocksDB to 6.19.3 (#10568)

This PR upgrades RocksDB to 6.19.3. After the upgrade the Gradle build exited with code 134 due to SIGABRT signals (""Pure virtual function called!"") coming from the C++ part of RocksDB. This error was caused by RocksDB state stores not properly closed in Streams' code. This PR adds the missing closings and updates the RocksDB option adapter.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Guozhang Wang <wangguoz@gmail.com>",2021-05-06 15:29:26,Bruno Cadonna,Mixed
45d7440c1577b838d4584d3860e5c4d691446f3f,"KAFKA-10847: Set StreamsConfig on InternalTopologyDriver before writing topology (#10640)

Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2021-05-06 17:27:23,Sergio Peña,Mixed
fae0784ce32a448a0d8c69e0b55f957290df1b5a,"KAFKA-5876: KIP-216 Part 4, Apply InvalidStateStorePartitionException for Interactive Queries (#10657)

KIP-216, part 4 - apply InvalidStateStorePartitionException

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-05-10 17:29:58,Vito Jeng,Mixed
7ef38794291fc5d2317a3c3e33b463e2525b12a9,"KAFKA-12758 Added `server-common` module to have server side common classes.  (#10638)

Added server-common module to have server side common classes. Moved ApiMessageAndVersion, RecordSerde, AbstractApiMessageSerde, and BytesApiMessageSerde to server-common module.

Reivewers:  Kowshik Prakasam <kprakasam@confluent.io>, Jun Rao <junrao@gmail.com>",2021-05-11 09:58:28,Satish Duggana,Mixed
4b2736570c9d5f4b6e501ab8cd5efe696a5142b7,"KAFKA-12648: MINOR - Add TopologyMetadata.Subtopology class for subtopology metadata (#10676)

Introduce a Subtopology class to wrap the topicGroupId and namedTopology metadata.

Reviewers: Walker Carlson <wcarlson@confluent.io>",2021-05-13 11:25:18,A. Sophie Blee-Goldman,Mixed
e69571aecc75d4b3d37c8b43d39cae83e250bedb,"KAFKA-12697: Add Global Topic and Partition count metrics to the Quorum Controller (#10679)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-05-13 12:08:18,Ryan Dielhenn,Mixed
6d1ae8bc007ffa1f3b3a9f949db6a99820dab75c,"KAFKA-8326: Introduce List Serde (#6592)

Introduce List serde for primitive types or custom serdes with a serializer and a deserializer according to KIP-466

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Matthias J. Sax <mjsax@conflunet.io>, John Roesler <roesler@confluent.io>, Michael Noll <michael@confluent.io>",2021-05-13 15:54:00,Daniyar Yeralin,Mixed
4153e754f1a4ebbd9a3d10be8bf75a7057c82f1d,"MINOR: prevent cleanup() from being called while Streams is still shutting down (#10666)

Currently KafkaStreams#cleanUp only throw an IllegalStateException if the state is RUNNING or REBALANCING, however the application could be in the process of shutting down in which case StreamThreads may still be running. We should also throw if the state is PENDING_ERROR or PENDING_SHUTDOWN

Reviewers: Walker Carlson <wcarlson@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2021-05-13 16:16:35,A. Sophie Blee-Goldman,Mixed
f2785f3c4f83bbc3caef48993018896bf73224df,"KAFKA-12754: Improve endOffsets for TaskMetadata (#10634)

Improve endOffsets for TaskMetadata by updating immediately after polling a new batch

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-05-14 12:17:31,Walker Carlson,Mixed
f20fdbd839ea1275fa4b26e9eb3c49ef5d9af1ca,"KAFKA-12778: Fix QuorumController request timeouts and electLeaders (#10688)

The QuorumController should honor the timeout for RPC requests
which feature a timeout. For electLeaders, attempt to trigger a leader
election for all partitions when the request specifies null for the topics
argument.

Reviewers: David Arthur <mumrah@gmail.com>",2021-05-14 12:44:16,Colin Patrick McCabe,Mixed
b9acc492a568ba869a8abdee0fa965f5f58c4de6,"KAFKA-12313: KIP-725: Streamlining configs for Windowed Deserialisers (#10542)

This PR aims to streamline the configurations for WindowedDeserialisers as described in KIP-725. It deprecates default.windowed.key.serde.inner and default.windowed.value.serde.inner configs in StreamConfig and adds windowed.inner.class.serde. 

Reviewers: Anna Sophie Blee-Goldman<ableegoldman@apache.org>",2021-05-17 10:17:31,vamossagar12,Mixed
0b9a7bd75ed76d0def67ef96da1cd8cc2f902943,"KAFKA-12792: Fix metrics bug and introduce TimelineInteger (#10707)

Introduce a TimelineInteger class which represents a single integer
value which can be changed while maintaining snapshot consistency. Fix a
case where a metric value would be corrupted after a snapshot restore.

Reviewers: David Arthur <mumrah@gmail.com>",2021-05-17 10:21:26,Colin Patrick McCabe,Mixed
cc6f4c49a9dc241b1b63ed7cf6ec982b05c541d4,"KAFKA-12574: remove internal Producer config and auto downgrade logic  (#10675)

Minor followup to #10573. Removes this internal Producer config which was only ever used to avoid a very minor amount of work to downgrade the consumer group metadata in the txn commit request in Kafka Streams

Reviewers: Ismael Juma <ismael@juma.me.uk>, Matthias J. Sax <mjsax@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2021-05-17 10:25:35,A. Sophie Blee-Goldman,Mixed
55b24ce9d68153effe8c303d03c7ac1a8a534eba,"MINOR: fix system test TestSecurityRollingUpgrade (#10694)

Ensure security protocol and sasl mechanism are updated in the cached SecurityConfig during rolling system tests. Also explicitly indicate which SASL mechanisms we wish to expose during the tests.

Reviewers: David Arthur <mumrah@gmail.com>",2021-05-17 13:46:44,Ron Dagostino,Not TDD
9eb9b16d573ae7a1dc235ad4eb036f88b98ad005,"KAFKA-12751: Reset AlterIsr in-flight state for duplicate update requests (#10633)

Reviewers: David Arthur <david.arthur@confluent.io>",2021-05-17 19:31:39,Rajini Sivaram,Mixed
9e5b77fb9687c319dd2b188d9669ca2bd01e9bb8,"KAFKA-12788: improve KRaft replica placement (#10494)

Implement a striped replica placement algorithm for KRaft. This also
means implementing rack awareness.  Previously, KRraft just chose
replicas randomly in a non-rack-aware fashion.  Also, allow replicas to
be placed on fenced brokers if there are no other choices.  This was
specified in KIP-631 but previously not implemented.

Reviewers: Jun Rao <junrao@gmail.com>",2021-05-17 16:49:47,Colin Patrick McCabe,Mixed
aefe0e4d8cba8585f74fb7c50761951e663bd8ef,"KAFKA-12686 AlterIsr and LeaderAndIsr race condition (#10561)

Remove the clearPending method from AlterIsrManager

Reviewers: Colin P. Mccabe <cmccabe@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2021-05-18 09:56:37,David Arthur,Mixed
924c870fb102041363acc00227f8dba152dc830f,"KAFKA-12543: Change RawSnapshotReader ownership model (#10431)

Kafka networking layer doesn't close FileRecords and assumes that they are already open when sending them over a channel. To support this pattern this commit changes the ownership model for FileRawSnapshotReader so that they are owned by KafkaMetadataLog.

Reviewers: dengziming <swzmdeng@163.com>, David Arthur <mumrah@gmail.com>, Jun Rao <junrao@gmail.com>",2021-05-18 14:14:17,José Armando García Sancio,Mixed
3a42baa260d4e39b82843d5458b56c1c4026abf7,"HOTFIX: undo renaming of public part of Subtopology API (#10713)

In #10676 we renamed the internal Subtopology class that implemented the TopologyDescription.Subtopology interface. By mistake, we also renamed the interface itself, which is a public API. This wasn't really the intended point of that PR, so rather than do a retroactive KIP, let's just reverse the renaming.

Reviewers: Walker Carlson <wcarlson@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2021-05-18 12:59:20,A. Sophie Blee-Goldman,Not TDD
5b0c58ed53c420e93957369516f34346580dac95,"MINOR: Support using the ZK authorizer with KRaft (#10550)

This patch adds support for running the ZooKeeper-based
kafka.security.authorizer.AclAuthorizer with KRaft clusters. Set the
authorizer.class.name config as well as the zookeeper.connect config while also
setting the typical KRaft configs (node.id, process.roles, etc.), and the
cluster will use KRaft for metadata and ZooKeeper for ACL storage. A system
test that exercises the authorizer is included.

This patch also changes ""Raft"" to ""KRaft"" in several system test files. It also
fixes a bug where system test admin clients were unable to connect to a cluster
with broker credentials via the SSL security protocol when the broker was using
that for inter-broker communication and SASL for client communication.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",2021-05-19 10:32:56,Ron Dagostino,Mixed
bb48cf33b3d6968fac392824edc331ccd2a1b89a,"MINOR: add ConfigUtils method for printing configurations (#10714)

Reviewers: Luke Chen <showuon@gmail.com>, David Arthur <mumrah@gmail.com>",2021-05-19 11:03:49,Colin Patrick McCabe,Mixed
476eccb968322879b1843dfa837b63ce386d192c,"KAFKA-12815: Preserve context for KTable.transformValues when getting value from upstream state store (#10720)

Reviewers: Victoria Xia <victoria.xia@confluent.io>, John Roesler <john@confluent.io>",2021-05-19 14:58:46,Matthias J. Sax,Mixed
0af37730fc7b93cbed7329cc47b9d24295581e81,"KAFKA-12813: Remove deprecated schedule method in ProcessorContext (#10730)

Removes methods deprecated via KIP-358.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2021-05-19 16:03:01,Josep Prat,Mixed
e23ede1ece67fc54d5be49493cbe1d96d78fc4f1,"KAFKA-12809: Remove deprecated methods of Stores factory (#10729)

Removes methods deprecated via KIP-319 and KIP-358.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2021-05-19 16:07:35,Josep Prat,Mixed
5d4f9f917c8dc356a2d922980ba8101e0f2e7093,"MINOR: Remove unused maxProducerIdExpirationMs parameter in Log constructor (#10723)

Reviewers: Satish Duggana <satishd@apache.org>, Chia-Ping Tsai <chia7712@gmail.com>",2021-05-20 23:06:09,Kowshik Prakasam,Not TDD
b56d9e4416bba3bc54d2e167298c370cbbe7edbd,"KAFKA-12779: KIP-740, Clean up public API in TaskId and fix TaskMetadata#taskId() (#10735)

As described in KIP-740, we clean up the public TaskId class and introduce new APIs to return it from TaskMetadata

Reviewers: Guozhang Wang <guozhang@confluent.io>",2021-05-20 15:01:23,A. Sophie Blee-Goldman,Mixed
f50f13d781fa60b7915b687e075e523aa9ba5bfc,"KAFKA-12342: Remove MetaLogShim and use RaftClient directly (#10705)

This patch removes the temporary shim layer we added to bridge the interface
differences between MetaLogManager and RaftClient. Instead, we now use the
RaftClient directly from the metadata module.  This also means that the
metadata gradle module now depends on raft, rather than the other way around.
Finally, this PR also consolidates the handleResign and handleNewLeader APIs
into a single handleLeaderChange API.

Co-authored-by: Jason Gustafson <jason@confluent.io>",2021-05-20 15:39:46,José Armando García Sancio,Mixed
80ec8fbcd560a7068cfa7baea72846f0ffd98b72,"KAFKA-12697: Add OfflinePartitionCount and PreferredReplicaImbalanceCount metrics to Quorum Controller (#10572)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-05-20 16:28:32,Ryan Dielhenn,Mixed
0c707b1fccd0b21a3ead765d61f376f338c69bd0,"KAFKA-12522: Cast SMT should allow null value records to pass through (#10375)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Lee Dongjin <dongjin@apache.org>, Chris Egerton  <fearthecellos@gmail.com>",2021-05-21 11:34:45,Daniel,Mixed
b46e17b1d7f58f2af8e3c634b3c0ba8c97a16d80,"KAFKA-12808: Remove Deprecated Methods under StreamsMetrics (#10724)

Removal of methods already deprecated since 2.5.
Adapt test to use the new alternative method.

Reviewers: Bruno Cadonna <cadonna@apache.org>",2021-05-21 12:37:35,Josep Prat,Mixed
aa25176e77c7643d8c7ca5c6ded797d9fe315aee,"MINOR: Kafka Streams code samples formating unification (#10651)

Code samples are now unified and correctly formatted.
Samples under Streams use consistently the prism library.

Reviewers: Bruno Cadonna <cadonna@apache.org>",2021-05-21 17:27:42,Josep Prat,Mixed
72d108274c98dca44514007254552481c731c958,"KAFKA-12620 Allocate producer ids on the controller (#10504)

Introduce new AllocateProducerIds RPC and IBP 3.0-IV0 as part of KIP-730.

This change adds a new AllocateProducerIds RPC which is used by the broker to request a block of 
producer IDs from the controller. The new IBP added will determine if the broker should talk directly to 
ZooKeeper (IBP < 3.0) or it if should use the new RPC to talk to the controller (IBP >= 3.0).

Per-broker property overrides for ClusterTests were also added (in order to test mixed IBPs in a cluster)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-05-21 15:58:49,David Arthur,Mixed
ae8b7845374b6bb01e1ae9ca27f6ab967561e011,"KAFKA-12499: add transaction timeout verification (#10482)

This PR tries to add the check for transaction timeout for a comparison against commit interval of streams. If transaction timeout is smaller than commit interval, stream should crash and inform user to update their commit interval to be larger or equal to the given transaction timeout, or vise versa.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, A. Sophie Blee-Goldman <sophie@confluent.io>",2021-05-21 15:05:39,Boyang Chen,Mixed
c92e62a67fc8efe51550492592039986994c81fb,"MINOR: Add log identifier/prefix printing in Log layer static functions (#10742)

When #10478 was merged, we accidentally lost the identifier/prefix string that we used to previously log to stderr from some of the functions in the Log class. In this PR, I have reinstated the identifier/prefix logging in these functions, so that the debuggability is restored.

Reviewers: Luke Chen <showuon@gmail.com>, Cong Ding <cong@ccding.com>, Jun Rao <junrao@gmail.com>",2021-05-24 10:39:46,Kowshik Prakasam,Mixed
e4f2f6f6e82cafbdea785d53521b96fe062e172d,"KAFKA-12260: Avoid hitting NPE for partitionsFor (#10017)

Remove null pointer from the public partitionsFor API.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-05-25 23:59:30,Boyang Chen,Mixed
38e8391a7709b53ef895825368a87eae72e1e346,"MINOR: Log more information when producer snapshot is written (#10757)

This patch logs more information when a producer snapshot is written to the disk.

Reviewers: Ismael Juma <mlists@juma.me.uk>, Lucas Bradstreet <lucas@confluent.io>",2021-05-26 09:21:21,David Jacot,Mixed
bbe170af701609180387ad4abbfaa2712936266d,"MINOR: deprecate TaskMetadata constructor and add KIP-740 notes to upgrade guide (#10755)

Quick followup to KIP-740 to actually deprecate this constructor, and update the upgrade guide with what we changed in KIP-740. I also noticed the TaskId#parse method had been modified previously, and should be re-added to the public TaskId class. It had no tests, so now it does

Reviewers: Matthias J. Sax <mjsax@confluent.io>, Luke Chen <showuon@gmail.com>",2021-05-26 10:35:12,A. Sophie Blee-Goldman,Not TDD
a02b19cb77084a573a25be1b75fc195b9a9c1f9b,"KAFKA-12796: Removal of deprecated classes under streams-scala (#10710)

Removes previously deprecated methods in older KIPs

Reviewers: Bruno Cadonna <cadonna@apache.org>",2021-05-27 11:30:15,Josep Prat,Mixed
3fb836f507d35e2a1ab39df57edca671ffc66073,"MINOR: Improve Log layer segment iteration logic and few other areas (#10684)

In Log.collectAbortedTransactions() I've restored a previously used logic, such that it would handle the case where the starting segment could be null. This was the case previously, but the PR #10401 accidentally changed the behavior causing the code to assume that the starting segment won't be null.

In Log.rebuildProducerState() I've removed usage of the allSegments local variable. The logic looks a bit simpler after I removed it.

I've introduced a new LogSegments.higherSegments() API. This is now used to make the logic a bit more readable in Log. collectAbortedTransactions() and Log.deletableSegments() APIs.

I've removed the unnecessary use of java.lang.Long in LogSegments class' segments map definition.

I've converted a few LogSegments API from public to private, as they need not be public.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Cong Ding <cong@ccding.com>, Jun Rao <junrao@gmail.com>",2021-05-27 08:56:00,Kowshik Prakasam,Mixed
6659777b820f32483d1e96e26831cb87f80a8576,"MINOR: Don't ignore deletion of partition metadata file and log topic id clean-ups (#10761)

Log if deletion fails and don't expose log topic id for mutability outside of `assignTopicId()`.

Also remove an unnecessary parameter in `PartitionTest`.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Justine Olshan <jolshan@confluent.io>",2021-05-27 13:50:51,Ismael Juma,Mixed
f207bac20cf19e841d3ee8dbcba03b1c30d88836,"KAFKA-8410: KTableProcessor migration groundwork (#10744)

* Lay the groundwork for migrating KTable Processors to the new PAPI.
* Migrate the KTableFilter processor to prove that the groundwork works.

This is an effort to help break up #10507 into multiple PRs.

Reviewers: Boyang Chen <boyang@apache.org>",2021-05-28 14:59:35,John Roesler,Mixed
6b005b2b4eece81a5500fb0080ef5354b4240681,"MINOR: Reduce allocations in requests via buffer caching (#9229)

Use a caching `BufferSupplier` per request handler thread so that
decompression buffers are cached if supported by the underlying
`CompressionType`. This achieves a similar outcome as #9220, but
with less contention.

We introduce a `RequestLocal` class to make it easier to introduce
new request scoped stateful instances (one example we discussed
previously was an `ActionQueue` that could be used to avoid
some of the complex group coordinator locking).

This is a small win for zstd (no synchronization or soft references) and
a more significant win for lz4. In particular, it reduces allocations
significantly when the number of partitions is high. The decompression
buffer size is typically 64 KB, so a produce request with 1000 partitions
results in 64 MB of allocations even if each produce batch is small (likely,
when there are so many partitions).

I did a quick producer perf local test with 5000 partitions, 1 KB record
size,
1 broker, lz4 and ~0.5 for the producer compression rate metric:

Before this change:
> 20000000 records sent, 346314.349535 records/sec (330.27 MB/sec),
148.33 ms avg latency, 2267.00 ms max latency, 115 ms 50th, 383 ms 95th, 777 ms 99th, 1514 ms 99.9th.

After this change:
> 20000000 records sent, 431956.113259 records/sec (411.95 MB/sec),
117.79 ms avg latency, 1219.00 ms max latency, 99 ms 50th, 295 ms 95th, 440 ms 99th, 662 ms 99.9th.

That's a 25% throughput improvement and p999 latency was reduced to
under half (in this test).

Default arguments will be removed in a subsequent PR.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-05-30 12:16:36,Ismael Juma,Mixed
cfe642edee80977173279f4a41e23aa822b9d19f,"KAFKA-12519: Remove built-in Streams metrics for versions 0.10.0-2.4 (#10765)

As specified in KIP-743, this PR removes the built-in metrics
in Streams that are superseded by the refactoring proposed in KIP-444.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Luke Chen <showuon@gmail.com>",2021-06-01 14:05:08,Bruno Cadonna,Mixed
a842e0e0847aef4860c59a4445e022d185833f26,"KAFKA-12866: Avoid root access to Zookeeper (#10795)

The broker shouldn't assume create access to the chroot. There are
deployement scenarios where the chroot is already created is the only
znode which the broker can access.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Ron Dagostino <rdagostino@confluent.io>",2021-06-01 19:10:07,Igor Soarez,Not TDD
21532a745d47a6851c11f7b4d8234d6f3025f264,"KAFKA-12596: remove --zookeeper option from topic command (#10457)

Also:
* Remove `ZookeeperTopicService`
* Remove `TopicCommandWithZKClientTest`
* Fix a topic create validation bug
* Adjust existing tests

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-06-01 06:59:00,Luke Chen,Mixed
2d7a4ed3352a927d7d2a13662b585eaef6efdf1c,"KAFKA-12709; Add Admin API for `ListTransactions` (#10616)

This patch adds `Admin` support for the `listTransactions` API, which was added by [KIP-664](https://cwiki.apache.org/confluence/display/KAFKA/KIP-664%3A+Provide+tooling+to+detect+and+abort+hanging+transactions). Similar to `listConsumerGroups`, the new `listTransactions` API is intended to be sent to all brokers. 

Reviewers: David Jacot <djacot@confluent.io>",2021-06-01 17:58:47,Jason Gustafson,Mixed
6db51e466301408e59a055dbadf614612e492fb2,"KAFKA-12675: improve the sticky general assignor scalability and performance (#10552)

I did code refactor/optimization, keep the same algorithm in this PR.

Originally, With this setting:
topicCount = 50;
partitionCount = 800;
consumerCount = 800;
We complete in 10 seconds, after my code refactor, the time down to 100~200 ms

With the 1 million partitions setting:
topicCount = 500;
partitionCount = 2000;
consumerCount = 2000;
No OutOfMemory will be thrown anymore. The time will take 4~5 seconds.

Reviewers: Vahid Hashemian <vahid.hashemian@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2021-06-02 15:01:11,Luke Chen,Mixed
ccec9b0c0dbcc63e733eacd310d3e3ebc4b87a44,"KAFKA-12864: Move KafkaEventQueue into server-common. #10787 (#10787)

Since KafkaEventQueue is a generic data structure not specific to metadata, move it
into the server-common module.

Reviewers: Ismael Juma <ismael@juma.me.uk>, David Arthur <mumrah@gmail.com>",2021-06-02 16:10:59,Colin Patrick McCabe,Mixed
93dca8ebd973f7a49280aa216137f685c00030e3,"KAFKA-12749: Changelog topic config on suppressed KTable lost (#10664)

Refactored logConfig to be passed appropriately when using shutDownWhenFull or emitEarlyWhenFull. Removed the constructor that doesn't accept a logConfig parameter so you're forced to specify it explicitly, whether it's empty/unspecified or not.

Co-authored-by: Bruno Cadonna <cadonna@apache.org>

Reviewers: Walker Carlson <wcarlson@confluent.io>, Bruno Cadonna <cadonna@apache.org>",2021-06-03 20:00:19,Viswanathan Ranganathan,Mixed
e97cff2702b6ba836c7925caa36ab18066a7c95d,"KAFKA-12620 Allocate Producer IDs in KRaft controller (#10752)

This is part 2 of KIP-730. Part 1 was in #10504.

This PR adds QuorumController support for handling AllocateProducerIDs requests
and managing the state of the latest producer ID block in the controller by committing
this state to the metadata log.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-06-03 16:23:32,David Arthur,Mixed
ccde334ca9314e28b16b931293db0eb7822fde4f,"KAFKA-12597: Remove deprecated --zookeeper option in ReassignPartitionsCommand (#10471)

Also remove zookeeper dependent methods and tests.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-06-03 23:31:29,Luke Chen,Not TDD
c72ce005e70a965dee25d341e5be8fceb1477b37,"KAFKA-10614: Ensure group state (un)load is executed in the right order (#9441)

Co-authored-by: Jason Gustafson<jason@confluent.io>
Reviewers: Jason Gustafson<jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2021-06-07 14:19:48,Tom Bentley,Mixed
51665b9f39f0df2f474de21ccc31af0b3b1811ae,"KAFKA-12338; Remove unused `MetadataParser` (#10793)

`MetadataParser` is a duplication of `MetadataRecordSerde` and it's not used in any code, so we can remove it. It did, however, have some useful validations which have been moved into `MetadataRecordSerde`.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-06-07 10:52:16,dengziming,Mixed
43db8ac86ac3e609d9e2a993444b8f1b22f7693b,"KAFKA-12897: KRaft multi-partition placement on single broker (#10823)

#10494 introduced a bug in the KRaft controller where the controller will loop forever in StripedReplicaPlacer trying to identify the racks on which to place partition replicas if there is a single unfenced broker in the cluster and the number of requested partitions in a CREATE_TOPICS request is greater than 1.

This patch refactors out some argument sanity checks and invokes those checks in both RackList and StripedReplicaPlacer, and it adds tests for this as well as the single broker placement issue.

Reviewers: Jun Rao <junrao@gmail.com>",2021-06-07 14:13:06,Ron Dagostino,Mixed
48379bd6e5075fc73449e235f1b527114f5a430c,"KAFKA-12648: Pt. 1 - Add NamedTopology to protocol and state directory structure (#10609)

This PR includes adding the NamedTopology to the Subscription/AssignmentInfo, and to the StateDirectory so it can place NamedTopology tasks within the hierarchical structure with task directories under the NamedTopology parent dir.

Reviewers: Walker Carlson <wcarlson@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2021-06-07 15:38:12,A. Sophie Blee-Goldman,Mixed
b5f7ce8b7b62b76951f9c5d6732b69e600b7ab15,"KAFKA-12815: Update JavaDocs of ValueTransformerWithKey (#10731)

Reviewers: Luke Chen <howuon@gmail.com>, John Roesler <john@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2021-06-07 22:04:33,Matthias J. Sax,Mixed
1dadb6db0c6848a8a1d2eee1497f9b79b6e04e0e,"MINOR: Only log overridden topic configs during topic creation (#10828)

It's quite verbose to include all configs for every partition loaded/created.
Also make sure to redact sensitive and unknown config values.

Unit test included.

Reviewers: David Jacot <djacot@confluent.io>, Kowshik Prakasam <kprakasam@confluent.io>, Luke Chen <showuon@gmail.com>",2021-06-08 06:39:31,Ismael Juma,Mixed
a75b5c635b3551d23da3fa66268b27c4801aef6e,"KAFKA-12874; Increase default consumer session timeout to 45s (#10803)

This patch increases the default consumer session timeout to 45s as documented in KIP-735: https://cwiki.apache.org/confluence/display/KAFKA/KIP-735%3A+Increase+default+consumer+session+timeout.

Reviewers: Luke Chen <showuon@gmail.com>, David Arthur <mumrah@gmail.com>, David Jacot <djacot@confluent.io>",2021-06-09 15:09:31,Jason Gustafson,Not TDD
953ec9810099d6e5f41541de46c0ceebf4372790,"MINOR: Improve Kafka Streams JavaDocs with regard to record metadata (#10810)

Reviewers: Luke Chen <howuon@gmail.com>, Josep Prat <josep.prat@aiven.io>, John Roesler <john@confluent.io>",2021-06-09 22:51:36,Matthias J. Sax,Mixed
8b6752d1839823b211b25c16bb1c0dc9abb13e17,"KAFKA-12905: Replace EasyMock and PowerMock with Mockito for NamedCacheMetricsTest (#10835)

* Development of EasyMock and PowerMock has stagnated while Mockito continues to be actively developed. With the new Java cadence, it's a problem to depend on libraries that do bytecode generation and are not actively maintained. In addition, Mockito is also easier to use.KAFKA-7438

Reviewers: Ismael Juma <ismael@juma.me.uk>, Chia-Ping Tsai <chia7712@gmail.com>, Bruno Cadonna <cadonna@apache.org>",2021-06-10 12:18:19,wycccccc,Not TDD
d4961038649b4f498b0fdd667ef4ad2a27f09605,"MINOR: Small optimizations and removal of unused code in Streams (#10856)

Remove unused methods in internal classes
Mark fields that can be final as final
Remove unneeded generic type annotation
Convert single use fields to local final variables
Use method reference in lambdas when it's more readable

Reviewers: Matthias J. Sax <mjsax@apache.org>, Bruno Cadonna <cadonna@apache.org>",2021-06-10 16:51:31,Josep Prat,Not TDD
7cd09b6a14f51aeef9e701fe24adf9f4f07170b0,"KAFKA-10585: Kafka Streams should clean up the state store directory from cleanup (#9414)

1. Update StateDirectory#clean
  - Delete application's statestore directory in cleanup process if it is empty.
2. Add Tests
  - StateDirectoryTest#shouldDeleteAppDirWhenCleanUpIfEmpty: asserting the empty application directory is deleted with StateDirectory#clean.
  - StateDirectoryTest#shouldNotDeleteAppDirWhenCleanUpIfNotEmpty: asserting the non-empty application directory is not deleted with StateDirectory#clean and appropriate log message is generated.
  - Add Integration test: StateDirectoryIntegrationTest
3. Improve EOSUncleanShutdownIntegrationTest: test all available cases regarding cleanup process on unclean shutdown.

Reviewers: John Roesler <vvcephei@apache.org>, Guozhang Wang <guozhang@apache.org>",2021-06-10 14:59:57,Lee Dongjin,Mixed
5936a249bda171851cfa669da4276d23230eab6e,"KAFKA-12934: Move some controller classes to the metadata package (#10865)

Move some controller classes to the metadata package so that they can be
used with broker snapshots. Rename ControllerTestUtils to
RecordTestUtils. Create LeaderConstants and PartitionRegistration.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-06-10 17:34:15,Colin Patrick McCabe,Mixed
787b4fe9550389a2ca6d1131b32aff6e4f8610d1,"MINOR: clean up unneeded `@SuppressWarnings` (#10855)

Reviewers: Luke Chen <showuon@gmail.com>, Matthias J. Sax <mjsax@apache.org>, Chia-Ping Tsai <chia7712@gmail.com>",2021-06-13 19:00:14,Josep Prat,Mixed
530224e4fe853df734e7bf7c15661fe6b1ab34fe,"KAFKA-12940: Enable JDK 16 builds in Jenkins (#10702)

JDK 15 no longer receives updates, so we want to switch from JDK 15 to JDK 16.
However, we have a number of tests that don't yet pass with JDK 16.

Instead of replacing JDK 15 with JDK 16, we have both for now and we either
disable (via annotations) or exclude (via gradle) the tests that don't pass with
JDK 16 yet. The annotations approach is better, but it doesn't work for tests
that rely on the PowerMock JUnit 4 runner.

Also add `--illegal-access=permit` when building with JDK 16 to make MiniKdc
work for now. This has been removed in JDK 17, so we'll have to figure out
another solution when we migrate to that.

Relevant JIRAs for the disabled tests: KAFKA-12790, KAFKA-12941, KAFKA-12942.

Moved some assertions from `testTlsDefaults` to `testUnsupportedTlsVersion`
since the former claims to test the success case while the former tests the failure case.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2021-06-13 08:14:37,Ismael Juma,Not TDD
1e88c758dea8c1f1cd5f5724e98a6af93637644c,"KAFKA-12948: Remove node from ClusterConnectionStates.connectingNodes when node is removed (#10882)

NetworkClient.poll() throws IllegalStateException when checking isConnectionSetupTimeout if all nodes in ClusterConnectionStates.connectingNodes aren't present in ClusterConnectionStates.nodeState. This commit ensures that when we remove a node from nodeState, we also remove from connectingNodes.

Reviewers: David Jacot <djacot@confluent.io>",2021-06-15 09:18:30,Rajini Sivaram,Not TDD
c16711cb8e0d1c03f123e3e9d7e3d810796bf315,"KAFKA-12701: NPE in MetadataRequest when using topic IDs (#10584)

We prevent handling MetadataRequests where the topic name is null (to prevent NPE) as
well as prevent requests that set topic IDs since this functionality has not yet been
implemented. When we do implement it  in https://github.com/apache/kafka/pull/9769,
we should bump the request/response version.

Added tests to ensure the error is thrown.

Reviewers: dengziming <swzmdeng@163.com>, Ismael Juma <ismael@juma.me.uk>",2021-06-15 06:09:46,Justine Olshan,Mixed
4b7ad7b14d04e1e362b8100f43375d1630ded1b4,"KAFKA-12773; Use UncheckedIOException when wrapping IOException (#10749)

The raft module may not be fully consistent on this but in general in that module we have decided to not throw the checked IOException. We have been avoiding checked IOException exceptions by wrapping them in RuntimeException. The raft module should instead wrap IOException in UncheckedIOException. 

Reviewers: Luke Chen <showuon@gmail.com>, David Arthur <mumrah@gmail.com>, José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",2021-06-15 10:22:48,loboya~,Mixed
b67a77d5b9ed497b5b3cf0dde95a4f3ef7f0b74f,"KAFKA-12787; Integrate controller snapshoting with raft client (#10786)

Directly use `RaftClient.Listener`, `SnapshotWriter` and `SnapshotReader` in the quorum controller.

1. Allow `RaftClient` users to create snapshots by specifying the last committed offset and last committed epoch. These values are validated against the log and leader epoch cache.
2. Remove duplicate classes in the metadata module for writing and reading snapshots.
3. Changed the logic for comparing snapshots. The old logic was assuming a certain batch grouping. This didn't match the implementation of the snapshot writer. The snapshot writer is free to merge batches before writing them.
4. Improve `LocalLogManager` to keep track of multiple snapshots.
5. Improve the documentation and API for the snapshot classes to highlight the distinction between the offset of batches in the snapshot vs the offset of batches in the log. These two offsets are independent of one another. `SnapshotWriter` and `SnapshotReader` expose a method called `lastOffsetFromLog` which represents the last inclusive offset from the log that is represented in the snapshot.

Reviewers: dengziming <swzmdeng@163.com>, Jason Gustafson <jason@confluent.io>",2021-06-15 10:32:01,José Armando García Sancio,Mixed
7c7cecded68213619ff988e9745ba9e97c0e3e31,"MINOR Updated transaction index as optional in LogSegmentData. (#10848)

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",2021-06-15 13:56:22,Satish Duggana,Mixed
135de5801ecaa1812e1677588025bb42878e0611,"KAFKA-12877: Make flexibleVersions mandatory (#10804)

Many Kafka protocol JSON files were accidentally configured to not use
flexible versions, since it was not on by default.  This PR requires
JSON files to specify a flexibleVersions value. If the JSON file does
not specify the flexibleVersions value, display an error message
suggesting the correct value to use for new messages.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-06-15 16:04:30,Colin Patrick McCabe,Not TDD
f0bb85cee3b127cfb13cd8fea85ac61936f2d39f,"KAFKA-12931: KIP-746: Revise KRaft Metadata Records (#10867)

Implement the metadata records changes described in KIP-746. Fix unit
tests as needed.

Reviewers: David Arthur <mumrah@gmail.com>",2021-06-15 16:39:18,Colin Patrick McCabe,Mixed
96767a60db4117f257e911871d139572b84be65d,"KAFKA-12909: disable spurious left/outer stream-stream join fix for old JoinWindows API (#10861)

We changed the behavior of left/outer stream-stream join via KAFKA-10847.
To avoid a breaking change during an upgrade, we need to disable this
fix by default.

We only enable the fix if users opt-in expliclity by changing their
code. We leverage KIP-633 (KAFKA-8613) that offers a new JoinWindows
API with mandatory grace-period to enable the fix.

Reviewers: Sergio Peña <sergio@confluent.io>, Israel Ekpo <israelekpo@gmail.com>, Guozhang Wang <guozhang@confluent.io>",2021-06-16 09:25:16,Matthias J. Sax,Mixed
fc5245d8c37a6c9d585c5792940a8f9501bedbe1,"KAFKA-12955: Fix LogLoader to pass materialized view of segments for deletion (#10888)

Within LogLoader.removeAndDeleteSegmentsAsync(), we should force materialization of the segmentsToDelete iterable, to make sure the results of the iteration remain valid and deterministic. We should also pass only the materialized view to the logic that deletes the segments, as otherwise we could end up deleting the wrong segments.

Reviewers: Jun Rao <junrao@gmail.com>",2021-06-16 15:02:50,Kowshik Prakasam,Mixed
1a16fc139a91e8344915173da4b6d5a90e3965a3,"KAFKA-10437: Update WordCount examples to use new PAPI (#10701)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2021-06-16 22:24:11,dengziming,Mixed
d294b946ca78c9b8caf16547cf2fa6ed348a3033,"KAFKA-12890; Consumer group stuck in `CompletingRebalance` (#10863)

This patch introduces a new delayed operation which effectively ensures that a SyncGroup request is received from all the stable members in the groups within the rebalance timeout. The timer starts when the group transitions to the `CompletingRebalance` state. The previous mechanism based on `DelayedHeartbeat` did not work anymore because of https://github.com/apache/kafka/pull/8834 which allows heartbeats while the group is in the `CompletingRebalance`.

Reviewers: Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",2021-06-17 13:46:16,David Jacot,Mixed
580c1112582ed6ddaca6c0402a1bb014c36235e5,"KAFKA-12662: add unit test for ProducerPerformance (#10588)

Reviewers: Luke Chen <showuon@gmail.com>, wenbingshen <oliver.shen999@gmail.com>, dengziming <dengziming1993@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2021-06-17 20:07:12,CHUN-HAO TANG,Mixed
d27a84f70c3f65de49da161213233291505c09db,"KAFKA-12945: Remove port, host.name and related configs in 3.0 (#10872)

They have been deprecated since 0.10.0. Full list of removes configs:
* port
* host.name
* advertised.port
* advertised.host.name

Also adjust tests to take the removals into account. Some tests were
no longer relevant and have been removed.

Finally, took the chance to:
* Clean up unnecessary usage of `KafkaConfig$.MODULE$` in
related files.
* Add missing `Test` annotations to `AdvertiseBrokerTest` and
make necessary changes for the tests to pass.

Reviewers: David Jacot <djacot@confluent.io>, Luke Chen <showuon@gmail.com>",2021-06-17 05:32:34,Ismael Juma,Mixed
31bb4c368dd8723ac90a89c5b255506fba43c633,"KAFKA-12906; Added RecordDeserializationException containing partition and offset  (#10836)

As documented in KIP-334 (https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=87297793), we should add a new RecordDeserializationException, which is raised by the consumer when failing to parse a record. This allows the consumer to decide to take an action such as to shut down or skip past the record. 

Reviewers: Jason Gustafson <jason@confluent.io>",2021-06-17 14:49:21,Sarwar Bhuiyan,Not TDD
195a8b0ed153a711d88e51b9dff66d27cc451776,"KAFKA-12835: Topic IDs can mismatch on brokers (after interbroker protocol version update) (#10754)

Upon upgrading to IBP 2.8, topic ID can end up getting reassigned which can cause errors in LeaderAndIsr handling when the partition metadata files from the previous ID are still on the broker. 

Topic IDs are stored in the TopicZNode. The behavior of the code before this fix is as follows:
Consider we had a controller with IBP 2.8+. Each topic will be assigned topic IDs and LeaderAndIsr requests will write partition.metadata files to the brokers. If we re-elect the controller and end up with a controller with an older IBP version and we reassign partitions, the TopicZNode is overwritten and we lose the topic ID. Upon electing a 2.8+ IBP controller, we will see the TopicZNode is missing a topic ID and will generate a new one. If the broker still has the old partition metadata file, we will see an ID mismatch that causes the error.

This patch changes controller logic so that we maintain the topic ID in the controller and the ZNode even when IBP < 2.8. This means that in the scenario above, reassigning partitions will not result in losing the topic ID and reassignment.

Topic IDs may be lost when downgrading the code below version 2.8, but upon re-upgrading to code version 2.8+, before bumping the IBP, all partition metadata files will be deleted to prevent any errors.

Reviewers:  Lucas Bradstreet <lucas@confluent.io>, David Jacot <djacot@confluent.io>",2021-06-18 09:25:03,Justine Olshan,Mixed
56250f446af6667bb034b7e20c235b2b59cd651b,"KAFKA-12816 Added tiered storage related configs including remote log manager configs. (#10733)

Added tiered storage related configs including remote log manager configs.
Added local log retention configs to LogConfig.
Added tests for the added configs.

Reviewers: Kowshik Prakasam <kprakasam@confluent.io>, Jun Rao <junrao@gmail.com>",2021-06-18 09:38:42,Satish Duggana,Mixed
4ddf1a5f94f7e74a0429ce23043b8d8a4961effa,"KAFKA-12837; Process entire batch reader in the `BrokerMetadataListener` commit handler (#10902)

We should process the entire batch in `BrokerMetadataListener` and make sure that `hasNext` is called before calling `next` on the iterator. The previous code worked because the raft client kept track of the position in the iterator, but it caused NoSuchElementException to be raised when the reader was empty (as might be the case with control records).

Reviewers: Jason Gustafson <jason@confluent.io>",2021-06-18 13:20:43,José Armando García Sancio,Mixed
299eea88a5068f973dc055776c7137538ed01c62,"KAFKA-12870; Flush in progress not cleared after transaction completion (#10880)

We had been using `RecordAccumulator.beginFlush` in order to force the `RecordAccumulator` to flush pending batches when a transaction was being completed. Internally, `RecordAccumulator` has a simple counter for the number of flushes in progress. The count gets incremented in `beginFlush` and it is expected to be decremented by `awaitFlushCompletion`. The second call to decrement the counter never happened in the transactional path, so the counter could get stuck at a positive value, which means that the linger time would effectively be ignored.

This patch fixes the problem by removing the use of `beginFlush` in `Sender`. Instead, we now add an additional condition in `RecordAccumulator` to explicitly check when a transaction is being completed. 

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2021-06-18 15:50:49,Jason Gustafson,Mixed
c333bfd41766bf33f41b5d32d8959ebbeff240b4,"MINOR: Add reset to SnapshotRegistry and Revertable (#10891)

Add reset functionality to SnapshotRegitry and Revertable, so that we can
clear the current state before loading a snapshot.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-06-18 17:08:54,José Armando García Sancio,Mixed
ac5ddc574ef23279267a8f9bda737a840be30c85,"KAFKA-12889: log clean relative index range check of group consider empty log segment to avoid too many empty log segment left (#10818)

To avoid log index 4 byte relative offset overflow, log cleaner group check log segments offset to make sure group offset range not exceed Int.MaxValue.

This offset check currentlly not cosider next is next log segment is empty, so there will left empty log files every about 2^31 messages.

The left empty logs will be reprocessed every clean cycle, which will rewrite it with same empty content, witch cause little no need io.

For __consumer_offsets topic, normally we can set cleanup.policy to compact,delete to get rid of this.

My cluster is 0.10.1.1, but after analyze the trunk code, it should has same problem too.

Co-authored-by: Liu Qiang(BSS-HZ) <qliu.zj@best-inc.com>

Reviewers: Luke Chen <showuon@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2021-06-19 15:33:52,iamgd67,Mixed
b38cadca230e85bc0748f975e6a8e8c2739c747e,"MINOR: Remove log warning for RocksDB 6+ upgrade (#10911)


Reviewers: Boyang Chen <boyang@apache.org>",2021-06-22 13:17:39,Bruno Cadonna,Mixed
2ad9350cc1052b39d8ae526d1df5a59744f74f2f,"MINOR: Remove obsolete variables for metric sensors (#10912)

This is a clean-up that we missed for ""KIP-743: Remove config value 0.10.0-2.4 of Streams built-in metrics version config""

Reviewers: Luke Chen <showuon@gmail.com>, Matthias J. Sax <mjsax@apache.org>",2021-06-22 14:10:28,Bruno Cadonna,Mixed
c8684d883b4c7db13272e8e28f55e2a02bf8cab7,"KAFKA-12483: Enable client overrides in connector configs by default (KIP-722) (#10336)

Changes the default value for the `connector.client.config.override.policy` worker configuration property from `None` to `All`. Modified unit tests to verify all policies still work, and that by default connectors can override all client policies.
See https://cwiki.apache.org/confluence/display/KAFKA/KIP-722%3A+Enable+connector+client+overrides+by+default

Updated the documentation for the worker's client overrides policy to mention the new default.

Author: Randall Hauch <rhauch@gmail.com>
Reviewer: Konstantine Karantasis <konstantine@confluent.io>",2021-06-22 09:12:11,Randall Hauch,Not TDD
c3475081c5e8228e9bd3a45022a93d61e542f72e,"KAFKA-10546: Deprecate old PAPI (#10869)

* Deprecate the old Processor API
* Suppress warnings on all internal usages of the old API
  (which will be migrated in other child tickets of KAFKA-8410)
* Add new KStream#process methods, since KAFKA-10603 has not seen any action.",2021-06-22 09:17:11,John Roesler,Mixed
fce771579c3e20f20949c4c7e0a5e3a16c57c7f0,"KAFKA-12888; Add transaction tool from KIP-664 (#10814)

This patch adds the transaction tool specified in KIP-664: https://cwiki.apache.org/confluence/display/KAFKA/KIP-664%3A+Provide+tooling+to+detect+and+abort+hanging+transactions. This includes all of the logic for describing transactional state and for aborting transactions. The only thing that is left out is the `--find-hanging` implementation, which will be left for a subsequent patch.

Reviewers: Boyang Chen <boyang@apache.org>, David Jacot <djacot@confluent.io>",2021-06-22 09:47:30,Jason Gustafson,Mixed
7da881ffbe0249b7ea98f1668303fc6f1ae4f803,"KAFKA-12928: Add a check whether the Task's statestore is actually a directory (#10862)

Throw an exception if a state directory exists as a regular file

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Luke Chen <showuon@gmail.com>",2021-06-22 16:35:30,Lee Dongjin,Mixed
5652ef1af04a919f6483294315572c7153ac6301,"KAFKA-12482 Remove deprecated rest.host.name and rest.port configs (#10841)

Remove the `rest.host.name` and `rest.port` Connect worker configs that were deprecated in KIP-208 and AK 1.1.

Author: Kalpesh Patel <kalpeshpatel.india@gmail.com>
Reviewers: Randall Hauch <rhauch@gmail.com>, Konstantine Karantasis <konstantine@confluent.io>, wenbingshen <oliver.shen999@gmail.com>",2021-06-23 09:20:04,kpatelatwork,Mixed
386670227b2e5ef7633c74033e2b99222b35d7cc,"KAFKA-12898; Owned partitions in the subscription must be sorted (#10878)

The group coordinator compares the provided subscription with the store subscription based on their bytes representation. So if the subscribed partitions are not in the same order, the group coordinator would consider that they are different and rebalance the group. This patch ensures that the topics and the owned partitions are sorted.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-06-24 09:56:27,David Jacot,Mixed
b0cfd1f4ca83e1bc3a324e5d4081b2731c420733,"KAFKA-12336 Custom stream naming does not work while calling stream[K… (#10190)

Custom stream naming does not work while calling stream[K, V](topicPattern: Pattern)

Reviewers: Bill Bejeck <bbejeck@apache.org>",2021-06-24 12:07:22,Geordie,Not TDD
2beaf9a720330615bc5474ec079f8b4b105eff91,"KAFKA-12967; KRaft broker should forward DescribeQuorum to controller (#10900)

We added the DescribeQuorum API in KIP-595. This patch adds the logic to forward DescribeQuorum requests to the controller when KRaft is enabled. The KRaft broker listener has already been enabled in DescribeQuorumRequest.json. The zk broker is not enabled, however, so DescribeQuorum requests will not be advertised and will be rejected at the network layer.

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, David Arthur <mumrah@gmail.com>",2021-06-24 10:54:32,Jason Gustafson,Mixed
bd72ef1bf1e40feb3bc17349a385b479fa5fa530,"KAFKA-12541; Extend ListOffset to fetch offset with max timestamp (KIP-734) (#10760)

This patch implements KIP-734 as described in https://cwiki.apache.org/confluence/display/KAFKA/KIP-734%3A+Improve+AdminClient.listOffsets+to+return+timestamp+and+offset+for+the+record+with+the+largest+timestamp.

Reviewers: David Jacot <djacot@confluent.io>",2021-06-25 14:29:12,thomaskwscott,Mixed
6655a09e99125aff34cb96188924fca1df3387ad,"KAFKA-12849: KIP-744 TaskMetadata ThreadMetadata StreamsMetadata as API (#10840)

Implementation of KIP-744.

Creates new Interfaces for TaskMetadata, ThreadMetadata, and
StreamsMetadata, providing internal implementations for each of them.

Deprecates current TaskMetadata, ThreadMetadata under o.a.k.s.processor,
and SreamsMetadata under a.o.k.s.state.

Updates references on internal classes from deprecated classes to new interfaces.

Deprecates methods on KafkaStreams returning deprecated ThreadMeatada and
StreamsMetadata, and provides new ones returning the new interfaces.

Update Javadocs referencing to deprecated classes and methods to point
to the right ones.

Co-authored-by: Bruno Cadonna <cadonna@apache.org>

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Bruno Cadonna <cadonna@apache.org>",2021-06-25 18:31:49,Josep Prat,Mixed
bd668e90c6992e7a1f23274aab37d186d6a4b560,"MINOR: add MockConfigRepository (#10927)

Use MockConfigRepository rather than CachedConfigRepository in unit
tests. This is useful for an upcoming change that will remove
CachedConfigRepository.

Reviewers: David Arthur <mumrah@gmail.com>",2021-06-25 16:40:42,Colin Patrick McCabe,Mixed
397fa1f894c176d71601183c36e5d498fc83fd1e,"KAFKA-12976; Remove UNSUPPORTED_VERSION error from delete topics call (#10923)

Removed the condition to throw the error. Now we return UNKNOWN_TOPIC_ID which allows clients to retry instead of failing. Updated the test for IBP < 2.8 that tries to delete topics using ID.

Reviewers: Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",2021-06-28 10:15:50,Justine Olshan,Not TDD
670630ae5b81d8d1cd32defe8824640dd865a538,"KAFKA-12951: restore must terminate for tx global topic (#10894)

Reviewers: Guozhang Wang <guozhang@confluent.io>, Luke Chen <showuon@gmail.com>, Gasparina Damien <d.gasparina@gmail.com>",2021-06-28 14:10:25,Matthias J. Sax,Mixed
cfcabc368c3f0a123c4561059b043648d79b1df8,"KAFKA-12718: SessionWindows are closed too early (#10824)

Session windows should not be close directly when ""window end"" time is reached, but ""window close"" time should be ""window-end + gap + grace-period"".

Reviewer: Matthias J. Sax <matthias@confluent.io>",2021-06-28 15:39:49,Juan Gonzalez-Zurita,Not TDD
f86cb1d1da4f73bf92b0fcfd5ef75b3ce77658cf,"KAFKA-12631; Implement `resign` API in `KafkaRaftClient` (#10913)

This patch adds an implementation of the `resign()` API which allows the controller to proactively resign leadership in case it encounters an unrecoverable situation. There was not a lot to do here because we already supported a `Resigned` state to facilitate graceful shutdown.

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, David Arthur <mumrah@gmail.com>",2021-06-28 18:00:19,Jason Gustafson,Mixed
d95c1919458bd5621774394c9eb61698ce2187b8,"KAFKA-12926: ConsumerGroupCommand's java.lang.NullPointerException at negative offsets while running kafka-consumer-groups.sh (#10858)

This patch fixes the `ConsumerGroupCommand` to correctly handle missing offsets, which are returned as `null` by the admin API.

Reviewers: David Jacot <djacot@confluent.io>",2021-06-29 09:00:56,Ignacio Acuña Frías,Not TDD
c6d2778a8d1383e76695ec82710208153e83b2c2,"KAFKA-12996; Return OFFSET_OUT_OF_RANGE for fetchOffset < startOffset even for diverging epochs (#10930)

If fetchOffset < startOffset, we currently throw OffsetOutOfRangeException when attempting to read from the log in the regular case. But for diverging epochs, we return Errors.NONE with the new leader start offset, hwm etc.. ReplicaFetcherThread throws OffsetOutOfRangeException when processing responses with Errors.NONE if the leader's offsets in the response are out of range and this moves the partition to failed state. The PR adds a check for this case when processing fetch requests and throws OffsetOutOfRangeException regardless of epoch.

Reviewers: Luke Chen <showuon@gmail.com>, Nikhil Bhatia <rite2nikhil@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2021-06-29 08:49:36,Rajini Sivaram,Mixed
0b6d6b178563f1890cc86458c677af4fb9179467,"KAFKA-12520: Ensure log loading does not truncate producer state unless required (#10763)

When we find a .swap file on startup, we typically want to rename and replace it as .log, .index, .timeindex, etc. as a way to complete any ongoing replace operations. These swap files are usually known to have been flushed to disk before the replace operation begins.

One flaw in the current logic is that we recover these swap files on startup and as part of that, end up truncating the producer state and rebuild it from scratch. This is unneeded as the replace operation does not mutate the producer state by itself. It is only meant to replace the .log file along with corresponding indices. Because of this unneeded producer state rebuild operation, we have seen multi-hour startup times for clusters that have large compacted topics.

This patch fixes the issue. With ext4 ordered mode, the metadata are ordered and no matter it is a clean/unclean shutdown. As a result, we rework the recovery workflow as follows.

If there are any .cleaned files, we delete all .swap files with higher/equal offsets due to KAFKA-6264. We also delete the .cleaned files. If no .cleaned file, do nothing for this step.
If there are any .log.swap files left after step 1, they, together with their index files, must be renamed from .cleaned and are complete (renaming from .cleaned to .swap is in reverse offset order). We rename these .log.swap files and their corresponding index files to regular files, while deleting the original files from compaction or segment split if they haven't been deleted.
Do log splitting for legacy log segments with offset overflow (KAFKA-6264)
If there are any other index swap files left, they must come from partial renaming from .swap files to regular files. We can simply rename them to regular files.
credit: some code is copied from @dhruvilshah3 's PR: #10388

Reviewers: Dhruvil Shah <dhruvil@confluent.io>, Jun Rao <junrao@gmail.com>",2021-06-29 09:17:13,Cong Ding,Not TDD
d3ec9f940cc4402270cba3ad159ec64a9676a385,"KAFKA-12952 Add header and footer records for raft snapshots (#10899)

Add header and footer records for raft snapshots. This helps identify when the snapshot
starts and ends. The header also contains a time.  The time field is currently set to 0.
KAFKA-12997 will add in the necessary wiring to use the correct timestamp.

Reviewers: Jose Sancio <jsancio@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",2021-06-29 09:37:20,Niket,Mixed
3c4be0b57a50f46e360830f9cf954919e6deec45,"KAFKA-12379: Allow configuring the location of the offset-syncs topic with MirrorMaker2 (#10221)

This commit implements KIP-716. It introduces a new setting `offset-syncs.topic.location` that allows specifying where the offset-syncs topic is created.

Reviewers: Tom Bentley <tbentley@redhat.com>, Edoardo Comar <ecomar@uk.ibm.com>",2021-06-29 21:33:59,Mickael Maison,Mixed
d9b898b678158626bd2872bbfef883ca60a41c43,"MINOR: Refactor the MetadataCache interface (#10887)

Remove getNonExistingTopics, which was not necessary. MetadataCache
already lets callers check for the existence of topics by calling
MetadataCache#contains.

Add MetadataCache#getAliveBrokerNode and getAliveBrokerNodes. This
simplifies the calling code, which always wants a Node.

Fix a case where we were calling getAliveBrokers and filtering by id,
rather than simply calling getAliveBroker(id) and making use of the hash
map.

Reviewers: Jason Gustafson <jason@confluent.io>, Jose Sancio <jsancio@gmail.com>",2021-06-29 15:59:20,Colin Patrick McCabe,Mixed
b1562a90e013be43bdc14de33d0cceea04230819,"MINOR: Replace easymock with mockito in log4j-appender (#10852)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-06-30 01:25:08,dengziming,Not TDD
4f5b4c868e72cc9d9a4f859c5bfe8364e9af9fff,"KAFKA-12756: Update ZooKeeper to v3.6.3 (#10918)

Update the ZooKeeper version to v3.6.3. This requires adding dropwizard
as a new dependency.

Also, add Kafka v2.8.0 to the ducktape system test image.

Reviewers: Luke Chen <showuon@gmail.com>, Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",2021-06-30 11:21:33,Ron Dagostino,Mixed
a10e4e8547478024794e1ec78bc491181c85d61b,"MINOR: Some broker code cleanups #10948

Fix the JavaDoc for the ClientQuotaManagerConfig#throttle function to
refer to the correct parameter name.

BrokerEndPointTest#testHashAndEquals should test the BrokerEndPoint
class, rather than the MetadataBroker class.

TopicConfigHandler: make the kafkaController argument optional, since we won't
have it when in KRaft mode.

Remove the unecessary ConfigRepository argument for the Partition class.

Remove the unused TestUtils#deleteBrokersInZk function.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-06-30 14:58:01,Colin Patrick McCabe,Mixed
b3905d9f71d48a60f2a9ee38014582d7ec7bc3c2,"KAFKA-8613: New APIs for Controlling Grace Period for Windowed Operations (#10926)

Implements KIP-633.

Grace-period is an important parameter and its best to make it the user's responsibility to set it expliclity. Thus, we move off to provide a default and make it a mandatory parameter when creating a window.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Luke Chen <showuon@gmail.com>, Matthias J. Sax <matthias@confluent.io>",2021-06-30 17:09:19,Israel Ekpo,Mixed
1b7ab8eb9fefc238c48c94130dda38563143c74b,"KAFKA-12863: Configure controller snapshot generation (#10812)

Add the ability for KRaft controllers to generate snapshots based on the number of new record bytes that have 
been applied since the last snapshot. Add a new configuration key to control this parameter. For now, it
defaults to being off, although we will change that in a follow-on PR. Also, fix LocalLogManager so that
snapshot loading is only triggered when the listener is not the leader.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-06-30 18:13:53,José Armando García Sancio,Mixed
527ba111c73aa32deaef102fc953f3d20a8670d7,"KAFKA-4793: Connect API to restart connector and tasks (KIP-745) (#10822)

Implements KIP-745 https://cwiki.apache.org/confluence/display/KAFKA/KIP-745%3A+Connect+API+to+restart+connector+and+tasks to change connector REST API to restart a connector and its tasks as a whole.

Testing strategy 
- [x]  Unit tests added for all possible combinations of onlyFailed and includeTasks
- [x]  Integration tests added for all possible combinations of onlyFailed and includeTasks
- [x]  System tests for happy path 

Reviewers: Randall Hauch <rhauch@gmail.com>, Diego Erdody <erdody@gmail.com>, Konstantine Karantasis <k.karantasis@gmail.com>",2021-06-30 21:13:07,kpatelatwork,Mixed
cee2e975d124da0a2bdc0065a3172ce31e036fa0,"KAFKA-13011; Update deleteTopics Admin API  (#10892)

This patch adds two new apis to support topic deletion using topic IDs or names. It uses a new class `TopicCollection` to keep a collection of topics defined either by names or IDs. Finally, it modifies `DeleteTopicsResult` to support both names and IDs and deprecates the old methods which have become ambiguous. Eventually we will want to deprecate the old `deleteTopics` apis as well, but this patch does not do so.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-06-30 23:20:21,Justine Olshan,Mixed
593b34a5bed4e1989d966f08d0fb1b318abb5007,"KAFKA-13002: listOffsets must downgrade immediately for non MAX_TIMESTAMP specs (#10936)

This patch fixes a regression introduced https://github.com/apache/kafka/pull/10760. The downgrade logic was not downgrading the version when only non MAX_TIMESTAMP specs were used.

Reviewers: David Jacot <djacot@confluent.io>",2021-07-01 08:35:55,thomaskwscott,Mixed
b4e45cd0d245eb66a9f3d2d69523a507bd820dff,"KAFKA-13019: Add MetadataImage and MetadataDelta classes for KRaft Snapshots (#10949)

Create the image/ module for storing, reading, and writing broker metadata images.
Metadata images are immutable. New images are produced from existing images
using delta classes. Delta classes are mutable, and represent changes to a base
image.

MetadataImage objects can be converted to lists of KRaft metadata records. This
is essentially writing a KRaft snapshot. The resulting snapshot can be read
back into a MetadataDelta object. In practice, we will typically read the
snapshot, and then read a few more records to get fully up to date. After that,
the MetadataDelta can be converted to a MetadataImage as usual.

Sometimes, we have to load a snapshot even though we already have an existing
non-empty MetadataImage. We would do this if the broker fell too far behind and
needed to receive a snapshot to catch up. This is handled just like the normal
snapshot loading process. Anything that is not in the snapshot will be marked
as deleted in the MetadataDelta once finishSnapshot() is called.

In addition to being used for reading and writing snapshots, MetadataImage also
serves as a cache for broker information in memory. A follow-up PR will replace
MetadataCache, CachedConfigRepository, and the client quotas cache with the
corresponding Image classes. TopicsDelta also replaces the ""deferred
partition"" state that the RaftReplicaManager currently implements. (That change
is also in a follow-up PR.)

Reviewers: Jason Gustafson <jason@confluent.io>, David Arthur <mumrah@gmail.com>",2021-07-01 00:08:25,Colin Patrick McCabe,Mixed
93f57370c68fe1e74320ec50cd26d44f84d63777,"KAFKA-9726: Add IdentityReplicationPolicy to MirrorMaker2 (#10652)

This new policy enables active/passive, one-way replication without renaming topics, similar to MM1. This implementation is described in KIP-382 (adopted), originally as ""LegacyReplicationPolicy"".

This enables operators to migrate from MM1 to MM2 without re-architecting their replication flows, and enables some additional use-cases for MM2. For example, operators may wish to ""upgrade"" their Kafka clusters by mirroring everything to a completely new cluster. Such a migration would have been difficult with either MM1 or MM2 previously.

When using IdentityReplicationPolicy, operators should be aware that MM2 will not be able to detect cycles among replicated topics. A misconfigured topology may result in replicating the same records back-and-forth or in an infinite loop. However, we don't prevent this behavior, as some use-cases involve filtering records (via SMTs) to prevent cycles.

Reviewers: Mickael Maison <mickael.maison@gmail.com>

Co-authored-by: Ryanne Dolan <rdolan@twitter.com>
Co-authored-by: Matthew de Detrich <mdedetrich@gmail.com>
Co-authored-by: Ivan Yurchenko <ivanyu@aiven.io>",2021-07-01 09:21:27,Ryanne Dolan,Mixed
f5d5f654db359af077088685e29fbe5ea69616cf,"KAFKA-12663: Update FindCoordinator to support batch lookups (KIP-699) (#10743)

This implements KIP-699: https://cwiki.apache.org/confluence/display/KAFKA/KIP-699%3A+Update+FindCoordinator+to+resolve+multiple+Coordinators+at+a+time

It updates FindCoordinator request and response to support resolving multiple coordinators at a time. If a broker does not support the new FindCoordinator version, clients can revert to the previous behaviour and use a request for each coordinator.

Reviewers: David Jacot <djacot@confluent.io>, Tom Bentley <tbentley@redhat.com>, Sanjana Kaundinya <skaundinya@gmail.com>",2021-07-01 22:05:03,Mickael Maison,Mixed
8cd04cb1a0e7e592d765a8b77dea85011a6e6f12,"KAFKA-13007; KafkaAdminClient getListOffsetsCalls reuse cluster snapshot (#10940)

In getListOffsetsCalls, we rebuild the cluster snapshot for every topic partition. instead, we should reuse a snapshot.

For manual testing (used AK 2.8), i've passed in a map of 6K topic partitions to listOffsets

Without snapshot reuse:
duration of building futures from metadata response: **15582** milliseconds
total duration of listOffsets: **15743** milliseconds

With reuse:
duration of building futures from metadata response: **24** milliseconds
total duration of listOffsets: **235** milliseconds

Reviewers: Luke Chen <showuon@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2021-07-01 14:16:35,Jeff Kim,Mixed
789fc26042b3863d1ff74619a59b8e66dccba63e,"KAFKA-12964: Collect and rename snapshot files prior to async deletion. (#10896)

Segment and index files are currently renamed with a .deleted
suffix prior to async deletion. This serves two purposes, to
resume deletion on broker failure and also protect against
deletion of new segments during truncation (due to deletion
being async).

We should do the same for snapshot files. While they are not subject
to issues around resuming deletion due to the stray snapshot
scanning which is performed on log initialization, we can end up
with situations where truncation queues snapshots for deletion, but
prior to deletion new segments with the same snapshot file name are
created. Async deletion can then delete these new snapshots.

This patch offers a two-stage snapshot deletion which first renames
and removes the segments in question from the ProducerStateManager,
allowing the Log to asynchronously delete them.

Credit to Kowshik Prakasam <kowshik@gmail.com> for finding this issue
and creating the test demonstrating the failure.

Co-authored-by: Kowshik Prakasam <kowshik@gmail.com> Address PR feedback

Reviewers: Kowshik Prakasam <kprakasam@confluent.io>, Jun Rao <junrao@gmail.com>",2021-07-01 14:23:58,Gardner Vickers,Mixed
4fd71a7ef1c79ec3f110ee2f9d38fa7d5194937e,"KAFKA-9559: Change default serde to be `null` (#10813)

Implements KIP-741

Reviewers: Matthias J. Sax <matthias@confluent.io>",2021-07-01 14:58:29,leah,Mixed
a095e1fd8ca38099605a21c9c8498ceb37cd07cd,"KAFKA-10847: improve throughput of stream-stream join with spurious left/outer join fix (#10917)

The fix to avoid spurious left/outer stream-stream join results, showed
very low throughput for RocksDB, due to excessive creation of iterators.
Instead of trying to emit left/outer stream-stream join result for every
input record, this PR adds tracking of the lower timestamp bound of
left/outer join candidates, and only tries to emit them (and create an
iterator) if they are potentially old enough.

Reviewers: Luke Chen <showuon@gmail.com>, Guozhang Wang <guozhang@confluent.io>, Sergio Peña <sergio@confluent.io>",2021-07-01 15:46:22,Matthias J. Sax,Not TDD
9f01909dc38624a4893b9292af35411dd04f0076,"KAFKA-12997: Expose the append time for batches from raft (#10946)

Add the record append time to Batch. Change SnapshotReader to set this time to the
time of the last log in the last batch. Fix the QuorumController to remember the last
committed batch append time and to store it in the generated snapshot.

Reviewers: David Arthur <mumrah@gmail.com>, Luke Chen <showuon@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",2021-07-01 16:38:59,José Armando García Sancio,Mixed
51796bcdef2e93ee4176415961ab98dd7407ebec,"KAFKA-10587; Rename kafka-mirror-maker CLI command line arguments for KIP-629

[KAFKA-10587](https://issues.apache.org/jira/browse/KAFKA-10587) Rename kafka-mirror-maker CLI command line arguments for KIP-629
Replace ""whitelist"" argument in kafka-mirror-maker cli command with ""include""

Author: OmniaGM <o.g.h.ibrahim@gmail.com>

Reviewers: Luke Chen, Xavier Leaute, Gwen Shapira

Closes #10937 from OmniaGM/KAFKA-10587",2021-07-01 18:56:35,OmniaGM,Not TDD
cad2f5e1208230f52e77f14759bdaba2d6da9781,"KAFKA-12717: Remove internal Connect converter properties (KIP-738) (#10854)

Removed Connect Distributed worker's internal converter properties.

Author: Chris Egerton <chrise@confluent.io>
Reviewer: Randall Hauch <rhauch@gmail.com>",2021-07-01 21:02:24,Chris Egerton,Mixed
6d2f563865de2a9921417ffc3f769ab65598664b,"KAFKA-12436: Deprecate MirrorMaker v1 (KIP-720) (#10805)


Reviewers: Luke Chen <showuon@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Mickael Maison <mickael.maison@gmail.com>",2021-07-04 15:17:31,Ryanne Dolan,Not TDD
10b1f73cd42faaaabe3154694aae62a01d5de20d,"KAFKA-12958: add an invariant that notified leaders are never asked to load snapshot (#10932)

 Track handleSnapshot calls and make sure it is never triggered on the leader node.

Reviewers: Luke Chen <showuon@gmail.com>, José Armando García Sancio <jsancio@users.noreply.github.com>, Boyang Chen <bchen11@outlook.com>",2021-07-04 08:32:12,zhaohaidao,Not TDD
2b6365c78b6e659f8df0651a24013d028f39edd9,"KAFKA-13029; Set appropriate fields for FindCoordinatorRequest based on version (#10965)

KIP-699 added support for batching in FindCoordinatorRequest using a new protocol that changes the wire format for both batched and unbatched requests. Clients were updated to try the new format first and switch irreversibly to the old format if the new format is not supported on one broker. During rolling upgrade (or a downgrade), it is possible that a broker doesn't support new format at some point while other brokers do at a later point. Clients end up in a bad state until restarted since they use new version with old format. This PR changes FindCoordinatorRequest to set data based on actual version when a single group is used. This is always the case for consumer coordinator and transaction manager. For admin API, we still switch to unbatched mode on failure, but the data is set based on actual version, so we never fail even if brokers are upgraded/downgraded.

Reviewers: Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>",2021-07-05 14:26:03,Rajini Sivaram,Not TDD
19e8fd513a15b595f940370be07215863ad1ff7b,"KAFKA-9687: KIP-707: Add KafkaFuture.toCompletionStage() (#9878)

* Improve the test prior to reimplementing KafkaFutureImpl using CompletableFuture.
* KAFKA-9687: Reimplement KafkaFutureImpl using a CompleteableFuture
* KIP-707: Add KafkaFuture.toCompletionStage

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>, Konstantine Karantasis <k.karantasis@gmail.com>",2021-07-05 17:33:33,Tom Bentley,Mixed
f29c43bdbb85fd7c97ad2f567dcd67f2f2ece8ef,"KAFKA-12979; Implement command to find hanging transactions (#10974)

This patch implements the `find-hanging` command described in KIP-664: https://cwiki.apache.org/confluence/display/KAFKA/KIP-664%3A+Provide+tooling+to+detect+and+abort+hanging+transactions#KIP664:Providetoolingtodetectandaborthangingtransactions-FindingHangingTransactions.

Reviewers: Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",2021-07-06 10:39:59,Jason Gustafson,Mixed
284ec262c6c84063d90271c965e4cbc1eda111fe,"KAFKA-12155: Metadata log and snapshot cleaning #10864

This PR includes changes to KafkaRaftClient and KafkaMetadataLog to support periodic
cleaning of old log segments and snapshots.

Four new public config keys are introduced: metadata.log.segment.bytes,
metadata.log.segment.ms, metadata.max.retention.bytes, and
metadata.max.retention.ms.

These are used to configure the log layer as well as the snapshot cleaning logic. Snapshot
and log cleaning is performed based on two criteria: total metadata log + snapshot size
(metadata.max.retention.bytes), and max age of a snapshot (metadata.max.retention.ms).
Since we have a requirement that the log start offset must always align with a snapshot,
we perform the cleaning on snapshots first and then clean what logs we can.

The cleaning algorithm follows:
1. Delete the oldest snapshot.
2. Advance the log start offset to the new oldest snapshot.
3. Request that the log layer clean any segments prior to the new log start offset
4. Repeat this until the retention size or time is no longer violated, or only a single
snapshot remains.

The cleaning process is triggered every 60 seconds from the KafkaRaftClient polling
thread.

Reviewers: José Armando García Sancio <jsancio@gmail.com>, dengziming <dengziming1993@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",2021-07-06 14:19:44,David Arthur,Mixed
7bd55f51567d08d35922cf5c23a4b424e58fff9a,"KAFKA-12998: Implement broker-side KRaft snapshots (#10931)

This PR implements broker-side KRaft snapshots, including both saving and
loading. The code for triggering a periodic broker-side snapshot will come in a
follow-on PR. Loading should work with just this PR. It also implements
reloading broker snapshots after initialization.

In order to facilitate snapshots, this PR introduces the concept of
MetadataImage and MetadataDelta. MetadataImage represents the metadata state
retained in memory. It is basically a generalization of MetadataCache that
includes a few things that MetadataCache does not (such as features and client
quotas.) KRaftMetadataCache is now an accessor for the data stored in this object.
Similarly, MetadataImage replaces CacheConfigRespository and ClientQuotaCache.
It also subsumes kafka.server.metadata.MetadataImage and related classes.

MetadataDelta represents a change to a MetadataImage. When a KRaft snapshot is
loaded, we will accumulate all the changes into a MetadataDelta first, prior to
applying it. If we must reload a snapshot because we fell too far behind while
consuming metadata, the resulting MetadataDelta will contain all the changes
needed to catch us up. During normal operation, MetadataDelta is also used to
accumulate the changes of each incoming batch of metadata records. These
incremental deltas should be relatively small.

I have removed the logic for updating the various manager objects from
BrokerMetadataListener and placed it into BrokerMetadataPublisher. This makes
it easier to unit test BrokerMetadataListener.

Reviewers: David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",2021-07-06 16:36:01,Colin Patrick McCabe,Mixed
b32e548156f10876b2d28065fa8b4e17928d2942,"KAFKA-13023: make ""range, cooperative-sticky"" as the default assignor in V3.0 (#10903)

Set the default assignor to [""range"", ""cooperative-sticky""] to make it easier for users to switch over to cooperative rebalancing by using only a single rolling bounce.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-07-06 21:41:00,Luke Chen,Mixed
c671e44b0bebc4cf4eb04392a673d3dad9cf5f23,"MINOR: Add `KafkaAdminClient.getListOffsetsCalls` benchmark (#10955)

Reviewers: David Jacot <djacot@confluent.io>",2021-07-07 08:58:56,Jeff Kim,Not TDD
e00c0f3719ad0803620752159ef8315d668735d6,"KAFKA-12234: Implement request/response for offsetFetch batching (KIP-709) (#10962)

This implements the request and response portion of KIP-709. It updates the OffsetFetch request and response to support fetching offsets for multiple consumer groups at a time. If the broker does not support the new OffsetFetch version, clients can revert to the previous behaviour and use a request for each coordinator.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Konstantine Karantasis <konstantine@confluent.io>",2021-07-07 11:55:00,Sanjana Kaundinya,Mixed
862f814cc3a55e20a01e2d0da719b1610a634f42,"KAFKA-7613: Enable -Xlint:rawtypes for connect, fixing warnings (#8571)

Reviewers: Konstantine Karantasis <konstantine@confluent.io>",2021-07-07 17:24:31,Tom Bentley,Mixed
03890ff1d1beabcd773bf96de4f8e9462fd82a5a,"MINOR: Fix NPE from addingReplicas and removingReplicas (#10992)

Fix NPE from addingReplicas and removingReplicas. Make addingReplicas and 
removingReplicas in PartitionRecord non-nullable as described in KIP-746.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-07-07 15:39:43,David Arthur,Mixed
2b8aff58b575c199ee8372e5689420c9d77357a5,"KAFKA-10580: Add topic ID support to Fetch request (#9944)

Updated FetchRequest and FetchResponse to use topic IDs rather than topic names.
Some of the complicated code is found in FetchSession and FetchSessionHandler.
We need to be able to store topic IDs and maintain a cache on the broker for IDs that may not have been resolved. On incremental fetch requests, we will try to resolve them or remove them if in toForget.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Chia-Ping Tsai <chia7712@gmail.com>, Jun Rao <junrao@gmail.com>",2021-07-07 16:02:37,Justine Olshan,Mixed
058589b03db686803b33052d574ce887fb5cfbd1,"KAFKA-13041: Enable connecting VS Code remote debugger (#10915)

The changes in this PR enable connecting VS Code's remote debugger to a system test running locally with ducker-ak.
Changes include:
- added zip_safe=False to setup.py - this enables installing kafkatest module together with source code when running `python setup.py  develop/install`.
- install [debugpy](https://github.com/microsoft/debugpy) on ducker nodes
- expose 5678 (default debugpy port) on ducker01 node - ducker01 is the one that actually executes tests, so that's where you'd connect to.
- added `-d|--debug` option to `ducker-ak test` command - if used, tests will run via `python3.7 -m debugpy` command, which would listen on 5678 and pause until debugger is connected.
- changed the logic of the `ducker-ak test` command so that ducktape args are collected separately after `--` - otherwise any argument we add to the `test` command in the future might potentially
shadow a similar ducktape argument. 
	- we don't really check that `ducktape_args` are args while `test_name_args` are actual test names, so the difference between the two is minimal actually - most importantly we do check that `test_name_args` is not empty, but we are ok if `ducktape_args` is.

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>",2021-07-08 20:35:14,Stanislav Vodetskyi,Not TDD
ecfccb480bd57f5195ea67d23702710014ec0e1a,"KAFKA-12660; Do not update offset commit sensor after append failure (#10560)

Do not update the commit-sensor if the commit failed and add test logic. The patch also adds 2 unit tests, the first for `OFFSET_METADATA_TOO_LARGE` error, the second is to cover circumstance when one offset is committed and the other is failed with `OFFSET_METADATA_TOO_LARGE`. Both of these cases were uncovered previously.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-07-08 10:13:23,dengziming,Mixed
526fdfb97b90234b7292030d39acf3cfd798a6e2,"MINOR: the broker should use metadata.log.max.record.bytes.between.snapshots (#10990)

The broker should trigger a snapshot once
metadata.log.max.record.bytes.between.snapshots has been exceeded.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-07-09 12:00:26,Colin Patrick McCabe,Mixed
d20865ae792baa287cf9707ab6c05ea6da6be517,"KAFKA-13053; Bump kraft frame version for incompatible changes from 2.8 (#11010)

This patch bumps the default frame version for kraft records from 0 to 1. At the same time, we reset all
records versions back to 0 and we enable flexible version support for UnregisterBrokerRecord, which was
missed previously. Note that the frame version bump also affects the KIP-405 records since they are
sharing AbstractApiMessageSerde. Since these records were not part of any previous releases, this should
not cause an issue.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-07-09 12:18:34,Jason Gustafson,Not TDD
efe6029f9c2b70cebc4359913ff809b7efa31daa,"KAFKA-10675: Add schema name to ConnectSchema.validateValue() error message (#9541)

The following error message
`org.apache.kafka.connect.errors.DataException: Invalid Java object for schema type INT64: class java.lang.Long for field: ""moderate_time""`
can be confusing because java.lang.Long is acceptable type for schema INT64.

In fact, in this case `org.apache.kafka.connect.data.Timestamp` is used but this info is not logged.

Reviewers: Randall Hauch <rhauch@gmail.com>, Chris Egerton <chrise@confluent.io>, Konstantine Karantasis <k.karantasis@gmail.com>",2021-07-09 22:35:02,Alexander Iskuskov,Not TDD
5ef962ba064efd5e073310aa39ab6a9b6ae8b7c3,"KAFKA-13056; Do not rely on broker for snapshots if controller is co-resident (#11013)

When a node is serving as both broker and controller, we should only rely on the controller to write new snapshots.

Reviewers: Luke Chen <showuon@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",2021-07-10 10:47:46,Jason Gustafson,Mixed
c003cc6b35333dd687b5fa5c6d16e7c2b305d25d,"KAFKA-12677: Return not_controller error in envelope response itself in KRaft mode (#10794)

In Kafka Raft mode, the flow sending request from client to controller is like this:
1. client send request to a random controller (ex: A-controller)
2. A-controller will forward the request to active controller (ex: B-controller) to handle the request
3. After active B-controller completed the request, the A-controller will receive the response, and do a check:
  3.1. if the response has ""disconnected"" or ""NOT_CONTROLLER"" error, which means the cached active controller is changed. So, clear the cached active controller, and wait for next retry to get the updated active controller from `controllerNodeProvider`
  3.2. else, complete the request and respond back to client

In this bug, we have 2 issues existed:
1. ""NOT_CONTROLLER"" exception won't be correctly send back to the requester, instead, `UNKNOWN_SERVER_ERROR` will be returned. The reason is the `NotControllerException` is wrapped by a `CompletionException` when the `Future` completeExceptionally. And the `CompletionException` will not match any Errors we defined, so the `UNKNOWN_SERVER_ERROR` will be returned. Even if we don't want the `NotControllerException` return back to client, we need to know it to do some check.

fix 1: unwrap the `CompletionException` before encoding the exception to error.

2. Even if we fixed 1st bug, we still haven't fixed this issue. After the 1st bug fixed, the client can successfully get `NotControllerException` now, and keep retrying... until timeout. So, why won't it meet the flow `3.1` mentioned above, since it has `NotControllerException`? The reason is, we wrapped the original request with `EnvelopeRequest` and forwarded to active controller. So, after the active controller completed the request, responded with `NotControllerException`, and then, wrapped into an `EnvelopeResponse` **with no error**, and then send the `EnvelopeResponse` back. That is, in the flow `3.1`, we only got ""no error"" from `EnvelopeResponse`, not the `NotControllerException` inside.

fix 2: Make the envelope response return `NotControllerException` if the controller response has `NotControllerException`. So that we can catch the `NotControllerException` on envelopeResponse to update the active controller.

Reviewers: wenbingshen <oliver.shen999@gmail.com>, Ismael Juma <ismael@juma.me.uk>, dengziming <dengziming1993@gmail.com>, Jason Gustafson <jason@confluent.io>",2021-07-12 09:17:46,Luke Chen,Mixed
332db13047e7f2065cd698e4c2443eb550c6df17,"HOTFIX: Fix verification of version probing (#10943)

Fixes and improves version probing in system test test_version_probing_upgrade().",2021-07-12 18:50:25,Bruno Cadonna,Not TDD
2b8d41b468cc67b90f1ba0b54577ebb59e634a35,"KAFKA-13003: In kraft mode also advertise configured advertised port instead of socket port (#10935)

In Kraft mode, Apache Kafka 2.8.0 advertises the socket port instead of the configured advertised port.
A broker with the following configuration:

listeners=PUBLIC://0.0.0.0:19092,REPLICATION://0.0.0.0:9091
advertised.listeners=PUBLIC://envoy-kafka-broker:9091,REPLICATION://kafka-broker1:9091

advertises on the PUBLIC listener envoy-kafka-broker:19092, however I would expect that
envoy-kafka-broker:9091 is advertised. In ZooKeeper mode it works as expected. This PR 
changes the BrokerServer class so that in Kraft mode the configured advertised port is
registered as expected.

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2021-07-12 13:40:09,Uwe Eisele,Not TDD
a08e0cfe652dc93cbed07a8912a460d85c579dd8,"KAFKA-8410: Update the docs to reference the new PAPI (#10994)

Reviewers: Jim Galasyn <jim.galasyn@confluent.io>, Luke Chen <showuon@gmail.com>, Matthias J. Sax <mjsax@apache.org>",2021-07-13 10:23:50,John Roesler,Mixed
f97f36b650ef75841164ba01d42e02955141655a,"KAFKA-13051; Require principal builders implement `KafkaPrincipalSerde` and set default (#11011)

This patch adds a check to ensure that principal builder implementations implement `KafkaPrincipalSerde` as specified in KIP-590: https://cwiki.apache.org/confluence/display/KAFKA/KIP-590%3A+Redirect+Zookeeper+Mutation+Protocols+to+The+Controller. This patch also changes the default value of `principal.builder.class` to `DefaultKafkaPrincipalBuilder`, which was already the implicit behavior when no principal builder was specified.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2021-07-13 10:54:36,Ryan Dielhenn,Not TDD
1f64df921cb3ab3341fef014dd7dd9a199770833,"KAFKA-12983: reset needsJoinPrepare flag before rejoining the group (#10986)

The #onJoinPrepare callback is not always invoked before a member (re)joins the group, but only once when it first enters the rebalance. This means that any updates or events that occur during the join phase can be lost in the internal state: for example, clearing the SubscriptionState (and thus the ""ownedPartitions"" that are used for cooperative rebalancing) after losing its memberId during a rebalance. We should reset the needsJoinPrepare flag inside the resetStateAndRejoin() method. 

Reviewers: Guozhang Wang <guozhang@apache.org>, Jason Gustafson <jason@confluent.io>, David Jacot <djacot@confluent.io>",2021-07-13 12:14:39,A. Sophie Blee-Goldman,Not TDD
d33a874ce7971c030ba58be80d98bb2e393fe901,"KAFKA-13080: Direct fetch snapshot request to kraft controller (#11041)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-07-13 16:14:15,José Armando García Sancio,Mixed
0785aa38d22f6a71d58deca43d53975292fe3ff7,"KAFKA-13067 Add internal config to lower the metadata log segment size (#11031)

Add an internal configuration in order to facilitate system and integration tests that need a smaller
log segment size. Since this is not intended for use in production, log an ERROR message if it is
set to a non-default level.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-07-13 16:23:32,David Arthur,Mixed
8134adcf91bd20d4f9def54c8b030ff392fad616,"KAFKA-13073: Fix MockLog snapshot implementation (#11032)

Fix a simulation test failure by:

1. Relaxing the valiation of the snapshot id against the log start
offset when the state machine attempts to create new snapshot. It
is safe to just ignore the request instead of throwing an exception
when the snapshot id is less that the log start offset.

2. Fixing the MockLog implementation so that it uses startOffset both
externally and internally.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-07-13 17:06:18,José Armando García Sancio,Mixed
b80ff184f35fb1690b7d724f365ebcbf2720ece8,"KAFKA-12554: Refactor Log layer (#10280)

TL;DR:

This PR implements the details of the Log layer refactor, as outlined in this document: https://docs.google.com/document/d/1dQJL4MCwqQJSPmZkVmVzshFZKuFy_bCPtubav4wBfHQ/edit. Few details maybe different from the doc, but it is more or less the same.

STRATEGY:

In this PR, I've extracted a new class called LocalLog out of Log. Currently LocalLog is purely an implementation detail thats not exposed outside Log class (except for tests). The object encapsulation is that each Log instance wraps around a LocalLog instance.

This new LocalLog class attempts to encompass most of the responsibilities of local log surrounding the segments map, which otherwise were present in Log previously. Note that not all local log responsibilities have been moved over to this new class (yet). The criteria I used was to preserve (for now) in existing Log class, any logic that is mingled in a complex manner with the logStartOffset or the LeaderEpochCache or the ProducerStateManager.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Satish Duggana <satishd@apache.org>, Jun Rao <junrao@gmail.com>",2021-07-13 18:01:39,Kowshik Prakasam,Mixed
37d086fa2aa3aea07053304fe9758e104e6abb1a,"KAFKA-12984: make AbstractStickyAssignor resilient to invalid input, utilize generation in cooperative, and fix assignment bug (#10985)

1) Bring the generation field back to the CooperativeStickyAssignor so we don't need to rely so heavily on the ConsumerCoordinator properly updating its SubscriptionState after eg falling out of the group. The plain StickyAssignor always used the generation since it had to, so we just make sure the CooperativeStickyAssignor has this tool as well
2) In case of unforeseen problems or further bugs that slip past the generation field safety net, the assignor will now explicitly look out for partitions that are being claimed by multiple consumers as owned in the same generation. Such a case should never occur, but if it does, we have to invalidate this partition from the ownedPartitions of both consumers, since we can't tell who, if anyone, has the valid claim to this partition.
3) Fix a subtle bug that I discovered while writing tests for the above two fixes: in the constrained algorithm, we compute the exact number of partitions each consumer should end up with, and keep track of the ""unfilled"" members who must -- or might -- require more partitions to hit their quota. The problem was that members at the minQuota were being considered as ""unfilled"" even after we had already hit the maximum number of consumers allowed to go up to the maxQuota, meaning those minQuota members could/should not accept any more partitions beyond that. I believe this was introduced in #10509, so it shouldn't be in any released versions and does not need to be backported.

Reviewers: Guozhang Wang <guozhang@apache.org>, Luke Chen <showuon@gmail.com>",2021-07-13 18:29:31,A. Sophie Blee-Goldman,Mixed
eccdfcdc3a67423a1b5e72f30ed2b0ef022a5137,"KAFKA-10588; Rename kafka-console-consumer CLI command line arguments for KIP-629 (#11008)

This patch marks --whitelist as deprecated argument and introduce --include for kafka-console-consumer as described in KIP-629: https://cwiki.apache.org/confluence/display/KAFKA/KIP-629%3A+Use+racially+neutral+terms+in+our+codebase.

Reviewers: Xavier Léauté <xavier@confluent.io>, David Jacot <djacot@confluent.io>",2021-07-14 08:26:07,Omnia G H Ibrahim,Mixed
efd09c2dafb14ed8b0c93be3b35e0d4bd7a81dcb,"KAFKA-7421: Ensure Connect's PluginClassLoader and DelegatingClassLoader are truly parallel capable and resolve deadlock occurrences (#8259)

* Adds SynchronizationTest class for concurrency testing of the classloading isolation mechanism
* Adds a test which deterministically reproduced a deadlock between simultaneous upward (Plugin -> Delegating) & downward (Delegating -> Plugin) class loading operations.
* Makes PluginClassLoader parallel capable, resolving the above deadlock by allowing multiple threads to concurrently use the PluginClassLoader.
* Makes DelegatingClassLoader parallel capable to allow parallel loading of classes from the parent loader (usually the system class loader)

Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>, Tom Bentley <tbentley@redhat.com>, Randall Hauch <rhauch@gmail.com>",2021-07-14 10:38:15,Greg Harris,Not TDD
301a07f4d877ebd22e111831d5445ade3f73af14,"KAFKA-13083: Fix KRaft ISR in createPartitions, createTopics

When creating a new topic or partition via a manual partition assignment, we
must check if the nodes are unfenced before adding them to the new ISR.
We also need to reject attempts to create a new partition with all fenced
nodes.

Reviewers: David Arthur <mumrah@gmail.com>",2021-07-14 10:52:25,Colin Patrick McCabe,Mixed
f413435585a3ed735ea9d4c551aa4f4f533d6a13,"KAFKA-12925: adding presfixScan operation for missed implementations (#10877)

The new prefixScan API may still throw UnsupportedVersionOperationException due to some missing implementations in vast store hierarchy of Streams, this PR adds those missing overrides and expands the test coverage.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-07-14 15:55:50,vamossagar12,Mixed
46c91f471259357bc63dd627b54113453c206eb9,"KAFKA-13059: Make DeleteConsumerGroupOffsetsHandler unmap for COORDINATOR_NOT_AVAILABLE error (#11019)

This patch improves the error handling in `DeleteConsumerGroupOffsetsHandler`. `COORDINATOR_NOT_AVAILABLE` is not unmapped to trigger a new find coordinator request to be sent out.

Reviewers: David Jacot <djacot@confluent.io>",2021-07-15 14:18:03,Luke Chen,Mixed
df398aa71b116895ae030adb9cbb2a55d8beee7b,"KAFKA-13063: Make DescribeConsumerGroupsHandler unmap for COORDINATOR_NOT_AVAILABLE error (#11022)

This patch improve the error handling in `DescribeConsumerGroupsHandler` and ensure that `COORDINATOR_NOT_AVAILABLE` is unmapped in order to look up the coordinator again.

Reviewers: David Jacot <djacot@confluent.io>",2021-07-15 14:25:41,Luke Chen,Mixed
f7cf4a44bc928c60e1519d26ffeb4aa06a9e4133,"KAFKA-13062: Make DeleteConsumerGroupsHandler unmap for COORDINATOR_NOT_AVAILABLE error (#11021)

This patch improve the error handling in `DeleteConsumerGroupsHandler` and ensure that `COORDINATOR_NOT_AVAILABLE` is unmapped in order to look up the coordinator again.

Reviewers: David Jacot <djacot@confluent.io>",2021-07-15 14:40:21,Luke Chen,Mixed
921a3428a8f961f2931b9e2798d5b32618a791f2,"KAFKA-13072: Make RemoveMembersFromConsumerGroupHandler unmap for COORDINATOR_NOT_AVAILABLE error (#11035)

This patch improve the error handling in `RemoveMembersFromConsumerGroupHandler` and ensures that `COORDINATOR_NOT_AVAILABLE` is unmapped in order to look up the coordinator again.

Reviewers: David Jacot <djacot@confluent.io>",2021-07-15 18:03:46,Luke Chen,Mixed
3e3264760ba26e75153c655694c820a531935607,"KAFKA-10847: Remove internal config for enabling the fix (#10941)

Also update the upgrade guide indicating about the grace period KIP and its indication on the fix with throughput impact.

Reviewers: Luke Chen <showuon@gmail.com>, Matthias J. Sax <mjsax@apache.org>",2021-07-15 10:58:15,Guozhang Wang,Not TDD
e07de97a4ce730a2755db7eeacb9b3e1f69a12c8,"KAFKA-12803: Support reassigning partitions when in KRaft mode (#10753)

Support the KIP-455 reassignment API when in KRaft mode. Reassignments
which merely rearrange partitions complete immediately. Those that only
remove a partition complete immediately if the ISR would be non-empty
after the specified removals. Reassignments that add one or more
partitions follow the KIP-455 pattern of adding all the adding replicas
to the replica set, and then waiting for the ISR to include all the new
partitions before completing. Changes to the partition sets are
accomplished via PartitionChangeRecord.

Reviewers: Jun Rao <junrao@gmail.com>",2021-07-15 11:41:51,Colin Patrick McCabe,Mixed
584213ed20d679b11206b67c5a65035347632f07,"Fix perf regression on LISR requests by asynchronously flushing the partition.metadata file (#11056)

After noticing increased LISR times, we discovered a lot of time was spent synchronously flushing the partition metadata file. This PR changes the code so we asynchronously flush the files.

We ensure files are flushed before appending, renaming or closing the log to ensure we have the partition metadata information on disk. Three new tests have been added to address these cases.

Reviewers:  Lucas Bradstreet <lucas@confluent.io>, Jun Rao <junrao@gmail.com>",2021-07-15 14:00:32,Justine Olshan,Mixed
4fd6d2bec8a6249e211b9769e887cc24d5cf1444,"KAFKA-13064: Make ListConsumerGroupOffsetsHandler unmap for COORDINATOR_NOT_AVAILABLE error (#11026)

This patch improve the error handling in `ListConsumerGroupOffsetsHandler` and ensures that `COORDINATOR_NOT_AVAILABLE` is unmapped in order to look up the coordinator again.

Reviewers: David Jacot <djacot@confluent.io>",2021-07-16 09:58:57,Luke Chen,Mixed
13b2df733a963963b0275266eed2b5e156cd56a0,"MINOR: Default GRACE with Old API should set as 24H minus window-size / inactivity-gap (#10953)

In 2.8 and before, we computed the default grace period with Math.max(maintainDurationMs - sizeMs, 0); in method gracePeriodMs() in TimeWindows, SessionWindows, and JoinWindows. That means that the default grace period has never been 24 hours but 24 hours - window size. Since gracePeriodMs() is used to compute the retention time of the changelog topic for the corresponding window state store and the segments for the window state store it is important to keep the same computation for the deprecated methods. Otherwise, Streams app that run with 2.8 and before might not be compatible with Streams 3.0 because the retention time of the changelog topics created with older Streams apps will be smaller than the assumed retention time for Streams apps in 3.0. For example, with a window size of 10 hours, an old Streams app would have created a changelog topic with retention time 10 hours (window size) + 14 hours (default grace period, 24 hours - 10 hours). A 3.0 Streams app would assume a retention time of 10 hours (window size) + 24 hours (deprecated default grace period as currently specified on trunk). In the presence of failures, where a state store needs to recreated, records might get lost, because before the failure the state store of a 3.0 Streams app contained 10 hours + 24 hours of records whereas the changelog topic that was created with the old Streams app would only contain 10 hours + 14 hours of records.

All this happened due to us always stating that the default grace period was 24 hours although it was not completely correct and a connected and unfortunate misunderstanding when we removed deprecated windows APIs (#10378).

Co-authors: Bruno Cadonna <cadonna@apache.org>
Reviewers: Luke Chen <showuon@gmail.com>, Matthias J. Sax <mjsax@apache.org>, Bruno Cadonna <cadonna@apache.org>",2021-07-16 11:22:26,Guozhang Wang,Mixed
3e38038278e8c6bb9c59432bedc81a06bc10d1de,"HOTFIX: Init stream-stream left/outer join emit interval correctly (#11055)

Follow up to #10917

The fix from #10917 intended to reduce the emit frequency to save the creation cost of RocksDB iterators. However, we incorrectly initialized the ""timer"" with timestamp zero, and thus, the timer was always in the past and we did try to emit left/outer join result too often.

This PR fixes the initialization of the emit interval timer to current wall-clock time to effectively 'enable' the fix from #10917.

Reviewers: Sergio Peña <sergio@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2021-07-16 13:30:19,Matthias J. Sax,Not TDD
b5cb02b2883d25b4a39f99e8ac16450a92b13e02,"KAFKA-13090: Improve kraft snapshot integration test

Check and verify generated snapshots for the controllers and the
brokers. Assert reader state when reading last log append time.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-07-16 14:10:52,José Armando García Sancio,Not TDD
762d11c13f1f4dc8e5a82f9bbed88582dcb045f4,"MINOR: ducktape should start brokers in parallel and support co-located kraft

This patch adds a sanity-check bounce system test for the case where we have 3
co-located KRaft controllers and fixes the system test code so that this case
will pass by starting brokers in parallel by default instead of serially. We
now also send SIGKILL to any running KRaft broker or controller nodes for the
co-located case when a majority of co-located controllers have been stopped --
otherwise they do not shutdown, and we spin for the 60 second timeout. Finally,
this patch adds the ability to specify that certain brokers should not be
started when starting the cluster, and then we can start those nodes at a later
time via the add_broker() method call; this is going to be helpful for KRaft
snapshot system testing.

We were not testing the 3 co-located KRaft controller case previously, and it
would not pass because the first Kafka node would never be considered started.
We were starting the Kafka nodes serially, and we decide that a node has
successfully started when it logs a particular message. This message is not
logged until the broker has identified the controller (i.e. the leader of the
KRaft quorum). There cannot be a leader until a majority of the KRaft quorum
has started, so with 3 co-located controllers the first node could never be
considered ""started"" by the system test.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-07-16 16:28:09,Ron Dagostino,Not TDD
a24dbba1e566080a8ad734c68ef1f0e1839ee8c8,"MINOR: make sure alterAclsPurgatory is closed when controller server … (#10868)

Reviewers:  Ismael Juma <ismael@juma.me.uk>",2021-07-17 14:52:37,Chia-Ping Tsai,Mixed
a46b82bea9abbd08e550d985f87e79a6d912a9ab,"KAFKA-12944: Assume message format version is 3.0 when inter-broker protocol is 3.0 or higher (KIP-724) (#11036)

Also:
* Deprecate `log.message.format.version` and `message.format.version`.
* Log broker warning if the deprecated config values are ignored due to
the inter-broker protocol version.
* Log warning if `message.format.version` is set via `ConfigCommand`.
* Always down-convert if fetch version is v3 or lower.
* Add tests to verify new message format version based on the
inter-broker protocol version.
* Adjust existing tests that create topics with an older message format to
have the inter-broker protocol set to 2.8.
* Add upgrade note.

Note that the log compaction change to always write new segments with
record format v2 if the IBP is 3.0 or higher will be done as part of
KAFKA-13093 (with Kafka 3.1 as the target release version).

Reviewers: David Jacot <djacot@confluent.io>, David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",2021-07-19 05:37:16,Ismael Juma,Mixed
f7790a067586e39df09cf8b4b8ab99baa74c055f,"KAFKA-13058; AlterConsumerGroupOffsetsHandler does not handle partition errors correctly. (#11016)

This patch updates `AlterConsumerGroupOffsetsHandler` to handle partition errors correctly. The issue is that any partition error fails the entire future instead of being passed as an error for its corresponding partition. 

Reviewers: Luke Chen <showuon@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2021-07-19 16:48:03,David Jacot,Mixed
e8ce93bd5310229ffd49cc42af49ee3a4368d014,"KAFKA-9555 Added default RLMM implementation based on internal topic storage. (#10579)

KAFKA-9555 Added default RLMM implementation based on internal topic storage.

This is the initial version of the default RLMM implementation.
This includes changes containing default RLMM configs, RLMM implementation, producer/consumer managers.
Introduced TopicBasedRemoteLogMetadataManagerHarness which takes care of bringing up a Kafka cluster and create remote log metadata topic and initializes TopicBasedRemoteLogMetadataManager.
Refactored existing RemoteLogMetadataCacheTest to RemoteLogSegmentLifecycleTest to have parameterized tests to run both RemoteLogMetadataCache and also TopicBasedRemoteLogMetadataManager.
Refactored existing InmemoryRemoteLogMetadataManagerTest, RemoteLogMetadataManagerTest to have parameterized tests to run both InmemoryRemoteLogMetadataManager and also TopicBasedRemoteLogMetadataManager.

This is part of tiered storage KIP-405 efforts.

Reviewers: Kowshik Prakasam <kprakasam@confluent.io>, Cong Ding <cong@ccding.com>, Jun Rao <junrao@gmail.com>",2021-07-19 09:05:46,Satish Duggana,Mixed
b6159042c0f9bd84bc248dc1e291b9cc70157811,"KAFKA-12598: ConfigCommand should only support communication via ZooKeeper for a reduced set of cases (#10811)

Checked the documentation, we must use `--zookeeper` option in 3 places (alter and describe):
1. user configs where the config is a SCRAM mechanism name (i.e. a SCRAM credential for a user)
2. update broker configs for a particular broker when that broker is down
3. broker default configs when all brokers are down

Reference:
1. [config SCRAM Credentials](https://kafka.apache.org/documentation/#security_sasl_scram_credentials)
2. [Update config before broker started](https://kafka.apache.org/documentation/#dynamicbrokerconfigs)

So, after this PR, we only support `--zookeeper` on `users` and `brokers` entity. Add some argument parse rules and tests. 

Reviewers: Ron Dagostino <rdagostino@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2021-07-19 18:53:14,Luke Chen,Mixed
69a4661d7a7578789f4752928622c010b2264565,"KAFKA-13100: Create KRaft controller snapshot during promotion (#11084)

The leader assumes that there is always an in-memory snapshot at the last
committed offset. This means that the controller needs to generate an in-memory
snapshot when getting promoted from inactive to active.  This PR adds that
code. This fixes a bug where sometimes we would try to look for that in-memory
snapshot and not find it.

The controller always starts inactive, and there is no requirement that there
exists an in-memory snapshot at the last committed offset when the controller
is inactive. Therefore we can remove the initial snapshot at offset -1.

We should also optimize when a snapshot is cancelled or completes, by deleting
all in-memory snapshots less that the last committed offset.

SnapshotRegistry's createSnapshot should allow the creating of a snapshot if
the last snapshot's offset is the given offset. This allows for simpler client
code. Finally, this PR renames createSnapshot to getOrCreateSnapshot.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-07-20 10:13:01,José Armando García Sancio,Mixed
030caec096d6d2bbab2545d1b748847451ef8d35,"MINOR: Handle some null cases in BrokerMetadataPublisher (#11029)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",2021-07-20 14:10:14,David Arthur,Mixed
0314801a8e67a96f8cdea85bf55cb5bed808fc34,"KAFKA-9887 fix failed task or connector count on startup failure (#8844)

Moved the responsibility for recording task and connector startup and failure metrics from the invocation code
into the status listener. The reason behind this is that the WorkerTasks (and subclasses) were either not propagating exceptions upwards, or were unable to do so easily because they were running on completely different threads.

Also split out WorkerMetricsGroup from being an inner class into being a standard class. This was to make sure
the Data Abstraction Count checkStyle rule was not violated.

Author: Michael Carter <michael.carter@instaclustr.com>
Reviewers: Chris Egerton <chrise@confluent.io>, Randall Hauch <rhauch@gmail.com>",2021-07-20 17:39:26,Michael Carter,Mixed
6dd425e276497f7e22109d94c0d0a57e7fc65ce5,"MINOR: Validate the KRaft controllerListener config on startup (#11070)

Reviewers: Colin P. McCabe <cmccabe@apache.org>, David Arthur <mumrah@gmail.com>",2021-07-21 10:41:41,Niket,Mixed
02dc615c1e2139e1bc92bf2284fda2c740152a0e,"KAFKA-13096: Ensure queryable store providers is up to date after adding stream thread (#10921)

When a new thread is added the queryable store providers continues to use the store providers it was given when KafkaStreams was instantiated. This means IQ will start performing lookups against an out-of-date list of threads, and may eventually become completely broken. We must make sure the QueryableStoreProvider is updated when threads are added and removed.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-07-21 13:23:15,Phil Hardwick,Mixed
57866bd588074b11ccddc38cabb7d3d84e590405,"MINOR: Rename the @metadata topic to __cluster_metadata #11102

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-07-21 17:30:35,Niket,Mixed
f959e6c58309a31b88f47263a9ea144d94f6b24a,"KAFKA-13129: replace describe topic via zk with describe users (#11115)

Replace the unsupported describe topic via zk with describe users to fix the system tests.
For the upgrade_test case where TLS support is not required, use list_acls instead.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-07-23 05:33:43,Luke Chen,Not TDD
d998cbcc886c82d5fc4081cda0908aa386e856c5,"KAFKA-8529; Flakey test ConsumerBounceTest#testCloseDuringRebalance (#11097)

When the replica fetcher receives a top-level error in the fetch response, it marks all partitions are failed and adds a backoff delay before resuming fetching from them. In addition to this, there is an additional backoff enforced after the top-level error is handled, so we end up waiting twice the configured backoff time before resuming. This patch removes this extra backoff.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-07-23 09:30:55,Justine Olshan,Mixed
f34bb28ab6c69945d944abc1283cacecdaf4ef8e,"KAFKA-13116: Fix message_format_change_test and compatibility_test_new_broker_test failures (#11108)

These failures were caused by a46b82bea9abbd08e5. Details for each test:

* message_format_change_test: use IBP 2.8 so that we can write in older message
formats.
* compatibility_test_new_broker_test_failures: fix down-conversion path to handle
empty record batches correctly. The record scan in the old code ensured that
empty record batches were never down-converted, which hid this bug.
* upgrade_test: set the IBP 2.8 when message format is < 0.11 to ensure we are
actually writing with the old message format even though the test was passing
without the change.

Verified with ducker that some variants of these tests failed without these changes
and passed with them. Also added a unit test for the down-conversion bug fix.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-07-23 13:43:31,Ismael Juma,Not TDD
a75997f2794926332baa99eea5de9aa18c213031,"KAFKA-13127; Fix stray topic partition deletion for kraft (#11118)

This patch fixes BrokerMetadataPublisher.findGhostReplicas (renamed to findStrayPartitions)
so that it returns the stray partitions. Previously it was returning the non-stray partitions. This
caused all of these partitions to get deleted on startup by mistake.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, José Armando García Sancio <jsancio@gmail.com>",2021-07-23 15:01:39,Jason Gustafson,Mixed
b69027726eee1be6e20c9f16d271d6948dc13224,"MINOR: Remove redundant fields in dump log record output (#11101)

In 2.8, the dump log output regressed to print batch level information for each record, which makes the output much noisier. This patch changes the output to what it was in 2.7 and previous versions. We only print batch metadata at the batch level.

Reviewers: David Arthur <mumrah@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2021-07-23 15:56:41,Jason Gustafson,Mixed
7fbc6b73aa5d194948b30a00074cd0f79365694d,"KAFKA-13021: clarify KIP-633 javadocs and address remaining feedback (#11114)

There were a few followup things to address from #10926, most importantly a number of updates to the javadocs. Also includes a few missing verification checks.

Reviewers: Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <mjsax@apache.org>, Israel Ekpo",2021-07-23 16:14:37,A. Sophie Blee-Goldman,Mixed
dc512cc038e554f1abf1fbfe6b79b27fe637471b,"KAFKA-13015: Ducktape System Tests for Metadata Snapshots (#11053)

This PR implements system tests in ducktape to test the ability of brokers and controllers to generate
and consume snapshots and catch up with the metadata log.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, José Armando García Sancio <jsancio@gmail.com>",2021-07-23 16:28:21,Niket,Not TDD
9baf5eb67b2a9086cb7c083a766d291ea0ba9fb7,"KAFKA-13008: Try to refresh end offset when partitionLag returns empty (#11057)

1. When listOffset result is retrieved inside Fetcher, check if the partitions are part of the subscriptions of the consumer; if yes update the corresponding LSO or HW based on the isolation level.
2. When partitionLag cannot return result since the log end offset (LSO/HW) is not known, send an async list offset which would be completed by other calls polling (also the hb thread may complete it as well), and hope the next partitionLag would get the result.
3. Keep track of list-offset request sent at the subscription state level so that frequent currentLag calls would not cause excessive list-offset requests.

Then on the streams side, the first partitionLag would still return empty, but soon enough the subsequent partitionLag should return data and we would not wait for the fetch response to update fetched state.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, John Roesler <vvcephei@apache.org>",2021-07-23 16:46:10,Guozhang Wang,Mixed
55d9acad65826176595bf7f9242524bda1985ba9,"KAFKA-13113; Support unregistering Raft listeners (#11109)

This patch adds support for unregistering listeners to `RaftClient`. 

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Jason Gustafson <jason@confluent.io>",2021-07-23 21:54:44,José Armando García Sancio,Mixed
8ed271e1fd7b64a7731df3accaf3f3a0ca333efe,"KAFKA-13026: Idempotent producer (KAFKA-10619) follow-up testings (#11002)

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2021-07-26 21:45:59,Cheng Tan,Not TDD
f6f6e52c7416e8bacef4b5fc265dc1aa0ff52520,"KAFKA-13139: Empty response after requesting to restart a connector without the tasks results in NPE (#11132)

Even after the implementation of KIP-745 it makes sense to return a response code of 204 NO CONTENT when the request is to restart the connector but not the tasks. 

This maintains the current behavior for this existing REST call and is also aligned with the description in the RFC: 
https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10.2.5

Reviewers: Kalpesh Patel <kpatel@confluent.io>, Randall Hauch <rhauch@gmail.com>",2021-07-27 13:47:16,Konstantine Karantasis,Mixed
c5ec390fa6fded24dee5d699a0ec87a5345a4e99,"KAFKA-13099; Transactional expiration should account for max batch size (#11098)

When expiring transactionalIds, we group the tombstones together into batches. Currently there is no limit on the size of these batches, which can lead to `MESSAGE_TOO_LARGE` errors when a bunch of transactionalIds need to be expired at the same time. This patch fixes the problem by ensuring that the batch size respects the configured limit. Any transactionalIds which are eligible for expiration and cannot be fit into the batch are postponed until the next periodic check.

Reviewers: David Jacot <djacot@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2021-07-27 18:23:00,Jason Gustafson,Mixed
fe0fe686e92d019ac2b5c8407ab2cbb55ae069e1,"KAFKA-13141; Skip follower fetch offset update in leader if diverging epoch is present (#11136)

Reviewers: Jason Gustafson <jason@confluent.io>",2021-07-28 17:27:26,Rajini Sivaram,Mixed
fd36e5a8b657b0858dbfef4ae9706bf714db4ca7,"KAFKA-12851: Fix Raft partition simulation (#11134)

Instead of waiting for a high-watermark of 20 after the partition, the
test should wait for the high-watermark to reach an offset greater than
the largest log end offset at the time of the partition. Only that offset
is guarantee to be reached as the high-watermark by the new majority.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-07-28 09:28:56,José Armando García Sancio,Not TDD
4710a491463a91ec12c670ea50c139fc14134e80,"KAFKA-12648: Pt. 2 - Introduce TopologyMetadata to wrap InternalTopologyBuilders of named topologies (#10683)

Pt. 1: #10609
Pt. 2: #10683
Pt. 3: #10788

The TopologyMetadata is next up after Pt. 1 #10609. This PR sets up the basic architecture for running an app with multiple NamedTopologies, though the APIs to add/remove them dynamically are not implemented until Pt. 3

Reviewers: Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",2021-07-28 11:18:56,A. Sophie Blee-Goldman,Mixed
3190ebd1e604b480ea5bdb7be2d8c269cccc415e,"KAFKA-10542: Migrate KTable mapValues, passthrough, and source to new Processor API (#11099)

As part of the migration of KStream/KTable operations to the new Processor API (KAFKA-8410), this PR includes the migration of KTable:
* mapValues,
* passthrough,
* and source operations.

Reviewers: John Roesler <vvcephei@apache.org>",2021-07-28 20:58:15,Jorge Esteban Quilcate Otoya,Mixed
976409ee081b5a4e5edfe73b5d597998feb2f402,"KAFKA-13137; KRaft Controller Metric MBean names incorrectly quoted (#11131)

Controller metric names that are in common between the ZooKeeper-based and KRaft-based controller must remain the same, but they were not in the AK 2.8 early access release of KRaft. For example, the non-KRaft MBean name `kafka.controller:type=KafkaController,name=OfflinePartitionsCount` incorrectly became `""kafka.controller"":type=""KafkaController"",name=""OfflinePartitionCount""` (note the added quotes and the lack of plural).  This patch fixes the issues, closes the test gap that allowed the divergence to occur, and adds de-registration logic to remove the metrics when the controller is closed (this logic was missing).

Reviewers: Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",2021-07-29 13:01:19,Ron Dagostino,Mixed
bebb9aeb9cc493d8acc475273c1c1c34a6a484d5,"KAFKA-13132; Ensure topicId is updated on replicas even when the leader epoch is unchanged (#11126)

In 3.0, there was a change that resulted in no longer assigning topic IDs to the log and the partition.metadata file in certain upgrade scenarios, specifically when upgrading from IBP 2.7 or below to 3.0. In this case, there may not be a bump to the leader epoch when the topicId is assigned by the controller, so the LeaderAndIsr request from the controller would be ignored by the replica. This PR fixes the problem by adding a check for whether we need to handle the LeaderAndIsr request given a new topic ID when one is not yet assigned in the log and code to assign a topic ID when the log is already associated to a partition in ReplicaManager.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-07-29 14:36:44,Justine Olshan,Mixed
22541361b7c62913bc848fb03e5f807e152a1023,"Add support for infinite endpoints for range queries (#11120)

Add support to open endpoint range queries in key-value stores

Implements: KIP-763

Reviewers: Almog Gavra <almog@confluent.io>, Luke Chen <showuon@gmail.com>, John Roesler <vvcephei@apache.org>",2021-07-29 21:52:16,Patrick Stuedi,Mixed
5d52de2ccfaebc8d4f8d6ff247b86a2830eb1c8b,"KAFKA-12648: minor followup from Pt. 2 and some new tests (#11146)

Addresses the handful of remaining feedback from Pt. 2, plus adds two new tests: one verifying a multi-topology application with a FKJ and its internal topics, another to make sure IQ works with named topologies (though note that there is a bit more work left for IQ to be fully supported, will be tackled after Pt. 3

Reviewers: Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",2021-07-30 10:56:57,A. Sophie Blee-Goldman,Not TDD
8a1fcee86e42c8bd1f26309dde8748927109056e,"MINOR: Use time constant algorithms when comparing passwords or keys (#10978)

Author: Randall Hauch <rhauch@gmail.com>
Reviewers: Manikumar Reddy <manikumar@confluent.io>, Rajini Sivaram <rajinisivaram@gmail.com>, Mickael Maison <mickael.maison@gmail.com>, Ismael Juma <ijuma@apache.org>",2021-07-30 17:48:03,Randall Hauch,Mixed
4efd9bf0cfde34b2438fdb013581f57cfc51cae1,"KAFKA-13114; Revert state and reregister raft listener (#11116)

RaftClient's scheduleAppend may split the list of records into multiple
batches. This means that it is possible for the active controller to
see a committed offset for which it doesn't have an in-memory snapshot.

If the active controller needs to renounce and it is missing an
in-memory snapshot, then revert the state and reregister the Raft
listener. This will cause the controller to replay the entire metadata
partition.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-08-01 15:26:04,José Armando García Sancio,Mixed
b980ca8709dbef31890a84de02ccf277af5743c7,"KAFKA-12158; Better return type of RaftClient.scheduleAppend (#10909)

This patch improves the return type for `scheduleAppend` and `scheduleAtomicAppend`. Previously we were using a `Long` value and using both `null` and `Long.MaxValue` to distinguish between different error cases. In this PR, we change the return type to `long` and only return a value if the append was accepted. For the error cases, we instead throw an exception. For this purpose, the patch introduces a couple new exception types: `BufferAllocationException` and `NotLeaderException`.

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",2021-08-02 14:47:03,dengziming,Mixed
79788ca042330faea7dc736f1f6ceb75b3f4d1d9,"KAFKA-12305: Fix Flatten SMT for array types (#10074)

Reviewers: Nigel Liang <nigel@nigelliang.com>, Tom Bentley <tbentley@redhat.com>",2021-08-03 13:53:54,Chris Egerton,Mixed
4eb72add11b548e3fe8fea72856af49dc950e444,"MINOR: Replace EasyMock with Mockito in test-utils module (#11157)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2021-08-03 17:26:46,dengziming,Not TDD
a103c95a31ee276e936669438828bdb6e73d5f14,"KAFKA-12724: Add 2.8.0 to system tests and streams upgrade tests. (#10602)

Also adjusted the acceptable recovery lag to stabilize Streams tests.

Reviewers: Justine Olshan <jolshan@confluent.io>, Matthias J. Sax <mjsax@apache.org>, John Roesler <vvcephei@apache.org>",2021-08-04 17:31:10,Kamal Chandraprakash,Not TDD
fccaa5c389f01485d32603063443096b1dded689,"KAFKA-13167; KRaft broker should send heartbeat immediately after starting controlled shutdown (#11177)

Controlled shutdown in KRaft is signaled through a heartbeat request with the `shouldShutDown` flag set to true. When we begin controlled shutdown, we should immediately schedule the next heartbeat instead of waiting for the next periodic heartbeat. This allows the broker to shutdown more quickly.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-08-04 15:58:34,Jason Gustafson,Mixed
d6f6edd2b17cbaccd4c87bfa66f871a676760044,KAFKA-13168: KRaft observers should not have a replica id (#11178),2021-08-05 11:18:41,Ryan Dielhenn,Mixed
001afa8ebec2a1b5fd05319b02f7d3eb6410ab8e,"KAFKA-13046: add test coverage for AbstractStickyAssignorTest (#11156)

1) Add tests for partitionsTransferringOwnership
  a. it should include revoked partitions and partitions claimed by multiple consumers.
  b. for non-equal assignment case (general case), it should be null so that the cooperative assignor knows to compute it from scratch

2) Small optimization for allPreviousPartitionsToOwner check.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-08-05 13:26:18,Luke Chen,Mixed
e5df7fd90b9e9a8ad7edd635ca9bb9d0511f2ffe,"MINOR: Should commit a task if the consumer position advanced as well (#11151)

Reviewers: John Roesler <vvcephei@apache.org>",2021-08-05 13:41:46,Guozhang Wang,Mixed
04023d49fd4ecdbd1cc05c442b04277de3334ee4,"KAFKA-13132; Upgrading to topic IDs in LISR requests has gaps introduced in 3.0 (part 2) (#11171)

Most of [KAFKA-13132](https://issues.apache.org/jira/browse/KAFKA-13132) has been resolved, but there is one part of one case not covered.
From the ticket:
`2. We only assign the topic ID when we are associating the log with the partition in replicamanager for the first time`

We covered the case where the log is already existing when the leader epoch is _equal_ (ie, no updates besides the topic ID), but we don't cover the update case where the leader epoch is bumped and we already have the log associated to the partition. 

This PR ensures we correctly assign topic ID in the makeLeaders/Followers path when the log already exists.
I've also added a test for the bumped leader epoch scenario.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-08-05 18:10:48,Justine Olshan,Not TDD
6854eb8332d6ef1f1c6216d2f67d6e146b1ef60f,"KAFKA-12648: Pt. 3 - addNamedTopology API (#10788)

Pt. 1: #10609
Pt. 2: #10683
Pt. 3: #10788

In Pt. 3 we implement the addNamedTopology API. This can be used to update the processing topology of a running Kafka Streams application without resetting the app, or even pausing/restarting the process. It's up to the user to ensure that this API is called on every instance of an application to ensure all clients are able to run the newly added NamedTopology. 

Reviewers: Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",2021-08-06 00:18:27,A. Sophie Blee-Goldman,Mixed
83f0ae3821033d6c564c6df0d55c06e8642bf231,"KAFKA-12862: Update Scala fmt library and apply fixes (#10784)

Updates the scala fmt to the latest stable version.
Applies all the style fixes (all source code changes are done by scala 
fmt).
Removes setting about dangling parentheses as `true` is already the
default.

Reviewer: John Roesler <john@confluent.io>",2021-08-09 12:05:31,Josep Prat,Not TDD
89f1bea39bdab1e93898480434b041414c102461,"KAFKA-13165: Validate KRaft node id, process role and quorum voters (#11179)

Validate that KRaft controllers are members of the KRaft quorum, and non-controllers are not.
This validation assumes that controllers and brokers have the same ID only when they are
co-located.

Reviewers: David Arthur <mumrah@gmail.com>, José Armando García Sancio <jsancio@gmail.com>, Luke Chen <showuon@gmail.com>",2021-08-09 12:57:23,Ryan Dielhenn,Mixed
9565a529e08d7aa36beac02c8e6115bcc87d2dc7,"KAFKA-12779: rename namedTopology in TaskId to topologyName #11192

Update to KIP-740.

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Konstantine Karantasis <konstantine@confluent.io>, Israel Ekpo <israelekpo@gmail.com>",2021-08-09 15:19:21,Walker Carlson,Mixed
0837fba997f480629172e752036cd1dce00a0c7a,"KAFKA-13161; Update replica partition state and replica fetcher state on follower update (#11189)

When processing the topics delta, make sure that the replica manager partition state and replica fetcher state matches the information included in the topic delta. Also ensure that delayed operations are processed after the follower state change has been made since that is what allows them to be completed.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-08-10 12:06:30,José Armando García Sancio,Mixed
35ebdd7ed0f271d52289903dcadce4bf82ab5a39,"MINOR: Fix flaky shouldCreateTopicWhenTopicLeaderNotAvailableAndThenTopicNotFound (#11155)

1. This test is taking two iterations since the firs iteration is designed to fail due to unknow topic leader. However both the timeout and the backoff are set to 50ms, while the actual SYSTEM time is used. This means we are likely to timeout before executing the second iteration. I thought about using a mock time but dropped that idea as it may forgo the purpose of this test, instead I set the backoff time to 10ms so that we are almost unlikely to hit this error anymore.

2. Found a minor issue while fixing this which is that when we have non-empty not-ready topics, but the topics-to-create is empty (which is possible as the test shouldCreateTopicWhenTopicLeaderNotAvailableAndThenTopicNotFound itself illustrates), we still call an empty create-topic function. Though it does not incur any round-trip it would still waste some cycles, so I branched it off and hence also simplified some unit tests.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Bruno Cadonna <cadonna@confluent.io>",2021-08-10 12:27:44,Guozhang Wang,Mixed
2bfd0ae2e91827518a9e31092b0940d74d1a29f0,"MINOR: update the branch(split) doc and java doc and tests (#11195)

Reviewers: Ivan Ponomarev <iponomarev@mail.ru>, Matthias J. Sax <matthias@confluent.io>",2021-08-10 13:37:59,Luke Chen,Not TDD
b1b872bd4eac979159a0fa7ec25a124973dc7314,"KAFKA-13173; Ensure KRaft controller handles concurrent broker expirations correctly (#11191)

Prior to this patch, the controller did not accumulate ISR/leader changes correctly when multiple broker's sessions expired at the same time. This patch fixes the problem by having the controller handle one expiration at a time.

Reviewers: Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",2021-08-12 09:38:44,Niket,Mixed
db1f581da7f3440cfd5be93800b4a9a2d7327a35,"KAFKA-13068: Rename Log to UnifiedLog (#11154)

In this PR, I've renamed kafka.log.Log to kafka.log.UnifiedLog. With the advent of KIP-405, going forward the existing Log class would present a unified view of local and tiered log segments, so we rename it to UnifiedLog. The motivation for this PR is also the same as outlined in this design document: https://docs.google.com/document/d/1dQJL4MCwqQJSPmZkVmVzshFZKuFy_bCPtubav4wBfHQ/edit.
This PR is a follow-up to #10280 where we had refactored the Log layer introducing a new kafka.log.LocalLog class.

Note: the Log class name had to be hardcoded to ensure metrics are defined under the Log class (for backwards compatibility). Please refer to the newly introduced UnifiedLog.metricName() method.

Reviewers: Cong Ding <cong@ccding.com>, Satish Duggana <satishd@apache.org>, Jun Rao <junrao@gmail.com>",2021-08-12 16:10:19,Kowshik Prakasam,Mixed
64b8e17827251174490678dd296ce2c1a79ff5ef,"KAFKA-13194: bound cleaning by both LSO and HWM when firstUnstableOffsetMetadata is None (#11199)

When the high watermark is contained in a non-active segment, we are not correctly bounding it by the hwm. This means that uncommitted records may overwrite committed data. I've separated out the bounding point tests to check the hwm case in addition to the existing active segment case.

Reviewers: Jun Rao <junrao@gmail.com>",2021-08-13 15:35:59,Lucas Bradstreet,Mixed
38fd06146cf83ffc7187817dc983ef9a52de78fe,"MINOR: clarify assertion in handleListPartitionReassignmentsRequest #11219

Reviewers: Colin P. McCabe <cmccabe@apache.org>, José Armando García Sancio <jsancio@gmail.com>, Ron Dagostino <rndgstn@gmail.com>",2021-08-16 11:59:09,dengziming,Mixed
bbf1ee74d719494ed5a5cac9dc54b7093171707c,"KAFKA-13207: Skip truncation on fetch response with diverging epoch if partition removed from fetcher (#11221)

AbstractFetcherThread#truncateOnFetchResponse is used with IBP 2.7 and above to truncate partitions based on diverging epoch returned in fetch responses. Truncation should only be performed for partitions that are still owned by the fetcher and this check should be done while holding partitionMapLock to ensure that any partitions removed from the fetcher thread are not truncated. Truncation will be performed by any new fetcher that owns the partition when it restarts fetching.

Reviewers: David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>",2021-08-17 17:12:51,Rajini Sivaram,Mixed
9bcf4a525b9a08b1d0a5f8c134c46f70c84692a0,"KAFKA-13198: Stop replicas when reassigned (#11216)

Stop the replica and resign the coordinators when a replica gets reassigned away from a topic partition.

1. Implement localChanges in TopicsDelta and TopicDelta to return all of the partitions that were deleted, became leader and became follower for the given broker id.
2. Add tests for TopicsDelta::localChanges
3. Resign coordinators that were moved away from the consumer offset and transaction topic partitions.
4. Add replica manager tests for testing reassignment of replicas and removal of topic.
5. Add a new type LocalReplicaChanges that encapsulates topic partitions deleted, became leader and became follower.

Reviewers: Jun Rao <junrao@gmail.com>",2021-08-17 13:10:03,José Armando García Sancio,Mixed
8bc4c334e36ac6fafe6e1d4a468da713336447e3,"KAFKA-13204: assignor name conflict check (#11217)

Add the partition assignor name conflicting check to avoid the wrong assignor being used. 

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-08-18 17:23:29,Luke Chen,Mixed
45ecaa19f8ded255eff9b31ca5e586ca08cf3d3d,"MINOR: Set session timeout back to 10s for Streams system tests (#11236)

We increased the default session timeout to 30s in KIP-735:
https://cwiki.apache.org/confluence/display/KAFKA/KIP-735%3A+Increase+default+consumer+session+timeout

Since then, we are observing sporadic system test failures
due to rebalances taking longer than the test timeout.
Rather than increase the test wait times, we can just override
the session timeout to a value more appropriate in the testing
domain.

Reviewers: A. Sophie Blee-Goldman <ableegoldman@apache.org>",2021-08-20 11:27:54,John Roesler,Not TDD
26ee78f392386862e0a125cdb9c040fda13f5604,"KAFKA-13091; Ensure high watermark incremented after AlterIsr returns (#11245)

After we have shrunk the ISR, we have an opportunity to advance the high watermark. We do this currently in `maybeShrinkIsr` after the synchronous update through ZK. For the `AlterIsr` path, however, we cannot rely on this call since the request is sent asynchronously. Instead we should attempt to advance the high watermark in the callback when the `AlterIsr` response returns successfully.

Reviewers: David Jacot <djacot@confluent.io>",2021-08-23 11:07:39,Jason Gustafson,Mixed
a594747d7566b28e3599c1940cb4c98ca9816dca,"HOTFIX: Fix null pointer when getting metric value in MetricsReporter (#11248)

The alive stream threads metric relies on the threads field as a monitor object for
its synchronized block. When the alive stream threads metric is registered it isn't
initialised so any call to get the metric value before it is initialised will result
in a null pointer exception.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Walker Carlson <wcarlson@confluent.io>",2021-08-23 13:21:38,Phil Hardwick,Not TDD
bc3972c9f3e8c6d92e2154501bf18ebcb1a93f64,"KAFKA-13219: BrokerState metric not working for KRaft clusters (#11239)

The BrokerState metric always has a value of 0, for NOT_RUNNING, in KRaft
clusters. This patch fixes it and adds a test.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-08-23 13:45:44,Ron Dagostino,Mixed
0fe4e24c095f57606a9c33a3135f2f81a1fb0285,"KAFKA-12840; Removing `compact` cleaning on a topic should abort on-going compactions (#11230)

This patch ensure that on-going compaction is aborted when `compact` is removed from the `cleanup.policy` of a topic.

Reviewers: Lucas Bradstreet <lucas@confluent.io>, Jun Rao <junrao@gmail.com>",2021-08-24 09:57:13,David Jacot,Mixed
d0ec4d7ebf0022537807f5080b19414bd81f706e,"KAFKA-13214; Consumer should not reset state after retriable error in rebalance (#11231)

Currently the consumer will reset state after any retriable error during a rebalance. This includes coordinator disconnects as well as coordinator changes. The impact of this is that rebalances get delayed since they will be blocked until the session timeout of the old memberId expires. 

The patch here fixes the problem by not resetting the member state after a retriable error.

Reviewers: David Jacot <djacot@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2021-08-24 11:59:38,Jason Gustafson,Mixed
844c1259a9e2ea9caf2635213c4c0a144f6b758f,"MINOR: Optimize the OrderedBytes#upperRange for not all query cases (#11181)

Currently in OrderedBytes#upperRange method, we'll check key bytes 1 by 1, to see if there's a byte value >= first timestamp byte value, so that we can skip the following key bytes, because we know compareTo will always return 0 or 1. However, in most cases, the first timestamp byte is always 0, more specifically the upperRange is called for both window store and session store. For former, the suffix is in timestamp, Long.MAX_VALUE and for latter the suffix is in Long.MAX_VALUE, timestamp. For Long.MAX_VALUE the first digit is not 0, for timestamp it could be 0 or not, but as long as it is up to ""now"" (i.e. Aug. 23rd) then the first byte should be 0 since the value is far smaller than what a long typed value could have. So in practice for window stores, that suffix's first byte has a large chance to be 0, and hence worth optimizing for.

This PR optimizes the not all query cases by not checking the key byte 1 by 1 (because we know the unsigned integer will always be >= 0), instead, put all bytes and timestamp directly. So, we won't have byte array copy in the end either.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2021-08-26 14:37:34,Luke Chen,Not TDD
d9bb98895453fa7cdf14eb3184e904fca884f9a1,"MINOR: remove unused Properties from GraphNode#writeToTopology (#11263)

The GraphNode#writeToTopology method accepts a Properties input parameter, but never uses it in any of its implementations. We can remove this parameter to clean things up and help make it clear that writing nodes to the topology doesn't involve the app properties.

Reviewers: Bruno Cadonna <cadonna@confluent.io>",2021-08-26 17:19:03,A. Sophie Blee-Goldman,Mixed
8d5185d9768cfce9581040341a15912a014797f7,"MINOR; Small optimizations in `ReplicaManager#becomeLeaderOrFollower` (#11225)

This patch refactors `ReplicaManager#becomeLeaderOrFollower` to avoid having to re-iterate over all the partitions to determine which ones should become leaders and which ones should become followers.

The patch also refactors how partitions are marked as offline when the log can't be created. Before the patch, we were iterating over all the partitions in the request or in the delta to mark them as offline is the log was not present. Now, we mark them as failed directly if the log can not be created.

Reviewers: Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",2021-08-27 08:22:36,David Jacot,Mixed
7201976378aeb206563c949dd0e0c62d411e57d6,"KAFKA-13079: Forgotten Topics in Fetch Requests may incorrectly use topic IDs (#11104)

The FetchSessionHandler had a small bug in the session build method where we did not consider building a session where no partitions were added and the session previously did not use topic IDs. (ie, it was relying on at least one partition being added to signify whether topic IDs were present)

Due to this, we could send forgotten partitions with the zero UUID. This would always result in an exception and closed session.

This patch fixes the logic to check that any forgotten partitions have topic IDs. There is also a test added for the empty session situation when topic IDs are used and when topic names are used.

Reviewers: David Jacot <djacot@confluent.io>, Jun Rao <junrao@gmail.com>",2021-08-27 18:28:21,Justine Olshan,Mixed
555f70917535176b61aa920223c02dcb27f25372,"MINOR: move tiered storage related configs to a separate class within LogConfig (#11110)

The original code uses a RemoteLogManagerConfig class to store KIP-405 configs and adds three configs to LogConfig. This makes the code complicated and developers may be confused.

This PR allows us to access RemoteLogManagerConfig from KafkaConfig and do the same for LogConfig. Kafka developers will see the same interface for the KIP-405 configs. After this change, if we want to read remoteStorageEnable we should use LogConfig.tieredLogConfig.remoteStorageEnable instead of LogConfig.remoteStorageEnable. The same for localRetentionMs and localRetentionBytes. If we want to read configs in RemoteLogManagerConfig, we should use KafkaConfig.tieredKafkaConfig.xxx.

Reviewers: Satish Duggana <satishd@apache.org>, Kowshik Prakasam <kprakasam@confluent.io>, Jun Rao <junrao@gmail.com>",2021-08-27 11:10:58,Cong Ding,Mixed
84b111f968a47c65d3498a1b3af42dd644403728,"KAFKA-12963: Add processor name to error (#11262)

This PR adds the processor name to the ClassCastException exception text in process()

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-08-27 20:06:49,Andy Lapidas,Mixed
1d22b0d70686aef5689b775ea2ea7610a37f3e8c,"KAFKA-10774; Admin API for Describe topic using topic IDs (#9769)

Reviewers: Justine Olshan <jolshan@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Satish Duggana <satishd@apache.org>, Rajini Sivaram <rajinisivaram@googlemail.com>",2021-08-28 09:00:36,dengziming,Mixed
923bc2e9f78c0d0f14e4adf6fc50bd9abdd416da,"MINOR Refactored the existing CheckpointFile in core module, moved to server-common module and introduced it as SnapshotFile. (#11060)

MINOR Refactored the existing CheckpointFile in core module, moved to server-common module.

Refactored CheckpointFile to server-common module as a Java class and it is reused by LeaderCheckpointFile, OffsetCheckpointFile.
This will be used by CommittedOffsetsFile which checkpoints remote log metadata partitions with respective offsets in the default RemoteLogMetadataManager implementation.
Existing tests are available for LeaderCheckpointFile, OffsetCheckpointFile.

Reviewers: Jun Rao <junrao@gmail.com>",2021-08-30 08:43:25,Satish Duggana,Not TDD
01ab888dbd08ccd4b0de9333d21581ce24fe2c3b,"KAFKA-13229: add total blocked time metric to streams (KIP-761) (#11149)

* Add the following producer metrics:
flush-time-total: cumulative sum of time elapsed during in flush.
txn-init-time-total: cumulative sum of time elapsed during in initTransactions.
txn-begin-time-total: cumulative sum of time elapsed during in beginTransaction.
txn-send-offsets-time-total: cumulative sum of time elapsed during in sendOffsetsToTransaction.
txn-commit-time-total: cumulative sum of time elapsed during in commitTransaction.
txn-abort-time-total: cumulative sum of time elapsed during in abortTransaction.

* Add the following consumer metrics:
commited-time-total: cumulative sum of time elapsed during in committed.
commit-sync-time-total: cumulative sum of time elapsed during in commitSync.

* Add a total-blocked-time metric to streams that is the sum of:
consumer’s io-waittime-total
consumer’s iotime-total
consumer’s committed-time-total
consumer’s commit-sync-time-total
restore consumer’s io-waittime-total
restore consumer’s iotime-total
admin client’s io-waittime-total
admin client’s iotime-total
producer’s bufferpool-wait-time-total
producer's flush-time-total
producer's txn-init-time-total
producer's txn-begin-time-total
producer's txn-send-offsets-time-total
producer's txn-commit-time-total
producer's txn-abort-time-total

Reviewers: Bruno Cadonna <cadonna@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2021-08-30 15:39:25,Rohan,Mixed
a5ce43781e7c5f66dcfc5684207a70666f2e1838,"MINOR: add units to metrics descriptions + test fix post KAFKA-13229 (#11286)

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2021-08-31 11:44:45,Rohan,Mixed
25b0857bdb8a17f786c8f546fef2a60b6a87b797,"KAFKA-13234; Transaction system test should clear URPs after broker restarts (#11267)

Clearing under-replicated-partitions helps ensure that partitions do not become unavailable longer than necessary as brokers are rolled. This prevents flakiness due to transaction timeouts.

Reviewers: Luke Chen <showuon@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2021-09-01 08:37:05,Jason Gustafson,Not TDD
4835c64f89876db5af2bba8fa3ef17de5a0b44e3,"KAFKA-12887 Skip some RuntimeExceptions from exception handler (#11228)

Instead of letting all RuntimeExceptions go through and be processed by the uncaught exception handler, IllegalStateException and IllegalArgumentException are not passed through and fail fast. In this PR when setting the uncaught exception handler we check if the exception is in an ""exclude list"", if so, we terminate the client, otherwise we continue as usual.

Added test checking this new case. Added integration test checking that user defined exception handler is not used when an IllegalStateException is thrown.

Reviewers: Bruno Cadonna <cadonna@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2021-09-01 09:58:36,Josep Prat,Not TDD
3c0b89d9df7a46cceeaa08a6efd25bd2e49dcaaf,"KAFKA-13225: Controller skips sending UpdateMetadataRequest when no change in partition state. (#11255)

The controller can skip sending updateMetadataRequest during the broker failure callback if there are offline partitions and the deleted brokers don't host any partitions.

Reviewers: Jun Rao <junrao@gmail.com>",2021-09-02 13:44:12,David Mao,Not TDD
37584ce4f57a9e087e9c9280803e556a856d95e8,"KAFKA-13103: add REBALANCE_IN_PROGRESS error as retriable error for AlterConsumerGroupOffsetsHandler (#11086)

This patch adds `REBALANCE_IN_PROGRESS` error as retriable error for `AlterConsumerGroupOffsetsHandler`, and tests for it.

Reviewers: David Jacot <djacot@confluent.io>",2021-09-03 20:29:44,Luke Chen,Mixed
7c64077b34e58bc82a708a070aa005546d0a34cf,"KAFKA-13032: add NPE checker for KeyValueMapper (#11241)

Currently KStreamMap and KStreamFlatMap classes will throw NPE if the call to KeyValueMapper#apply() return null. This commit checks whether the result of KeyValueMapper#apply() is null and throws a more meaningful error message for better debugging.

Two unit tests are also added to check if we successfully captured nulls.

Reviewers: Josep Prat <josep.prat@aiven.io>,  Luke Chen <showuon@gmail.com>, Bruno Cadonna <cadonna@apache.org>",2021-09-06 14:03:16,Yanwen(Jason) Lin,Mixed
81667e2bf5e0f91b75e70a7e7420fa5ede98a287,"KAFKA-13066: Replace EasyMock with Mockito for FileStreamSinkConnectorTest (#11027)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-09-06 08:22:34,CHUN-HAO TANG,Not TDD
0118330103e992253a7875a523de3526cad4a6c5,"KAFKA-13273: Add support for Java 17 (#11296)

Java 17 is at release candidate stage and it will be a LTS release once
it's out (previous LTS release was Java 11).

Details:
* Replace Java 16 with Java 17 in Jenkins and Readme.
* Replace `--illegal-access=permit` (which was removed from Java 17)
   with  `--add-opens` for the packages we require internal access to.
   Filed KAFKA-13275 for updating the tests not to require `--add-opens`
   (where possible).
* Update `release.py` to use JDK8. and JDK 17 (instead of JDK 8 and JDK 15).
* Removed all but one Streams test from `testsToExclude`. The
   Connect test exclusion list remains the same.
* Add notable change to upgrade.html
* Upgrade to Gradle 7.2 as it's required for proper Java 17 support.
* Upgrade mockito to 3.12.4 for better Java 17 support.
* Adjusted `KafkaRaftClientTest` and `QuorumStateTest` not to require
   private access to `jdk.internal.util.random`.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2021-09-06 08:55:52,Ismael Juma,Not TDD
3475347aed004141f2bf8e16ddf34ecfbbae0ed6,"KAFKA-13270: Set JUTE_MAXBUFFER to 4 MB by default (#11295)

We restore the 3.4.x/3.5.x behavior unless the caller has set the property (note that ZKConfig
auto configures itself if certain system properties have been set).

I added a unit test that fails without the change and passes with it.

I also refactored the code to streamline the way we handle parameters passed to
KafkaZkClient and ZooKeeperClient.
 
See https://github.com/apache/zookeeper/pull/1129 for the details on why the behavior
changed in 3.6.0.

Credit to @rondagostino for finding and reporting this issue.

Reviewers: David Jacot <djacot@confluent.io>",2021-09-06 09:18:47,Ismael Juma,Mixed
519322338993ab56bac74a37bd74a135c83ccc23,"KAFKA-13101: Replace EasyMock and PowerMock with Mockito for RestServerTest (#11074)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-09-06 11:20:38,CHUN-HAO TANG,Not TDD
9d107c174bfb23e5ce0daca9a59796f018f627c6,"KAFKA-13277; Fix size calculation for tagged string fields in message generator (#11308)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-09-07 13:02:45,Rajini Sivaram,Mixed
66a27af2f17f4abd94f76edf828745f104c7ba4d,"KAFKA-10038: Supports default client.id for ConsoleConsumer, ProducerPerformance, ConsumerPerformance (#11297)

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2021-09-07 13:49:50,Yanwen(Jason) Lin,Mixed
5f89ce5f202bf560214e00fa1ac7add7a27248cf,"KAFKA-13201: Convert KTable suppress to new PAPI (#11213)

Migrate Suppress as part of the migration of KStream/KTable
 operations to the new Processor API (KAFKA-8410)

Reviewers: John Roesler <vvcephei@apache.org>",2021-09-07 17:17:44,Jorge Esteban Quilcate Otoya,Mixed
c56905bacc6c20e8996d8dd79b4c22ee944cdc7d,"KAFKA-13258/13259/13260: Fix error response generation (#11288)

AlterClientQuotas, DescribeProducers and FindCoordinator have issues when building error responses. This can lead to brokers returning responses without errors even when some have happened.

Reviewers: David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>, Luke Chen <showuon@gmail.com>",2021-09-08 11:16:23,Mickael Maison,Not TDD
fb77da941ac2a34513cf2cd5d11137ba9b275575,"KAFKA-12766 - Disabling WAL-related Options in RocksDB (#11250)

Description
Streams disables the write-ahead log (WAL) provided by RocksDB since it replicates the data in changelog topics. Hence, it does not make much sense to set WAL-related configs for RocksDB.

Proposed solution
Ignore any WAL-related configuration and state in the log that we are ignoring them.

Co-authored-by: Tomer Wizman <tomer.wizman@personetics.com>
Co-authored-by: Bruno Cadonna <cadonna@apache.org>

Reviewers: Boyang Chen <boyang@apache.org>, Bruno Cadonna <cadonna@apache.org>",2021-09-08 13:57:08,Tomer Wizman,Mixed
06e53afbefaf3ad1f64a49607775bbcc85edb81e,"KAFKA-13266; `InitialFetchState` should be created after partition is removed from the fetchers (#11294)

 `ReplicationTest.test_replication_with_broker_failure` in KRaft mode sometimes fails with the following error in the log:

```
[2021-08-31 11:31:25,092] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Unexpected error occurred while processing data for partition __consumer_offsets-1 at offset 31727 (kafka.server.ReplicaFetcherThread)java.lang.IllegalStateException: Offset mismatch for partition __consumer_offsets-1: fetched offset = 31727, log end offset = 31728. at kafka.server.ReplicaFetcherThread.processPartitionData(ReplicaFetcherThread.scala:194) at kafka.server.AbstractFetcherThread.$anonfun$processFetchRequest$8(AbstractFetcherThread.scala:545) at scala.Option.foreach(Option.scala:437) at kafka.server.AbstractFetcherThread.$anonfun$processFetchRequest$7(AbstractFetcherThread.scala:533) at kafka.server.AbstractFetcherThread.$anonfun$processFetchRequest$7$adapted(AbstractFetcherThread.scala:532) at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62) at scala.collection.convert.JavaCollectionWrappers$JMapWrapperLike.foreachEntry(JavaCollectionWrappers.scala:359) at scala.collection.convert.JavaCollectionWrappers$JMapWrapperLike.foreachEntry$(JavaCollectionWrappers.scala:355) at scala.collection.convert.JavaCollectionWrappers$AbstractJMapWrapper.foreachEntry(JavaCollectionWrappers.scala:309) at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:532) at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:216) at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:215) at scala.Option.foreach(Option.scala:437) at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:215) at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:197) at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:99)[2021-08-31 11:31:25,093] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Partition __consumer_offsets-1 marked as failed (kafka.server.ReplicaFetcherThread)
```

The issue is due to a race condition in `ReplicaManager#applyLocalFollowersDelta`. The `InitialFetchState` is created and populated before the partition is removed from the fetcher threads. This means that the fetch offset of the `InitialFetchState` could be outdated when the fetcher threads are re-started because the fetcher threads could have incremented the log end offset in between.

The patch fixes the issue by removing the partitions from the replica fetcher threads before creating the `InitialFetchState` for them.

Reviewers: Jason Gustafson <jason@confluent.io>

### Committer Checklist (excluded from commit message)
- [ ] Verify design and implementation 
- [ ] Verify test coverage and CI build status
- [ ] Verify documentation (including upgrade notes)",2021-09-08 18:23:37,David Jacot,Mixed
5e3ecf192e40f7eda092e71bc758886a2dba37e3,"KAFKA-13237; Add ActiveBrokerCount and FencedBrokerCount metrics to the ZK controller (KIP-748) (#11273)

This patch adds the `ActiveBrokerCount` and the `FencedBrokerCount` metrics to the ZK controller. Note that `FencedBrokerCount` is always set to zero in the ZK controller.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-09-08 18:44:29,David Jacot,Not TDD
286126f9a53751285e6b71349cdb6abcba35ddff,"KAFKA-13243: KIP-773 Differentiate metric latency measured in ms and ns (#11302)

KAFKA-13243: KIP-773 Differentiate metric latency measured in ms and ns

Implementation of KIP-773

Deprecates inconsistent metrics bufferpool-wait-time-total,
io-waittime-total, and iotime-total.
Introduces new metrics bufferpool-wait-time-ns-total,
io-wait-time-ns-total, and io-time-ns-total with the same semantics as
before.
Adds metrics (old and new) in ops.html.
Adds upgrade guide for these metrics.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Tom Bentley <tbentley@redhat.com>",2021-09-08 18:00:58,Josep Prat,Mixed
0a1df1238274adf0d5f599f97687cc1b082495d4,"KAFKA-13276: Prefer KafkaFuture in admin Result constructors (#11301)

Avoid using the non-public API KafkaFutureImpl in the Admin client's `*Result` class constructors.
This is particularly problematic for `DescribeConsumerGroupsResult` which currently has a
public constructor.  For the other classes the rationale is simply consistency with the majority of
the `*Result` classes.

Reviewers: Ismael Juma <ismael@juma.me.uk, David Jacot <djacot@confluent.io>, Luke Chen <showuon@gmail.com>",2021-09-08 12:15:44,Tom Bentley,Not TDD
df55c7ecfffa4601eaf36a3cd534d75c6525af49,"KAFKA-13256: Fix NPE in ConfigDef when documentation is null (#11287)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Luke Chen <showuon@gmail.com>",2021-09-09 18:39:10,René Kerner,Mixed
1e19de3199f53c89b5455390d8bbb2b58f6603b3,"KAFKA-12988 Asynchronous API support for RemoteLogMetadataManager add/update methods. (#11033)

Added asynchronous API support for RemoeLogMetadataManager add/update/put methods.

Implemented the changes on default topic based RemoteLogMetadataManager.

Refactored the respective tests to cover the introduced asynchronous APIs.

Reviewers: Cong Ding <cong@ccding.com>, Jun Rao <junrao@gmail.com>",2021-09-09 10:06:25,Satish Duggana,Mixed
c1c639db77aea4842a12a5630e2346d975a9f7d6,"KAFKA-13288; Include internal topics when searching hanging transactions (#11319)

This patch ensures that internal topics are included when searching for hanging transactions with the `--broker-id` argument in `kafka-transactions.sh`.

Reviewers: David Jacot <djacot@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2021-09-10 14:33:37,Jason Gustafson,Mixed
0786dc87842bae3733b309ea50c5601c7df3a62d,"KAFKA-13224: Ensure that broker.id is set in KafkaConfig#originals (#11312)

Some plugins make use of KafkaConfig#originals rather than the
KafkaConfig object. We should ensure that these plugins see the
correct value for broker.id if the broker is running in KRaft mode and
node.id has been configured, but not broker.id.

This PR does this by ensuring that both node.id and broker.id are set in
the originals map if either one is set.  We also check that they are set
to the same value in KafkaConfig#validateValues.

Co-author: Ron Dagostino <rdagostino@confluent.io>",2021-09-13 10:13:41,Colin Patrick McCabe,Mixed
a03bda61e068d72823af47e5f25ffd12c3319541,"KAFKA-13249: Always update changelog offsets before writing the checkpoint file (#11283)

When using EOS checkpointed offsets are not updated to the latest offsets from the changelog because the maybeWriteCheckpoint method is only ever called when commitNeeded=false. This change will force the update if enforceCheckpoint=true .

I have also added a test which verifies that both the state store and the checkpoint file are completely up to date with the changelog after the app has shutdown.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Guozhang Wang <wangguoz@gmail.com>",2021-09-13 14:15:22,Oliver Hutchison,Mixed
9628c1278e5dcd4f6995c89809461d350d9a530a,"KAFKA-13264: fix inMemoryWindowStore backward fetch not in reversed order (#11292)

When introducing backward iterator for WindowStroe in #9138, we forgot to make ""each segment"" in reverse order (i.e. in descendingMap) in InMemoryWindowStore. Fix it and add integration tests for it.

Currently, in Window store, we store records in [segments -> [records] ].

For example:
window size = 500,
input records:

key: ""a"", value: ""aa"", timestamp: 0 ==> will be in [0, 500] window
key: ""b"", value: ""bb"", timestamp: 10 ==> will be in [0, 500] window
key: ""c"", value: ""cc"", timestamp: 510 ==> will be in [500, 1000] window

So, internally, the ""a"" and ""b"" will be in the same segment, and ""c"" in another segments.
segments: [0 /* window start */, records], [500, records].
And the records for window start 0 will be ""a"" and ""b"".
the records for window start 500 will be ""c"".

Before this change, we did have a reverse iterator for segments, but not in ""records"". So, when doing backwardFetchAll, we'll have the records returned in order: ""c"", ""a"", ""b"", which should be ""c"", ""b"", ""a"" obviously.

Reviewers: Jorge Esteban Quilcate Otoya <quilcate.jorge@gmail.com>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Guozhang Wang <wangguoz@gmail.com>",2021-09-13 14:40:54,Luke Chen,Not TDD
75795d1ed8402f185e00b5f3aedcc2bcbb914ca9,"KAFKA-13149; Fix NPE when handling malformed record data in produce requests (#11080)

Raise `InvalidRecordException` from `DefaultRecordBatch.readFrom` instead of returning null if there are not enough bytes remaining to read the record. This ensures that the broker can raise a useful exception for malformed record batches.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>",2021-09-14 09:47:54,Cong Ding,Mixed
7de8a93c7e1036553ab6e738cf91bc39e154719e,"KAFKA-13162: Ensure ElectLeaders is properly handled in KRaft (#11186)

This patch fixes several problems with the `ElectLeaders` API in KRaft:

- `KafkaApis` did not properly forward this request type to the controller.
- `ControllerApis` did not handle the request type.
- `ElectLeadersRequest.getErrorResponse` may raise NPE when `TopicPartitions` is null.
- Controller should not do preferred election if `ElectLeaders` specifies `UNCLEAN` election.
- Controller should not do unclean election if `ElectLeaders` specifies `PREFERRED` election.
- Controller should use proper error codes to handle cases when desired leader is unavailable or when no election is needed because a desired leader is already elected.
- When election for all partitions is requested (indicated with null `TopicPartitions` field), the response should not return partitions for which no election was necessary.

In addition to extending the unit test coverage in `ReplicationControlManagerTest`, I have also converted `LeaderElectionCommandTest` to use KRaft.

Reviewers: dengziming <swzmdeng@163.com>, José Armando García Sancio <jsancio@users.noreply.github.com>, David Arthur <mumrah@gmail.com>",2021-09-15 08:52:45,Jason Gustafson,Mixed
6c806430093c152b916d8e8f1fa542980c03a181,"[KAFKA-8522] Streamline tombstone and transaction marker removal (#10914)

This PR aims to remove tombstones that persist indefinitely due to low throughput. Previously, deleteHorizon was calculated from the segment's last modified time.

In this PR, the deleteHorizon will now be tracked in the baseTimestamp of RecordBatches. After the first cleaning pass that finds a record batch with tombstones, the record batch is recopied with deleteHorizon flag and a new baseTimestamp that is the deleteHorizonMs. The records in the batch are rebuilt with relative timestamps based on the deleteHorizonMs that is recorded. Later cleaning passes will be able to remove tombstones more accurately on their deleteHorizon due to the individual time tracking on record batches.

KIP 534: https://cwiki.apache.org/confluence/display/KAFKA/KIP-534%3A+Retain+tombstones+and+transaction+markers+for+approximately+delete.retention.ms+milliseconds

Co-authored-by: Ted Yu <yuzhihong@gmail.com>
Co-authored-by: Richard Yu <yohan.richard.yu@gmail.com>",2021-09-16 09:17:15,Matthew Wong,Mixed
a0c7e6d8b4945f01f0ea956a66f05d57b92937f0,"KAFKA-13216: Use a KV with list serde for the shared store (#11252)

This is an alternative approach in parallel to #11235. After several unsuccessful trials to improve its efficiency i've come up with a larger approach, which is to use a kv-store instead as the shared store, which would store the value as list. The benefits of this approach are:

Only serde once that compose <timestamp, byte, key>, at the outer metered stores, with less byte array copies.
Deletes are straight-forward with no scan reads, just a single call to delete all duplicated <timestamp, byte, key> values.
Using a KV store has less space amplification than a segmented window store.
The cons though:

Each put call would be a get-then-write to append to the list; also we would spend a few more bytes to store the list (most likely a singleton list, and hence just 4 more bytes).
It's more complicated definitely.. :)
The main idea is that since the shared store is actively GC'ed by the expiration logic, not based on time retention, and since that the key format is in <timestamp, byte, key>, the range expiration query is quite efficient as well.

Added testing covering for the list stores (since we are still use kv-store interface, we cannot leverage on the get() calls in the stream-stream join, instead we use putIfAbsent and range only). Another minor factoring piggy-backed is to let toList to always close iterator to avoid leaking.

Reviewers: Sergio Peña <sergio@confluent.io>, Matthias J. Sax <mjsax@apache.org>",2021-09-16 16:44:32,Guozhang Wang,Mixed
55701dc00ab72233e7c238550a423fdce479afc1,"KAFKA-12762: Use connection timeout when polling the network for new connections (#10649)


Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Ismael Juma <ismael@juma.me.uk>, Tom Bentley <tbentley@redhat.com>

Co-authored-by: Mickael Maison <mickael.maison@gmail.com>
Co-authored-by: Edoardo Comar <ecomar@uk.ibm.com>
Co-authored-by: Tom Bentley <tombentley@users.noreply.github.com>",2021-09-17 15:35:49,Edoardo Comar,Not TDD
074a3dacca27f3ee313b5185adcf83cfa2c6605d,"MINOR: Make ReplicaManager, LogManager, KafkaApis easier to construct (#11320)

The ReplicaManager, LogManager, and KafkaApis class all have many
constructor parameters. It is often difficult to add or remove a
parameter, since there are so many locations that need to be updated. In
order to address this problem, we should use named parameters when
constructing these objects from Scala code. This will make it easy to
add new optional parameters without modifying many test cases.  It will
also make it easier to read git diffs and PRs, since the parameters will
have names next to them. Since Java does not support named paramters,
this PR adds several Builder classes which can be used to achieve the
same effect.

ReplicaManager also had a secondary constructor, which this PR removes.
The function of the secondary constructor was just to provide some
default parameters for the main constructor. However, it is simpler just
to actually use default parameters.

Reviewers: David Arthur <mumrah@gmail.com>",2021-09-17 14:12:31,Colin Patrick McCabe,Mixed
968e18cc799faa6b2b5f94e4f376bc768895afd2,"KAFKA-13254; Fix deadlock when `AlterIsr` response returns (#11289)

This patch fixes a deadlock when incrementing the high watermark after the synchronous zk ISR modification happens. The main difference is that we prevent the callback from executing while under the leader and ISR lock. The deadlock bug was introduced in https://github.com/apache/kafka/pull/11245.

Reviewers: David Jacot <djacot@confluent.io>",2021-09-20 09:46:38,Jason Gustafson,Mixed
b61ec0003f907b61243102811fdb2e92f8d7d2c5,"KAFKA-13211: add support for infinite range query for WindowStore (#11227)

Add support for infinite range query for WindowStore. Story JIRA: https://issues.apache.org/jira/browse/KAFKA-13210

Reviewers: Patrick Stuedi <pstuedi@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2021-09-22 09:14:58,Luke Chen,Mixed
d15969af286f4f239c0a972f4135ef429381ccd6,"KAFKA-10544: Migrate KTable aggregate and reduce (#11316)

As part of the migration of KStream/KTable operations to the new Processor API https://issues.apache.org/jira/browse/KAFKA-8410, this PR includes the migration of KTable aggregate/reduce operations.

Reviewers: John Roesler <vvcephei@apache.org>",2021-09-22 14:25:41,Jorge Esteban Quilcate Otoya,Mixed
85548acafbc799ee371b531802580fcde170ddc1,"KAFKA-13279: allow CreateTopicsPolicy, AlterConfigsPolicy in KRaft mode (#11310)

Add support for CreateTopicsPolicy and AlterConfigsPolicy when running in KRaft mode.

Reviewers: David Arthur <mumrah@gmail.com>, Niket Goel <ngoel@confluent.io>",2021-09-22 13:07:45,Colin Patrick McCabe,Mixed
509c1653fd0d107196fbf599a01d7899f6222160,"MINOR: Replace EasyMock with Mockito in connect:basic-auth-extension (#11321)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2021-09-23 05:08:06,dengziming,Not TDD
b76bcaf3a8f28a5ad553a9edd477c4d6d887f08a,"KAFKA-13102: Topic IDs not propagated to metadata cache quickly enough for Fetch path (#11170)

Before we used the metadata cache to determine whether or not to use topic IDs. Unfortunately, metadata cache updates with ZK controllers are in a separate request and may be too slow for the fetcher thread. This results in switching between topic names and topic IDs for topics that could just use IDs.

This patch adds topic IDs to FetcherState created in LeaderAndIsr requests. It also supports updating this state for follower threads as soon as a LeaderAndIsr request provides a topic ID.

We've opted to only update replica fetcher threads. AlterLogDir threads will use either topic name or topic ID depending on what was present when they were created.

Reviewers: David Jacot <djacot@confluent.io>",2021-09-24 10:51:08,Justine Olshan,Mixed
c6aeb5c5546f34276879c1eef4199d208f1c23dc,"KAFKA-13305: fix NullPointerException in LogCleanerManager ""uncleanable-bytes"" gauge (#11327)

Reviewers: David Jacot <djacot@confluent.io>, Jun Rao <junrao@gmail.com>",2021-09-27 09:49:21,Vincent Jiang,Not TDD
b741e9386e74aa9c9fceb5715b8c138ae49c07a8,"KAFKA-13324: KRaft: fix validateOnly in CreateTopics (#11361)

Fix a bug where the validateOnly flag for createTopics was being ignored.

Reviewers: David Arthur <mumrah@gmail.com>, José Armando García Sancio <jsancio@gmail.com>, singingMan <3schwartz@users.noreply.github.com>",2021-09-27 16:00:41,Colin Patrick McCabe,Mixed
5e45196fb078e5e211440c70e928a23aa45f9d48,"Add DirectoryConfigProvider to the service provider list (#11352)

* Add DirectoryConfigProvider to the service provider list

Reviewers: Chris Egerton <chrise@confluent.io>, Tom Bentley <tbentley@redhat.com>",2021-09-28 07:22:42,Jakub Scholz,Not TDD
7e573001484427dc73d821cc232a4c3bb3b5f5bb,"KAFKA-12486: Enforce Rebalance when a TaskCorruptedException is throw… (#11076)

This PR aims to utilize HighAvailabilityTaskAssignor to avoid downtime on corrupted tasks. The idea is that, when we hit TaskCorruptedException on an active task, a rebalance is triggered after we've wiped out the corrupted state stores. This will allow the assignor to temporarily redirect this task to another client who can resume work on the task while the original owner works on restoring the state from scratch.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-09-28 16:50:16,vamossagar12,Mixed
71f1cb7bfb2dc801c9ea47e0794d915e7f279635,"MINOR: optimize performAssignment to skip unnecessary check (#11218)

Found this while reading the code. We did a ""a little heavy"" check each time after performing assignment, which is to compare the ""assigned topics"" set and the ""subscribed topics"" set, to see if there's any topics not existed in another set. Also, the ""assigned topics"" set is created by traversing all the assigned partitions, which will be a little heavy if partition numbers are large.

However, as the comments described, it's a safe-guard for user-customized assignor, which might do assignment that we don't expected. In most cases, user will just use the in-product assignor, which guarantee that we only assign the topics from subscribed topics. Therefore, no need this check for in-product assignors.

In this PR, I added an ""in-product assignor names"" list, and we'll in consumerCoordinator check if the assignor is one of in-product assignors, to decide if we need to do the additional check. Also add test for it.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Guozhang Wang <guozhang@confluent.io>",2021-09-28 17:22:05,Luke Chen,Mixed
361b7845c6e6badc4be19fec596380a3de7a5c98,"KAFKA-13309: fix InMemorySessionStore#fetch/backwardFetch order issue (#11337)

In #9139, we added backward iterator on SessionStore. But there is a bug that when fetch/backwardFetch the key range, if there are multiple records in the same session window, we can't return the data in the correct order.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman<apache.org>",2021-09-28 17:31:29,Luke Chen,Not TDD
6d7a7859568eb5b25931a3be81cda9f4e0e3ec0d,"MINOR: expand logging and improve error message during partition count resolution (#11364)

Recently a user hit this TaskAssignmentException due to a bug in their regex that meant no topics matched the pattern subscription, which in turn meant that it was impossible to resolve the number of partitions of the downstream repartition since there was no upstream topic to get the partition count for. Debugging this was pretty difficult and ultimately came down to stepping through the code line by line, since even with TRACE logging we only got a partial picture.

We should expand the logging to make sure the TRACE logging hits both conditional branches, and improve the error message with a suggestion for what to look for should someone hit this in the future

Reviewers: Walker Carlson <wcarlson@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2021-09-29 18:19:43,A. Sophie Blee-Goldman,Mixed
ce83e5be6644884d5c727ed49982f45eca8c136f,"KAFKA-10540: Migrate KStream aggregate operations (#11315)

As part of the migration of KStream/KTable operations to the new
Processor API https://issues.apache.org/jira/browse/KAFKA-8410,
this PR includes the migration of KStream aggregate/reduce operations.

Reviewers: John Roesler <vvcephei@apache.org>",2021-09-30 11:40:40,Jorge Esteban Quilcate Otoya,Mixed
1a3e23a5798373fb40f31af2eb7c4348270ac437,"MINOR: TopicIdPartition improvements (#11374)

1. It should not require a TopicPartition during construction and normal
usage.
2. Simplify `equals` since `topicId` and `topicPartition` are never
null.
3. Inline `Objects.hash` to avoid array allocation.
4. Make `toString` more concise using a similar approach as
`TopicPartition` since this `TopicIdPartition` will replace
`TopicPartition` in many places in the future.
5. Add unit tests for `TopicIdPartition`, it seems like we had none.
6. Minor clean-up in calling/called classes.

Reviewers: David Jacot <djacot@confluent.io>, Satish Duggana <satishd@apache.org>",2021-10-05 11:37:38,Ismael Juma,Mixed
3f3a0e0d9ee1142d47913e744bfd57ebbc5e5b40,"KAFKA-13280: Avoid O(N) behavior in KRaftMetadataCache#topicNamesToIds (#11311)

Avoid O(N) behavior in KRaftMetadataCache#topicNamesToIds and
KRaftMetadataCache#topicIdsToNames by returning a map subclass that
exposes the TopicsImage data structures without copying them.

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2021-10-07 09:41:57,Colin Patrick McCabe,Mixed
34d56dc8d00bd27955eb9bb6ac01d5ae7f134dbd,"KAFKA-12802 Added a file based cache for consumed remote log metadata for each partition to avoid consuming again incase of broker restarts. (#11058)

Added snapshots for consumed remote log metadata for each partition to avoid consuming again in case of broker restarts. These snapshots are stored in the respective topic partition log directories.

Reviewers: Kowshik Prakasam <kprakasam@confluent.io>, Cong Ding <cong@ccding.com>, Jun Rao <junrao@gmail.com>",2021-10-11 10:24:55,Satish Duggana,Mixed
e31a53a2cdee2ad8a1f71c9e8c9f1cab64393df9,"KAFKA-13319: Do not commit empty offsets on producer (#11362)

We observed on the broker side that txn-offset-commit request with empty topics are received. After checking the source code I found there's on place on Streams which is unnecessarily sending empty offsets. This PR cleans up the streams layer logic a bit to not send empty offsets, and at the same time also guard against empty offsets at the producer layer as well.

Reviewers: Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",2021-10-12 13:33:23,Guozhang Wang,Mixed
d1415866cc3ed7eeb198df6477a09584b6d1f8a2,"KAFKA-13021: disallow grace called after grace set via new API (#11188)

Disallow calling grace() if it was already set via ofTimeDifferenceAndGrace/WithNoGrace(). Add the check to disallow grace called after grace set via new API, and add tests for them.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2021-10-12 16:05:22,Luke Chen,Mixed
65b01a0464d9bc4cc185cfb99ea80dc66cfeb2ec,"KAFKA-13212: add support infinite query for session store (#11234)

Add support for infinite range query for SessionStore.

Reviewers: Patrick Stuedi <pstuedi@apache.org>, Guozhang Wang <wangguoz@gmail.com>",2021-10-12 16:14:38,Luke Chen,Mixed
da58d75c4389aa988ac6028bb8bd073646f07300,"MINOR: Fix highest offset when loading KRaft metadata snapshots (#11386)

When loading a snapshot the broker BrokerMetadataListener was using the batch's append time, offset
and epoch. These are not the same as the append time, offset and epoch from the log. This PR fixes
it to instead use the lastContainedLogTimeStamp, lastContainedLogOffset and lastContainedLogEpoch
from the SnapshotReader.

This PR refactors the MetadataImage and MetadataDelta to include an offset and epoch. It also swaps
the order of the arguments for ReplicaManager.applyDelta, in order to be more consistent with
MetadataPublisher.publish.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-10-12 17:19:03,José Armando García Sancio,Mixed
f58d79d549957d4a13547a41634735325ab56982,"KAFKA-13345: Use ""delete"" cleanup policy for windowed stores if duplicates are enabled (#11380)

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Luke Chen <showuon@gmail.com>",2021-10-14 22:06:30,Matthias J. Sax,Mixed
da38a1df273ec9d3a077435b2a63d75053edd308,"MINOR: ""partition"" typos and method doc arg fix (#11298)



Reviewers: Mickael Maison <mickael.maison@gmail.com>, Luke Chen <showuon@gmail.com>",2021-10-18 10:44:11,Lucas Bradstreet,Not TDD
68223d32278913bc75d8f8ed41d27afe0c25d959,"KAFKA-10539: Convert KStreamImpl joins to new PAPI (#11356)

Part of the migration to new Processor API, this PR converts KStream to KStream joins.

Depends #11315

Reviewers: John Roesler <vvcephei@apache.org>",2021-10-18 15:34:08,Jorge Esteban Quilcate Otoya,Mixed
b86c307b0e514cae4be5bed3e74cfca65d08c673,"MINOR: Make TestUtils usable for KRaft mode (#11410)

Make TestUtils usable for KRaft mode by using KafkaBroker instead of KafkaServer where appropriate,
and adding some alternate functions that use AdminClient instead of ZooKeeper.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-10-19 15:48:24,Colin Patrick McCabe,Not TDD
38a3ddb5627f7860aea40cb602186bde79808d3d,"MINOR: Add a replication system test which simulates a slow replica (#11395)

This patch adds a new system test which exercises the shrining/expansion process of the partition leader. It does so by introducing a network partition which isolates a broker from the other brokers in the cluster but not from KRaft Controller/ZK.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-10-20 08:19:36,David Jacot,Not TDD
b53412422496f6cc2caf2abe3139f3bc2ed75c9d,"KAFKA-12648: Wrap all exceptions thrown to handler as StreamsException & add TaskId field (#11405)

To help users distinguish which task an exception was thrown from, and which NamedTopology if it exists, we add a TaskId field to the StreamsException class. We then make sure that all exceptions thrown to the handler are wrapped as StreamsExceptions, to help the user simplify their handling code as they know they will always need to unwrap the thrown exception exactly once.

Reviewers: Walker Carlson <wcarlson@confluent.io>, Luke Chen <showuon@gmail.com>, Guozhang Wang <wangguoz@gmail.com>, John Roesler <vvcephei@apache.org>",2021-10-21 16:21:20,A. Sophie Blee-Goldman,Mixed
3f433c0b4a3fc024d4ec48f7e8b5541336fca053,"KAFKA-12697: Add FencedBrokerCount and ActiveBrokerCount metrics to the QuorumController (#10772)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-10-22 12:57:36,Ryan Dielhenn,Mixed
37b3f8c15b2a9f7d332179a33ab18ce4753a66fd,"MINOR: MetadataShell should handle ClientQuotaRecord (#11339)

MetadataShell should handle ClientQuotaRecord. Also, add MetadataNodeManagerTest.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-10-26 13:23:20,dengziming,Mixed
53f5c2606de16331cb4ddeb38fdc3f94bff4b233,"MINOR: ZkMetadataCache should be in kafka.server.metadata #10956

Put ZkMetadataCache in the kafka.server.metadata package rather than the kafka.server package, so
that its package is consistent with its position in the source directory hierarchy.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2021-10-26 14:16:52,dengziming,Mixed
d36832e6fc531b56bbab49e60d96efdf17fb6191,"MINOR: fix the path metadata shell uses for client quotas (#11437)

Client quotas should appear under /client-quotas rather than /configs, since client quotas are
not configs. Additionally we should correctly handle the case where the entity name is null
(aka ""default"" quotas.)

Reviewers: Jason Gustafson <jason@confluent.io>",2021-10-26 15:27:30,Colin Patrick McCabe,Mixed
cf2b3930311f3dfe23b64853a19607c5f3085b13,"KAFKA-13385: In the KRPC request header, translate null clientID to empty (#11385)

Reviewers: David Jacot <djacot@confluent.io>",2021-10-27 15:19:09,Colin Patrick McCabe,Mixed
7b379539a5533179b0c86adb352548ac1aa82006,"KAFKA-13202: KIP-768: Extend SASL/OAUTHBEARER with Support for OIDC (#11284)

This task is to provide a concrete implementation of the interfaces defined in KIP-255 to allow Kafka to connect to an OAuth/OIDC identity provider for authentication and token retrieval. While KIP-255 provides an unsecured JWT example for development, this will fill in the gap and provide a production-grade implementation.

The OAuth/OIDC work will allow out-of-the-box configuration by any Apache Kafka users to connect to an external identity provider service (e.g. Okta, Auth0, Azure, etc.). The code will implement the standard OAuth client credentials grant type.

The proposed change is largely composed of a pair of AuthenticateCallbackHandler implementations: one to login on the client and one to validate on the broker.

See the following for more detail:

KIP-768
KAFKA-13202

Reviewers: Yi Ding <dingyi.zj@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",2021-10-28 11:36:53,Kirk True,Mixed
af8100b94fda4a27511797233e9845078ae8a69f,"KAFKA-13340: Change ZooKeeperTestHarness to QuorumTestHarness (#11417)

Change ZooKeeperTestHarness to QuorumTestHarness so that integration tests which inherit from
this class can test Kafka in both ZK and KRaft mode. Test cases which do this can specify the
modes they support by including a ParameterizedTest annotation before each test case, like the
following:

@ParameterizedTest
@valuesource(strings = Array(""zk"", ""kraft""))
def testValidCreateTopicsRequests(quorum: String): Unit = { ... }

For each value that is specified here (zk, kraft), the test case will be run once in the
appropriate mode. So the test shown above is run twice. This allows integration tests to be
incrementally converted over to support KRaft mode, rather than rewritten to support it. For
now, test cases which do not specify a quorum argument will continue to run only in ZK mode.

JUnit5 makes the quorum annotation visible in the TestInfo object which each @BeforEeach
function in a test can optionally take. Therefore, this PR converts over the setUp function of
the quorum base class, plus every derived class, to take a TestInfo argument. The TestInfo
object gets ""passed up the chain"" to the base class, where it determines which quorum type we
create (ZK or KRaft). In a few cases, I discovered test cases inheriting from the test harness
that had more than one @BeforeEach function. Because the JUnit5 framework does not define the
order in which @BeforeEach hooks are run, I changed these to overload setUp() instead, to avoid
undefined behavior.

The general approach taken here is to make as much as possible work with KRaft, but to leave some
things as ZK-only when appropriate. For example, a test that explicitly requests an AdminZkClient
object will get an exception if it is running in KRaft mode. Similarly, tests which explicitly
request KafkaServer rather than KafkaBroker will get an exception when running in KRaft mode.
As a proof of concept, this PR converts over kafka.api.MetricsTest to support KRaft.

This PR also renames the quorum controller event handler thread to include the text
""QuorumControllerEventHandler"". This allows QuorumTestHarness to check for hanging quorum
controller threads, as it does for hanging ZK-based controller threads.

Finally, ConsumerBounceTest#testRollingBrokerRestartsWithSmallerMaxGroupSizeConfigDisruptsBigGroup
caused many failing test runs. Therefore, I disabled it here and filed KAFKA-13421 to fix the
test logic to be more reliable.

Reviewers: Jason Gustafson <jason@confluent.io>, Igor Soarez <soarez@apple.com>",2021-10-30 08:00:34,Colin Patrick McCabe,Mixed
252a40ea1f273a5f11ccb5a9b362bceca7e66271,"KAFKA-8941: Add RocksDB Metrics that Could not be Added due to RocksD… (#11441)

This PR adds some RocksDB metrics that could not be added in KIP-471 due to RocksDB version. The new metrics are extracted using Histogram data provided by RocksDB API, and the old ones were extracted using Tickers. The new metrics added are memtable-flush-time-(avg|min|max) and compaction-time-(avg|min|max).

Reviewer: Bruno Cadonnna <cadonna@apache.org>",2021-11-03 12:18:28,Luizfrf3,Mixed
22d056c9b76c9bf8417d8701594d1fcee1c6a655,"TRIVIAL: Fix type inconsistencies, unthrown exceptions, etc (#10678)

Reviewers: Ismael Juma <ismael@juma.me.uk>, Bruno Cadonna <cadonna@apache.org>",2021-11-03 14:58:42,Lee Dongjin,Mixed
01e6a6ebf2af87e12b60fb7cf55d261ded72ed3e,"KAFKA-13261: Add support for custom partitioners in foreign key joins (#11368)

Implements KIP-775.

Co-authored-by: Tomas Forsman <tomas-forsman@users.noreply.github.com>",2021-11-03 10:55:24,Victoria Xia,Not TDD
43bcc5682da82a602a4c0a000dc7433d0507b450,"KAFKA-13396: Allow create topic without partition/replicaFactor (#11429)

[KIP-464](https://cwiki.apache.org/confluence/display/KAFKA/KIP-464%3A+Defaults+for+AdminClient%23createTopic) (PR: https://github.com/apache/kafka/pull/6728)
made it possible to create topics without passing partition count and/or replica factor when using
the admin client. We incorrectly disallowed this via https://github.com/apache/kafka/pull/10457 while
trying to ensure validation was consistent between ZK and the admin client (in this case the
inconsistency was intentional).

Fix this regression and add tests for the command lines in quick start (i.e. create topic and describe
topic) to make sure it won't be broken in the future.

Reviewers: Lee Dongjin <dongjin@apache.org>, Ismael Juma <ismael@juma.me.uk>",2021-11-04 06:44:05,Luke Chen,Mixed
c1bdfa125d224d07290a2d33cdac9d7387796fef,"KAFKA-12226: Commit source task offsets without blocking on batch delivery (#11323)

Replaces the current logic for committing source offsets, which is batch-based and blocks until the entirety of the current batch is fully written to and acknowledged by the broker, with a new non-blocking approach that commits source offsets for source records that have been ""fully written"" by the producer. The new logic consider a record fully written only if that source record and all records before it with the same source partition have all been written to Kafka and acknowledged.

This new logic uses a deque for every source partition that a source task produces records for. Each element in that deque is a SubmittedRecord with a flag to track whether the producer has ack'd the delivery of that source record to Kafka. Periodically, the worker (on the same thread that polls the source task for records and transforms, converts, and dispatches them to the producer) polls acknowledged elements from the beginning of each of these deques and collects the latest offsets from these elements, storing them in a snapshot that is then committed on the separate source task offset thread.

The behavior of the `offset.flush.timeout.ms property` is retained, but essentially now only applies to the actual writing of offset data to the internal offsets topic (if running in distributed mode) or the offsets file (if running in standalone mode). No time is spent during `WorkerSourceTask::commitOffsets` waiting on the acknowledgment of records by the producer.

This behavior also does not change how the records are dispatched to the producer nor how the producer sends or batches those records.

It's possible that memory exhaustion may occur if, for example, a single Kafka partition is offline for an extended period. In cases like this, the collection of deques in the SubmittedRecords class may continue to grow indefinitely until the partition comes back online and the SubmittedRecords in those deques that targeted the formerly-offline Kafka partition are acknowledged and can be removed. Although this may be suboptimal, it is no worse than the existing behavior of the framework in these cases.

Author: Chris Egerton <chrise@confluent.io>
Reviewed: Randall Hauch <rhauch@gmail.com>",2021-11-07 11:39:04,Chris Egerton,Mixed
807c5b4d282e7a7a16d0bb94aa2cda9566a7cc2d,"KAFKA-10543: Convert KTable joins to new PAPI (#11412)

* Migrate KTable joins to new Processor API.
* Migrate missing KTableProcessorSupplier implementations.
* Replace KTableProcessorSupplier with new Processor API implementation.

Reviewers: John Roesler <vvcephei@apache.org>",2021-11-08 14:48:54,Jorge Esteban Quilcate Otoya,Mixed
78a5e921d4566f2e2d56714834e3c5dd6ad17125,"KAFKA-13417; Ensure dynamic reconfigurations set old config properly (#11448)

This patch fixes a bug in `DynamicBrokerConfig` which causes some configuration changes to be ignored. In particular, the bug is the result of the reference to the old configuration getting indirectly mutated prior to the call to `BrokerReconfigurable.reconfigure`. This causes the first dynamic configuration update to pass effectively the same configuration as both `oldConfig` and `newConfig`. In cases such as in `DynamicThreadPool`, the update is ignored because the old configuration value matches the new configuration value.

This bug only affects KRaft. It is protected in the zk broker by the call to `DynamicBrokerConfig.initialize()`, which overwrites the stored reference to the original configuration. The patch fixes the problem by ensuring that `initialize()` is also invoked in KRaft when `BrokerServer` starts up.

Reviewers: David Jacot <djacot@confluent.io>, Rajini Sivaram <rajinisivaram@googlemail.com>",2021-11-09 13:42:54,Jason Gustafson,Mixed
b8c3a67012218188330110ce94636b70116131f9,"MINOR: Remove topic null check from `TopicIdPartition` and adjust constructor order (#11403)

`TopicPartition` allows a null `topic` and there are cases where we have
a topic id, but no topic name. Even for `TopicIdPartition`, the non null
topic name check was only enforced in one constructor.

Also adjust the constructor order to move the nullable parameter to the
end, update tests and javadoc.

Reviewers: David Jacot <djacot@confluent.io>, Luke Chen <showuon@gmail.com>",2021-11-10 05:44:26,Ismael Juma,Mixed
39b1bf4ee3cb63a889eb64d51d922866d37e7f5f,"KAFKA-12487: Add support for cooperative consumer protocol with sink connectors (#10563)

Currently, the `WorkerSinkTask`'s consumer rebalance listener (and related logic) is hardcoded to assume eager rebalancing, which means that all partitions are revoked any time a rebalance occurs and then the set of partitions included in `onPartitionsAssigned` is assumed to be the complete assignment for the task. Not only does this cause failures when the cooperative consumer protocol is used, it fails to take advantage of the benefits provided by that protocol.

These changes alter framework logic to not only not break when the cooperative consumer protocol is used for a sink connector, but to reap the benefits of it as well, by not revoking partitions unnecessarily from tasks just to reopen them immediately after the rebalance has completed.

This change will be necessary in order to support [KIP-726](https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=177048248), which currently proposes that the default consumer partition assignor be changed to the `CooperativeStickyAssignor`.

Two integration tests are added to verify sink task behavior with both eager and cooperative consumer protocols, and new and existing unit tests are adopted as well.

Reviewers: Nigel Liang <nigel@nigelliang.com>, Konstantine Karantasis <k.karantasis@gmail.com>",2021-11-10 11:14:50,Chris Egerton,Mixed
908a6d2ad7807642b917231769c8d3b6a0c1ad16,"KAFKA-12648: introduce TopologyConfig and TaskConfig for topology-level overrides (#11272)

Most configs that are read and used by Streams today originate from the properties passed in to the KafkaStreams constructor, which means they get applied universally across all threads, tasks, subtopologies, and so on. The only current exception to this is the topology.optimization config which is parsed from the properties that get passed in to StreamsBuilder#build. However there are a handful of configs that could also be scoped to the topology level, allowing users to configure each NamedTopology independently of the others, where it makes sense to do so.

This PR refactors the handling of these configs by interpreting the values passed in via KafkaStreams constructor as the global defaults, which can then be overridden for individual topologies via the properties passed in when building the NamedTopology. More topology-level configs may be added in the future, but this PR covers the following:

max.task.idle.ms
task.timeout.ms
buffered.records.per.partition
default.timestamp.extractor.class
default.deserialization.exception.handler

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Walker Carlson <wcarlson@confluent.io>, Luke Chen <showuon@confluent.io>",2021-11-10 11:27:59,A. Sophie Blee-Goldman,Mixed
6f6248509c0c38dcd867b28e6481de5370c6e082,"MINOR: Introduce `ApiKeyVersionsSource` annotation for `ParameterizedTest` (#11468)

It is common in our code base to have unit tests which must be run for all the versions of a given request. Most of the time, we do so by iterating over all the versions in the test itself which is error prone.

With JUnit5 and ParameterizedTest, we can now use a custom arguments source for this case, which is way more convenient. It looks likes this:

```
@ParameterizedTest
@ApiKeyVersionsSource(apiKey = ApiKeys.ADD_PARTITIONS_TO_TXN)
public void mytest(short version) {
  // do smth based on version...
}
```

This patch introduces the new annotation and updates `AddPartitionsToTxnRequestTest` test as a first example. I will migrate all the other cases in subsequent PRs.

Reviewers: Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",2021-11-11 16:39:08,David Jacot,Not TDD
e8818e234a879d5ca45accba0121f43f45381f4a,"KAFKA-13111: Re-evaluate Fetch Sessions when using topic IDs (#11331)

With the changes for topic IDs, we have a different flow. When a broker receives a request, it uses a map to convert the topic ID to topic names. If the topic ID is not found in the map, we return a top level error and close the session. This decision was motivated by the difficulty to store “unresolved” partitions in the session. In earlier iterations we stored an “unresolved” partition object in the cache, but it was somewhat hard to reason about and required extra logic to try to resolve the topic ID on each incremental request and add to the session. It also required extra logic to forget the topic (either by topic ID if the topic name was never known or by topic name if it was finally resolved when we wanted to remove from the session.)

One helpful simplifying factor is that we only allow one type of request (uses topic ID or does not use topic ID) in the session. That means we can rely on a session continuing to have the same information. We don’t have to worry about converting topics only known by name to topic ID for a response and we won’t need to convert topics only known by ID to name for a response.

This PR introduces a change to store the ""unresolved partitions"" in the cached partition object. If a version 13+ request is sent with a topic ID that is unknown, a cached partition will be created with that fetch request data and a null topic name. On subsequent incremental requests, unresolved partitions may be resolved with the new IDs found in the metadata cache. When handling the request, getting all partitions will return a TopicIdPartition object that will be used to handle the request and build the response. Since we can rely on only one type of request (with IDs or without), the cached partitions map will have different keys depending on what fetch request version is being used. 

This PR involves changes both in FetchSessionHandler and FetchSession. Some major changes are outlined below.

1. FetchSessionHandler: Forgetting a topic and adding a new topic with the same name -  We may have a case where there is a topic foo with ID 1 in the session. Upon a subsequent metadata update, we may have topic foo with ID 2. This means that topic foo has been deleted and recreated. When sending fetch requests version 13+ we will send a request to add foo ID 2 to the session and remove foo ID 1. Otherwise, we will fall back to the same behavior for versions 12 and below

2. FetchSession: Resolving in Incremental Sessions - Incremental sessions contain two distinct sets of partitions. Partitions that are sent in the latest request that are new/updates/forgotten partitions and the partitions already in the session. If we want to resolve unknown topic IDs we will need to handle both cases.
    * Partitions in the request  - These partitions are either new or updating/forgetting previous partitions in the session. The new partitions are trivial. We either have a resolved partition or create a partition that is unresolved. For the other cases, we need to be a bit more careful. 
        * For updated partitions we have a few cases – keep in mind, we may not programmatically know if a partition is an update:
            1. partition in session is resolved, update is resolved: trivial 
            2. partition in session is unresolved, update is unresolved: in code, this is equivalent to the case above, so trivial as well 
            3. partition in session is unresolved, update is resolved: this means the partition in the session does not have a name, but the metadata cache now contains the name –  to fix this we can check if there exists a cached partition with the given ID and update it both with the partition update and with the topic name. 
            4. partition in session is resolved, update is unresolved: this means the partition in the session has a name, but the update was unable to be resolved (ie, the topic is deleted) – this is the odd case. We will look up the partition using the ID. We will find the old version with a name but will not replace the name. This will lead to an UNKNOWN_TOPIC_OR_PARTITION or INCONSISTENT_TOPIC_ID error which will be handled with a metadata update. Likely a future request will forget the partition, and we will be able to do so by ID. 
            5. Two partitions in the session have IDs, but they are different: only one topic ID should exist in the metadata at a time, so likely only one topic ID is in the fetch set. The other one should be in the toForget. We will be able to remove this partition from the session. If for some reason, we don't try to forget this partition — one of the partitions in the session will cause an inconsistent topic ID error and the metadata for this partition will be refreshed — this should result in the old ID being removed from the session. This should not happen if the FetchSessionHandler is correctly in sync. 
        * For the forgotten partitions we have the same cases:
            1. partition in session is resolved, forgotten is resolved: trivial 
            2. partition in session is unresolved, forgotten is unresolved: in code, this is equivalent to the case above, so trivial as well 
            3. partition in session is unresolved, forgotten is resolved: this means the partition in the session does not have a name, but the metadata cache now contains the name –  to fix this we can check if there exists a cached partition with the given ID and try to forget it before we check the resolved name case. 
            4. partition in session is resolved, update is unresolved: this means the partition in the session has a name, but the update was unable to be resolved (ie, the topic is deleted) We will look up the partition using the ID. We will find the old version with a name and be able to delete it. 
            5. both partitions in the session have IDs, but they are different: This should be the same case as described above. If we somehow do not have the ID in the session, no partition will be removed. This should not happen unless the Fetch Session Handler is out of sync. 
    * Partitions in the session - there may be some partitions in the session already that are unresolved. We can resolve them in forEachPartition using a method that checks if the partition is unresolved and tries to resolve it using a topicName map from the request. The partition will be resolved before the function using the cached partition is applied.

Reviewers: David Jacot <djacot@confluent.io>",2021-11-15 10:04:43,Justine Olshan,Mixed
8318786b72ccc1e74538aa99f3c5b1c21258bbfb,"KAFKA-13255: Use config.properties.exclude when mirroring topics (#11401)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2021-11-15 11:45:48,Ed B,Mixed
f7031aa8073097e806d011b1aacf967e2a173a9c,"KAFKA-13445: Add ECDSA test for JWT validation (#11487)

Reviewers: Jun Rao <junrao@gmail.com>",2021-11-15 16:20:27,Kirk True,Not TDD
627cad1f7b6dd70caf88ec314daf1719ac377f90,"KAFKA-13406: skip assignment validation for built-in cooperativeStickyAssignor (#11439)

This fix is trying to skip the assignment validation for built-in cooperative sticky assignor, since (a) we know the assignment is valid since we do essentially this same check already in the cooperative sticky assignor, and (b) the check is broken anyways due to potential for claimed `ownedPartitions` to be incorrect 

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-11-15 18:57:03,Luke Chen,Mixed
ffbef88cd7fba1b545002d9f9150eb1a36d5f81a,"Add recordMetadata() to StateStoreContext (#11498)

Implements KIP-791

Reviewers: John Roesler <vvcephei@apache.org>",2021-11-16 10:51:41,Patrick Stuedi,Not TDD
a448ddbecb5036baafea039325e644e8bf866507,"KAFKA-13443: Kafka broker exits when OAuth enabled and certain configuration not specified (#11484)

The sasl.oauthbearer.jwks.endpoint.retry.backoff.ms and sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms configuration options were added to the SaslConfig class but their default values were not added to KafkaConfig. As a result, when the OAuth validation feature is enabled in the broker and those two configuration values aren't explicitly provided by the user, the broker exits. This patch fixes the issue by defining them in the KafkaConfig class.

Reviewers: David Jacot <djacot@confluent.io>",2021-11-17 11:17:26,Kirk True,Mixed
ef94af1e8ad283800a9ff4aed20890db666d6e1d,"KAFKA-13397: MirrorMaker should not mirror topics ending with `.internal` (#11431)

When running in dedicated mode, Connect runtimes are configured to use the `.internal` suffix for their topics. 

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Omnia G H Ibrahim <o.g.h.ibrahim@gmail.com>",2021-11-17 18:14:02,Lee Dongjin,Mixed
06dfa54be758e8589e9ce9b2ee67c9721b5b0546,"KAFKA-12257; Consumer mishandles topics deleted and recreated with the same name (#11004)

Store topic ID info in consumer metadata. We will always take the topic ID from the latest metadata response and remove any topic IDs from the cache if the metadata response did not return a topic ID for the topic. The benefit of this is that it lets us detect topic recreations. This allows the client to update metadata even if the leader epoch is lower than what was seen previously.

Reviewers: Jason Gustafson <jason@confluent.io>",2021-11-17 09:57:17,Justine Olshan,Mixed
051efc7b1a740ebe9f8fc3b167644ccf64396d50,"MINOR: Remove unused parameters, exceptions, comments, etc. (#11472)

* Remove redundant toString call & unused value in LogCleanerParameterizedIntegrationTest
* Remove unthrown exceptions in FileRawSnapshotTest
* Remove unused parameters in DumpLogSegmentsTest.scala
* Remove redundant parameter to FetchDataInfo()
* Remove redundant toString call in EndToEndLatency
* Remove unused parameters in DumpLogSegments
* Remove unused toString call in AbstractLogCleanerIntegrationTest
* Remove unused parameter in LogCleanerTest#appendTransactionalAsLeader
* Remove redundant 'val's from ClientQuotaManagerTest.UserClient.
* Remove redundant parameters in EdgeCaseRequestTest
* Remove redundant Int.MaxValue from DumpLogSegments.dumpTimeIndex parameters.
* Remove '// 9) static client-id quota' from DefaultQuotaCallback#quotaMetricTags; static client-id quota was removed in 3.0.0.
* Remove redundant parameters to DumpLogSegments#[dumpLog, dumpTimeIndex].

Reviewers: Mickael Maison <mickael.maison@gmail.com>",2021-11-18 11:52:10,Lee Dongjin,Mixed
0916622bcc04ba6fdbe2b58752c71c77341f2211,"KAFKA-13394: Topic IDs should be removed from PartitionFetchState if they are no longer sent by the controller (#11459)

With KAFKA-13102, we added topic IDs to the InitialFetchState and the PartitionFetchState in order to send fetch requests using topic IDs when IBP is 3.1. 

However, there are some cases where we could initially send topic IDs from the controller and then no longer to do so (controller changes to an IBP < 2.8). If we do not remove from the PartitionFetchState and one broker is still IBP 3.1, it will try to send a version 13 fetch request to brokers that no longer have topic IDs in the metadata cache. This could leave the cluster in a state unable to fetch from these partitions.

This patch removes the topic IDs from the PartitionFetchState if the log contains a topic ID but the request does not. This means that we will always handle a leader and isr request if there is no ID in the request but an ID in the log. 
Such a state should be transient because we are either 
* upgrading the cluster and somehow switched between a new IBP controller and an old one --> and will eventually have all new IBP controllers/brokers.
* downgrading the cluster --> will eventually have all old IBP controllers/brokers and will restart the broker/delete the partition metadata file for them.

Reviewers: David Jacot <djacot@confluent.io>",2021-11-18 17:30:40,Justine Olshan,Mixed
30a9085d505ac301acee18e4cdcc98d8060e0388,"KAFKA-9648: Add configuration to adjust listen backlog size for Acceptor (KIP-764) (#11422)

This patch implements KIP-764 as described in https://cwiki.apache.org/confluence/display/KAFKA/KIP-764%3A+Configurable+backlog+size+for+creating+Acceptor.

Reviewers: David Jacot <djacot@confluent.io>",2021-11-19 17:53:43,Okada Haruki,Mixed
1e0916580f16b99b911b0ed36e9740dcaeef520e,"KAFKA-13117: migrate TupleForwarder and CacheFlushListener to new Record API (#11481)

* Migrate TupleForwarder and CacheFlushListener to new Processor API
* Update the affected Processors

Reviewers: John Roesler <vvcephei@apache.org>",2021-11-22 21:34:59,Jorge Esteban Quilcate Otoya,Mixed
28dcbad007e64275df98868e7f79133fad0cba9e,"KAFKA-13457: SocketChannel in Acceptor#accept is not closed upon IOException (#11504)

This patch ensures that SocketChannel in Acceptor#accept is closed if an IOException is thrown while the socket is configured.

Reviewers:  Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",2021-11-24 09:30:43,Haoze Wu,Mixed
e8b53caab475a976fc2ce97d4b41977752b64633,"KAFKA-13357; Store producer IDs in broker snapshots

When creating snapshots, controllers generate a ProducerIdsRecord indicating the highest producer ID
that has been used so far. Brokers should generate the same record, so that the snapshots can be
compared.

Also, fix a bug in MetadataDelta#finishSnapshot. The current logic will produce the wrong result if
all objects of a certain type are completely removed in the snapshot. The fix is to unconditionally
create each delta object.

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",2021-11-24 11:06:09,Colin Patrick McCabe,Mixed
23e9818e625976c22fe6d4297a5ab76b01f92ef6,"KAFKA-13480: Track Position in KeyValue stores (#11514)

Add position tracking to KeyValue stores in support of KIP-796

Reviewers: John Roesler <vvcephei@apache.org>",2021-11-24 18:28:00,Patrick Stuedi,Mixed
4fed0001ec1ddbfd1f8fc9af75007e89ef40ea8d,"MINOR: Fix system test StreamsCooperativeRebalanceUpgradeTest.test_upgrade_to_cooperative_rebalance (#11532)

Log messages were changed in the AssignorConfiguration (#11490) that are
also used for verification in system test
StreamsCooperativeRebalanceUpgradeTest.test_upgrade_to_cooperative_rebalance.

This commit fixes the test and adds comments to the log messages
that point to the test that needs to be updated in case of
changes to the log messages.

Reviewers: John Roesler <vvcephei@apache.org>, Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",2021-11-25 10:48:09,Bruno Cadonna,Not TDD
e8dcbb99bb3289193a9036599d87acd56e11499f,"KAFKA-13472: Correct last-committed offsets tracking for sink tasks after partial revocation (#11526)

The `WorkerSinkTask.lastCommittedOffsets` field is now added to (via `Map::putAll`) after a successful offset commit, instead of being completely overwritten. In order to prevent this collection from growing indefinitely, elements are removed from it after topic partitions are revoked from the task's consumer.

Two test cases are added to `WorkerSinkTaskTest`:

- A basic test to verify the ""rewind for redelivery"" behavior when a task throws an exception from `SinkTask::preCommit`; surprisingly, no existing test cases appear to cover this scenario
- A more sophisticated test to verify this same behavior, but with a few rounds of cooperative consumer rebalancing beforehand that expose a bug in the current logic for the `WorkerSinkTask` class

The `VerifiableSinkTask` class is also updated to only flush the requested topic partitions in its `flush` method. This is technically unrelated to the issue addressed by this PR and can be moved to a separate PR if necessary; including it here as the original context for identifying this bug was debugging failed system tests and the logic in this part of the tests was originally suspected as a cause of the test failure.

Reviewers: Konstantine Karantasis <k.karantasis@gmail.com>",2021-11-29 11:26:08,Chris Egerton,Mixed
f875576f218c90bc4a682a641ff149d66f75e0b8,"KAFKA-13469: Block for in-flight record delivery before end-of-life source task offset commit (#11524)

Although committing source task offsets without blocking on the delivery of all in-flight records is beneficial most of the time, it can lead to duplicate record delivery if there are in-flight records at the time of the task's end-of-life offset commit.

A best-effort attempt is made here to wait for any such in-flight records to be delivered before proceeding with the end-of-life offset commit for source tasks. Connect will block for up to offset.flush.timeout.ms milliseconds before calculating the latest committable offsets for the task and flushing those to the persistent offset store.

Author: Chris Egerton <chrise@confluent.io>
Reviewer: Randall Hauch <rhauch@gmail.com>",2021-11-30 10:35:50,Chris Egerton,Mixed
42306ba267aba684f7377bd78db90fdc4139546f,"KAFKA-12932: Interfaces for SnapshotReader and SnapshotWriter (#11529)

Change the snapshot API so that SnapshotWriter and SnapshotReader are interfaces. Change the existing types SnapshotWriter and SnapshotReader to use a different name and to implement the interfaces introduced by this commit.

Co-authored-by: loboxu <loboxu@tencent.com>
Reviews: José Armando García Sancio <jsancio@users.noreply.github.com>",2021-11-30 11:44:39,loboya~,Not TDD
62f73c30d3b156a440bd0e4ac2c5491869c83ba5,"KAFKA-13498: track position in remaining state stores (#11541)

Reviewers: Vicky Papavasileiou <vpapavasileiou@confluent.io>, John Roesler<vvcephei@apache.org>",2021-12-01 11:49:10,Patrick Stuedi,Mixed
da56146c60cf016966b119ea63eb2cfa60f03ad4,"KAFKA-13461: Don't re-initialize ZK client session after auth failure if connection still alive (#11563)

If JAAS configuration does not contain a Client section for ZK clients, an auth failure event is generated. If this occurs after the connection is setup in the controller, we schedule reinitialize(), which causes controller to resign. In the case where SASL is not mandatory and the connection is alive, controller maintains the current session and doesn't register its watchers, leaving it in a bad state.

Reviewers: Jun Rao <junrao@gmail.com>",2021-12-02 22:10:37,Rajini Sivaram,Mixed
14c24490505090b0bedeabd891542915692501be,"KAFKA-13491: IQv2 framework (#11557)

Implements the major part of the IQv2 framework as proposed in KIP-796.

Reviewers: Patrick Stuedi <pstuedi@apache.org>, Vicky Papavasileiou <vpapavasileiou@confluent.io>, Bruno Cadonnna <cadonna@apache.org>",2021-12-03 12:53:31,John Roesler,Mixed
965ec40c0a282bc311c702c6eb795689ec7ddfa5,"KAFKA-12648: Make changing the named topologies have a blocking option (#11479)

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2021-12-03 11:32:55,Walker Carlson,Not TDD
a957748d2e0de872e881ec17f6cc27ada7ab7cd9,"KAFKA-13490: Fix createTopics and incrementalAlterConfigs for KRaft mode #11416

For CreateTopics, fix a bug where if one createTopics in a batch failed, they would all fail with
the same error code.  Make the error message for TOPIC_ALREADY_EXISTS consistent with the ZK-based
code by including the topic name.

For IncrementalAlterConfigs, before we allow topic configurations to be set, we should check that
they are valid. (This also applies to newly created topics.) IncrementalAlterConfigs should ignore
non-null payloads for DELETE operations. Previously we would return an error in these cases.
However, this is not compatible with the old ZK-based code, which ignores the payload in these
cases.

Reviewers: José Armando García Sancio <jsancio@gmail.com>, Jason Gustafson <jason@confluent.io>",2021-12-05 16:32:56,Colin P. Mccabe,Mixed
7acd12d6e3550d5e3768215e5bd64487c0a2ae7e,"KAFKA-13506: Write and restore position to/from changelog (#11513)

Introduces changelog headers to pass position information
to standby and restoring stores. The headers are guarded by an internal
config, which defaults to `false` for backward compatibility. Once IQv2
is finalized, we will make that flag a public config.

Reviewers: Patrick Stuedi <pstuedi@apache.org>, John Roesler <vvcephei@apache.org>",2021-12-08 11:58:35,Vicky Papavasileiou,Mixed
ddb6959c6272d2039ed8c9f595634c3c9573f85e,"KAFKA-12980; Return empty record batch from Consumer::poll when position advances due to aborted transactions (#11046)

Return empty record batch from Consumer::poll when position advances due to aborted transactions or control records. This is useful for reads to the end of a topic that contains aborted or empty transactions. If an aborted transaction is at the end of the topic, the consumer can now be expected to return from `poll` if it advances past that aborted transaction, and users can query the consumer's latest `position` for the relevant topic partitions to see if it has managed to make it past the end of the topic (or rather, what was the end of the topic when the attempt to read to the end of the topic began).

Reviewers: Jason Gustafson <jason@confluent.io>",2021-12-08 20:36:53,Chris Egerton,Mixed
e20f102298cc3e056e079cbd1cb33913a9ade0ce,"KAFKA-12648: extend IQ APIs to work with named topologies (#11562)

In the new NamedTopology API being worked on, state store names and their uniqueness requirement is going to be scoped only to the owning topology, rather than to the entire app. In other words, two different named topologies can have different state stores with the same name.

This is going to cause problems for some of the existing IQ APIs which require only a name to resolve the underlying state store. We're now going to need to take in the topology name in addition to the state store name to be able to locate the specific store a user wants to query

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2021-12-09 03:54:28,Tolga H. Dur,Not TDD
133b515b5e95a7ce511f442eb6d7892b506af27c,"KAFKA-13507: GlobalProcessor ignores user specified names (#11573)

Use the name specified via consumed parameter in InternalStreamsBuilder#addGlobalStore method for initializing the source name and processor name. If not specified, the names are generated.

Reviewers: Luke Chen <showuon@gmail.com>, Bill Bejeck <bbejeck@apache.org>",2021-12-09 09:42:00,Tamara Skokova,Mixed
d565c969f33e00ed91ce2da3f9b150d6999ab0e7,"MINOR: Refactor RequestResponseTest (#11393)

- Ensure we test all requests and responses
- Code cleanups

Reviewers: Tom Bentley <tbentley@redhat.com>, Luke Chen <showuon@gmail.com>",2021-12-10 18:54:52,Mickael Maison,Not TDD
454d63c158dcf778bf12b412063341f2dd3e3088,"KAFKA-13515: Fix KRaft config validation issues (#11577)

Require that topics exist before topic configurations can be created for them.

Merge the code from ConfigurationControlManager#checkConfigResource into
ControllerConfigurationValidator to avoid duplication.

Add KRaft support to DynamicConfigChangeTest.

Split out tests in DynamicConfigChangeTest that don't require a cluster into
DynamicConfigChangeUnitTest to save test time.

Reviewers: David Arthur <mumrah@gmail.com>",2021-12-10 12:29:58,Colin Patrick McCabe,Mixed
ff6cf670f49301a325342b6d7b598a1b462a012c,"KAFKA-13456; Tighten KRaft listener config checks/constraints (#11503)

This patch tightens the configuration checks related to KRaft configs by adding the following constraints:

* `control.plane.listener.name` is confirmed to be empty in KRaft mode whenever a config object is created as opposed to later when the broker is given the config and tries to start.
* `controller.listener.names` is required to be empty for the non-KRaft (i.e. ZooKeeper) case.  A ZooKeeper-based cluster that sets this config will fail to restart until this config is removed.
* There must be no advertised listeners when running just a KRaft controller (i.e. when `process.roles=controller`).  This means neither `listeners` nor `advertised.listeners` (if the latter is explicitly defined) can contain a listener that does not also appear in `controller.listener.names`.
* When running a KRaft broker (i.e. when `process.roles=broker` or `process.roles=broker,controller`), advertised listeners (which was already checked to be non-empty via the check that the inter-broker listener appear there) must not include any listeners appearing in `controller.listener.names`.
* When running a KRaft controller (i.e. when `process.roles=controller` or `process.roles=broker,controller`) `controller.listener.names` must be non-empty and every one must appear in `listeners`
* When running just a KRaft broker (i.e. when `process.roles=broker`) `controller.listener.names` must be non-empty and none of them can appear in `listeners`.  This was indirectly checked previously, but the indirect checks did not catch all cases.
* When running just a KRaft broker we log a warning if more than one entry appears in `controller.listener.names` because only the first entry is used.
* We also map configured controller listener names to the `PLAINTEXT` security protocol by default provided that the security mapping is empty and no other security protocols are in use.

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",2021-12-10 13:28:57,Ron Dagostino,Mixed
1e459271d777e4721c3f7a36c5b4fbb2a5793f63,"KAFKA-12648: fix IllegalStateException in ClientState after removing topologies (#11591)

Fix for one of the causes of failure in the NamedTopologyIntegrationTest: org.apache.kafka.streams.errors.StreamsException: java.lang.IllegalStateException: Must initialize prevActiveTasks from ownedPartitions before initializing remaining tasks.

This exception could occur if a member sent in a subscription where all of its ownedPartitions were from a named topology that is no longer recognized by the group leader, eg because it was just removed from the client. We should filter each ClientState based on the current topology only so the assignor only processes the partitions/tasks it can identify. The member with the out-of-date tasks will eventually clean them up when the #removeNamedTopology API is invoked on them

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",2021-12-10 14:26:27,A. Sophie Blee-Goldman,Mixed
2cd96f0e64f8a4f4b74e8049a6c527a990cb4777,MINOR: some code cleanups in the controller,2021-12-10 15:29:50,Colin P. Mccabe,Mixed
acd1f9c5631ed2aec2d6ab238e6b81c1a9eb47a2,"KAFKA-13522: add position tracking and bounding to IQv2 (#11581)

* Fill in the Position response in the IQv2 result.
* Enforce PositionBound in IQv2 queries.
* Update integration testing approach to leverage consistent queries.

Reviewers: Patrick Stuedi <pstuedi@apache.org>, Vicky Papavasileiou <vpapavasileiou@confluent.io>, Guozhang Wang <guozhang@apache.org>",2021-12-11 01:00:59,John Roesler,Mixed
065fba96198074ab473e4734ae29084d3681084a,"KAFKA-13539: Improve propagation and processing of SSL handshake failures (#11597)

When server fails SSL handshake and closes its connection, we attempt to report this to clients on a best-effort basis. When IOException is detected in the client, we may proceed to close the connection before processing all the data from the server if we have data pending to be sent to the server. Server attempts to send any data that has been already wrapped, but may not wrap again after handshake failure, so error may not be propagated to clients. However, our tests assume that clients always detect handshake failures. This commit attempts to wrap and send all data on the server-side after handshake failure and attempts to process all data on the client-side.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2021-12-14 10:01:58,Rajini Sivaram,Mixed
f653cb7b5889fd619ab0e6a25216bd981a9d82bf,"KAFKA-13488: Producer fails to recover if topic gets deleted midway (#11552)

Allow the leader epoch to be re-assigned to the new value from the Metadata response if `oldTopicId` is not present in the cache. This is needed because `oldTopicId` is removed from the cache if the topic gets deleted but the leader epoch is not removed. Hence, metadata for the newly recreated topic won't be accepted unless we allow `oldTopicId` to be null.

Reviewers: Jason Gustafson <jason@confluent.io>, David Jacot <djacot@confluent.io>",2021-12-16 15:44:39,Prateek Agarwal,Mixed
b38f6ba5cc989702180f5d5f8e55ba20444ea884,"KAFKA-13479: Implement range and scan queries (#11598)

Implement the RangeQuery as proposed in KIP-805

Reviewers: John Roesler <vvcephei@apache.org>",2021-12-16 11:09:01,Vicky Papavasileiou,Not TDD
c219fba421fde142729a42da038a8e747b71cca4,"KAFKA-13419: Only reset generation ID when ILLEGAL_GENERATION error (#11451)

Updated: This PR will reset generation ID when ILLEGAL_GENERATION error since the member ID is still valid.

=====
resetStateAndRejoin when REBALANCE_IN_PROGRESS error in sync group, to avoid out-of-date ownedPartition

== JIRA description ==
In KAFKA-13406, we found there's user got stuck when in rebalancing with cooperative sticky assignor. The reason is the ""ownedPartition"" is out-of-date, and it failed the cooperative assignment validation.

Investigate deeper, I found the root cause is we didn't reset generation and state after sync group fail. In KAFKA-12983, we fixed the issue that the onJoinPrepare is not called in resetStateAndRejoin method. And it causes the ownedPartition not get cleared. But there's another case that the ownedPartition will be out-of-date. Here's the example:

consumer A joined and synced group successfully with generation 1
New rebalance started with generation 2, consumer A joined successfully, but somehow, consumer A doesn't send out sync group immediately
other consumer completed sync group successfully in generation 2, except consumer A.
After consumer A send out sync group, the new rebalance start, with generation 3. So consumer A got REBALANCE_IN_PROGRESS error with sync group response
When receiving REBALANCE_IN_PROGRESS, we re-join the group, with generation 3, with the assignment (ownedPartition) in generation 1.
So, now, we have out-of-date ownedPartition sent, with unexpected results happened
We might want to do resetStateAndRejoin when RebalanceInProgressException errors happend in sync group. Because when we got sync group error, it means, join group passed, and other consumers (and the leader) might already completed this round of rebalance. The assignment distribution this consumer have is already out-of-date.

Reviewers: David Jacot <djacot@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2021-12-17 15:36:12,Luke Chen,Mixed
57477886593a60cd92cc50b5722788f9ac1c3d7a,"KAFKA-13525: Implement KeyQuery in Streams IQv2 (#11582)

Implement the KeyQuery as proposed in KIP-796

Reviewers: Vicky Papavasileiou <vpapavasileiou@confluent.io>, Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <guozhang@apache.org>",2021-12-20 12:22:05,John Roesler,Not TDD
b8f1cf14c396ab04b8968a8fa04d8cf67dd3254c,"KAFKA-13494: WindowKeyQuery and WindowRangeQuery (#11567)

Implement WindowKeyQuery and WindowRangeQuery as
proposed in KIP-806

Reviewer: John Roesler <vvcephei@apache.org>",2022-01-02 22:17:38,Patrick Stuedi,Not TDD
7ef8701cca92d8d4ecf07b2b12832aaafb8a5331,"KAFKA-13553: add PAPI KV store tests for IQv2 (#11624)

During some recent reviews, @mjsax pointed out that StateStore layers
are constructed differently the stores are added via the PAPI vs. the DSL.

This PR adds KeyValueStore PAPI construction to the
IQv2StoreIntegrationTest so that we can ensure IQv2 works on every
possible state store.

Reviewers: Patrick Stuedi <pstuedi@apache.org>, Guozhang Wang <guozhang@apache.org>",2022-01-05 21:04:37,John Roesler,Not TDD
7567cbc857eef4f535410a8f6256308197c3b9c8,"KAFKA-13476: Increase resilience timestamp decoding Kafka Streams (#11535)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2022-01-05 21:38:10,Richard,Mixed
8e301b48e937198c65a058518dc7551488aac8fc,"KAFKA-13528: KRaft RegisterBroker should validate that the cluster ID matches (#11593)

The KRaft controller should validate that the clusterID matches before allowing a broker to register in
the cluster.

Reviewers: José Armando García Sancio <jsancio@gmail.com>",2022-01-06 10:28:36,Colin Patrick McCabe,Mixed
c182a431d224cb39c0bb43a55199e2d8b4aee1b7,"MINOR: prefix topics if internal config is set (#11611)

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2022-01-10 16:08:48,Walker Carlson,Not TDD
1aa26faf8889005d65e338540e888b60ef5a611f,"MINOR: Fix EventQueueProcessingTimeMs metric #11668

Make sure that the event queue processing time histogram gets updated
and add tests that verify that the update methods modify the correct
histogram.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2022-01-11 21:48:39,José Armando García Sancio,Mixed
5c7cf29c150631e7572934c69b3685d34c56f2ab,"KAFKA-7589: Allow configuring network threads per listener (#11560)

Implements KIP-788. The number of network threads can be set per listener using the following syntax:
listener.name.<listener>.num.network.threads=<num>

Reviewers: Tom Bentley <tbentley@redhat.com>, Andrew Eugene Choi <andrew.choi@uwaterloo.ca>, David Jacot  <djacot@confluent.io>",2022-01-13 11:24:50,Mickael Maison,Mixed
69645f1fe5103adb00de6fa43152e7df989f3aea,"KAFKA-13495: Add reason to JoinGroupRequest (KIP-800) (#11566)

This patch adds a `reason` field to the `JoinGroupRequest` as specified in KIP-800: https://cwiki.apache.org/confluence/display/KAFKA/KIP-800%3A+Add+reason+to+JoinGroupRequest+and+LeaveGroupRequest.

Reviewers: loboya~ <317307889@qq.com>, Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",2022-01-13 16:01:37,Jeff Kim,Mixed
bf609694f83931990ce63e0123f811e6475820c5,"KAFKA-13496: Add reason to LeaveGroupRequest (KIP-800) (#11571)

This patch adds a `reason` field to the `LeaveGroupRequest` as specified in KIP-800: https://cwiki.apache.org/confluence/display/KAFKA/KIP-800%3A+Add+reason+to+JoinGroupRequest+and+LeaveGroupRequest.

Reviewers: Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",2022-01-13 16:06:11,Jeff Kim,Mixed
529dde904a892ba2f95e6150066758e7476f15e3,"KAFKA-12648: handle MissingSourceTopicException for named topologies (#11600)

Avoid throwing a MissingSourceTopicException inside the #assign method when named topologies are used, and just remove those topologies which are missing any of their input topics from the assignment.

Reviewers: Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>, Bruno Cadonna <cadonna@confluent.io>",2022-01-18 11:49:23,A. Sophie Blee-Goldman,Mixed
ed8b7875fed82feccec3d35aa700cce1ea5138f9,"KAFKA-13351: Add possibility to write kafka headers in Kafka Console Producer (KIP-798) (#11456)

This patch adds the possibility to write Kafka headers with the `kafka-console-producer` as specified in KIP-798: https://cwiki.apache.org/confluence/display/KAFKA/KIP-798%3A+Add+possibility+to+write+kafka+headers+in+Kafka+Console+Producer.

Reviewers: David Jacot <djacot@confluent.io>, Mickael Maison <mickael.maison@gmail.com>",2022-01-19 09:53:28,florin-akermann,Not TDD
df2236d73bc630a588adc049e7e63a4a5095da32,"KAFKA-13412; Ensure initTransactions() safe for retry after timeout (#11452)

If the user's `initTransactions` call times out, the user is expected to retry. However, the producer will continue retrying the `InitProducerId` request in the background. If it happens to return before the user retry of `initTransactions`, then the producer will raise an exception about an invalid state transition. 

The patch fixes the issue by tracking the pending state transition until the user has acknowledged the operation's result. In the case of `initTransactions`, even if the `InitProducerId` returns in the background and the state changes, we can still retry the `initTransactions` call to obtain the result.

Reviewers: David Jacot <djacot@confluent.io>",2022-01-19 13:20:41,Jason Gustafson,Mixed
7d9b9847f184ec72c4c80c046edc408789dcc066,"KAFKA-6502: Update consumed offsets on corrupted records. (#11683)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2022-01-20 09:26:38,Aleksandr Sorokoumov,Mixed
33a004ab6270c3e30c15fb555a50113131debff5,"KAFKA-13388; Kafka Producer nodes stuck in CHECKING_API_VERSIONS (#11671)

At the moment, the `NetworkClient` will remain stuck in the `CHECKING_API_VERSIONS` state forever if the `Channel` does not become ready. To prevent this from happening, this patch changes the logic to transition to the `CHECKING_API_VERSIONS` only when the `ApiVersionsRequest` is queued to be sent out. With this, the connection will timeout if the `Channel` does not become ready within the connection setup timeout. Once the `ApiVersionsRequest` is queued up, the request timeout takes over.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2022-01-21 17:44:56,David Jacot,Mixed
68a19539cf1fcd86787960d0010b672d0d611b91,"KAFKA-13552: Fix BROKER and BROKER_LOGGER in KRaft (#11657)

Currently, KRaft does not support setting BROKER_LOGGER configs (it always fails.) Additionally,
there are several bugs in the handling of BROKER configs. They are not properly validated on the
forwarding broker, and the way we apply them is buggy as well. This PR fixes those issues.

KafkaApis: add support for doing validation and log4j processing on the forwarding broker. This
involves breaking the config request apart and forwarding only part of it. Adjust KafkaApisTest to
test the new behavior, rather than expecting forwarding of the full request.

MetadataSupport: remove MetadataSupport#controllerId since it duplicates the functionality of
MetadataCache#controllerId. Add support for getResourceConfig and maybeForward.

ControllerApis: log an error message if the handler throws an exception, just like we do in
KafkaApis.

ControllerConfigurationValidator: add JavaDoc.

Move some functions that don't involve ZK from ZkAdminManager to DynamicConfigManager. Move some
validation out of ZkAdminManager and into a new class, ConfigAdminManager, which is not tied to ZK.

ForwardingManager: add support for sending new requests, rather than just forwarding existing
requests.

BrokerMetadataPublisher: do not try to apply dynamic configurations for brokers other than the
current one. Log an INFO message when applying a new dynamic config, like we do in ZK mode. Also,
invoke reloadUpdatedFilesWithoutConfigChange when applying a new non-default BROKER config.

QuorumController: fix a bug in ConfigResourceExistenceChecker which prevented cluster configs from
being set. Add a test for this class.

Reviews: José Armando García Sancio <jsancio@users.noreply.github.com>",2022-01-21 17:00:21,Colin Patrick McCabe,Mixed
d13d09fb682356a3013ca531c769e92a664657db,"KAFKA-13590:rename InternalTopologyBuilder#topicGroups (#11704)

Renamed the often confusing and opaque #topicGroups API to #subtopologyToTopicsInfo

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2022-01-24 21:03:37,Sayantanu Dey,Mixed
265d3199ec741928c1731397302f6c320cf6af40,"KAFKA-12648: fixes for query APIs with named topologies (#11609)

Fixes some issues with the NamedTopology version of the IQ methods that accept a topologyName argument, and adds tests for all.

Reviewers:  Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",2022-01-25 05:49:23,A. Sophie Blee-Goldman,Mixed
9d602a01beb0a9467c43b9ee0b80ff53fdd2dbb4,"KAFKA-12648: invoke exception handler for MissingSourceTopicException with named topologies (#11686)

Followup to #11600 to invoke the streams exception handler on the MissingSourceTopicException, without killing/replacing the thread

Reviewers: Guozhang Wang <guozhang@confluent.io>, Bruno Cadonna <cadonna@confluent.io>",2022-01-25 10:37:35,A. Sophie Blee-Goldman,Mixed
96fa468106f538ca83973ce040e6cfe900f389ed,"MINOR: fix NPE in iqv2 (#11702)

There is a brief window between when the store is registered and when
it is initialized when it might handle a query, but there is no context.
We treat this condition just like a store that hasn't caught up to the
desired position yet.

Reviewers: Guozhang Wang <guozhang@apache.org>, Matthias J. Sax <mjsax@apache.org>, A. Sophie Blee-Goldman <ableegoldman@apache.org>, Patrick Stuedi <pstuedi@apache.org>",2022-01-25 13:23:46,John Roesler,Mixed
868cbcb8e54493a60668bdb433b2821d64d9bb97,"MINOR: Fix bug of empty position in windowed and session stores #11713 

Reviewers: John Roesler <vvcephei@apache.org>",2022-01-25 13:46:20,Vicky Papavasileiou,Not TDD
da25add383b3c855bfaa7cd12eff84539fe27e38,"MINOR: Add shutdown tests for KRaft (#11606)

Augments existing shutdown tests for KRaft. Adds the ability to update configs in KRaft tests,
and in both the ZK and KRaft cases to be able to update configs without losing the server's
log directory and data.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2022-01-25 23:38:11,Ron Dagostino,Not TDD
000ba031c3d1135cb0e1fe6438d1e464ff10b6b0,"KAFKA-9279: Fail producer transactions for asynchronously-reported, synchronously-encountered ApiExceptions (#11508)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2022-01-26 11:51:10,Chris Egerton,Mixed
fe72187cb15bf7dcc16e8630ed379e979c101151,"KAFKA-13524: Add IQv2 query handling to the caching layer (#11682)

Currently, IQv2 forwards all queries to the underlying store. We add this bypass to allow handling of key queries in the cache. If a key exists in the cache, it will get answered from there.
As part of this PR, we realized we need access to the position of the underlying stores. So, I added the method getPosition to the public API and ensured all state stores implement it. Only the ""leaf"" stores (Rocks*, InMemory*) have an actual position, all wrapping stores access their wrapped store's position.

Reviewers: Patrick Stuedi <pstuedi@apache.org>, John Roesler <vvcephei@apache.org>",2022-01-26 09:36:39,Vicky Papavasileiou,Mixed
e51ebb8a0ab5e9322572fae6bfcdfac74a603e87,"MINOR: Convert LogLoader into a class (#11693)

The logic for log loading is encapsulated in `LogLoader`. Currently all the methods are static and we pass the parameters through a separate object `LogLoaderParams`. This patch simplifies this structure by turning `LogLoader` into a normal object and get rid of `LogLoaderParams`. 

Reviewers: David Jacot <djacot@confluent.io>",2022-01-26 12:54:07,Jason Gustafson,Mixed
5eef6b269d86944798001f2a9a7361498d6a25fc,"KAFKA-13614: Don't apply leader replication quota to consumer fetches (#11714)

In the fetch path, we check shouldLeaderThrottle regardless of whether the read is coming from a consumer or follower broker. This results in replication quota being applied to consumer fetches. This patch ensures that it is only applied to followers.

Reviewers: David Jacot <djacot@confluent.io>",2022-01-27 08:21:57,David Mao,Not TDD
1a218926636d2d0f31b4ad402f8d26c2ad8d9838,"KAFKA-13605: checkpoint position in state stores (#11676)

There are cases in which a state store neither has an in-memory position built up nor has it gone through the state restoration process. If a store is persistent (i.e., RocksDB), and we stop and restart Streams, we will have neither of those continuity mechanisms available.

This patch:
* adds a test to verify that all stores correctly recover their position after a restart
* implements storage and recovery of the position for persistent stores alongside on-disk state

Reviewers: Vicky Papavasileiou <vpapavasileiou@confluent.io>, Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <guozhang@apache.org>, John Roesler <vvcephei@apache.org>",2022-01-27 09:25:04,Patrick Stuedi,Mixed
9f2f63e3a118acb334b6ca755392da06c938f2e5,"KAFKA-13348: Allow Source Tasks to Handle Producer Exceptions (KIP-779) (#11382)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chris Egerton <fearthecellos@gmail.com>",2022-01-27 19:17:59,"Knowles Atchison, Jr",Mixed
a21aec8d6287f170ccb2568eadde515980dd597c,"KAFKA-13603: Allow the empty active segment to have missing offset index during recovery (#11345)

Within a LogSegment, the TimeIndex and OffsetIndex are lazy indices that don't get created on disk until they are accessed for the first time. However, Log recovery logic expects the presence of an offset index file on disk for each segment, otherwise, the segment is considered corrupted.

This PR introduces a forceFlushActiveSegment boolean for the log.flush function to allow the shutdown process to flush the empty active segment, which makes sure the offset index file exists.

Co-Author: Kowshik Prakasam kowshik@gmail.com
Reviewers: Jason Gustafson <jason@confluent.io>, Jun Rao <junrao@gmail.com>",2022-01-27 14:59:21,Cong Ding,Mixed
af377b5f30e7cff691bb50f67c3e9a1cd040fe32,"KAFKA-13423: GlobalThread should not log ERROR on clean shutdown (#11455)

Reviewers: Guozhang Wang <guozhang@confluent.io>, Bruno Cadonna <cadonna@confluent.io>",2022-01-27 20:40:43,Matthias J. Sax,Mixed
14c6030c6ad70997863070f5b93c817ea8829425,"KAFKA-13152: Replace ""buffered.records.per.partition"" with ""input.buffer.max.bytes"" (#11424)

This PR is an implementation of: https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=186878390. The following changes have been made:

* Adding a new config input.buffer.max.bytes applicable at a topology level.
* Adding new config statestore.cache.max.bytes.
* Adding new metric called input-buffer-bytes-total.
* The per partition config buffered.records.per.partition is deprecated.
* The config cache.max.bytes.buffering is deprecated.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Guozhang Wang <guozhang@confluent.io>",2022-01-27 21:19:04,vamossagar12,Mixed
7215c90c5e9086126cbecbb5d8b3bfee22f6d1fa,"MINOR: Add 3.0 and 3.1 to streams system tests (#11716)

Reviewers: Bill Bejeck <bill@confluent.io>",2022-01-28 10:06:31,David Jacot,Not TDD
a47dae4622a25d7ca094c32ef36cf234a6c61cca,"MINOR: ConsoleConsumer should not always exit when Consumer::poll returns an empty record batch (#11718)

With https://github.com/apache/kafka/commit/ddb6959c6272d2039ed8c9f595634c3c9573f85e, `Consumer::poll` will return an empty record batch when position advances due to aborted transactions or control records. This makes the `ConsoleConsumer` exists because it assumes that `poll` returns due to the timeout being reached. This patch fixes this by explicitly tracking the timeout.

Reviewers: Jason Gustafson <jason@confluent.io>",2022-01-31 10:34:11,David Jacot,Mixed
830d83e2cde4f33735128b533cacc8b8ea23a2c0,"MINOR: Fix typo ""Exsiting"" -> ""Existing"" (#11547)

Co-authored-by: Kurt Ostfeld <kurt@samba.tv>
Reviewers: Kvicii <Karonazaba@gmail.com>, Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",2022-02-01 11:09:04,kurtostfeld,Not TDD
31fca1611a6780e8a8aa3ac21618135201718e32,"KAFKA-13527: Add top-level error code field to DescribeLogDirsResponse (#11599)

Implements KIP-784: https://cwiki.apache.org/confluence/display/KAFKA/KIP-784%3A+Add+top-level+error+code+field+to+DescribeLogDirsResponse

Reviewers: David Jacot <djacot@confluent.io>, Tom Bentley <tbentley@redhat.com>",2022-02-01 18:53:30,Mickael Maison,Mixed
3b534e1c7d098a8dc7e08f95c2611b53fa40f522,"KAFKA-13595: Allow producing records with null fields in ConsoleProducer (#11695)

Implements KIP-810: https://cwiki.apache.org/confluence/display/KAFKA/KIP-810%3A+Allow+producing+records+with+null+values+in+Kafka+Console+Producer

ConsoleProducer accepts a new setting, `null.marker`, that allows settings the record key, value or headers to null. This can be used to produce ""tombstone"" records.

Reviewers: David Jacot <djacot@confluent.io>, Tom Bentley <tbentley@redhat.com>, Israel Ekpo <israelekpo@gmail.com>",2022-02-01 18:56:04,Mickael Maison,Not TDD
67cf187603f54ba4f53f0b9eb93b269430f829db,"Revert ""KAFKA-13152: Replace ""buffered.records.per.partition"" with ""input.buffer.max.bytes"" (#11424)""

This reverts commit 14c6030c6ad70997863070f5b93c817ea8829425.
Reason: Implemenation breaks backward compatibility",2022-02-01 14:08:11,Matthias J. Sax,Mixed
4101be51aa2331b11d19707b641e4df159d7aef1,"KAFKA-13619: Remove zookeeper.sync.time.ms (#11717)

`zookeeper.sync.time.ms` was previously used with the old Scala consumer, which
was removed in Apache Kafka 2.0.0. Remove the config definition from `KafkaConfig`
and documentation.

Reviewers: Luke Chen <showuon@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2022-02-02 05:59:13,Tomonari Yamashita,Mixed
915991445fde106d02e61a70425ae2601c813db0,"KAFKA-13221; Implement `PartitionsWithLateTransactionsCount` metric (#11725)

This patch implements a new metric `PartitionsWithLateTransactionsCount` which tracks the number of partitions with late transactions in the cluster. This metric was documented in KIP-664: https://cwiki.apache.org/confluence/display/KAFKA/KIP-664%3A+Provide+tooling+to+detect+and+abort+hanging+transactions.

Reviewers: David Jacot <djacot@confluent.io>",2022-02-02 11:57:13,Jason Gustafson,Mixed
319732dbeb08aa7926175cbaf4dfa8a05c52ac18,"KAFKA-12841: Fix producer callback handling when partition is missing (#11689)

Sometimes, the Kafka producer encounters an error prior to selecting a topic partition. In this case, we
would like to acknowledge the failure in the producer interceptors, if any are configured. We should also
pass a non-null Metadata object to the producer callback, if there is one. This PR implements that
behavior. It also updates the JavaDoc to clarify that if a partition cannot be selected, we will pass
back a partition id of -1 in the metadata. This is in keeping with KAFKA-3303.

Co-authors: Kirk True <kirk@mustardgrain.com>
Reviewers: Colin P. McCabe <cmccabe@apache.org>",2022-02-02 16:03:32,Philip Nee,Mixed
af6a9a17bffe654096d21190b3742e8835b2fccf,"KAFKA-13637: Use default.api.timeout.ms as default timeout value for KafkaConsumer.endOffsets (#11726)

We introduced `default.api.timeout.ms` in https://github.com/apache/kafka/commit/53ca52f855e903907378188d29224b3f9cefa6cb but we missed updating `KafkaConsumer.endOffsets` which still use `request.timeout.ms`. This patch fixes this.

Reviewers: David Jacot <djacot@confluent.io>",2022-02-03 10:32:25,dengziming,Mixed
e6db0ca48c42c03655e3781b46ac09dae75cf33e,"KAFKA-13598: enable idempotence producer by default and validate the configs (#11691)

In v3.0, we changed the default value for `enable.idempotence` to true, but we didn't adjust the validator and the `idempotence` enabled check method. So if a user didn't explicitly enable idempotence, this feature won't be turned on. This patch addresses the problem, cleans up associated logic, and fixes tests that broke as a result of properly applying the new default. Specifically it does the following:

1. fix the `ProducerConfig#idempotenceEnabled` method, to make it correctly detect if `idempotence` is enabled or not
2. remove some unnecessary config overridden and checks due to we already default `acks`, `retries` and `enable.idempotence` configs.
3. move the config validator for the idempotent producer from `KafkaProducer` into `ProducerConfig`. The config validation should be the responsibility of `ProducerConfig` class.
4. add an `AbstractConfig#hasKeyInOriginals` method, to avoid `originals` configs get copied and only want to check the existence of the key. 
5. fix many broken tests. As mentioned, we didn't actually enable idempotence in v3.0. After this PR, there are some tests broken due to some different behavior between idempotent and non-idempotent producer.
6. add additional tests to validate configuration behavior

Reviewers: Kirk True <kirk@mustardgrain.com>, Ismael Juma <ismael@juma.me.uk>, Mickael Maison <mimaison@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",2022-02-05 10:53:27,Luke Chen,Mixed
ba0fe610eddf2710cdb404f198a9886c01293de3,"MINOR: Do not use optional args in `ProducerStateManager` (#11734)

We allowed `maxProducerIdExpirationMs` and `time` to be optional in the `ProducerStateManager` constructor. We generally frown on optional arguments since it is too easy to overlook them. In this case, it was especially dangerous because the recently added `maxTransactionTimeoutMs` argument used the same type as `maxProducerIdExpirationMs`.

Reviewers: David Jacot <david.jacot@gmail.com, Ismael Juma <ismael@juma.me.uk>",2022-02-05 11:00:17,Jason Gustafson,Mixed
f49524e4c315e47f6a29cf330db8755fb6d51c57,"MINOR: disable zookeeper.sasl.client to avoid false error (#11469)

Reviewers: Mickael Maison <mimaison@users.noreply.github.com>",2022-02-06 03:34:22,Chia-Ping Tsai,Mixed
c05403f47fa4e6a8244b56c2287b64a42b968292,"KAFKA-13629: Use faster algorithm for ByteUtils sizeOfXxx algorithm (#11721)

Replace loop with a branch-free implementation.

Include:
- Unit tests that includes old code and new code and runs through several ints/longs.
- JMH benchmark that compares old vs new performance of algorithm.

JMH results with JDK 17.0.2 and `compiler` blackhole mode are 2.8-3.4 faster with
the new implementation. In a real application, a 6% reduction in CPU cycles was
observed in the `send()` path via flamegraphs.

```
ByteUtilsBenchmark.testSizeOfUnsignedVarint                            thrpt    4  1472440.102 ±  67331.797  ops/ms
ByteUtilsBenchmark.testSizeOfUnsignedVarint:·async                     thrpt               NaN                  ---
ByteUtilsBenchmark.testSizeOfUnsignedVarint:·gc.alloc.rate             thrpt    4       ≈ 10⁻⁴               MB/sec
ByteUtilsBenchmark.testSizeOfUnsignedVarint:·gc.alloc.rate.norm        thrpt    4       ≈ 10⁻⁷                 B/op
ByteUtilsBenchmark.testSizeOfUnsignedVarint:·gc.count                  thrpt    4          ≈ 0               counts
ByteUtilsBenchmark.testSizeOfUnsignedVarintSimple                      thrpt    4   521333.117 ± 595169.618  ops/ms
ByteUtilsBenchmark.testSizeOfUnsignedVarintSimple:·async               thrpt               NaN                  ---
ByteUtilsBenchmark.testSizeOfUnsignedVarintSimple:·gc.alloc.rate       thrpt    4       ≈ 10⁻⁴               MB/sec
ByteUtilsBenchmark.testSizeOfUnsignedVarintSimple:·gc.alloc.rate.norm  thrpt    4       ≈ 10⁻⁶                 B/op
ByteUtilsBenchmark.testSizeOfUnsignedVarintSimple:·gc.count            thrpt    4          ≈ 0               counts
ByteUtilsBenchmark.testSizeOfVarlong                                   thrpt    4  1106519.633 ±  16556.502  ops/ms
ByteUtilsBenchmark.testSizeOfVarlong:·async                            thrpt               NaN                  ---
ByteUtilsBenchmark.testSizeOfVarlong:·gc.alloc.rate                    thrpt    4       ≈ 10⁻⁴               MB/sec
ByteUtilsBenchmark.testSizeOfVarlong:·gc.alloc.rate.norm               thrpt    4       ≈ 10⁻⁶                 B/op
ByteUtilsBenchmark.testSizeOfVarlong:·gc.count                         thrpt    4          ≈ 0               counts
ByteUtilsBenchmark.testSizeOfVarlongSimple                             thrpt    4   324435.607 ± 147754.813  ops/ms
ByteUtilsBenchmark.testSizeOfVarlongSimple:·async                      thrpt               NaN                  ---
ByteUtilsBenchmark.testSizeOfVarlongSimple:·gc.alloc.rate              thrpt    4       ≈ 10⁻⁴               MB/sec
ByteUtilsBenchmark.testSizeOfVarlongSimple:·gc.alloc.rate.norm         thrpt    4       ≈ 10⁻⁶                 B/op
ByteUtilsBenchmark.testSizeOfVarlongSimple:·gc.count                   thrpt    4          ≈ 0               counts
```

Reviewers: Ismael Juma <ismael@juma.me.uk>, Artem Livshits",2022-02-06 13:36:44,Jason Koch,Mixed
ca5d6f9229c170beb23809159113037f05a1120f,"KAFKA-13563: clear FindCoordinatorFuture for non consumer group mode (#11631)

After KAFKA-10793, we clear the findCoordinatorFuture in 2 places:

1. heartbeat thread
2. AbstractCoordinator#ensureCoordinatorReady

But in non consumer group mode with group id provided (for offset commitment. So that there will be consumerCoordinator created), there will be no (1)heartbeat thread , and it only call (2)AbstractCoordinator#ensureCoordinatorReady when 1st time consumer wants to fetch committed offset position. That is, after 2nd lookupCoordinator call, we have no chance to clear the findCoordinatorFuture , and causes the offset commit never succeeded.

To avoid the race condition as KAFKA-10793 mentioned, it's not safe to clear the findCoordinatorFuture in the future listener. So, I think we can fix this issue by calling AbstractCoordinator#ensureCoordinatorReady when coordinator unknown in non consumer group case, under each ConsumerCoordinator#poll.


Reviewers: Guozhang Wang <wangguoz@gmail.com>",2022-02-06 15:07:59,Luke Chen,Mixed
b125a06c4625b106c7d743d602b9147b1951eac6,"MINOR: Use CRC32 from standard library and remove custom implementation (#11736)

We only use it in the legacy record formats (V0 and V1) and the CRC32
implementation in the standard library has received various performance
improvements over the years
(https://bugs.openjdk.java.net/browse/JDK-8245512 is a recent example).

Also worth noting that record formats V0 and V1 have been deprecated
since Apache Kafka 3.0.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Kvicii <Karonazaba@gmail.com>",2022-02-07 06:42:30,Ismael Juma,Mixed
f1fdd31e8f0fd3145aeb86fb561e97e99672a623,"KAFKA-7572: Producer should not send requests with negative partition id (#10525)

This PR is for KAFKA-7572, which fixes the issue that producers will throw confusing exceptions when a custom Partitioner returns a negative partition. Since the PR #5858 is not followed by anyone currently, I reopen this one to continue the work.

Reviewers: Luke Chen <showuon@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2022-02-07 09:53:10,Wenhao Ji,Mixed
7c2d6724130f8251aa255917b74d9c3ef1fe67f7,"MINOR: Update library dependencies (Q1 2022) (#11306)

- scala 2.13: 2.13.6 -> 2.13.8
  * Support Java 18 and improve Android compatibility
  * https://www.scala-lang.org/news/2.13.7
  * https://www.scala-lang.org/news/2.13.8
- scala 2.12: 2.12.14 -> 2.12.15. 
  * The `-release` flag now works with Scala 2.12, backend parallelism
    can be enabled via `-Ybackend-parallelism N` and string interpolation
    is more efficient.
  * https://www.scala-lang.org/news/2.12.5
- gradle versions plugin: 0.38.0 -> 0.42.0
  * Minor fixes
  * https://github.com/ben-manes/gradle-versions-plugin/releases/tag/v0.40.0
  * https://github.com/ben-manes/gradle-versions-plugin/releases/tag/v0.41.0
  * https://github.com/ben-manes/gradle-versions-plugin/releases/tag/v0.42.0
- gradle dependency check plugin: 6.1.6 -> 6.5.3
  * Minor fixes
- gradle spotbugs plugin: 4.7.1 -> 5.0.5
  * Fixes and minor improvements
  * There were too many releases to include all the links, include the major version bump
  * https://github.com/spotbugs/spotbugs-gradle-plugin/releases/tag/5.0.0
- gradle scoverage plugin: 5.0.0 -> 7.0.0
  * Support newer Gradle versions and other improvements
  * https://github.com/scoverage/gradle-scoverage/releases/tag/6.0.0
  * https://github.com/scoverage/gradle-scoverage/releases/tag/6.1.0
  * https://github.com/scoverage/gradle-scoverage/releases/tag/7.0.0
- gradle shadow plugin: 7.0.0 -> 7.1.2
  * Support gradle toolchains and security fixes
  * https://github.com/johnrengelman/shadow/releases/tag/7.1.0
  * https://github.com/johnrengelman/shadow/releases/tag/7.1.1
  * https://github.com/johnrengelman/shadow/releases/tag/7.1.2
- bcpkix: 1.66 -> 1.70
  * Several improvements and fixes
  * https://www.bouncycastle.org/releasenotes.html
- jline: 3.12.1 -> 3.21.0
  * Various fixes and improvements
- jmh: 1.32 -> 1.34
  * Compiler blackhole enabled by default when using Java 17 and improved
    gradle incremental compilation
  * https://mail.openjdk.java.net/pipermail/jmh-dev/2021-August/003355.html
  * https://mail.openjdk.java.net/pipermail/jmh-dev/2021-December/003406.html
- scalaLogging: 3.9.3 -> 3.9.4
  * Support for Scala 3.0
- jose4j: 0.7.8 -> 0.7.9
  * Minor fixes
- junit: 5.7.1 -> 5.8.2
  * Minor improvements and fixes
  * https://junit.org/junit5/docs/current/release-notes/index.html#release-notes-5.8.0
  * https://junit.org/junit5/docs/current/release-notes/index.html#release-notes-5.8.1
  * https://junit.org/junit5/docs/current/release-notes/index.html#release-notes-5.8.2
- jqwik: 1.5.0 -> 1.6.3
  * Numerous improvements
  * https://github.com/jlink/jqwik/releases/tag/1.6.0
- mavenArtifact: 3.8.1 -> 3.8.4
- mockito: 3.12.4 -> 4.3.1
  * Removed deprecated methods, `DoNotMock` annotation and
    minor fixes/improvements
  * https://github.com/mockito/mockito/releases/tag/v4.0.0
  * https://github.com/mockito/mockito/releases/tag/v4.1.0
  * https://github.com/mockito/mockito/releases/tag/v4.2.0
  * https://github.com/mockito/mockito/releases/tag/v4.3.0
- scalaCollectionCompat: 2.4.4 -> 2.6.0
  * Minor fixes
  * https://github.com/scala/scala-collection-compat/releases/tag/v2.5.0
  * https://github.com/scala/scala-collection-compat/releases/tag/v2.6.0
- scalaJava8Compat: 1.0.0 -> 1.0.2
  * Minor changes
- scoverage: 1.4.1 -> 1.4.11
  * Support for newer Scala versions
- slf4j: 1.7.30 -> 1.7.32
  * Minor fixes, 1.7.35 automatically uses reload4j and 1.7.33/1.7.34
    cause build failures, so we stick with 1.7.32 for now.
- zstd: 1.5.0-4 -> 1.5.2-1
  * zstd 1.5.2
  * Small refinements and performance improvements
  * https://github.com/facebook/zstd/releases/tag/v1.5.1
  * https://github.com/facebook/zstd/releases/tag/v1.5.2

Checkstyle, spotBugs and spotless will be upgraded separately as they
either require non trivial code changes or they have regressions
that affect us.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2022-02-07 15:24:50,Ismael Juma,Not TDD
4b468a9d81f7380f7197a2a6b859c1b4dca84bd9,"KAFKA-13310 : KafkaConsumer cannot jump out of the poll method, and the… (#11340)

Title: KafkaConsumer cannot jump out of the poll method, and cpu and traffic on the broker side increase sharply
description: The local test has been passed, the problem described by jira can be solved

JIRA link : https://issues.apache.org/jira/browse/KAFKA-13310

Reviewers: Luke Chen <showuon@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2022-02-08 23:05:42,RivenSun,Mixed
d35283f011a797902fc9c4d896a1a6f039eb7d06,"KAFKA-13646; Implement KIP-801: KRaft authorizer (#11649)

Currently, when using KRaft mode, users still have to have an Apache ZooKeeper instance if they want to use AclAuthorizer. We should have a built-in Authorizer for KRaft mode that does not depend on ZooKeeper. This PR introduces such an authorizer, called StandardAuthorizer. See KIP-801 for a full description of the new Authorizer design.

Authorizer.java: add aclCount API as described in KIP-801. StandardAuthorizer is currently the only authorizer that implements it, but eventually we may implement it for AclAuthorizer and others as well.

ControllerApis.scala: fix a bug where createPartitions was authorized using CREATE on the topic resource rather than ALTER on the topic resource as it should have been.

QuorumTestHarness: rename the controller endpoint to CONTROLLER for consistency (the brokers already called it that). This is relevant in AuthorizerIntegrationTest where we are examining endpoint names. Also add the controllerServers call.

TestUtils.scala: adapt the ACL functions to be usable from KRaft, by ensuring that they use the Authorizer from the current active controller.

BrokerMetadataPublisher.scala: add broker-side ACL application logic.

Controller.java: add ACL APIs. Also add a findAllTopicIds API in order to make junit tests that use KafkaServerTestHarness#getTopicNames and KafkaServerTestHarness#getTopicIds work smoothly.

AuthorizerIntegrationTest.scala: convert over testAuthorizationWithTopicExisting (more to come soon)

QuorumController.java: add logic for replaying ACL-based records. This means storing them in the new AclControlManager object, and integrating them into controller snapshots. It also means applying the changes in the Authorizer, if one is configured. In renounce, when reverting to a snapshot, also set newBytesSinceLastSnapshot to 0.

Reviewers: YeonCheol Jang <YeonCheolGit@users.noreply.github.com>,  Jason Gustafson <jason@confluent.io>",2022-02-09 10:38:52,Colin Patrick McCabe,Mixed
78a3789496569dad373d7a961361a54e3a4abd73,"KAFKA-13636: Fix for the group coordinator issue where the offsets are deleted for unstable groups (#11742)

This patch ensures that the committed offsets are not expired while the group is rebalancing. The issue is that we can't rely on the subscribed topics if the group is not stable.

Reviewers: David Jacot <djacot@confluent.io>",2022-02-10 17:21:17,prince-mahajan,Mixed
03af63d0761cff0cc895f65825829eb6314c0de1,"KAFKA-13306: Null connector config value passes validation, but fails creation (#11333)

This patch adds null value check to the connector config validation, and extends unit tests to cover this functionality.

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chris Egerton <chrise@confluent.io>, Boyang Chen <bchen11@outlook.com>, Andras Katona <akatona@cloudera.com>",2022-02-11 16:14:06,lhunyady,Mixed
0269edfc80e36d468516b943f0a9a08b7ee652fb,"KAFKA-13577: Replace easymock with mockito in kafka:core - part 3 (#11674)


Reviewers: Tom Bentley <tbentley@redhat.com>",2022-02-11 16:16:25,Mickael Maison,Not TDD
40b261f0820faa335fab880e1366f7e56a62eada,"MINOR: improve logging (#11584)

Reviewers: A. Sophie Blee-Goldman <sophie@confluent.io>, Luke Chen <showuon@gmail.com>",2022-02-11 10:50:44,Matthias J. Sax,Not TDD
e43916c148ad90aab6b51c465a32ba1d4d4b474b,"KAFKA-13661; Consistent permissions in KRaft for CreatePartitions API (#11745)

In #11649, we fixed one permission inconsistency between kraft and zk authorization for the `CreatePartitions` request. Previously kraft was requiring `CREATE` permission on the `Topic` resource when it should have required `ALTER`. A second inconsistency is that kraft was also allowing `CREATE` on the `Cluster` resource, which is not supported in zk clusters and was not documented in KIP-195: https://cwiki.apache.org/confluence/display/KAFKA/KIP-195%3A+AdminClient.createPartitions. This patch fixes this inconsistency and adds additional test coverage for both cases.

Reviewers: José Armando García Sancio <jsancio@gmail.com>",2022-02-11 15:01:08,Jason Gustafson,Mixed
fc20c551d6b4f5c675d9bd80876950e23d194933,"MINOR: Clearer field names for ProducerIdsRecord and related classes (#11747)

The current naming of the fields in `ProducerIdsRecord` is a little confusing in regard to whether the block range was inclusive or exclusive. This patch tries to improve naming to make this clearer. In the record class, instead of `ProducerIdsEnd`, we use `NextProducerId`. We have also updated related classes such as `ProducerIdsBlock.java` with similar changes.

Reviewers: dengziming <dengziming1993@gmail.com>, David Arthur <mumrah@gmail.com>",2022-02-11 16:14:31,Jason Gustafson,Mixed
99310360a589ccb28f7636b714e98e2e7c5a5110,"KAFKA-12939: After migrating processors, search the codebase for missed migrations (#11534)

Migrated internal usages that had previously been marked with TODO suppressions.

Reviewer: John Roesler<vvcephei@apache.org>",2022-02-11 22:25:03,Jorge Esteban Quilcate Otoya,Mixed
076648e280ba319773bdca56775b775b7b21a8a8,"MINOR: MetadataShell should handle ProducerIdsRecord (#11603)

MetadataShell should be able to display contents from `ProducerIdsRecord`.

Reviewers: Mickael Maison <mickael.maison@gmail.com>, David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",2022-02-12 11:11:21,dengziming,Mixed
f9201666a1216fcbe07ed4f2ba544833fced6e39,"MINOR: Small cleanups in mirror/mirror-client (#11749)


Reviewers: Jason Gustafson <jason@confluent.io>",2022-02-14 10:17:54,Mickael Maison,Mixed
c8fbe26f3bd3a7c018e7619deba002ee454208b9,"KAFKA-13435; Static membership protocol should let the leader skip assignment (KIP-814) (#11688)

This patch implements KIP-814 as described here: https://cwiki.apache.org/confluence/display/KAFKA/KIP-814%3A+Static+membership+protocol+should+let+the+leader+skip+assignment.

Reviewers: Luke Chen <showuon@gmail.com>, Artem Livshits <alivshits@confluent.io>, Jason Gustafson <jason@confluent.io>",2022-02-14 11:55:38,David Jacot,Mixed
dd36331a817d5db8b595d0cec6e03d747af3b760,"MINOR: Enable kraft in ApiVersionTest (#11667)

This patch enables `ApiVersionsTest` to test both kraft brokers and controllers. It fixes a minor bug in which the `Envelope` request to be exposed from `ApiVersions` requests to the kraft broker. 

Reviewers: Jason Gustafson <jason@confluent.io>",2022-02-15 10:16:03,dengziming,Mixed
fdb98df839146a6ac742c4d603c6f73ae00ba484,"KAFKA-12648: avoid modifying state until NamedTopology has passed validation (#11750)

Previously we were only verifying the new query could be added after we had already inserted it into the TopologyMetadata, so we need to move the validation upfront.

Also adds a test case for this and improves handling of NPE in case of future or undiscovered bugs.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2022-02-15 13:06:54,A. Sophie Blee-Goldman,Mixed
b765a2b44e9e7c7fd662cb7e0ed7d964a0ddeeed,"MINOR: Remove redundant forwarding integration tests (#11766)

There are a few integration tests for the forwarding logic which were added prior to kraft being ready for integration testing. Now that we have enabled kraft in integration tests, these tests are redundant and can be removed.

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",2022-02-15 18:28:34,Jason Gustafson,Not TDD
8047ba3800436d6162d0f8eb707e28857ab9eb68,"MINOR: Small cleanups in connect:runtime (#11756)


Reviewers: Jason Gustafson <jason@confluent.io>",2022-02-16 20:02:25,Mickael Maison,Mixed
4c23e47bd5b04d49e1ef55b8a33ba18e72a818e2,"MINOR: move non-management methods from TaskManager to Task Executor (#11738)

Basic refactoring with no logical changes to lay the groundwork & facilitate reviews for error handling work.

This PR just moves all methods that go beyond the management of tasks into a new TaskExecutor class, such as processing, committing, and punctuating. This breaks up the ever-growing TaskManager class so it can focus on the tracking and updating of the tasks themselves, while the TaskExecutor can focus on the actual processing. In addition to cleaning up this code this should make it easier to test this part of the code.

Reviewers: Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",2022-02-18 00:39:41,A. Sophie Blee-Goldman,Mixed
a5bb45c11ad7a68856d14c86184bc3488770aa43,"KAFKA-13511: Add support for different unix precisions in TimestampConverter SMT (#11575)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Tom Bentley <tbentley@redhat.com>",2022-02-22 17:17:16,Julien Chanaud,Mixed
d8cf47bf28af0b5eb5be8382883e6a331b788e01,"KAFKA-13676: Commit successfully processed tasks on error (#11791)

When we hit an exception when processing tasks we should save the work we have done so far.
This will only be relevant with ALOS and EOS-v1, not EOS-v2. It will actually reduce the number of duplicated record in ALOS because we will not be successfully processing tasks successfully more than once in many cases.

This is currently enabled only for named topologies.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Guozhang Wang <guozhang@confluent.io>",2022-02-22 23:10:05,Walker Carlson,Not TDD
6f09c3f88b2f02946f85a3cbde1298b47a4470cc,"KAFKA-10000: Utils methods for overriding user-supplied properties and dealing with Enum types (#11774)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2022-02-23 14:49:30,Chris Egerton,Mixed
711b603ddc85210090246349603bdb7a2b1466d7,"MINOR: Cleanup admin creation logic in integration tests (#11790)

There seemed to be a little sloppiness in the integration tests in regard to admin client creation. Not only was there duplicated logic, but it wasn't always clear which listener the admin client was targeting. This made it difficult to tell in the context of authorization tests whether we were indeed testing with the right principal. As an example, we had a method in TestUtils which was using the inter-broker listener implicitly. This meant that the test was using the broker principal which had super user privilege. This was intentional, but I think it would be clearer to make the dependence on this listener explicit. This patch attempts to clean this up a bit by consolidating some of the admin creation logic and making the reliance on the listener clearer.

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",2022-02-24 07:37:28,Jason Gustafson,Mixed
cd4a1cb4101abcc7cdd1d2d0d73662114108f3e5,"KAFKA-12738: track processing errors and implement constant-time task backoff (#11787)

Part 1 in the initial series of error handling for named topologies.

*Part 1: Track tasks with errors within a named topology & implement constant-time based task backoff
Part 2: Implement exponential task backoff to account for recurring errors
Part 3: Pause/backoff all tasks within a named topology in case of a long backoff/frequent errors for any individual task

Reviewers:  Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",2022-02-24 12:10:31,A. Sophie Blee-Goldman,Not TDD
c2ee1411c8bb73fcf96c12abeedbfe6fde2c6354,"KAFKA-12738: send LeaveGroup request when thread dies to optimize replacement time (#11801)

Quick followup to #11787 to optimize the impact of the task backoff by reducing the time to replace a thread. When a thread is going through a dirty close, ie shutting down from an uncaught exception, we should be sending a LeaveGroup request to make sure the broker acknowledges the thread has died and won't wait up to the `session.timeout` for it to join the group if the user opts to `REPLACE_THREAD` in the handler

Reviewers: Walker Carlson <wcarlson@confluent.io>, John Roesler <vvcephei@apache.org>",2022-02-24 16:18:13,A. Sophie Blee-Goldman,Not TDD
2c90447a593196a11b57d1617f990de2aa492b7c,"KAFKA-13697; KRaft authorizer should support AclOperation.ALL (#11806)

KRaft authorizer should support AclOperation.ALL correctly.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2022-02-25 15:43:21,Jason Gustafson,Mixed
abb74d406a13bd989e718f737b18073af5a626d5,"KAFKA-13281: allow #removeNamedTopology while in the CREATED state (#11810)

We should be able to change the topologies while still in the CREATED state. We already allow adding them, but this should include removing them as well

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2022-02-25 19:11:06,Walker Carlson,Not TDD
5f91aa7b4c1a5b7b22305b08c35871050853a855,"KAFKA-13698; KRaft authorizer should use host address instead of name (#11807)

Use `InetAddress.getHostAddress` in `StandardAuthorizer` instead of `InetAddress.getHostName`.

Reviewers: Colin Patrick McCabe <cmccabe@confluent.io>",2022-02-26 10:52:34,Jason Gustafson,Mixed
2ccc834faa3fffcd5d15d2463aeef3ee6f5cea13,"KAFKA-13542: add rebalance reason in Kafka Streams (#11804)

Add rebalance reason in Kafka Streams.

Reviewers: Luke Chen <showuon@gmail.com>, Bruno Cadonna <cadonna@apache.org>",2022-02-28 18:26:46,Hao Li,Mixed
14faea4aab8b772d7e41d0fb12cad110ad922293,"KAFKA-8659: fix SetSchemaMetadata failing on null value and schema (#7082)

Make SetSchemaMetadata SMT ignore records with null value and valueSchema or key and keySchema.

The transform has been unit tested for handling null values gracefully while still providing the necessary validation for non-null values.

Reviewers: Konstantine Karantasis<konstantine@confluent.io>, Bill Bejeck <bbejeck@apache.org>",2022-03-01 10:10:43,Marc Löhe,Mixed
6eb57f6df1706c6ec228123cea1c120bd53b62d6,"KAFKA-12738: address minor followup and consolidate integration tests of PR #11787 (#11812)

This PR addresses the remaining nits from the final review of #11787

It also deletes two integration test classes which had only one test in them, and moves the tests to another test class file to save on the time to bring up an entire embedded kafka cluster just for a single run

Reviewers: Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",2022-03-01 12:59:18,A. Sophie Blee-Goldman,Not TDD
07553d13f7207d3e005cee3f8c8b520815738d89,"MINOR: create KafkaConfigSchema and TimelineObject (#11809)

Create KafkaConfigSchema to encapsulate the concept of determining the types of configuration keys.
This is useful in the controller because we can't import KafkaConfig, which is part of core. Also
introduce the TimelineObject class, which is a more generic version of TimelineInteger /
TimelineLong.

Reviewers: David Arthur <mumrah@gmail.com>",2022-03-02 14:26:31,Colin Patrick McCabe,Mixed
62e646619b208098c07e4d044c1ed7fcd44bf6f9,"KAFKA-6718 / Rack aware standby task assignor (#10851)

This PR is part of KIP-708 and adds rack aware standby task assignment logic.

Reviewer: Bruno Cadonna <cadonna@apache.org>, Luke Chen <showuon@gmail.com>, Vladimir Sitnikov <vladimirsitnikov.apache.org>",2022-03-03 11:37:26,Levani Kokhreidze,Mixed
066cdc8c621dfc4d26e12ee539368d6c1eb2707f,"KAFKA-10000: Add producer fencing API to admin client (KIP-618) (#11777)

* KAFKA-10000: Add producer fencing API to admin client

Reviewers: Luke Chen <showuon@gmail.com>, Tom Bentley <tbentley@redhat.com>",2022-03-03 10:27:17,Chris Egerton,Mixed
029a14b530dcaab980faee4fa18c925b95db3122,"KAFKA-13510: Connect APIs to list all connector plugins and retrieve their configs (#11572)

Implements KIP-769: https://cwiki.apache.org/confluence/display/KAFKA/KIP-769%3A+Connect+APIs+to+list+all+connector+plugins+and+retrieve+their+configuration+definitions

Reviewers: Tom Bentley <tbentley@redhat.com>, Chris Egerton <fearthecellos@gmail.com>",2022-03-03 14:28:50,Mickael Maison,Mixed
7c280c1d5f6267acbbebd10d3e58ea4b8fe7a4ef,"KAFKA-13673: disable idempotence when config conflicts (#11788)

Disable idempotence when conflicting config values for acks, retries
and max.in.flight.requests.per.connection are set by the user. For the
former two configs, we log at info level when we disable idempotence
due to conflicting configs. For the latter, we log at warn level since
it's due to an implementation detail that is likely to be surprising.

This mitigates compatibility impact of enabling idempotence by default.

Added unit tests to verify the change in behavior.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jason Gustafson <jason@confluent.io>, Mickael Maison <mickael.maison@gmail.com>",2022-03-03 05:40:41,Luke Chen,Mixed
6f54faed2d0792f3a36534fd7e6d00b6603253a8,"KAFKA-12648: fix #add/removeNamedTopology blocking behavior when app is in CREATED (#11813)

Currently the #add/removeNamedTopology APIs behave a little wonky when the application is still in CREATED. Since adding and removing topologies runs some validation steps there is valid reason to want to add or remove a topology on a dummy app that you don't plan to start, or a real app that you haven't started yet. But to actually check the results of the validation you need to call get() on the future, so we need to make sure that get() won't block forever in the case of no failure -- as is currently the case

Reviewers: Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",2022-03-04 09:58:56,A. Sophie Blee-Goldman,Mixed
3be978464ca01c29241954516b4d952f69d4e16d,"KAFKA-13694: Log more specific information when the verification record fails on brokers. (#11830)

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2022-03-04 10:45:44,RivenSun,Mixed
0dac4b42678049e210759f38d897a75271aac72a,"KAFKA-13689: printing unused and unknown logs separately (#11800)

Differentiate between unused and unknown configs during log output.

Reviewer: Luke Chen <showuon@gmail.com>",2022-03-05 16:08:14,RivenSun,Mixed
e3ef29ea0300e3ed5edf5c800f914f19273c9851,"KAFKA-12959: Distribute standby and active tasks across threads to better balance load between threads (#11493)

Balance standby and active stateful tasks evenly across threads

Reviewer: Luke Chen <showuon@gmail.com>",2022-03-05 16:11:42,Tim Patterson,Mixed
539f006e65d9060cd46a4052d1b70f2312d8ca34,"KAFKA-12648: fix NPE due to race condtion between resetting offsets and removing a topology (#11847)

While debugging the flaky NamedTopologyIntegrationTest. shouldRemoveOneNamedTopologyWhileAnotherContinuesProcessing test, I did discover one real bug. The problem was that we update the TopologyMetadata's builders map (with the known topologies) inside the #removeNamedTopology call directly, whereas the StreamThread may not yet have reached the poll() in the loop and in case of an offset reset, we get an NP.e
I changed the NPE to just log a warning for now, going forward I think we should try to tackle some tech debt by keeping the processing tasks and the TopologyMetadata in sync

Also includes a quick fix on the side where we were re-adding the topology waiter/KafkaFuture for a thread being shut down

Reviewers: Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",2022-03-07 11:09:18,A. Sophie Blee-Goldman,Mixed
1848f049e106101293739f6471d3d589c4018e5e,"KAFKA-13710: bring the InvalidTimestampException back for record error (#11853)


Reviewers: Guozhang Wang <guozhang@confluent.io>, Ricardo Brasil <anribrasil@gmail.com>",2022-03-08 14:28:16,Luke Chen,Mixed
fc7133d52d1ad6d8a2c91ce2f3d550bb56de1fb1,"KAFKA-12648: fix bug where thread is re-added to TopologyMetadata when shutting down (#11857)

We used to call TopologyMetadata#maybeNotifyTopologyVersionWaitersAndUpdateThreadsTopologyVersion when a thread was being unregistered/shutting down, to check if any of the futures listening for topology updates had been waiting on this thread and could be completed. Prior to invoking this we make sure to remove the current thread from the TopologyMetadata's threadVersions map, but this thread is actually then re-added in the #maybeNotifyTopologyVersionWaitersAndUpdateThreadsTopologyVersion call.

To fix this, we should break up this method into separate calls for each of its two distinct functions, updating the version and checking for topology update completion. When unregistering a thread, we should only invoke the latter method

Reviewers: Guozhang Wang <guozhang@confluent.io>, Walker Carlson <wcarlson@confluent.io>",2022-03-07 23:59:43,A. Sophie Blee-Goldman,Not TDD
28393be6d7416f51eb51f7fe2b075570b45ef09f,"KAFKA-12879: Revert changes from KAFKA-12339 and instead add retry capability to KafkaBasedLog (#11797)

Fixes the compatibility issue regarding KAFKA-12879 by reverting the changes to the admin client from KAFKA-12339 (#10152) that retry admin client operations, and instead perform the retries within Connect's `KafkaBasedLog` during startup via a new `TopicAdmin.retryEndOffsets(..)` method. This method delegates to the existing `TopicAdmin.endOffsets(...)` method, but will retry on `RetriableException` until the retry timeout elapses.

This change should be backward compatible to the KAFKA-12339 so that when Connect's `KafkaBasedLog` starts up it will retry attempts to read the end offsets for the log's topic. The `KafkaBasedLog` existing thread already has its own retry logic, and this is not changed.

Added more unit tests, and thoroughly tested the new `RetryUtil` used to encapsulate the parameterized retry logic around any supplied function.",2022-03-09 12:39:28,Philip Nee,Mixed
ddcee81043dd892776a36657db3eb1771e7bc017,"KAFKA-12879: Addendum to reduce flakiness of tests (#11871)

This is an addendum to the KAFKA-12879 (#11797) to fix some tests that are somewhat flaky when a build machine is heavily loaded (when the timeouts are too small).

- Add an if check to void sleep(0)
- Increase timeout in the tests",2022-03-09 14:37:48,Philip Nee,Mixed
798275f25401b41af6a9703c117173b687d218ba,"KAFKA-13717: skip coordinator lookup in commitOffsetsAsync if offsets is empty (#11864)

Reviewer: Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",2022-03-10 10:52:05,Vincent Jiang,Not TDD
84b41b9d3ad4b45a9137197a304996759e993cde,"KAFKA-13689: Revert AbstractConfig code changes (#11863)

Reviewer: Luke Chen <showuon@gmail.com>",2022-03-10 10:54:10,RivenSun,Mixed
4d5a28973f96492215531520b34737d529d8fd8b,"Revert ""KAFKA-13542: add rebalance reason in Kafka Streams (#11804)"" (#11873)

This reverts commit 2ccc834faa3fffcd5d15d2463aeef3ee6f5cea13.

This reverts commit 2ccc834. We were seeing serious regressions in our state heavy benchmarks. We saw that our state heavy benchmarks were experiencing a really bad regression. The State heavy benchmarks runs with rolling bounces with 10 nodes.

We regularly saw this exception:  java.lang.OutOfMemoryError: Java heap space                                                                                                                                                                                              

I ran through a git bisect and found this commit. We verified that the commit right before did not have the same issues as this one did. I then reverted the problematic commit and ran the benchmarks again on this commit and did not see any more issues. We are still looking into the root cause, but for now since this isn't a critical improvement so we can remove it temporarily.

Reviewers: Bruno Cadonna <cadonna@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>, David Jacot <djacot@confluent.io>, Ismael Juma <ismael@confluent.io>",2022-03-10 13:52:05,Walker Carlson,Mixed
87eb0cf03c879fe77e6e72b490fcf0b9621dd559,"KAFKA-6718: Update SubscriptionInfoData with clientTags (#10802)

adds ClientTags to SubscriptionInfoData

Reviewer: Luke Chen <showuon@gmail.com>, Bruno Cadonna <cadonna@apache.org>",2022-03-11 16:29:05,Levani Kokhreidze,Mixed
63ea5db9ec2e93ded483025649f48565f056242d,"KIP-825: Part 1, add new RocksDBTimeOrderedWindowStore (#11802)

Initial State store implementation for TimedWindow and SlidingWindow.

RocksDBTimeOrderedWindowStore.java contains one RocksDBTimeOrderedSegmentedBytesStore which contains index and base schema.

PrefixedWindowKeySchemas.java implements keyschema for time ordered base store and key ordered index store.

Reviewers: James Hughes, Guozhang Wang <wangguoz@gmail.com>",2022-03-11 17:51:10,Hao Li,Mixed
7f284497cb46366cc266ec6abac4661e6e3a839d,"KAFKA-13438: Replace EasyMock and PowerMock with Mockito in WorkerTest (#11817)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2022-03-14 13:03:41,Liam Clarke-Hutchinson,Not TDD
76cf7a5793702b55e2cfd98a375f8f1708ff32c3,"KAFKA-7077: Use default producer settings in Connect Worker (#11475)

Reviewers: Luke Chen <showuon@gmail.com>",2022-03-15 11:20:18,Liam Clarke-Hutchinson,Mixed
e8a762eee4f2dbe2564cbb2319e51277ba6b4b3a,"MINOR: set batch-size option into batch.size config in consoleProducer (#11855)

Reviewers: Luke Chen <showuon@gmail.com>",2022-03-15 19:40:11,wangyap,Mixed
03411ca28b21d554d754b3f67a7857afe64f5bef,"KAFKA-13721: asymetric join-winodws should not emit spurious left/outer join results (#11875)

Reviewers:  Sergio Peña <sergio@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2022-03-15 09:37:01,Matthias J. Sax,Mixed
76d287c96771159d9b86dcf2fa193ff69198dd5b,"KAFKA-13727; Preserve txn markers after partial segment cleaning (#11891)

It is possible to clean a segment partially if the offset map is filled before reaching the end of the segment. The highest offset that is reached becomes the new dirty offset after the cleaning completes. The data above this offset is nevertheless copied over to the new partially cleaned segment. Hence we need to ensure that the transaction index reflects aborted transactions from both the cleaned and uncleaned portion of the segment. Prior to this patch, this was not the case. We only collected the aborted transactions from the cleaned portion, which means that the reconstructed index could be incomplete. This can cause the aborted data to become effectively committed. It can also cause the deletion of the abort marker before the corresponding data has been removed (i.e. the aborted transaction becomes hanging).

Reviewers: Jun Rao <junrao@gmail.com>",2022-03-15 12:26:23,Jason Gustafson,Mixed
bda5c34b030207f542c7987a5e0f9bcb23406c18,"MINOR: refactor how ConfigurationControl checks for resource existence (#11835)

ConfigurationControl methods should take a boolean indicating whether the resource is newly
created, rather than taking an existence checker object. The boolean is easier to understand. Also
add a unit test of existing checking failing (and succeeding).

Reviewers: Kirk True <kirk@mustardgrain.com>, José Armando García Sancio <jsancio@users.noreply.github.com>",2022-03-15 12:50:53,Colin Patrick McCabe,Mixed
9e8ace080990a6471ed058edffaafa74984649e4,"KAFKA-13549: Add repartition.purge.interval.ms (#11610)

Implements KIP-811.

Add a new config `repartition.purge.interval.ms` that limits how often data is purged from repartition topics.",2022-03-15 15:55:20,Nick Telford,Mixed
5c1dd493d6f608b566fdad5ab3a896cb13622bce,"Don't generate Uuid with a leading ""-"" (#11901)",2022-03-16 11:54:02,David Arthur,Mixed
b68463c250ec99d86ffacdbd45e58059d0ca51e1,"KAFKA-6718 / Add rack awareness configurations to StreamsConfig (#11837)

This PR is part of KIP-708 and adds rack aware standby task assignment logic.

Rack aware standby task assignment won't be functional until all parts of this KIP gets merged.

Splitting PRs into three smaller PRs to make the review process easier to follow. Overall plan is the following:

⏭️ Rack aware standby task assignment logic #10851
⏭️ Protocol change, add clientTags to SubscriptionInfoData #10802
👉 Add required configurations to StreamsConfig (public API change, at this point we should have full functionality)

This PR implements last point of the above mentioned plan.

Reviewers: Luke Chen <showuon@gmail.com>, Bruno Cadonna <cadonna@apache.org>",2022-03-16 18:02:24,Levani Kokhreidze,Mixed
fbe7fb941173c0907792a8b48e8e9122aabecbd8,"KAFKA-9847: add config to set default store type (KIP-591) (#11705)

Reviewers: Hao Li <hli@confluent.io>, A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <mjsax@apache.org>",2022-03-17 10:19:42,Luke Chen,Mixed
3dacdc5694da5db283524889d2270695defebbaa,"MINOR: Replace EasyMock with Mockito in connect:file (#11471)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2022-03-17 17:30:37,dengziming,Not TDD
5cebe12a664d95c6dc5b5aeacd3cee0913ce2c4f,"KAFKA-13509; Support max timestamp in GetOffsetShell (KIP-815) (#11173)

This patch implements KIP-815 as described here: https://cwiki.apache.org/confluence/display/KAFKA/KIP-815%3A++Support+max-timestamp+in+GetOffsetShell.

Reviewers: Luke Chen <showuon@gmail.com>, Justine Olshan <jolshan@confluent.io>, David Jacot <djacot@confluent.io>",2022-03-17 17:53:37,dengziming,Mixed
df963ee0a98c3107093b22c670a6bc8d8f459e05,"MINOR: Fix incorrect log for out-of-order KTable (#11905)

Reviewers: Luke Chen <showuon@gmail.com>",2022-03-18 10:00:03,Ludovic DEHON,Mixed
52621613fd386203773ba93903abd50b46fa093a,"KAFKA-13587; Implement leader recovery for KIP-704 (#11733)

Implementation of the protocol for starting and stopping leader recovery after an unclean leader election. This includes the management of state in the controllers (legacy and KRaft) and propagating this information to the brokers. This change doesn't implement log recovery after an unclean leader election.

Protocol Changes
================

For the topic partition state znode, the new field ""leader_recovery_state"" was added. If the field is missing the value is assumed to be RECOVERED.

ALTER_PARTITION was renamed from ALTER_ISR. The CurrentIsrVersion field was renamed to PartitionEpoch. The new field LeaderRecoveryState was added.

The new field LeaderRecoverState was added to the LEADER_AND_ISR request. The inter broker protocol version is used to determine which version to send to the brokers.

A new tagged field for LeaderRecoveryState was added to both the PartitionRecord and PartitionChangeRecord.

Controller
==========

For both the KRaft and legacy controller the LeaderRecoveryState is set to RECOVERING, if the leader was elected out of the ISR, also known as unclean leader election. The controller sets the state back to RECOVERED after receiving an ALTER_PARTITION request with version 0, or with version 1 and with the LeaderRecoveryState set to RECOVERED.

Both controllers preserve the leader recovery state even if the unclean leader goes offline and comes back online before an RECOVERED ALTER_PARTITION is sent.

The controllers reply with INVALID_REQUEST if the ALTER_PARTITION either:

    1. Attempts to increase the ISR while the partition is still RECOVERING
    2. Attempts to change the leader recovery state to RECOVERING from a RECOVERED state.

Topic Partition Leader
======================

The topic partition leader doesn't implement any log recovery in this change. The topic partition leader immediately marks the partition as RECOVERED and sends that state in the next ALTER_PARTITION request.

Reviewers: Jason Gustafson <jason@confluent.io>",2022-03-18 09:24:11,José Armando García Sancio,Mixed
8d6968e8322d74ebb0fde513113d42bef69fb72b,"KAFKA-13682; KRaft Controller auto preferred leader election (#11893)

Implement auto leader rebalance for KRaft by keeping track of the set of topic partitions which have a leader that is not the preferred replica. If this set is non-empty then schedule a leader balance event for the replica control manager.

When applying PartitionRecords and PartitionChangeRecords to the ReplicationControlManager, if the elected leader is not the preferred replica then remember this topic partition in the set of imbalancedPartitions.

Anytime the quorum controller processes a ControllerWriteEvent it schedules a rebalance operation if the there are no pending rebalance operations, the feature is enabled and there are imbalance partitions.

This KRaft implementation only supports the configurations properties auto.leader.rebalance.enable and leader.imbalance.check.interval.seconds. The configuration property leader.imbalance.per.broker.percentage is not supported and ignored.

Reviewers: Jun Rao <junrao@gmail.com>, David Arthur <mumrah@gmail.com>",2022-03-18 14:30:52,José Armando García Sancio,Mixed
3a8f6b17a6a771d99322c78e8455bbbe4bdc6930,"KAFKA-7540: commit offset sync before close (#11898)

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2022-03-21 16:51:21,Luke Chen,Not TDD
e5eb180a6fa6e1ff3ff2c3d1d67b702ca8c9957b,"MINOR: Pass materialized to the inner KTable instance (#11888)

Reviewers: Luke Chen <showuon@gmail.com>",2022-03-21 17:03:04,Márton Sigmond,Mixed
d449f850e1934680a96780c01ac95bfef52eeac7,"MINOR: show LogRecoveryState in MetadataShell and fix log message

Show the LeaderRecoveryState in MetadataShell.

Fix a case where we were comparing a Byte type with an enum type.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2022-03-21 14:33:51,dengziming,Mixed
c9c03dd7ef9ff4edf2596e905cabececc72a9e9d,"MINOR: Remove scala KafkaException (#11913)

Use the standard org.apache.kafka.common.KafkaException instead of kafka.common.KafkaException.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@confluent.io>",2022-03-21 14:56:25,dengziming,Mixed
0924fd3f9f75c446310ed1e97b44bbc3f33c6c31,"KAFKA-13152: Replace ""buffered.records.per.partition"" with ""input.buffer.max.bytes"" (#11796)

Implements KIP-770

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2022-03-21 17:16:00,vamossagar12,Mixed
be4ef3df428b9d783710a8779d5eadc80e10e299,"KAFKA-13752: Uuid compare using equals in java (#11912)

This patch fixes a few cases where we use `==` instead of `equals` to compare UUID. The impact of this bug is low because `Uuid.ZERO_UUID` is used by default everywhere.

Reviewers: Justine Olshan <jolshan@confluent.io>, dengziming <dengziming1993@gmail.com>, David Jacot <djacot@confluent.io>",2022-03-22 09:31:46,Xiaobing Fang,Mixed
eddb98df67e792b87719636b33c19b0bc5934ffa,"MINOR: Fix class comparison in `AlterConfigPolicy.RequestMetadata.equals()` (#11900)

This patch fixes a bug in the `AlterConfigPolicy.RequestMetadata.equals` method where we were not comparing the class correctly.

Co-authored-by: David Jacot <djacot@confluent.io>

Reviewers: David Jacot <djacot@confluent.io>",2022-03-22 09:45:04,Idan Kamara,Mixed
b60f4464acaa540de75ef2fc83a911d4ff6a8786,"Revert ""KAFKA-7077: Use default producer settings in Connect Worker (#11475)"" (#11932)

This reverts commit 76cf7a5793702b55e2cfd98a375f8f1708ff32c3.

Connect already allows users to enable idempotent producers for connectors and the Connect workers. Although Kafka producers enabled idempotency by default in 3.0, due to compatibility requirements and the fact that [KIP-318](https://cwiki.apache.org/confluence/display/KAFKA/KIP-318%3A+Make+Kafka+Connect+Source+idempotent) hasn't been explicitly approved, the changes here are reverted. A separate commit will explicitly disable idempotency in producers instantiated by Connect by default until KIP-318 is approved and scheduled for release.",2022-03-22 17:19:29,Konstantine Karantasis,Mixed
a3adf41d8b90d1244232e448b959db3b3f4dc2fe,"[Emit final][4/N] add time ordered store factory (#11892)

Add factory to create time ordered store supplier.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2022-03-22 20:53:53,Hao Li,Mixed
6ce69021fd1daa7bf39a9796152aff260b633b3a,"KAFKA-13759: Disable idempotence by default in producers instantiated by Connect (#11933)

With AK 3.0, idempotence was enabled by default in Kafka producers. However, if idempotence is enabled, Connect won't be able to communicate via its producers with Kafka brokers older than version 0.11. Perhaps more importantly, for brokers older than version 2.8 the IDEMPOTENT_WRITE ACL is required to be granted to the principal of the Connect worker.

Therefore this commit disables producer idempotence by default to all the producers instantiated by Connect. Users can still choose to enable producer idempotence by explicitly setting the right worker and/or connector properties.

The changes were tested via existing unit, integration and system tests.

Reviewers: Randall Hauch <rhauch@gmail.com>",2022-03-23 15:03:52,Konstantine Karantasis,Mixed
322a065b9055649c713baf43f154052d45cd1588,"KAFKA-13714: Fix cache flush position (#11926)

The caching store layers were passing down writes into lower store layers upon eviction, but not setting the context to the evicted records' context. Instead, the context was from whatever unrelated record was being processed at the time.

Reviewers: Matthias J. Sax <mjsax@apache.org>",2022-03-23 22:09:05,John Roesler,Not TDD
e8f09007e4259d8a6adcba162b0385b66783a7f8,"KAFKA-13672: Race condition in DynamicBrokerConfig (#11920)

Reviewers: David Jacot <djacot@confluent.io>, Luke Chen <showuon@gmail.com>",2022-03-24 11:54:05,Liam Clarke-Hutchinson,Not TDD
01533e3dd7388ca96b9fd3b84260a8df1b2a9d28,"KAFKA-13692: include metadata wait time in total blocked time (#11805)

This patch includes metadata wait time in total blocked time. First, this patch adds a new metric for total producer time spent waiting on metadata, called metadata-wait-time-ms-total. Then, this time is included in the total blocked time computed from StreamsProducer.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2022-03-24 09:55:26,Rohan,Mixed
ce883892270a02a72e91afbdb1fabdd50d7da474,"KAFKA-13770: Restore compatibility with KafkaBasedLog using older Kafka brokers (#11946)

The `retryEndOffsets(…)` method in `TopicAdmin` recently added (KAFKA-12879, #11797) to allow the `KafkaBasedLog.start()` method to retry any failures reading the last offsets for a topic. However, this introduce a regression when talking to older brokers (0.10.x or earlier).

The `KafkaBasedLog` already had logic that expected an `UnsupportedVersionException` thrown by the admin client when a Kafka API is not available on an older broker, but the new retry logic in `TopicAdmin` did not account for this and wrapped the exception, thereby breaking the `KafkaBasedLog` logic and preventing startup.

The fix is to propagate this `UnsupportedVersionException` from the `TopicAdmin.retryEndOffsets(…)` method. Added a new unit test that first replicated the problem before the fix, and verified the fix corrects the problem.",2022-03-24 21:40:10,Randall Hauch,Mixed
110bccac4af74e04368e13c4e638b0b5bcf4100f,"KAFKA-13600: Kafka Streams - Fall back to most caught up client if no caught up clients exist (#11760)

The task assignor is modified to consider the Streams client with the most caught up states if no Streams client exists that is caught up, i.e., the lag of the states on that client is less than the acceptable recovery lag.  

Unit test for case task assignment where no caught up nodes exist.
Existing unit and integration tests to verify no other behaviour has been changed

Co-authored-by: Bruno Cadonna <cadonna@apache.org>

Reviewer: Bruno Cadonna <cadonna@apache.org>",2022-03-28 16:48:39,Tim Patterson,Mixed
7243facb8d69a7252e6b9556b5eaee13e41bab7f,"MINOR: Fix stream-join metadata (#11952)

#11356 inadvertently changed
the (undefined) header forwarding behavior of stream-stream joins.

This change does not define the behavior, but just restores the prior
undefined behavior for continuity's sake. Defining the header-forwarding
behavior is future work.

Reviewers: Matthias J. Sax <mjsax@apache.org>, Jorge Esteban Quilcate Otoya <quilcate.jorge@gmail.com>",2022-03-28 11:35:43,John Roesler,Not TDD
db2485cb597c6f9cc0787a24b49273e992e8e310,"KAFKA-13767; Fetch from consumers should return immediately when preferred read replica is defined by the leader (#11942)

When a replica selector is configured, the partition leader computes a preferred read replica for any fetch from the consumers. When the preferred read replica is not the leader, the leader returns the preferred read replica with `FetchDataInfo(LogOffsetMetadata.UnknownOffsetMetadata, MemoryRecords.EMPTY)` to the `ReplicaManager`. This causes the fetch to go into in the fetch purgatory because the exit conditions are not met. In turns out that the delayed fetch is not completed until the timeout is reached because the delayed fetch ignores partition with an unknown offset (-1). If the fetch contains only one partition, the fetch is unnecessarily delayed by the timeout time (500ms by default) to only inform the consumer that it has to read from a follower.

This patch fixes the issue by completing the fetch request immediately when a preferred read replica is defined.

Reviewers: David Jacot <djacot@confluent.io>",2022-03-29 10:13:05,bozhao12,Mixed
35ae4f248b34cc60a522bc856a42158e503d20b7,"KAFKA-6718: Add documentation for KIP-708 (#11923)

Adds documentation for KIP-708: Rack awareness for Kafka Streams

Co-authored-by: Bruno Cadonna <cadonna@apache.org>

Reviewers: Luke Chen <showuon@gmail.com>, Bruno Cadonna <cadonna@apache.org>",2022-03-29 14:08:51,Levani Kokhreidze,Mixed
5aed178048dd5a79112274ee5e8a72611d9f0ec2,"KAFKA-13418: Support key updates with TLS 1.3 (#11966)

Key updates with TLS 1.3 trigger code paths similar to renegotiation with TLS 1.2.
Update the read/write paths not to throw an exception in this case (kept the exception
in the `handshake` method).

With the default configuration, key updates happen after 2^37 bytes are encrypted.
There is a security property to adjust this configuration, but the change has to be
done before it is used for the first time and it cannot be changed after that. As such,
it is best done via a system test (filed KAFKA-13779).

To validate the change, I wrote a unit test that forces key updates and manually ran
a producer workload that produced more than 2^37 bytes. Both cases failed without
these changes and pass with them.

Note that Shylaja Kokoori attached a patch with the SslTransportLayer fix and hence
included them as a co-author of this change.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Co-authored-by: Shylaja Kokoori",2022-03-29 14:59:38,Ismael Juma,Not TDD
8e205b503a39ba8c798e3ce14cd887b66a88551c,"KAFKA-13719: Fix connector restart cause duplicate tasks (#11869)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Luke Chen <showuon@gmail.com>, Chris Egerton <fearthecellos@gmail.com>
Co-authored-by: Chris Egerton <fearthecellos@gmail.com>",2022-03-30 14:58:58,sunshujie1990,Mixed
dd62ef2eda571576a222d757beabcd7690dd8c16,"KAFKA-13748: Do not include file stream connectors in Connect's CLASSPATH and plugin.path by default (#11908)

With this change we stop including the non-production grade connectors that are meant to be used for demos and quick starts by default in the CLASSPATH and plugin.path of Connect deployments. The package of these connector will still be shipped with the Apache Kafka distribution and will be available for explicit inclusion. 

The changes have been tested through the system tests and the existing unit and integration tests. 

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Randall Hauch <rhauch@gmail.com>",2022-03-30 13:15:42,Konstantine Karantasis,Mixed
b2cb6caa1e9267c720c00fa367a277ee8509baea,"MINOR: Move `KafkaYammerMetrics` to server-common (#11970)

With major server components like the new quorum controller being moved outside of the `core` module, it is useful to have shared dependencies moved into `server-common`. An example of this is Yammer metrics which server components still rely heavily upon. All server components should have access to the default registry used by the broker so that new metrics can be registered and metric naming conventions should be standardized. This is particularly important in KRaft where we are attempting to recreate identically named metrics in the controller context. This patch takes a step in this direction. It moves `KafkaYammerMetrics` into `server-common` and it implements
standard metric naming utilities there. 

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2022-03-30 13:59:22,Jason Gustafson,Mixed
1317f3f77a9e1e432e7a81de2dcb88365feeac43,"MINOR: log warning when topology override for cache size is non-zero (#11959)

Since the topology-level cache size config only controls whether we disable the caching layer entirely for that topology, setting it to anything other than 0 has no effect. The actual cache memory is still just split evenly between the threads, and shared by all topologies.

It's possible we'll want to change this in the future, but for now we should make sure to log a warning so that users who do try to set this override to some nonzero value are made aware that it doesn't work like this.

Also includes some minor refactoring plus a fix for an off-by-one error in #11796

Reviewers: Luke Chen <showuon@gmail.com>, Walker Carlson <wcarlson@confluent.io>, Sagar Rao <sagarmeansocean@gmail.com>",2022-03-30 16:24:01,A. Sophie Blee-Goldman,Mixed
669a49063db814b7d7181f0798bd9822bdf5a3d4,"MINOR: Fix an uncompatible bug in GetOffsetShell (#11936)

In KIP-815 we replaced KafkaConsumer with AdminClient in GetOffsetShell. In the previous implementation, partitions were just ignored if there is no offset for them, however, we will print -1 instead now, This PR fix this inconsistency.

Reviewers: David Jacot <djacot@confluent.io>, Luke Chen <showuon@gmail.com>",2022-03-31 10:34:39,dengziming,Mixed
ce7788aadaf989214c70e4df7ec286ed080e8cd1,"KAFKA-13783; Remove reason prefixing in JoinGroupRequest and LeaveGroupRequest (#11971)

KIP-800 introduced a mechanism to pass a reason in the join group request and in the leave group request. A default reason is used unless one is provided by the user. In this case, the custom reason is prefixed by the default one.

When we tried to used this in Kafka Streams, we noted a significant degradation of the performances, see https://github.com/apache/kafka/pull/11873. It is not clear wether the prefixing is the root cause of the issue or not. To be on the safe side, I think that we should remove the prefixing. It does not bring much anyway as we are still able to distinguish a custom reason from the default one on the broker side.

This patch removes prefixing the user provided reasons. So if a the user provides a reason, the reason is used directly. If the reason is empty or null, the default reason is used.

Reviewers: Luke Chen <showuon@gmail.com>, <jeff.kim@confluent.io>, Hao Li <hli@confluent.io>",2022-03-31 14:31:31,David Jacot,Mixed
430f9c99012d1585aa544d4dadf449963296c1fd,"KAFKA-13772: Partitions are not correctly re-partitioned when the fetcher thread pool is resized (#11953)

Partitions are assigned to fetcher threads based on their hash modulo the number of fetcher threads. When we resize the fetcher thread pool, we basically re-distribute all the partitions based on the new fetcher thread pool size. The issue is that the logic that resizes the fetcher thread pool updates the `fetcherThreadMap` while iterating over it. The `Map` does not give any guarantee in this case - especially when the underlying map is re-hashed - and that led to not iterating over all the fetcher threads during the process and thus in leaving some partitions in the wrong fetcher threads.

Reviewers: Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",2022-03-31 14:45:59,Yu,Mixed
3c279b63fa862671330b568f5f58df69f9352c35,"fix: make sliding window works without grace period (#kafka-13739) (#11928)

Fix upperbound for sliding window, making it compatible with no grace period (kafka-13739)

Added unit test for early sliding window and ""normal"" sliding window for both events within one time difference (small input) and above window time difference (large input).

Fixing this window interval may slightly change stream behavior but probability to happen is extremely slow and may not have a huge impact on the result given.

Reviewers Leah Thomas <lthomas@confluent.io>, Bill Bejeck <bbejeck@apache.org>",2022-03-31 10:05:53,Bounkong Khamphousone,Mixed
6b2a0bcf8c76e6387f0f5ec13d1a7f00341ba110,"KAFKA-13785: add processor metadata to be committed with offset (#11829)

Part of KIP-825

Reviewers: Matthias J. Sax <matthias@confluent.io>",2022-03-31 09:48:21,Hao Li,Mixed
eefdf9d6a7fd79a21bb9aea2df25ea642062f28c,"KAFKA-12875: Change Log layer segment map mutations to avoid absence of active segment (#11950)

Reviewers: Kowshik Prakasam <kprakasam@confluent.io>, Jun Rao <junrao@gmail.com>",2022-03-31 10:56:07,Yang Yu,Mixed
62ea4c46a9be7388baeaef1c505d3e5798a9066f,"KAFKA-13749: CreateTopics in KRaft must return configs (#11941)

Previously, when in KRaft mode, CreateTopics did not return the active configurations for the
topic(s) it had just created. This PR addresses that gap. We will now return these topic
configuration(s) when the user has DESCRIBE_CONFIGS permission. (In the case where the user does
not have this permission, we will omit the configurations and set TopicErrorCode. We will also omit
the number of partitions and replication factor data as well.)

For historical reasons, we use different names to refer to each topic configuration when it is set
in the broker context, as opposed to the topic context. For example, the topic configuration
""segment.ms"" corresponds to the broker configuration ""log.roll.ms"". Additionally, some broker
configurations have synonyms. For example, the broker configuration ""log.roll.hours"" can be used to
set the log roll time instead of ""log.roll.ms"". In order to track all of this, this PR adds a
table in LogConfig.scala which maps each topic configuration to an ordered list of ConfigSynonym
classes. (This table is then passed to KafkaConfigSchema as a constructor argument.)

Some synonyms require transformations. For example, in order to convert from ""log.roll.hours"" to
""segment.ms"", we must convert hours to milliseconds. (Note that our assumption right now is that
topic configurations do not have synonyms, only broker configurations. If this changes, we will
need to add some logic to handle it.)

This PR makes the 8-argument constructor for ConfigEntry public. We need this in order to make full
use of ConfigEntry outside of the admin namespace. This change is probably inevitable in general
since otherwise we cannot easily test the output from various admin APIs in junit tests outside the
admin package.

Testing:

This PR adds PlaintextAdminIntegrationTest#testCreateTopicsReturnsConfigs. This test validates
some of the configurations that it gets back from the call to CreateTopics, rather than just checking
if it got back a non-empty map like some of the existing tests. In order to test the
configuration override logic, testCreateDeleteTopics now sets up some custom static and dynamic
configurations.

In QuorumTestHarness, we now allow tests to configure what the ID of the controller should be. This
allows us to set dynamic configurations for the controller in testCreateDeleteTopics. We will have
a more complete fix for setting dynamic configuations on the controller later.

This PR changes ConfigurationControlManager so that it is created via a Builder. This will make it
easier to add more parameters to its constructor without having to update every piece of test code
that uses it. It will also make the test code easier to read.

Reviewers: David Arthur <mumrah@gmail.com>",2022-04-01 10:50:25,Colin Patrick McCabe,Mixed
3ceedac79e58a4a457d36d75c1f4c5a5b36af3d2,"KAFKA-13782; Ensure correct partition added to txn after abort on full batch (#11995)

Fixes a regression introduced in https://github.com/apache/kafka/pull/11452. Following [KIP-480](https://cwiki.apache.org/confluence/display/KAFKA/KIP-480%3A+Sticky+Partitioner), the `Partitioner` will receive a callback when a batch has been completed so that it can choose another partition. Because of this, we have to wait until the batch has been successfully appended to the accumulator before adding the partition in `TransactionManager.maybeAddPartition`. This is still safe because the `Sender` cannot dequeue a batch from the accumulator until it has been added to the transaction successfully.

Reviewers: Artem Livshits <84364232+artemlivshits@users.noreply.github.com>, David Jacot <djacot@confluent.io>,  Tom Bentley <tbentley@redhat.com>",2022-04-05 09:48:21,Jason Gustafson,Mixed
4218fc61fedb02b78d35c88e56ab253baaf09f39,"KAFKA-13778: Fetch from follower should never run the preferred read replica selection (#11965)

The current preferred read replica selection logic relies on `partition.leaderReplicaIdOpt` to determine if the selection must be run. The issue is that `partition.leaderReplicaIdOpt` is defined for both the leader and the followers thus the logic is ran all the time. The impact is not too bad as the leader is selected most of the time when the logic is ran by the follower and the leader is filtered out. However there are cases where the selection on a follower could redirect the consumer to another follower under certain rare conditions. For instance with the `RackAwareReplicaSelector `, the follower must have stale replica states from a previous leadership and must have other followers in the same rack for instance. Other implementation of the selection logic could be more impacted.

This patch ensures that the preferred read replica selection is only ran by the leader.

Reviewers: David Jacot <djacot@confluent.io>",2022-04-05 18:56:23,bozhao12,Mixed
f0a2b62b0e7660ca9e0f0159da636463356206c5,"KAFKA-13794; Fix comparator of `inflightBatchesBySequence` in `TransactionManager` (#11991)

Fixes a bug in the comparator used to sort producer inflight batches for a topic partition. This can cause batches in the map `inflightBatchesBySequence` to be removed incorrectly: i.e. one batch may be removed by another batch with the same sequence number. This leads to an `IllegalStateException` when the inflight request finally returns. This patch fixes the comparator to check equality of the `ProducerBatch` instances if the base sequences match.

Reviewers: Jason Gustafson <jason@confluent.io>",2022-04-05 10:03:33,Xiaoyue Xue,Mixed
92305c2cf26764de89fabcbe33401382f43610ff,"KAFKA-13687: Limiting the amount of bytes to be read in a segment logs (#11842)

This PR allows to limit the output batches while they are inspected via the kafka-dump-log.sh script.

The idea is to take samples from the logsegments without affecting a production cluster as the current script will read the whole files, this could create issues related to performance.

Please see the KIP-824

Reviewers: Jun Rao <junrao@gmail.com>",2022-04-06 08:48:43,sciclon2,Mixed
60c0916bfdc87ddf2e01f172d5455bfeaa8e8cc7,"KAFKA-13801: Kafka server does not respect MetricsReporter contract for dynamically configured reporters (#11998)

MetricsReporter.contextChange contract states the method should always be called first before MetricsReporter.init is called. This is done correctly for reporters enabled by default (e.g. JmxReporter) but not for metrics reporters configured dynamically.

This fixes the call ordering for dynamically configured metrics reporter and updates tests to enforce ordering.

Reviewers: David Jacot <djacot@confluent.io>",2022-04-07 10:13:15,Xavier Léauté,Not TDD
7a5f0cfaefb57cefa70c81d63c60316075c6dd97,"MINOR: Fix DescribeLogDirs API error handling for older API versions (#12017)

With KAFKA-13527 / KIP-784 we introduced a new top-level error code for
the DescribeLogDirs API for versions 3 and above. However, the change
regressed the error handling for versions less than 3 since the response
converter fails to write the non-zero error code out (rightly) for
versions lower than 3 and drops the response to the client which
eventually times out instead of receiving an empty log dirs response and
processing that as a Cluster Auth failure.

With this change, the API conditionally propagates the error code out to
the client if the request API version is 3 and above. This keeps the
semantics of the error handling the same for all versions and restores
the behavior for older versions.

See current behavior in the broker log:
```bash
ERROR] 2022-04-08 01:22:56,406 [data-plane-kafka-request-handler-10] kafka.server.KafkaApis - [KafkaApi-0] Unexpected error handling request RequestHeader(apiKey=DESCRIBE_LOG_DIRS, apiVersion=0, clientId=sarama, correlationId=1) -- DescribeLogDirsRequestData(topics=null)
org.apache.kafka.common.errors.UnsupportedVersionException: Attempted to write a non-default errorCode at version 0
[ERROR] 2022-04-08 01:22:56,407 [data-plane-kafka-request-handler-10] kafka.server.KafkaRequestHandler - [Kafka Request Handler 10 on Broker 0], Exception when handling request
org.apache.kafka.common.errors.UnsupportedVersionException: Attempted to write a non-default errorCode at version 0
```

Reviewers: Ismael Juma <ismael@juma.me.uk>",2022-04-08 12:54:09,Alok Nikhil,Not TDD
1df232c839f4568718a52c04aad72b69beb52026,"MINOR: Supplement the description of `Valid Values` in the documentation of `compression.type` (#11985)

Because a validator is added to ProducerConfig.COMPRESSION_TYPE_CONFIG and KafkaConfig.CompressionTypeProp, the corresponding testCase is improved to verify whether the wrong value of compression.type will throw a ConfigException.

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2022-04-12 21:24:57,RivenSun,Mixed
c93b717836b6d92d0f2e9fb101ea6ff3e823ffca,"KAFKA-13542: Add rebalance reason in Kafka Streams (#12018)

Reviewers: Bruno Cadonna <bruno@confluent.io>, David Jacot <djacot@confluent.io>",2022-04-13 13:49:31,Hao Li,Mixed
f97646488cff1984455ffb1fe9a147a522e6ac76,"KAFKA-13651; Add audit logging to `StandardAuthorizer` (#12031)

This patch adds audit support through the kafka.authorizer.logger logger to StandardAuthorizer. It
follows the same conventions as AclAuthorizer with a similarly formatted log message. When
logIfAllowed is set in the Action, then the log message is at DEBUG level; otherwise, we log at
trace. When logIfDenied is set, then the log message is at INFO level; otherwise, we again log at
TRACE.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2022-04-13 10:33:15,Jason Gustafson,Mixed
87aa8259ddf5d4e5ed75aa41c4ba2ad65e2624a6,"KAFKA-13743: Prevent topics with conflicting metrics names from being created in KRaft mode #11910

In ZK mode, the topic ""foo_bar"" will conflict with ""foo.bar"" because of limitations in metric
names. We should implement this in KRaft mode.  This PR also changes TopicCommandIntegrationTest to
support KRaft mode.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2022-04-13 11:59:29,dengziming,Mixed
55ff5d360381af370fe5b3a215831beac49571a4,"KAFKA-13823 Feature flag changes from KIP-778 (#12036)

This PR includes the changes to feature flags that were outlined in KIP-778.  Specifically, it
changes UpdateFeatures and FeatureLevelRecord to remove the maximum version level. It also adds
dry-run to the RPC so the controller can actually attempt the upgrade (rather than the client). It
introduces an upgrade type enum, which supersedes the allowDowngrade boolean. Because
FeatureLevelRecord was unused previously, we do not need to introduce a new version.

The kafka-features.sh tool was overhauled in KIP-778 and now includes the describe, upgrade,
downgrade, and disable sub-commands.  Refer to
[KIP-778](https://cwiki.apache.org/confluence/display/KAFKA/KIP-778%3A+KRaft+Upgrades) for more
details on the new command structure.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, dengziming <dengziming1993@gmail.com>",2022-04-14 10:04:32,David Arthur,Mixed
adf5cc5371db6253e070b11dc78dedc99c8065f9,"KAFKA-13769: Explicitly route FK join results to correct partitions (#11945)

Prior to this commit FK response sink routed FK results to
SubscriptionResolverJoinProcessorSupplier using the primary key.

There are cases, where this behavior is incorrect. For example,
if KTable key serde differs from the data source serde which might
happen without a key changing operation.

Instead of determining the resolver partition by serializing the PK
this patch includes target partition in SubscriptionWrapper payloads.
Default FK response-sink partitioner extracts the correct partition
from the value and routes the message accordingly.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2022-04-15 11:28:43,Aleksandr Sorokoumov,Mixed
1521813a3a9710011b1ac7526ad3379f809032ca,"KAFKA-13807: Fix incrementalAlterConfig and refactor some things (#12033)

Ensure that we can set log.flush.interval.ms at the broker or cluster level via
IncrementalAlterConfigs. This was broken by KAFKA-13749, which added log.flush.interval.ms as the
second synonym rather than the first. Add a regression test to DynamicConfigChangeTest.

Create ControllerRequestContext and pass it to every controller API. This gives us a uniform way to
pass through information like the deadline (if there is one) and the Kafka principal which is
making the request (in the future we will want to log this information).

In ControllerApis, enforce a timeout for broker heartbeat requests which is equal to the heartbeat
request interval, to avoid heartbeats piling up on the controller queue. This should have been done
previously, but we overlooked it.

Add a builder for ClusterControlManager and ReplicationControlManager to avoid the need to deal
with a lot of churn (especially in test code) whenever a new constructor parameter gets added for
one of these.

In ControllerConfigurationValidator, create a separate function for when we just want to validate
that a ConfigResource is a valid target for DescribeConfigs. Previously we had been re-using the
validation code for IncrementalAlterConfigs, but this was messy.

Split out the replica placement code into a separate package and reorganize it a bit.

Reviewers: David Arthur <mumrah@gmail.com",2022-04-15 16:07:23,Colin Patrick McCabe,Mixed
6d36487b684fd41522cccd4da4fd88f0b89ff0b7,"MINOR: Fix TestDowngrade.test_upgrade_and_downgrade (#12027)

The second validation does not verify the second bounce because the verified producer and the verified consumer are stopped in `self.run_validation`. This means that the second `run_validation` just spit out the same information as the first one. Instead, we should just run the validation at the end.

Reviewers: Jason Gustafson <jason@confluent.io>",2022-04-18 14:22:33,David Jacot,Not TDD
44906bdcdfbb09516e28f207ed0902d07f174cfd,"KAFKA-8785: fix request timeout by waiting for metadata cache up-to-date (#11681)

The reason why this test is flaky is because we have race condition at the beginning of the test, when brokers are staring up, and the adminClient is requesting for brokers metadata. Once the adminClient only got partial metadata, the test will fail, because in these tests, brokers will be shutdown to test leader election.

Fix this issue by explicitly waiting for metadata cache up-to-date in waitForReadyBrokers, and let admin client get created after waitForReadyBrokers.

Reviewers: Jason Gustafson <jason@confluent.io>, David Jacot <djacot@confluent.io>, dengziming <dengziming1993@gmail.com>",2022-04-19 14:13:21,Luke Chen,Not TDD
fa0324485b1e76388bb15ea98170cfb9202aab1f,"KAFKA-13654: Extend KStream process with new Processor API (#11993)

Updates the KStream process API to cover the use cases
of both process and transform, and deprecate the KStream transform API.

Implements KIP-820

Reviewer: John Roesler <vvcephei@apache.org>",2022-04-19 10:29:28,Jorge Esteban Quilcate Otoya,Mixed
9c3f605fc78f297ecf5accdcdec18471c19cf7d6,"KAFKA-13835: Fix two bugs related to dynamic broker configs in KRaft (#12063)

Fix two bugs related to dynamic broker configs in KRaft. The first bug is that we are calling reloadUpdatedFilesWithoutConfigChange when a topic configuration is changed, but not when a
broker configuration is changed. This is backwards. This function must be called only for broker 
configs, and never for topic configs or cluster configs.

The second bug is that there were several configurations such as max.connections which are related
to broker listeners, but which do not involve changing the registered listeners. We should support
these configurations in KRaft. This PR fixes the configuration change validation to support this case.

Reviewers: Jason Gustafson <jason@confluent.io>, Matthew de Detrich <mdedetrich@gmail.com>",2022-04-19 13:17:16,Colin Patrick McCabe,Mixed
301c6f44d605f7152f25057c599eeb0b01b2aef9,"KAFKA-10095: Add stricter assertion in LogCleanerManagerTest (#12004)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2022-04-20 12:45:03,Divij Vaidya,Mixed
d83fccd65f06a13c6245044ea5d1a2116bd67cbf,"KAFKA-13785: [5/N][emit final] cache for time ordered window store (#12030)

A new cache for RocksDBTimeOrderedWindowStore. Need this because RocksDBTimeOrderedWindowStore's key ordering is different from CachingWindowStore which has issues for MergedSortedCacheWindowStoreIterator

Reviewers: Matthias J. Sax <mjsax@apache.org>, Guozhang Wang <wangguoz@gmail.com>",2022-04-20 11:09:13,Hao Li,Mixed
252e09501d08a36fa85e146239e114a71a944331,"KAFKA-13834: fix drain batch starving issue (#12066)

In drainBatchesForOneNode method, there's possibility causing some partitions in a node will never get picked. Fix this issue by maintaining a drainIndex for each node.

Reviewers: Luke Chen <showuon@gmail.com>, RivenSun <91005273+RivenSun2@users.noreply.github.com>",2022-04-21 19:26:55,ruanliang,Mixed
4380eae7ceb840dd93fee8ec90cd89a72bad7a3f,"MINOR; Fix partition change record noop check (#12073)

When LeaderRecoveryState was added to the PartitionChangeRecord, the
check for being a noop was not updated. This commit fixes that and
improves the associated test to avoid this oversight in the future.

Reviewers: Colin Patrick McCabe <cmccabe@apache.org>",2022-04-21 09:05:46,José Armando García Sancio,Mixed
d480c4aa6e513e36050d8e067931de2270525d18,"KAFKA-13841: Fix a case where we were unable to place on fenced brokers in KRaft mode (#12075)

This PR fixes a case where we were unable to place on fenced brokers In KRaft mode. Specifically,
if we had a broker registration in the metadata log, but no associated heartbeat, previously the
HeartbeatManager would not track the fenced broker. This PR fixes this by adding this logic to the
metadata log replay path in ClusterControlManager.

Reviewers: David Arthur <mumrah@gmail.com>, dengziming <dengziming1993@gmail.com>",2022-04-21 14:58:02,Colin Patrick McCabe,Mixed
7c8c65fc54b9eb0386787632ff8315e097d99818,"MINOR: Rename `ZkVersion` to `PartitionEpoch` (#12071)

This patch does some initial cleanups in the context of KAFKA-13790. Mainly, it renames `ZkVersion` field to `PartitionEpoch` in the `LeaderAndIsrRequest`, the `LeaderAndIsr` and the `Partition`.

Reviewers: Jason Gustafson <jason@confluent.io>, dengziming <dengziming1993@gmail.com>",2022-04-22 20:38:17,David Jacot,Mixed
25ee7f147c8b798a881538f59ba7b8544fbb2b1a,"MINOR: Change `AlterPartition` validation order in `KafkaController` (#12032)

Currently we validate recovery state before checking leader epoch in `KafkaController`. It seems more intuitive to validate leader epoch first since the leader might be working with stale state, which is what we do in KRaft. This patch fixes this and adds a couple additional validations to make the behavior consistent. 

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",2022-04-25 09:37:03,Jason Gustafson,Not TDD
a5f7c82a8674a3ae68b57571e8d9a564c87c7d54,"MINOR: Refactor `kafka.cluster.Replica` (#12081)

This patch refactors kafka.cluster.Replica, it usages and tests. This is part of the work in KAFKA-13790.

Reviewers: Jason Gustafson <jason@confluent.io>",2022-04-25 21:43:32,David Jacot,Mixed
b020819ac415976bd09a8e5bfdfb43642837c64d,"KAFKA-12841: Remove an additional call of onAcknowledgement (#12064)

The bug was introduced in #11689 that an additional onAcknowledgement was made using the InterceptorCallback class. This is undesirable since onSendError will attempt to call onAcknowledgement once more.

Reviewers: Jun Rao <junrao@gmail.com>",2022-04-25 15:59:45,Philip Nee,Mixed
f2a782a4d7c71dabf79861f18c4bb14d2b2776ae,"MINOR: Rename `AlterIsrManager` to `AlterPartitionManager` (#12089)

Since we have changed the `AlterIsr` API to `AlterPartition`, it makes sense to rename `AlterIsrManager` as well and some of the associated classes.

Reviewers: dengziming <dengziming1993@gmail.com>, David Jacot <djacot@confluent.io>",2022-04-26 09:34:18,Jason Gustafson,Mixed
a673f2124218e524335ea13337bd3b49f52c52a3,"KAFKA-12380 shutdown Executor in Connect's Worker when closed (#11955)

When the worker is stopped, it does not shutdown this executor. This PR fixes the issue.

Reviewers: Luke Chen <showuon@gmail.com>",2022-04-29 13:35:25,Rajani Karuturi,Mixed
8245c9a3d5af2ad891844194a5fa281af471b568,"KAFKA-13854 Refactor ApiVersion to MetadataVersion (#12072)

Refactoring ApiVersion to MetadataVersion to support both old IBP versioning and new KRaft versioning (feature flags)
for KIP-778.

IBP versions are now encoded as enum constants and explicitly prefixed w/ IBP_ instead of KAFKA_, and having a
LegacyApiVersion vs DefaultApiVersion was not necessary and replaced with appropriate parsing rules for extracting
the correct shortVersions/versions.

Co-authored-by: David Arthur <mumrah@gmail.com>
Reviewers: Ismael Juma <ismael@juma.me.uk>, David Arthur <mumrah@gmail.com>, dengziming <dengziming1993@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",2022-05-02 16:27:52,Alyssa Huang,Mixed
cc2aa96ae4063bdc50d692eaf5d11becbb94154b,"KAFKA-13785: [6/N][Emit final] Copy: Emit final for TimeWindowedKStreamImpl (#12100)

This is a copy PR of #11896, authored by @lihaosky (Hao Li): Initial implementation to emit final for TimeWindowedKStreamImpl. This PR is on top of #12030 

Author: Hao Li
Reviewers: John Roesler <vvcephei@apache.org>",2022-05-03 09:42:23,Guozhang Wang,Mixed
bf7cd675f8b35b806b1414c68479e69055df4a91,"MINOR: Remove duplicated test cases in MetadataVersionTest (#12116)

These tests belongs to ApiVersionsResponseTest, and accidentally copied them to MetadataVersionTest when working on #12072.

Reviewer: Luke Chen <showuon@gmail.com>",2022-05-04 11:10:39,dengziming,Not TDD
430f75ba227b8f600ee7fafc2b83e2e97c38f03b,"KAFKA-13861; Fix the validateOnly behavior for CreatePartitions requests in KRaft mode (#12106)

The KRaft implementation of the `CreatePartitions` ignores the `validateOnly` flag in the
request and creates the partitions if the validations are successful. Fixed the behavior
not to create partitions upon validation if the `validateOnly` flag is true.

Reviewers: Divij Vaidya <divijvaidya13@gmail.com>, dengziming <dengziming1993@gmail.com>, Jason Gustafson <jason@confluent.io>",2022-05-04 10:31:46,Akhilesh Chaganti,Mixed
0a9893cac0db15d6de20f394bef46158410b4bcc,"KAFKA-13815: Avoid reinitialization for a replica that is being deleted (#12029)

This PR tries to avoid the reinitialization of the leader epoch cache
and the partition metadata if the corresponding replica is being deleted.
With this change, the asyncDelete method can run more efficiently,
which means a StopReplica request with many partitions to be deleted can be
processed more quickly.

Reviewers: David Jacot <djacot@confluent.io>, Jun Rao <junrao@gmail.com>",2022-05-04 11:41:34,Lucas Wang,Mixed
ced5989ff69f8a5e76518fdeb39f41ab20b2574f,"KAFKA-10199: Implement adding active tasks to the state updater (#12128)

This PR adds the default implementation of the state updater. The implementation only implements adding active tasks to the state updater.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2022-05-05 16:00:35,Bruno Cadonna,Mixed
3b08deaa761c2387a41610893dc8302ab1d97338,"KAFKA-13785: [8/N][emit final] time-ordered session store (#12127)

Time ordered session store implementation. I introduced AbstractRocksDBTimeOrderedSegmentedBytesStore to make it generic for RocksDBTimeOrderedSessionSegmentedBytesStore and RocksDBTimeOrderedSegmentedBytesStore.

A few minor follow-up changes:

1. Avoid extra byte array allocation for fixed upper/lower range serialization.
2. Rename some class names to be more consistent.

Authored-by: Hao Li <1127478+lihaosky@users.noreply.github.com>
Reviewers: Guozhang Wang <wangguoz@gmail.com.com>, John Roesler <vvcephei@apache.org>",2022-05-05 16:09:16,Guozhang Wang,Mixed
f7db6031b84a136ad0e257df722b20faa7c37b8a,"KAFKA-10888: Sticky partition leads to uneven produce msg (#12049)

The design is described in detail in KIP-794
https://cwiki.apache.org/confluence/display/KAFKA/KIP-794%3A+Strictly+Uniform+Sticky+Partitioner.

Implementation notes:

The default partitioning logic is moved to the BuiltInPartitioner class
(there is one object per topic).  The object keeps track of how many
bytes are produced per-partition and once the amount exceeds batch.size,
switches to the next partition (note that partition switch decision is
decoupled from batching).  The object also keeps track of probability
weights that are based on the queue sizes (the larger the queue size
is the less chance for the next partition to be chosen).  The queue
sizes are calculated in the RecordAccumulator in the `ready` method,
the method already enumerates all partitions so we just add some extra
logic into the existing O(N) method.  The partition switch decision may
take O(logN), where N is the number partitions per topic, but it happens
only once per batch.size (and the logic is avoided when all queues are
of equal size).  Produce bytes accounting logic is lock-free.

When partitioner.availability.timeout.ms is non-0, RecordAccumulator
keeps stats on ""node latency"" which is defined as the difference between
the last time the node had a batch waiting to be send and the last time
the node was ready to take a new batch.  If this difference exceeds
partitioner.availability.timeout.ms we don't switch to that partition
until the node is ready.

Reviewers: Jun Rao <junrao@gmail.com>",2022-05-06 11:31:12,Artem Livshits,Mixed
1278e385c02a44861e9d00b32c0f476d4b149be5,"KAFKA-13763: Refactor IncrementalCooperativeAssignor for improved unit testing (#11983)

The goals here include:

1. Create an overloaded variant of the IncrementalCooperativeAssignor::performTaskAssignment method that is more testing friendly
2. Simplify the parameter list for the IncrementalCooperativeAssignor::handleLostAssignments method, which in turn simplifies the logic for testing this class
3. Capture repeated Java 8 streams logic in simple, reusable, easily-verifiable utility methods added to the ConnectUtils class

Reviewers: Luke Chen <showuon@gmail.com>",2022-05-09 21:43:47,Chris Egerton,Mixed
df507e56e2d782b347fe51537153c33b599da55f,"KAFKA-13793: Add validators for configs that lack validators (#12010)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Luke Chen <showuon@gmail.com>, Chris Egerton <fearthecellos@gmail.com>, Christo Lolov <lolovc@amazon.com>, Divij Vaidya <divijvaidya13@gmail.com>",2022-05-09 20:29:17,RivenSun,Mixed
b485f92647faecc3594bdf4164999d52c859b1bb,"KAFKA-13790; ReplicaManager should be robust to all partition updates from kraft metadata log (#12085)

This patch refactors the `Partition.makeLeader` and `Partition.makeFollower` to be robust to all partition updates from the KRaft metadata log. Particularly, it ensures the following invariants:

- A partition update is accepted if the partition epoch is equal or newer. The partition epoch is updated by the AlterPartition path as well so we accept an update from the metadata log with the same partition epoch in order to fully update the partition state.
- The leader epoch state offset is only updated when the leader epoch is bumped.
- The follower states are only updated when the leader epoch is bumped.
- Fetchers are only restarted when the leader epoch is bumped. This was already the case but this patch adds unit tests to prove/maintain it.

In the mean time, the patch unifies the state change logs to be similar in both ZK and KRaft world.

Reviewers: Jason Gustafson <jason@confluent.io>",2022-05-09 20:47:14,David Jacot,Mixed
989d3ce07f1848d4c0b9fbb116ff0cf9b3b382d7,"MINOR: Small cleanups in connect/mirror (#12113)

Reviewers: Luke Chen <showuon@gmail.com>, Divij Vaidya <divijvaidya13@gmail.com>",2022-05-10 14:49:56,Mickael Maison,Not TDD
eeb1e702eb7a43d88f11458f739672e2b7aa4871,"KAFKA-13879: Reconnect exponential backoff is ineffective in some cases (#12131)

When a client connects to a SSL listener using PLAINTEXT security protocol, after the TCP connection is setup, the client considers the channel setup is complete. In reality the channel setup is not complete yet. The client then resets reconnect exponential backoff and issues API version request. Since the broker expects SSL handshake, the API version request will cause the connection to disconnect. Client reconnects without exponential backoff since it has been reset.

This commit removes the reset of reconnect exponential backoff when sending API version request. In the good case where the channel setup is complete, reconnect exponential backoff will be reset when the node becomes ready, which is after getting the API version response. Inter-broker clients which do not send API version request and go directly to ready state continue to reset backoff before any  successful requests.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2022-05-10 11:36:42,chern,Not TDD
0c1cde10802456b1bc3f5f12f5e4d3d6ae400edd,"KAFKA-13862; Support Append/Subtract multiple config values in KRaft mode (#12108)

We can append/subtract multiple config values in kraft mode using the `IncrementalAlterConfig` RPC. For example: append/subtract topic config ""cleanup.policy"" with value=""delete,compact"" will end up treating ""delete,compact"" as a value not 2 values. This patch fixes the problem. Additionally, it update the zk logic to correctly handle duplicate additions.

Reviewers: Akhilesh Chaganti <akhileshchg@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",2022-05-10 12:41:17,dengziming,Mixed
773047660359bf6b551d06763eeff80bc551b58a,"MINOR: Create case class to encapsulate fetch parameters and simplify handling (#12082)

This patch adds a new case class `FetchParams` which encapsulates the parameters of the fetch request. It then uses this class in `DelayedFetch` directly instead of `FetchMetadata`. The intent is to reduce the number of things we need to change whenever we need to pass through new parameters. The patch also cleans up `ReplicaManagerTest` for more consistent usage.

Reviewers: David Jacot <djacot@confluent.io>",2022-05-10 13:24:23,Jason Gustafson,Mixed
040b11d70594e0499e96014e17a307366b640444,"KAFKA-13892: Fix bug where multiple remove records are generated for one ACL

Fix a bug where multiple remove records could be generated for a single ACL. Previously, this happened
if the user submitted multiple filters to deleteAcls, and more than one matched.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Jason Gustafson <jason@confluent.io>",2022-05-10 15:26:57,andymg3,Mixed
7268284699f84c7f61f5656167c36877b72d27f2,"KAFKA-10000: Add all public-facing config properties (#11775)

Reviewers: Luke Chen <showuon@gmail.com>, Tom Bentley <tbentley@redhat.com>, Andrew Eugene Choi <andrew.choi@uwaterloo.ca>",2022-05-12 14:45:53,Chris Egerton,Mixed
e94934b6b7275c64cf4b9a63d8de88f326e591cd,"MINOR; DeleteTopics version tests (#12141)

Add a DeleteTopics test for all supported versions. Convert the
DeleteTopicsRequestTest to run against both ZK and KRaft mode.

Reviewers: Colin Patrick McCabe <cmccabe@apache.org>, dengziming <dengziming1993@gmail.com>",2022-05-12 13:04:48,José Armando García Sancio,Not TDD
fa59be4e770627cd34cef85986b58ad7f606928d,"KAFKA-13649: Implement early.start.listeners and fix StandardAuthorizer loading (#11969)

Since the StandardAuthorizer relies on the metadata log to store its ACLs, we need to be sure that
we have the latest metadata before allowing the authorizer to be used. However, if the authorizer
is not usable for controllers in the cluster, the latest metadata cannot be fetched, because
inter-node communication cannot occur. In the initial commit which introduced StandardAuthorizer,
we punted on the loading issue by allowing the authorizer to be used immediately. This commit fixes
that by implementing early.start.listeners as specified in KIP-801. This will allow in superusers
immediately, but throw the new AuthorizerNotReadyException if non-superusers try to use the
authorizer before StandardAuthorizer#completeInitialLoad is called.

For the broker, we call StandardAuthorizer#completeInitialLoad immediately after metadata catch-up
is complete, right before unfencing. For the controller, we call
StandardAuthorizer#completeInitialLoad when the node has caught up to the high water mark of the
cluster metadata partition.

This PR refactors the SocketServer so that it creates the configured acceptors and processors in
its constructor, rather than requiring a call to SocketServer#startup A new function,
SocketServer#enableRequestProcessing, then starts the threads and begins listening on the
configured ports. enableRequestProcessing uses an async model: we will start the acceptor and
processors associated with an endpoint as soon as that endpoint's authorizer future is completed.

Also fix a bug where the controller and listener were sharing an Authorizer when in co-located
mode, which was not intended.

Reviewers: Jason Gustafson <jason@confluent.io>",2022-05-12 14:48:33,Colin Patrick McCabe,Mixed
78dd40123cc47e425264f516a4b8c6c2003c99b8,"MINOR: Add upgrade tests for FK joins (#12122)

Follow up PR for KAFKA-13769.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2022-05-13 17:21:27,Alex Sorokoumov,Not TDD
46efb72600e26ac4211a2defac1ff44f8734b404,"KAFKA-13785: [7/N][Emit final] emit final for sliding window (#12135)

This is a copy PR of #12037: Implementation to emit final for sliding window agg. This is authored by lihaosky.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2022-05-13 19:29:00,Guozhang Wang,Mixed
1c02a764eca19d2606259a4efa58f6cfdfc8e70a,"KAFKA-12703; Allow unencrypted private keys when using PEM files (#11916)

Reviewers: David Jacot <djacot@confluent.io>",2022-05-16 09:25:05,Dejan Maric,Mixed
cdd19a5326aae83d470eb8eab800b3e9ed21f013,"KAFKA-12635: Don't emit checkpoints for partitions without offset-syncs (#11748)


Reviewers: Luke Chen <showuon@gmail.com>,  Viktor Somogyi-Vass <viktorsomogyi@gmail.com>, Dániel Urbán <urb.daniel7@gmail.com>, Federico Valeri <fedevaleri@gmail.com>",2022-05-16 17:44:14,Mickael Maison,Mixed
1103c76d63a6bf14563eac8b5aaec4836061ff7e,"KAFKA-13899: Use INVALID_CONFIG error code consistently in AlterConfig APIs (#12162)

In the AlterConfigs/IncrementalAlterConfigs zk handler, we return `INVALID_REQUEST` and `INVALID_CONFIG` inconsistently. The problem is in `LogConfig.validate`. We may either return `ConfigException` or `InvalidConfigException`. When the first of these is thrown, we catch it and convert to `INVALID_REQUEST`. If the latter is thrown, then we return `INVALID_CONFIG`. It seems more appropriate to return `INVALID_CONFIG` consistently, which is what the KRaft implementation already does this. This patch fixes this and converts a few integration tests to KRaft.

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",2022-05-16 17:41:23,Jason Gustafson,Not TDD
a1cd1d183900af787c8971c9af3a3546d02d4451,"MINOR: Followers should not have any remote replica states left over from previous leadership (#12138)

This patch ensures that followers don't have any remote replica states left over from previous leadership.

Reviewers: Jason Gustafson <jason@confluent.io>",2022-05-18 09:32:48,David Jacot,Mixed
67d00e25e941f73be8b959c6732ac4db1d1083bf,"MINOR: Enable some AdminClient integration tests (#12110)

Enable KRaft in `AdminClientWithPoliciesIntegrationTes`t and `PlaintextAdminIntegrationTest`. There are some tests not enabled or not as expected yet:

- testNullConfigs, see KAFKA-13863
- testDescribeCluster and testMetadataRefresh, currently we don't get the real controller in KRaft mode so the test may not run as expected

This patch also changes the exception type raised from invalid `IncrementalAlterConfig` requests with the `SUBTRACT` and `APPEND` operations. When the configuration value type is not a list, we now raise `INVALID_CONFIG` instead of `INVALID_REQUEST`.

Reviewers: Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",2022-05-18 09:39:26,dengziming,Not TDD
1135f22eaf404fdf76489302648199578876c4ac,"KAFKA-13830 MetadataVersion integration for KRaft controller (#12050)

This patch builds on #12072 and adds controller support for metadata.version. The kafka-storage tool now allows a
user to specify a specific metadata.version to bootstrap into the cluster, otherwise the latest version is used.

Upon the first leader election of the KRaft quroum, this initial metadata.version is written into the metadata log. When
writing snapshots, a FeatureLevelRecord for metadata.version will be written out ahead of other records so we can
decode things at the correct version level.

This also includes additional validation in the controller when setting feature levels. It will now check that a given
metadata.version is supportable by the quroum, not just the brokers.

Reviewers: José Armando García Sancio <jsancio@gmail.com>, Colin P. McCabe <cmccabe@apache.org>, dengziming <dengziming1993@gmail.com>, Alyssa Huang <ahuang@confluent.io>",2022-05-18 12:08:36,David Arthur,Mixed
8efdbce5231f3b5ef61deb827c41b0a8c50aa84a,"KAFKA-13837; Return an error from Fetch if follower is not a valid replica (#12150)

When a partition leader receives a `Fetch` request from a replica which is not in the current replica set, the behavior today is to return a successful fetch response, but with empty data. This causes the follower to retry until metadata converges without updating any state on the leader side. It is clearer in this case to return an error, so that the metadata inconsistency is visible in logging and so that the follower backs off before retrying. 

In this patch, we use `UNKNOWN_LEADER_EPOCH` when the `Fetch` request includes the current leader epoch. The way we see this is that the leader is validating the (replicaId, leaderEpoch) tuple. When the leader returns `UNKNOWN_LEADER_EPOCH`, it means that the leader does not expect the given leaderEpoch from that replica. If the request does not include a leader epoch, then we use `NOT_LEADER_OR_FOLLOWER`. We can take a similar interpretation for this case: the leader is rejecting the request because it does not think it should be the leader for that replica. But mainly these errors ensure that the follower will retry the request.

As a part of this patch, I have refactored the way that the leader updates follower fetch state. Previously, the process is a little convoluted. We send the fetch from `ReplicaManager` down to `Partition.readRecords`, then we iterate over the results and call `Partition.updateFollowerFetchState`. It is more straightforward to update state directly as a part of `readRecords`. All we need to do is pass through the `FetchParams`. This also prevents an unnecessary copy of the read results.

Reviewers: David Jacot <djacot@confluent.io>",2022-05-18 20:58:20,Jason Gustafson,Mixed
6380652a5a3c66bef4dc8231c3eb4842b3556148,"KAFKA-13863; Prevent null config value when create topic in KRaft mode (#12109)

This patch ensures consistent handling of null-valued topic configs between the zk and kraft controller. Prior to this patch, we returned INVALID_REQUEST in zk mode and it was not an error in kraft. After this patch, we return INVALID_CONFIG consistently for this case.

Reviewers: Jason Gustafson <jason@confluent.io>",2022-05-19 09:46:48,dengziming,Mixed
a8e3a259e5d4daf098a503a25aa6249e21ba557a,"KAFKA-13889: Fix AclsDelta handling of REMOVE_ACCESS_CONTROL_ENTRY_RECORD (#12160)

AclsDelta stores the pending deletion in the changes Map. This could override a creation that might have just happened. This is an issue because in BrokerMetadataPublisher this results in us making a removeAcl call which finally results in StandardAuthorizerData trying to remove an ACL that doesn't exist which throws an exception. If the ACCESS_CONTROL_ENTRY_RECORD event never got processed by BrokerMetadataPublisher then the ACL wont be in the Map yet.

The fix here is to remove the entry from the changes Map if the ACL doesnt exist in the image yet.

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",2022-05-19 16:24:34,andymg3,Mixed
b5699b5ccd68ae0b27530a6cfcf14a5f3099eef0,"KAFKA-13923; Generalize authorizer system test for kraft (#12190)

Change `ZookeeperAuthorizerTest` to `AuthorizerTest` and add support for KRaft's `StandardAuthorizer` implementation.

Reviewers: David Jacot <djacot@confluent.io>",2022-05-23 09:47:14,Jason Gustafson,Not TDD
9dc332f5ca34b80af369646f767c40c6b189f831,"KAFKA-13217: Reconsider skipping the LeaveGroup on close() or add an overload that does so (#12035)

This is for KIP-812:

* added leaveGroup on a new close function in kafka stream
* added logic to resolve future returned by remove member call in close method
* added max check on remainingTime value in close function


Reviewers: David Jacot <david.jacot@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2022-05-23 10:07:19,Sayantanu Dey,Mixed
286bae4251fcea47de58a3e4b77e337201c5b64d,"KAFKA-10199: Implement adding standby tasks to the state updater (#12200)

This PR adds adding of standby tasks to the default implementation of the state updater.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2022-05-24 16:59:14,Bruno Cadonna,Mixed
54d60ced869cbc31776f755c7f464ae2d2ee3e95,"KAFKA-13833: Remove the min_version_level from the finalized version range written to ZooKeeper (#12062)

Reviewers: David Arthur <mumrah@gmail.com>",2022-05-25 14:02:34,dengziming,Mixed
76477ffd2d8a84803c57839fab6e0707045cd8f5,"KAFKA-13858; Kraft should not shutdown metadata listener until controller shutdown is finished (#12187)

When the kraft broker begins controlled shutdown, it immediately disables the metadata listener. This means that metadata changes as part of the controlled shutdown do not get sent to the respective components. For partitions that the broker is follower of, that is what we want. It prevents the follower from being able to rejoin the ISR while still shutting down. But for partitions that the broker is leading, it means the leader will remain active until controlled shutdown finishes and the socket server is stopped. That delay can be as much as 5 seconds and probably even worse.

This PR revises the controlled shutdown procedure as follow:
* The broker signals to the replica manager that it is about to start the controlled shutdown.
* The broker requests a controlled shutdown to the controller.
* The controller moves leaders off from the broker, removes the broker from any ISR that it is a member of, and writes those changes to the metadata log.
* When the broker receives a partition metadata change, it looks if it is in the ISR. If it is, it updates the partition as usual. If it is not or if there is no leader defined--as would be the case if the broker was the last member of the ISR--it stops the fetcher/replica. This basically stops all the partitions for which the broker was part of their ISR.

When the broker is a replica of a partition but it is not in the ISR, the controller does not do anything. The leader epoch is not bumped. In this particular case, the follower will continue to run until the replica manager shuts down. In this time, the replica could become in-sync and the leader could try to bring it back to the ISR. This remaining issue will be addressed separately.

Reviewers: Jason Gustafson <jason@confluent.io>",2022-05-25 16:09:01,David Jacot,Mixed
c22d320a5c85f38506839352d82d5fbbc0749878,"KAFKA-12902: Add unit32 type in generator (#10830)

Add uint32 support in the KRPC generator.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2022-05-25 16:25:16,dengziming,Mixed
4efdc1a31070b1d1d338e9908041697378af0d8e,"MINOR: Consolidate FinalizedFeatureCache into MetadataCache (#12214)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2022-05-26 16:25:58,David Arthur,Mixed
7143267f71ca0c14957d8560fbc42a5f8aac564d,"MINOR: Fix some bugs with UNREGISTER_BROKER

Fix some bugs in the KRaft unregisterBroker API and add a junit test.

1. kafka-cluster-tool.sh unregister should fail if no broker ID is passed.

2. UnregisterBrokerRequest must be marked as a KRaft broker API so 
that KRaft brokers can receive it.

3. KafkaApis.scala must forward UNREGISTER_BROKER to the controller.

Reviewers: Jason Gustafson <jason@confluent.io>, dengziming <dengziming1993@gmail.com>, David Jacot <djacot@confluent.io>",2022-05-26 14:07:29,Colin Patrick McCabe,Not TDD
645c1ba526ec11049429dc5e9ba347fc386df58e,"MINOR: Fix buildResponseSend test cases for envelope responses (#12185)

The test cases we have in `RequestChannelTest` for `buildResponseSend` construct the envelope request incorrectly. The request is created using the envelope context, but also a reference to the wrapped envelope request object. This patch fixes `TestUtils.buildEnvelopeRequest` so that the wrapped request is built properly. It also fixes the dependence on this incorrect construction and consolidates the tests in `RequestChannelTest` to avoid duplication.

Reviewers: dengziming <dengziming1993@gmail.com>, David Jacot <djacot@confluent.io>",2022-05-30 11:34:36,Jason Gustafson,Mixed
7d1b0926fab104311a505826831ddc45864e9a6a,"KAFKA-13883: Implement NoOpRecord and metadata metrics (#12183)

Implement NoOpRecord as described in KIP-835. This is controlled by the new
metadata.max.idle.interval.ms configuration.

The KRaft controller schedules an event to write NoOpRecord to the metadata log if the metadata
version supports this feature. This event is scheduled at the interval defined in
metadata.max.idle.interval.ms. Brokers and controllers were improved to ignore the NoOpRecord when
replaying the metadata log.

This PR also addsffour new metrics to the KafkaController metric group, as described KIP-835.

Finally, there are some small fixes to leader recovery. This PR fixes a bug where metadata version
3.3-IV1 was not marked as changing the metadata. It also changes the ReplicaControlManager to
accept a metadata version supplier to determine if the leader recovery state is supported.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2022-06-01 10:48:24,José Armando García Sancio,Mixed
1d6e3d6cb3a798983cafb0367b90c3a51579c364,"KAFKA-13845: Add support for reading KRaft snapshots in kafka-dump-log (#12084)

The kafka-dump-log command should accept files with a suffix of "".checkpoint"". It should also decode and print using JSON the snapshot header and footer control records.

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",2022-06-01 14:49:00,dengziming,Mixed
0ca9cd4d2d2a89510dbe357783a316f2f0789799,"MINOR: Several fixes and improvements for FeatureControlManager (#12207)

This PR fixes a bug where FeatureControlManager#replay(FeatureLevelRecord) was throwing an
exception if not all controllers in the quorum supported the feature being applied. While we do
want to validate this, it needs to be validated earlier, before the record is committed to the log.
Once the record has been committed to the log it should always be applied if the current controller
supports it.

Fix another bug where removing a feature was not supported once it had been configured. Note that
because we reserve feature level 0 for ""feature not enabled"", we don't need to use
Optional<VersionRange>; we can just return a range of 0-0 when the feature is not supported.

Allow the metadata version to be downgraded when UpgradeType.UNSAFE_DOWNGRADE has been set.
Previously we were unconditionally denying this even when this was set.

Add a builder for FeatureControlManager, so that we can easily add new parameters to the
constructor in the future. This will also be useful for creating FeatureControlManagers that are
initialized to a specific MetadataVersion.

Get rid of RemoveFeatureLevelRecord, since it's easier to just issue a FeatureLevelRecord with
the level set to 0.

Set metadata.max.idle.interval.ms to 0 in RaftClusterSnapshotTest for more predictability.

Reviewers: David Arthur <mumrah@gmail.com>, dengziming <dengziming1993@gmail.com>",2022-06-01 16:09:38,Colin Patrick McCabe,Mixed
65b4374203608dc4d68544bde16d4acd2e31efd1,"MINOR: implement BrokerRegistrationChangeRecord (#12195)

Implement BrokerRegistrationChangeRecord as specified in KIP-746. This is a more flexible record than the
single-purpose Fence / Unfence records.

Reviewers: José Armando García Sancio <jsancio@gmail.com>, dengziming <dengziming1993@gmail.com>",2022-06-01 16:33:01,Colin Patrick McCabe,Mixed
fa33fb4d3ced39ee985a15c1e44650542a3b47d2,"KAFKA-13773: catch kafkaStorageException to avoid broker shutdown directly (#12136)

When logManager startup and loadLogs, we expect to catch any IOException (ex: out of space error) and turn the log dir into offline. Later, we'll handle the offline logDir in ReplicaManage, so that the cleanShutdown file won't be created when all logDirs are offline. The reason why the broker shutdown with cleanShutdown file after full disk is because during loadLogs and do log recovery, we'll write leader-epoch-checkpoint fil. And if any IOException thrown, we'll wrap it as KafkaStorageException and rethrow. And since we don't catch KafkaStorageException, so the exception is caught in the other place and go with clean shutdown path.

This PR is to fix the issue by catching the KafkaStorageException with IOException cause exceptions during loadLogs, and mark the logDir as offline to let the ReplicaManager handle the offline logDirs.

Reviewers: Jun Rao <jun@confluent.io>, Alok Thatikunta <alok123thatikunta@gmail.com>",2022-06-02 14:15:51,Luke Chen,Not TDD
61df3034fece16180a479ed8758f383f6523eac3,"KAFKA-12657: Increase timeouts in Connect integration tests (#12191)

As an initial step to address the notoriously flaky BlockingConnectorTest test suite, we can try increasing test timeouts.

This approach may not be sufficient, and even if it is, it's still suboptimal. Although it may address flakiness on Jenkins, it will make genuine failures harder to detect when testing local changes. Additionally, if the workload on Jenkins continues to increase, we'll probably have to bump these timeouts in the future again at some point.

Potential next steps, for this PR and beyond:

    Stop leaking threads that block during test runs
    Instead of artificially reducing the REST request timeout at the beginning of every test, reduce it selectively right before issuing a REST request that is expected to time out, and then immediately reset it.
    Eliminate artificial reduction of the REST request timeout entirely, as it may be negatively impacting other Connect integration tests that are being run concurrently.
    Test repeatedly on Jenkins, ideally at least 50 times
    Gather information on the number of CPU cores available to each Jenkins node and the distribution of how many threads are allocated over a given time period (maybe a day?); this is especially relevant since local testing indicates that these tests all do much better when parallelism is reduced, which shouldn't be too surprising considering that each Connect integration test spins up separate threads for at least one Zookeeper node, one Kafka broker, one Connect worker, and usually at least one connector and one task.

I'd like to test these changes as a first step before investigating any of the above (except maybe items 1 and 2, which should be fairly straightforward). To trigger new runs I plan on pushing empty commits or, if those do not trigger new Jenkins runs, dummy commits. If this is objectionable let me know and hopefully we can find a suitable alternative.

Reviewers: Kvicii <Karonazaba@gmail.com>, Bruno Cadonna <cadonna@apache.org>",2022-06-02 10:21:07,Chris Egerton,Not TDD
a110f1fe852ae8c958a8c64b0736a9bb0617338e,"KAFKA-10000: Add new preflight connector config validation logic (#11776)


Reviewers: Mickael Maison <mickael.maison@gmail.com>  , Tom Bentley <tbentley@redhat.com>",2022-06-02 11:57:50,Chris Egerton,Mixed
d8d92f0f8014e5686e956a0c82bb2afdd41592d5,"MINOR: Update the kafka-reassign-partitions script command in documentation (#12237)

Reviewers: Luke Chen <showuon@gmail.com>",2022-06-02 21:30:22,RivenSun,Not TDD
3467036e017adc3ac0919bbc0c067b1bb1b621f3,"KAFKA-13803: Refactor Leader API Access (#12005)

This PR refactors the leader API access in the follower fetch path.

Added a LeaderEndPoint interface which serves all access to the leader.

Added a LocalLeaderEndPoint and a RemoteLeaderEndPoint which implements the LeaderEndPoint interface to handle fetches from leader in local & remote storage respectively.

Reviewers: David Jacot <djacot@confluent.io>, Kowshik Prakasam <kprakasam@confluent.io>, Jun Rao <junrao@gmail.com>",2022-06-03 09:12:06,Rittika Adhikari,Mixed
2047fc3715002899996ba3e41d16551d2067edad,"HOTFIX: only try to clear discover-coordinator future upon commit (#12244)

This is another way of fixing KAFKA-13563 other than #11631.

Instead of letting the consumer to always try to discover coordinator in pool with either mode (subscribe / assign), we defer the clearance of discover future upon committing async only. More specifically, under manual assign mode, there are only three places where we need the coordinator:

* commitAsync (both by the consumer itself or triggered by caller), this is where we want to fix.
* commitSync, which we already try to re-discovery coordinator.
* committed (both by the consumer itself based on reset policy, or triggered by caller), which we already try to re-discovery coordinator.

The benefits are that for manual assign mode that does not try to trigger any of the above three, then we never would be discovering coordinator. The original fix in #11631 would let the consumer to discover coordinator even if none of the above operations are required.

Reviewers: Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",2022-06-06 11:05:41,Guozhang Wang,Mixed
603502bf5fb78983434a1a44ccc15a49ef6942b0,"KAFKA-10000: Use transactional producer for leader-only writes to the config topic (#11778)

Implements the behavior described in KIP-618: using a transactional producer for writes to the config topic that should only be performed by the leader of the cluster.

Reviewers: Luke Chen <showuon@gmail.com>, Tom Bentley <tbentley@redhat.com>",2022-06-07 15:16:48,Chris Egerton,Mixed
a6c5a74fdbdce9a992b47706913c920902cda28c,"KAFKA-13945: add bytes/records consumed and produced metrics (#12235)

Implementation of KIP-846: Source/sink node metrics for Consumed/Produced throughput in Streams

Adds the following INFO topic-level metrics for the total bytes/records consumed and produced:

    bytes-consumed-total
    records-consumed-total
    bytes-produced-total
    records-produced-total

Reviewers: Kvicii <Karonazaba@gmail.com>, Guozhang Wang <guozhang@apache.org>, Bruno Cadonna <cadonna@apache.org>",2022-06-07 16:02:17,A. Sophie Blee-Goldman,Mixed
151ca12a56c854d78be07f9893ef7984277bb5c1,"KAFKA-13916; Fenced replicas should not be allowed to join the ISR in KRaft (#12240)

This PR implements the first part of KIP-841. Specifically, it implements the following:

1. Adds a new metadata version.
2. Adds the InControlledShutdown field to the BrokerRegistrationRecord and BrokerRegistrationChangeRecord and bump their versions. The newest versions are only used if the new metadata version is enabled.
3. Writes a BrokerRegistrationChangeRecord with InControlledShutdown set when a broker requests a controlled shutdown.
4. Ensures that fenced and in controlled shutdown replicas are not picked as leaders nor included in the ISR.
5. Adds or extends unit tests.

Reviewes: José Armando García Sancio <jsancio@users.noreply.github.com>, dengziming <dengziming1993@gmail.com>, David Arthur <mumrah@gmail.com>",2022-06-07 10:37:20,David Jacot,Mixed
806098ffe1bd28e2ae12884a60f5bf14432b7e01,"KAFKA-13410; Add a --release-version flag for storage-tool (#12245)

This patch removes the --metadata-version and adds a --release-version to the kafka-storage tool. This change is not a breaking change since we are removing --metadata-version which was introduced on May 18, but it has not been released yet.

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, dengziming <dengziming1993@gmail.com>",2022-06-07 11:25:40,David Arthur,Mixed
e67408c859fb2a80f1b3c208b7fef6ddc9a711fb,"KAFKA-10199: Implement removing active and standby tasks from the state updater (#12270)

This PR adds removing of active and standby tasks from the default implementation of the state updater. The PR also includes refactoring that clean up the code.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2022-06-09 10:28:26,Bruno Cadonna,Mixed
0a50005408b41fc8b3b26e2ed146b3e49d15af10,"KAFKA-13929: Replace legacy File.createNewFile() with NIO.2 Files.createFile() (#12197)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2022-06-10 13:28:55,Divij Vaidya,Not TDD
6853d63e4de03d679978add576aa0977cecc053a,"KAFKA-10000: Zombie fencing logic (#11779)


Reviewers: Mickael Maison <mickael.maison@gmail.com>  , Tom Bentley <tbentley@redhat.com>",2022-06-10 14:35:35,Chris Egerton,Mixed
3d5b41e05f0011dcf607f7d9cb269e8bb4558c57,"[KAFKA-13848] Clients remain connected after SASL re-authentication f… (#12179)



Clients remain connected and able to produce or consume despite an expired OAUTHBEARER token.

Root cause seems to be SaslServerAuthenticator#calcCompletionTimesAndReturnSessionLifetimeMs failing to set ReauthInfo#sessionExpirationTimeNanos when tokens have already expired (when session life time goes negative), in turn causing KafkaChannel#serverAuthenticationSessionExpired returning false and finally SocketServer not closing the channel.

The issue is observed with OAUTHBEARER but seems to have a wider impact on SASL re-authentication.

Reviewers: Luke Chen <showuon@gmail.com>, Tom Bentley <tbentley@redhat.com>, Sam Barker <sbarker@redhat.com>",2022-06-10 21:33:33,András Csáki,Mixed
c23d60d56cd73118624192cf03f6e400f59027e7,"KAFKA-13891: reset generation when syncgroup failed with REBALANCE_IN_PROGRESS (#12140)

Reviewers: Luke Chen <showuon@gmail.com>",2022-06-13 10:39:54,Shawn,Mixed
9e8ef8bb317599c184ce8201d494edf109d9c528,"KAFKA-10000: Exactly-once source tasks (#11780)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Tom Bentley <tbentley@redhat.com>",2022-06-13 16:25:29,Chris Egerton,Mixed
5cab11cf525f6c06fcf9eb43f7f95ef33fe1cdbb,"KAFKA-13846: Adding overloaded metricOrElseCreate method (#12121)

Reviewers: David Jacot <djacot@confluent.io>, Justine Olshan <jolshan@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2022-06-13 10:36:39,vamossagar12,Not TDD
cc384054c6e63abd011f7687523b1292062b049d,"KAFKA-13935 Fix static usages of IBP in KRaft mode (#12250)

* Set the minimum supported MetadataVersion to 3.0-IV1
* Remove MetadataVersion.UNINITIALIZED
* Relocate RPC version mapping for fetch protocols into MetadataVersion
* Replace static IBP calls with dynamic calls to MetadataCache

A side effect of removing the UNINITIALIZED metadata version is that the FeatureControlManager and FeatureImage will initialize themselves with the minimum KRaft version (3.0-IV1).

The rationale for setting the minimum version to 3.0-IV1 is so that we can avoid any cases of KRaft mode running with an old log message format (KIP-724 was introduced in 3.0-IV1). As a side-effect of increasing this minimum version, the feature level values decreased by one.

Reviewers: Jason Gustafson <jason@confluent.io>, Jun Rao <junrao@gmail.com>",2022-06-13 14:23:28,David Arthur,Mixed
3189a8648f3abf3e16c5932dfa37e0d28d97a016,"HOTFIX: null check keys of ProducerRecord when computing sizeInBytes (#12288)

Minor followup to #12235 that adds a null check on the record key in the new ClientUtils#producerRecordSizeInBytes utility method, as there are valid cases in which we might be sending records with null keys to the Producer, such as a simple builder.stream(""non-keyed-input-topic"").filter(...).to(""output-topic"")

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>",2022-06-13 22:27:06,A. Sophie Blee-Goldman,Mixed
f83d95d9a28267f7ef7a7b1e584dcdb4aa842210,"KAFKA-13916; Fenced replicas should not be allowed to join the ISR in KRaft (KIP-841, Part 2) (#12181)

This path implements [KIP-841](https://cwiki.apache.org/confluence/display/KAFKA/KIP-841%3A+Fenced+replicas+should+not+be+allowed+to+join+the+ISR+in+KRaft). Specifically, it implements the following:
* It introduces INELIGIBLE_REPLICA and NEW_LEADER_ELECTED error codes.
* The KRaft controller validates the new ISR provided in the AlterPartition request and rejects the call if any replica in the new ISR is not eligible to join the the ISR - e.g. when fenced or shutting down. The leader reverts to the last committed ISR when its request is rejected due to this.
* The partition leader also verifies that a replica is eligible before trying to add it back to the ISR. If it is not eligible, the ISR expansion is not triggered at all.
* Updates the AlterPartition API to use topic ids. Updates the AlterPartition manger to handle topic names/ids. Updates the ZK controller and the KRaft controller to handle topic names/ids depending on the version of the request used.

Reviewers: Artem Livshits <84364232+artemlivshits@users.noreply.github.com>, José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",2022-06-14 13:12:45,David Jacot,Mixed
4fcfd9ddc4a8da3d4cfbb69268c06763352e29a9,"KAFKA-13958: Expose logdirs total/usable space via Kafka API (KIP-827) (#12248)

This implements KIP-827: https://cwiki.apache.org/confluence/display/KAFKA/KIP-827%3A+Expose+logdirs+total+and+usable+space+via+Kafka+API

Add TotalBytes and UsableBytes to DescribeLogDirsResponse
Add matching getters on LogDirDescription

Reviewers: Tom Bentley <tbentley@redhat.com>, Divij Vaidya<diviv@amazon.com>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>, Igor Soarez <soarez@apple.com>",2022-06-14 14:20:29,Mickael Maison,Mixed
39a555ba94a6a5d851b31e0a7f07e19c48327835,"KAFKA-13846: Use the new addMetricsIfAbsent API (#12287)

Use the newly added function to replace the old addMetric function that may throw illegal argument exceptions.

Although in some cases concurrency should not be possible they do not necessarily remain always true in the future, so it's better to use the new API just to be less error-prone.

Reviewers: Bruno Cadonna <cadonna@apache.org>",2022-06-14 16:04:26,Guozhang Wang,Mixed
a126e3a622f2b7142f3543b9dbee54b6412ba9d8,"KAFKA-13888; Addition of Information in DescribeQuorumResponse about Voter Lag (#12206)

This commit adds an Admin API handler for DescribeQuorum Request and also
adds in two new fields LastFetchTimestamp and LastCaughtUpTimestamp to
the DescribeQuorumResponse as described by KIP-836.

This commit does not implement the newly added fields. Those will be
added in a subsequent commit.

Reviewers: dengziming <dengziming1993@gmail.com>, David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>",2022-06-15 09:20:15,Niket,Mixed
7ed3748a462cd1ce7c30bb9a331b94a3cd79a401,"KAFKA-13873 Add ability to Pause / Resume KafkaStreams Topologies (#12161)

This PR adds the ability to pause and resume KafkaStreams instances as well as named/modular topologies (KIP-834).

Co-authored-by: Bruno Cadonna <cadonna@apache.org>

Reviewers: Bonnie Varghese <bvarghese@confluent.io>, Walker Carlson <wcarlson@confluent.io>, Guozhang Wang <guozhang@apache.org>, Bruno Cadonna <cadonna@apache.org>",2022-06-16 16:06:02,James Hughes,Mixed
30216ea1c58761e62f51af40033f24e3ae1c5c2a,"KAFKA-13998: JoinGroupRequestData 'reason' can be too large (#12298)

The `reason` field cannot contain more than 32767 chars. We did not expect to ever reach this but it turns out that it is possible if the the message provided in the `Throwable` somehow contains the entire stack trace. This patch ensure that the reason crafted based on exceptions remain small.

Co-authored-by: David Jacot <djacot@confluent.io>

Reviewers:  Bruno Cadonna <cadonna@apache.org>, A. Sophie Blee-Goldman <ableegoldman@apache.org>, David Jacot <djacot@confluent.io>",2022-06-20 16:47:02,James Hughes,Mixed
d65d8867983e54a36178c3a1227b68c8a468d415,"KAFKA-6945: KIP-373, allow users to create delegation token for others (#10738)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2022-06-21 12:51:08,Viktor Somogyi-Vass,Mixed
b7b7615db38d8a5d16fa13a227c4a09b4ea355e8,"KAFKA-10000: Per-connector offsets topics (#11781)

Implements support for per-connector offsets topics as described in KIP-618.

Reviewers: Luke Chen <showuon@gmail.com>, Tom Bentley <tbentley@redhat.com>",2022-06-21 15:58:17,Chris Egerton,Mixed
09286669877abaf17a1d9d52fa34c294e050f835,"MINOR: change Streams topic-level metrics tag from 'topic-name' to 'topic' (#12310)

Changes the tag name from topic-name to just topic to conform to the way this tag is named elsewhere (ie in the clients)
Also:
    - fixes a comment about dynamic topic routing
    - fixes some indentation in MockRecordCollector
    - Undoes the changes to KStreamSplitTest.scala and TestTopicsTest which are no longer necessary after this hotfix

Reviewers: Bruno Cadonna <cadonna@apache.org>",2022-06-21 13:10:36,A. Sophie Blee-Goldman,Not TDD
4d53dd99720ca4605a2975d2f14c58b80a965550,"KAFKA-13930: Add 3.2.0 Streams upgrade system tests (#12209)

* KAFKA-13930: Add 3.2.0 Streams upgrade system tests

Apache Kafka 3.2.0 was recently released. Now we need
to test upgrades from 3.2 to trunk in our system tests.

Reviewer: Bill Bejeck <bbejeck@apache.org>",2022-06-21 16:33:40,Bruno Cadonna,Not TDD
3072b3d23e43f3bc3478eca1087312edb620dc6b,"MINOR: Fix AlterPartitionManager topic id handling in response handler (#12317)

https://github.com/apache/kafka/commit/f83d95d9a28267f7ef7a7b1e584dcdb4aa842210 introduced topic ids in the AlterPartitionRequest/Response and we just found a bug in the request handling logic. The issue is the following.

When the `AlterPartitionManager` receives the response, it builds the `partitionResponses` mapping `TopicIdPartition` to its result. `TopicIdPartition` is built from the response. Therefore if version < 2 is used, `TopicIdPartition` will have the `ZERO` topic id. Then the `AlterPartitionManager` iterates over the item sent to find their response. If an item has a topic id in its `TopicIdPartition` and version < 2 was used, it cannot find it because one has it and the other one has not.

This patch fixes the issue by using `TopicPartition` as a key in the `partitionResponses` map. This ensures that the result can be found regardless of the topic id being set or not.

Note that the case where version 2 is used is handled correctly because we already have logic to get back the topic name from the topic id in order to construct the `TopicPartition`.

`testPartialTopicIds` test was supposed to catch this but it didn't due to the ignorable topic id field being present. This patch fixes the test as well.

Reviewers: Kvicii <42023367+Kvicii@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",2022-06-21 18:24:33,David Jacot,Mixed
d00b7875e0ad7e005b9b54d39f47269c71e95fbe,"KAFKA-13987: Isolate REST request timeout changes in Connect integration tests (#12291)

This causes the artificial reductions in the Connect REST request timeout to be more isolated. Specifically, they now only take place in the tests that need them (instead of any tests that happen to be running after the reduction has taken place and before it has been reset), and they are only performed for the requests that are expected to time out, before being immediately reset. This should help reduce spurious test failures (especially in slow environments like Jenkins) for all Connect integration tests that interact with the REST API, not just the BlockingConnectorTest test suite.

Reviewers: Bruno Cadonna <cadonna@apache.org>",2022-06-23 16:56:53,Chris Egerton,Not TDD
c6c9da02a81fcc034ea916230ac8acea603d41b7,"KAFKA-13966 Prepend bootstrap metadata to controller queue (#12269)

Also fixes flaky QuorumControllerTest#testInvalidBootstrapMetadata

Reviewers: Jason Gustafson <jason@confluent.io>",2022-06-23 11:29:21,David Arthur,Mixed
925c6281733662cd40fffaab54a6483b00f80ee6,"KAFKA-10199: Commit the restoration progress within StateUpdater (#12279)

During restoring, we should always commit a.k.a. write checkpoint file regardless of EOS or ALOS, since if there's a failure we would just over-restore them upon recovery so no EOS violations happened.

Also when we complete restore or remove task, we should enforce a checkpoint as well; for failing cases though, we should not write a new one.

Reviewers: Bruno Cadonna <cadonna@apache.org>",2022-06-23 10:46:14,Guozhang Wang,Mixed
1ceaf30039e48199e40951c5a8d52894bb45e4d3,"KAFKA-10199: Expose tasks in state updater (#12312)

This PR exposes the tasks managed by the state updater. The state updater manages all tasks that were added to the state updater and that have not yet been removed from it by draining one of the output queues.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2022-06-24 09:33:24,Bruno Cadonna,Mixed
6ac7f4ea8f1dafdf644fcfb869fbf9f04238786e,"KAFKA-13821: Update Kafka Streams WordCount demo to new Processor API (#12139)

https://issues.apache.org/jira/browse/KAFKA-13821

Reviewers: Jorge Esteban Quilcate Otoya <quilcate.jorge@gmail.com>, Bill Bejeck <bbejeck@apache.org>",2022-06-28 21:39:32,CHUN-HAO TANG,Mixed
08e509459bd61f6aafb9f7d3902dccbbc7e13296,"KAFKA-14010: AlterPartition request won't retry when receiving retriable error (#12329)

When submitting the AlterIsr request, we register a future listener to handle the response. When receiving retriable error, we expected the AlterIsr request will get retried. And then, we'll re-submit the request again.

However, before the future listener got called, we didn't clear the `unsentIsrUpdates`, which causes we failed to ""enqueue"" the request because we thought there's an in-flight request. We use ""try/finally"" to make sure the unsentIsrUpdates got cleared, but it happened ""after"" we retry the request	

Reviewers: David Jacot <djacot@confluent.io>, dengziming <dengziming1993@gmail.com>",2022-06-29 20:53:36,Luke Chen,Mixed
ababc4261bfa03ee9d29ae7254ddd0ba988f826d,"[9/N][Emit final] Emit final for session window aggregations (#12204)

* Add a new API for session windows to range query session window by end time (KIP related).
* Augment session window aggregator with emit strategy.
* Minor: consolidated some dup classes.
* Test: unit test on session window aggregator.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2022-06-29 09:22:37,Guozhang Wang,Mixed
3faa6cf6d060887288fcf68adb8c3f1e2090b8ed,"MINOR: Use mock time in DefaultStateUpdaterTest (#12344)

For most tests we would need an auto-ticking mock timer to work with draining-with-timeout functions.
For tests that check for never checkpoint we need no auto-ticking timer to control exactly how much time elapsed.

Reviewers: Bruno Cadonna <cadonna@apache.org>",2022-06-29 12:33:00,Guozhang Wang,Mixed
c19398ee6682f08ed12a2b7ca5ec58af25ede130,"KAFKA-14035; Fix NPE in `SnapshottableHashTable::mergeFrom()` (#12371)

The NPE causes the kraft controller to be in an inconsistent state. 

Reviewers: Jason Gustafson <jason@confluent.io>",2022-06-30 21:03:54,Niket,Mixed
6bf5bfc2982158c3a1bfff4a0f65ea901ea84e7a,"KAFKA-14036; Set local time in `ControllerApis` when `handle` returns (#12372)

In `ControllerApis`, we are missing the logic to set the local processing end time after `handle` returns. As a consequence of this, the remote time ends up reported as the local time in the request level metrics. The patch adds the same logic we have in `KafkaApis` to set `apiLocalCompleteTimeNanos`.

Reviewers: José Armando García Sancio <jsancio@gmail.com>",2022-06-30 21:07:21,Jason Gustafson,Mixed
c12348ac982378b755e104e95d7e1b2cba4c2948,"MINOR: Remove unused code from BrokerEndPoint (#12368)

Removes unused methods from `BrokerEndPoint`:

* `createBrokerEndPoint(Int, String)`
* `readFrom(buffer: ByteBuffer)`
* `connectionString(): String`
* `writeTo(buffer: ByteBuffer)`
* `sizeInBytes: Int`

Reviewers: dengziming <dengziming1993@gmail.com>, Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",2022-07-01 10:28:37,Nikolay,Mixed
ae570f59533ae941bbf5ab9ff5e739a5bd855fd6,"HOTFIX: Correct ordering of input buffer and enforced processing sensors (#12363)

1. As titled, fix the right constructor param ordering.
2. Also added a few more loglines.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Sagar Rao <sagarmeansocean@gmail.com>, Hao Li <1127478+lihaosky@users.noreply.github.com>",2022-07-03 10:02:59,Guozhang Wang,Mixed
ec22af94a6d7892c454fab97898bf68930bb61fc,"KAFKA-13613: Remove hard dependency on HmacSHA256 algorithm for Connect (#11894)


Reviewers: Mickael Maison <mickael.maison@gmail.com>  , Tom Bentley <tbentley@redhat.com>",2022-07-05 12:34:23,Chris Egerton,Mixed
448441a35d2f0c200c0f642f2bb618bd2d43df23,"KAFKA-13228; Ensure ApiVersionRequest is properly handled KRaft co-resident mode (#11784)

When brokers are co-resident with controllers using kraft, we incorrectly determine the supported API versions on the controller using `NodeApiVersions.create()`. The patch fixes the problem by using the versions from the sent `ApiVersions` request even when connecting to the local node.

The patch also improves integration tests by adding support for co-resident mode.

Reviewers: Justine Olshan <jolshan@confluent.io>, Jason Gustafson <jason@confluent.io>",2022-07-05 15:19:00,dengziming,Not TDD
3ae1afa43838066e44ea78918050c6780c208042,"KAFKA-10000: Integration tests (#11782)

Implements embedded end-to-end integration tests for KIP-618, and brings together previously-decoupled logic from upstream PRs.

Reviewers: Luke Chen <showuon@gmail.com>, Tom Bentley <tbentley@redhat.com>, Mickael Maison <mickael.maison@gmail.com>",2022-07-06 10:35:05,Chris Egerton,Not TDD
00f395bb889252e3efb62cedfaa1209b58d5fd3c,"KAFKA-10199: Remove call to Task#completeRestoration from state updater (#12379)

The call to Task#completeRestoration calls methods on the main consumer.
The state updater thread should not access the main consumer since the
main consumer is not thread-safe. Additionally, Task#completeRestoration
changed the state of active tasks, but we decided to keep task life cycle
management outside of the state updater.

Task#completeRestoration should be called by the stream thread on
restored active tasks returned by the state udpater.

Reviewer: Guozhang Wang <guozhang@apache.org>",2022-07-06 12:36:15,Bruno Cadonna,Mixed
6495a0768cae1086d4b1dfa466967dfe178c1553,"KAFKA-14032; Dequeue time for forwarded requests is unset (#12360)

When building a forwarded request, we need to override the dequeue time of the underlying request to match the same value as the envelope. Otherwise, the field is left unset, which causes inaccurate reporting.

Reviewers; Jason Gustafson <jason@confluent.io>",2022-07-06 13:21:28,YU,Mixed
915c781243933fe1a127eda6178d3db467e0bcf3,"KAFKA-10199: Remove main consumer from store changelog reader (#12337)

When store changelog reader is called by a different thread than the stream thread, it can no longer use the main consumer to get committed offsets since consumer is not thread-safe. Instead, we would remove main consumer and leverage on the existing admin client to get committed offsets.

Reviewers: Bruno Cadonna <cadonna@apache.org>",2022-07-06 17:23:18,Guozhang Wang,Mixed
38b08dfd3384a04b73e236c83f1e3ce0fffeda45,"MINOR: revert KIP-770 (#12383)

KIP-770 introduced a performance regression and needs some re-design.

Needed to resolve some conflict while reverting.

This reverts commits 1317f3f77a9e1e432e7a81de2dcb88365feeac43 and 0924fd3f9f75c446310ed1e97b44bbc3f33c6c31.

Reviewers:  Sagar Rao <sagarmeansocean@gmail.com>, Guozhang Wang <guozhang@confluent.io>",2022-07-07 11:19:37,Matthias J. Sax,Mixed
dc6f555492240c8c300fbbdf1d566c1b588760ab,"KAFKA-13983: Fail the creation with ""/"" in resource name in zk ACL (#12359)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2022-07-08 15:47:48,Aman Singh,Mixed
e85500bbbef7c10ee6bd379ab1327e8abb858b6b,"KAFKA-13996: log.cleaner.io.max.bytes.per.second can be changed dynamically (#12296)

log.cleaner.io.max.bytes.per.second cannot be changed dynamically using bin/kafka-configs.sh. Call updateDesiredRatePerSec() of Throttler with new log.cleaner.io.max.bytes.per.second value in reconfigure() of Log Cleaner to fix the issue.

Reviewers: Tom Bentley <tbentley@redhat.com>, Luke Chen <showuon@gmail.com>",2022-07-08 20:41:47,Tomonari Yamashita,Mixed
fc6e91e19920a41a56ff60c65e3b9719f4506977,"KAFKA-13474: Allow reconfiguration of SSL certs for broker to controller connection (#12381)

What:
When a certificate is rotated on a broker via dynamic configuration and the previous certificate expires, the broker to controller connection starts failing with SSL Handshake failed.

Why:
A similar fix was earlier performed in #6721 but when BrokerToControllerChannelManager was introduced in v2.7, we didn't enable dynamic reconfiguration for it's channel.

Summary of testing strategy (including rationale)
Add a test which fails prior to the fix done in the PR and succeeds afterwards. The bug wasn't caught earlier because there was no test coverage to validate the scenario.

Reviewers: Luke Chen <showuon@gmail.com>",2022-07-09 18:06:02,Divij Vaidya,Not TDD
0bc8da7aec8dfb7c61321b22e717a94565f4855d,"KAFKA-14055; Txn markers should not be removed by matching records in the offset map (#12390)

When cleaning a topic with transactional data, if the keys used in the user data happen to conflict with the keys in the transaction markers, it is possible for the markers to get removed before the corresponding data from the transaction is removed. This results in a hanging transaction or the loss of the transaction's atomicity since it would effectively get bundled into the next transaction in the log. Currently control records are excluded when building the offset map, but not when doing the cleaning. This patch fixes the problem by checking for control batches in the `shouldRetainRecord` callback.

Reviewers: Jun Rao <junrao@gmail.com>",2022-07-10 10:16:39,Jason Gustafson,Mixed
a3f06d88140783a73e0301c4c1a521b2a4fc97b9,"KAFKA-14013: Limit the length of the `reason` field sent on the wire (#12388)

KIP-800 added the `reason` field to the JoinGroupRequest and the LeaveGroupRequest as I mean to provide more information to the group coordinator. In https://issues.apache.org/jira/browse/KAFKA-13998, we discovered that the size of the field is limited to 32767 chars by our serialisation mechanism. At the moment, the field either provided directly by the user or constructed internally is directly set regardless of its length.

This patch sends only the first 255 chars of the used provided or internally generated reason on the wire. Given the purpose of this field, that seems acceptable and that should still provide enough information to operators to understand the cause of a rebalance.

Reviewers: David Jacot <djacot@confluent.io>",2022-07-12 09:31:16,Eugene Tolbakov,Mixed
d3130f2e911473fcf1265dec14016c824499d9a7,"KAFKA-14062: OAuth client token refresh fails with SASL extensions (#12398)

- Different objects should be considered unique even with same content to support logout
- Added comments for SaslExtension re: removal of equals and hashCode
- Also swapped out the use of mocks in exchange for *real* SaslExtensions so that we exercise the use of default equals() and hashCode() methods.
- Updates to implement equals and hashCode and add tests in SaslExtensionsTest to confirm

Co-authored-by: Purshotam Chauhan <pchauhan@confluent.io>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2022-07-12 14:28:19,Kirk True,Mixed
98726c2bac8bc221ec2df64b35ce15d0ee71893f,"KAFKA-13968: Fix 3 major bugs of KRaft snapshot generating (#12265)

There are 3 bugs when a broker generates a snapshot.

1. Broker should not generate snapshots until it starts publishing.
    Before a broker starts publishing, BrokerMetadataListener._publisher=None, so _publisher.foreach(publish) will do nothing, so featuresDelta.metadataVersionChange().isPresent is always true, so we will generating a snapshot on every commit since we believe metadata version has changed, here are the logs, note offset 1 is a LeaderChangeMessage so there is no snapshot:

[2022-06-08 13:07:43,010] INFO [BrokerMetadataSnapshotter id=0] Creating a new snapshot at offset 0... (kafka.server.metadata.BrokerMetadataSnapshotter:66)
[2022-06-08 13:07:43,222] INFO [BrokerMetadataSnapshotter id=0] Creating a new snapshot at offset 2... (kafka.server.metadata.BrokerMetadataSnapshotter:66)
[2022-06-08 13:07:43,727] INFO [BrokerMetadataSnapshotter id=0] Creating a new snapshot at offset 3... (kafka.server.metadata.BrokerMetadataSnapshotter:66)
[2022-06-08 13:07:44,228] INFO [BrokerMetadataSnapshotter id=0] Creating a new snapshot at offset 4... (kafka.server.metadata.BrokerMetadataSnapshotter:66)

2. We should compute metadataVersionChanged before _publisher.foreach(publish)
    After _publisher.foreach(publish) the BrokerMetadataListener_delta is always Empty, so metadataVersionChanged is always false, this means we will never trigger snapshot generating even metadata version has changed.

3. We should try to generate a snapshot when starting publishing
    When we started publishing, there may be a metadata version change, so we should try to generate a snapshot before first publishing.

Reviewers: Jason Gustafson <jason@confluent.io>, Divij Vaidya <diviv@amazon.com>, José Armando García Sancio <jsancio@users.noreply.github.com>",2022-07-12 08:02:43,dengziming,Mixed
b5d4fa7645eb75d2030eb8cac78545a681686a39,"KAFKA-13785: [10/N][emit final] more unit test for session store and disable cache for emit final sliding window (#12370)

1. Added more unit test for RocksDBTimeOrderedSessionStore and RocksDBTimeOrderedSessionSegmentedBytesStore
2. Disable cache for sliding window if emit strategy is ON_WINDOW_CLOSE

Reviewers: Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2022-07-12 10:57:11,Hao Li,Not TDD
beac86f049385932309158c1cb49c8657e53f45f,"KAFKA-13043: Implement Admin APIs for offsetFetch batching (#10964)

This implements the AdminAPI portion of KIP-709: https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=173084258. The request/response protocol changes were implemented in 3.0.0. A new batched API has been introduced to list consumer offsets for different groups. For brokers older than 3.0.0, separate requests are sent for each group.

Co-authored-by: Rajini Sivaram <rajinisivaram@googlemail.com>
Co-authored-by: David Jacot <djacot@confluent.io>

Reviewers: David Jacot <djacot@confluent.io>,  Rajini Sivaram <rajinisivaram@googlemail.com>",2022-07-14 13:47:34,Sanjana Kaundinya,Mixed
ddbc0300365dd1d9a2fb2c73faef8c4cbec0b316,"MINOR: Fix options for old-style Admin.listConsumerGroupOffsets (#12406)

Reviewers: David Jacot <djacot@confluent.io>",2022-07-15 09:21:35,Rajini Sivaram,Not TDD
c020c94e043ca4a997797da91a226735803774ab,"KAFKA-14039 Fix AlterConfigPolicy usage in KRaft (#12374)

Only pass configs from the request to the AlterConfigPolicy. This changes the KRaft usage of the AlterConfigPolicy to match the usage in ZK mode.

Reviewers: Jason Gustafson <jason@confluent.io>",2022-07-15 15:48:35,David Arthur,Mixed
ab9aaea3ce498db80ca55d0340f47abf1d975b07,"KAFKA-13572 Fix negative preferred replica imbalanced count metric (#12405)


Currently, preferredReplicaImbalanceCount calculation has a race that becomes negative when topic deletion is initiated simultaneously. This PR addresses the problem by fixing cleanPreferredReplicaImbalanceMetric to be called only once per topic-deletion procedure

Reviewers: Luke Chen <showuon@gmail.com>",2022-07-18 14:19:01,Okada Haruki,Mixed
81428226332005c27870aacfccc813950c84386c,"KAFKA-14079 - Ack failed records in WorkerSourceTask when error tolerance is ALL (#12415)

Make sure to ack all records where produce failed, when a connector's `errors.tolerance` config property is set to `all`. Acking is essential so that the task will continue to commit future record offsets properly and remove the records from internal tracking, preventing a memory leak.

(cherry picked and slightly modified from commit 63e06aafd0cf37f8488c3830946051b3a30db2a0)

Reviewers: Chris Egerton <fearthecellos@gmail.com>, Randall Hauch <rhauch@gmail.com>",2022-07-18 17:07:20,Christopher L. Shannon,Mixed
309e0f986e97be966c797f7729eb1e94ef5400a9,"KAFKA-10199: Add PAUSE in state updater (#12386)

* Add pause action to task-updater.
* When removing a task, also check in the paused tasks in addition to removed tasks.
* Also I realized we do not check if tasks with the same id are added, so I add that check in this PR as well.

Reviewers: Bruno Cadonna <cadonna@apache.org>",2022-07-18 16:42:48,Guozhang Wang,Mixed
188b2bf2802c2bc5900a286a9ef023daaeb08c21,"Revert ""KAFKA-12887 Skip some RuntimeExceptions from exception handler (#11228)"" (#12421)

This reverts commit 4835c64f

Reviewers: Matthias J. Sax <matthias@confluent.io>",2022-07-19 09:17:46,Walker Carlson,Not TDD
693e283802590b724ef441d5bf7acb6eeced91c5,"KAFKA-10199: Add RESUME in state updater (#12387)

* Need to check enforceRestoreActive / transitToUpdateStandby when resuming a paused task.
* Do not expose another getResumedTasks since I think its caller only need the getPausedTasks.

Reviewers: Bruno Cadonna <cadonna@apache.org>",2022-07-19 09:44:10,Guozhang Wang,Mixed
b62d8b975cf97b5c1328b9b03a05fa09b07cf13a,"KAFKA-12699: Override the default handler for stream threads if the stream's handler is used (#12324)

Override the default handler for stream threads if the stream's handler is used. We do no want the java default handler triggering when a thread is replaced.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2022-07-19 13:35:26,Walker Carlson,Not TDD
eee40200df5c68963c0b534f95b5154bfd60e290,"KAFKA-14024: Consumer keeps Commit offset in onJoinPrepare in Cooperative rebalance (#12349)

In KAFKA-13310, we tried to fix a issue that consumer#poll(duration) will be returned after the provided duration. It's because if rebalance needed, we'll try to commit current offset first before rebalance synchronously. And if the offset committing takes too long, the consumer#poll will spend more time than provided duration. To fix that, we change commit sync with commit async before rebalance (i.e. onPrepareJoin).

However, in this ticket, we found the async commit will keep sending a new commit request during each Consumer#poll, because the offset commit never completes in time. The impact is that the existing consumer will be kicked out of the group after rebalance timeout without joining the group. That is, suppose we have consumer A in group G, and now consumer B joined the group, after the rebalance, only consumer B in the group.

Besides, there's also another bug found during fixing this bug. Before KAFKA-13310, we commitOffset sync with rebalanceTimeout, which will retry when retriable error until timeout. After KAFKA-13310, we thought we have retry, but we'll retry after partitions revoking. That is, even though the retried offset commit successfully, it still causes some partitions offsets un-committed, and after rebalance, other consumers will consume overlapping records.

Reviewers: RivenSun <riven.sun@zoom.us>, Luke Chen <showuon@gmail.com>",2022-07-20 10:03:43,Shawn,Mixed
ed77bebcaf8e4a8f74dd3823c905c8fd01dadf64,"KAFKA-13702: Connect RestClient overrides response status code on request failure (#12320)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chris Egerton <fearthecellos@gmail.com>",2022-07-20 11:29:00,Elkhan Eminov,Mixed
c9b6e19b3b37499de17da19e82b1b98e3b9f6b5c,"KAFKA-10199: Cleanup TaskManager and Task interfaces (#12397)

In order to integrate with the state updater, we would need to refactor the TaskManager and Task interfaces. This PR achieved the following purposes:

    Separate active and standby tasks in the Tasks placeholder, plus adding pendingActiveTasks and pendingStandbyTasks into Tasks. The exposed active/standby tasks from the Tasks set would only be mutated by a single thread, and the pending tasks hold for those tasks that are assigned but cannot be actively managed yet. For now they include two scenarios: a) tasks from unknown sub-topologies and hence cannot be initialized, b) tasks that are pending for being recycled from active to standby and vice versa. Note case b) would be added in a follow-up PR.

    Extract any logic that mutates a task out of the Tasks / TaskCreators. Tasks should only be a place for maintaining the set of tasks, but not for manipulations of a task; and TaskCreators should only be used for creating the tasks, but not for anything else. These logic are all migrated into TaskManger.

    While doing 2) I noticed we have a couple of minor issues in the code where we duplicate the closing logics, so I also cleaned them up in the following way:
    a) When closing a task, we first trigger the corresponding closeClean/Dirty function; then we remove the task from Tasks bookkeeping, and for active task we also remove its task producer if EOS-V1 is used.
    b) For closing dirty, we swallow the exception from close call and the remove task producer call; for closing clean, we store the thrown exception from either close call or the remove task producer, and then rethrow at the end of the caller. The difference though is that, for the exception from close call we need to retry close it dirty; for the exception from the remove task producer we do not need to re-close it dirty.

Reviewer: Bruno Cadonna <cadonna@apache.org>",2022-07-21 15:11:40,Guozhang Wang,Mixed
ff7cbf264c0cb79ae56209ac381c51ef588ab97a,"KAFKA-14076: Fix issues with KafkaStreams.CloseOptions (#12408)

- used static memberId was incorrect
- need to remove all threads/members from the group
- need to use admit client correctly

Add test to verify fixes.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2022-07-21 07:35:29,James Hughes,Not TDD
5a52601691478857472333d8a13a07b09a7d13c5,"KAFKA-10199: Add tasks to state updater when they are created (#12427)

This PR introduces an internal config to enable the state updater. If the state updater is enabled newly created tasks are added to the state updater. Additionally, this PR introduces a builder for mocks for tasks.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2022-07-21 12:37:17,Bruno Cadonna,Mixed
679e9e0cee67e7d3d2ece204a421ea7da31d73e9,"KAFKA-13919: expose log recovery metrics (#12347)

Implementation for KIP-831.
1. add remainingLogsToRecover metric for the number of remaining logs for each log.dir to be recovered
2.  add remainingSegmentsToRecover metric for the number of remaining segments for the current log assigned to the recovery thread.
3. remove these metrics after log loaded completely
4. add tests 

Reviewers: Jun Rao <jun@confluent.io>, Tom Bentley <tbentley@redhat.com>",2022-07-22 11:00:15,Luke Chen,Mixed
6b76c01cf895db0651e2cdcc07c2c392f00a8ceb,"KAFKA-13158: Migrate ConnectClusterStateImpl to Mockito (#12423)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chris Egerton <fearthecellos@gmail.com>",2022-07-25 19:47:08,Christo Lolov,Not TDD
a450fb70c12ba66257e8f61cc4903290f1e435ea,"KAFKA-14078; Do leader/epoch validation in Fetch before checking for valid replica (#12411)

After the fix for https://github.com/apache/kafka/pull/12150, if a follower receives a request from another replica, it will return UNKNOWN_LEADER_EPOCH even if the leader epoch matches. We need to do epoch leader/epoch validation first before we check whether we have a valid replica.

Reviewers: David Jacot <djacot@confluent.io>",2022-07-25 13:24:40,Jason Gustafson,Mixed
25b914750dcd07ac4c74afbc42956a1affec59e8,KAFKA-13982: Move WorkerConfigTransformerTest to use Mockito (#12422),2022-07-26 09:39:27,Christo Lolov,Not TDD
14d2269471141067dc3c45300187f20a0a051777,"KAFKA-13166 Fix missing ControllerApis error handling (#12403)

Makes all ControllerApis request handlers return a `CompletableFuture[Unit]`. Also adds an additional completion stage which ensures we capture errors thrown during response building.

Reviewed-by: Colin P. McCabe <cmccabe@apache.org>",2022-07-26 19:08:59,David Arthur,Mixed
160a6ab4cb0bd4c3e303329b5bb30a13c196b030,"KAFKA-13730: OAuth access token validation fails if it does not contain the ""sub"" claim (#11886)

Removes the requirement of presence of sub claim in JWT access tokens, when clients authenticate via OAuth.
This does not interfere with OAuth specifications and is to ensure wider compatibility with OAuth providers.
Unit test added.

Reviewers:  Kirk True <ktrue@confluent.io>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>,  Manikumar Reddy <manikumar.reddy@gmail.com>",2022-07-27 16:44:54,Daniel Fonai,Mixed
d076b7ad0ee3a2dba710ff79d6c4dd5840766e9f,"KAFKA-13769: Add tests for ForeignJoinSubscriptionProcessorSupplier (#12437)

Reviewers: Adam Bellemare <adam.bellemare@gmail.com>, John Roesler <vvcephei@apache.org>",2022-07-27 13:58:12,Alex Sorokoumov,Not TDD
06f47c3b517f5c96c1bd981369843f3483947197,"KAFKA-10199: Further refactor task lifecycle management (#12439)

1. Consolidate the task recycle procedure into a single function within the task. The current procedure now becomes: a) task.recycleStateAndConvert, at end of it the task is in closed while its stateManager is retained, and the manager type has been converted; 2) create the new task with old task's fields and the stateManager inside the creators.
2. Move the task execution related metadata into the corresponding TaskExecutionMetadata class, including the task idle related metadata (e.g. successfully processed tasks); reduce the number of params needed for TaskExecutor as well as Tasks.
3. Move the task execution related fields (embedded producer and consumer) and task creators out of Tasks and migrated into TaskManager. Now the Tasks is only a bookkeeping place without any task mutation logic.
4. When adding tests, I realized that we should not add task to state updater right after creation, since it was not initialized yet, while state updater would validate that the task's state is already restoring / running. So I updated that logic while adding unit tests.

Reviewers: Bruno Cadonna <cadonna@apache.org>",2022-07-27 17:29:05,Guozhang Wang,Mixed
0c5f5a7f8b3628e991459ba9cff414c675676b8b,"KAFKA-14007: Close header converters during Connect task shutdown (#12309)

The HeaderConverter interface extends Closeable, but we weren't closing them anywhere before. This change causes header converters to be closed as part of task shutdown.

Reviewers: Kvicii <42023367+Kvicii@users.noreply.github.com>, Chris Egerton <fearthecellos@gmail.com>",2022-07-27 22:31:07,vamossagar12,Mixed
9e74f91e56dbc06f17c95fe80dd3923f7b713457,"KAFKA-14089: Only check for committed seqnos after disabling exactly-once support in Connect integration test (#12429)


Reviewers: Mickael Maison <mickael.maison@gmail.com>  , Tom Bentley <tbentley@redhat.com>",2022-07-28 17:18:09,Chris Egerton,Not TDD
2724cc99203d943c69f1fbddcb7b1ce16f62d287,"KAFKA-10199: Bookkeep tasks during assignment for use with state updater (#12442)

Bookkeeps tasks to be recycled, closed, and updated during handling of the assignment. The bookkeeping is needed for integrating the state updater.

These change is hidden behind internal config STATE_UPDATER_ENABLED. If the config is false Streams should not use the state updater and behave as usual.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2022-07-28 13:28:47,Bruno Cadonna,Mixed
5f7c99dd77fc71982f8664d99bb3ce1b4924d34c,"MINOR: Remove code of removed metric (#12453)

When we removed metric skipped-records in 3.0 we missed to
remove some code related to that metric.

Reviewer: Guozhang Wang <wangguoz@gmail.com>",2022-07-29 16:53:01,Bruno Cadonna,Mixed
54af64c33a1796bcea8a9990aa61c804d9fc0df4,"KAFKA-14108: Ensure both JUnit 4 and JUnit 5 tests run (#12441)

When the migration of the Streams project to JUnit 5 started with PR #12285, we discovered that the migrated tests were not run by the PR builds. This PR ensures that Streams' tests that are written in JUnit 4 and JUnit 5 are run in the PR builds.

Co-authored-by: Divij Vaidya <diviv@amazon.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Bruno Cadonna <cadonna@apache.org>",2022-07-29 17:21:25,Christo Lolov,Not TDD
f26842ca0b564196793ea9f7ca7155314e7bfd35,"MINOR; Use right enum value for broker registration change (#12236)

The code used BrokerRegistrationFencingChange.FENCE when unfencing a broker and used BrokerRegistrationFencingChange.UNFENCE when fencing a broker, this is confusing. This commit flips the values of the two enums and changes their usage at all of the call sites.

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",2022-08-02 05:38:52,dengziming,Mixed
a02c8d336a1370714bc13396e4dad5dbfb237543,"KAFKA-13546: Do not fail connector validation if default topic creation group is explicitly specified (#11615)

Reviewers: Chris Egerton <fearthecellos@gmail.com>",2022-08-02 14:03:57,venkatteki,Mixed
0c4da23098f8b8ae9542acd7fbaa1e5c16384a39,"KAFKA-14129: KRaft must check manual assignments for createTopics are contiguous (#12467)

KRaft should validate that manual assignments given to createTopics are contiguous. In other words,
they must start with partition 0, and progress through 1, 2, 3, etc. ZK mode does this, but KRaft
mode previously did not. Also fix a null pointer exception when the placement for partition 0
was not specified.

Convert over AddPartitionsTest to use KRaft. This PR converts all of the test except for some of
the placement logic tests, which will need to be redone for KRaft mode in a future change.

Fix null pointer exception in KRaftMetadataCache#getPartitionInfo.  Specifically, we should not
assume that the partition will be found in the hash map. This is another case where we had
""Some(x)"" but it should be ""Option(x).""

Fix a potential null pointer exception in BrokerServer#state.

Reviewers: dengziming <dengziming1993@gmail.com>, Jason Gustafson <jason@confluent.io>",2022-08-02 15:39:47,Colin Patrick McCabe,Not TDD
32024593947f8bb497f2f5d392e0d1d892a16ff3,"KAFKA-13877: Fix flakiness in RackAwarenessIntegrationTest (#12468)

In the current test, we check for tag distribution immediately after everyone is on the running state, however due to the fact of the follow-up rebalances, ""everyone is now in running state"" does not mean that the cluster is now stable. In fact, a follow-up rebalance may occur, upon which the local thread metadata would return empty which would cause the distribution verifier to fail.

Reviewers: Divij Vaidya <diviv@amazon.com>, Luke Chen <showuon@gmail.com>",2022-08-03 09:17:38,Guozhang Wang,Not TDD
bfd9e6eccdfdf3a735c866d83ddc3095dabb1274,"KAFKA-14111 Fix sensitive dynamic broker configs in KRaft (#12455)

Enable some of the dynamic broker reconfiguration tests in KRaft mode",2022-08-03 13:28:06,David Arthur,Mixed
add7cd85baa61cd0e1430a0299dc330321126f31,KAFKA-14136 Generate ConfigRecord for brokers even if the value is unchanged (#12483),2022-08-04 15:09:08,David Arthur,Not TDD
555744da7040f1ad91decc3cf2b813285af60aa2,"KAFKA-14124: improve quorum controller fault handling (#12447)

Before trying to commit a batch of records to the __cluster_metadata log, the active controller
should try to apply them to its current in-memory state. If this application process fails, the
active controller process should exit, allowing another node to take leadership. This will prevent
most bad metadata records from ending up in the log and help to surface errors during testing.

Similarly, if the active controller attempts to renounce leadership, and the renunciation process
itself fails, the process should exit. This will help avoid bugs where the active controller
continues in an undefined state.

In contrast, standby controllers that experience metadata application errors should continue on, in
order to avoid a scenario where a bad record brings down the whole controller cluster.  The
intended effect of these changes is to make it harder to commit a bad record to the metadata log,
but to continue to ride out the bad record as well as possible if such a record does get committed.

This PR introduces the FaultHandler interface to implement these concepts. In junit tests, we use a
FaultHandler implementation which does not exit the process. This allows us to avoid terminating
the gradle test runner, which would be very disruptive. It also allows us to ensure that the test
surfaces these exceptions, which we previously were not doing (the mock fault handler stores the
exception).

In addition to the above, this PR fixes a bug where RaftClient#resign was not being called from the
renounce() function. This bug could have resulted in the raft layer not being informed of an active
controller resigning.

Reviewers: David Arthur <mumrah@gmail.com>",2022-08-04 22:49:45,Colin Patrick McCabe,Mixed
48caba934091cb4cf5ec5540357fb018da21aa8d,"KAFKA-14104; Add CRC validation when iterating over Metadata Log Records (#12457)

This commit adds a check to ensure the RecordBatch CRC is valid when
iterating over a Batch of Records using the RecordsIterator. The
RecordsIterator is used by both Snapshot reads and Log Records reads in
Kraft. The check can be turned off by a class parameter and is on by default.

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",2022-08-08 15:03:04,Niket,Mixed
62c2880a584dee52af52d74d7f0ec44475528c72,"KAFKA-14144:; Compare AlterPartition LeaderAndIsr before fencing partition epoch (#12489)

This PR fixes an AlterPartition regression introduced in https://github.com/apache/kafka/pull/12032

When an AlterPartition request succeeds, the partition epoch gets bumped. In Zk controller mode the sender also relies on the AlterPartition response to be informed of the new partition epoch.
If the sender times out the request before a response is sent, the sender will have a stale partition epoch compared to the ZK controller state and will be fenced on subsequent AlterPartition request attempts. The sender will not receive an updated partition epoch until it receives a LeaderAndIsr request for controller-initiated ISR changes.

Reviewers: Jason Gustafson <jason@confluent.io>",2022-08-09 08:55:38,David Mao,Not TDD
e67711af71a3d21e43487933f05406c320646474,"MINOR: BrokerMetadataSnapshotter must avoid exceeding batch size (#12486)

BrokerMetadataSnapshotter should split up record lists that exceed the batch size.

Reviewers: David Arthur <mumrah@gmail.com>",2022-08-09 13:24:24,Colin Patrick McCabe,Mixed
ac64693434a66ad76bfc401a1a89ab2dbeaaeaa8,"KAFKA-14114: Add Metadata Error Related Metrics

This PR adds in 3 metrics as described in KIP-859:
 kafka.server:type=broker-metadata-metrics,name=metadata-load-error-count
 kafka.server:type=broker-metadata-metrics,name=metadata-apply-error-count
 kafka.controller:type=KafkaController,name=MetadataErrorCount

These metrics are incremented by fault handlers when the appropriate fault happens. Broker-side
load errors happen in BrokerMetadataListener. Broker-side apply errors happen in the
BrokerMetadataPublisher. The metric on the controller is incremented when the standby controller
(not active) encounters a metadata error.

In BrokerMetadataPublisher, try to limit the damage caused by an exception by introducing more
catch blocks. The only fatal failures here are those that happen during initialization, when we
initialize the manager objects (these would also be fatal in ZK mode).

In BrokerMetadataListener, try to improve the logging of faults, especially ones that happen when
replaying a snapshot. Try to limit the damage caused by an exception.

Replace MetadataFaultHandler with LoggingFaultHandler, which is more flexible and takes a Runnable
argument. Add LoggingFaultHandlerTest.

Make QuorumControllerMetricsTest stricter. Fix a bug where we weren't cleaning up some metrics from
the yammer registry on close in QuorumControllerMetrics.

Co-author: Colin P. McCabe <cmccabe@apache.org>",2022-08-09 15:22:15,Niket Goel,Mixed
163d00b3e61ac63cb0b65a4d9b23c410ee421c50,"KAFKA-14140: Ensure an offline or in-controlled-shutdown replica is not eligible to join ISR in ZK mode (#12487)

This patch prevents offline or in-controller-shutdown replicas from being added back to the ISR and therefore to become leaders in ZK mode. This is an extra line of defense to ensure that it never happens. This is a continuation of the work done in KIP-841.

Reviewers: David Mao <dmao@confluent.io>, Jason Gustafson <jason@confluent.io>, Jun Rao <jun@confluent.io>, David Jacot <djacot@confluent.io>",2022-08-10 10:25:35,Justine Olshan,Mixed
f17928e4be35d1d22b50aa575697b4c2601a2ea0,"Fix the rate window size calculation for edge cases (#12184)

## Problem
Implementation of connection creation rate quotas in Kafka is dependent on two configurations:
[quota.window.num](https://kafka.apache.org/documentation.html#brokerconfigs_quota.window.num) AND [quota.window.size.seconds](https://kafka.apache.org/documentation.html#brokerconfigs_quota.window.size.seconds)

The minimum possible values of these configuration is 1 as per the documentation. However, when we set 1 as the configuration value, we can hit a situation where rate is calculated as NaN (and hence, leads to exceptions). This specific scenario occurs when an event is recorded at the start of a sample window.

## Solution
This patch fixes this edge case by ensuring that the windowSize over which Rate is calculated is at least 1ms (even if it is calculated at the start of the sample window).

## Test
Added a unit test which fails before the patch and passes after the patch

Reviewers: Ismael Juma <ismael@juma.me.uk>, David Mao <dmao@confluent.io>",2022-08-10 06:25:05,Divij Vaidya,Mixed
9a3a34cab04bd2a7b49ce7b6268ae0dfbc1b0c8e,"KAFKA-13060: Replace EasyMock and PowerMock with Mockito in WorkerGroupMemberTest.java (#12484)

This PR is created on top of #10904 and includes commits from original author for attribution. 

## Testing
1. `./gradlew connect:runtime:unitTest --tests WorkerGroupMemberTest` is successful.
2. Verified that test is run as part of `./gradlew connect:runtime:unitTest` (see report in the PR)

Reviewers: Ismael Juma <ismael@juma.me.uk>

Co-authored-by: Chun-Hao Tang <tang7526@gmail.com>",2022-08-10 06:45:07,Divij Vaidya,Not TDD
24b0ebbac1676c7a90181bfb83b7297fab8729ae,"KAFKA-13986; Brokers should include node.id in fetches to metadata quorum (#12498)

Currently we do not set the replicaId in fetches from brokers to the metadata quorum. It is useful to do so since that allows us to debug replication using the `DescribeQuorum` API.

Reviewers: dengziming <dengziming1993@gmail.com>, José Armando García Sancio <jsancio@users.noreply.github.com>",2022-08-11 14:08:37,Jason Gustafson,Mixed
520f72995ddc5c687e364b83c7ace45f14fdd701,"KAFKA-14154; Return NOT_CONTROLLER from AlterPartition if leader is ahead of controller (#12506)

It is possible for the leader to send an `AlterPartition` request to a zombie controller which includes either a partition or leader epoch which is larger than what is found in the controller context. Prior to https://github.com/apache/kafka/pull/12032, the controller handled this in the following way:

1. If the `LeaderAndIsr` state exactly matches the current state on the controller excluding the partition epoch, then the `AlterPartition` request is considered successful and no error is returned. The risk with this handling is that this may cause the leader to incorrectly assume that the state had been successfully updated. Since the controller's state is stale, there is no way to know what the latest ISR state is.
2. Otherwise, the controller will attempt to update the state in zookeeper with the leader/partition epochs from the `AlterPartition` request. This operation would fail if the controller's epoch was not still current in Zookeeper and the result would be a `NOT_CONTROLLER` error.

Following https://github.com/apache/kafka/pull/12032, the controller's validation is stricter. If the partition epoch is larger than expected, then the controller will return `INVALID_UPDATE_VERSION` without attempting the operation. Similarly, if the leader epoch is larger than expected, the controller will return `FENCED_LEADER_EPOCH`. The problem with this new handling is that the leader treats the errors from the controller as authoritative. For example, if it sees the `FENCED_LEADER_EPOCH` error, then it will not retry the request and will simply wait until the next leader epoch arrives. The ISR state gets suck in a pending state, which can lead to persistent URPs until the leader epoch gets bumped.

In this patch, we want to fix the issues with this handling, but we don't want to restore the buggy idempotent check. The approach is straightforward. If the controller sees a partition/leader epoch which is larger than what it has in the controller context, then it assumes that has become a zombie and returns `NOT_CONTROLLER` to the leader. This will cause the leader to attempt to reset the controller from its local metadata cache and retry the `AlterPartition` request.

Reviewers: David Jacot <djacot@confluent.io>, José Armando García Sancio <jsancio@users.noreply.github.com>",2022-08-11 16:43:12,Jason Gustafson,Not TDD
4a3e92b1abb562a27b6a461b3dfedde2d15fd3b2,"KAFKA-10199: Expose read only task from state updater (#12497)

The state updater exposes tasks that are in restoration
to the stream thread. To ensure that the stream thread
only accesses the tasks to read from the tasks without
modifying any internal state, this PR introduces a
read-only task that throws an exception if the caller
tries to modify the internal state of a task.

This PR also returns read-only tasks from
DefaultStateUpdater#getTasks().

Reviewer: Guozhang Wang <wangguoz@gmail.com>",2022-08-12 17:03:50,Bruno Cadonna,Mixed
50e5b32a6d5f7940e932c6acb20a452535c0bf60,"KAFKA-13959: Controller should unfence Broker with busy metadata log (#12274)

The reason for KAFKA-13959 is a little complex, the two keys to this problem are:

KafkaRaftClient.MAX_FETCH_WAIT_MS==MetadataMaxIdleIntervalMs == 500ms. We rely on fetchPurgatory to complete a FetchRequest, in details, if FetchRequest.fetchOffset >= log.endOffset, we will wait for 500ms to send a FetchResponse. The follower needs to send one more FetchRequest to get the HW.

Here are the event sequences:

1. When starting the leader(active controller) LEO=m+1(m is the offset of the last record), leader HW=m(because we need more than half of the voters to reach m+1)
2. Follower (standby controller) and observer (broker) send FetchRequest(fetchOffset=m)
    2.1. leader receives FetchRequest, set leader HW=m and waits 500ms before send FetchResponse
    2.2. leader send FetchResponse(HW=m)
    3.3 broker receive FetchResponse(HW=m), set metadataOffset=m.
3. Leader append NoOpRecord, LEO=m+2. leader HW=m
4. Looping 1-4

If we change MAX_FETCH_WAIT_MS=200 (less than half of MetadataMaxIdleIntervalMs), this problem can be solved temporarily.

We plan to improve this problem in 2 ways, firstly, in this PR, we change the controller to unfence a broker when the broker's high-watermark has reached the broker registration record for that broker. Secondly, we will propagate the HWM to the replicas as quickly as possible in KAFKA-14145.

Reviewers: Luke Chen <showuon@gmail.com>, José Armando García Sancio <jsancio@users.noreply.github.com>",2022-08-12 09:06:24,dengziming,Mixed
d529d86aa4be533d1251cfc0b4c0fb57c69ace72,"KAFKA-13559: Fix issue where responses intermittently takes 300+ ms to respond, even when the server is idle. (#12416)

Ensures that SSL buffered data is processed by server immediately on the next poll when channel is unmuted after processing previous request. Poll timeout is reset to zero for this case to avoid 300ms delay in poll() if no new data arrives on the sockets.

Reviewers: David Mao <dmao@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>",2022-08-15 12:34:03,Badai Aqrandista,Not TDD
3154714548174fd2b037de293c143f3c3db9f7db,"MINOR: Appending value to LIST config should not generate empty string with … (#12503)

Reviewers: dengziming <dengziming1993@gmail.com>, Luke Chen <showuon@gmail.com>",2022-08-16 02:05:28,Chia-Ping Tsai,Not TDD
5990471b8ca0dc275c9a8ff0cde2a6562ee8199e,"KAFKA-14154; Kraft controller should return NOT_CONTROLLER if request epoch is ahead (#12514)

Similar to https://github.com/apache/kafka/pull/12506. For the Kraft controller, we should return NOT_CONTROLLER if the leader/partition epoch in the request is ahead of the controller. 

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",2022-08-15 11:34:29,Jason Gustafson,Mixed
18142bff4b313e0bfb9d26c70a5b4b469cbc4005,"KAFKA-13809: Propagate full connector configuration to tasks in FileStream connectors (#12450)

Reviewers: Chris Egerton <fearthecellos@gmail.com>",2022-08-15 15:25:29,Yash Mayya,Mixed
dc72f6ec02c7a7fbda083cd8a5a9f0081c7e58fd,"KAFKA-10199: Handle task closure and recycling from state updater (#12466)

1. Within the tryCompleteRestore function of the thread, try to drain the removed tasks from state updater and handle accordingly: 1) for recycle, 2) for closure, 3) for update input partitions.
2. Catch up on some unit test coverage from previous PRs.
3. Some minor cleanups around exception handling.

Reviewers: Bruno Cadonna <cadonna@apache.org>",2022-08-15 19:33:46,Guozhang Wang,Mixed
9f20f8995399d9e03f518f7b9c8be2bffb2fdcfc,"KAFKA-10199: Remove tasks from state updater on partition lost (#12521)

Removes tasks from the state updater when the input partitions of the tasks are lost during a rebalance.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2022-08-17 11:12:30,Bruno Cadonna,Mixed
b47c4d859805068de6a8fe8de3bda5e7a21132e2,"KAFKA-10199: Remove tasks from state updater on revocation (#12520)

Removes tasks from the state updater when the input partitions of the tasks are revoked during a rebalance.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2022-08-17 11:13:34,Bruno Cadonna,Mixed
0243bb98a7cc6bc4ed3c8f39b3a1ed9f70d0f8bd,"HOTFIX: Revert KAFKA-10199 which is causing compilation failures (#12532)

Compilation is failing after these two commits:
```
> Task :streams:compileJava
/Users/jgustafson/Projects/kafka/streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java:852: error: cannot find symbol
                        tasks.addPendingTaskToClose(restoringTask.id());
                             ^
  symbol:   method addPendingTaskToClose(org.apache.kafka.streams.processor.TaskId)
  location: variable tasks of type org.apache.kafka.streams.processor.internals.Tasks
1 error
```

Also here:
```

[2022-08-17T20:58:20.912Z] > Task :streams:compileTestJava

[2022-08-17T20:58:20.912Z] /home/jenkins/jenkins-agent/workspace/Kafka_kafka-pr_PR-12530/streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java:822: error: method setupForRevocation(Set<Task>,Set<Task>) is already defined in class TaskManagerTest

[2022-08-17T20:58:20.912Z]     private TaskManager setupForRevocation(final Set<Task> tasksInStateUpdater,
```
 This patch reverts them.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2022-08-17 14:29:49,Jason Gustafson,Mixed
e5b865d6bf37495e9949878c8206b9459aa5e1f4,"KAFKA-13940; Return NOT_LEADER_OR_FOLLOWER if DescribeQuorum sent to non-leader (#12517)

Currently the server will return `INVALID_REQUEST` if a `DescribeQuorum` request is sent to a node that is not the current leader. In addition to being inconsistent with all of the other leader APIs in the raft layer, this error is treated as fatal by both the forwarding manager and the admin client. Instead, we should return `NOT_LEADER_OR_FOLLOWER` as we do with the other APIs. This error is retriable and we can rely on the admin client to retry it after seeing this error.

Reviewers: David Jacot <djacot@confluent.io>",2022-08-17 15:48:32,Jason Gustafson,Mixed
bc90c29fafc69747daeecada8bb0c347e138edc8,"KAFKA-14167; Completion exceptions should not be translated directly to error codes (#12518)

There are a few cases in `ControllerApis` where we may see an `ApiException` wrapped as a `CompletionException`. This can happen in `QuorumController.allocateProducerIds` where the returned future is the result of calling `thenApply` on the future passed to the controller. The danger when this happens is that the `CompletionException` gets passed to `Errors.forException`, which translates it to an `UNKNOWN_SERVER_ERROR`. At a minimum, I found that the `AllocateProducerIds` and `UpdateFeatures` APIs were affected by this bug, but it is difficult to root out all cases. 

Interestingly, `DeleteTopics` is not affected by this bug as I originally suspected. This is because we have logic in `ApiError.fromThrowable` to check for both `CompletionException` and `ExecutionException` and to pull out the underlying cause. This patch duplicates this logic from `ApiError.fromThrowable` into `Errors.forException` to be sure that we handle all cases where exceptions are converted to error codes.

Reviewers: David Arthur <mumrah@gmail.com>",2022-08-17 18:11:42,Jason Gustafson,Mixed
73e8d5dd5b2344a2c494cef59929b8e187fa68ec,"MINOR: Remove unused ShutdownableThread class and ineffective ThreadedTest class (#12410)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Christo Lolov <christo_lolov@yahoo.com>",2022-08-18 12:08:03,Chris Egerton,Mixed
5c77c544c6c448f615db5852fe29e4806ab7700e,"KAFKA-13769 Fix version check in SubscriptionStoreReceiveProcessorSupplier (#12535)

This patch fixes another incorrect version check in the FK code and adds unit tests that would have caught this bug.

Reviewers: John Roesler <vvcephei@apache.org>",2022-08-18 13:20:04,Alex Sorokoumov,Mixed
5f4af5f7d170fb71eec7e117858056870fc7e6fe,"KAFKA-14170: Fix NPE in the deleteTopics() code path of KRaft Controller (#12533)

Fix a bug in ReplicationControlManager where we got a NullPointerException when removing a topic
with no offline replicas, and there were other topics that did have offline replicas.

Fix an issue in MetadataDelta#replay where we were replaying RemoveTopicRecord twice.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, dengziming <dengziming1993@gmail.com>",2022-08-18 17:14:17,Akhilesh C,Not TDD
a724166fcc9d260df4a9f05357d96535da7c1627,"MINOR: Fix unexpected request error in kraft shutdown (#12538)

We have been seeing a few exceptions like the following when running integration tests:
```
[2022-08-18 13:02:59,470] ERROR [ControllerApis nodeId=3000] Unexpected error handling request RequestHeader(apiKey=FETCH, apiVersion=13, clientId=raft-client-0, correlationId=7) -- FetchRequestData(clusterId='txpo87ZUSbGSeV2v7H0n_w', replicaId=0, maxWaitMs=500, minBytes=0, maxBytes=8388608, isolationLevel=0, sessionId=0, sessionEpoch=-1, topics=[FetchTopic(topic='__cluster_metadata', topicId=AAAAAAAAAAAAAAAAAAAAAQ, partitions=[FetchPartition(partition=0, currentLeaderEpoch=1, fetchOffset=6, lastFetchedEpoch=1, logStartOffset=-1, partitionMaxBytes=0)])], forgottenTopicsData=[], rackId='') with context RequestContext(header=RequestHeader(apiKey=FETCH, apiVersion=13, clientId=raft-client-0, correlationId=7), connectionId='127.0.0.1:63113-127.0.0.1:63114-0', clientAddress=/127.0.0.1, principal=User:ANONYMOUS, listenerName=ListenerName(CONTROLLER), securityProtocol=PLAINTEXT, clientInformation=ClientInformation(softwareName=apache-kafka-java, softwareVersion=unknown), fromPrivilegedListener=false, principalSerde=Optional[org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder@201038c3]) (kafka.server.ControllerApis:76)
java.util.concurrent.CompletionException: java.util.NoSuchElementException: key not found: BROKER_NOT_AVAILABLE
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:315)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:320)
	at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:936)
	at java.base/java.util.concurrent.CompletableFuture$UniHandle.tryFire(CompletableFuture.java:911)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)
	at java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2147)
	at org.apache.kafka.raft.KafkaRaftClient.lambda$handleRequest$19(KafkaRaftClient.java:1666)
	at java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:863)
	at java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:841)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2162)
	at kafka.raft.TimingWheelExpirationService$TimerTaskCompletableFuture.run(TimingWheelExpirationService.scala:32)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.NoSuchElementException: key not found: BROKER_NOT_AVAILABLE
```
There are two causes for this error that I found. First, we were not shutting down the timer services in `RaftManager` which are used in the purgatory implementation. This meant that operations remaining in purgatory could be completed even after `RaftManager` was shutdown. Second, the shutdown order in `KafkaClusterTestKit` was problematic. The `RaftManager` instance depends on the `SocketServer` in `ControllerServer`, but it was the latter that was shutdown first. Instead, we should shutdown `RaftManager` first as we do in `KafkaRaftServer`. 

Reviewers: Ismael Juma <ismael@juma.me.uk>",2022-08-19 12:45:05,Jason Gustafson,Not TDD
c7f051914e5d20e137901b6d687d6e7cf8775df1,"KAFKA-13888; Implement `LastFetchTimestamp` and  in `LastCaughtUpTimestamp` for DescribeQuorumResponse [KIP-836] (#12508)

This commit implements the newly added fields `LastFetchTimestamp` and `LastCaughtUpTimestamp` for KIP-836: https://cwiki.apache.org/confluence/display/KAFKA/KIP-836:+Addition+of+Information+in+DescribeQuorumResponse+about+Voter+Lag.

Reviewers: Jason Gustafson <jason@confluent.io>",2022-08-19 15:09:09,Niket,Mixed
150fd5b0b18c4761d8f7d7ba9a480aa9f622024f,"KAFKA-13914: Add command line tool kafka-metadata-quorum.sh (#12469)

 Add `MetadataQuorumCommand` to describe quorum status, I'm trying to use arg4j style command format, currently, we only support one sub-command which is ""describe"" and we can specify 2 arguments which are --status and --replication.

```
# describe quorum status
kafka-metadata-quorum.sh --bootstrap-server localhost:9092 describe --replication

ReplicaId	LogEndOffset	Lag	LastFetchTimeMs	LastCaughtUpTimeMs	Status  	
0        	10          	        0  	-1             	        -1                	                 Leader  	
1        	10          	        0  	-1             	        -1                	                 Follower	
2        	10          	        0  	-1             	        -1                	                 Follower	

kafka-metadata-quorum.sh --bootstrap-server localhost:9092 describe --status
ClusterId:                             fMCL8kv1SWm87L_Md-I2hg
LeaderId:                             3002
LeaderEpoch:                      2
HighWatermark:                  10
MaxFollowerLag:                 0
MaxFollowerLagTimeMs:   -1
CurrentVoters:                    [3000,3001,3002]
CurrentObservers:              [0,1,2]

# specify AdminClient properties
kafka-metadata-quorum.sh --bootstrap-server localhost:9092 --command-config config.properties describe --status
```

Reviewers: Jason Gustafson <jason@confluent.io>",2022-08-20 08:37:26,dengziming,Mixed
b392cf212f7ed4a82b79c3690b488619c027dba9,"KAFKA-14097: Separate configuration for producer ID expiry (KIP-854) (#12501)

This patch implements ""KIP-854: Separate configuration for producer ID expiry"" as described here: https://cwiki.apache.org/confluence/display/KAFKA/KIP-854+Separate+configuration+for+producer+ID+expiry.

Reviewers: David Jacot <djacot@confluent.io>",2022-08-22 10:56:05,Justine Olshan,Mixed
519d8ac5b97bce1914eb302882fe6bdddaba4ea5,"KAFKA-14147: Prevent deferredTaskUpdates map from growing monotonically in KafkaConfigBackingStore (#12490)

Reviewers: Chris Egerton <fearthecellos@gmail.com>",2022-08-22 10:13:43,Yash Mayya,Mixed
ddb7fdd88fbb559d858866f8674a670273405f72,"KAFKA-14133: Replace EasyMock with Mockito in WorkerCoordinatorTest and RootResourceTest (#12509)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Dalibor Plavcic <dalibor.os@proton.me>",2022-08-22 20:17:34,Yash Mayya,Mixed
add4ca6c7f1b289477aa7d6e918f5d22b78088fe,"KAFKA-10199: Remove tasks from state updater on revoked and lost partitions (#12547)

Removes tasks from the state updater when the input partitions of the tasks are revoked or partitions are lost during a rebalance.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2022-08-22 11:50:50,Bruno Cadonna,Mixed
9aef9921184d4f8fbf2e7af4875ca922173e2a8d,"MINOR: Catch InvocationTargetException explicitly and propagate underlying cause (#12230)

Catch InvocationTargetException explicitly and propagate underlying cause

Reviewers: Ismael Juma <mlists@juma.me.uk>, Matthew de Detrich <mdedetrich@gmail.com>, Kvicii, Luke Chen <showuon@gmail.com>",2022-08-23 17:34:39,Divij Vaidya,Not TDD
6df57679d01c9716738dd0decfeeb26eeece09a5,"KAFKA-14162: Stop adding immutable maps/lists to record keys/values in HoistField and MaskField SMTs (#12502)

Reviewers:  Sagar Rao <sagarmeansocean@gmail.com>, Chris Egerton <fearthecellos@gmail.com>",2022-08-23 10:22:02,Yash Mayya,Mixed
4bd3fd840d0a6d61d20f17c4ed6b53b09ec21cf1,"KAFKA-14160: Streamline clusterId retrieval in Connect (#12536)

Cache the Kafka cluster Id once it has been retrieved to avoid creating many Admin clients at startup.

Reviewers: Chris Egerton <fearthecellos@gmail.com>",2022-08-23 17:09:22,Mickael Maison,Mixed
4b310d1fe171d6d5edda13bb1baf2cf5a0d8eb68,"KAFKA-13133: Replace EasyMock and PowerMock with Mockito for AbstractHerderTest (#12473)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Yash Mayya <yash.mayya@gmail.com>

Co-authored-by: wycccccc <493172422@qq.com>
Co-authored-by: wycccccc <43372856+wycccccc@users.noreply.github.com>",2022-08-23 17:49:38,Divij Vaidya,Not TDD
f191126550f155c50069a75a82fd44923997642a,"KAFKA-10199: Introduce task registry (#12549)

Currently the task manager stores the tasks it manages in an
internally. We recently extracted the code to store and retrieve
tasks into its own class Tasks. However, the task manager creates
the Tasks object internally and during testing of the task
manager we do not have access to it which makes testing the task
manager quite complex.

This commit externalizes the data structure that the task manager
uses to store and rerieve tasks. It introduces the TasksRegistry
interface and lets the Tasks object implementing TasksRegistry.
The Tasks object is passed into the task manager via its
constructor. Passing the TasksRegistry dependency to the task
manager from outside faciliates simpler testing of the task
manager.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Walker Carlson <wcarlson@confluent.io>",2022-08-24 08:19:40,Bruno Cadonna,Mixed
4170e742956699aa15c4a9deb411b33994e6142e,"MINOR: Use underscore for variable initialization in Scala sources (#12534)

In Scala it's standard practice to use `_` whenever you are initializing variables. In regard to implementation, for object references, `_` initialization maps to `null` so there is no change in behavior.

Reviewers: Mickael Maison <mickael.maison@gmail.com>",2022-08-24 15:07:13,Matthew de Detrich,Mixed
0507597597e1d2d9adaa33b87e5ea509e12fd2f0,"KAFKA-10360: Allow disabling JMX Reporter (KIP-830) (#12046)

This implements KIP-830: https://cwiki.apache.org/confluence/display/KAFKA/KIP-830%3A+Allow+disabling+JMX+Reporter
It adds a new configuration `auto.include.jmx.reporter` that can be set to false to disable the JMX Reporter. This configuration is deprecated and will be removed in the next major version.

Reviewers: Tom Bentley <tbentley@redhat.com>, Christo Lolov <christo_lolov@yahoo.com>",2022-08-24 18:30:31,Mickael Maison,Mixed
5c52c61a46f103cda7fa48bd96584dafe984d6d3,"MINOR: A few cleanups for DescribeQuorum APIs (#12548)

A few small cleanups in the `DescribeQuorum` API and handling logic:

- Change field types in `QuorumInfo`:
  - `leaderId`: `Integer` -> `int`
  - `leaderEpoch`: `Integer` -> `long` (to allow for type expansion in the future)
  - `highWatermark`: `Long` -> `long`
- Use field names `lastFetchTimestamp` and `lastCaughtUpTimestamp` consistently
- Move construction of `DescribeQuorumResponseData.PartitionData` into `LeaderState`
- Consolidate fetch time/offset update logic into `LeaderState.ReplicaState.updateFollowerState`

Reviewers: Luke Chen <showuon@gmail.com>, José Armando García Sancio <jsancio@users.noreply.github.com>",2022-08-24 13:12:14,Jason Gustafson,Mixed
19581effbf9265db318f855cc37f6b0526c1b544,"KAFKA-13850: Show missing record type in MetadataShell (#12103)

AccessControlEntryRecord and RemoveAccessControlEntryRecord are added in KIP-801, FeatureLevelRecord was added in KIP-778, and BrokerRegistrationChangeRecord was added in KIP-841, and NoOpRecord was added in KIP-835, I added these 5 record types in MetadataShell.

 Reviewers: Luke Chen <showuon@gmail.com>",2022-08-25 14:09:01,dengziming,Mixed
f0f918b242e223d9329ae61be8bf12894ba23d77,"KAFKA-14177: Correctly support older kraft versions without FeatureLevelRecord (#12513)

The main changes here are ensuring that we always have a metadata.version record in the log, making
˘sure that the bootstrap file can be used for records other than the metadata.version record (for
example, we will want to put SCRAM initialization records there), and fixing some bugs.

If no feature level record is in the log and the IBP is less than 3.3IV0, then we assume the minimum KRaft
version for all records in the log.

Fix some issues related to initializing new clusters. If there are no records in the log at all,
then insert the bootstrap records in a single batch. If there are records, but no metadata version,
process the existing records as though they were metadata.version 3.3IV0 and then append a metadata
version record setting version 3.3IV0.  Previously, we were not clearly distinguishing between the
case where the metadata log was empty, and the case where we just needed to add a metadata.version
record.

Refactor BootstrapMetadata into an immutable class which contains a 3-tuple of metadata version,
record list, and source. The source field is used to log where the bootstrap metadata was obtained
from. This could be a bootstrap file, the static configuration, or just the software defaults.
Move the logic for reading and writing bootstrap files into BootstrapDirectory.java.

Add LogReplayTracker, which tracks whether the log is empty.

Fix a bug in FeatureControlManager where it was possible to use a ""downgrade"" operation to
transition to a newer version. Do not store whether we have seen a metadata version or not in
FeatureControlManager, since that is now handled by LogReplayTracker.

Introduce BatchFileReader, which is a simple way of reading a file containing batches of snapshots
that does not require spawning a thread. Rename SnapshotFileWriter to BatchFileWriter to be
consistent, and to reflect the fact that bootstrap files aren't snapshots.

QuorumController#processBrokerHeartbeat: add an explanatory comment.

Reviewers: David Arthur <mumrah@gmail.com>, Jason Gustafson <jason@confluent.io>",2022-08-25 18:12:31,Colin Patrick McCabe,Mixed
6144843234b29ab1f2b76ae95ffa8d1020a24ac9,"MINOR: Fix config name and remove hard coded values (#12564)

Fix config name and remove hard coded values

Reviewers: Luke Chen <showuon@gmail.com>",2022-08-27 15:36:33,Justine Olshan,Not TDD
f83c6f2da4dd1553ac581aa56ce6f179c799773a,"KAFKA-14183; Cluster metadata bootstrap file should use header/footer (#12565)

The boostrap.checkpoint files should include a control record batch for
the SnapshotHeaderRecord at the start of the file. It should also
include a control record batch for the SnapshotFooterRecord at the end
of the file.

The snapshot header record is important because it versions the rest of
the bootstrap file.

Reviewers: David Arthur <mumrah@gmail.com>",2022-08-27 19:11:06,José Armando García Sancio,Mixed
d606eb46ef8ee24e1eb06ff2bb27ae44d1f19eaa,"MINOR: Small javadoc/code cleanups in connect api and transforms (#12558)


Reviewers: Luke Chen <showuon@gmail.com>, Divij Vaidya <diviv@amazon.com>",2022-08-29 09:44:56,Mickael Maison,Not TDD
14b1db35e5eb40d281907d1157e7b907be2e0675,"MINOR: Small code cleanups in GroupCoordinator (#12563)

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Luke Chen <showuon@gmail.com>",2022-08-29 11:37:24,David Jacot,Mixed
0e6a3fa97893d3c78fc871de6307c0e0f0faa776,"KAFKA-10199: Handle restored tasks output by state updater (#12554)

Once the state updater restored an active task it puts it
into an output queue. The stream thread reads the restored
active task from the output queue and after it verified
that the task is still owned by the stream thread it transits
it to RUNNING.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Walker Carlson <wcarlson@confluent.io>",2022-08-29 18:26:02,Bruno Cadonna,Mixed
7b07b2676bfb47d340ccb1f13ac54204752ce980,"KAFKA-10199: Remove tasks from state updater on shutdown (#12562)

The state updater removes its updating and paused task on shutdown.
The removed tasks are added to the output queue for removed tasks.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Walker Carlson <wcarlson@confluent.io>",2022-08-29 18:29:21,Bruno Cadonna,Mixed
7fb178aad778870b2e5f5c49e2f3634b5483a356,"MINOR: Displaying default entity name in MetadataShell (#12053)

When debugging some bugs related to configs, I find we are unable to show default broker/topic entity name since the resourceName="""". Changed it to similar to how we trait default client quotas.

Reviewers: Luke Chen <showuon@gmail.com>",2022-08-30 11:28:49,dengziming,Mixed
28d5a059438634db6fdecdbb816e2584715884d6,"KAFKA-14187: kafka-features.sh: add support for --metadata (#12571)

This PR adds support to kafka-features.sh for the --metadata flag, as specified in KIP-778.  This
flag makes it possible to upgrade to a new metadata version without consulting a table mapping
version names to short integers. Change --feature to use a key=value format.

FeatureCommandTest.scala: make most tests here true unit tests (that don't start brokers) in order
to improve test run time, and allow us to test more cases. For the integration test part, test both
KRaft and ZK-based clusters. Add support for mocking feature operations in MockAdminClient.java.

upgrade.html: add a section describing how the metadata.version should be upgraded in KRaft
clusters.

Add kraft_upgrade_test.py to test upgrades between KRaft versions.

Reviewers: David Arthur <mumrah@gmail.com>, dengziming <dengziming1993@gmail.com>, José Armando García Sancio <jsancio@gmail.com>",2022-08-30 16:56:03,Colin Patrick McCabe,Mixed
9e71d818d6d90dc427a1f30979192991c570e041,"KAFKA-13990: KRaft controller should return right features in ApiVersionResponse (#12294)

Previously, the KRaft controller was incorrectly reporting an empty feature set in
ApiVersionResponse. This was preventing any multi-node clusters from being upgraded via
kafka-features.sh, since they would incorrectly believe that metadata.version was not a supported
feature. This PR adds a regression test for this bug, KRaftClusterTest.testUpdateMetadataVersion.

Reviewers: José Armando García Sancio <jsancio@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",2022-08-31 11:35:58,dengziming,Not TDD
bc8f7d07d9c544536dc24391bf5dbf170905733f,"KAFKA-10199: Shutdown state updater on task manager shutdown (#12569)

When the task manager is shutdown, the state updater should also
shutdown. After the shutdown of the state updater, the tasks
in its output queues should be closed.

Reviewer: Guozhang Wang <wangguoz@gmail.com>",2022-08-31 20:45:53,Bruno Cadonna,Mixed
2bef80e3604e9a50660d423daaf8e66dd7c4e989,"KAFKA-10199: Remove changelog unregister from state updater (#12573)

Changelogs are already unregistered when tasks are closed.
There is no need to also unregister them in the state
updater.

In future, when we will only have the state updater without
the old code path, we should consider registering and
unregistering the changelogs within the state updater.

Reviewer: Guozhang Wang <wangguoz@gmail.com>",2022-09-01 14:29:39,Bruno Cadonna,Mixed
ef65b6e566ef69b2f9b58038c98a5993563d7a68,"KAFKA-14195: Fix KRaft AlterConfig policy usage for Legacy/Full case (#12578)

#12374 adjusted the invocation of the alter configs policy check in KRaft to match the behavior in ZooKeeper, which is to only provide the configs that were explicitly sent in the request. While the code was correct for the incremental alter configs case, the code actually included the implicit deletions for the legacy/non-incremental alter configs case, and those implicit deletions are not included in the ZooKeeper-based invocation. This patch adds a test to check for this and adjusts ConfigurationControlManager code so that the test passes -- the adjusted test is confirmed to fail locally otherwise. We also add a log statement to emit any unexpected stack traces in the alter config code path.

Reviewers: José Armando García Sancio <jsancio@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",2022-09-01 15:59:17,Ron Dagostino,Mixed
7ec10ce19a1c5869a4713f9c9b6b12da5c63e42b,"HOTFIX: fix PriorityQueue iteration to assign warmups in priority order (#12585)

Based on a patch submitted to the confluentinc fork & then abandoned. Needed some updates and minor expansion but more or less just re-applied the changes proposed in confluentinc#697.

Original PR has a very detailed justification for these changes but the tl;dr of it is that apparently the PriorityQueue's iterator does not actually guarantee to return elements in priority order.

Reviewer: Luke Chen <showuon@gmail.com>",2022-09-02 18:14:34,A. Sophie Blee-Goldman,Mixed
8380d2edf48d3e97ebf0c2312a8127960232b947,"KAFKA-10199: Handle exceptions from state updater (#12519)

1. In state updater, when handling task corrupted exception due to invalid restoring offset, first delete the affected partitions from the checkpoint before reporting it back to the stream thread. This is to mimic the same behavior in stream threads's StateManager#handleCorruption#closeDirtyAndRevive. It's cleaner to do so inside the restore thread, plus it enables us to optimize by only deleting those corrupted partitions, and not all.
2. In the state manager, handle the drained exceptions as follows (this is the same as handling all exceptions from handleAssignment): 1) Task-migrated, throw all the way to stream-thread as handleTaskMigrated, 2) any fatal Streams exception, throw all the way to stream-thread to trigger exception handler, 3) Task-corrupted, throw to the stream-thread as handleCorruption. Note that for 3), we would specially distinguish if the corrupted-tasks are already closed (when they are thrown from handleAssignment or not (when they are thrown from the state updater).

Reviewers: Bruno Cadonna <cadonna@apache.org>",2022-09-02 17:50:23,Guozhang Wang,Mixed
0cbf74a940c445947bb8b7456d1f829b9736a9f7,"KAFKA-14194: Fix NPE in Cluster.nodeIfOnline (#12584)

When utilizing the rack-aware consumer configuration and rolling updates are being applied to the Kafka brokers the metadata updates can be in a transient state and a given topic-partition can be missing from the metadata. This seems to resolve itself after a bit of time but before it can resolve the `Cluster.nodeIfOnline` method throws an NPE. This patch checks to make sure that a given topic-partition has partition info available before using that partition info.

Reviewers: David Jacot <djacot@confluent.io>",2022-09-05 09:56:23,Andrew Dean,Not TDD
c3595588269282ba7d90df990b5544f3f16dd304,"KAFKA-14015: Reconfigure tasks if configs have been changed for restarted connectors in standalone mode(#12568)

Reviewers: Chris Egerton <chrise@aiven.io>",2022-09-06 09:05:21,Yash Mayya,Mixed
44b500b6795c4eb9f77362e25baee60fd83e5ce4,"KAFKA-10199: Separate state updater from old restore (#12583)

Separates the code path for the new state updater from
the code path of the old restoration.

Ensures that with the state updater tasks are processed
before all tasks are running.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Walker Carlson <wcarlson@confluent.io",2022-09-07 14:21:36,Bruno Cadonna,Mixed
9578cdabfdb60266349767db8b2c4b7944141c47,"KAFKA-14200: kafka-features.sh must exit with non-zero error code on error (#12586)

kafka-features.sh must exit with a non-zero error code on error. We must do this in order to catch
regressions like KAFKA-13990.

Reviewers: David Arthur <mumrah@gmail.com>",2022-09-07 09:03:55,Colin Patrick McCabe,Mixed
0c97be53fa7e1e0720f2086b5d9d80ffcc1db470,"KAFKA-13952 fix RetryWithToleranceOperator to respect infinite retries configuration (#12478)

Reviewers: Chris Egerton <chrise@aiven.io>",2022-09-08 10:14:04,Yash Mayya,Mixed
897bf4741caaaca1b3e33404d5246bc35e07bb24,"KAFKA-14143: Exactly-once source connector system tests (#11783)

Also includes a minor quality-of-life improvement to clarify why some internal REST requests to workers may fail while that worker is still starting up.

Reviewers: Tom Bentley <tbentley@redhat.com>, Luke Chen <showuon@gmail.com>, José Armando García Sancio <jsancio@gmail.com>, Mickael Maison <mickael.maison@gmail.com>",2022-09-08 15:13:43,Chris Egerton,Mixed
81b71c06f300daf353cef04653d59385db561b38,"KAFKA-14204: QuorumController must correctly handle overly large batches (#12595)

Originally, the QuorumController did not try to limit the number of records in a batch that it sent
to the Raft layer.  This caused two problems. Firstly, we were not correctly handling the exception
that was thrown by the Raft layer when a batch of records was too large to apply atomically. This
happened because the Raft layer threw an exception which was a subclass of ApiException. Secondly,
by letting the Raft layer split non-atomic batches, we were not able to create snapshots at each of
the splits. This led to O(N) behavior during controller failovers.

This PR fixes both of these issues by limiting the number of records in a batch. Atomic batches
that are too large will fail with a RuntimeException which will cause the active controller to
become inactive and revert to the last committed state. Non-atomic batches will be split into
multiple batches with a fixed number of records in each.

Reviewers: Luke Chen <showuon@gmail.com>, José Armando García Sancio <jsancio@gmail.com>",2022-09-08 14:21:29,Colin Patrick McCabe,Mixed
706adc39f6aff378f98000b0466181d7fcb1d997,"KAFKA-14201; Consumer should not send group instance ID if committing with empty member ID (server side) (#12598)

The consumer group instance ID is used to support a notion of ""static"" consumer groups. The idea is to be able to identify the same group instance across restarts so that a rebalance is not needed. However, if the user sets `group.instance.id` in the consumer configuration, but uses ""simple"" assignment with `assign()`, then the instance ID nevertheless is sent in the OffsetCommit request to the coordinator. This may result in a surprising UNKNOWN_MEMBER_ID error.

This PR attempts to fix this issue for existing consumers by relaxing the validation in this case. One way is to simply ignore the member id and the static id when the generation id is -1. -1 signals that the request comes from either the admin client or a consumer which does not use the group management. This does not apply to transactional offsets commit.

Reviewers: Jason Gustafson <jason@confluent.io>",2022-09-08 14:35:59,David Jacot,Mixed
b7f20be809c47202ace4b54e69be5428012df1a9,"KAFKA-14201; Consumer should not send group instance ID if committing with empty member ID (#12599)

The consumer group instance ID is used to support a notion of ""static"" consumer groups. The idea is to be able to identify the same group instance across restarts so that a rebalance is not needed. However, if the user sets `group.instance.id` in the consumer configuration, but uses ""simple"" assignment with `assign()`, then the instance ID nevertheless is sent in the OffsetCommit request to the coordinator. This may result in a surprising UNKNOWN_MEMBER_ID error.

This PR fixes the issue on the client side by not setting the group instance id if the member id is empty (no generation).

Reviewers: Jason Gustafson <jason@confluent.io>",2022-09-08 15:05:40,David Jacot,Mixed
e138772ba54d834ab02f95dcb161f92fb5e941e9,"MINOR: Update Scalafmt to latest version (#12475)

Reviewers: Divij Vaidya <diviv@amazon.com>, Chris Egerton <fearthecellos@gmail.com>",2022-09-12 10:05:15,Matthew de Detrich,Mixed
d2a2d448a950aabf0034bf24785169e1df42e8ac,KAFKA-14203 Disable snapshot generation on broker after metadata errors (#12596),2022-09-12 17:40:29,David Arthur,Mixed
d4fc3186b400cced20076a6d21fb6cdaa1d64e05,"MINOR: Replace usage of File.createTempFile() with TestUtils.tempFile() (#12591)

Why
Current set of integration tests leak files in the /tmp directory which makes it cumbersome if you don't restart the machine often.

Fix
Replace the usage of File.createTempFile with existing TestUtils.tempFile method across the test files. TestUtils.tempFile automatically performs a clean up of the temp files generated in /tmp/ folder.

Reviewers: Luke Chen <showuon@gmail.com>, Ismael Juma <mlists@juma.me.uk>",2022-09-13 08:44:21,Divij Vaidya,Not TDD
b9774c0b025d4eef025c12af9c264eff1e98410c,"KAFKA-14215; Ensure forwarded requests are applied to broker request quota (#12624)

Currently forwarded requests are not applied to any quotas on either the controller or the broker. The controller-side throttling requires the controller to apply the quota changes from the log to the quota managers, which will be done separately. In this patch, we change the response logic on the broker side to also apply the broker's request quota. The enforced throttle time is the maximum of the throttle returned from the controller (which is 0 until we fix the aforementioned issue) and the broker's request throttle time.

Reviewers: David Arthur <mumrah@gmail.com>",2022-09-12 20:50:33,Jason Gustafson,Not TDD
536cdf692fb15ef87b86da75af85e2f06c6cd52b,"KAFKA-14196; Do not continue fetching partitions awaiting auto-commit prior to revocation (#12603)

When auto-commit is enabled with the ""eager"" rebalance strategy, the consumer will commit all offsets prior to revocation. Following recent changes, this offset commit is done asynchronously, which means there is an opportunity for fetches to continue returning data to the application. When this happens, the progress is lost following revocation, which results in duplicate consumption. This patch fixes the problem by adding a flag in `SubscriptionState` to ensure that partitions which are awaiting revocation will not continue being fetched.

Reviewers: Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",2022-09-12 21:02:13,Philip Nee,Mixed
3d2ac7cdbe89cdabfd95db9971de31878afa5498,"KAFKA-14208; Do not raise wakeup in consumer during asynchronous offset commits (#12626)

Asynchronous offset commits may throw an unexpected WakeupException following #11631 and #12244. This patch fixes the problem by passing through a flag to ensureCoordinatorReady to indicate whether wakeups should be disabled. This is used to disable wakeups in the context of asynchronous offset commits. All other uses leave wakeups enabled.

Note: this patch builds on top of #12611.

Co-Authored-By: Guozhang Wang wangguoz@gmail.com

Reviewers: Luke Chen <showuon@gmail.com>",2022-09-13 15:43:09,Jason Gustafson,Mixed
c5954175a487639faf5e82d8e96c1364e5861c69,"KAFKA-14222; KRaft's memory pool should always allocate a buffer (#12625)

Because the snapshot writer sets a linger ms of Integer.MAX_VALUE it is
possible for the memory pool to run out of memory if the snapshot is
greater than 5 * 8MB.

This change allows the BatchMemoryPool to always allocate a buffer when
requested. The memory pool frees the extra allocated buffer when released if
the number of pooled buffers is greater than the configured maximum
batches.

Reviewers: Jason Gustafson <jason@confluent.io>",2022-09-13 08:04:40,José Armando García Sancio,Mixed
86645cb40a7f0e3b3e7aed7925f2488c0cbbf1b4,"KAFKA-14073; Log the reason for snapshot (#12414)

When a snapshot is taken it is due to either of the following reasons -

    Max bytes were applied
    Metadata version was changed

Once the snapshot process is started, it will log the reason that initiated the process.

Updated existing tests to include code changes required to log the reason. I was not able to check the logs when running tests - could someone guide me on how to enable logs when running a specific test case.

Reviewers: dengziming <dengziming1993@gmail.com>, José Armando García Sancio <jsancio@apache.org>",2022-09-13 10:03:47,Ashmeet Lamba,Mixed
1ab4596ee67f99cfee3dab2451223fd0c8ee7d30,"KAFKA-10199: Suspend tasks in the state updater on revocation (#12600)

In the first attempt to handle revoked tasks in the state updater
we removed the revoked tasks from the state updater and added it to
the set of pending tasks to close cleanly. This is not correct since
a revoked task that is immediately reassigned to the same stream thread
would neither be re-added to the state updater nor be created again.
Also a revoked active task might be added to more than one bookkeeping
set in the tasks registry since it might still be returned from
stateUpdater.getTasks() after it was removed from the state updater.
The reason is that the removal from the state updater is done
asynchronously.

This PR solves this issue by introducing a new bookkeeping set
in the tasks registry to bookkeep revoked active tasks (actually
suspended active tasks).

Additionally this PR closes some testing holes around the modified
code.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Hao Li <1127478+lihaosky@users.noreply.github.com>",2022-09-14 09:03:43,Bruno Cadonna,Mixed
bdf2cdb27fa39c30171a0e63641cd8e8b851fe0c,"KAFKA-14132: Migrate some Connect tests from EasyMock/PowerMock to Mockito (#12615)

Reviewers: Chris Egerton <chrise@aiven.io>",2022-09-14 11:00:32,Yash Mayya,Mixed
2b2039f0ba88e210dd09031291c050cfcda7ce4a,"KAFKA-14156: Built-in partitioner may create suboptimal batches (#12570)

Now the built-in partitioner defers partition switch (while still
accounting produced bytes) if there is no ready batch to send, thus
avoiding switching partitions and creating fractional batches.

Reviewers: Jun Rao <jun@confluent.io>",2022-09-14 17:39:14,Artem Livshits,Mixed
b09cadcaa7fd0eaea32ce1fe2e22fefcbf1079ee,"KAFKA-13985: Skip committing MirrorSourceTask records without metadata (#12602)

Reviewers: Chris Egerton <chrise@aiven.io>",2022-09-15 09:55:44,Rens Groothuijsen,Mixed
a1f3c6d16061566a4f53c72a95e2679b8ee229e0,"KAFKA-10199: Register and unregister changelog topics in state updater (#12638)

Registering and unregistering the changelog topics in the
changelog reader outside of the state updater leads to
race conditions between the stream thread and the state
updater thread. Thus, this PR moves registering and
unregistering of changelog topics in the changelog
reader into the state updater if the state updater
is enabled.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Hao Li <1127478+lihaosky@users.noreply.github.com>",2022-09-16 09:05:11,Bruno Cadonna,Mixed
b166ac43cb646d9589623abfe283874d59ce923b,"KAFKA-14238;  KRaft metadata log should not delete segment past the latest snapshot (#12655)

Disable segment deletion based on size and time by setting the KRaft metadata log's `RetentionMsProp` and `RetentionBytesProp` to `-1`. This will cause `UnifiedLog.deleteRetentionMsBreachedSegments` and `UnifiedLog.deleteRetentionSizeBreachedSegments` to short circuit instead of deleting segments.

Without this changes the included test would fail. This happens because `deleteRetentionMsBreachedSegments` is able to delete past the `logStartOffset`. Deleting past the `logStartOffset` would violate the invariant that if the `logStartOffset` is greater than 0 then there is a snapshot with an end offset greater than or equal to the log start offset.

Reviewers: Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",2022-09-17 06:30:50,José Armando García Sancio,Mixed
51b079dca764b10c80c953dba06028bb6136c87f,"KAFKA-12878: Support --bootstrap-server in kafka-streams-application-reset tool (#12632)

Reviewers: Chris Egerton <chrise@aiven.io>",2022-09-19 13:20:41,Nikolay,Not TDD
8c8b5366a69a14def32bffe01faeeea448d0c9d6,"KAFKA-14240; Validate kraft snapshot state on startup (#12653)

We should prevent the metadata log from initializing in a known bad state. If the log start offset of the first segment is greater than 0, then must be a snapshot an offset greater than or equal to it order to ensure that the initialized state is complete.

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",2022-09-19 11:52:48,Jason Gustafson,Mixed
f8e0a6d9245217d1f73fd9b9d0b109203e0509c5,"KAFKA-14212: Enhance HttpAccessTokenRetriever to retrieve error message (#12651)

Currently HttpAccessTokenRetriever client side class does not retrieve error response from the token e/p. As a result, seemingly trivial config issues could take a lot of time to diagnose and fix. For example, client could be sending invalid client secret, id or scope.
This PR aims to remedy the situation by retrieving the error response, if present and logging as well as appending to any exceptions thrown.
New unit tests have also been added.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2022-09-20 12:33:19,Sushant Mahajan,Mixed
8ddc9509cf77adc7a10c7a0152e01ac6610cb2cc,"KAFKA-13927: Fix sink task offset tracking during exception retries (#12566)

Reviewers: Chris Egerton <chrise@aiven.io>",2022-09-20 13:46:35,Jordan Bull,Mixed
ae4bb0c6fad5f6a610476110a9d17fa77ec5b97f,"KAFKA-14243: Temporarily disable unsafe downgrade (#12664)

Reviewers: David Arthur <mumrah@gmail.com>",2022-09-20 15:32:52,Colin Patrick McCabe,Mixed
b401fdaefbfbd9263deef0ab92b6093eaeb26d9b,"MINOR: Add more validation during KRPC deserialization

    When deserializing KRPC (which is used for RPCs sent to Kafka, Kafka Metadata records, and some
    other things), check that we have at least N bytes remaining before allocating an array of size N.

    Remove DataInputStreamReadable since it was hard to make this class aware of how many bytes were
    remaining. Instead, when reading an individual record in the Raft layer, simply create a
    ByteBufferAccessor with a ByteBuffer containing just the bytes we're interested in.

    Add SimpleArraysMessageTest and ByteBufferAccessorTest. Also add some additional tests in
    RequestResponseTest.

    Reviewers: Tom Bentley <tbentley@redhat.com>, Mickael Maison <mickael.maison@gmail.com>, Colin McCabe <colin@cmccabe.xyz>

    Co-authored-by: Colin McCabe <colin@cmccabe.xyz>
    Co-authored-by: Manikumar Reddy <manikumar.reddy@gmail.com>
    Co-authored-by: Mickael Maison <mickael.maison@gmail.com>",2022-09-21 20:58:23,Colin Patrick McCabe,Mixed
5587c65fd3c5c7f28b459e1c8589ca7cc8b52409,"MINOR: Add configurable max receive size for SASL authentication requests

This adds a new configuration `sasl.server.max.receive.size` that sets the maximum receive size for requests before and during authentication.

Reviewers: Tom Bentley <tbentley@redhat.com>, Mickael Maison <mickael.maison@gmail.com>

Co-authored-by: Manikumar Reddy <manikumar.reddy@gmail.com>
Co-authored-by: Mickael Maison <mickael.maison@gmail.com>",2022-09-21 20:58:33,Manikumar Reddy,Mixed
cda5da9b65f78b51cdfe5371f712a0d392dbdb4d,"KAFKA-14209: Change Topology optimization to accept list of rules 1/3 (#12641)

This PR is part of a series implementing the self-join rewriting. As part of it, we decided to clean up the TOPOLOGY_OPTIMIZATION_CONFIG and make it a list of optimization rules. Acceptable values are: NO_OPTIMIZATION, OPTIMIZE which applies all optimization rules or a comma separated list of specific optimizations.

Reviewers: Guozhang Wang <guozhang@apache.org>, John Roesler <vvcephei@apache.org>",2022-09-22 11:20:37,Vicky Papavasileiou,Mixed
a7caed39b7451d591dd43391437ab47e39ff4422,"KAFKA-14097: Make producer ID expiration a dynamic config (#12643)

Make `producer.id.expiration.ms` a dynamic configuration as described in KIP-854.

Reviewers: David Jacot <djacot@confluent.io>",2022-09-23 09:19:48,Justine Olshan,Mixed
8e43548175db086cbedf1b990e17c80dc438d55e,"KAFKA-13725: KIP-768 OAuth code mixes public and internal classes in same package (#12039)

* KAFKA-13725: KIP-768 OAuth code mixes public and internal classes in same package

Move classes into a sub-package of ""internal"" named ""secured"" that
matches the layout more closely of the ""unsecured"" package.

Replaces the concrete implementations in the former packages with
sub-classes of the new package layout and marks them as deprecated. If
anyone is already using the newer OAuth code, this should still work.

* Fix checkstyle and spotbugs violations

Co-authored-by: Kirk True <kirk@mustardgrain.com>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2022-09-23 13:15:15,Kirk True,Mixed
7496e6243410ca851f4b8502270cf4222bd89a2b,"KAFKA-14259: BrokerRegistration#toString throws an exception, terminating metadata replay (#12681)

Previously, BrokerRegistration#toString sould throw an exception, terminating metadata replay,
because the sorted() method is used on an entry set rather than a key set.

Reviewers: David Arthur <mumrah@gmail.com>",2022-09-23 15:39:50,Colin Patrick McCabe,Mixed
07a31599c3f5b23158f83988ebc05381a1e86b00,"KAFKA-10199: Fix switching to updating standbys if standby is removed (#12687)

When the state updater only contains standby tasks and then a
standby task is removed, an IllegalStateException is thrown
because the changelog reader does not allow to switch to standby
updating mode more than once in a row.

This commit fixes this bug by checking that the removed task is
an active one before trying to switch to standby updating mode.
If the task to remove is a standby task then either we are already
in standby updating mode and we should not switch to it again or
we are not in standby updating mode which implies that there are
still active tasks that would prevent us to switch to standby
updating mode.

Reviewer: Guozhang Wang <wangguoz@gmail.com>",2022-09-26 20:34:09,Bruno Cadonna,Mixed
d62a42df2e24b7e12b7fae2ccd9c2931e62a95ae,"KAFKA-10199: Integrate Topology Pause/Resume with StateUpdater (#12659)

When a topology is paused / resumed, we also need to pause / resume its corresponding tasks inside state updater.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2022-09-28 16:26:01,Guozhang Wang,Mixed
fc786c335c6f51a9022b0190b15f57f42e4ea9ab,add unit and integration tests,2022-09-28 22:58:39,Colin P. McCabe,Mixed
51dbd175b08e78aeca03d6752847aa5f23c98659,"KAFKA-4852: Fix ByteBufferSerializer#serialize(String, ByteBuffer) not compatible with offsets (#12683)

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2022-09-29 10:59:47,LinShunKang,Not TDD
496ae054c2d43c0905167745bfb2f4a0725e9fc2,"Fix ByteBufferSerializer#serialize(String, ByteBuffer) not roundtrip input with ByteBufferDeserializer#deserialize(String, byte[]) (#12704)

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2022-09-30 06:45:18,LinShunKang,Not TDD
c5745d2845cfdb9d99f3a93f4eb77aebe4344bdd,"MINOR: Add initial property tests for StandardAuthorizer (#12703)

In https://github.com/apache/kafka/pull/12695, we discovered a gap in our testing of `StandardAuthorizer`. We addressed the specific case that was failing, but I think we need to establish a better methodology for testing which incorporates randomized inputs. This patch is a start in that direction. We implement a few basic property tests using jqwik which focus on prefix searching. It catches the case from https://github.com/apache/kafka/pull/12695 prior to the fix. In the future, we can extend this to cover additional operation types, principal matching, etc.

Reviewers: David Arthur <mumrah@gmail.com>",2022-10-04 16:31:43,Jason Gustafson,Not TDD
21a15c6b1f1ee80f163633ba617ad381f5edc0c1,"KAFKA-14209 : Rewrite self joins to use single state store 2/3 (#12644)

Implements KIP-862: https://cwiki.apache.org/confluence/x/WSf1D

Reviewers: Guozhang Wang <guozhang@apache.org>,  Austin Heyne <aheyne>, John Roesler <vvcephei@apache.org>",2022-10-05 07:36:04,Vicky Papavasileiou,Mixed
cbdcd20ac183c8935161179e2d8cc53eabcb027c,"MINOR: Include all hosts in metadata for topology (#12594)

When building streams metadata we want to build even if the host is empty as it is a common way to find the other host addresses

Reviewers: John Roesler <vvcephei@apache.org>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2022-10-06 21:33:00,Walker Carlson,Not TDD
e8d32563f323a245b3127394d97d6356e84f0294,"MINOR; Fix error message when validating KRaft config (#12717)

The error message reported when advertised.listeners is used in
controller only is confusing. When the KRaft server is configured to
controller only the following must be true:

1. `advertised.listeners` is not set
2. `listeners` contains a listener for every name in `controller.listener.names`
3. `controller.listener.names` contains a name for every listener in `listeners`

Reviewers: Jason Gustafson <jason@confluent.io>, Igor Soarez <i@soarez.me>",2022-10-07 10:40:55,José Armando García Sancio,Mixed
daae2a189de21e4fed42eb7bd204db2e8636eb4a,"HOTFIX: Only update input partitions of standby tasks if they really changed (#12730)

Updating the input partitions of tasks also updates the mapping from
source nodes to input topics in the processor topology within the task.
The mapping is updated with the topics from the topology metadata.
The topology metadata does not prefix intermediate internal topics with
the application ID. Thus, if a standby task has input partitions from an
intermediate internal topic the update of the mapping in the processor
topology leads to an invalid topology exception during recycling of a
standby task to an active task when the input queues are created. This
is because the input topics in the processor topology and the input
partitions of the task do not match because the former miss the
application ID prefix.

The added verification to only update input partitions of standby tasks
if they really changed avoids the invalid topology exception if the
standby task only has input partitions from intermediate internal
topics since they should never change. If the standby task has input
partitions from intermediate internal topics and external topics
subscribed to via a regex pattern, the invalid topology exception
might still be triggered.

Reviewers: Guozhang Wang <guozhang@apache.org>, John Roesler <vvcephei@apache.org>",2022-10-11 18:13:58,Bruno Cadonna,Mixed
98a3dcb477914dcf0c1adc4f7494db9e9a55bd3e,"KAFKA-14275; KRaft Controllers should crash after failing to apply any metadata record (#12709)

Make all faults in metadata processing on standby controllers be fatal. This is the same behavior-wise as the active controller. This prevents a standby controller from eventually becoming active with incomplete state.

Reviewers: Colin Patrick McCabe <cmccabe@apache.org>, Jason Gustafson <jason@confluent.io>",2022-10-11 09:46:42,Niket,Mixed
d834947ae7abc8a9421d741e742200bb36f51fb3,"KAFKA-14225; Fix deadlock caused by lazy val exemptSensor (#12634)

There is a chance to cause deadlock when multiple threads access ClientRequestQuotaManager. In the version Scala 2.12, the lazy val initialization is under the object lock. The deadlock could happen in the following condition:

In thread a, when ClientRequestQuotaManager.exemptSensor is being initialized, it has acquired the object lock and enters the the actual initialization block. The initialization of 'exemptSensor' requires another lock private val lock = new ReentrantReadWriteLock() and it is waiting for this lock.

In thread b, at the same time, ClientQuotaManager.updateQuota() is called and it has already acquired ReentrantReadWriteLock lock by calling lock.writeLock().lock(). And then it executes info(). If this is the first time accessing Logging.logger, which is also a lazy val, it need to wait for the object lock.

The deadlock happens.

Since the lazy val initialization is under the object lock, we should avoid using lazy val if the initialization function holds another lock to prevent holding two locks at the same time which is prone for deadlock. Change to create exemptSensor during ClientRequestQuotaManager initialization with an expiration time of Long.MaxValue to prevent expiration if request quota is not enabled at that time.

Reviewers: Jason Gustafson <jason@confluent.io>",2022-10-11 10:30:07,Huilin Shi,Not TDD
a6b60e7cf3860be7a19708a2b762e6bd507885d7,"KAFKA-12965 - Graceful clean up of task error metrics (#10910)

Reviewers: Chris Egerton <chrise@aiven.io>",2022-10-12 09:59:52,Ramesh,Mixed
62914129c7dbf856a7702f33ed456109c6980b0c,"KAFKA-14099 - Fix request logging in connect (#12434)

Reviewers: Chris Egerton <chrise@aiven.io>",2022-10-12 10:28:55,Alexandre Garnier,Mixed
07c10024890c0761ba47ccd4d6301e8101d8c8de,"KAFKA-12960: Enforcing strict retention time for WindowStore and Sess… (#11211)

WindowedStore and SessionStore do not implement a strict retention time in general. We should consider to make retention time strict: even if we still have some record in the store (due to the segmented implementation), we might want to filter expired records on-read. This might benefit PAPI users.

This PR, adds the filtering behaviour in the Metered store so that, it gets automatically applied for cases when a custom state store is implemented

Reviewer: Luke Chen <showuon@gmail.com>, A. Sophie Blee-Goldman <sophie@confluent.io>, Matthias J. Sax <mjsax@apache.org>",2022-10-13 09:39:58,vamossagar12,Mixed
18e60cb0001f72018d9d00221253f69b8761a2e7,"KAFKA-12497: Skip periodic offset commits for failed source tasks (#10528)

Also moves the Streams LogCaptureAppender class into the clients module so that it can be used by both Streams and Connect.

Reviewers: Nigel Liang <nigel@nigelliang.com>, Kalpesh Patel <kpatel@confluent.io>, John Roesler <vvcephei@apache.org>, Tom Bentley <tbentley@redhat.com>",2022-10-13 10:15:42,Chris Egerton,Mixed
dac81161dbf743b9e0c31ab5ffa7bb8c757feb3d,"MINOR; Introduce ImageWriter and ImageWriterOptions (#12715)

This PR adds a new ImageWriter interface which replaces the generic Consumer interface which
accepted lists of records. It is better to do batching in the ImageWriter than to try to deal with
that complexity in the MetadataImage#write functions, especially since batching is not semantically
meaningful in KRaft snapshots. The new ImageWriter interface also supports freeze and close, which
more closely matches the semantics of the underlying Raft classes.

The PR also adds an ImageWriterOptions class which we can use to pass parameters to control how the
new image is written. Right now, the parameters that we are interested in are the target metadata
version (which may be more or less than the original image's version) and a handler function which
is invoked whenever metadata is lost due to the target version.

Convert over the MetadataImage#write function (and associated functions) to use the new ImageWriter
and ImageWriterOptions. In particular, we now have a way to handle metadata losses by invoking
ImageWriterOptions#handleLoss. This allows us to handle writing an image at a lower version, for
the first time. This support is still not enabled externally by this PR, though. That will come in
a future PR.

Get rid of the use of SOME_RECORD_TYPE.highestSupportedVersion() in several places. In general, we
do not want to ""silently"" change the version of a record that we output, just because a new version
was added. We should be explicit about what record version numbers we are outputting.

Implement ProducerIdsDelta#toString, to make debug logs look better.

Move MockRandom to the server-common package so that other internal broker packages can use it.

Reviewers: José Armando García Sancio <jsancio@apache.org>",2022-10-13 09:56:19,Colin Patrick McCabe,Mixed
484f85ff53b3d1dee5ecb940c4ee8170a68f1700,"HOTFIX: Revert ""KAFKA-12960: Enforcing strict retention time for WindowStore and Sess… (#11211)"" (#12745)

This reverts commit 07c10024890c0761ba47ccd4d6301e8101d8c8de which broke trunk.

Reviewers: David Jacot <djacot@confluent.io>, Bill Bejeck <bbejeck@apache.org>",2022-10-13 13:27:19,Bruno Cadonna,Mixed
0cb1d614136f92529aa2be4958f5c51f277f98da,"KAFKA-14292; Fix KRaft controlled shutdown delay (#12736)

The `controlledShutDownOffset` is defined as the ""offset at which the broker should complete its controlled shutdown, or -1 if the broker is not performing a controlled shutdown"". The controller sets this offset to a non-negative integer on receiving a heartbeat from a broker that's in controlled shutdown state. Currently, this offset is being updated and bumped every single time a broker in controlled shutdown mode send a heartbeat, delaying when controlled shutdown can actually complete for the broker. We should only update the offset when it was previously set to -1 to allow controlled shutdown to complete.

Reviewers: Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",2022-10-13 13:29:45,Alyssa Huang,Mixed
5cff8f67b060a81f454dd4a8b0e78aa7858250fd,"KAFKA-14296; Partition leaders are not demoted during kraft controlled shutdown (#12741)

When the `BrokerServer` starts its shutting down process, it transitions to `SHUTTING_DOWN` and sets `isShuttingDown` to `true`. With this state change, the follower state changes are short-cutted. This means that a broker which was serving as leader would remain acting as a leader until controlled shutdown completes. Instead, we want the leader and ISR state to be updated so that requests will return NOT_LEADER and the client can find the new leader.

We missed this case while implementing https://github.com/apache/kafka/pull/12187.

This patch fixes the issue and updates an existing test to ensure that `isShuttingDown` has not effect. We should consider adding integration tests for this as well. We can do this separately.

Reviewers: Ismael Juma <ismael@juma.me.uk>, José Armando García Sancio <jsancio@users.noreply.github.com>, Jason Gustafson <jason@confluent.io>",2022-10-13 16:59:19,David Jacot,Mixed
dfb592966549a2a9f2acda72ca21f89753740881,"Kafka Streams Threading P2: Skeleton TaskExecutor Impl (#12744)

0. Address comments from P1.
1. Add the DefaultTaskExecutor implementation class.
2. Related DefaultTaskExecutorTest.

Pending in future PRs: a) exception handling, primarily to send them to polling thread, b) light-weight task flushing procedure.",2022-10-14 15:32:48,Guozhang Wang,Mixed
55a3a95b7a1f61c2a93a6341d3e091f68b048234,"Kafka Streams Threading P3: TaskManager Impl (#12754)

0. Add name to task executors.
1. DefaultTaskManager implementation, for interacting with the TaskExecutors and support add/remove/lock APIs.
2. Related unit tests.",2022-10-14 16:10:57,Guozhang Wang,Mixed
cc582897bfb237572131369a598f7869220b43dc,"KAFKA-14299: Fix incorrect pauses in separate state restoration (#12743)

The original code path paused the main consumer for
all tasks before entering the restoration section
of the code, and then resumed all after restoration
has finished.

In the new state updater part of the code, tasks that
do not require restoration skip the restoration completely.
They remain with the TaskManger and are never transferred
to the StateUpdater, and thus are never resumed.

This change makes sure that tasks that remain with the
TaskManager are not paused.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bruno Cadonna <cadonna@apache.org>",2022-10-18 12:16:44,Lucas Brutschy,Mixed
7a7ad9b422eac4ab9bfec6b5bbfc7c31dc02854c,"KAFKA-14299: Fix busy polling with separate state restoration (#12749)

StreamThread in state PARTITIONS_ASSIGNED was running in
a busy loop until restoration is finished, stealing CPU
cycles from restoration.

Make sure the StreamThread uses poll_time when
state updater is enabled, and we are in state
PARTITIONS_ASSIGNED.

Reviewer: Bruno Cadonna <cadonna@apache.org>",2022-10-18 21:33:40,Lucas Brutschy,Mixed
7dc17908de540b461b67b71652cef652adc488b0,"KAFKA-14300; Generate snapshot after repeated controller resign (#12747)

Setting the `committedBytesSinceLastSnapshot` to 0 when resigning can cause the controller to not generate a snapshot after `snapshotMaxNewRecordBytes` committed bytes have been replayed.

This change fixes that by simply not resetting the counter during resignation. This is correct because the counter tracks the number of committed bytes replayed but not included in the latest snapshot. In other words, reverting the last committed state does not invalidate this value.

Reviewers: Colin Patrick McCabe <cmccabe@apache.org>",2022-10-18 15:09:20,José Armando García Sancio,Mixed
a692223a44cd92c6379705865426cd68858cc830,"KAFKA-14316; Fix feature control iterator metadata version handling (#12765)

The iterator `FeatureControlIterator.hasNext()` checks two conditions: 1) whether we have already written the metadata version, and 2) whether the underlying iterator has additional records. However, in `next()`, we also check that the metadata version is at least high enough to include it in the log. When this fails, then we can see an unexpected `NoSuchElementException` if the underlying iterator is empty.

Reviewers: Colin Patrick McCabe <cmccabe@apache.org>",2022-10-18 15:30:45,Jason Gustafson,Mixed
2c8f14c57e13f7edf02a832603048e568170626e,"KAFKA-14299: Never transition to UpdateStandby twice (#12762)

In two situations, the current code could transition the ChangelogReader
to UpdateStandby when already in that state, causing an IllegalStateException. 
Namely these two cases are:

1. When only standby tasks are restoring and one of them crashes.
2. When only standby tasks are restoring and one of them is paused.

This change fixes both issues by only transitioning if the paused or
failed task is an active task.

Reviewer: Bruno Cadonna <cadonna@apache.org>",2022-10-19 09:29:19,Lucas Brutschy,Mixed
d0ff8697189bda65b5381a95cccf6c4428b08637,"MINOR; Add accessor methods to OffsetAndEpoch (#12770)

Accessor are preferred over fields because they compose better with Java's
lambda syntax.

Reviewers: Jason Gustafson <jason@confluent.io>",2022-10-19 12:07:07,José Armando García Sancio,Mixed
0a045d4ef7d67dbe35b8fd2e1c51df87af19a0ab,"KAFKA-14247: Consumer background thread base implementation (#12672)

Adds skeleton of the background thread.

1-pager: https://cwiki.apache.org/confluence/display/KAFKA/Proposal%3A+Consumer+Threading+Model+Refactor
Continuation of #12663

Reviewers: Guozhang Wang <guozhang@apache.org>, Kirk True <kirk@mustardgrain.com>, John Roesler <vvcephei@apache.org>",2022-10-19 21:02:55,Philip Nee,Mixed
b525ddc9f1fab24bc30209d5b12462dd9c566bfd,"MINOR: Fix PartitionRegistration.hashCode (#12774)

`PartitionRegistration.hashCode` passes raw arrays to `Objects.hash` in the `hashCode` implementation. This doesn't work since the `equals` implementation uses `Arrays.equals`. We should use `Arrays.hashCode` instead. 

Reviewers: David Arthur <mumrah@gmail.com>",2022-10-20 14:01:01,Jason Gustafson,Mixed
9a793897ec486df550367dee43078e463b234294,"KAFKA-13152: KIP-770, cache size config deprecation (#12758)

PR implementing KIP-770 (#11424) was reverted as it brought in a regression wrt pausing/resuming the consumer. That KIP also introduced a change to deprecate config CACHE_MAX_BYTES_BUFFERING_CONFIG and replace it with STATESTORE_CACHE_MAX_BYTES_CONFIG.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2022-10-20 17:03:50,vamossagar12,Mixed
47adb866369e46a9a56c417d243de03cfd9ebd7f,"KAFKA-10149: Allow auto preferred leader election when there are ongoing partition reassignments (#12543)

Reviewers: Justine Olshan <jolshan@confluent.io>, Chris Egerton <fearthecellos@gmail.com>",2022-10-26 09:21:55,Shenglong Zhang,Not TDD
5e399fe6f3aa65b42b9cdbf1c4c53f6989a570f0,"Move to mockito (#12465)

This PR build on top of #11017. I have added the previous author's comment in this PR for attribution. I have also addressed the pending comments from @chia7712 in this PR.

Notes to help the reviewer:

Mockito has mockStatic method which is equivalent to PowerMock's method.
When we run the tests using @RunWith(MockitoJUnitRunner.StrictStubs.class) Mockito performs a verify() for all stubs that are mentioned, hence, there is no need to explicitly verify the stubs (unless you want to verify the number of times etc.). Note that this does not work for static mocks.

Reviewers: Bruno Cadonna <cadonna@apache.org>, Walker Carlson <wcarlson@confluent.io>, Bill Bejeck <bbejeck@apache.org>",2022-10-27 14:08:44,Divij Vaidya,Mixed
61f48a9f63a692efdb43c1595b8fdb9d1cbb2aa4,"KAFKA-14314: Add check for null upstreamTopic (#12769)


Reviewers: Mickael Maison <mickael.maison@gmail.com>
Co-authored-by: John Krupka <john.krupka@united.com>",2022-10-28 17:28:26,(+ (* 1 2 3 4) 5 6 7),Mixed
a0e37b79aa5ec7a9588eccf22929824d582f3fdb,"MINOR: Add test cases to the Raft module (#12692)


Reviewers: Mickael Maison <mickael.maison@gmail.com> , Divij Vaidya <diviv@amazon.com>, Ismael Juma <mlists@juma.me.uk>",2022-10-28 17:54:34,Orsák Maroš,Not TDD
c1bb307a361b7b6e17261cc84ea2b108bacca84d,"KAFKA-14337; Correctly remove topicsWithCollisionChars after topic deletion (#12790)

In https://github.com/apache/kafka/pull/11910 , we added a feature to prevent topics with conflicting metrics names from being created. We added a map to store the normalized topic name to the topic names, but we didn't remove it correctly while deleting topics. This PR fixes this bug and add a test.

Reviewers: Igor Soarez <i@soarez.me>, dengziming <dengziming1993@gmail.com>, Jason Gustafson <jason@confluent.io>",2022-10-28 10:08:53,Luke Chen,Not TDD
cbe50d95a980529c84698d0d2be476ff178c2c29,"MINOR: Add test case for topic recreation with collision chars (#12796)

This patch adds a unit test for topic recreation with colliding characters (such as `.`). This was broken up until https://github.com/apache/kafka/pull/12790. 

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>",2022-10-28 18:50:08,Jason Gustafson,Mixed
f7304db6d2d3a2a55db7e945586aeb91843dbacb,"KAFKA-14338: Use MockTime in RetryUtilTest to eliminate flakiness (#12791)

Reviewers: Chris Egerton <chrise@aiven.io>",2022-10-29 06:38:24,Greg Harris,Mixed
fa10e213bfea306bb5d4590dbdc5e54854192782,"KAFKA-14247: add handler impl to the prototype (#12775)

Minor revision for KAFKA-14247. Added how the handler is called and constructed to the prototype code path.

Reviewers: John Roesler <vvcephei@apache.org>, Kirk True <kirk@mustardgrain.com>",2022-10-31 14:01:22,Philip Nee,Mixed
98bf375b6f3c01123d077074d7c46bda6062be96,"KAFKA-13989: Errors while evaluating connector type should return UNKNOWN (#12789)

Reviewers: Igor Soarez <i@soarez.me>, Chris Egerton <chrise@aiven.io>",2022-10-31 16:54:32,Greg Harris,Mixed
9ab140d5419d735baae45aff56ffce7f5622744f,"KAFKA-14132; Replace EasyMock with Mockito ConnectorsResourceTest (#12725)

Reviewers: Chris Egerton <chrise@aiven.io>",2022-10-31 20:08:41,Matthew de Detrich,Not TDD
e7c1e4a0a154db95304708eb1894447d3e3aa865,"KAFKA-14299: Handle TaskCorruptedException during initialization (#12771)

State stores are initialized from the StreamThread even when
the state updater thread is enabled. However, we were missing
the corresponding handling of exceptions when thrown directly
during the initialization. In particular, TaskCorruptedException
would directly fall through to runLoop, and the task
would fall out of book-keeping, since the exception is thrown
when neither the StreamThread nor the StateUpdater is owning
the task.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Bruno Cadonna <cadonna@apache.org>",2022-11-01 18:25:19,Lucas Brutschy,Mixed
14c36c7539cf5a7a54c2c7e30e115b3f4c4a9402,"KAFKA-14058: Migrate ExactlyOnceWorkerSourceTaskTest from EasyMock and Powermock to Mockito (#12409)

Reviewers: Mickael Maison <mickael.maison@gmail.com>",2022-11-03 12:42:08,Chris Egerton,Not TDD
bc780c7c32c24e681e08e097ad4ecb4c1a5ee9a7,"MINOR: Move timeline data structures from metadata to server-common (#12811)

This path moves the timeline data structures from metadata module to server-common module as those will be used in the new group coordinator.

Reviewers: José Armando García Sancio <jsancio@users.noreply.github.com>, Colin Patrick McCabe <cmccabe@apache.org>",2022-11-04 08:52:32,David Jacot,Mixed
fcab5fb888297957da255451f0d048d0efd9ad91,"Revert ""KAFKA-13891: reset generation when syncgroup failed with REBALANCE_IN_PROGRESS (#12140)"" (#12794)

This reverts commit c23d60d56cd73118624192cf03f6e400f59027e7.

Reviewers: Luke Chen <showuon@gmail.com>",2022-11-05 14:05:48,Shawn,Mixed
b8754c074ab59d2ebc8d0212b36065f470c9081b,"KAFKA-14355: Fix integer overflow in ProducerPerformance (#12822)

Change types from int to long to avoid overflow

Reviewers: Luke Chen <showuon@gmail.com>,  Igor Soarez <soarez@apple.com>",2022-11-05 20:19:08,runom,Mixed
7fd6a9b3e22eabfe31d0f3e7792d03f09cf8aabc,"Kafka 12960: Follow up Commit to filter expired records from Windowed/Session Stores (#12756)

KAFKA-12960: Enforcing strict retention time for WindowStore and SessionStore

Reviewers: Luke Chen <showuon@gmail.com>, Vicky Papavasileiou",2022-11-07 11:53:34,vamossagar12,Mixed
9608f3a2e7e82613c7d00a4c031ef82a25976caf,"KAFKA-14344: Build EmbeddedKafkaCluster with common configs used for all clients (#12804)


Reviewers: Mickael Maison <mickael.maison@gmail.com>  , Tom Bentley <tbentley@redhat.com>",2022-11-07 11:11:16,Omnia G H Ibrahim,Not TDD
37a3645e7e478f30e4b60a86bdf4bcf6d1161713,"KAFKA-14299: Return emptied ChangelogReader to ACTIVE_RESTORING (#12773)

The ChangelogReader starts of in `ACTIVE_RESTORING` state, and
then goes to `STANDBY_RESTORING` when changelogs from standby
tasks are added. When the last standby changelogs are removed,
it remained in `STANDBY_RESTORING`, which means that an empty
ChangelogReader could be in either `ACTIVE_RESTORING` or
`STANDBY_RESTORING` depending on the exact sequence of
add/remove operations. This could lead the state updater into
an illegal state. Instead of changing the state updater,
I propose to stengthen the state invariant of the
`ChangelogReader` slightly: it should always be in
`ACTIVE_RESTORING` state, when empty.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Bruno Cadonna <cadonna@apache.org>",2022-11-07 13:35:18,Lucas Brutschy,Mixed
a971448f3f20ec52324b59e8e99f14da0e88efc6,"KAFKA-14254: Format timestamps as dates in logs (#12684)

Improves logs withing Streams by replacing timestamps to date instances to improve readability.

Approach - Adds a function within common.utils.Utils to convert a given long timestamp to a date-time string with the same format used by Kafka's logger.

Reviewers: Divij Vaidya <diviv@amazon.com>, Bruno Cadonna <cadonna@apache.org>",2022-11-07 13:42:39,Ashmeet Lamba,Mixed
98ed31c95bce3f62abc9928fad487dbb8bd96485,"KAFKA-14346: Remove difficult to mock Plugins.compareAndSwapLoader usages  (#12817)

Reviewers: Chris Egerton <chrise@aiven.io>",2022-11-07 09:37:24,Greg Harris,Mixed
cd5f6c60b5bf191ec2aaff64ed2aceb105a3d33e,"KAFKA-14299: Avoid busy polling in state updater (#12772)

The state updater can enter a busy polling loop if it
only updates standby tasks. We need to use the user-provided
poll-time to update always when using the state updater, since
the only other place where the state update blocks
(inside `waitIfAllChangelogsCompletelyRead`) is also
not blocking if there is at least one standby task.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Bruno Cadonna <cadonna@apache.org>",2022-11-07 16:46:25,Lucas Brutschy,Mixed
4560978ed73ac2aa340506cfc34c30c6c1af4ca7,"KAFKA-14309: FK join upgrades not tested with DEV_VERSION (#12760)

The streams upgrade system inserted FK join code for every version of the
the StreamsUpgradeTest except for the latest. Also, the original code
never switched on the `test.run_fk_join` flag for the target version of
the upgrade.

The effect was that FK join upgrades were not tested at all, since
no FK join code was executed after the bounce in the system test.

We introduce `extra_properties` in the system tests, that can be used
to pass any property to the upgrade driver, which is supposed to be
reused by system tests for switching on and off flags (e.g. for the
state restoration code).

Reviewers: Alex Sorokoumov <asorokoumov@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2022-11-07 15:46:51,Lucas Brutschy,Not TDD
bb84476215ec951f2fd3dce6e7afe0846d4e18f0,"KAFKA-14098: Add meaningful client IDs for Connect workers (#12544)

Reviewers: Greg Harris <greg.harris@aiven.io>, Mickael Maison <mickael.maison@gmail.com>",2022-11-08 10:22:30,Chris Egerton,Mixed
c034388a0a528bb7cef9aff6dd9c08a3db1e1ad3,"KAFKA-14299: Avoid allocation & synchronization overhead in StreamThread loop (#12808)

The state updater code path introduced allocation and synchronization
overhead by performing relatively heavy operations in every iteration of
the StreamThread loop. This includes various allocations and acquiring
locks for handling `removedTasks` and `failedTasks`, even if the
corresponding queues are empty.

This change introduces `hasRemovedTasks` and
`hasExceptionsAndFailedTasks` in the `StateUpdater` interface that
can be used to skip over any allocation or synchronization. The new
methods do not require synchronization or memory allocation.

This change increases throughput by ~15% in one benchmark.

We extend existing unit tests to cover the slightly modified
behavior.

Reviewer: Bruno Cadonna <cadonna@apache.org>",2022-11-08 17:55:37,Lucas Brutschy,Mixed
51b7eb7937b113784cbd6ab31d2de142728ec1c1,"KAFKA-14282: stop tracking Produced sensors by processor node id  (#12836)

Users have been seeing a large number of these error messages being logged by the RecordCollectorImpl:

Unable to records bytes produced to topic XXX by sink node YYY as the node is not recognized.
It seems like we try to save all known sink nodes when the record collector is constructed, by we do so by going through the known sink topics which means we could miss some nodes, for example if dynamic topic routing is used. Previously we were logging an error and would skip recording the metric if we tried to send a record from a sink node it didn't recognize, but there's not really any reason to have been tracking the sensors by node in the first place -- we can just track the actual sink topics themselves.

Reviewers: John Roesler <vvcephei@apache.org>, Christo Lolov <lolovc@amazon.com>",2022-11-11 17:58:08,A. Sophie Blee-Goldman,Mixed
e422a67d3f0a30335a68e50df69690819dd9f511,"KAFKA-14294: check whether a transaction is in flight before skipping a commit (#12835)

Add a new #transactionInFlight API to the StreamsProducer to expose the flag of the same name, then check whether there is an open transaction when we determine whether or not to perform a commit in TaskExecutor. This is to avoid unnecessarily dropping out of the group on transaction timeout in the case a transaction was begun outside of regular processing, eg when a punctuator forwards records but there are no newly consumer records and thus no new offsets to commit.

Reviewer: Bruno Cadonna <cadonna@apache.org>",2022-11-14 09:43:46,A. Sophie Blee-Goldman,Mixed
a55071a99fabc9a706afa0e9acddf898c7cd05c4,"KAFKA-14299: Initialize tasks in state updater (#12795)

The state updater code path puts tasks into an
""initialization queue"", with created, but not initialized tasks.
These are later, during the event-loop, initialized and added
to the state updater. This might lead to losing track of those 
tasks - in particular it is possible to create
tasks twice, if we do not go once around `runLoop` to initialize
the task. This leads to `IllegalStateExceptions`. 

By handing the task to the state updater immediately and let the
state updater initialize the task, we can fulfil our promise to 
preserve the invariant ""every task is owned by either the task 
registry or the state updater"".

Reviewer: Bruno Cadonna <cadonna@apache.org>",2022-11-14 10:00:29,Lucas Brutschy,Mixed
46bee5bcf3e6877079111cbfd91a2fbaf3975a98,"KAFKA-13401: KIP-787 - MM2 manage Kafka resources with custom Admin implementation. (#12577)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Tom Bentley <tombentley@users.noreply.github.com>

Co-authored-by: Tom Bentley <tombentley@users.noreply.github.com>
Co-authored-by: oibrahim3 <omnia@apple.com>",2022-11-15 11:21:24,Omnia G H Ibrahim,Not TDD
09da44ed80bd88e1ca4526a352a7b3d3e3899c37,"KAFKA-12495: Exponential backoff retry to prevent rebalance storms when worker joins after revoking rebalance (#12561)

Reviewers: Yash Mayya <yash.mayya@gmail.com>, Luke Chen <showuon@gmail.com>, Chris Egerton <chrise@aiven.io>",2022-11-15 16:26:21,vamossagar12,Mixed
1894856d0efa9d04d011ac219714095a059c90a4,"KAFKA-13414: Replace PowerMock/EasyMock with Mockito in connect.storage.KafkaOffsetBackingStoreTest (#12418)

Reviewers: Chris Egerton <chrise@aiven.io>",2022-11-15 16:30:52,Christo Lolov,Mixed
dbf5826cd545820652ed6d136727aa80a03f4f54,"KAFKA-14334: Complete delayed purgatory after replication (#12783)

When a consumer makes a fetch request to a follower (KIP-392), the fetch request will sit in the purgatory until `fetch.max.wait.ms` is reached because the purgatory is not completed after replication. This patch aims to complete the delayed fetch purgatory after successfully replicating from the leader.

Reviewers: Artem Livshits <alivshits@confluent.io>, Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",2022-11-16 14:54:42,Jeff Kim,Mixed
c2fc36f3319b5c359ab5047025692cfdef8fa904,"MINOR: Handle JoinGroupResponseData.protocolName backward compatibility in JoinGroupResponse (#12864)

This is a small refactor extracted from https://github.com/apache/kafka/pull/12845. It basically moves the logic to handle the backward compatibility of `JoinGroupResponseData.protocolName` from `KafkaApis` to `JoinGroupResponse`.

The patch adds a new unit test for `JoinGroupResponse` and relies on existing tests as well.

Reviewers: Justine Olshan <jolshan@confluent.io>, Jason Gustafson <jason@confluent.io>",2022-11-16 12:43:00,David Jacot,Mixed
3012332e3d82947e434933efd4ab4e9366ab429d,"KAFKA-14388 - Fixes the NPE when using the new Processor API with the DSL (#12861)

With the addition of the new Processor API the newly added FixedKeyProcessorNodeFactory extends the ProcessorNodeFactory class. The ProcessorNodeFactory had a private field Set<String> stateStoreNames initialized to an empty see. The FixedKeyProcessorNodeFactory also had a private field Set<String> stateStoreNames.

When executing InternalTopologyBuilder.build executing the buildProcessorNode method passed any node factory as ProcessorNodeFactory and the method references the stateStoreNames field, it's pointing to the superclass field, which is empty so the corresponding StoreBuilder(s) are never added - causing NPE in the topology.

This PR makes the field protected on the ProcessorNodeFactory class so FixedKeyProcessorNodeFactory inherits it.

The added test fails without this change.

Reviewers: Matthias J. Sax <mjsax@apache.org>,  Sophie Blee-Goldman <sophie@confluent.io>, Jorge Esteban Quilcate Otoya <quilcate.jorge@gmail.com>",2022-11-16 17:06:15,Bill Bejeck,Not TDD
7a93d5c8331b405ac2eb517a4a84396c515517bd,"KAFKA-14346: Replace static mocking of WorkerConfig::lookupKafkaClusterId (#12839)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2022-11-17 10:32:39,Greg Harris,Mixed
529a44d5cf9e27d4b8916563c15ac5e554ad7d90,"KAFKA-14375: Remove use of ""authorizer-properties"" from EndToEndAuthorizerTest (#12843)

- This removes use of a deprecated feature and instead has all ACL
calls going through the brokers. This work is preliminary work
needed before I can make them run in KRAFT mode.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,  Igor Soarez <soarez@apple.com>",2022-11-17 21:49:00,Proven Provenzano,Not TDD
5bd556a49b0810eab2fe9c3c1fbbec7bca00769a,"KAFKA-14303 Producer.send without record key and batch.size=0 goes into infinite loop (#12752)

This fixes an bug which causes a call to producer.send(record) with a record without a key and configured with batch.size=0 never to return.

Without specifying a key or a custom partitioner the new BuiltInPartitioner, as described in KIP-749 kicks in.

BuiltInPartitioner seems to have been designed with the reasonable assumption that the batch size will never be lower than one.

However, documentation for producer configuration states batch.size=0 as a valid value, and even recommends its use directly. [1]

[1] clients/src/main/java/org/apache/kafka/clients/producer/ProducerConfig.java:87

Reviewers: Artem Livshits <alivshits@confluent.io>, Luke Chen <showuon@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",2022-11-17 14:27:02,Igor Soarez,Not TDD
fca5bfe13cb528b800ec48819c072b3130894009,"KAFKA-14346: Remove hard-to-mock RestClient calls (#12828)

Reviewers: Chris Egerton <chrise@aiven.io>",2022-11-17 17:51:54,Greg Harris,Mixed
31c69ae9321e5a12baf0cef045cbddf312f104fe,"KAFKA-14346: Remove hard-to-mock javax.crypto calls (#12866)

Reviewers: Chris Egerton <chrise@aiven.io>",2022-11-17 18:10:17,Greg Harris,Mixed
93dd6ce21a8ded7ae5e43478331bba5573724448,"KAFKA-13586: Prevent exception thrown during connector update from crashing distributed herder (#12295)

Reviewers: Kvicii <kvicii.yu@gmail.com>, Chris Egerton <chrise@aiven.io>",2022-11-18 09:49:52,Dan Stelljes,Mixed
56ab2f80343d7d842c1b0e3069833106d4fe3259,"KAFKA-14382: wait for current rebalance to complete before triggering followup (#12869)

Fix for the subtle bug described in KAFKA-14382 that was causing rebalancing loops. If we trigger a new rebalance while the current one is still ongoing, it may cause some members to fail the first rebalance if they weren't able to send the SyncGroup request in time (for example due to processing records during the rebalance). This means those consumers never receive their assignment from the original rebalance, and won't revoke any partitions they might have needed to. This can send the group into a loop as each rebalance schedules a new followup cooperative rebalance due to partitions that need to be revoked, and each followup rebalance causes some consumer(s) to miss the SyncGroup and never revoke those partitions.

Reviewers: John Roesler <vvcephei@apache.org>",2022-11-18 22:38:58,A. Sophie Blee-Goldman,Mixed
72b535acaf611e17472820bf53e44b8e0effb627,"KAFKA-14307; Controller time-based snapshots (#12761)

Implement time based snapshot for the controller. The general strategy for this feature is that the controller will use the record-batch's append time to determine if a snapshot should be generated. If the oldest record that has been committed but is not included in the latest snapshot is older than `metadata.log.max.snapshot.interval.ms`, the controller will trigger a snapshot immediately. This is useful in case the controller was offline for more that `metadata.log.max.snapshot.interval.ms` milliseconds.

If the oldest record that has been committed but is not included in the latest snapshot is NOT older than `metadata.log.max.snapshot.interval.ms`, the controller will schedule a `maybeGenerateSnapshot` deferred task.

It is possible that when the controller wants to generate a new snapshot, either because of time or number of bytes, the controller is currently generating a snapshot. In this case the `SnapshotGeneratorManager` was changed so that it checks and potentially triggers another snapshot when the currently in-progress snapshot finishes.

To better support this feature the following additional changes were made:
1. The configuration `metadata.log.max.snapshot.interval.ms` was added to `KafkaConfig` with a default value of one hour.
2. `RaftClient` was extended to return the latest snapshot id. This snapshot id is used to determine if a given record is included in a snapshot.
3. Improve the `SnapshotReason` type to support the inclusion of values in the message.

Reviewers: Jason Gustafson <jason@confluent.io>, Niket Goel <niket-goel@users.noreply.github.com>",2022-11-21 17:30:50,José Armando García Sancio,Mixed
1874f2388cffa7a1e866cbe4aff8b92c9d953b41,"MINOR: Don't call `scheduleAtFixedRate` when period is 0 (#12882)

Since `scheduleAtFixedRate` doesn't allow period <= 0, we should use `schedule` when period == 0.

Reviewers: Luke Chen <showuon@gmail.com>",2022-11-22 11:34:08,行路难行路难,Mixed
cc77a38d280657a0e3969b255f103af4d11c7914,"KAFKA-12610: Implement PluginClassLoader::getResource and getResources (#12805)

Reviewers: Chris Egerton <chrise@aiven.io>",2022-11-23 08:37:51,Greg Harris,Mixed
9d8b4e94b726e195f1c9db56ccc9de808c64d400,"KAFKA-14372: Choose replicas only from ISR for preferred read replica (#12877)

The default replica selector chooses a replica on whether the broker.rack matches the client.rack in the fetch request and whether the offset exists in the follower. If the follower is not in the ISR, we know it's lagging behind which will also lag the consumer behind. there are two cases:
1. the follower recovers and joins the isr. the consumer will no longer fall behind.
2. the follower continues to lag behind. after 5 minutes, the consumer will refresh its preferred read replica and the leader will return the same lagging follower since the offset the consumer fetched up to is capped by the follower's HWM. this can go on indefinitely.

If the replica selector chooses a broker in the ISR then we can ensure that at least every 5 minutes the consumer will consume from an up-to-date replica. 

Reviewers: David Jacot <djacot@confluent.io>",2022-11-24 15:04:43,Jeff Kim,Mixed
d139379e50ee3556c17e8d9ee9af490061212a7d,"KAFKA-14009: Rebalance timeout should be updated when static member rejoins

When consumers use static membership protocol, they can not update the rebalance timeout because the group coordinator simply ignore any new values. This patch fixes this.

Reviewers: David Jacot <djacot@confluent.io>",2022-11-24 15:18:28,zou shengfu,Mixed
c8a228d122b32d9df9f56b43fe55a27a07ee6a12,"MINOR: Improve Scala collection usage (#12900)


Reviewers: Mickael Maison <mickael.maison@gmail.com> , Christo Lolov <christo_lolov@yahoo.com>",2022-11-25 11:14:21,Divij Vaidya,Mixed
fea0eb4ca3c0b18ab876ba3820ee05b0f27a5f8a,"KAFKA-14299: Handle double rebalances better (#12904)

The original implementation of the state updater could not
handle double rebalances within one poll phase correctly,
because it could create tasks more than once if they hadn't
finished initialization yet.

In a55071a, we
moved initialization to the state updater to fix this. However,
with more testing, I found out that this implementation has
it's problems as well: There are problems with locking the
state directory (state updater acquired the lock to the state
directory, so the main thread wouldn't be able to clear the
state directory when closing the task), and benchmarks also
show that this can lead to useless work (tasks are being
initialized, although they will be taken from the thread soon
after in a follow-up rebalance).

In this PR, I propose to revert the original change, and fix
the original problem in a much simpler way: When we
receive an assignment, we simply clear out the
list of tasks pending initialization. This way, no double
tasks instantiations can happen.

The change was tested in benchmarks, system tests,
and the existing unit & integration tests. We also add
the state updater to the smoke integration test, which
triggered the double task instantiations before.

Reviewer: Bruno Cadonna <cadonna@apache.org>",2022-11-28 13:16:44,Lucas Brutschy,Mixed
edfa894eb5e2c4ba9dd262452781c0786be3f29f,"KAFKA-14414: Remove unnecessary usage of ObjectSerializationCache (#12890)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2022-11-28 15:15:34,Divij Vaidya,Mixed
9ea3d0d1c8d975f5d53e3bd74d78e1a9913169c4,"KAFKA-12679: Handle lock exceptions in state updater  (#12875)

In this change, we enable backing off when the state directory
is still locked during initialization of a task. When the state
directory is locked, the task is reinserted into the
initialization queue. We will reattempt to acquire the lock
after the next round of polling.

Tested through a new unit test.

Reviewer: Bruno Cadonna <cadonna@apache.org>",2022-11-28 17:17:14,Lucas Brutschy,Mixed
be032735b39360df1a6de1a7feea8b4336e5bcc0,"KAFKA-14422; Consumer rebalance stuck after new static member joins a group with members not supporting static members (#12909)

When a consumer group on a version prior to 2.3 is upgraded to a newer version and static membership is enabled in the meantime, the consumer group remains stuck, iff the leader is still on the old version.

The issue is that setting `GroupInstanceId` in the response to the leader is only supported from JoinGroup version >= 5 and that `GroupInstanceId` is not ignorable nor handled anywhere else. Hence is there is at least one static member in the group, sending the JoinGroup response to the leader fails with a serialization error.

```
org.apache.kafka.common.errors.UnsupportedVersionException: Attempted to write a non-default groupInstanceId at version 2
```

When this happens, the member stays around until the group coordinator is bounced because a member with a non-null `awaitingJoinCallback` is never expired.

This patch fixes the issue by making `GroupInstanceId` ignorable. A unit test has been modified to cover this.

Reviewers: Jason Gustafson <jason@confluent.io>",2022-11-28 20:15:54,David Jacot,Not TDD
c2c8b246c925cc15efd05ed8b924175bb4672c74,"MINOR: JoinGroup and SyncGroup callbacks should catch exceptions (#12910)

We recently had a bug causing the JoinGroup callback to thrown an exception (https://github.com/apache/kafka/pull/12909). When it happens, the exception is propagated to the caller and the JoinGroup callback is never completed. To make it worst, the member whose callback failed become a zombie because the group coordinator does not expire member with a pending callback.

This patch catch exceptions for both invocation of JoinGroup and SyncGroup callbacks and retry to complete them with a `UNKNOWN_SERVER_ERROR` error if they failed.

Reviewers: Jason Gustafson <jason@confluent.io>",2022-11-29 09:48:31,David Jacot,Mixed
d3ee9341cc894ab14a3ec013c8a590b268438f71,"KAFKA-12476: Prevent herder tick thread from sleeping excessively after slow operations (#12876)

Reviewers: Chris Egerton <chrise@aiven.io>",2022-11-29 09:40:39,Greg Harris,Mixed
98e19b30007b922e7644d5601c80a2180daeca56,"KAFKA-14367; Add `JoinGroup` to the new `GroupCoordinator` interface (#12845)

This patch adds `joinGroup` to the new `GroupCoordinator` interface and updates `KafkaApis` to use it.

For the context, I will do the same for all the other interactions with the current group coordinator. In order to limit the changes, I have chosen to introduce the `GroupCoordinatorAdapter` that translates the new interface to the old one. It is basically a wrapper. This allows keeping the current group coordinator untouched for now and focus on the `KafkaApis` changes. Eventually, we can remove `GroupCoordinatorAdapter`.

Reviewers: Justine Olshan <jolshan@confluent.io>, Jeff Kim <jeff.kim@confluent.io>, Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",2022-11-29 20:39:12,David Jacot,Mixed
3799125c2f5439fd6d981e831f27d93dcd809075,"KAFKA-14339 : Do not perform producerCommit on serializationError when trying offsetWriter flush (#12920)

Reviewers: Chris Egerton <chrise@aiven.io>",2022-11-29 19:06:30,Greg Harris,Mixed
b2d8354e10b99959754e3b7fa495d0c758b78af6,"KAFKA-14414: Fix request/response header size calculation (#12917)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Luke Chen <showuon@gmail.com>",2022-11-30 12:17:21,Divij Vaidya,Mixed
40af3a74507cce9155f4fb4fca317d3c68235d78,"KAFKA-14413: Separate MirrorMaker configurations for each connector (#12899)


Reviewers: Luke Chen <showuon@gmail.com>, Chris Egerton <fearthecellos@gmail.com>, Christo Lolov  <christo_lolov@yahoo.com>",2022-11-30 18:37:37,Mickael Maison,Mixed
6663acff2307c4e2d1e711460826e0ff95c55021,"KAFKA-13152: Add cache size metrics (#12778)

Adds the new DEBUG metric cache-size-bytes-total

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2022-11-30 17:54:37,vamossagar12,Mixed
81d98993ada4d19501570644aa1c31a7722f970e,"KAFKA-13715: add generationId field in subscription (#12748)

Implementation for KIP-792, to add generationId field in ConsumerProtocolSubscription message. So when doing assignment, we'll take from subscription generationId fields it is provided in cooperative rebalance protocol. Otherwise, we'll fall back to original solution to use userData.

Reviewers: David Jacot <djacot@confluent.io>",2022-12-01 14:25:51,Luke Chen,Mixed
b56e71faeecd2fa91adf906490b1e4eb56d9f1d2,"MINOR: Update unit/integration tests to work with the IBM Semeru JDK (#12343)

The IBM Semeru JDK use the OpenJDK security providers instead of the IBM security providers so test for the OpenJDK classes first where possible and test for Semeru in the java.runtime.name system property otherwise.

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Bruno Cadonna <cadonna@apache.org>",2022-12-01 16:22:00,Jonathan Albrecht,Mixed
e11b515ef35475e8940cf2655a6d3a5d2acecbe3,"KAFKA-14017: Implement new KIP-618 APIs in FileStreamSourceConnector (#12355)

Reviewers: Yash Mayya <yash.mayya@gmail.com>,  Maison <mickael.maison@gmail.com>",2022-12-01 11:20:55,Chris Egerton,Mixed
a3f5eb6e35108ed542670e80226fdb6a37e55a0b,"MINOR: Implement EventQueue#size and EventQueue#empty (#12930)

Implement functions to measure the number of events in the event queue.

Reviewers: David Arthur <mumrah@gmail.com>",2022-12-01 09:04:04,Colin Patrick McCabe,Mixed
f5305fb38d8009bc90c5665a2d58830b6d3ddf59,"KAFKA-14367; Add `Heartbeat` to the new `GroupCoordinator` interface (#12848)

This patch adds `heartbeat` to the new `GroupCoordinator` interface and updates `KafkaApis` to use it.

Reviewers: Justine Olshan <jolshan@confluent.io>, Jeff Kim <jeff.kim@confluent.io>, Jason Gustafson <jason@confluent.io>",2022-12-01 19:59:33,David Jacot,Mixed
9b409de1e2719f72e3c17663ce131e40dc459361,"KAFKA-14358; Disallow creation of cluster metadata topic (#12885)

With KRaft the cluster metadata topic (__cluster_metadata) has a different implementation compared to regular topic. The user should not be allowed to create this topic. This can cause issues if the metadata log dir is the same as one of the log dirs.

This change returns an authorization error if the user tries to create the cluster metadata topic.

Reviewers: David Arthur <mumrah@gmail.com>",2022-12-01 18:34:29,José Armando García Sancio,Mixed
5514f372b3e12db1df35b257068f6bb5083111c7,"MINOR: extract jointly owned parts of BrokerServer and ControllerServer (#12837)

Extract jointly owned parts of BrokerServer and ControllerServer into SharedServer. Shut down
SharedServer when the last component using it shuts down. But make sure to stop the raft manager
before closing the ControllerServer's sockets.

This PR also fixes a memory leak where ReplicaManager was not removing some topic metric callbacks
during shutdown. Finally, we now release memory from the BatchMemoryPool in KafkaRaftClient#close.
These changes should reduce memory consumption while running junit tests.

Reviewers: Jason Gustafson <jason@confluent.io>, Ismael Juma <ismael@juma.me.uk>",2022-12-02 00:27:22,Colin Patrick McCabe,Mixed
4877a94885ab8362e1934711e4ccbef027b847f7,"KAFKA-14146: Config file option for MessageReader/MessageFormatter in ConsoleProducer/ConsoleConsumer (KIP-840) (#12175)

This patch implements KIP-840 as outlined here: https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=211884652.

Reviewers: David Jacot <djacot@confluent.io>",2022-12-02 17:03:17,Alexandre Garnier,Mixed
fd05073cc17a788d07d85a87c5c4053317a8ffa2,"KAFKA-14367; Add `SyncGroup` to the new `GroupCoordinator` interface (#12847)

This patch adds `syncGroup` to the new `GroupCoordinator` interface and updates `KafkaApis` to use it.

Reviewers: Justine Olshan <jolshan@confluent.io>, Jeff Kim <jeff.kim@confluent.io>, Jason Gustafson <jason@confluent.io>",2022-12-02 17:15:29,David Jacot,Mixed
7b7e40a536a79cebf35cc278b9375c8352d342b9,"KAFKA-14304 Add RPC changes, records, and config from KIP-866 (#12928)

Reviewers: Colin Patrick McCabe <cmccabe@apache.org>",2022-12-02 19:59:52,David Arthur,Mixed
3929c2651da8e51a841bc86d97fc6b556d95af21,"MINOR: Remove unused `ApiUtils` (#12949)

Also remove `ApiUtilsTest`.

Reviewers: David Jacot <djacot@confluent.io>, dengziming <dengziming1993@gmail.com>",2022-12-03 22:31:15,Ismael Juma,Mixed
93df7f5485e8118a32341c722542fed54ce141fa,"MINOR: Remove unused variables and other minor clean-ups (#12952)

* Remove whitespace before package declaration
* Avoid unnecessary postfix language usage

Reviewers: Luke Chen <showuon@gmail.com>",2022-12-04 20:52:33,Ismael Juma,Not TDD
6ae08c4ee82013166b3d002886bdfe3163d23b4a,"KAFKA-14256: Upgrade from Scala 2.13.8 to 2.13.10 (#12675)

In addition to the version bump, we also had to:
* Update the zinc version
* Workaround compiler warnings via suppression (proper fix in a follow up)
* Adjust `testDeleteTopicDoesNotRetryThrottlingQuotaExceededException` to fix a test failure

Release notes:
* https://github.com/scala/scala/releases/tag/v2.13.9
* https://github.com/scala/scala/releases/tag/v2.13.10

Reviewers: Ismael Juma <ismael@juma.me.uk>",2022-12-04 21:02:43,Matthew de Detrich,Not TDD
df29b17fc40f7c15460988d58bc652c3d66b60f8,"KAFKA-14367; Add `LeaveGroup` to the new `GroupCoordinator` interface (#12850)

This patch adds `leaveGroup` to the new `GroupCoordinator` interface and updates `KafkaApis` to use it.

Reviewers: Justine Olshan <jolshan@confluent.io>, Jeff Kim <jeff.kim@confluent.io>, Jason Gustafson <jason@confluent.io>",2022-12-05 09:28:35,David Jacot,Mixed
fc7fe8f76542d4b8178538235088ad08e5b14751,"MINOR: Remove KafkaTimer (#12950)

It doesn't add much value since lambdas
were introduced in Java 8.

Also remove KafkaTimerTest.

Reviewers: David Jacot <djacot@confluent.io>, Christo Lolov <lolovc@amazon.com>",2022-12-05 06:17:09,Ismael Juma,Mixed
1c10d107fe59aea526dc8062207c36c138684dce,"KAFKA-14293: Basic Auth filter should set the SecurityContext after a successful login (#12846)

Reviewers: Greg Harris <greg.harris@aiven.io>, Chris Egerton <chrise@aiven.io>",2022-12-05 09:38:40,Patrik Marton,Mixed
77e294e7fca31e4e384930aa0c26431cfcc13410,"KAFKA-13602: Adding ability to multicast records (#12803)

This PR implements KIP-837 which enhances StreamPartitioner to multicast records.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, YEONCHEOL JANG",2022-12-06 02:01:38,vamossagar12,Mixed
b6fb95e4c49c25945f1e406eb5086d001a083ef1,"KAFKA-14342: Clear offsets for connector source partitions on tombstone messages (#12800)

Reviewers: Sagar Rao <sagarmeansocean@gmail.com>, Chris Egerton <chrise@aiven.io>",2022-12-06 09:25:41,Yash Mayya,Mixed
5aad085a8e7514c14a17121d316a2e2b2add8bcc,"KAFKA-14417: Producer doesn't handle REQUEST_TIMED_OUT for InitProducerIdRequest, treats as fatal error (#12915)

The broker may return the `REQUEST_TIMED_OUT` error in `InitProducerId` responses when allocating the ID using the `AllocateProducerIds` request. The client currently does not handle this. Instead of retrying as we would expect, the client raises a fatal exception to the application. 

In this patch, we address this problem by modifying the producer to handle `REQUEST_TIMED_OUT` and any other retriable errors by re-enqueuing the request. 

Reviewers: Jason Gustafson <jason@confluent.io>",2022-12-06 11:41:31,Justine Olshan,Mixed
e96e42ead4bde40dcda6e55a7e8ff404afc22b75,"KAFKA-14386; Return TopicAssignment from the ReplicaPlacer (#12892)

This changes the ReplicaPlacer interface to return a class instead of a list of list of integers. There are two reasons for the suggestion. First, as mentioned in the JIRA, it will make the interface, arguably, a bit more readable and understandable by explicitly modeling the idea of topic and partition. Second and more importantly, it makes the interface more extendable in the future. Right now it would be challenging to add more metadata to the response.

Reviewers: José Armando García Sancio <jsancio@apache.org>",2022-12-06 13:01:36,andymg3,Mixed
923fea583bec78b22f26c866821a4bee9025c5c5,"KAFKA-14260: add `synchronized` to `prefixScan` method (#12893)

As a result of ""14260: InMemoryKeyValueStore iterator still throws ConcurrentModificationException"", I'm adding synchronized to prefixScan as an alternative to going back to the ConcurrentSkipList.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2022-12-06 19:39:32,Lucia Cerchie,Not TDD
d23ce20bdfbe5a9598523961cb7cf747ce4f52ef,"KAFKA-14352: Rack-aware consumer partition assignment protocol changes (KIP-881) (#12954)

Reviewers: David Jacot <djacot@confluent.io>",2022-12-07 11:41:21,Rajini Sivaram,Mixed
100e87467135514170bdd4a0614f9b1c37c04c48,"MINOR: Move dynamic config logic to DynamicConfigPublisher (#12958)

Split out the logic for applying dynamic configurations to a KafkaConfig object from
BrokerMetadataPublisher into a new class, DynamicConfigPublisher. This will allow the
ControllerServer to also run this code, in a follow-up change.

Create separate KafkaConfig objects in BrokerServer versus ControllerServer. This is necessary
because the controller will apply configuration changes as soon as its raft client catches up to
the high water mark, whereas the broker will wait for the active controller to acknowledge it has
caught up in a heartbeat response. So when running in combined mode, we want two separate
KafkaConfig objects that are changed at different times.

Minor changes: improve the error message when catching up broker metadata fails. Fix incorrect
indentation in checkstyle/import-control.xml. Invoke AppInfoParser.unregisterAppInfo from
SharedServer.stop so that it happens only when both the controller and broker have shut down.

Reviewers: David Arthur <mumrah@gmail.com>",2022-12-07 10:43:34,Colin Patrick McCabe,Mixed
854dfb5ffcec279d4df003374df8984296d264f1,"KAFKA-14367; Add `ListGroups` to the new `GroupCoordinator` interface (#12853)

This patch adds `listGroups` to the new `GroupCoordinator` interface and updates `KafkaApis` to use it.

Reviewers: Justine Olshan <jolshan@confluent.io>, Jason Gustafson <jason@confluent.io>",2022-12-07 20:42:42,David Jacot,Mixed
36a2f7bfd0827158b085a6a12b61cfc1a54b4c1a,"KAFKA-14432: RocksDBStore relies on finalizers to not leak memory (#12935)

RocksDBStore relied on finalizers to not leak memory (and leaked memory after the upgrade to RocksDB 7).
The problem was that every call to options.statistics creates a new wrapper object that needs to be finalized.

I simplified the logic a bit and moved the ownership of the statistics from ValueProvider to RocksDBStore.

Reviewers: Bruno Cadonna <cadonna@apache.org>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Christo Lolov <lolovc@amazon.com>",2022-12-07 18:25:58,Lucas Brutschy,Mixed
d40561e90ab5b1f5c79d174393645c22b5797eff,"KAFKA-14427 ZK client support for migrations (#12946)

This patch adds support for reading and writing ZooKeeper metadata during a KIP-866 migration.

For reading metadata from ZK, methods from KafkaZkClient and ZkData are reused to ensure we are decoding the JSON consistently.

For writing metadata, we use a new multi-op transaction that ensures only a single controller is writing to ZK. This is similar to the existing multi-op transaction that KafkaController uses, but it also includes a check on the new ""/migration"" ZNode. The transaction consists of three operations:

* CheckOp on /controller_epoch
* SetDataOp on /migration with zkVersion
* CreateOp/SetDataOp/DeleteOp (the actual operation being applied)

In the case of a batch of operations (such as topic creation), only the final MultiOp has a SetDataOp on /migration while the other requests use a CheckOp (similar to /controller_epoch).

Reviewers: Colin Patrick McCabe <cmccabe@apache.org>, dengziming <dengziming1993@gmail.com>",2022-12-08 13:14:01,David Arthur,Mixed
c6590ee28b2751757797346090c27895827b5e44,"KAFKA-14435: Fix `allow.everyone.if.no.acl.found` config behavior for StandardAuthorizer

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Colin Patrick McCabe <cmccabe@apache.org>",2022-12-09 00:58:13,Purshotam Chauhan,Mixed
a0c19c05efa21e47db41398c8feb18bc5227bd6e,"KAFKA-14425; The Kafka protocol should support nullable structs (#12932)

This patch adds support for nullable structs in the Kafka protocol as described in KIP-893 - https://cwiki.apache.org/confluence/display/KAFKA/KIP-893%3A+The+Kafka+protocol+should+support+nullable+structs.

Reviewers: Colin Patrick McCabe <cmccabe@apache.org>",2022-12-08 20:54:29,David Jacot,Mixed
88725669e7c4de153493c9c1ed91466280ee3d6c,"MINOR: Move MetadataQuorumCommand from `core` to `tools` (#12951)

`core` should only be  used for legacy cli tools and tools that require
access to `core` classes instead of communicating via the kafka protocol
(typically by using the client classes).

Summary of changes:
1. Convert the command implementation and tests to Java and move it to
    the `tools` module.
2. Introduce mechanism to capture stdout and stderr from tests.
3. Change `kafka-metadata-quorum.sh` to point to the new command class.
4. Adjusted the test classpath of the `tools` module so that it supports tests
    that rely on the `@ClusterTests` annotation.
5. Improved error handling when an exception different from `TerseFailure` is
    thrown.
6. Changed `ToolsUtils` to avoid usage of arrays in favor of `List`.

Reviewers: dengziming <dengziming1993@gmail.com>",2022-12-09 09:22:58,Ismael Juma,Mixed
d9b139220ee253da673af44d58dc87bd184188f1,"KAFKA-14318: KIP-878, Introduce partition autoscaling configs (#12962)

First PR for KIP-878: Internal Topic Autoscaling for Kafka Streams

Introduces two new configs related to autoscaling in Streams: a feature flag and retry timeout. This PR just adds the configs and gets them passed through to the Streams assignor where they'll ultimately be needed/used

Reviewers: Bill Bejeck <bill@confluent.io>, Walker Carlson <wcarlson@confluent.io>",2022-12-09 15:02:36,A. Sophie Blee-Goldman,Mixed
43f39c2e602bc718609ba34ad15087810f76d382,"KAFKA-14379: Consumer should refresh preferred read replica on update metadata (#12956)

The consumer (fetcher) used to refresh the preferred read replica on
three conditions:
    
1. the consumer receives an OFFSET_OUT_OF_RANGE error
2. the follower does not exist in the client's metadata (i.e., offline)
3. after metadata.max.age.ms (5 min default)
    
For other errors, it will continue to reach to the possibly unavailable
follower and only after 5 minutes will it refresh the preferred read
replica and go back to the leader.
    
Another problem is that the client might have stale metadata and not
send fetches to preferred replica, even after the leader redirects to
the preferred replica.
    
A specific example is when a partition is reassigned. the consumer will
get NOT_LEADER_OR_FOLLOWER which triggers a metadata update but the
preferred read replica will not be refreshed as the follower is still
online. it will continue to reach out to the old follower until the
preferred read replica expires.
    
The consumer can instead refresh its preferred read replica whenever it
makes a metadata update request, so when the consumer receives i.e.
NOT_LEADER_OR_FOLLOWER it can find the new preferred read replica without
waiting for the expiration.
    
Generally, we will rely on the leader to choose the correct preferred
read replica and have the consumer fail fast (clear preferred read replica
cache) on errors and reach out to the leader.

Co-authored-by: Jeff Kim <jeff.kim@confluent.io>

Reviewers: David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>",2022-12-12 09:55:22,Artem Livshits,Mixed
b2dea17041157ceee741041d23783ff993b88ef1,"MINOR: Introduce MetadataProvenance and ImageReWriter (#12964)

Introduce MetadataProvenance to encapsulate the three-tuple of (offset, epoch, timestamp) that is
associated with each MetadataImage, as well as each on-disk snapshot. Also introduce a builder
for MetadataDelta.

Remove offset and epoch tracking from MetadataDelta. We do not really need to know this information
until we are creating the final MetadataImage object. Therefore, this bookkeeping should be done by
the metadata loading code, not inside the delta code, like the other bookkeeping. This simplifies a
lot of tests, as well as simplifying RecordTestUtils.  It also makes more sense for snapshots, where
the offset and epoch are the same for every record.

Add ImageReWriter, an ImageWriter that applies records to a MetadataDelta. This is useful when you
need to create a MetadataDelta object that holds the contents of a MetadataImage. This will be
used in the new image loader code (coming soon).

Add ImageWriterOptionsTest to test ImageWriterOptions.

Reviewers: David Arthur <mumrah@gmail.com>",2022-12-12 09:52:06,Colin Patrick McCabe,Mixed
4a9c0fa4a4f60d4377f68c3b25caf32e1d0239b7,"KAFKA-14367; Add `DescribeGroups` to the new `GroupCoordinator` interface (#12855)

This patch adds `describeGroups` to the new `GroupCoordinator` interface and updates `KafkaApis` to use it.

Reviewers: Justine Olshan <jolshan@confluent.io>, Jason Gustafson <jason@confluent.io>",2022-12-13 09:19:21,David Jacot,Mixed
7ff779f3f4ac59f449f526a543d4bcfd00c0088f,"KAFKA-14285: Delete quota node in zookeeper when configs are empty (#12729)

The PR resolve issue KAFKA-14285. After doing changeConfigs, check and clean quota nodes if configs are empty, to avoid infinite increasement of quota nodes in zookeeper

Reviewers: Luke Chen <showuon@gmail.com>, Igor Soarez <soarez@apple.com>, dengziming <dengziming1993@gmail.com>",2022-12-13 17:04:11,Junyang Liu,Mixed
26a4d420726f4c63da6ea5a045694a6c6ac87207,"MINOR: Pass snapshot ID directly in `RaftClient.createSnapshot` (#12981)

Let `RaftClient.createSnapshot` take the snapshotId directly instead of the committed offset/epoch (which may not exist). 

Reviewers: José Armando García Sancio <jsancio@apache.org>",2022-12-13 10:44:56,Jason Gustafson,Not TDD
67c72596afe58363eceeb32084c5c04637a33831,"KAFKA-14448 Let ZK brokers register with KRaft controller (#12965)

Prior to starting a KIP-866 migration, the ZK brokers must register themselves with the active
KRaft controller. The controller waits for all brokers to register in order to verify that all the
brokers can

A) Communicate with the quorum
B) Have the migration config enabled
C) Have the proper IBP set

This patch uses the new isMigratingZkBroker field in BrokerRegistrationRequest and
RegisterBrokerRecord. The type was changed from int8 to bool for BrokerRegistrationRequest (a
mistake from #12860). The ZK brokers use the existing BrokerLifecycleManager class to register and
heartbeat with the controllers.

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",2022-12-13 13:15:21,David Arthur,Mixed
87b9c572c685f95d57b28749698dcd017381aec2,"MINOR: Change KRaft ZK controller registration algorithm (#12973)

Increment the value in ""/controller_epoch"" when registering a KRaft controller as the active controller. Use the ""kraftControllerEpoch"" stored under ""/controller"" to ensure we are registering a newer KRaft controller.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2022-12-14 08:37:06,David Arthur,Mixed
9b23d9305d2c35fc3438b38e886e9f862856aa3a,"KAFKA-14395: add config to configure client supplier (#12944)

Implements KIP-884.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2022-12-14 09:17:27,Hao Li,Mixed
f8556fe7915875a47dca7018f010bbc759c32baa,"KAFKA-14367; Add `DeleteGroups` to the new `GroupCoordinator` interface (#12858)

This patch adds `deleteGroups` to the new `GroupCoordinator` interface and updates `KafkaApis` to use it.

Reviewers: Omnia G H Ibrahim <o.g.h.ibrahim@gmail.com>, Justine Olshan <jolshan@confluent.io>, Jason Gustafson <jason@confluent.io>",2022-12-15 09:29:56,David Jacot,Mixed
8b045dcbf6b89e1a9594ff95642d4882765e4b0d,"KAFKA-14446: API forwarding support from zkBrokers to the Controller (#12961)

This PR enables brokers which are upgrading from ZK mode to KRaft mode to forward certain metadata
change requests to the controller instead of applying them directly through ZK. To faciliate this,
we now support EnvelopeRequest on zkBrokers (instead of only on KRaft nodes.)

In BrokerToControllerChannelManager, we can now reinitialize our NetworkClient. This is needed to
handle the case when we transition from forwarding requests to a ZK-based broker over the
inter-broker listener, to forwarding requests to a quorum node over the controller listener.

In MetadataCache.scala, distinguish between KRaft and ZK controller nodes with a new type,
CachedControllerId.

In LeaderAndIsrRequest, StopReplicaRequest, and UpdateMetadataRequest, switch from sending both a
zk and a KRaft controller ID to sending a single controller ID plus a boolean to express whether it
is KRaft. The previous scheme was ambiguous as to whether the system was in KRaft or ZK mode when
both IDs were -1 (although this case is unlikely to come up in practice). The new scheme avoids
this ambiguity and is simpler to understand.

Reviewers: dengziming <dengziming1993@gmail.com>, David Arthur <mumrah@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",2022-12-15 14:16:41,Akhilesh C,Mixed
a46d16e7abab5ed1d34c273f52adc12677830420,"Removing Multicasting partitioner for IQ (#12977)

Follow up PR for KIP-837. We don't want to allow multicasting for IQ. This PR imposes that restriction.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2022-12-15 15:09:41,vamossagar12,Mixed
29c09e2ca199386efbcb05cdfb10b7376b956233,"MINOR: ControllerServer should use the new metadata loader and snapshot generator (#12983)

This PR introduces the new metadata loader and snapshot generator. For the time being, they are
only used by the controller, but a PR for the broker will come soon.

The new metadata loader supports adding and removing publishers dynamically. (In contrast, the old
loader only supported adding a single publisher.) It also passes along more information about each
new image that is published. This information can be found in the LogDeltaManifest and
SnapshotManifest classes.

The new snapshot generator replaces the previous logic for generating snapshots in
QuorumController.java and associated classes. The new generator is intended to be shared between
the broker and the controller, so it is decoupled from both.

There are a few small changes to the old snapshot generator in this PR. Specifically, we move the
batch processing time and batch size metrics out of BrokerMetadataListener.scala and into
BrokerServerMetrics.scala.

Finally, fix a case where we are using 'is' rather than '==' for a numeric comparison in
snapshot_test.py.

Reviewers: David Arthur <mumrah@gmail.com>",2022-12-15 16:53:07,Colin Patrick McCabe,Mixed
e3585a4cd5ddb5b8475a49c38143d18e7c640bfe,"MINOR: Document Offset and Partition 0-indexing, fix typo (#12753)

Add comments to clarify that both offsets and partitions are 0-indexed, and fix a minor typo. Clarify which offset will be retrieved by poll() after seek() is used in various circumstances. Also added integration tests.

Reviewers: Luke Chen <showuon@gmail.com>",2022-12-16 17:12:40,Daniel Scanteianu,Not TDD
f247aac96a1c16ac7255496cb2815223386eae9a,"KAFKA-14496: Wrong Base64 encoder used by OIDC OAuthBearerLoginCallbackHandler (#13000)

The OAuth code to generate the Authentication header was incorrectly
using the URL-safe base64 encoder. For client IDs and/or secrets with
dashes and/or plus signs would not be encoded correctly, leading to the
OAuth server to reject the credentials.

This change uses the correct base64 encoder, per RFC-7617.

Co-authored-by: Endre Vig <vendre@gmail.com>",2022-12-16 19:44:41,Kirk True,Mixed
7146ac57ba9ddd035dac992b9f188a8e7677c08d,"[KAFKA-13369] Follower fetch protocol changes for tiered storage. (#11390)

This PR implements the follower fetch protocol as mentioned in KIP-405.

Added a new version for ListOffsets protocol to receive local log start offset on the leader replica. This is used by follower replicas to find the local log star offset on the leader.

Added a new version for FetchRequest protocol to receive OffsetMovedToTieredStorageException error. This is part of the enhanced fetch protocol as described in KIP-405.

We introduced a new field locaLogStartOffset to maintain the log start offset in the local logs. Existing logStartOffset will continue to be the log start offset of the effective log that includes the segments in remote storage.

When a follower receives OffsetMovedToTieredStorage, then it tries to build the required state from the leader and remote storage so that it can be ready to move to fetch state.

Introduced RemoteLogManager which is responsible for

initializing RemoteStorageManager and RemoteLogMetadataManager instances.
receives any leader and follower replica events and partition stop events and act on them
also provides APIs to fetch indexes, metadata about remote log segments.
Followup PRs will add more functionality like copying segments to tiered storage, retention checks to clean local and remote log segments. This will change the local log start offset and make sure the follower fetch protocol works fine for several cases.

You can look at the detailed protocol changes in KIP: https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage#KIP405:KafkaTieredStorage-FollowerReplication

Co-authors: satishd@apache.org, kamal.chandraprakash@gmail.com, yingz@uber.com

Reviewers: Kowshik Prakasam <kprakasam@confluent.io>, Cong Ding <cong@ccding.com>, Tirtha Chatterjee <tirtha.p.chatterjee@gmail.com>, Yaodong Yang <yangyaodong88@gmail.com>, Divij Vaidya <diviv@amazon.com>, Luke Chen <showuon@gmail.com>, Jun Rao <junrao@gmail.com>",2022-12-17 09:36:44,Satish Duggana,Mixed
95dc9d9eede40deb303c9c2b3365bfb0abdd3330,"Move IndexEntry and related to storage module (#12993)

For broader context on this change, please check:

* KAFKA-14470: Move log layer to storage module

Reviewers: dengziming <dengziming1993@gmail.com>",2022-12-17 10:07:11,Ismael Juma,Mixed
8d09fc9935fc976d730801c2c0f86556affe6e09,"MINOR: Fix compiler errors in `RemoteIndex*` related to `OffsetPosition` (#13008)

#11390 and #12993 were merged in relatively quick succession, which resulted in compiler errors that weren't present when each change was on top of trunk.

Reviewers: Mickael Maison <mickael.maison@gmail.com>",2022-12-17 20:25:33,Ismael Juma,Mixed
e3cb2deff6e983aeb1744d4403af4b3c9aa85e57,"KAFKA-14466: Move ClassloaderAwareRemoteStorageManager to storage module (#13013)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2022-12-19 06:37:33,Satish Duggana,Mixed
22bb3e7a5853c8f54fc030273f83f1db8c99648f,"KAFKA-14417: Address incompatible error code returned by broker from `InitProducerId` (#12968)

Older clients can not handle the `REQUEST_TIMED_OUT` error that is returned from `InitProducerId` when the next producerId block cannot be fetched from the controller. In this patch, we return `COORDINATOR_LOAD_IN_PROGRESS` instead which is retriable.

Reviewers: Jason Gustafson <jason@confluent.io>",2022-12-19 09:33:11,Justine Olshan,Mixed
4548c272ae39a6630174ab428bc82fce7c98f7fd,"KAFKA-14264; New logic to discover group coordinator (#12862)

[KAFKA-14264](https://issues.apache.org/jira/browse/KAFKA-14264)
In this patch, we refactored the existing FindCoordinator mechanism. In particular, we first centralize all of the network operation (send, poll) in `NetworkClientDelegate`, then we introduced a RequestManager interface that is responsible to handle the timing of different kind of requests, based on the implementation.  In this path, we implemented a `CoordinatorRequestManager` which determines when to create an `UnsentRequest` upon polling the request manager.

Reviewers: Jason Gustafson <jason@confluent.io>",2022-12-19 09:48:52,Philip Nee,Mixed
ea65d74f6bc7f4a94f7f037cbf0103e925a9ddbb,"MINOR: No error with zero results state query (#13002)

This PR updates StateQueryResult.getOnlyPartitionResult() to not throw an IllegaArgumentException when there are 0 query results.

Added a test that will fail without this patch

Reviewers: John Roesler<vvcephei@apache.org>",2022-12-19 13:39:06,Bill Bejeck,Mixed
802fb11d4ea276db0d44d591f6e0588192acfef6,"KAFKA-14529 Use the MetadataVersion from ClusterConfig in ZK tests (#13020)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2022-12-19 14:30:21,David Arthur,Not TDD
e2678d57d0919aaa97effe2ee7591cd6b85b5303,"KAFKA-14472: Move TransactionIndex and related to storage module (#12996)

For broader context on this change, please check:

* KAFKA-14470: Move log layer to storage module

Reviewers: Jun Rao <junrao@gmail.com>, Satish Duggana <satishd@apache.org>",2022-12-19 11:31:37,Ismael Juma,Mixed
26fcf73feb1d2a2f8f517a7a0d4bdede9d1e5ca9,"MINOR: Use `withClassLoader` in a couple more places (#13018)

Instead of try/finally.

Reviewers: Ron Dagostino <rndgstn@gmail.com>",2022-12-19 16:30:54,Ismael Juma,Not TDD
429a2570b095a26fbf284069a8308012c200f935,"MINOR: Don't throw if MirrorMaker topics already exist (#13005)


Reviewers: Luke Chen <showuon@gmail.com>",2022-12-20 14:33:32,Mickael Maison,Mixed
71ea16f8eb28e2cc5731a94abfefdb3e57b7aecd,"KAFKA-14531 Fix controller snapshot interval (#13019)

This patch applies the necessary conversion of milliseconds to nanoseconds for SnapshotGenerator. 

Reviewers: Colin P. McCabe <cmccabe@apache.org>, José Armando García Sancio <jsancio@gmail.com>",2022-12-20 10:20:41,David Arthur,Not TDD
44b3177a087ff809a9d95a27b63b10e00aa4da7d,"KAFKA-14457; Controller metrics should only expose committed data (#12994)

The controller metrics in the controllers has three problems. 1) the active controller exposes uncommitted data in the metrics. 2) the active controller doesn't update the metrics when the uncommitted data gets aborted. 3) the controller doesn't update the metrics when the entire state gets reset.

We fix these issues by only updating the metrics when processing committed metadata records and reset the metrics when the metadata state is reset.

This change adds a new type `ControllerMetricsManager` which processes committed metadata records and updates the metrics accordingly. This change also removes metrics updating responsibilities from the rest of the controller managers. 

Reviewers: Ron Dagostino <rdagostino@confluent.io>",2022-12-20 10:55:14,José Armando García Sancio,Mixed
82c9216c77579967831e230c9baa6944da724d53,"KAFKA-14474: Move OffsetIndex to storage module (#13009)

For broader context on this change, please check:

* KAFKA-14470: Move log layer to storage module

Reviewers: Jun Rao <junrao@gmail.com>, Satish Duggana <satishd@apache.org>",2022-12-20 11:45:47,Ismael Juma,Mixed
7b634c7034c87c7419a1860070cebffcf4bfd223,"KAFKA-14521: Replace BrokerCompressionCodec with BrokerCompressionType (#13011)

This is a requirement for:

* KAFKA-14477: Move LogValidator to storage module.

For broader context on this change, please check:

* KAFKA-14470: Move log layer to storage module

Reviewers: dengziming <dengziming1993@gmail.com>",2022-12-20 11:53:49,Ismael Juma,Mixed
c4f10364cda6435f88688b1bfd56c5c52448f821,"KAFKA-14475: Move TimeIndex/LazyIndex to storage module (#13010)

For broader context on this change, please check:

* KAFKA-14470: Move log layer to storage module

 Reviewers: Jun Rao <junrao@gmail.com>, Satish Duggana <satishd@apache.org>",2022-12-20 19:08:40,Ismael Juma,Mixed
6a6c7302415c799fb00726a896c6e916fb029b5e,"KAFKA-14532: Correctly handle failed fetch when partitions unassigned (#13023)

The failure handling code for fetches could run into an IllegalStateException if a fetch response came back with a failure after the corresponding topic partition has already been removed from the assignment.

Reviewers: David Jacot <djacot@confluent.io>",2022-12-21 09:17:11,Lucas Brutschy,Not TDD
2dcf306ef839ada65ba021e0a9c0a046b754adf3,"KAFKA-14132: Replace EasyMock and PowerMock with Mockito in connect/runtime/ErrorHandlingTaskTest (#12735)

Reviewers: Divij Vaidya <divijvaidya13@gmail.com>, Chris Egerton <chrise@aiven.io>",2022-12-21 11:41:03,Shekhar Rajak,Not TDD
755e04a41dfd00dd4587b0fe0980befd0ae5c433,"KAFKA-14446: code style improvements for broker-to-controller forwarding (#13001)

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>, David Arthur <mumrah@gmail.com>",2022-12-21 11:17:27,Akhilesh C,Not TDD
e8232edd24c6dd31bc58d29967d552f3dc6cf831,"KAFKA-14477: Move LogValidator and related to storage module (#13012)

Also improved `LogValidatorTest` to cover a bug that was originally
only caught by `LogAppendTimeTest`.

For broader context on this change, please check:

* KAFKA-14470: Move log layer to storage module

Reviewers: Jun Rao <junrao@gmail.com>",2022-12-21 16:57:02,Ismael Juma,Mixed
06af8fc6309db3b917929afaccb427f8b90c7004,"KAFKA-14549: Move LogDirFailureChannel to storage module (#13041)

For broader context on this change, please check:

* KAFKA-14470: Move log layer to storage module

Reviewers: dengziming <dengziming1993@gmail.com>, Mickael Maison <mickael.maison@gmail.com>, Satish Duggana <satishd@apache.org>, Ismael Juma <ismael@juma.me.uk>",2022-12-23 07:13:43,Federico Valeri,Mixed
871289c5c4b01fd0a362281bd3fd96ad87610096,"KAFKA-14476: Move OffsetMap and related to storage module (#13042)

For broader context on this change, please check:

* KAFKA-14470: Move log layer to storage module

Reviewers: dengziming <dengziming1993@gmail.com>, Satish Duggana <satishd@apache.org>, Federico Valeri <fedevaleri@gmail.com>",2022-12-23 08:19:00,Ismael Juma,Mixed
13d1c086f39531e2a47fe8475c4fd79e300adabd,"KAFKA-14544 The ""is-future"" should be removed from metrics tags after future log becomes current log (#12979)

Reviewers: Luke Chen <showuon@gmail.com>",2022-12-26 15:44:18,Chia-Ping Tsai,Mixed
8184ada6a5c98cd637e8d323c56dbe6b20d582bd,"KAFKA-14543: Move LogOffsetMetadata to storage module (#13038)

Reviewers: Ismael Juma <ismael@juma.me.uk>, dengziming <dengziming1993@gmail.com>, Satish Duggana <satishd@apache.org>, Federico Valeri <fedevaleri@gmail.com>",2022-12-27 17:12:02,Mickael Maison,Mixed
9c6c6bfa2bdf97d546ebb7721bc19d15c955b746,"KAFKA-13817 Always sync nextTimeToEmit with wall clock (#12166)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Hao Li <hli@confluent.io>",2022-12-28 12:32:54,Qing,Mixed
026105d05f66d15544db6468f800fba6a6d4e171,"KAFKA-14550: Move SnapshotFile and CorruptSnapshotException to storage module (#13039)

For broader context on this change, see:

* KAFKA-14470: Move log layer to storage module

Reviewers: Ismael Juma <ismael@juma.me.uk>",2023-01-02 07:31:40,Satish Duggana,Mixed
96d9710c17b34d4e80259f09845d21de66a5efaf,"KAFKA-14478: Move LogConfig/CleanerConfig and related to storage module (#13049)

Additional notable changes to fix multiple dependency ordering issues:

* Moved `ConfigSynonym` to `server-common`
* Moved synonyms from `LogConfig` to `ServerTopicConfigSynonyms `
* Removed `LogConfigDef` `define` overrides and rely on
   `ServerTopicConfigSynonyms` instead.
* Moved `LogConfig.extractLogConfigMap` to `KafkaConfig`
* Consolidated relevant defaults from `KafkaConfig`/`LogConfig` in the latter
* Consolidate relevant config name definitions in `TopicConfig`
* Move `ThrottledReplicaListValidator` to `storage`

Reviewers: Satish Duggana <satishd@apache.org>, Mickael Maison <mickael.maison@gmail.com>",2023-01-04 02:42:52,Ismael Juma,Mixed
ad94dc2134474c9d790fe0bb79c0d390c562846a,"KAFKA-14545: Make MirrorCheckpointTask.checkpoint handle null OffsetAndMetadata gracefully (#13052)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Greg Harris <gharris1727@gmail.com>",2023-01-04 12:02:52,csolidum,Mixed
ef3b581ff0c4eba1fbf1e1d60507365ef141f0c3,"KAFKA-14571: Include rack info in ZkMetadataCache.getClusterMetadata (#13073)

ZkMetadataCache.getClusterMetadata returns a Cluster object where the aliveNodes were
missing their rack info.

Problem: when ZkMetadataCache updates the metadataSnapshot, includes the rack in
aliveBrokers but not in aliveNodes

Trivial fix with matching assertion in existing unit test.

Note that the Cluster object returned from `MetadataCache.getClusterMetadata(...)`
is passed to `ClientQuotaCallback.updateClusterMetadata(...)`
so it is used, though not by clients, but by service providers.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2023-01-04 14:24:16,Edoardo Comar,Mixed
0e51a2026c9f0e43e69e848075f75d241e85b796,"KAFKA-14458: Introduce RPC support during ZK migration #13028

Add infrastructure for sending UpdateMetadataRequest and LeaderAndIsr RPCs during the migration
process from ZK to KRaft. The new classes use ControllerChannelManager to send the RPCs.  The
information to send comes from MetadataDelta and MetadataImage.

Reviewers: David Arthur <mumrah@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",2023-01-04 16:54:58,Akhilesh Chaganti,Mixed
b99be76ff1e79b10dd284375c41437f214ca587f,"KAFKA-9087 Replace log high watermark by future log high watermark wh… (#13075)

Reviewers: Ismael Juma <ismael@juma.me.uk>, Justine Olshan <jolshan@confluent.io>, Jun Rao <junrao@gmail.com>",2023-01-07 15:24:36,Chia-Ping Tsai,Mixed
2dec39d6e49da4cfb502da3e84d4f9c50508e809,"KAFKA-14558: Move/Rewrite LastRecord, TxnMetadata, BatchMetadata, ProducerStateEntry, and ProducerAppendInfo to the storage module (#13043)

For broader context on this change, see:
* KAFKA-14470: Move log layer to storage module.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2023-01-07 20:13:38,Satish Duggana,Mixed
db490707606855c265bc938e1b236070e0e2eba5,"KAFKA-14493: Introduce Zk to KRaft migration state machine STUBs in KRaft controller. (#12998)

This patch introduces a preliminary state machine that can be used by KRaft
controller to drive online migration from Zk to KRaft.

MigrationState -- Defines the states we can have while migration from Zk to
KRaft.

KRaftMigrationDriver -- Defines the state transitions, and events to handle
actions like controller change, metadata change, broker change and have
interfaces through which it claims Zk controllership, performs zk writes and
sends RPCs to ZkBrokers.

MigrationClient -- Interface that defines the functions used to claim and
relinquish Zk controllership, read to and write from Zk.

Co-authored-by: David Arthur <mumrah@gmail.com>
Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-01-09 10:44:11,Akhilesh C,Mixed
896573f9bc2c6a695cb265df027c4f21214bc933,"KAFKA-14279: Add 3.3.x streams system tests (#13077)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-01-09 23:37:05,José Armando García Sancio,Not TDD
def8d724c82f84964f353f8cf45ef8d52247b2cc,"KAFKA-14540: Fix DataOutputStreamWritable#writeByteBuffer (#13032)

When writing a ByteBuffer backed by a HeapBuffer to a DataOutputStream, it is necessary to pass in the offset and the position, not just the position. It is also necessary to pass the remain length, not the limit. The current code results in writing the wrong data to DataOutputStream. While the DataOutputStreamWritable is used in the project, I do not see any references that would utilize this code path, so this bug fix is relatively minor.

I added a new test to cover the exact bug. The test fails without this change.",2023-01-10 11:50:07,Michael Marshall,Mixed
6e7e2e08a982c6667476a932e2571f8ef4b70dc3,"KAFKA-12558: Do not prematurely mutate internal partition state in Mirror Maker 2 (#11818)

Reviewers: Greg Harris <greg.harris@aiven.io>, Chris Egerton <chrise@aiven.io>",2023-01-10 09:46:25,emilnkrastev,Mixed
43f531d87a0ad6c49f0cfc343e8d21c7319ad397,"MINOR: Implement toString method for TopicAssignment and PartitionAssignment (#13101)

Implements `toString` method for classes `TopicAssignment` and` PartitionAssignment`. Also removes the `final` keyword from the constructor arguments for consistency.

Reviewers: José Armando García Sancio <jsancio@apache.org>",2023-01-10 10:00:59,andymg3,Mixed
2fc1875d0b1e5cd58727bbe80ee6d06602671993,"KAFKA-14557; Lock metadata log dir (#13058)

This change makes sure that Kafka grabs a log dir lock in the following additional cases:

1. When a Kafka node runs in controller only. The current implementation doesn't grab a file lock because the LogManager is never instantiated.
2. When the metadata log dir is different from the log dir(s). The current implementation of LogManager doesn't load or grab a lock on the metadata dir.

Reviewers: Ron Dagostino <rdagostino@confluent.io> , dengziming <dengziming1993@gmail.com>",2023-01-10 10:18:40,José Armando García Sancio,Mixed
24a86423e9907b751d98fddc7196332feea2b48d,"KAFKA-14367; Add `OffsetFetch` to the new `GroupCoordinator` interface (#12870)

This patch adds OffsetFetch to the new GroupCoordinator interface and updates KafkaApis to use it. 

Reviewers: Philip Nee <pnee@confluent.i>, Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-01-10 11:38:31,David Jacot,Mixed
8ac644d2b198a386f67b213db35bb9cbd8eda073,"KAFKA-14607: Move Scheduler/KafkaScheduler to server-common (#13092)

There were some concurrency inconsistencies in `KafkaScheduler` flagged by spotBugs
that had to be fixed, summary of changes below:
* Executor is `volatile`
* We always synchronize and check `isStarted` as the first thing within the critical
   section when a mutating operation is performed.
* We don't synchronize (but ensure the executor is not null in a safe way) in read-only
   operations that operate on the executor.

With regards to `MockScheduler/MockTask`:
* Set the type of `nextExecution` to `AtomicLong` and replaced inconsistent synchronization
* Extracted logic into `MockTask.rescheduleIfPeriodic`

Tweaked the `Scheduler` interface a bit:
* Removed `unit` parameter since we always used `ms` except one invocation
* Introduced a couple of `scheduleOnce` overloads to replace the usage of default
   arguments in Scala
* Pulled up `resizeThreadPool` to the interface and removed `isStarted` from the
  interface.

Other cleanups:
* Removed spotBugs exclusion affecting `kafka.log.LogConfig`, which no longer exists.

For broader context, see:
* KAFKA-14470: Move log layer to storage module

Reviewers: Jun Rao <junrao@gmail.com>",2023-01-10 23:51:58,Ismael Juma,Mixed
0bb05d8679b684ad8fbb2eb40dfc00066186a75a,"KAFKA-14304 Use boolean for ZK migrating brokers in RPC/record (#13103)

With the new broker epoch validation logic introduced in #12998, we no longer need the ZK broker epoch to be sent to the KRaft controller. This patch removes that epoch and replaces it with a boolean.

Another small fix is included in this patch for controlled shutdown in migration mode. Previously, if a ZK broker was in migration mode, it would always try to do controlled shutdown via BrokerLifecycleManager. Since there is no ordering dependency between bringing up ZK brokers and the KRaft quorum during migration, a ZK broker could be running in migration mode, but talking to a ZK controller. A small check was added to see if the current controller is ZK or KRaft before decided which controlled shutdown to attempt.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-01-11 14:36:56,David Arthur,Mixed
22606a0a4d45dfb37b72a40de3728778ac4ffe84,"KAFKA-14530: Check state updater more often (#13017)

In the new state restoration code, the state updater needs to be checked regularly
by the main thread to transfer ownership of tasks back to the main thread once the
state of the task is restored. The more often we check this, the faster we can
start processing the tasks.

Currently, we only check the state updater once in every loop iteration of the state
updater. And while we couldn't observe this to be strictly not often enough, we can
increase the number of checks easily by moving the check inside the inner processing
loop. This would mean that once we have iterated over `numIterations` records, we can
already start processing tasks that have finished restoration in the meantime.

Reviewer: Bruno Cadonna <cadonna@apache.org>",2023-01-12 12:40:07,Lucas Brutschy,Mixed
e6669672ef11ee869e3e4e5ae04bad6c505d5342,"KAFKA-14367; Add `OffsetCommit` to the new `GroupCoordinator` interface (#12886)

This patch adds `OffsetCommit` to the new `GroupCoordinator` interface and updates `KafkaApis` to use it.

Reviewers: Omnia G H Ibrahim <o.g.h.ibrahim@gmail.com>, Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-01-12 18:05:49,David Jacot,Mixed
8478bbb5892d09bcd3f7d2794db1b5db1a29c077,"KAFKA-14601: Improve exception handling in KafkaEventQueue #13089

If KafkaEventQueue gets an InterruptedException while waiting for a condition variable, it
currently exits immediately. Instead, it should complete the remaining events exceptionally and
then execute the cleanup event. This will allow us to finish any necessary cleanup steps.

In order to do this, we require the cleanup event to be provided when the queue is contructed,
rather than when it's being shut down.

Also, handle cases where Event#handleException itself throws an exception.

Remove timed shutdown from the event queue code since nobody was using it, and it adds complexity.

Add server-common/src/test/resources/test/log4j.properties since this gradle module somehow avoided
having a test log4j.properties up to this point.

Reviewers: David Arthur <mumrah@gmail.com>",2023-01-12 10:03:14,Colin Patrick McCabe,Mixed
0d9a7022a4486e08dc4bd71e2fd7632ecdd3b76f,"KAFKA-14612: Make sure to write a new topics ConfigRecords to metadata log iff the topic is created (#13104)

### JIRA
https://issues.apache.org/jira/browse/KAFKA-14612

### Details
Makes sure we emit `ConfigRecord`s for a topic iff it actually gets created. Currently, we might emit `ConfigRecord`s even if the topic creation fails later in the `createTopics` method.

I created a new method `incrementalAlterConfig` in `ConfigurationControlManager` that is similar to `incrementalAlterConfig` but it just handles one config at a time. This is used in `ReplicationControlManager` for each topic. By handling one topic's config at a time, it's easier to isolate each topic's config records. This enables us to make sure we only write config records for topics that get created.

I refactored `incrementalAlterConfigResource` to return an `ApiError`. This made it easier to implement the new method `incrementalAlterConfig` in `ConfigurationControlManager` because it then doesnt have to search in the `Map` for the result.

### Testing
Enhanced pre-existing test `ReplicationControlManagerTest.testCreateTopicsWithConfigs`. I ran the tests without the changes to `ReplicationControlManager` and made sure each assertion ends up failing. Also ran `./gradlew metadata:test --tests org.apache.kafka.controller.ReplicationControlManagerTest`.

Reviewers: Jason Gustafson <jason@confluent.io>",2023-01-12 16:23:57,andymg3,Mixed
111f02cc74cd3a742f9b6b6cd7f183ec2a494354,"KAFKA-14568: Move FetchDataInfo and related to storage module (#13085)

Part of KAFKA-14470: Move log layer to storage module.

Reviewers: Ismael Juma <ismael@juma.me.uk>

Co-authored-by: Ismael Juma <ismael@juma.me.uk>",2023-01-12 21:32:23,Federico Valeri,Mixed
a2926edc2f1b59b0d69524fac28ad77ffe56ffcf,"KAFKA-14367; Add `TxnOffsetCommit` to the new `GroupCoordinator` interface (#12901)

This patch adds `TxnOffsetCommit` to the new `GroupCoordinator` interface and updates `KafkaApis` to use it.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-01-13 09:54:54,David Jacot,Mixed
a382acd31d1b53cd8695ff9488977566083540b1,KAFKA-13709 (follow-up): Avoid mention of 'exactly-once delivery' or 'delivery guarantees' in Connect (#13106),2023-01-13 09:19:29,Chris Egerton,Mixed
058d8d530b0cda41c4f709b57621043ad858cd47,"KAFKA-14618; Fix off by one error in snapshot id (#13108)

The KRaft client expects the offset of the snapshot id to be an end offset. End offsets are
exclusive. The MetadataProvenance type was createing a snapshot id using the last contained offset
which is inclusive. This change fixes that and renames some of the fields to make this difference
more obvious.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-01-13 10:06:38,José Armando García Sancio,Mixed
700947aa5a64a707264caac8959fe2dc6b7e7fd0,"KAFKA-14367; Add `OffsetDelete` to the new `GroupCoordinator` interface (#12902)

This patch adds `OffsetDelete` to the new `GroupCoordinator` interface and updates `KafkaApis` to use it.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-01-17 20:39:01,David Jacot,Mixed
b7e3ee72ce0493dade24e2da821807d3356bcba1,"KAFKA-14621 Disallow authorizers during ZK migration (#13117)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-01-17 16:10:38,David Arthur,Mixed
653e284fcce3f992a0e97d6551717e891df016d5,"KAFKA-13972; Ensure replica state deleted after reassignment cancellation (#13107)

When a reassignment is cancelled, we need to delete the partition state of adding replicas. Failing to do so causes ""stray"" replicas which take up disk space and can cause topicId conflicts if the topic is later recreated. Currently, this logic does not work because the leader epoch does not always get bumped after cancellation. Without a leader epoch bump, the replica will ignore StopReplica requests sent by the controller and the replica may remain online.

In this patch, we fix the problem by loosening the epoch check on the broker side when a StopReplica request is received. Instead of ignoring the request when the request epoch matches the current epoch, the request will be accepted.

Note, this problem only affects the ZK controller. The integration tests added here nevertheless cover both metadata modes.

Reviewers:  David Jacot <djacot@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-01-18 10:26:48,Jason Gustafson,Mixed
7a22c0c98f33ce0514ef93318bab322e84ba1e41,"KAFKA-14637 Fix upgrade compatibility issue from older versions to 3.4 (#13130)

3.4 introduced a change that requires cluster.id to be present in meta.properties if the file is available. This information is not persisted by the brokers in old versions (< 0.10). So on upgrade, the requirement check fails and halts the broker start up. This patch fixes the requirement to ensure that cluster.id is not required in zk mode on upgrade.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Colin P. McCabe <cmccabe@apache.org>, David Arthur <mumrah@gmail.com>",2023-01-19 10:55:59,Akhilesh C,Mixed
2e0a005dd47d922d66c1da9b20b6ab7f5d1be5a1,"KAFKA-14367; Add internal APIs to the new `GroupCoordinator` interface (#13112)

This patch migrates all the internal APIs of the current group coordinator to the new `GroupCoordinator` interface. It also makes the current implementation package private to ensure that it is not used anymore.

Reviewers: Justine Olshan <jolshan@confluent.io>",2023-01-20 08:38:21,David Jacot,Mixed
8b4423765574e8fc68a24bce0ac36dd29eb81c98,"KAFKA-14575: Move ClusterTool to tools module (#13080)


Reviewers: dengziming <dengziming1993@gmail.com>, Federico Valeri  <fedevaleri@gmail.com>",2023-01-22 12:50:43,Mickael Maison,Mixed
86c953d42e61af787765f930e7cb685bc6f17dd4,"MINOR: KafkaConfig should not expose internal config when queried for non-internal configs. (#13059)

Side fix: Print the topic/broker/broker-loggers configurations in the alphabetical/sorted order. This will be useful when the user supplies '--all' flag.

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Luke Chen <showuon@gmail.com>",2023-01-23 12:58:41,Kamal Chandraprakash,Not TDD
00e5803cd3af89011254e734232308618403309d,"MINOR: Various cleanups in client tests (#13094)


Reviewers: Luke Chen <showuon@gmail.com>, Ismael Juma <mlists@juma.me.uk>, Divij Vaidya <diviv@amazon.com>, Christo Lolov <christololov@gmail.com>",2023-01-23 13:07:44,Mickael Maison,Mixed
cfbd8979bc70dec21ebc5f81547acefddf4a6767,"KAFKA-14311: Cleanly cleanly stop connectors/tasks on Connect worker shutdown (#12802)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-01-23 14:15:59,vamossagar12,Mixed
b2cb546fba03bbdc4054c7d120b0b2654c7cf34e,"MINOR: Small cleanups in refactored consumer implementation (#13138)

This patch contains a few cleanups and fixes in the new refactored consumer logic:

- Use `CompletableFuture` instead of `RequestFuture` in `NetworkClientDelegate`. This is a much more extensible API and it avoids tying the new implementation to `ConsumerNetworkClient`.
- Fix call to `isReady` in `NetworkClientDelegate`. We need the call to `ready` to initiate the connection.
- Ensure backoff is enforced even after successful `FindCoordinator` requests. This avoids a tight loop while metadata is converging after a coordinator change.
- `RequestState` was incorrectly using the reconnect backoff as the retry backoff. In fact, we don't currently have a retry backoff max implemented in the consumer, so the use of `ExponentialBackoff` is unnecessary, but I've left it since we may add this with https://cwiki.apache.org/confluence/display/KAFKA/KIP-580%3A+Exponential+Backoff+for+Kafka+Clients. 
- Minor cleanups in test cases to avoid unused classes/fields.

Reviewers: Philip Nee <pnee@confluent.i>, Guozhang Wang <guozhang@apache.org>",2023-01-23 12:45:24,Jason Gustafson,Mixed
26119bae901ab83bc7105dfb1e8f099a6778344b,"KAFKA-14463 Close ConnectorClientConfigOverridePolicy instances (#13144)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-01-23 21:38:37,Nikolay,Mixed
0711375b1efacd6f4b572317438d73953dba44c6,"KRaft brokers and controllesr should fail on Authorizer failure (#13151)

KRaft brokers and controllesr should fail to start if any authorizer fails to start.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-01-24 16:08:33,Alyssa Huang,Not TDD
598ba5f2fd57fc2cea21013a438650d98cda6623,"KAFKA-14644: Process should crash after failure in Raft IO thread (#13140)

Unexpected errors caught in the Raft IO thread should cause the process to stop. This is similar to the handling of exceptions in the controller.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-01-25 09:41:38,Jason Gustafson,Mixed
72cfc994f5675be349d4494ece3528efed290651,"KAFKA-14628: Move CommandLineUtils and CommandDefaultOptions to tools (#13131)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Christo Lolov <christololov@gmail.com>, Sagar Rao <sagarmeansocean@gmail.com>",2023-01-26 20:06:09,Federico Valeri,Mixed
17559d581e9ba89eb3c96b32f232cfa03d8b45a5,"KAFKA-14645: Use plugin classloader when retrieving connector plugin config definitions (#13148)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Greg Harris <gharris1727@gmail.com>",2023-01-30 18:06:02,Chris Egerton,Mixed
eb7d5cbf15b2e53249d8126859c4cbb2c7019f5c,"MINOR: add startup timeouts to KRaft integration tests (#13153)

When running junit tests, it is not good to block forever on CompletableFuture objects.  When there
are bugs, this can lead to junit tests hanging forever. Jenkins does not deal with this well -- it
often brings down the whole multi-hour test run.  Therefore, when running integration tests in
JUnit, set some reasonable time limits on broker and controller startup time.

Reviewers: Jason Gustafson <jason@confluent.io>",2023-01-30 11:29:30,Colin Patrick McCabe,Mixed
89a4735c35b80abcf5cd80f5c5ae80fc39107571,"KAFKA-14656: Send UMR first during ZK migration (#13159)

When in migration-from-ZK mode and sending RPCs to ZK-based brokers, the KRaft controller must send
full UpdateMetadataRequests prior to sending full LeaderAndIsrRequests. If the controller sends the
requests in the other order, and the ZK-based broker does not already know about some of the nodes
referenced in the LeaderAndIsrRequest, it will reject the request.

This PR includes an integration test, and a number of other small fixes for dual-write.

Co-authored-by: Akhilesh C <akhileshchg@users.noreply.github.com>
Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-01-30 22:31:45,David Arthur,Mixed
6c98544a964b40ede6bbe1b3440f8e5db96a4ad6,"KAFKA-14491: [2/N] Refactor RocksDB store open iterator management (#13142)

This PR refactors how the list of open iterators for RocksDB stores is managed. Prior to this PR, the `openIterators` list was passed into the constructor for the iterators themselves, allowing `RocksDbIterator.close()` to remove the iterator from the `openIterators` list. After this PR, the iterators themselves will not know about lists of open iterators. Instead, a generic close callback is exposed, and it's the responsibility of the store that creates a new iterator to set the callback on the iterator, to ensure that closing an iterator removes the iterator from the list of open iterators.

This refactor is desirable because it enables more flexible iterator lifecycle management. Building on top of this, RocksDBStore is updated with an option to allow the user (i.e., the caller of methods such as `range()` and `prefixScan()` which return iterators) to pass a custom `openIterators` list for the new iterator to be stored in. This will allow for a new Segments implementation where multiple Segments can share the same RocksDBStore instance, while having each Segment manage its own open iterators.

Part of KIP-889.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-01-31 00:05:43,Victoria Xia,Mixed
6625214c52961fc40b7992a031d60c6805db4cec,"KAFKA-14658: Do not open broker ports until we are ready to accept traffic (#13169)

When we are listening on fixed ports, we should defer opening ports until we're ready to accept
traffic. If we open the broker port too early, it can confuse monitoring and deployment systems.
This is a particular concern when in KRaft mode, since in that mode, we create the SocketServer
object earlier in the startup process than when in ZK mode.

The approach taken in this PR is to defer opening the acceptor port until Acceptor.start is called.
Note that when we are listening on a random port, we continue to open the port ""early,"" in the
SocketServer constructor. The reason for doing this is that there is no other way to find the
random port number the kernel has selected. Since random port assignment is not used in production
deployments, this should be reasonable.

FutureUtils.java: add chainFuture and tests.

SocketServerTest.scala: add timeouts to cases where we call get() on futures.

Reviewers: David Arthur <mumrah@gmail.com>, Alexandre Dupriez <hangleton@users.noreply.github.com>",2023-02-01 09:42:03,Colin Patrick McCabe,Mixed
65bb819313bbfe21f021f925b49a26e7ce0c954d,"KAFKA-14491: [1/N] Add segment value format for RocksDB versioned store (#13126)

Part of KIP-889.

The KIP proposed the introduction of versioned key-value stores, as well as a RocksDB-based implementation. The RocksDB implementation will consist of a ""latest value store"" for storing the latest record version associated with each key, in addition to multiple ""segment stores"" to store older record versions. Within a segment store, multiple record versions for the same key will be combined into a single bytes array ""value"" associated with the key and stored to RocksDB.

This PR introduces the utility class that will be used to manage the value format of these segment stores, i.e., how multiple record versions for the same key will be combined into a single bytes array ""value."" Follow-up PRs will introduce the versioned store implementation itself (which calls heavily upon this utility class).

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-02-01 13:19:53,Victoria Xia,Mixed
50e0e3c257c823192ca79644d4bfc2be088e903b,"KAFKA-14582: Move JmxTool to tools (#13136)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2023-02-02 11:23:26,Federico Valeri,Mixed
a3cf8b54e03c60f92f3db5e62a45c2751306f0f3,"KAFKA-14455: Kafka Connect create and update REST APIs should surface failures while writing to the config topic (#12984)

Reviewers: Greg Harris <greg.harris@aiven.io>, Chris Egerton <chrise@aiven.io>",2023-02-02 11:03:38,Yash Mayya,Mixed
b8e606355b71528aa438e80ffeb3042d0d586998,"KAFKA-14491: [4/N] Improvements to segment value format for RocksDB versioned store (#13186)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-02-02 21:48:40,Victoria Xia,Mixed
4a7fedd46a7fc1eff5411a0f4329781c9474f8e8,"KAFKA-14491: [3/N] Add logical key value segments (#13143)

Part of KIP-889

Reviewers: Matthias J. Sax <matthias@confuent.io>",2023-02-03 17:26:33,Victoria Xia,Mixed
9ab689f7d45458e92883019f54fdcf9a2d9ce456,"KAFKA-14610: Publish Mirror Maker 2 offset syncs in task commit() method (#13181)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Greg Harris <gharris1727@gmail.com>",2023-02-06 10:53:58,Chris Egerton,Mixed
6d11261d5deaca300e273bebe309f9e4f814f815,"MINOR: IBP_3_4_IV1 should be IBP_3_5_IV0 because it is not in 3.4 (#13198)

The KIP-405 MetadataVersion changes will be released as part of AK 3.5, but were added as BP_3_4_IV1.
This change fixes them to be IBP_3_5_IV0. There is no incompatibility  because this feature has not yet
been released. Also set didMetadataChange to false because KRaft metadata log records did not change.

Reviewers: Satish Duggana <satishd@apache.org>, Christo Lolov <christo_lolov@yahoo.com>, Colin P. McCabe <cmccabe@apache.org>",2023-02-06 10:37:50,Ron Dagostino,Mixed
da2e8dce71a86143d0545a84b5449aabde48a44c,"KAFKA-14551 Move/Rewrite LeaderEpochFileCache and its dependencies to the storage module. (#13046)

KAFKA-14551 Move/Rewrite LeaderEpochFileCache and its dependencies to the storage module.

For broader context on this change, you may want to look at KAFKA-14470: Move log layer to the storage module

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>, Alexandre Dupriez <alexandre.dupriez@gmail.com>",2023-02-07 15:37:23,Satish Duggana,Mixed
a0a9b6ffeaa61511f79e17fad8430d9114d472ef,"MINOR: Remove unnecessary code (#13210)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Divij Vaidya <diviv@amazon.com>",2023-02-07 17:37:45,Christo Lolov,Mixed
8cdf9564ab0f56845bb0cc0192a43b39c26c3375,MINOR: Add FeatureZNode ZK node path to ZK root paths,2023-02-07 23:10:18,Manikumar Reddy,Not TDD
788793dee6fa5d7ba5cb7d756b72c7d043dc8789,"KAFKA-10575: Add onRestoreSuspsnded to StateRestoreListener (#13179)

1. Add the new API (default impl is empty) to StateRestoreListener.
2. Update related unit tests

Reviewers: Lucas Brutschy <lucasbru@users.noreply.github.com>, Matthias J. Sax <mjsax@apache.org>",2023-02-07 11:33:09,Guozhang Wang,Mixed
1d3fb760926bf559b0c127c6bc4d462a93ac23d6,"KAFKA-14688 Move package org.apache.kafka.server.log.internals to org.apache.kafka.storage.internals.log (#13213)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2023-02-08 09:22:42,Satish Duggana,Mixed
3be7f7d611d0786f2f98159d5c7492b0d94a2bb7,"KAFKA-14391; Add ConsumerGroupHeartbeat API (#12972)

This patch does a few things:
1) It introduces a new flag to the request spec: `latestVersionUnstable`. It signifies that the last version of the API is considered unstable (or still in development). As such, the last API version is not exposed by the server unless specified otherwise with the new internal `unstable.api.versions.enable`. This allows us to commit new APIs which are still in development.
3) It adds the ConsumerGroupHeartbeat API, part of KIP-848, and marks it as unreleased for now.
4) It adds the new error codes required by the new ConsumerGroupHeartbeat API.

Reviewers: Justine Olshan <jolshan@confluent.io>, Jeff Kim <jeff.kim@confluent.io>, Jason Gustafson <jason@confluent.io>",2023-02-09 09:13:31,David Jacot,Mixed
e903f2cd9646639cbada753a705b49fb903e1add,"KAFKA-7109: Close fetch sessions on close of consumer (#12590)

## Problem
When consumer is closed, fetch sessions associated with the consumer should notify the server about it's intention to close using a Fetch call with epoch = -1 (identified by `FINAL_EPOCH` in `FetchMetadata.java`). However, we are not sending this final fetch request in the current flow which leads to unnecessary fetch sessions on the server which are closed only after timeout.

## Changes
1. Change `close()` in `Fetcher` to add a logic to send the final Fetch request notifying close to the server.
2. Change `close()` in `Consumer` to respect the timeout duration passed to it. Prior to this change, the timeout parameter was being ignored.
3. Change tests to close with `Duration.zero` to reduce the execution time of the tests. Otherwise the tests will wait for default timeout to exit (close() in the tests is expected to be unsuccessful because there is no server to send the request to).
4. Distinguish between the case of ""close existing session and create new session"" and ""close existing session"" by renaming the `nextCloseExisting` function to `nextCloseExistingAttemptNew`.

## Testing
Added unit test which validates that the correct close request is sent to the server.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Kirk True <kirk@mustardgrain.com>, Philip Nee <philipnee@gmail.com>, Luke Chen <showuon@gmail.com>, David Jacot <djacot@confluent.io>",2023-02-09 14:53:10,Divij Vaidya,Mixed
f93d5af8392e01f29b853cc44c6f78d74ead41be,"KAFKA-15086, KAFKA-9981: Intra-cluster communication for Mirror Maker 2 (#13137)

Reviewers: Daniel Urban <durban@cloudera.com>, Greg Harris <greg.harris@aiven.io>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>, Mickael Maison <mickael.maison@gmail.com>",2023-02-09 10:50:07,Chris Egerton,Mixed
cb4d9d1abf28333196503e807603c621b2303219,"KAFKA-14668 Avoid unnecessary UMR during ZK migration (#13183)

Only send UMR to ZK brokers if the cluster metadata or topic metadata has changed.

Reviewers: Akhilesh C <akhileshchg@users.noreply.github.com>, Colin P. McCabe <cmccabe@apache.org>",2023-02-09 13:24:02,David Arthur,Mixed
083e11a22ca9966ed010acdd5705351ab4300b52,"KAFKA-14650: Synchronize access to tasks inside task manager (#13167)

1. The major fix: synchronize access to tasks inside task manager, this is a fix of a regression introduced in #12397
2. Clarify on func names of StreamThread that maybe triggered outside the StreamThread.
3. Minor cleanups.

Reviewers: Lucas Brutschy <lucasbru@users.noreply.github.com>",2023-02-09 10:33:19,Guozhang Wang,Mixed
b5a9b9d67e76761b8e8d62a77cf09ece0cc0b717,"MINOR: Remove references to HIGHEST_SUPPORTED_VERSION from ZkMigrationClient (#13226)

Do not use HIGHEST_SUPPORTED_VERSION in ZkMigrationClient because
it will do the wrong thing when more MV options are added in the future.

Reviewers: David Arthur <mumrah@gmail.com>",2023-02-10 14:41:43,Colin Patrick McCabe,Mixed
df22a9d0e698203c1c1ba4bd4a4fdfa1a8920d7a,"KAFKA-14491: [5/N] Basic operations for RocksDB versioned store (#13188)

Introduces the VersionedKeyValueStore interface proposed in KIP-889, along with the RocksDB-based implementation of the interface. This PR includes fully functional put, get, get-with-timestamp, and delete operations, but does not include the ability to restore records from changelog or surrounding store layers (for metrics or writing to the changelog). Those pieces will come in follow-up PRs.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-02-10 17:30:09,Victoria Xia,Mixed
c576e02849b9e7ada80198de41499bcc2480bc93,"KAFKA-14480 Move/Rewrite ProducerStateManager to storage module. (#13040)

KAFKA-14480 Move/Rewrite of ProducerStateManager to the storage module.

Replaced `File.listFiles` with `Files.list` in ProducerStateManager.listSnapshotFiles
Used `Path` instead of `File` in ProducerStateManager.isSnapshotFile to check whether the given path is a file or not and has a suffix of '.snapshot'.",2023-02-12 13:00:51,Satish Duggana,Mixed
ef9c9486dac8d6076e2897580b10a699697205ac,"KAFKA-14676: Include all SASL configs in login cache key to ensure clients in a JVM can use different OAuth configs (#13211)

We currently cache login managers in static maps for both static JAAS config using system property and for JAAS config specified using Kafka config sasl.jaas.config. In addition to the JAAS config, the login manager callback handler is included in the key, but all other configs are ignored. This implementation is based on the assumption clients that require different logins (e.g. username/password) use different JAAS configs, because login properties are included in the JAAS config rather than as separate top-level configs. The OIDC support added in KIP-768 only allows configuration of token endpoint URL as a top-level config. This results in two clients in a JVM configured with different token endpoint URLs to incorrectly share a login.

This PR includes all SASL configs prefixed with sasl. to be included in the key so that logins are only shared if all the sasl configs are identical. 

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Kirk True <kirk@mustardgrain.com>",2023-02-12 19:49:12,Rajini Sivaram,Mixed
959756ae9d14f434109525aa43513358a27bf75c,"MINOR: Remove unnecessary usage of `LazyIndex` (#13218)

The remote index classes use `LazyIndex`, but immediately
force materialization. This results in more verbose code
and it's misleading since the indexes are not lazily
used in practice.

Also simplify `LazyIndex.forOffset/forTime` by removing
`writable` parameter, which is always `true`.

Reviewers: Satish Duggana <satishd@apache.org>",2023-02-13 13:46:37,Ismael Juma,Mixed
8cfafba2794562840b0f1c537e304f084b9359cf,"KAFKA-14021: Implement new KIP-618 APIs in MirrorSourceConnector (#12366)

Reviewers: Mickael Maison <mickael.maison@gmail.com>",2023-02-13 10:09:14,Chris Egerton,Mixed
631e6be3a02efe165611990e9f6721f7687d5457,"KAFKA-14711: kafaka-metadata-quorum.sh does not honor --command-confi… (#13241)

…g option

https://github.com/apache/kafka/pull/12951 accidentally changed the behavior of the `kafaka-metadata-quorum.sh` CLI by making it silently ignore a `--command-config <filename>` properties file that exists. This was an undetected regression in the 3.4.0 release.  This patch fixes the issue such that any such specified file will be honored.

Reviewers: José Armando García Sancio <jsancio@apache.org>, Ismael Juma <ismael@juma.me.uk>",2023-02-13 18:33:20,Ron Dagostino,Mixed
528a777df66ab1e66544ad2a8fb3d020ff229bff,"KAFKA-14491: [6/N] Support restoring RocksDB versioned store from changelog (#13189)

This PR builds on the new RocksDB-based versioned store implementation (see KIP-889) by adding code for restoring from changelog. The changelog topic format is the same as for regular timestamped key-value stores: record keys, values, and timestamps are stored in the Kafka message key, value, and timestamp, respectively. The code for actually writing to this changelog will come in a follow-up PR.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-02-13 17:06:44,Victoria Xia,Mixed
1ed61e4090353bc9e4802ee09366f512dc60884f,"MINOR: Few cleanups to JaasContext/Utils classes

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2023-02-14 11:18:24,Manikumar Reddy,Mixed
bd32d98bd7cbd8cff35d6786bc8b00061e0fedf7,"KAFKA-14704; Follower should truncate before incrementing high watermark (#13230)

When a leader becomes a follower, it is likely that it has uncommitted records in its log. When it reaches out to the leader, the leader will detect that they have diverged and it will return the diverging epoch and offset. The follower truncates it log based on this.

There is a small caveat in this process. When the leader return the diverging epoch and offset, it also includes its high watermark, low watermark, start offset and end offset. The current code in the `AbstractFetcherThread` works as follow. First it process the partition data and then it checks whether there is a diverging epoch/offset. The former may accidentally expose uncommitted records as this step updates the local watermark to whatever is received from the leader. As the follower, or the former leader, may have uncommitted records, it will be able to updated the high watermark to a larger offset if the leader has a higher watermark than the current local one. This result in exposing uncommitted records until the log is finally truncated. The time window is short but a fetch requests coming at the right time to the follower could read those records. This is especially true for clients out there which uses recent versions of the fetch request but without implementing KIP-320.

When this happens, the follower logs the following messages: 
* `Truncating XXX to offset 21434 below high watermark 21437`
* `Non-monotonic update of high watermark from (offset=21437 segment=[20998:98390]) to (offset=21434 segment=[20998:97843])`.

This patch proposes to mitigate the issue by starting by checking on whether a diverging epoch/offset is provided by the leader and skip processing the partition data if it is. This basically means that the first fetch request will result in truncating the log and a subsequent fetch request will update the low/high watermarks.

Reviewers: Ritika Reddy <rreddy@confluent.io>, Justine Olshan <jolshan@confluent.io>, Jason Gustafson <jason@confluent.io>",2023-02-14 09:54:32,David Jacot,Mixed
10164a6d2e1373c5cf57e37f63a3b10d07db6091,"KAFKA-14693; Kafka node should halt instead of exit (#13227)

Extend the implementation of ProcessTerminatingFaultHandler to support calling either Exit.halt or Exit.exit. Change the fault handler used by the Controller thread and the KRaft thread to use a halting fault handler.

Those threads cannot call Exit.exit because Runtime.exit joins on the default shutdown hook thread. The shutdown hook thread joins on the controller and kraft thread terminating. This causes a deadlock.

Reviewers: Colin Patrick McCabe <cmccabe@apache.org>, Jason Gustafson <jason@confluent.io>",2023-02-14 09:53:38,José Armando García Sancio,Mixed
b9754747d6eaa029c4bb69b073d749ff8df15908,"KAFKA-14653: Use raw properties instead of post-resolution properties for MirrorMaker connectors(#13163)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-02-14 16:36:34,Dániel Urbán,Mixed
35142d43e6aa55bd11484224b8b09a83800d3a22,"KAFKA-14664; Fix inaccurate raft idle ratio metric (#13207)

The raft idle ratio is currently computed as the average of all recorded poll durations. This tends to underestimate the actual idle ratio since it treats all measurements equally regardless how much time was spent. For example, say we poll twice with the following durations:

Poll 1: 2s
Poll 2: 0s

Assume that the busy time is negligible, so 2s passes overall.

In the first measurement, 2s is spent waiting, so we compute and record a ratio of 1.0. In the second measurement, no time passes, and we record 0.0. The idle ratio is then computed as the average of these two values (1.0 + 0.0 / 2 = 0.5), which suggests that the process was busy for 1s, which overestimates the true busy time.

In this patch, we create a new `TimeRatio` class which tracks the total duration of a periodic event over a full interval of time measurement.

Reviewers: José Armando García Sancio <jsancio@apache.org>",2023-02-15 14:40:00,Jason Gustafson,Mixed
bfeef298041add5d10f4279119aff2209d51d284,"KAFKA-14491: [7/N] Enforce strict grace period for versioned stores (#13243)

Changes the versioned store semantics to define an explicit ""grace period"" property. Grace period will always be equal to the history retention, though in the future we could introduce a new KIP to expose options to configure grace period separately.

Part of KIP-889.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-02-15 18:02:20,Victoria Xia,Mixed
dcaf95a35f4ba7de73433aa5a5b1a33427744e45,"KAFKA-14491: [8/N] Add serdes for ValueAndTimestamp with null value (#13249)

Introduces a new Serde, that serializes a value and timestamp as a single byte array, where the value may be null (in order to represent putting a tombstone with timestamp into the versioned store).

Part of KIP-889.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-02-15 18:07:47,Victoria Xia,Mixed
958bc0601c7852b8aaf28960280b1f45efd7d850,"KAFKA-5756: Wait for concurrent source task offset flush to complete before starting next flush (#13208)

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chris Egerton <chrise@aiven.io>",2023-02-15 21:29:20,Greg Harris,Mixed
f3dc3f0dad1d781e01319847ecd2db0cde916f86,"Kafka 14565: On failure, close AutoCloseable objects instantiated and configured by AbstractConfig (#13168)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-02-16 12:39:24,Terry,Mixed
aea6090ce479a06ea5489a54aeecf9b40233a3a1,"KAFKA-14727: Enable periodic offset commits for EOS source tasks (#13262)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-02-16 18:51:34,Greg Harris,Mixed
322ac86ba282f35373382854cc9e790e4b7fb5fc,"KAFKA-14706: Move/rewrite ShutdownableThread to server-common module. (#13234)

Move/rewrite ShutdownableThread to server-common module.

Reviewers: Luke Chen <showuon@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2023-02-17 11:51:17,Satish Duggana,Mixed
7e149990bdd2a0010ad8c970e46427dbb3164071,"KAFKA-14717 KafkaStreams can' get running if the rebalance happens be… (#13248)

I noticed this issue when tracing #12590.

StreamThread closes the consumer before changing state to DEAD. If the partition rebalance happens quickly, the other StreamThreads can't change KafkaStream state from REBALANCING to RUNNING since there is a PENDING_SHUTDOWN StreamThread

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2023-02-17 08:40:34,Chia-Ping Tsai,Not TDD
2e3bbe63c1d7a5484d0475c57e82011fada9cfa5,"KAFKA-14491: [9/N] Add versioned bytes store and supplier (#13250)

As part of introducing versioned key-value stores in KIP-889, we'd like a way to represent a versioned key-value store (VersionedKeyValueStore<Bytes, byte[]>) as a regular key-value store (KeyValueStore<Bytes, byte[]>) in order to be compatible with existing DSL methods for passing key-value stores, e.g., StreamsBuilder#table() and KTable methods, which are explicitly typed to accept Materialized<K, V, KeyValueStore<Bytes, byte[]>. This way, we do not need to introduce new versions of all relevant StreamsBuilder and KTable methods to relax the Materialized type to accept versioned stores.

This PR introduces the new VersionedBytesStore extends KeyValueStore<Bytes, byte[]> interface for this purpose, along with the corresponding supplier (VersionedBytesStoreSupplier) and implementation (RocksDbVersionedKeyValueBytesStoreSupplier). The RocksDbVersionedKeyValueBytesStoreSupplier implementation leverages an adapter (VersionedKeyValueToBytesStoreAdapter) to assist in converting from VersionedKeyValueStore to VersionedBytesStore.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-02-17 11:06:04,Victoria Xia,Mixed
a54a34a11c1c867ff62a7234334cad5139547fd7,"KAFKA-12468, KAFKA-13659, KAFKA-12566: Fix MM2 causing negative downstream lag, syncing stale offsets, and flaky integration tests (#13178)

KAFKA-12468: Fix negative lag on down consumer groups synced by MirrorMaker 2

KAFKA-13659: Stop syncing consumer groups with stale offsets in MirrorMaker 2

KAFKA-12566: Fix flaky MirrorMaker 2 integration tests

Reviewers: Chris Egerton <chrise@aiven.io>",2023-02-17 17:25:17,Greg Harris,Mixed
4dd27a9f2116edfd22b4dc7368a62fedef28fe3b,"KAFKA-14673; Add high watermark listener to Partition/Log layers (#13196)

In the context of KIP-848, we implements are new group coordinator in Java. This new coordinator follows the architecture of the new quorum controller. It is basically a replicated state machine that writes to the log and commits its internal state when the writes are committed. At the moment, the only way to know when a write is committed is to use a delayed fetch. This is not ideal in our context because a delayed fetch can be completed before the write is actually committed to the log.

This patch proposes to introduce a high watermark listener to the Partition/Log layers. This will allow the new group coordinator to simply listen to changes and commit its state based on this. This mechanism is simpler and lighter as well.

Reviewers: Christo Lolov <lolovc@amazon.com>, Justine Olshan <jolshan@confluent.io>, Jason Gustafson <jason@confluent.io>",2023-02-20 08:26:17,David Jacot,Mixed
81b3b2fb3399ab2784eb8158564fc1c9a1299a8d,"KAFKA-13771: Support to explicitly delete delegationTokens that have expired but have not been automatically cleaned up (#11976)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2023-02-21 10:07:42,RivenSun,Mixed
c39123d83d996edfdc23cdd50be8e51853b6cf1d,"KAKFA-14733: Added a few missing checks for Kraft Authorizer and updated AclAuthorizerTest to run tests for both zk and kraft (#13282)

Added the following checks - 
* In StandardAuthorizerData.authorize() to fail if `patternType` other than `LITERAL` is passed.
* In AclControlManager.addAcl() to fail if Resource Name is null or empty.

Also, updated `AclAuthorizerTest` includes a lot of tests covering various scenarios that are missing in `StandardAuthorizerTest`. This PR changes the AclAuthorizerTest to run tests for both `zk` and `kraft` modes - 
* Rename AclAuthorizerTest -> AuthorizerTest
* Parameterize relevant tests to run for both modes

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2023-02-21 19:21:15,Purshotam Chauhan,Mixed
c9a42c85e2c903329b3550181d230527e90e3646,"KAFKA-14675: Extract metadata-related tasks from Fetcher into MetadataFetcher 1/4 (#13192)

The `Fetcher` class is used internally by the `KafkaConsumer` to fetch records from the brokers. There is [ongoing work to create a new consumer implementation with a significantly refactored threading model](https://issues.apache.org/jira/browse/KAFKA-14246). The threading refactor work requires a similarly refactored `Fetcher`.

This task covers the work to extract from `Fetcher` the APIs that are related to metadata operations into two new classes: `OffsetFetcher` and `TopicMetadataFetcher`. This will allow the refactoring of `Fetcher` and `MetadataFetcher` for the new consumer.

Reviewers: Philip Nee <pnee@confluent.io>, Guozhang Wang <guozhang@apache.org>, Jason Gustafson <jason@confluent.io>",2023-02-21 09:00:35,Kirk True,Mixed
0fc029c6a47a7a930a2b078569de1173cdb547a4,"KAFKA-14299: Fix pause and resume with state updater (#13025)

* Fixes required to make the PauseResumeIntegrationTest pass. It was not enabled and it does not pass for the state updater code path.

* Make sure no progress is made on paused topologies. The state updater restored one round of polls from the restore
consumer before realizing that a newly added task was already in paused state when being added.

* Wake up state updater when tasks are being resumed. If a task is resumed, it may be necessary to wake up the state updater from waiting on the tasksAndActions condition.

* Make sure that allTasks methods also return the tasks that are currently being restored.

* Enable PauseResumeIntegrationTest and upgrade it to JUnit5.

Reviewers: Bruno Cadonna <cadonna@apache.org>, Guozhang Wang <wangguoz@gmail.com>",2023-02-21 10:17:09,Lucas Brutschy,Mixed
a2c9f421af40e0c8ace722be94aedf8dec4f2b31,"KAFKA-14491: [10/N] Add changelogging wrapper for versioned stores (#13251)

Introduces the changelogging layer for the new versioned key-value store introduced in KIP-889. The changelogging layer operate on VersionedBytesStore rather than VersionedKeyValueStore so that the outermost metered store can serialize to bytes once and then all inner stores operate only with bytes types.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-02-21 13:27:54,Victoria Xia,Mixed
30d7d3b5ce42ed7663a90193be47e30aab75537f,"MINOR: add size check for tagged fields (#13100)

Add size check for taggedFields of a tag, and add tests.

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Divij Vaidya <diviv@amazon.com>",2023-02-22 11:52:21,Luke Chen,Not TDD
069ce59e1e33f47c000d8cdc247851f2e0a82154,"KAFKA 14714: Move/Rewrite RollParams, LogAppendInfo, and LeaderHwChange to storage module. (#13255)

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2023-02-22 23:12:04,Satish Duggana,Mixed
3fe2f8c4427123814fdeb8e6f620fb9c79274878,"MINOR: after reading BYTES type it's possible to access data beyond its size (#13261)

After reading data of type BYTES, COMPACT_BYTES, NULLABLE_BYTES or COMPACT_NULLABLE_BYTES returned ByteBuffer might have a capacity that is larger than its limit, thus these data types may access data that lies beyond its size by increasing limit of the returned ByteBuffer. I guess this is not very critical but I think it would be good to restrict increasing limit of the returned ByteBuffer by making its capacity strictly equal to its limit. I think someone might unintentionally mishandle these data types and accidentally mess up data in the ByteBuffer from which they were read.

Reviewers: Luke Chen <showuon@gmail.com>",2023-02-23 10:13:18,bachmanity1,Not TDD
8c84d29c2e4f5f056a46e7453c4aa634358ee7bf,"KAFKA-14128: Kafka Streams does not handle TimeoutException (#13161)

Kafka Streams is supposed to handle TimeoutException during internal topic creation gracefully. This PR fixes the exception handling code to avoid crashing on an TimeoutException returned by the admin client.

Reviewer: Matthias J. Sax <matthias@confluent.io>, Colin Patrick McCabe <cmccabe@apache.org>, Alexandre Dupriez (@Hangleton)",2023-02-22 22:51:51,Lucia Cerchie,Mixed
c55e5afb836e7f1fed749b9d02a73bc83fdf52fd,"KAFKA-14744; NPE while converting OffsetFetch from version < 8 to version >= 8 (#13295)

While refactoring the OffsetFetch handling in KafkaApis, we introduced a NullPointerException (NPE). The NPE arises when the FetchOffset API is called with a client using a version older than version 8 and using null for the topics to signal that all topic-partition offsets must be returned. This means that this bug mainly impacts admin tools. The consumer does not use null.

This NPE is here: https://github.com/apache/kafka/commit/24a86423e9907b751d98fddc7196332feea2b48d#diff-0f2f19fd03e2fc5aa9618c607b432ea72e5aaa53866f07444269f38cb537f3feR237.

We missed this during the refactor because we had no tests in place to test this mode.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Justine Olshan <jolshan@confluent.io>",2023-02-23 18:32:33,David Jacot,Mixed
7626a43079298e88895b6f9e2fe3f8206da0155c,"KAFKA-14295 FetchMessageConversionsPerSec meter not recorded (#13279)

Reviewers: Luke Chen <showuon@gmail.com>",2023-02-24 01:50:49,Chia-Ping Tsai,Not TDD
9f55945270876ff9cc71472f223ff266d5400206,"MINOR: Introduce OffsetAndEpoch in LeaderEndpoint interface return values (#13268)

Reviewers: Satish Duggana <satishd@apache.org>, Alexandre Dupriez <alexandre.dupriez@gmail.com>, Jun Rao <junrao@gmail.com>",2023-02-23 17:29:32,Kowshik Prakasam,Mixed
2fad1652942226454a44038f2350642817f9f74b,"KAFKA-10199: Add task updater metrics, part 1 (#13228)

* Moved pausing-tasks logic out of the commit-interval loop to be on the top-level loop, similar to resuming tasks.
* Added thread-level restoration metrics.
* Related unit tests.

Reviewers: Lucas Brutschy <lucasbru@users.noreply.github.com>, Matthias J. Sax <matthias@confluent.io>",2023-02-24 10:25:11,Guozhang Wang,Mixed
400ba0aeaeb6c460069d5ad12b1b3976ab447332,"KAFKA-14491: [11/N] Add metered wrapper for versioned stores (#13252)

Introduces the metered store layer for the new versioned key-value store introduced in KIP-889. This outermost, metered store layer handles all serialization/deserialization from VersionedKeyValueStore to a bytes-representation (VersionedBytesStore) so that all inner stores may operate only with bytes types.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-02-24 14:32:43,Victoria Xia,Mixed
8d32a0f2463eaa4c0b669b8a957a7abc066c066f,"[KAFKA-14685] Refactor logic to handle OFFSET_MOVED_TO_TIERED_STORAGE error (#13206)

Reviewers: Rittika Adhikari <rittika.adhikari@gmail.com>, Luke Chen <showuon@gmail.com>, Satish Duggana <satishd@apache.org>, Alexandre Dupriez <alexandre.dupriez@gmail.com>, Jun Rao <junrao@gmail.com>",2023-02-24 15:29:35,Matthew Wong,Mixed
62431dca700fb2c7c3afe1a7c9eb07fe336f9b04,"KAFKA-14468: Implement CommitRequestManager to manage the commit and autocommit requests (#13021)

This pull request introduces a CommitRequestManager to efficiently manage commit requests from clients and the autocommit state. The manager utilizes a ""staged"" commit queue to store commit requests made by clients. A background thread regularly polls the CommitRequestManager, which then checks the queue for any outstanding commit requests. When permitted, the CommitRequestManager generates a PollResult which contains a list of UnsentRequests that are subsequently processed by the NetworkClientDelegate.

In addition, a RequestManagerRegistry has been implemented to hold all request managers, including the new CommitRequestManager and the CoordinatorRequestManager. The registry is regularly polled by a background thread in each event loop, ensuring that all request managers are kept up to date and able to handle incoming requests

Reviewers: Jason Gustafson <jason@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2023-02-24 15:42:38,Philip Nee,Mixed
ae6725740651cc76280840af3a657f9bb9522e37,"Kafka-14743: update request metrics after callback (#13297)

Currently, the kafka.network:type=RequestMetrics,name=MessageConversionsTimeMs,request=Fetch will not get updated because the request metrics is recorded BEFORE the messageConversions metrics value updated. That means, even if we updated the messageConversions metrics value, the request metrics will never reflect the update. This patch fixes it by updating the request metric after callback completed, so that the messageConversions metric value can be updated correctly.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Divij Vaidya <diviv@amazon.com>",2023-02-26 15:16:51,Luke Chen,Not TDD
5f9d01668cae64b2cacd7872d82964fa78862aaf,"KAFKA-14060: Replace EasyMock and PowerMock with Mockito in AbstractWorkerSourceTaskTest (#13191)

Reviewers: Christo Lolov <christololov@gmail.com>, Chris Egerton <chrise@aiven.io>",2023-02-27 09:25:21,Hector Geraldino,Not TDD
867fb295d0b4e91d650d21594eeb515bd9accc54,"KAFKA-14742: Throttle connectors in ExactlyOnceSourceIntegrationTest to fix flakey OOMEs (#13291)

KAFKA-14742: Throttle connectors in ExactlyOnceSourceIntegrationTest to fix flakey OOMEs
fixup: rename config constant, use meaningful constant names in EOSIT

Signed-off-by: Greg Harris <greg.harris@aiven.io>

Reviewers: Edoardo Comar <edocomar@gmail.com>",2023-02-28 10:21:36,Greg Harris,Not TDD
a1b8586a579fd892ab47b0780322df9b43e4ef6f,"KAFKA-14659 source-record-write-[rate|total] metrics should exclude filtered records (#13193)

Reviewers: Christo Lolov <christololov@gmail.com>, Chris Egerton <chrise@aiven.io>",2023-02-28 09:40:18,Hector Geraldino,Mixed
8dd697b05f36c319bd6c50d6e499168aac172e02,"KAFKA-14732: Use an exponential backoff retry mechanism while reconfiguring connector tasks (#13276)

Reviewers: Chaitanya Mukka <chaitanya.mvs2007@gmail.com>, Chris Egerton <chrise@aiven.io>",2023-02-28 10:36:34,Yash Mayya,Mixed
f586fa59d3f938e04bda4e8143ddb1c4310eaf78,"KAFKA-14671: Refactor PredicatedTransformation to not implement Transformation (#13184)

Reviewers: Christo Lolov <christololov@gmail.com>, Yash Mayya <yash.mayya@gmail.com>, Chris Egerton <chrise@aiven.io>",2023-02-28 11:23:19,Greg Harris,Mixed
6b89672b5e5d527cf26207d3985a24025afedb1a,"MINOR: some ZK migration code cleanups.

Some minor improvements to the JavaDoc for ZkMigrationState.

Rename MigrationState to MigrationDriverState to avoid confusion with ZkMigrationState.

Remove ClusterImage#zkBrokers. This costs O(num_brokers) time to calculate, but is only ever used
when in migration state. It should just be calculated in the migration code. (Additionally, the
function ClusterImage.zkBrokers() returns something other than ClusterImage#zkBrokers, which is
confusing.)

Also remove ClusterDelta#liveZkBrokerIdChanges. This is only used in one place, and it's easy to
calculate it there. In general we should avoid providing expensive accessors unless absolutely
necessary. Expensive code should look expensive: if people want to iterate over all brokers, they
can write a loop to do that rather than hiding it inside an accessor.",2023-02-28 13:59:07,Colin P. McCabe,Mixed
f7f376f6c162717e60e143b05fbd12ea2f347e3c,"KAFKA-12639: Exit upon expired timer to prevent tight looping (#13190)

In AbstractCoordinator#joinGroupIfNeeded - joinGroup request will be retried without proper backoff, due to the expired timer. This is an uncommon scenario and possibly only appears during the testing, but I think it makes sense to enforce the client to drive the join group via poll.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2023-02-28 17:36:37,Philip Nee,Mixed
0927049a617fa2937a211aab895f6590403130fb,"KAFKA-14371: Remove unused clusterId field from quorum-state file (#13102)

Remove clusterId field from the KRaft controller's quorum-state file $LOG_DIR/__cluster_metadata-0/quorum-state

Reviewers: Luke Chen <showuon@gmail.com>, dengziming <dengziming1993@gmail.com>, Christo Lolov <christololov@gmail.com>",2023-03-01 10:13:38,Gantigmaa Selenge,Not TDD
510e99e1a2636f9a7035020f682ab7df8530986b,"MINOR Moved a few log segment util methods from LocalLog to LogFileUtils (#13309)

Reviewers: Jun Rao <junrao@gmail.com>, Luke Chen <showuon@gmail.com>",2023-03-01 10:58:49,Satish Duggana,Mixed
98d84b17f74b0bfe65163d0ddf88976746de5f7e,"KAFKA-14451: Rack-aware consumer partition assignment for RangeAssignor (KIP-881) (#12990)

Best-effort rack alignment for range assignor when both consumer racks and partition racks are available with the protocol changes introduced in KIP-881. Rack-aware assignment is enabled by configuring client.rack for consumers. Balanced assignment per topic is prioritized over rack-alignment. For topics with equal partitions and the same set of subscribers, co-partitioning is prioritized over rack-alignment.

Reviewers: David Jacot <djacot@confluent.io>",2023-03-01 21:01:35,Rajini Sivaram,Mixed
d479d129e0b24f2c2173f2bfd1fb261ec2be757b,"KAFKA-13999: Add ProducerCount metrics (KIP-847) (#13078)

This is the PR for the implementation of KIP-847: https://cwiki.apache.org/confluence/display/KAFKA/KIP-847%3A+Add+ProducerIdCount+metrics
Add ProducerIdCount metric at the broker level:

kafka.server:type=ReplicaManager,name=ProducerIdCount
Added unit tests below to ensure the metric reported the count correctly.

---------

Co-authored-by: Artem Livshits <84364232+artemlivshits@users.noreply.github.com>

Reviewers: Ismael Juma <ismael@juma.me.uk>, Divij Vaidya <diviv@amazon.com>, Christo Lolov <christo_lolov@yahoo.com>, Alexandre Dupriez <alexandre.dupriez@gmail.com>, Justine Olshan <jolshan@confluent.io>",2023-03-01 14:20:15,Anastasia Vela,Mixed
5842953249727b9a4d755b02fd78386681486d89,"MINOR: Fix flaky tests in DefaultStateUpdaterTest (#13319)

Found a few flaky tests while reviewing another PR. The root cause seems to be with changing the return behavior of when in mockito. Fixed those without using reset and also bumped a couple debug log lines to info since they could be very helpful in debugging.

Reviewers: Luke Chen <showuon@gmail.com>, Lucas Brutschy <lbrutschy@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2023-03-01 17:36:23,Guozhang Wang,Mixed
9be36a4cd3615dea203c558986486bd51b38222a,"KAFKA-14729: The kafakConsumer pollForFetches(timer) method takes up a lot of cpu due to the abnormal exit of the heartbeat thread (#13270)

throwing an exception directly form the foreground thread's callers when the abnormal exit of the heartbeat thread

Reviewers: Luke Chen <showuon@gmail.com>, Philip Nee <philipnee@gmail.com>",2023-03-02 11:37:33,RivenSun,Mixed
ea30ec4b5628fed7bdea228f6bf149a23a415816,"KAFKA-14590: Move DelegationTokenCommand to tools (#13172)

KAFKA-14590: Move DelegationTokenCommand to tools

Reviewers: Luke Chen <showuon@gmail.com>, Christo Lolov <christo_lolov@yahoo.com>, Federico Valeri <fvaleri@redhat.com>",2023-03-02 14:30:07,Gantigmaa Selenge,Mixed
bb3111f472f5007e47c0a01b24a4d61f44550ab9,"KAFKA-14580: Moving EndToEndLatency from core to tools module (#13095)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Federico Valeri <fedevaleri@gmail.com>, Ismael Juma <mlists@juma.me.uk>",2023-03-02 12:05:22,vamossagar12,Mixed
b0e28351ecf98f7a0ffc5008a575125d777dcc1c,"MINOR: Refactor task change logic to AbstractHerder, reuse for standalone mode. (#13287)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-03-02 09:53:52,Greg Harris,Not TDD
99e2b71fd69bc63fcf3f064267c703a049b217d6,"KAFKA-14462; [1/N] Add new server configurations (KIP-848) (#13322)

This patch adds the new server configurations introduced in KIP-848. All of them are kept as internal configurations for now. We will make them public when the KIP is ready. It also adds an internal configuration named `group.coordinator.new.enable` that we will used during the development of the KIP. This one will be remove later on and replaced by IBP/feature flag.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-03-02 20:46:50,David Jacot,Mixed
3109e9c843e33057dd5d823c50c41fb91dc1a8fc,"KAFKA-14649: Isolate failures during plugin path scanning to single plugin classes (#13182)

Reviewers: Christo Lolov <christo_lolov@yahoo.com>, Chris Egerton <chrise@aiven.io>",2023-03-02 15:10:01,Greg Harris,Not TDD
517b5d2b09ec22cf1734ba1e2d8be9ece5fb0365,"KAFKA-14491: [12/N] Relax requirement that KTable stores must be TimestampedKVStores (#13264)

As part of introducing versioned key-value stores in KIP-889, we want to lift the existing DSL restriction that KTable stores are always TimestampedKeyValueStores to allow for KTable stores which are VersionedKeyValueStores instead. This PR lifts this restriction by replacing raw usages of TimestampedKeyValueStore with a new KeyValueStoreWrapper which supports either TimestampedKeyValueStore or VersionedKeyValueStore.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-03-02 14:14:30,Victoria Xia,Mixed
71fa008b4561628662cf84d895c5eb3eb5dba3d5,"KAFKA-14745: Cache the ReplicationPolicy instance in MirrorConnectorConfig (#13328)


Reviewers: Chris Egerton <fearthecellos@gmail.com>",2023-03-03 12:14:17,Mickael Maison,Mixed
38c409cf33cad1e18e4080f04ba21f127a0c4028,"KAFKA-14084: SCRAM support in KRaft. (#13114)

This commit adds support to store the SCRAM credentials in a cluster with KRaft quorum servers and
no ZK cluster backing the metadata. This includes creating ScramControlManager in the controller,
and adding support for SCRAM to MetadataImage and MetadataDelta.

Change UserScramCredentialRecord to contain only a single tuple (name, mechanism, salt, pw, iter)
rather than a mapping between name and a list. This will avoid creating an excessively large record
if a single user has many entries. Because record ID 11 (UserScramCredentialRecord) has not been
used before, this is a compatible change. SCRAM will be supported in 3.5-IV0 and later.

This commit does not include KIP-900 SCRAM bootstrapping support, or updating the credential cache
on the controller (as opposed to broker). We will implement these in follow-on commits.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",2023-03-03 10:23:34,Proven Provenzano,Mixed
97105a8e5812135515f5a0fa4d5ff554d80df2fe,"KAFKA-14726 Move/rewrite of LogReadInfo, LogOffsetSnapshot, LogStartOffsetIncrementReason to storage module (#13304)

Reviewers: Jun Rao <junrao@gmail.com>, Luke Chen <showuon@gmail.com>, Mickael Maison <mickael.maison@gmail.com>, Ismael Juma <ismael@juma.me.uk>",2023-03-04 06:30:41,Satish Duggana,Mixed
07e2f6cd4d0ba703db510ba72354f8e500f72536,"KAFKA-14578: Move ConsumerPerformance to tools (#13215)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Alexandre Dupriez <alexandre.dupriez@gmail.com>",2023-03-06 18:16:55,Federico Valeri,Mixed
5b295293c06f80accb86df5c46f78c1e5629f86a,"MINOR: Remove unnecessary toString(); fix comment references (#13212)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Divij Vaidya <diviv@amazon.com>, Lucas Brutschy <lbrutschy@confluent.io>",2023-03-06 18:39:04,Christo Lolov,Not TDD
9407b842bd69a47e54776581932950039d5df4fc,"MINOR: fix fault handling in ControllerServer and KafkaServer (#13331)

This PR has two fixes for fault handling. One makes fault handling more
strict on the controller; the other makes it a bit less strict on the
(ZK-based) broker.

In ControllerServer, invoke a fatal fault handler in the catch block of
the ControllerServer.startup() function. This will protect us from cases
where unwinding startup would otherwise encounter a deadlock, or be too
slow.  This is the same reason why we made controller fault handlers
call halt() instead of exit() in KAFKA-14693.  In a sense, this JIRA is
a continuation of that fix since it turns some cases that would
previously have been handled by calling shutdown() into cases where we
invoke a fault handler which will call halt() directly.

In KafkaServer,  when we are in migration-from-zk mode and we create a
RaftManager, it should have a fault handler which simply calls
shutdown() on the broker rather than invoking
ProcessTerminatingFaultHandler. This fixes the bug where we could invoke
the process terminating fault handler from junit tests.

Reviewers: Ron Dagostino <rndgstn@gmail.com>",2023-03-06 11:23:37,Colin Patrick McCabe,Not TDD
84351efd51adb6d4dbd50431a464a9d7ad475b9f,"KAFKA-14491: [13/N] Add versioned store builder and materializer (#13274)

This PR introduces VersionedKeyValueStoreBuilder for building the new versioned stores introduced in KIP-889, analogous to the existing TimestampedKeyValueStoreBuilder for building timestamped stores. This PR also updates the existing KTable store materializer class to materialize versioned stores in addition to timestamped stores. As part of this change, the materializer is renamed from TimestampedKeyValueStoreMaterializer to simply KeyValueStoreMaterializer.

Reviewers: Matthias J. Sax <matthias@confluent.io>, John Roesler <john@confluent.io>",2023-03-06 17:13:33,Victoria Xia,Mixed
c13b49f2d1e80b69e4e86aa4a3c24aa3d0280adf,"Revert ""KAFKA-14371: Remove unused clusterId field from quorum-state file (#13102)"" (#13355)

This reverts commit 0927049a617fa2937a211aab895f6590403130fb.

Reviewers: Luke Chen <showuon@gmail.com>",2023-03-06 18:09:21,José Armando García Sancio,Not TDD
6d37b0f07ff56ede7b4e066cf873f8b67ca449d1,"KAFKA-14462; [2/N] Add ConsumerGroupHeartbeart to GroupCoordinator interface (#13329)

This patch adds ConsumerGroupHeartbeat to the GroupCoordinator interface and implements the API in KafkaApis.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-03-07 09:20:03,David Jacot,Mixed
4d43abf1e09e01fc5e7af52f65e3fbae02cf9771,"KAFKA-14770: Allow dynamic keystore update for brokers if string representation of DN matches even if canonical DNs don't match (#13346)

To avoid mistakes during dynamic broker config updates that could potentially affect clients, we restrict changes that can be performed dynamically without broker restart. For broker keystore updates, we require the DN to be the same for the old and new certificates since this could potentially contain host names used for host name verification by clients. DNs are compared using standard Java implementation of X500Principal.equals() which compares canonical names. If tags of fields change from one with a printable string representation and one without or vice-versa, canonical name check fails even if the actual name is the same since canonical representation converts to hex for some tags only. We can relax the verification to allow dynamic updates in this case by enabling dynamic update if either the canonical name or the RFC2253 string representation of the DN matches.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Kalpesh Patel <kpatel@confluent.io>",2023-03-07 09:41:01,Rajini Sivaram,Mixed
29a1a16668d76a1cc04ec9e39ea13026f2dce1de,"KAFKA-14402: Update AddPartitionsToTxn protocol to batch and handle verifyOnly requests (#13231)

Part 1 of KIP-890

I've updated the API spec and related classes.

Clients should only be able to send up to version 3 requests and that is enforced by using a client builder.

Requests > 4 only require cluster permissions as they are initiated from other brokers. API version 4 is marked as unstable for now.

I've added tests for the batched requests and for the verifyOnly mode.

Also -- minor change to the KafkaApis method to properly match the request name.

Reviewers: Jason Gustafson <jason@confluent.io>, Jeff Kim <jeff.kim@confluent.io>, Guozhang Wang <wangguoz@gmail.com>, David Jacot <djacot@confluent.io>",2023-03-07 09:20:16,Justine Olshan,Mixed
e3817cac894140e0b26c09050b10ce653f7c3d97,"KAFKA-14351: Controller Mutation Quota for KRaft (#13116)

Implement KIP-599 controller mutation quotas for the KRaft controller. These quotas apply to create
topics, create partitions, and delete topic operations. They are specified in terms of number of
partitions.

The approach taken here is to reuse the ControllerMutationQuotaManager that is also used in ZK
mode. The quotas are implemented as Sensor objects and Sensor.checkQuotas enforces the quota,
whereas Sensor.record notes that new partitions have been modified. While ControllerApis handles
fetching the Sensor objects, we must make the final callback to check the quotas from within
QuorumController. The reason is because only QuorumController knows the final number of partitions
that must be modified. (As one example, up-to-date information about the number of partitions that
will be deleted when a topic is deleted is really only available in QuorumController.)

For quota enforcement, the logic is already in place. The KRaft controller is expected to set the
throttle time in the response that is embedded in EnvelopeResponse, but it does not actually apply
the throttle because there is no client connection to throttle. Instead, the broker that forwarded
the request is expected to return the throttle value from the controller and to throttle the client
connection. It also applies its own request quota, so the enforced/returned quota is the maximum of
the two.

This PR also installs a DynamicConfigPublisher in ControllerServer. This allows dynamic
configurations to be published on the controller. Previously, they could be set, but they were not
applied. Note that we still don't have a good way to set node-level configurations for isolatied
controllers. However, this will allow us to set cluster configs (aka default node configs) and have
them take effect on the controllers.

In a similar vein, this PR separates out the dynamic client quota publisher logic used on the
broker into DynamicClientQuotaPublisher. We can now install this on both BrokerServer and
ControllerServer. This makes dynamically configuring quotas (such as controller mutation quotas)
possible.

Also add a ducktape test, controller_mutation_quota_test.py.

Reviewers: David Jacot <djacot@confluent.io>, Ismael Juma <ismael@juma.me.uk>, Colin P. McCabe <cmccabe@apache.org>",2023-03-07 11:25:34,Ron Dagostino,Mixed
6fbe4d85a22872b97ec45614cc219d3a1da42f20,"KAFKA-14761 Adding integration test for the prototype consumer (#13303)

The goal of this PR is to add more tests to the PrototypeAsyncConsumer to test

* Successful startup and shutdown.
* Commit.

I also added integration tests:

* Test commitAsync()
* Test commitSync()
Note that I still need to implement committed() to test if commitSync() has been successfully committed.
Additional things:

Change KafkaConsumer<K, V> to Consumer<K, V> to use different implementations

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Guozhang Wang <wangguoz@gmail.com>",2023-03-07 16:15:59,Philip Nee,Mixed
788cc11f4554f515e4002992936c36b68c989f2d,"KAFKA-14462; [3/N] Add `onNewMetadataImage` to `GroupCoordinator` interface (#13357)

The new group coordinator needs to access cluster metadata (e.g. topics, partitions, etc.) and it needs a mechanism to be notified when the metadata changes (e.g. to trigger a rebalance). In KRaft clusters, the easiest is to subscribe to metadata changes via the MetadataPublisher.

Reviewers: Justine Olshan <jolshan@confluent.io>",2023-03-08 08:52:01,David Jacot,Mixed
e28e0bf0f2c21206abccfffb280605dd02404678,"KAFKA-14524: Rewrite KafkaMetricsGroup in Java (#13067)

* KAFKA-14524: Rewrite KafkaMetricsGroup in Java

Instead of being a base trait for classes, `KafkaMetricsGroup` is now an independent object. User classes could override methods in it to adjust its behavior like they used to with the trait model.

Some classes were extending the `KafkaMetricsGroup` trait, but it wasn't actually used.

Reviewers: Ismael Juma <ismael@juma.me.uk>, lbownik <lukasz.bownik@gmail.com>, Satish Duggana <satishd@pache.org>",2023-03-08 15:59:51,Ivan Yurchenko,Mixed
39d41e5aac4e8cf303040b0bb12c122832be5ea1,"KAFKA-14781: Downgrade MM2 log message severity when no ACL authorizer is configured on source broker (#13351)

Reviewers: Mickael Maison <mickael.maison@gmail.com>",2023-03-08 10:25:55,Chris Egerton,Mixed
c66c412862f9c83d2210a0c07258415de808566b,"MINOR: fix authorizer reconfiguration in KRaft mode (#13360)

Fix a bug with authorizer reconfiguration in KRaft mode. The bug
happened because we were invoking DynamicBrokerConfig.addReconfigurables
before initializing BrokerServer.authorizer. Add a test of reconfiguring
the Authorizer. Also, in testReconfigureControllerClientQuotas, test
both combined and isolated mode.

Reviewers: Ron Dagostino <rdagostino@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2023-03-08 14:14:52,Colin Patrick McCabe,Not TDD
00c7a018b8b1f8676290cd3bc41cbf6a2527bb89,"KAFKA-14794; Decode base64 JSON string (#13363)

A binary value (array of bytes) can be a BinaryNode or a TextNode. When it is a BinaryNode, the method binaryValue() always returns non-null. When it is a TextNode, the method binaryValue() will return non-null if the value is a base64 string. For all other JSON nodes binaryValue() returns null.

Reviewers: Colin Patrick McCabe <cmccabe@apache.org>",2023-03-08 18:40:29,José Armando García Sancio,Mixed
c5240c0390892fe9ecbe5285185c370e7be8b2aa,"KAFKA-14317: ProduceRequest timeouts are logged as network exceptions (#12813)

Minor changes to `Sender` and `NetworkClient` so that we can log timeouts during `ProduceRequest` with a more precise error message, denoting a timeout vs. ""generic"" network error.

Reviewers: Philip Nee <pnee@confluent.io>, Guozhang Wang <guozhang@apache.org>, David Jacot <djacot@confluent.io>",2023-03-09 10:04:07,Kirk True,Mixed
aaa976a3409f61e1e65ed49742567c08a502d9e1,"MINOR: Some metadata publishing fixes and refactors (#13337)

This PR refactors MetadataPublisher's interface a bit. There is now an onControllerChange
callback. This is something that some publishers might want. A good example is ZkMigrationClient.
Instead of two different publish functions (one for snapshots, one for log deltas), we now have a single onMetadataUpdate function. Most publishers didn't want to do anything different in those two cases.
The ones that do want to do something different for snapshots can always check the manifest type.
The close function now has a default empty implementation, since most publishers didn't need to do
anything there.

Move the SCRAM logic out of BrokerMetadataPublisher and run it on the controller as well.

On the broker, simply use dynamicClientQuotaPublisher to handle dynamic client quotas changes.
That is what the controller already does, and the code is exactly the same in both cases.

Fix the logging in FutureUtils.waitWithLogging a bit. Previously, when invoked from BrokerServer
or ControllerServer, it did not include the standard ""[Controller 123] "" style prefix indicating server
name and ID. This was confusing, especially when debugging junit tests.

Reviewers: Ron Dagostino <rdagostino@confluent.io>, David Arthur <mumrah@gmail.com>",2023-03-09 14:52:40,Colin Patrick McCabe,Mixed
5f6a050bfee09b634497f9ba35e2964289be1e4d,"MINOR; Export control record type value (#13366)

Reviewers: David Arthur <mumrah@gmail.com>",2023-03-09 15:15:39,José Armando García Sancio,Mixed
c74c0f2facde2b392ab745144d6ad520575ab9ef,"KAFKA-14758: Extract inner classes from Fetcher for reuse in refactoring (#13301)

The Fetcher class is used internally by the KafkaConsumer to fetch records from the brokers. There is ongoing work to create a new consumer implementation with a significantly refactored threading model. The threading refactor work requires a similarly refactored Fetcher.

This task includes refactoring Fetcher by extracting out the inner classes into top-level (though still in internal) so that those classes can be referenced by forthcoming refactored fetch logic.

Reviewers: Philip Nee <philipnee@gmail.com>, Guozhang Wang <wangguoz@gmail.com>",2023-03-10 10:17:14,Kirk True,Mixed
5d597b0fc81a1e77905d57666069b336eba8805c,"MINOR: Replace BrokerMetadataListener with MetadataLoader (#13344)

Replace BrokerMetadataListener with MetadataLoader. BrokerMetadataListener was, in a sense, an
early prototype of MetadataLoader. It constructed a MetadataImage object from records supplied by
the Raft layer.

MetadataLoader is a rewrite of this code with several improvements.

- It is in Java, and not part of the core gradle module.

- It is not broker-specific. This is especially useful in combined mode where it means we do not
  have to have a separate, controller-specific code path for creating MetadataImage objects.

- It supports multiple publishers rather than a single publisher. The publishers can be dynamically
  added and removed.

This PR also removes BrokerMetadataSnapshotter in favor of the code path which the controller is
already using, org.apache.kafka.image.publisher.SnapshotGenerator. This means we only have to
maintain one snapshotter, rather than two.

Reviewers: David Arthur <mumrah@gmail.com>",2023-03-14 10:24:37,Colin Patrick McCabe,Mixed
404a833df7de9a7d5efe35beb5bafb7c6972601e,"KAFKA-14799: Ignore source task requests to abort empty transactions (#13379)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2023-03-14 15:10:29,Chris Egerton,Mixed
d01662fb0f7bbb43e6a2d22f5ea88b5bf136057c,"KAFKA-14793: Propagate Topic Ids to the Group Coordinator during Offsets Commit (#13378)

This patch refactors the GroupCoordinator to use TopicIdPartition on the offsets commit paths. This change is required by https://github.com/apache/kafka/pull/13240 in order to correctly handle topic ids.

Reviewers: David Jacot <djacot@confluent.io>",2023-03-15 12:20:26,Alexandre Dupriez,Mixed
8e4c0d0b04580cde1e15e7b4793bae747d38999c,"MINOR: Fixed ProducerPerformance still counting successful sending when sending failed (#13348)

Reviewers: Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2023-03-15 21:30:51,hudeqi,Mixed
44e613c4cd1a2b7303da7dd30d47bbe87090131f,"KAFKA-13884; Only voters flush on Fetch response (#13396)

The leader only requires that voters have flushed their log up to the fetch offset before sending a fetch request.

This change only flushes the log when handling the fetch response, if the follower is a voter. This should improve the disk performance on observers (brokers).

Reviewers: Jason Gustafson <jason@confluent.io>",2023-03-15 12:06:41,José Armando García Sancio,Mixed
3137b75d40c1857a7bc5191093142ab0fa1e6582,"KAFKA-14801: Encoded configs are not decoded before ZK migration (#13384)

Encoded configurations need to be decoded during ZK migration.

Reviewers: David Arthur <mumrah@gmail.com>",2023-03-15 15:24:22,Akhilesh C,Mixed
79b5f7f1ce2791fcebf70a447e5530c60b768702,"KAFKA-14617: Add ReplicaState to FetchRequest (KIP-903) (#13323)

This patch is the first part of KIP-903. It updates the FetchRequest to include the new tagged ReplicaState field which replaces the now deprecated ReplicaId field. The FetchRequest version is bumped to version 15 and the MetadataVersion to 3.5-IV1.

Reviewers: David Jacot <djacot@confluent.io>",2023-03-16 14:04:34,Calvin Liu,Mixed
279c237632878347f0a7bbb5f09a5f9924829419,"Revert ""MINOR: Fixed ProducerPerformance still counting successful sending when sending failed (#13348)"" (#13401)

This reverts commit 8e4c0d0b04580cde1e15e7b4793bae747d38999c.

Reviewers: Luke Chen <showuon@gmail.com>",2023-03-16 21:26:01,Chia-Ping Tsai,Mixed
5dcdf71dec4124b67f13fcd1561faef3dac38d55,"MINOR: Improved error handling in ZK migration (#13372)

This patch fixes many small issues to improve error handling and logging during the ZK migration. A test was added
to simulate a ZK session expiration to ensure the correctness of the migration driver.

With this change, ZK errors thrown during the migration will not hit the fault handler registered with with
KRaftMigrationDriver, but they will be logged.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-03-16 14:21:18,David Arthur,Mixed
ddd652c672b503de52b6cb2be20c29c7a5e6816f,"MINOR: Standardize KRaft logging, thread names, and terminology (#13390)

Standardize KRaft thread names.

- Always use kebab case. That is, ""my-thread-name"".

- Thread prefixes are just strings, not Option[String] or Optional<String>.
  If you don't want a prefix, use the empty string.

- Thread prefixes end in a dash (except the empty prefix). Then you can
  calculate thread names as $prefix + ""my-thread-name""

- Broker-only components get ""broker-$id-"" as a thread name prefix. For example, ""broker-1-""

- Controller-only components get ""controller-$id-"" as a thread name prefix. For example, ""controller-1-""

- Shared components get ""kafka-$id-"" as a thread name prefix. For example, ""kafka-0-""

- Always pass a prefix to KafkaEventQueue, so that threads have names like
  ""broker-0-metadata-loader-event-handler"" rather than ""event-handler"". Prior to this PR, we had
  several threads just named ""EventHandler"" which was not helpful for debugging.

- QuorumController thread name is ""quorum-controller-123-event-handler""

- Don't set a thread prefix for replication threads started by ReplicaManager. They run only on the
  broker, and already include the broker ID.

Standardize KRaft slf4j log prefixes.

- Names should be of the form ""[ComponentName id=$id] "". So for a ControllerServer with ID 123, we
  will have ""[ControllerServer id=123] ""

- For the QuorumController class, use the prefix ""[QuorumController id=$id] "" rather than
  ""[Controller <nodeId] "", to make it clearer that this is a KRaft controller.

- In BrokerLifecycleManager, add isZkBroker=true to the log prefix for the migration case.

Standardize KRaft terminology.

- All synonyms of combined mode (colocated, coresident, etc.) should be replaced by ""combined""

- All synonyms of isolated mode (remote, non-colocated, distributed, etc.) should be replaced by
  ""isolated"".",2023-03-16 15:33:03,Colin Patrick McCabe,Mixed
e427897c67c83ada340f731dc952bfd49d6cc32e,"KAFKA-14816: Only load SSL properties when issuing cross-worker requests to HTTPS URLs (#13415)

This fixes a regression introduced in #12828, which caused workers to start unconditionally loading (and therefore validating) SSL-related properties when issuing REST requests to other workers. That was fine for the most part, but caused unnecessary failures when workers were configured with invalid SSL-related properties and their REST API used HTTP instead of HTTPS.

Reviewers: Ian McDonald <imcdonald@confluent.io>, Greg Harris <greg.harris@aiven.io>, Yash Mayya <yash.mayya@gmail.com>, Justine Olshan <jolshan@confluent.io>",2023-03-20 08:32:01,Chris Egerton,Mixed
df5850274d3f9186cdb4a2288193c8977a4552bf,"MINOR: Expand use of PartitionAssignment (#13402)

Updates ReplicationControlManager and PartitionReassignmentReplicas to use PartitionAssignment.

Reviewers: José Armando García Sancio <jsancio@apache.org>",2023-03-20 13:44:54,andymg3,Mixed
6fae237638e908cbe9c81de44ed73280107a4faa,"MINOR: Use JUnit-5 extension to enforce strict stubbing (#13347)

A privious change disabled strict stubbing for the `RocksDBMetricsRecorderTest`. To re-enable the behavior in JUnit-5, we need to pull in a new dependency in the `streams` gradle project.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2023-03-20 13:49:35,Lucas Brutschy,Not TDD
361095a1a755d789b9b690a3f55ac5c29f7f1e64,"KAFKA-14491: [17/N] Refactor segments cleanup logic

Part of KIP-899.

AbstractSegments automatically calls the helper method to clean up expired segments as part of getOrCreateSegmentIfLive(). This works fine for windowed store implementations which call getOrCreateSegmentIfLive() exactly once per put() call, but is inefficient and difficult to reason about for the new RocksDBVersionedStore implementation (cf. #13188) which makes potentially multiple calls to getOrCreateSegmentIfLive() for different segments for a single put() call. This PR addresses this by refactoring the call to clean up expired segments out of getOrCreateSegmentIfLive(), opting to have the different segments implementations specify when cleanup should occur instead. After this PR, RocksDBVersionedStore only cleans up expired segments once per call to put().

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-03-20 20:03:50,Victoria Xia,Mixed
dc1cd001be551615528a506c747bbdc90687c8fe,"KAFKA-14795: Provide message formatter for RemoteLogMetadata (#13362)

* KAFKA-14795: Provide message formatter for RemoteLogMetadata

This commit introduces a formatter for `RemoteLogMetadata`.

Example usage:
```bash
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic __remote_log_metadata --from-beginning --formatter 'org.apache.kafka.server.log.remote.metadata.storage.serialization.RemoteLogMetadataSerde$RemoteLogMetadataFormatter'

RemoteLogSegmentMetadata{remoteLogSegmentId=RemoteLogSegmentId{topicIdPartition=M1z1YtfhQ5i7oqLNve_0UQ:topic1-0, id=iWtc1Z6xQu2_DJXTklzKxQ}, startOffset=97990, endOffset=98467, brokerId=0, maxTimestampMs=1678292889855, eventTimestampMs=1678292938280, segmentLeaderEpochs={0=97990}, segmentSizeInBytes=511460, state=COPY_SEGMENT_STARTED}
```

Reviewers: Luke Chen <showuon@gmail.com>, Divij Vaidya <diviv@amazon.com>, Satish Duggana <satishd@apache.org>",2023-03-21 14:35:49,Ivan Yurchenko,Not TDD
ccda370e9537056d1dc46202ccc8db4105acad56,"KAFKA-6891: send.buffer.bytes should be allowed to set -1 in KafkaConnect (#13398)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2023-03-21 16:45:40,Zheng-Xian Li,Mixed
aef004edeec36ac958dbb5499522115b7e99803b,"KAFKA-14812:ProducerPerformance still counting successful sending in console when sending failed (#13404)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2023-03-21 16:59:18,hudeqi,Mixed
897ced12eebe7cea7a5ed9227f463107d858fbc2,"KAFKA-14797: Emit offset sync when offset translation lag would exceed max.offset.lag (#13367)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-03-21 09:31:08,Greg Harris,Mixed
1b278c4e555c14d93b13c92a8ab633094820dde1,"KAFKA-8713: Allow using null for field in JsonConverter (KIP-581) (#13419)

Add a new configuration replace.null.with.default to allow using null instead of the default value.

Reviewers: Chris Egerton <fearthecellos@gmail.com>",2023-03-21 17:57:28,Mickael Maison,Mixed
1d8f79964e9578f3769fd13c2535988bfc803696,"KAFKA-14740: Add source tag to MirrorSourceMetrics - KIP-911 (#13420)

New add.source.alias.to.metrics setting to add the source cluster alias to the MirrorSourceConnector metrics

Reviewers: Chris Egerton <fearthecellos@gmail.com>",2023-03-21 19:16:04,Mickael Maison,Mixed
d604534cc34f640e1baf36085bac9911b47a8914,"MINOR; Increase log level of some rare events (#13430)

To help debug KRaft's behavior this change increases the log level of
some rare messages to INFO level.

Reviewers: Jason Gustafson <jason@confluent.io>",2023-03-21 17:02:38,José Armando García Sancio,Not TDD
bfd15299b1f31b1f5ba0f2c9145d4abc3042405c,"KAFKA-14491: [14/N] Set changelog topic configs for versioned stores (#13292)

Sets the correct topic configs for changelog topics for versioned stores introduced in KIP-889. Changelog topics for versioned stores differ from those for non-versioned stores only in that min.compaction.lag.ms needs to be set in order to prevent version history from being compacted prematurely.

The value for min.compaction.lag.ms is equal to the store's history retention plus some buffer to account for the broker's use of wall-clock time in performing compactions. This buffer is analogous to the windowstore.changelog.additional.retention.ms value for window store changelog topic retention time, and uses the same default of 24 hours. In the future, we can propose a KIP to expose a config such as versionedstore.changelog.additional.compaction.lag.ms to allow users to tune this value.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-03-21 17:08:10,Victoria Xia,Mixed
1560c5bd7e556ca6c0f49934b5ad3542ed6208fb,"KAFKA-14491: [18/N] Update versioned store to check latest value on timestamped get (#13409)

Part of KIP-889.

Prior to this PR, versioned stores always returned null for get(key, timestamp) calls where the timestamp has exceeded the store's history retention, even if the latest value for the key (i.e., the one returned from get(key)) satisfies the timestamp bound. This was an oversight from the earlier implementation -- get(key, timestamp) should still return a record in this situation since the record exists in the store. This PR updates both the javadocs and the implementation accordingly.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-03-21 17:12:05,Victoria Xia,Mixed
45ecae6a28fe820eb2698c8a375c83ee15036f5c,"KAFKA-14491: [15/N] Add integration tests for versioned stores (#13340)

Adds integration tests for the new versioned stores introduced in KIP-889.

This PR also contains a small bugfix for the restore record converter, required to get the tests above to pass: even though versioned stores are timestamped stores, we do not want to use the record converter for prepending timestamps when restoring a versioned store.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-03-22 10:26:06,Victoria Xia,Not TDD
3c25b311cbe5c6c77b764bd9dbac28ee2c0b4f94,"KAFKA-14814: Skip Connect target state updates when the configs store has same state (#13426)

Reviewers: Yash Mayya <yash.mayya@gmail.com>, Chris Egerton <chrise@aiven.io>",2023-03-23 11:23:38,Chaitanya Mukka,Mixed
f79c2a6e04129832eacec60bbc180173ecc37549,"MINOR:Incorrect/canonical use of constants in AdminClientConfig and StreamsConfigTest (#13427)

Co-authored-by: Deqi Hu <deqi.hu@shopee.com>

Reviewers: Ziming Deng <dengziming1993@gmail.com>, Guozhang Wang <guozhang.wang.us@gmail.com>",2023-03-23 09:36:35,hudeqi,Not TDD
71ca8ef4ecd8522ac6dbf86daf4a3a9540482950,"KAFKA-14722: Make BooleanSerde public (#13382)

KAFKA-14722: Make BooleanSerde public (#13328)

Addition of boolean serde
https://cwiki.apache.org/confluence/display/KAFKA/KIP-907%3A+Add+Boolean+Serde+to+public+interface

During the task KAFKA-14491 Victoria added BooleanSerde class, It will be useful to have such class in public package.

Reviewers: Walker Carlson <wcarlson@confluent.io>, Lucas Brutschy <lbrutschy@confluent.io>, Divij Vaidya <diviv@amazon.com>",2023-03-24 10:41:51,Spacrocket,Not TDD
ed400e4c0d779dcb0b6fe438594328e81b1a49db,"KAFKA-14835: Create ControllerMetadataMetricsPublisher (#13438)

Separate out KRaft controller metrics into two groups: metrics directly managed by the
QuorumController, and metrics handled by an external publisher. This separation of concerns makes
the code easier to reason about, by clarifying what metrics can be changed where.

The external publisher, ControllerServerMetricsPublisher, handles all metrics which are related to
the content of metadata. For example, metrics about number of topics or number of partitions, etc.
etc. It fits into the MetadataLoader metadata publishing framework as another publisher.  Since
ControllerServerMetricsPublisher operates off of a MetadataImage, we don't have to create
(essentially) another copy of the metadata in memory, as ControllerMetricsManager. This reduces
memory consumption. Another benefit of operating off of the MetadataImage is that we don't have to
have special handling for each record type, like we do now in ControllerMetricsManager.

Reviewers: David Arthur <mumrah@gmail.com>",2023-03-24 11:26:53,Colin Patrick McCabe,Mixed
a3252629a37344be1f1f86a77cf685f9c147be4d,"KAFKA-14365: Extract common logic from Fetcher (#13425)

* KAFKA-14365: Extract common logic from Fetcher

Extract logic from Fetcher into AbstractFetcher.

Also introduce FetchConfig as a more concise way to delineate state from
incoming configuration.

Formalized the defaults in CommonClientConfigs and ConsumerConfig to be
accessible elsewhere.

* Removed overridden methods in favor of synchronizing where needed

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2023-03-24 14:33:13,Kirk True,Mixed
18fba41946690aace6863f5114b7453383b0228a,"KAFKA-10244 An new java interface to replace 'kafka.common.MessageReader' (#13393)

Reviewers: Mickael Maison <mimaison@users.noreply.github.com>",2023-03-25 21:27:02,Chia-Ping Tsai,Mixed
7438f100cf409a1ca178b15b6b7bcfd99e541098,"KAFKA-14774 the removed listeners should not be reconfigurable (#13326)

Reviewers: Mickael Maison <mimaison@users.noreply.github.com>",2023-03-27 18:48:31,Chia-Ping Tsai,Not TDD
31440b00f3ed8de65f368d41d6cf2efb07ca4a5c,"KAFKA-14848: KafkaConsumer incorrectly passes locally-scoped serializers to FetchConfig (#13452)

Fix for a NPE bug that was caused by referring to a local variable and not the instance variable of the deserializers.

Co-authored-by: Robert Yokota <1761488+rayokota@users.noreply.github.com>

Reviewers: Robert Yokota <1761488+rayokota@users.noreply.github.com>, Guozhang Wang <wangguoz@gmail.com>",2023-03-27 09:53:12,Kirk True,Mixed
f1b3732fa64372327377834954561d2e63e7d2ce,"KAFKA-14796 Migrate ACLs from AclAuthorizor to KRaft (#13368)

This patch refactors the loadCache method in AclAuthorizer to make it reusable by ZkMigrationClient.
The loaded ACLs are converted to AccessControlEntryRecord. I noticed we still have the defunct
AccessControlRecord, so I've deleted it.

Also included here are the methods to write ACL changes back to ZK while in dual-write mode.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>, Colin P. McCabe <cmccabe@apache.org>",2023-03-27 16:12:02,David Arthur,Mixed
c14f56b48461f01743146d58987bc8661ba0d459,"KAFKA-14586: Moving StreamResetter to tools (#13127)

Moves StreamResetter to tools project.

Reviewers: Federico Valeri <fedevaleri@gmail.com>, Christo Lolov <lolovc@amazon.com>, Bruno Cadonna <cadonna@apache.org>",2023-03-28 14:43:22,vamossagar12,Mixed
f7ea9cfb50cbd0d2f295df9ec07240581aa1046f,"KAFKA-14837/14842:Avoid the rebalance caused by the addition and deletion of irrelevant groups for MirrorCheckPointConnector (#13446)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-03-28 09:19:52,hudeqi,Mixed
5afedd9ac37c4d740f47867cfd31eaed15dc542f,"KAFKA-14843: Include Connect framework properties when retrieving connector config definitions (#13445)

Reviewers: Yash Mayya <yash.mayya@gmail.com>, Greg Harris <greg.harris@aiven.io>, Chris Egerton <chrise@aiven.io>",2023-03-28 11:26:23,Jorge Esteban Quilcate Otoya,Mixed
6e8d0d9850b05fc1de0ceaf77834e68939f782c1,"KAFKA-14853 the serializer/deserialize which extends ClusterResourceListener is not added to Metadata (#13460)

Reviewers: dengziming <dengziming1993@gmail.com>",2023-03-29 16:02:04,Chia-Ping Tsai,Not TDD
379b6978a04c171bcc64331a095f1c97eb4e1830,"KAFKA-14829: Consolidate reassignment logic into PartitionReassignmentReplicas (#13440)

Currently, we have various bits of reassignment logic spread across different classes. For example, ReplicationControlManager contains logic for when a reassignment is in progress, which is duplication in PartitionChangeBuilder. Another example is PartitionReassignmentRevert which contains logic for how to undo/revert a reassignment. The idea here is to move the logic to PartitionReassignmentReplicas so it's more testable and easier to reason about.

Reviewers: José Armando García Sancio <jsancio@apache.org>",2023-03-29 10:12:40,andymg3,Mixed
09e59bc7761a6b9ec1437b3decdfcd7b5fff868e,"KAFKA-14857: Fix some MetadataLoader bugs (#13462)

The MetadataLoader is not supposed to publish metadata updates until we have loaded up to the high
water mark. Previously, this logic was broken, and we published updates immediately. This PR fixes
that and adds a junit test.

Another issue is that the MetadataLoader previously assumed that we would periodically get
callbacks from the Raft layer even if nothing had happened. We relied on this to install new
publishers in a timely fashion, for example. However, in older MetadataVersions that don't include
NoOpRecord, this is not a safe assumption.

Aside from the above changes, also fix a deadlock in SnapshotGeneratorTest, fix the log prefix for
BrokerLifecycleManager, and remove metadata publishers on brokerserver shutdown (like we do for
controllers).

Reviewers: David Arthur <mumrah@gmail.com>, dengziming <dengziming1993@gmail.com>",2023-03-29 12:30:12,Colin Patrick McCabe,Mixed
5c0e4aa67642ac0df1bbb79be84ef579b04194c2,"KAFKA-14468: Committed API (#13380)

In this PR, I implemented the committed API. Here are the specifics:

* the CommitRequestManager handles committed() request.
* I implemented a UnsentOffsetFetchRequestState to handle deduping the request: because we don't want to send the exact requests repeatedly.
* I implemented the retry mechanism: Some retriable errors will be retried automatically
* ClientResponse errors are handled in the handlers.
* Some of the top-level APIs were refactored lightly.

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2023-03-29 16:09:52,Philip Nee,Mixed
2b26db0d38f7245505812e4cb3fa622fc07ba6c8,"Switch to SplittableRandom in ProducerPerformance utility (#13482)

Why:
Using java.util.Random to generate every byte sent from the ProducerPerformance
appears to be a limiting factor. Throughput of the ProducerPerformance script is
higher with a file of records as compared to randomly generated records.

On my machine a single thread can generate ~100MB/second of uppercase letters using
java.util.Random and ~300MB/sec using java.util.SplittableRandom. This is a limit on
throughput.

Note: you can optimise further by expanding it from 26 letters to 32 letter generated
as it is more efficient to generate a nicely distributed int when the bound is a
power of two.

Reviewers: Luke Chen <showuon@gmail.com>",2023-03-31 14:52:10,Robert Young,Mixed
8c88cdb7186b1d594f991eb324356dcfcabdf18a,"KAFKA-14617: Update AlterPartitionRequest and enable Kraft controller to reject stale request. (#13408)

Second part of the [KIP-903](https://cwiki.apache.org/confluence/display/KAFKA/KIP-903%3A+Replicas+with+stale+broker+epoch+should+not+be+allowed+to+join+the+ISR), it updates the AlterPartitionRequest:
- Deprecate the NewIsr field
- Create a new field BrokerState with BrokerId and BrokerEpoch
- Bump the AlterPartition version to 3

With this change, the Quorum Controller is enabled to reject stale AlterPartition request.

Reviewers: Jun Rao <junrao@gmail.com>, David Jacot <djacot@confluent.io>",2023-03-31 11:27:42,Calvin Liu,Mixed
3c4472d701a7e9d9b8714a0b9d87ae190d1679fb,"KAFKA-14867: Trigger rebalance when replica racks change if client.rack is configured (KIP-881) (#13474)

When `client.rack` is configured for consumers, we perform rack-aware consumer partition assignment to improve locality. After/during reassignments, replica racks may change, so to ensure optimal consumer assignment, trigger rebalance from the leader when set of racks of any partition changes.

Reviewers: David Jacot <djacot@confluent.io>",2023-03-31 15:01:07,Rajini Sivaram,Mixed
0aa365add881428815c3d71fd5ce575fb8fb8089,"KAFKA-14838: Add flow/connector/task/role information to MM2 Kafka client.id configs (#13458)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-03-31 10:50:11,Dániel Urbán,Mixed
145ef2d1e06abd3e4f4f9220b74c07da51e8bf79,"MINOR: fix BrokerMetadataPublisherTest.testExceptionInUpdateCoordinator

Fix a case where we were getting an exception because we removed a publisher, but left it in
BrokerServer.metadataPublishers (resulting in us trying to remove it during broker shutdown.)",2023-03-31 10:15:52,Colin P. McCabe,Not TDD
970dea60e8674ca54a1458fd20c685704cc01f7c,"KAFKA-14785 (KIP-875): Connect offset read REST API (#13434)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-04-02 13:09:33,Yash Mayya,Mixed
1f0ae71fb328288152a938aa2a259f9646783f60,"KAFKA-14452: Make sticky assignors rack-aware if client rack is configured (KIP-881) (#13350)

Best-effort rack alignment for sticky assignors when both consumer racks and partition racks are available with the protocol changes introduced in KIP-881. Rack-aware assignment is enabled by configuring client.rack for consumers. The assignment builders attempt to align on racks on a best-effort basis, but prioritize balanced assignment over rack alignment.

Reviewers: David Jacot <djacot@confluent.io>",2023-04-03 09:22:47,Rajini Sivaram,Mixed
f503aa3ab4963149b854c9af8832e0dca46e3ba4,"KAFKA-14491: [16/N] Add recovery logic for store inconsistency due to failed write (#13364)

The RocksDB-based implementation of versioned stores introduced via KIP-889 consists of a ""latest value store"" and separate (logical) ""segments stores."" A single put operation may need to modify multiple (two) segments, or both a segment and the latest value store, which opens the possibility to store inconsistencies if the first write succeeds while the later one fails. When this happens, Streams will error out, but the store still needs to be able to recover upon restart. This PR adds the necessary repair logic into RocksDBVersionedStore to effectively undo the earlier failed write when a store inconsistency is encountered.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-04-03 21:23:48,Victoria Xia,Mixed
63fee01366e6ce98b9dfafd279a45d40b80e282d,"KAFKA-14491: [19/N] Combine versioned store RocksDB instances into one (#13431)

The RocksDB-based versioned store implementation introduced in KIP-889 currently uses two physical RocksDB instances per store instance: one for the ""latest value store"" and another for the ""segments store."" This PR combines those two RocksDB instances into one by representing the latest value store as a special ""reserved"" segment within the segments store. This reserved segment has segment ID -1, is never expired, and is not included in the regular Segments methods for getting or creating segments, but is represented in the physical RocksDB instance the same way as any other segment.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-04-03 21:27:19,Victoria Xia,Mixed
6d36db1c78ff28ed3e6134e271e72a5c2ff1c276,"KAFKA-14765 and KAFKA-14776: Support for SCRAM at bootstrap with integration tests (#13374)

Implement KIP-900

Update kafka-storage to be able to add SCRAM records to the bootstrap metadata file at format time so that SCRAM is enabled at initial start (bootstrap) of KRaft cluster. Includes unit tests.

Update ./core/src/test/scala/integration/kafka/api/SaslScramSslEndToEndAuthorizationTest.scala to use bootstrap and
enable the test to run with both ZK and KRaft quorum.

Moved the one test from ScramServerStartupTest.scala into SaslScramSslEndToEndAuthorizationTest.scala. This test is really small, so there was no point in recreating all the bootstrap startup just for a 5 line test when it could easily be run elsewhere.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Manikumar Reddy <manikumar.reddy@gmail.com>",2023-04-04 08:34:09,Proven Provenzano,Mixed
beb0be5fe45d08ff45d6cdddfd86feac8500a7d7,"KAFKA-14533: Do not interrupt state-updater thread during shutdown (#13318)

1. Fix the StateUpdater shutdown procedure: a) in shutdown, we first set the running flag, then notify the condition; b) in the thread's waitIfAllChangelogsCompletelyRead block, we collapse the if condition together with the while condition so that we always check all four conditions once the thread is notified inside the while loop. As a result, shutdown procedure would not involve any thread interruptions anymore.
2. Print fine-grained streams exception when list-offset fails, this is a byproduct of the debugging procedure but I think it's worth keeping since it has better operational visibilities.
3. Some nit logging improvements (including moving logger from the inner thread into the outer class to also add some more logging).
4. Re-enable state-updater in SmokeTestDriverIntegrationTest.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>, Bruno Cadonna <cadonna@apache.org>",2023-04-04 15:29:00,Guozhang Wang,Mixed
31f9a54cba38fbdc015590bd82c1f1d62839f09f,"KAFKA-14850: introduce InMemoryLeaderEpochCheckpoint (#13456)

The motivation for introducing InMemoryLeaderEpochCheckpoint is to allow remote log manager to create the RemoteLogSegmentMetadata(RLSM) with the correct leader epoch info for a specific segment. To do that, we need to rely on the LeaderEpochCheckpointCache to truncate from start and end, to get the epoch info. However, we don't really want to truncate the epochs in cache (and write to checkpoint file in the end). So, we introduce this InMemoryLeaderEpochCheckpoint to feed into LeaderEpochCheckpointCache, and when we truncate the epoch for RLSM, we can do them in memory without affecting the checkpoint file, and without interacting with file system.

Reviewers: Divij Vaidya <diviv@amazon.com>, Satish Duggana <satishd@apache.org>",2023-04-05 20:11:32,Luke Chen,Mixed
df59cc1a0151accb82082baaa56543ea157830d2,"KAFKA-14491: [20/N] Add public-facing methods for versioned stores (#13442)

Until this PR, all the code added for KIP-889 for introducing versioned stores to Kafka Streams has been accessible from internal packages only. This PR exposes the stores via public Stores.java methods, and also updates the TopologyTestDriver.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-04-05 09:27:53,Victoria Xia,Mixed
653baa669486cca928a7bafba8ec47626624fbdc,"KAFKA-10199: Add task updater metrics, part 2 (#13300)

Part of KIP-869

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2023-04-05 11:49:08,Guozhang Wang,Mixed
b2ee6df1c4cfee921deb4e8b9ea48ee0939d85dc,"KAFKA-14172: Should clear cache when active recycled from standby (#13369)

This fix is inspired by #12540.

1. Added a clearCache function for CachedStateStore, which would be triggered upon recycling a state manager.
2. Added the integration test inherited from #12540 .
3. Improved some log4j entries.
4. Found and fixed a minor issue with log4j prefix.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2023-04-05 16:05:11,Guozhang Wang,Mixed
290eeed7bab144eedd648ae6735b2c9285c1f697,"KAFKA-14880; TransactionMetadata with producer epoch -1 should be expirable (#13499)

We have seen the following error in logs:

```
""Mar 22, 2019 @ 21:57:56.655"",Error,""kafka-0-0"",""transaction-log-manager-0"",""Uncaught exception in scheduled task 'transactionalId-expiration'"",""java.lang.IllegalArgumentException: Illegal new producer epoch -1
```

Investigations showed that it is actually possible for a transaction metadata object to still have -1 as producer epoch when it transitions to Dead.

When a transaction metadata is created for the first time (in handleInitProducerId), it has -1 as its producer epoch. Then a producer epoch is attributed and the transaction coordinator tries to persist the change. If the write fail for instance because there is an under min isr, the transaction metadata remains with its epoch as -1 forever or until the init producer id is retried.

This means that it is possible for transaction metadata to remain with -1 as producer epoch until it gets expired. At the moment, this is not allowed because we enforce a producer epoch greater or equals to 0 in prepareTransitionTo.

Reviewers: Luke Chen <showuon@gmail.com>, Justine Olshan <jolshan@confluent.io>",2023-04-06 08:45:16,David Jacot,Not TDD
4f34ce1b49199c151795551876c61fec48627c47,"KAFKA-14376: Add ConfigProvider to make use of environment variables KIP-887 (#12992)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>, Jordan Moore <crikket.007@gmail.com>, Chris Egerton <fearthecellos@gmail.com>",2023-04-06 17:22:12,Roman Schmitz,Mixed
f02f5f8c8a8b1f196a1904fe2bd78f228980e1d6,"MINOR: fix stream failing tests (#13512)

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>, Guozhang Wang <wangguoz@gmail.com>",2023-04-06 09:00:10,Luke Chen,Not TDD
637bc92ba1b8704577425d5e636068206df8d639,"MINOR: move RecordReader from org.apache.kafka.tools (client module) to org.apache.kafka.tools.api (tools-api module) (#13454)

Reviewers: Jun Rao <junrao@gmail.com>",2023-04-07 00:20:56,Chia-Ping Tsai,Mixed
ef453dd1ad4d6388bd7a74dcb0c2d2573ee945a6,"KAFKA-12634 enforce checkpoint after restoration (#13269)

Under at-least-once, we want to ensure checkpointing the progress after completing the restoration to prevent losing the progress and needing to restore from scratch.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Bruno Cadonna <cadonna@apache.org>",2023-04-07 11:18:40,Philip Nee,Mixed
d5e216d6183a2aae109324652d92a3355690b9d6,"KAFKA-14617: Fill broker epochs to the AlterPartitionRequest (#13489)

As the third part of the KIP-903, it fills the broker epochs from the Fetch request into the AlterPartitionRequest. Also, before generating the alterPartitionRequest, the partition will check whether the broker epoch from the FetchRequest matches with the broker epoch recorded in the metadata cache. If not, the ISR change will be delayed.

Reviewers: Jun Rao <junrao@gmail.com>",2023-04-07 09:09:29,Calvin Liu,Mixed
672dd3ab6aea413eaa8170236f351a0f2a35a89c,"KAFKA-13020; Implement reading Snapshot log append timestamp (#13345)

The SnapshotReader exposes the ""last contained log time"". This is mainly used during snapshot cleanup. The previous implementation used the append time of the snapshot record. This is not accurate as this is the time when the snapshot was created and not the log append time of the last record included in the snapshot.

The log append time of the last record included in the snapshot is store in the header control record of the snapshot. The header control record is the first record of the snapshot.

To be able to read this record, this change extends the RecordsIterator to decode and expose the control records in the Records type.

Reviewers: Colin Patrick McCabe <cmccabe@apache.org>",2023-04-07 09:25:54,José Armando García Sancio,Mixed
751a8af1f0f01b199d4d8e23f0c90edb7b38bd8c,"KAFKA-14420: Use incrementalAlterConfigs API for syncing topic configurations in MirrorMaker 2 (KIP-894) (#13373)

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chris Egerton <chrise@aiven.io>",2023-04-10 11:55:49,Gantigmaa Selenge,Mixed
396536bb5aa1ba78c71ea824d736640b615bda8a,"KAFKA-12446: Call subtractor before adder if key is the same (#10747)

Implements KIP-904.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-04-10 13:27:04,Farooq Qaiser,Not TDD
e49a5a265fd2d60d197b940b7c2a6867f7b90cb1,"KAFKA-14783 (KIP-875): New STOPPED state for connectors (#13424)

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Yash Mayya <yash.mayya@gmail.com>, Greg Harris <gharris1727@gmail.com>",2023-04-11 09:37:26,Chris Egerton,Mixed
f1f35ef1a87154c84623132207b54c1491497452,"KAFKA-14894: MetadataLoader must call finishSnapshot after loading a snapshot (#13541)

The MetadataLoader must call finishSnapshot after loading a snapshot. This function removes
whatever was in the old snapshot that is not in the new snapshot that was just loaded. While this
is not significant when the old snapshot was the empty snapshot, it is important to do when we are
loading a snapshot on top of an existing non-empty image.

In initializeNewPublishers, the newly installed publishers should be given a MetadataDelta based on
MetadataImage.EMPTY, reflecting the fact that they are seeing everything for the first time.

Reviewers: David Arthur <mumrah@gmail.com>",2023-04-11 15:02:33,Colin Patrick McCabe,Mixed
cb7d0833ee02e190a194cc5bd28fd2b3ac31cccb,"KAFKA-14834: [1/N] Add timestamped get to KTableValueGetter (#13496)

In preparation for updating DSL processors to use versioned stores (cf KIP-914), this PR adds two new methods to KTableValueGetter: isVersioned() and get(key, asOfTimestamp) and updates all existing implementations accordingly.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-04-11 20:40:11,Victoria Xia,Not TDD
17b4569d706ff2cdf63b1f2daa4521703dda387e,"KAFKA-14834: [2/N] Test coverage for out-of-order data in joins (#13497)

In preparation for updating DSL join processors to have updated semantics when versioned stores are used (cf KIP-914), this PR adds test coverage for out-of-order data in joins to the existing integration tests for stream-table joins and primary-key table-table joins. Follow-up PRs will build on top of this change by adding new tests for versioned stores, and the out-of-order data will produce different results in those settings.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-04-11 20:42:55,Victoria Xia,Not TDD
e99984248da3042fd7fd6ed5f951f7222a4a3ccd,"KAFKA-9550 Copying log segments to tiered storage in RemoteLogManager (#13487)

Added functionality to copy log segments, indexes to the target remote storage for each topic partition enabled with tiered storage. This involves creating scheduled tasks for all leader partition replicas to copy their log segments in sequence to tiered storage.

Reviewers: Jun Rao <junrao@gmail.com>, Luke Chen <showuon@gmail.com>",2023-04-12 13:55:36,Satish Duggana,Mixed
b64ac94a8c6410db113f92e53e4a3d66869823f5,"KAFKA-14891: Fix rack-aware range assignor to assign co-partitioned subsets (#13539)

Reviewers: David Jacot <djacot@confluent.io>",2023-04-12 08:35:03,Rajini Sivaram,Mixed
e1e3900ba1980ca774b927df4a8713a0328eeb86,"KAFKA-14462; [4/N] Add Group, Record and Result (#13520)

This patch adds Group, Record and Result.

Reviewers: Jason Gustafson <jason@confluent.io>, Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-04-12 13:16:49,David Jacot,Mixed
750a3893081fbe1e01f8c6eadf84726ace1eb47a,"MINOR: Follow-up on failing streams test, and fix StoreChangelogReader (#13523)

1. I've verified and made sure the only case that task would be null and not stream task would be in testing code only, with pausing / resuming topologies; I've revamped the restoration recording func, mainly to make just one method on the Task interface, to make sure we would never get task == null and do not need to cast to StreamTask.
2. Use numRecords directly to avoid calling records.size() that triggers concurrent modifications.
3. Rewrite the TaskMetricsTest to not use the removed impl functions.
4. Found an issue while fixing 1) above, turns out it's related to pausing tasks: if the tasks are paused due to instance / named-topologies are paused while they need restoration, the restoration would never finish, and hence the instance's state would not transit to RUNNING. Similarly, if user paused just one of the named-topology right at the beginning, since the state would not transit to RUNNING, every tasks across all named-topologies would not make progress. We keep the behavior as is to be consistent with and without state-updater.

Reviewers: Matthias J. Sax <mjsax@apache.org>, Lucas Brutschy <lbrutschy@confluent.io>",2023-04-12 14:57:02,Guozhang Wang,Mixed
88e2d6b8c23c548ebd4146b447c80fcda85f5102,"KAFKA-14834: [3/N] Timestamped lookups for stream-table joins (#13509)

This PR updates the stream-table join processors, including both KStream-KTable and KStream-GlobalKTable joins, to perform timestamped lookups when the (global) table is versioned, as specified in KIP-914.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-04-12 16:54:15,Victoria Xia,Not TDD
56dcb837a2f1c1d8c016cfccf8268a910bb77a36,"KAFKA-14561: Improve transactions experience for older clients by ensuring ongoing transaction (#13391)

Added check for ongoing transaction
Thread to send and receive verify only add partition to txn requests
Code to send on request thread courtesy of @artemlivshits

Reviewers: Artem Livshits <alivshits@confluent.io>, Jun Rao <junrao@gmail.com>",2023-04-12 17:04:51,Justine Olshan,Mixed
1395ad6497a43077a68baa5521b7c6e6ee581f11,"KAFKA-14834: [4/N] Drop out-of-order records from table-table join with versioned tables (#13510)

This PR updates primary-key table-table join processors to ignore out-of-order records from versioned tables, as specified in KIP-914.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-04-12 17:06:28,Victoria Xia,Not TDD
1d5d003ff48097c17464ebadee58182114ee1a7f,"KAFKA-14834: [5/N] Drop out-of-order records from FK join with versioned tables (#13522)

This PR updates foreign-key table-table join processors to ignore out-of-order records from versioned tables, as specified in KIP-914.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-04-12 19:05:10,Victoria Xia,Not TDD
571841fed3eed7cb3e76a8fec4477750b7533060,"KAFKA-14883: Expose `observer` state in KRaft metrics (#13525)

Currently, the current-state KRaft related metric reports follower state for a broker while technically it should be reported as an observer as the kafka-metadata-quorum tool does.

Reviewers: Luke Chen <showuon@gmail.com>, dengziming <dengziming1993@gmail.com>",2023-04-13 12:55:57,Paolo Patierno,Mixed
440a53099d6aed34bc9f407b5fb3d74484f1e167,"KAFKA-14462; [5/N] Add EventAccumulator (#13505)

This patch adds the `EventAccumulator` which will be used in the runtime of the new group coordinator. The aim of this accumulator is to basically have a queue per __consumer_group partitions and to ensure that events addressed to the same partitions are not processed concurrently. The accumulator is generic so we could reuse it in different context.

Reviewers: Alexandre Dupriez <alexandre.dupriez@gmail.com>, Justine Olshan <jolshan@confluent.io>",2023-04-13 08:33:40,David Jacot,Mixed
7d580dc7a2ae0517032f28fe7ef62e0b96355527,"KAFKA-14834: [6/N] Add tracking of versioned tables into graph nodes (#13552)

This PR adds a method into GraphNode to assist in tracking whether tables are materialized as versioned or unversioned stores. This is needed in order to allow processors which have different behavior on versioned vs unversioned tables to use the correct semantics. Part of KIP-914.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-04-13 14:21:28,Victoria Xia,Mixed
9217c7e151a85079fd1e5dd8bb196d651fb2f56e,"KAFKA-14834: [7/N] Update VersionedKeyValueStore#put() to return validTo (#13554)

Part of KIP-914.

This PR updates the return type of VersionedKeyValueStore#put(...) from void to long, where the long is the validTo timestamp of the newly put record, with two special values to indicate either that no such timestamp exists (because the record is the latest for its key) or that the put did not take place (because grace period has elapsed). 

As part of making this change, VersionedBytesStore introduces its own put(key, value, timestamp) method to avoid method signature conflicts with the existing put(key, value) method from KeyValueStore<Bytes, byte[]> which has void return type. As a result, the previously added NullableValueAndTimestampSerde class is no longer needed so it's also been removed in this PR as cleanup.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-04-13 20:19:42,Victoria Xia,Mixed
a87edf13d5fed66cc4f26144a93e4d0a6afd8aed,"KAFKA-14834: [8/N] Propagate `isLatest` as part of `Change` (#13564)

Part of KIP-914.

This PR adds an additional boolean isLatest into Change which specifies whether the new value is the latest for its key. For un-versioned stores, isLatest is always true. For versioned stores, isLatest is true if the value has the latest timestamp seen for the key, else false. This boolean will be used by processors such as the table repartition map processor to determine when a record is out-of-order and should be dropped (when processing a versioned table).  This PR updates the table repartition map processor accordingly, and also adds test coverage for table filter.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-04-13 21:20:05,Victoria Xia,Mixed
f1eb260fea75de9b861a35678e8c8233fb948e1a,"KAFKA-14834: [10/N] Reserve repartition topic formats to include isLatest (#13566)

KIP-914 introduced a new boolean isLatest into Change to indicate whether a change update represents the latest for the key. Even though Change is serialized into the table repartition topic, the new boolean does not need to be serialized in, because the table repartition map processor performs an optimization to drop records for which isLatest = false. If not for this optimization, the downstream table aggregate would have to drop such records instead, and isLatest would need to be serialized into the repartition topic.

In light of the possibility that isLatest may need to be serialized into the repartition topic in the future, e.g., if other downstream processors are added which need to distinguish between records for which isLatest = true vs isLatest = false, this PR reserves repartition topic formats which include isLatest. Reserving these formats now comes at no additional cost to users since a rolling bounce is already required for the upcoming release due to KIP-904. If we don't reserve them now and instead have to add them later, then another bounce would be required at that time. Reserving formats is cheap, so we choose to do it now.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-04-13 21:56:36,Victoria Xia,Not TDD
b8d8fcdd6295af1f8de1531772353dbaa2c7b0a6,"KAFKA-7499: Handle serialization error in ProductionExceptionHandler (#13477)

Implements KIP-399.

Extends ProductionExceptionHandler to handle serialization errors, and to allow users to continue processing and dropping the corresponding record on the floor.

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2023-04-13 23:36:26,Philip Nee,Mixed
b1830e4aa2d83d2f213faf5f7432a119742df80c,"KAFKA-14834: [9/N] Disable versioned-stores for unsupported operations (#13565)

Using versioned-stores for global-KTables is not allowed, because a
global-table is bootstrapped on startup, and a stream-globalTable join
does not support temporal semantics.

Furthermore, `suppress()` does not support temporal semantics and thus
cannot be applied to an versioned-KTable.

This PR disallows both use-cases explicitely.

Part of KIP-914.

Reviewers: Bill Bejeck <bbejeck@gmail.com>, Victoria Xia <victoria.xia@confluent.io>",2023-04-14 11:43:54,Matthias J. Sax,Mixed
5767d129634094ffcc8e7d546c581af57b9ca70d,"MINOR: Refactor changelogger to accept timestamp (#13563)

Reviewers: Bill Bejeck <bill@confluent.io>",2023-04-14 07:14:10,Matthias J. Sax,Not TDD
cfd0503006127b58bb181076bffaccb947fdd2bd,"MINOR: fix some flaky KRaft-related tests (#13543) (#13543)

In SharedServer, fix some cases where a volatile variable could change to null while we were using
it, during shutdown. This is mainly a junit test issue, although it could also cause ugly error
messages during shutdown when running the server in a production context.

Fix a race in KafkaEventQueueTest.testSize.

Reviewers: David Arthur <mumrah@gmail.com>",2023-04-14 13:39:08,Colin Patrick McCabe,Not TDD
c958d8719dc2588bd27958b54a65dea514808796,"Revert ""KAFKA-14318: KIP-878, Introduce partition autoscaling configs (#12962)"" (#13527)

This reverts commit d9b139220ee253da673af44d58dc87bd184188f1.

KIP-878 implementation did not make any progress, so we need to revert
the public API changes which are not functional right now.

Reviewers: Bill Bejeck <bill@confluent.io>",2023-04-14 12:08:49,Matthias J. Sax,Mixed
7159f6c1a81ead277030f55f293943270346ad4e,"MINOR: KRaftMetadataCache.getPartitionInfo must set all relevant fields

Fix a case where KRaftMetadataCache.getPartitionInfo was not setting all the PartitionInfo fields it
should have been. Add a regression test.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-04-17 11:03:45,Alyssa Huang,Mixed
e27926f92b1f6b34ed6731f33c712a5d0d594275,"KAFKA-14735: Improve KRaft metadata image change performance at high … (#13280)

topic counts.

Introduces the use of persistent data structures in the KRaft metadata image to avoid copying the entire TopicsImage upon every change.  Performance that was O(<number of topics in the cluster>) is now O(<number of topics changing>), which has dramatic time and GC improvements for the most common topic-related metadata events.  We abstract away the chosen underlying persistent collection library via ImmutableMap<> and ImmutableSet<> interfaces and static factory methods.

Reviewers: Luke Chen <showuon@gmail.com>, Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>, Purshotam Chauhan <pchauhan@confluent.io>",2023-04-17 17:52:28,Ron Dagostino,Mixed
5e9d4de748dff7b91043a9b799716ab4becdae7e,"KAFKA-14869: Ignore unknown record types for coordinators (KIP-915, Part-1) (#13511)

This patch implemented the first part of KIP-915. It updates the group coordinator and the transaction coordinator to ignores unknown record types while loading their respective state from the partitions. This allows downgrades from future versions that will include new record types.

Reviewers: Alexandre Dupriez <alexandre.dupriez@gmail.com>, David Jacot <djacot@confluent.io>",2023-04-18 10:41:54,Jeff Kim,Mixed
61530d68ce83467de6190a52da37b3c0af84f0ef,"KAFKA-14869: Bump coordinator value records to flexible versions (KIP-915, Part-2) (#13526)

This patch implemented the second part of KIP-915. It bumps the versions of the value records used by the group coordinator and the transaction coordinator to make them flexible versions. The new versions are not used when writing to the partitions but only when reading from the partitions. This allows downgrades from future versions that will include tagged fields.

Reviewers: David Jacot <djacot@confluent.io>",2023-04-18 15:37:04,Jeff Kim,Mixed
abca86511ecc9e081d676976ff6d3b845308f444,"KAFKA-14881: Rework UserScramCredentialRecord (#13513)

Rework UserScramCredentialRecord to store serverKey and StoredKey rather than saltedPassword. This
is necessary to support migration from ZK, since those are the fields we stored in ZK.  Update
latest MetadataVersion to IBP_3_5_IV2 and make SCRAM support conditional on this version.  Moved
ScramCredentialData.java from org.apache.kafka.image to org.apache.kafka.metadata, which seems more
appropriate.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-04-18 09:41:38,Proven Provenzano,Mixed
3388adf1b52f545e2d69edd30cdd53241b2887f3,"MINOR: rename internal FK-join processor classes (#13589)

Reviewers: John Roesler <john@confluent.io>, Bill Bejeck <bill@confluent.io>",2023-04-18 11:32:27,Matthias J. Sax,Mixed
f905a5a45d87c94d369cde9d1326e6d18b95cf7e,"MINOR: Fixing gradle build during compileScala and compileTestScala (#13588)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2023-04-19 03:16:03,vamossagar12,Mixed
d04c3e56c29fc6cb876a1074b1108db2c0f37afc,"KAFKA-14908: Set setReuseAddress on the kafka server socket (#13572)

Changes SocketServer to set the setReuseAddress(true) socket option.

This aids use-cases where kafka is started/stopped on the same port in rapid succession. Examples are: where a kafka cluster is embedded in an integration test suite that starts/stops a cluster before/after each test.

Reviewers: Luke Chen <showuon@gmail.com>, Tom Bentley <tbentley@redhat.com>, Divij Vaidya <diviv@amazon.com>",2023-04-19 10:58:29,Keith Wall,Mixed
b10716e72370c4e128bddb17bcc107ccab221e47,"KAFKA-14868: Remove all ReplicaManager metrics when it is closed (#13471)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Divij Vaidya <diviv@amazon.com>",2023-04-19 18:49:08,hudeqi,Mixed
750cfd86bf36ac7c71c5670e50eb8668f97b4246,"KAFKA-14918 Only send controller RPCs to migrating ZK brokers (#13606)

This patch fixes an issue where the KRaft controller could incorrectly send ZK controller RPCs to KRaft brokers.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-04-19 14:19:13,David Arthur,Mixed
809966a9a06664e0b521c2298fa0de834e443607,"KAFKA-13299: Accept duplicate listener on port for IPv4/IPv6 (#11478)

Loosens the validation so that Kafka can accept duplicate listeners on the same port but if and only if the listeners are valid IP addresses with one address being an IPv4 address and the other being an IPv6 address.

Reviewers: Josep Prat <jlprat@apache.org>, Luke Chen <showuon@apache.org>",2023-04-19 20:54:07,Matthew de Detrich,Mixed
11c8bf4826197533807b2132cfc6599ba70de1c1,"KAFKA-14834: [11/N] Update table joins to identify out-of-order records with `isLatest` (#13609)

This PR fixes a bug in the table-table join handling of out-of-order records in versioned tables where if the latest value for a particular key is a tombstone, by using the isLatest value from the Change object instead of calling get(key) on the state store to fetch timestamps to compare against. As part of this fix, this PR also updates table-table joins to determine whether upstream tables are versioned by using the GraphNode mechanism, instead of checking the table's value getter.

Part of KIP-914.

Reviewer: Matthias J. Sax <matthias@confluent.io>",2023-04-19 16:34:36,Victoria Xia,Mixed
e14dd8024adae746c50c8b7d9cd268e859669576,"KAFKA-14821 Implement the listOffsets API with AdminApiDriver (#13432)

We are handling complex workflows ListOffsets by chaining together MetadataCall instances and ListOffsetsCall instances, there are many complex and error-prone logic. In this PR we rewrote it with the `AdminApiDriver` infra, notable changes better than old logic:
1. Retry lookup stage on receiving `NOT_LEADER_OR_FOLLOWER` and `LEADER_NOT_AVAILABLE`, whereas in the past we failed the partition directly without retry.
2. Removing class field `supportsMaxTimestamp` and calculating it on the fly to avoid the mutable state, this won't change any behavior of  the client.
3. Retry fulfillment stage on `RetriableException`, whereas in the past we just retry fulfillment stage on `InvalidMetadataException`, this means we will retry on `TimeoutException` and other `RetriableException`.

We also `handleUnsupportedVersionException` to `AdminApiHandler` and `AdminApiLookupStrategy`, they are used to keep consistency with old logic, and we can continue improvise them. 

Reviewers: Ziming Deng <dengziming1993@gmail.com>, David Jacot <djacot@confluent.io>",2023-04-20 11:29:27,Dimitar Dimitrov,Mixed
ef09a2e3fc11a738f6681fd57fb84ad109593fd3,"KAFKA-14904: Pending state blocked verification of transactions (#13579)

KAFKA-14561 added verification to transactional produce requests to confirm an ongoing transaction.

There is an edge case where the transaction is added, but the coordinator is writing to the log for another partition. In this case, when verifying, we return CONCURRENT_TRANSACTIONS and retry. However, the next inflight batch is often successful because the write completes.

When a partition has no entry in the PSM, it will allow any sequence number. This means if we retry the first write to the partition (or first write in a while) we will never be able to write it and get OutOfOrderSequence exceptions. This is a known issue. Since the verification makes this more common, I propose allowing verification on pending ongoing state since the pending state doesn't prevent us from checking the already added partitions.

The good news is part 2 of KIP-890 will allow us to enforce that the first write for a transaction is sequence 0 and this issue will go away entirely.

This PR also adds the locking back into the addPartitions/verify path that was incorrectly removed.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Artem Livshits <alivshits@confluent.io>, Jason Gustafson <jason@confluent.io>",2023-04-20 09:30:11,Justine Olshan,Mixed
2ee770ac7e576c85a911ccb307339be3d58a8942,"Revert ""KAFKA-14908: Set setReuseAddress on the kafka server socket (#13572)""

This reverts commit d04c3e56c29fc6cb876a1074b1108db2c0f37afc.",2023-04-20 10:21:26,Colin P. McCabe,Mixed
df137752542c005c6998c37c03222ffbeca0f349,"KAFKA-14828: Remove R/W locks using persistent data structures (#13437)

Currently, StandardAuthorizer uses a R/W lock for maintaining the consistency of data. For the clusters with very high traffic, we will typically see an increase in latencies whenever a write operation comes. The intent of this PR is to get rid of the R/W lock with the help of immutable or persistent collections. Basically, new object references are used to hold the intermediate state of the write operation. After the completion of the operation, the main reference to the cache is changed to point to the new object. Also, for the read operation, the code is changed such that all accesses to the cache for a single read operation are done to a particular cache object only.

In the PR description, you can find the performance of various libraries at the time of both read and write. Read performance is checked with the existing AuthorizerBenchmark. For write performance, a new AuthorizerUpdateBenchmark has been added which evaluates the performance of the addAcl operation.


Reviewers:  Ron Dagostino <rndgstn@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>,  Divij Vaidya <diviv@amazon.com>",2023-04-21 14:08:23,Purshotam Chauhan,Mixed
2d0b816150c79057c813387bd126523b6326a1fc,"MINOR: Move `ControllerPurgatory` to `server-common` (#13555)

This patch renames from `ControllerPurgatory` to `DeferredEventQueue` and moves it from the `metadata` module to `server-common` module.

Reviewers: Alexandre Dupriez <alexandre.dupriez@gmail.com>, Ziming Deng <dengziming1993@gmail.com>, José Armando García Sancio <jsancio@apache.org>",2023-04-21 11:19:04,David Jacot,Mixed
c39bf714bbaf2a632be4c2a7e446553fe40ba129,"KAFKA-14462; [7/N] Add ClientAssignor, Assignment, TopicMetadata and VersionedMetadata (#13537)

This patch adds ClientAssignor, Assignment, TopicMetadata and VersionedMetadata classes.

Reviewers: Christo Lolov <lolovc@amazon.com>, Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-04-21 11:22:16,David Jacot,Mixed
dd63d88ac3ea7a9a55a6dacf9c5473e939322a55,"MINOR: fix noticed typo in raft and metadata projects (#13612)

Reviewers: Josep Prat <jlprat@apache.org>",2023-04-21 15:02:06,Manyanda Chitimbo,Not TDD
6dcdb017327587a6943fa868595fa3488c7f7ef7,"KAFKA-14862: Outer stream-stream join does not output all results with multiple input partitions (#13592)

Stream-stream outer join, uses a ""shared time tracker"" to track stream-time progress for left and right input in a single place. This time tracker is incorrectly shared across tasks.

This PR introduces a supplier to create a ""shared time tracker"" object per task, to be shared between the left and right join processors.

Reviewers: Victoria Xia <victoria.xia@confluent.io>, Bruno Cadonna <bruno@confluent.io>, Walker Carlson <wcarlson@confluent.io>",2023-04-24 12:40:25,Matthias J. Sax,Mixed
ab8f2850973b1e9fd548d5b7b8eae458fdd26402,"KAFKA-14834: [12/N] Minor code cleanups relating to versioned stores (#13615)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-04-24 14:06:26,Victoria Xia,Not TDD
2557a4b842b07ac796193bd9a3ef6b724dc995cf,"KAFKA-12446: update change encoding to use varint (#13533)

KIP-904 had the goal in mind to save space when encoding the size on a byte array. However, using UINT32 does not achieve this goal. This PR changes the encoding to VARINT instead.

Reviewers: Victoria Xia <victoria.xia@confluent.io>,  Farooq Qaiser <fqaiser94@gmail.com>, Walker Carlson <wcarlson@confluent.io>",2023-04-24 15:29:57,Matthias J. Sax,Not TDD
ea540fa40042c5e2d808cc4dfc71c71f7466fbe4,"KAFKA-14592: Move FeatureCommand to tools (#13459)

KAFKA-14592: Move FeatureCommand to tools

Reviewers: Luke Chen <showuon@gmail.com>",2023-04-25 20:28:37,Gantigmaa Selenge,Mixed
9a36da12b7359b7158332c541655716312efb5b3,"KAFKA-14462; [8/N] Add ConsumerGroupMember (#13538)

This patch adds ConsumerGroupMember.

Reviewers: Christo Lolov <lolovc@amazon.com>, Jeff Kim <jeff.kim@confluent.io>, Jason Gustafson <jason@confluent.io>",2023-04-25 18:50:51,David Jacot,Mixed
baf127a6633161cb52747467880b006d2f54d3bd,"KAFKA-14666: Add MM2 in-memory offset translation index for offsets behind replication (#13429)

Reviewers: Daniel Urban <durban@cloudera.com>, Chris Egerton <chrise@aiven.io>",2023-04-26 03:30:13,Greg Harris,Mixed
c1b5c75d9271638776392822a094e9e7ef37f490,"KAFKA-14805 KRaft controller supports pre-migration mode (#13407)

This patch adds the concept of pre-migration mode to the KRaft controller. While in this mode, 
the controller will only allow certain write operations. The purpose of this is to disallow metadata 
changes when the controller is waiting for the ZK migration records to be committed.

The following ControllerWriteEvent operations are permitted in pre-migration mode

* completeActivation
* maybeFenceReplicas
* writeNoOpRecord
* processBrokerHeartbeat
* registerBroker (only for migrating ZK brokers)
* unregisterBroker

Raft events and other controller events do not follow the same code path as ControllerWriteEvent, 
so they are not affected by this new behavior.

This patch also add a new metric as defined in KIP-868: kafka.controller:type=KafkaController,name=ZkMigrationState

In order to support upgrades from 3.4.0, this patch also redefines the enum value of value 1 to mean 
MIGRATION rather than PRE_MIGRATION.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",2023-04-26 10:20:30,David Arthur,Mixed
dd6690a7a0a565a681c52dbfe0c7c89875bdf8c9,"KAFKA-14944: Reduce CompletedFetch#parseRecord() memory copy (#12545)

This implements KIP-863: https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=225152035
Direct use ByteBuffer instead of byte[] to deserialize.

Reviewers: Luke Chen <showuon@gmail.com>, Kirk True <kirk@kirktrue.pro>",2023-04-27 10:44:08,LinShunKang,Not TDD
8bde4e79cdeea7761b54e24516a7d2cc9f52e051,"KAFKA-14462; [9/N] Add RecordHelpers (#13544)

This patch adds RecordHelpers.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-04-27 14:05:41,David Jacot,Mixed
70493336171363cfa95237a0fe14ef57090553e4,"KAFKA-14943: Fix ClientQuotaControlManager validation

Don't allow setting negative or zero values for quotas. Don't allow SCRAM mechanism names to be
used as client quota names. SCRAM mechanisms are not client quotas. (The confusion arose because of
internal ZK representation details that treated them both as ""client configs."")

Add unit tests for ClientQuotaControlManager.isValidIpEntity and
ClientQuotaControlManager.configKeysForEntityType.

This change doesn't affect metadata record application, only input validation. If there are bad
client quotas that are set currently, this change will not alter the current behavior (of throwing
an exception and ignoring the bad quota).",2023-04-27 10:42:32,Colin P. McCabe,Mixed
c708f7ba5f4f449920cec57a5b69e84e92128b54,"MINOR: remove spurious call to fatalFaultHandler (#13651)

Remove a spurious call to fatalFaultHandler accidentally introduced by KAFKA-14805.  We should only
invoke the fatal fault handller if we are unable to generate the activation records. If we are
unable to write the activation records, a controller failover should be sufficient to remedy the
situation.

Co-authored-by: Luke Chen showuon@gmail.com

Reviewers: Luke Chen <showuon@gmail.com>, David Arthur <mumrah@gmail.com>",2023-04-28 10:15:26,Colin Patrick McCabe,Mixed
d796480fe87fd819fc0ac560ca318759180d4644,"KAFKA-14909: check zkMigrationReady tag before migration (#13631)

1. add ZkMigrationReady in apiVersionsResponse
2. check all nodes if ZkMigrationReady are ready before moving to next migration state

Reviewers: David Arthur <mumrah@gmail.com>, dengziming <dengziming1993@gmail.com>",2023-04-28 14:35:12,Luke Chen,Mixed
c6ad151ac3bac0d8d1d6985d230eacaa170b8984,"KAFKA-14639: A single partition may be revoked and assign during a single round of rebalance (#13550)

This is a really long story, but the incident started in KAFKA-13419 when we observed a member sending out a topic partition owned from the previous generation when a member missed a rebalance cycle due to REBALANCE_IN_PROGRESS.

This patch changes the AbstractStickyAssignor.AllSubscriptionsEqual method.  In short, it should no long check and validate only the highest generation.  Instead, we consider 3 cases:
1. Member will continue to hold on to its partition if there are no other owners
2. If there are 1+ owners to the same partition. One with the highest generation will win.
3. If two members of the same generation hold on to the same partition.  We will log an error but remove both from the assignment. (Same with the current logic)

Here are some important notes that lead to the patch:
- If a member is kicked out of the group, and `UNKNOWN_MEMBER_ID` will be thrown.
- It seems to be a common situation that members are late to joinGroup and therefore get `REBALANCE_IN_PROGRESS` error.  This is why we don't want to reset generation because it might cause lots of revocations and can be disruptive

To summarize the current behavior of different errors:
`REBALANCE_IN_PROGRESS`
- heartbeat: requestRejoin if member state is stable
- joinGroup: rejoin immediately
- syncGroup: rejoin immediately
- commit: requestRejoin and fail the commit. Raise this exception if the generation is staled, i.e. another rebalance is already in progress.

`UNKNOWN_MEMBER_ID`
- heartbeat: resetStateAndRejoinif generation hasn't changed. otherwise, ignore
- joinGroup: resetStateAndRejoin if generation unchanged, otherwise rejoin immediately
- syncGroup:  resetStateAndRejoin if generation unchanged, otherwise rejoin immediately

`ILLEGAL_GENERATION`
- heartbeat: resetStateAndRejoinif generation hasn't changed. otherwise, ignore
- syncGroup: raised the exception if generation has been resetted or the member hasn't completed rebalancing.  then resetStateAndRejoin if generation unchanged, otherwise rejoin immediately

Reviewers: David Jacot <djacot@confluent.io>",2023-04-28 11:08:32,Philip Nee,Mixed
e29942347acc70aa85d47e84e2021f9c24cd7c80,"KAFKA-14859: SCRAM ZK to KRaft migration with dual write (#13628)

Handle migrating SCRAM records in ZK when migrating from ZK to KRaft.

This includes handling writing back SCRAM records to ZK while in dual write mode where metadata updates are written to both the KRaft metadata log and to ZK. This allows for rollback of migration to include SCRAM metadata changes.

Reviewers: David Arthur <mumrah@gmail.com>",2023-05-01 09:56:04,Proven Provenzano,Mixed
141c76a2c904705f2cd484e96767fcb217c5db25,"KAFKA-14133: Migrate topology builder mock in TaskManagerTest to mockito (#13529)

1. Migrates topology builder mock in TaskManagerTest to mockito.

2. Replaces the unit test to verify if subscribed partitions are added
to topology metadata.

3. Modifies signatures of methods for adding subscribed partitions to
topology metadata to use sets instead of lists. This makes the
intent of the methods clearer and makes the tests more portable.

Reviewers: Christo Lolov <lolovc@amazon.com>, Matthias J. Sax <mjsax@apache.org>",2023-05-02 14:00:34,Bruno Cadonna,Mixed
f44ee4fab7ef7adf715ecf2b96defa5cc8311949,"MINOR: Remove unnecessary code in client/connect (#13259)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2023-05-02 17:39:31,Christo Lolov,Not TDD
16fc8e1cfff6f0ac29209704a079b0ddcbd0625e,"KAFKA-14462; [10/N] Add TargetAssignmentBuilder (#13637)

This patch adds TargetAssignmentBuilder. It is responsible for computing a target assignment for a given group.

Reviewers: Ritika Reddy <rreddy@confluent.io>, Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-05-02 18:04:50,David Jacot,Mixed
b620c03ccf48d6d92b219cba35bb1e5e248d2547,"KAFKA-14946: fix NPE when merging the deltatable (#13653)

Fix NPE while merging the deltatable. Because it's possible that hashTier is
not null but deltatable is null (ex: removing data), we should have null check
while merging for deltatable like other places did. Also added tests that will
fail without this change.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-05-03 10:08:25,Luke Chen,Mixed
c08120f83f7318f15dcf14d525876d18caf6afd0,"MINOR: Allow tagged fields with version subset of flexible version range (#13551)

The generated message types are missing a range check for the case when the tagged version range is a subset of
the flexible version range. This causes the tagged field count, which is computed correctly, to conflict with the
number of tags serialized.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-05-03 15:25:32,Jason Gustafson,Mixed
dc7819d7f1fe6b0160cd95246420ab10c335410b,"KAFKA-14594: Move LogDirsCommand to tools module (#13122)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2023-05-04 12:00:33,Christo Lolov,Mixed
ea81e99e5980c807414651034a8c60426a158ca4,"KAFKA-13668: Retry upon missing initProducerId due to authorization error (#12149)

Producers used to throw a fatal error upon failing initProducerId, which can be caused by authorization errors. In this case, the user will need to instantiate a producer.

This PR makes authorization errors non-fatal so that the user can retry until the permission is fixed by an admin.

Here we first transition the producer to the ABORTABLE state, then to the UNINITIALIZED state (so that the producer is recoverable). Upon the subsequent send, the producer will transition to INITIALIZING and attempt to send another InitProducerIdRequest.

Reviewers: Kirk True <ktrue@confluent.io>, David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-05-04 09:20:01,Philip Nee,Mixed
ffd814d25fb97f2ee0b73000788c93ec1d5b9bff,"KAFKA-14916: Fix code that assumes transactional ID implies all records are transactional (#13607)

Also modifies verification to only add a partition to verify if it is transactional.

When verifying we look at all the transactional producer IDs and throw INVALID_RECORD on the request if one is different.

Reviewers: Kirk True <ktrue@confluent.io>, Artem Livshits <alivshits@confluent.io>, Jason Gustafson <jason@confluent.io>",2023-05-04 09:55:45,Justine Olshan,Mixed
63f9f23ec0aaa62f0da93ebc42934f5fce743ddb,"MINOR: improve QuorumController logging #13540

When creating the QuorumController, log whether ZK migration is enabled.

When applying a feature level record which sets the metadata version, log the metadata version enum
rather than the numeric feature level.

Improve the logging when we replay snapshots in QuorumController. Log both the beginning and the
end of replay.

When TRACE is enabled, log every record that is replayed in QuorumController. Since some records
may contain sensitive information, create RecordRedactor to assist in logging only what is safe to
put in the log4j file.

Add logging to ControllerPurgatory. Successful completions are logged at DEBUG; failures are logged
at INFO, and additions are logged at TRACE.

Remove SnapshotReason.java, SnapshotReasonTest.java, and
QuorumController#generateSnapshotScheduled. They are deadcode now that snapshot generation moved to
org.apache.kafka.image.publisher.SnapshotGenerator.

Reviewers: David Arthur <mumrah@gmail.com>, José Armando García Sancio <jsancio@apache.org>",2023-05-04 11:18:03,Colin P. McCabe,Mixed
97c36f3f3142580325daa1a6aadb662893390561,HOTFIX: fix file deletions left out of MINOR: improve QuorumController logging #13540,2023-05-04 12:20:33,Colin P. McCabe,Mixed
0822ce0ed1a106a510930bc9ac53a266f54684d7,"KAFKA-14840: Support for snapshots during ZK migration (#13461)

This patch adds support for handling metadata snapshots while in dual-write mode. Prior to this change, if the active
controller loaded a snapshot, it would get out of sync with the ZK state.

In order to reconcile the snapshot state with ZK, several methods were added to scan through the metadata in ZK to
compute differences with the MetadataImage. Since this introduced a lot of code, I opted to split out a lot of methods
from ZkMigrationClient into their own client interfaces, such as TopicMigrationClient, ConfigMigrationClient, and
AclMigrationClient. Each of these has some iterator method that lets the caller examine the ZK state in a single pass
and without using too much memory.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Luke Chen <showuon@gmail.com>",2023-05-05 01:35:26,David Arthur,Mixed
e34f88403159cc8381da23dafdf7e3d7403114a2,"KAFKA-14926: Remove metrics on Log Cleaner shutdown (#13623)

When Log cleaning is shutdown, it doesn't remove metrics that were registered to `KafkaYammerMetrics.defaultRegistry()` which has one instance per server. Log cleaner's lifecycle is associated with lifecycle of `LogManager` and hence, there is no possibility where log cleaner will be shutdown but the broker won't. Broker shutdown will close the `jmxReporter` and hence, there is no current metric leak here. The motivation for this code change is to ""do the right thing"" from a code hygiene perspective.

Reviewers: Manyanda Chitimbo <manyanda.chitimbo@gmail.com>, Kirk True <kirk@mustardgrain.com>, David Jacot <djacot@confluent.io>",2023-05-05 13:55:17,Divij Vaidya,Mixed
6bcc497c36a1aef19204b1bfe3b17a8c1c84c059,"KAFKA-14766: Improve performance of VarInt encoding and decoding (#13312)

Motivation

Reading/writing the protocol buffer varInt32 and varInt64 (also called varLong in our code base) is in the hot path of data plane code in Apache Kafka. We read multiple varInt in a record and in long. Hence, even a minor change in performance could extrapolate to larger performance benefit.

In this PR, we only update varInt32 encoding/decoding.
Changes

This change uses loop unrolling and reduces the amount of repetition of calculations. Based on the empirical results from the benchmark, the code has been modified to pick up the best implementation.
Results

Performance has been evaluated using JMH benchmarks on JDK 17.0.6. Various implementations have been added in the benchmark and benchmarking has been done for different sizes of varints and varlongs. The benchmark for various implementations have been added at ByteUtilsBenchmark.java

Reviewers: Ismael Juma <mlists@juma.me.uk>, Luke Chen <showuon@gmail.com>, Alexandre Dupriez <alexandre.dupriez@gmail.com>",2023-05-05 20:05:20,Divij Vaidya,Mixed
6e7144ac24973afdb71ef59a63c6bacbbb1d2714,"MINOR: add docs to remind reader that impl of ConsumerPartitionAssign… (#13659)

Reviewers: David Jacot <djacot@confluent.io>, Kirk True <kirk@kirktrue.pro>",2023-05-06 02:56:26,Chia-Ping Tsai,Mixed
86daf8ce6573eb79d6e78381dbab738055f914c4,"KAFKA-14913: Using ThreadUtils.shutdownExecutorServiceQuietly to close executors in Connect Runtime (#13594)

#13557 introduced a utils method to close executors silently. This PR leverages that method to close executors in connect runtime. There was duplicate code while closing the executors which isn't the case with this PR.

Note that there are a few more executors used in Connect runtime but their close methods don't follow this pattern of shutdown, await and shutdown. Some of them have some logic like executor like Worker, so not changing at such places.

---------

Co-authored-by: Sagar Rao <sagarrao@Sagars-MacBook-Pro.local>

Reviewers: Daniel Urban <durban@cloudera.com>, Yash Mayya <yash.mayya@gmail.com>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>",2023-05-08 16:39:47,vamossagar12,Mixed
7634eee2627da39937e3112ffc58bd7cfedc98f2,"KAFKA-14462; [11/N] Add CurrentAssignmentBuilder (#13638)

This patch adds the `CurrentAssignmentBuilder` class which encapsulates the reconciliation engine of the consumer group protocol. Given the current state of a member and a desired or target assignment state, the state machine takes the necessary steps to converge the member to its desired state.

Reviewers: Ritika Reddy <rreddy@confluent.io>, Calvin Liu <caliu@confluent.io>, Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-05-08 20:46:07,David Jacot,Mixed
b40a7fc037bb1543c3355fad9c71570f770f5177,"HOTFIX: fix broken Streams upgrade system test (#13654)

Reviewers: Victoria Xia <victoria.xia@confluent.io>, John Roesler <john@confluent.io>",2023-05-08 14:24:11,Matthias J. Sax,Not TDD
59ba9dbbc927ddc8660d0d98d9422909fd306758,"KAFKA-14974: Restore backward compatibility in KafkaBasedLog (#13688)

`KafkaBasedLog` is a widely used utility class that provides a generic implementation of a shared, compacted log of records in a Kafka topic. It isn't in Connect's public API, but has been used outside of Connect and we try to preserve backward compatibility whenever possible. KAFKA-14455 modified the two overloaded void `KafkaBasedLog::send` methods to return a `Future`. While this change is source compatible, it isn't binary compatible. We can restore backward compatibility simply by renaming the new Future returning send methods, and reinstating the older send methods to delegate to the newer methods.

This refactoring changes no functionality other than restoring the older methods.

Reviewers: Randall Hauch <rhauch@gmail.com>",2023-05-09 07:28:45,Yash Mayya,Mixed
228434d23583189cdcaa7f4a90ebb178ccc17c73,"KAFKA-14500; [1/N] Rewrite MemberMetadata in Java (#13644)

This patch adds GenericGroupMember which is a rewrite of MemberMetadata in Java.

Reviewers: David Jacot <djacot@confluent.io>",2023-05-09 16:49:27,Jeff Kim,Mixed
4653507926a42dccda5c086fcae6278afcfc53ca,"KAFKA-14514; Add Range Assignor on the Server (KIP-848) (#13443)

This patch adds the RangeAssignor on the server for KIP-848. This range assignor is very different from the old client side implementation. We added functionality to make these assignments sticky while also inheriting crucial properties of the range assignor such as facilitating joins and distributing partitions of a topic somewhat equally amongst its subscribers.

Reviewers: Philip Nee <philipnee@gmail.com>, Jeff Kim <jeff.kim@confluent.io>, David Jacot <djacot@confluent.io>",2023-05-10 14:09:12,Ritika Reddy,Mixed
f17fb75b2de32512f14cb94a7d1bfb0f37485780,"KAFKA-14978 ExactlyOnceWorkerSourceTask should remove parent metrics (#13690)

Reviewers: Chris Egerton <chrise@aiven.io>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>",2023-05-10 16:41:52,Dániel Urbán,Mixed
a263627adb75f1ca5c87f1482cc70b994ba49d63,"MINOR: Remove unused methods in CoreUtils (#13170)


Reviewers: Josep Prat <josep.prat@aiven.io>, Christo Lolov <christololov@gmail.com>",2023-05-11 11:02:45,Mickael Maison,Mixed
bd65db82b4bad623b0bb31398979e466978148da,"MINOR: clean up unused methods in core utils (#13706)

Reviewers: Manyanda Chitimbo <manyanda.chitimbo@gmail.com>, Mickael Maison <mimaison@apache.org>",2023-05-11 17:55:26,Josep Prat,Mixed
54a4067f81e1434d956ef797274f7b437fe49ea1,"KAFKA-14559: Fix JMX tool to handle the object names with wildcard and optional attributes (#13060)

Reviewers: Federico Valeri <fedevaleri@gmail.com>, Satish Duggana <satishd@apache.org>",2023-05-11 21:49:21,Kamal Chandraprakash,Mixed
a7c9842f709c5985ea41a5811e479551ea0fb7f2,"KAFKA-14291: KRaft controller should return right finalized features in ApiVersionResponse (#13679)

The KRaft controller return empty finalized features in `ApiVersionResponse`, the brokers are not infected by this, so this problem doesn't have any impact currently, but it's worth fixing it to avoid unexpected problems.

And there is a bunch of of confusing methods in `ApiVersionResponse` which are only used in test code, I moved them to TestUtils to make the code more clear, and force everyone to pass in the correct parameters instead of the default zero parameters, for example, empty supported features and empty finalized features.

Reviewers: Luke Chen <showuon@gmail.com>",2023-05-12 13:46:06,dengziming,Mixed
440bed2391338dc10fe4d36ab17dc104b61b85e8,"MINOR:code optimization in QuorumController (#13697)

1. add hint in switch item ""BROKER_LOGGER"" in ConfigResourceExistenceChecker, otherwise, it will be classified as default break and deleted directly. I don’t know if adding hint is better than deleting directly.
2. delete some unused variables and methods.
3. add the ""@test"" mark to a method in unit test that is forgotten.

Reviewers: dengziming <dengziming1993@gmail.com>",2023-05-12 14:03:17,hudeqi,Mixed
cc011f77aaeecb64e1a18ea403b866b66e37ec2c,"KAFKA-14500; [2/N] Rewrite GroupMetadata in Java (#13663)

This patch introduces `GenericGroup` which rewrite the `GroupMetadata` in Java. The `GenericGroup` is basically a group using the current rebalance protocol in the new group coordinator.

Reviewers: Ritika Reddy <rreddy@confluent.io>, Christo Lolov <lolovc@amazon.com>, David Jacot <djacot@confluent.io>",2023-05-12 11:22:29,Jeff Kim,Mixed
bb10ae4273451468b26fad755bfa41001ac6849c,"KAFKA-14962: Trim whitespace from ACL configuration (#13670)

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Christo Lolov <lolovc@amazon.com>",2023-05-12 23:51:00,Divij Vaidya,Mixed
d944ef1efbdb577e4c7c847b790df884ba2b58d2,"MINOR: Rename handleSnapshot to handleLoadSnapshot (#13727)

Rename handleSnapshot to handleLoadSnapshot to make it explicit that it is handling snapshot load,
not generation.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Jason Gustafson <jason@confluent.io>",2023-05-17 09:57:24,David Mao,Mixed
6f197301646135e0bb39a461ca0a07c09c3185fb,"KAFKA-9579 Fetch implementation for records in the remote storage through a specific purgatory. (#13535)

This change includes
- Recognize the fetch requests with out of range local log offsets
- Add fetch implementation for the data lying in the range of [logStartOffset, localLogStartOffset]
- Add a new purgatory for async remote read requests which are served through a specific thread pool

We have an extended version of remote fetch that can fetch from multiple remote partitions in parallel, which we will raise as a followup PR.

A few tests for the newly introduced changes are added in this PR. There are some tests available for these scenarios in 2.8.x, refactoring with the trunk changes, will add them in followup PRs.

Other contributors:
Kamal Chandraprakash <kchandraprakash@uber.com> - Further improvements and adding a few tests
Luke Chen <showuon@gmail.com> - Added a few test cases for these changes.

PS: This functionality is pulled out from internal branches with other functionalities related to the feature in 2.8.x. The reason for not pulling all the changes as it makes the PR huge, and burdensome to review and it also needs other metrics, minor enhancements(including perf), and minor changes done for tests. So, we will try to have followup PRs to cover all those.

Reviewers: Jun Rao <junrao@gmail.com>, Alexandre Dupriez <alexandre.dupriez@gmail.com>, Divij Vaidya <diviv@amazon.com>,  Jorge Esteban Quilcate Otoya <quilcate.jorge@gmail.com>",2023-05-18 06:37:37,Satish Duggana,Mixed
a14e73a0361556d86dc18aac865536c6a485bb0a,"KAFKA-14980: Fix MirrorSourceConnector source consumer configuration (#13723)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Josep Prat <josep.prat@aiven.io>",2023-05-19 14:45:01,Chris Egerton,Mixed
6b955818672de7ce4643ab90f2f37961c4003ca8,"KAFKA-15007: Use the correct MetadataVersion in MetadataPropagator (#13732)

Use the MetadataVersion from the MetadataImage passed to MetadataPropagator. The ensures the propagator 
sends the right versions of UMR, LISR and StopReplica requests when the migration is in DUAL_WRITE mode.

Reviewers: David Arthur <mumrah@gmail.com>",2023-05-22 14:46:53,Akhilesh C,Mixed
c98c1ed41cfb2fdede4e6ec874d4c581f27b4508,"KAFKA-14500; [3/N] add GroupMetadataKey/Value record helpers (#13704)

This path enables the new group metadata manager to generate GroupMetadataKey/Value records.

Reviewers: David Jacot <djacot@confluent.io>",2023-05-23 10:42:13,Jeff Kim,Mixed
ea6ce3bf82e72565b53db6df7cd1e583ea132eb9,"KAFKA-15009: Handle new ACLs in KRaft snapshot during migration (#13741)

When loading a snapshot during dual-write mode, we were missing the logic to detect new ACLs that 
had been added on the KRaft side. This patch adds support for finding those new ACLs as well as tests
to verify the correct behavior.

Reviewers: David Arthur <mumrah@gmail.com>",2023-05-23 10:43:02,Akhilesh C,Not TDD
12130cfceca7c286cd6ab5f6faafd2000d8a9c84,"MINOR: Create the MetadataNode classes to introspect MetadataImage

Metadata image classes such as MetadataImage, ClusterImage, FeaturesImage, and so forth contain
numerous sub-images. This PR adds a structured way of traversing those sub-images. This is useful
for the metadata shell, and also for implementing toString functions.

In both cases, the previous solution was suboptimal. The metadata shell was previously implemented
in an ad-hoc way by mutating text-based tree nodes when records were replayed. This was difficult
to keep in sync with changes to the record types (for example, we forgot to do this for SCRAM). It
was also pretty low-level, being done at a level below that of the image classes. For toString, it
was difficult to keep the implementations consistent previously, and also support both redacted and
non-redacted output.

The metadata shell directory was getting crowded since we never had submodules for it. This PR
creates glob/, command/, node/, and state/ directories to keep things better organized.

Reviewers: David Arthur <mumrah@gmail.com>, Ron Dagostino <rdagostino@confluent.io>",2023-05-23 10:11:26,Colin P. McCabe,Mixed
5b3b385881d5518ef1b2c63cb55244cf80a80da2,"KAFKA-13504: Retry connect internal topics' creation in case of InvalidReplicationFactorException (#11565)

In case the Kafka Broker cluster and the Kafka Connect cluster is started together and Connect would want to create its topics, there's a high chance to fail the creation with InvalidReplicationFactorException.

---------

Co-authored-by: Daniel Urban <durban@cloudera.com>

Reviewers: Daniel Urban <durban@cloudera.com>, Mickael Maison <mickael.maison@gmail.com>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>, Chris Egerton <chrise@aiven.io>, Laszlo Hunyadi <laszlo.istvan.hunyady@gmail.com>",2023-05-24 11:05:02,Andras Katona,Mixed
79351ec88ea65e0622cfd7a552bad16455b94edd,"KAFKA-14970: Fix SCRAM during migration dual-write (#13729)

Fixed a bug during dual write mode where if a user is updating SCRAM records and has no quotas, the SCRAM records will not be written to ZK. Add tests explicitly for this scenario.

Reviewers: David Arthur <mumrah@gmail.com>",2023-05-24 17:01:39,Proven Provenzano,Not TDD
dc00832b965c29fbbb4148cc680fadfc3f28642a,"KAFKA-14654: Connector classes should statically initialize with plugin classloader (#13165)

Reviewers: Chaitanya Mukka <chaitanya.mvs2007@gmail.com>, Chris Egerton <chrise@aiven.io>",2023-05-25 10:22:44,Greg Harris,Not TDD
6d72c26731fe69955127a90e3d43f6d9eb41e2d3,"KAFKA-14841 Handle callbacks to ConsumerRebalanceListener in MockConsumer (#13455)

Reviewers: Philip Nee <philipnee@gmail.com>",2023-05-26 08:33:03,Daniel Scanteianu,Mixed
7ff2dbb1078b71d031652bf4b7378586f374f6fe,"KAFKA-14368: Connect offset write REST API (#13465)

Reviewers: Greg Harris <greg.harris@aiven.io>, Chris Egerton <chrise@aiven.io>",2023-05-26 12:08:06,Yash Mayya,Mixed
2ec6b5e1e2e29fd6a45d2e9344c0bdf3470454f4,"KAFKA-14789: Prevent mis-attributing classpath plugins, allow discovery of classpath RestExtension and ConfigProvider (#13356)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-05-26 12:17:07,Greg Harris,Mixed
9aac5ff1fe23fdd0bc8442dd2da03a4517f4dba8,"MINOR: Move plugin path parsing from DelegatingClassLoader to PluginUtils (#13334)

Reviewers: Chaitanya Mukka <chaitanya.mvs2007@gmail.com>, Chris Egerton <chrise@aiven.io>",2023-05-26 12:36:00,Greg Harris,Mixed
b74204fa0a41e5779d513116cb32c0f24e7662c2,"KAFKA-14996: Handle overly large user operations on the kcontroller (#13742)

Previously, if a user tried to perform an overly large batch operation on the KRaft controller
(such as creating a million topics), we would create a very large number of records in memory. Our
attempt to write these records to the Raft layer would fail, because there were too many to fit in
an atomic batch. This failure, in turn, would trigger a controller failover.

(Note: I am assuming here that no topic creation policy was in place that would prevent the
creation of a million topics. I am also assuming that the user operation must be done atomically,
which is true for all current user operations, since we have not implemented KIP-868 yet.)

With this PR, we fail immediately when the number of records we have generated exceeds the
threshold that we can apply. This failure does not generate a controller failover. We also now
fail with a PolicyViolationException rather than an UnknownServerException.

In order to implement this in a simple way, this PR adds the BoundedList class, which wraps any
list and adds a maximum length. Attempts to grow the list beyond this length cause an exception to
be thrown.

Reviewers: David Arthur <mumrah@gmail.com>, Ismael Juma <ijuma@apache.org>, Divij Vaidya <diviv@amazon.com>",2023-05-26 13:16:17,Colin Patrick McCabe,Mixed
7a679af687a47dcfee365808301aa99ede1719d0,"KAFKA-15004: Fix configuration dual-write during migration (#13767)

This patch fixes several small bugs with configuration dual-write during migration.

* Topic configs are not written back to ZK while handling snapshot.
* New broker/topic configs in KRaft that did not exist in ZK will not be written to ZK.
* The sensitive configs are not encoded while writing them to Zookeeper.
* Handle topic configs in ConfigMigrationClient and KRaftMigrationZkWriter#handleConfigsSnapshot

Added tests to ensure we no longer have the above mentioned issues.

Co-authored-by: Akhilesh Chaganti <akhileshchg@users.noreply.github.com>
Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-05-27 17:20:44,David Arthur,Mixed
45520c1342fea9598e608a402ffd2ed8c5e69245,"KAFKA-14982: Improve the kafka-metadata-quorum output (#13738)

When running kafka-metadata-quorum script to get the quorum replication status, the LastFetchTimestamp and LastCaughtUpTimestamp output is not human-readable.

I will be convenient to add an optional flag (-hr, --human-readable) to enable a human-readable format showing the delay in ms (i.e. 366 ms ago).

This dealy is computed as (now - timestamp), where they are both represented as Unix time (UTC based).

$ bin/kafka-metadata-quorum.sh --bootstrap-server :9092 describe --replication --human-readable
NodeId	LogEndOffset	Lag	LastFetchTimestamp	LastCaughtUpTimestamp	Status  	
2     	61          	0  	5 ms ago          	5 ms ago             	Leader  	
3     	61          	0  	56 ms ago         	56 ms ago            	Follower	
4     	61          	0  	56 ms ago         	56 ms ago            	Follower

Reviewers: Luke Chen <showuon@gmail.com>",2023-05-29 10:04:46,Federico Valeri,Mixed
9edf2ec5cce7bd92f3a7fb0617774374b681cd2c,"MINOR: Add transaction verification config to producerStateManager config (#13770)

I have moved this config into producer state manager so it can be checked easily under the log lock when we are about to append.

Only a few test files currently use the validation and those have been verified to work via running the tests.

Reviews:  David Jacot <djacot@confluent.io>",2023-05-30 13:46:17,Justine Olshan,Mixed
49d9c6775dedd1abcf45683d6c9e3d9c6c05db9c,"KAFKA-14462; [12/N] Add GroupMetadataManager and ConsumerGroup (#13639)

This patch adds the GroupMetadataManager to the group-coordinator module. This manager is responsible for handling the groups management, the members management and the entire reconciliation process. At this point, only the new consumer group type/protocol is implemented.

The new manager is based on an architecture inspired from the quorum controller. A request can access/read the state but can't mutate it directly. Instead, a list of records is generated together with the response and those records are applied to the state by the runtime framework. We use timeline data structures. Note that the runtime framework is not part of this patch. It will come in a following one.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-05-31 08:29:41,David Jacot,Mixed
1957be19d963d3416e3d75a763f0248a51604efc,"KAFKA-8713: JsonConverter replace.null.with.default should prevent emitting default for Struct fields (#13781)

Co-authored-by: GeunJae Jeon <krespo>
Reviewers: Mickael Maison <mickael.maison@gmail.com>",2023-05-31 15:48:03,Greg Harris,Mixed
7e9a82c7324ac2aaf18883989035f71611197a2a,"MINOR: Fix for MetadataQuorumCommandErrorTest.testRelativeTimeMs (#13784)

Reviewers: Divij Vaidya <diviv@amazon.com>, David Jacot <djacot@confluent.io>",2023-05-31 18:48:26,Federico Valeri,Not TDD
9b3db6d50a9bb892032fa0c09692241fe070103a,"KAFKA-15019: Improve handling of broker heartbeat timeouts (#13759)

When the active KRaft controller is overloaded, it will not be able to process broker heartbeat
requests. Instead, they will be timed out. When using the default configuration, this will happen
if the time needed to process a broker heartbeat climbs above a second for a sustained period.
This, in turn, could lead to brokers being improperly fenced when they are still alive.

With this PR, timed out heartbeats will still update the lastContactNs and metadataOffset of the
broker in the BrokerHeartbeatManager. While we don't generate any records, this should still be
adequate to prevent spurious fencing. We also log a message at ERROR level so that this condition
will be more obvious.

Other small changes in this PR: fix grammar issue in log4j of BrokerHeartbeatManager. Add JavaDoc
for ClusterControlManager#zkMigrationEnabled field. Add builder for ReplicationControlTestContext
to avoid having tons of constructors. Update ClusterControlManager.DEFAULT_SESSION_TIMEOUT_NS to
match the default in KafkaConfig.

Reviewers: Ismael Juma <ijuma@apache.org>, Ron Dagostino <rdagostino@confluent.io>",2023-05-31 10:49:05,Colin Patrick McCabe,Mixed
731c8c967e04ffe212e8b4d8ea15e67f22a60e65,"KAFKA-15017 Fix snapshot load in dual write mode for ClientQuotas and SCRAM  (#13757)

This patch fixes the case where a ClientQuota or SCRAM credential was added in KRaft, but not written back to ZK. This missed write only occurred when handling a KRaft snapshot. If the changed quota was processed in a metadata delta (which is the typical case), it would be written to ZK.

Reviewers: David Arthur <mumrah@gmail.com>",2023-05-31 15:42:00,Proven Provenzano,Not TDD
d27ba5bfba46647401218d5c1b5d6a1a51a6b631,"KAFKA-15010 ZK migration failover support (#13758)

This patch adds snapshot reconciliation during ZK to KRaft migration. This reconciliation happens whenever a snapshot is loaded by KRaft, or during a controller failover. Prior to this patch, it was possible to miss metadata updates coming from KRaft when dual-writing to ZK.

Internally this adds a new state SYNC_KRAFT_TO_ZK to the KRaftMigrationDriver state machine. The controller passes through this state after the initial ZK migration and each time a controller becomes active. 

Logging during dual-write was enhanced to include a count of write operations happening.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-06-01 10:25:46,David Arthur,Mixed
ddad02baa6d2ce9cfa96176509bf6276409ac628,"MINOR: Covering all epoch cases in add partitions to txn manager (#13769)

Cleaning up the AddPartitionsToTxnManager and covering the 3 epoch cases more clearly.

Reviewers:  David Jacot <djacot@confluent.io>",2023-06-01 13:29:52,Justine Olshan,Mixed
47551ea369cd72171900a73d5b79137cff731203,"KAFKA-14462; [13/N] CoordinatorEvent and CoordinatorEventProcessor (#13666)

Adds CoordinatorEvent, CoordinatorEventProcessor, and MultiThreadedEventProcessor.

Reviewers: Kirk True <ktrue@confluent.io>, Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-06-01 13:33:40,David Jacot,Mixed
f4996629239a49afb570a725642fb0311dd42e71,"KAFKA-15003: Fix ZK sync logic for partition assignments (#13735)

Fixed the metadata change events in the Migration component to check correctly for the diff in
existing topic changes and replicate the metadata to the Zookeeper. Also, made the diff check
exhaustive enough to handle the partial writes in Zookeeper when we're try to replicate changes
using a snapshot in the event of Controller failover.

Add migration client and integration tests to verify the change.

Co-authored-by: Akhilesh Chaganti <akhileshchg@users.noreply.github.com>",2023-06-01 15:43:41,David Arthur,Mixed
7c3a2846d46f21f2737483eeb7c04e4eee4c2b5f,"KAFKA-14462; [15/N] Make Result generic and rename it (#13793)

This patch makes the record type generic, moves the class to the runtime package and finally rename the class to follow the naming of the other classes in the runtime package.

Reviewers: Calvin Liu <caliu@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-06-02 09:18:09,David Jacot,Mixed
89581a738f6a67f1735956d0ac7f0c7a2e14822e,"KAFKA-14863: Hide plugins with invalid constructors during plugin discovery (#13467)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-06-02 11:09:43,Greg Harris,Not TDD
02fb4b882b86bc835cf4b0bbdaee099d6056799b,"KAFKA-15012: Allow leading zeros in numeric fields while deserializing JSON messages using the JsonConverter (#13800)

Reviewers: Sagar Rao <sagarmeansocean@gmail.com>, Chris Egerton <chrise@aiven.io>",2023-06-02 11:20:37,Yash Mayya,Not TDD
146a6976aed0d9f90c70b6f21dca8b887cc34e71,"KAFKA-15048: Improve handling of unexpected quorum controller errors (#13799)

When the active quorum controller encounters an ""unexpected"" error, such as a NullPointerException,
it currently resigns its leadership. This PR fixes it so that in addition to doing that, it also
increments the metadata error count metric. This will allow us to better track down these errors.

This PR also fixes a minor bug where performing read operations on a standby controller would
result in an unexpected RuntimeException. The bug happened because the standby controller does not
take in-memory snapshots, and read operations were attempting to read from the epoch of the latest
committed offset. The fix is for the standby controller to simply read the latest value of each
data structure. This is always safe, because standby controllers don't contain uncommitted data.

Also, fix a bug where listPartitionReassignments was reading the latest data, rather than data from
the last committed offset.

Reviewers: dengziming <dengziming1993@gmail.com>, David Arthur <mumrah@gmail.com>",2023-06-02 12:51:15,Colin Patrick McCabe,Mixed
7a6435af499fc98207747be231997ebd76761a36,"KAFKA-15037: pass remoteLogEnabled to unifiedLog (#13779)

UnifiedLog relied on the remoteStorageSystemEnable to identify if the broker is enabling remote storage, but we never pass this value from the config into UnifiedLog. So it'll always be false.

In this PR, I did:

   - pass remoteStorageSystemEnable to UnifiedLog
   - remove remoteLogManager from the class member of UnifiedLog since only UnifiedLog#fetchOffsetByTimestamp needs remoteLogManager, and this can be passed when called from ReplicaManager.

Reviewers: Satish Duggana <satishd@apache.org>, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>",2023-06-05 15:00:16,Luke Chen,Mixed
fe6a827e20d30af5328d7376a831f9666e0c8110,"KAFKA-14633: Reduce data copy & buffer allocation during decompression (#13135)

After this change,

    For broker side decompression: JMH benchmark RecordBatchIterationBenchmark demonstrates 20-70% improvement in throughput (see results for RecordBatchIterationBenchmark.measureSkipIteratorForVariableBatchSize).
    For consumer side decompression: JMH benchmark RecordBatchIterationBenchmark a mix bag of single digit regression for some compression type to 10-50% improvement for Zstd (see results for RecordBatchIterationBenchmark.measureStreamingIteratorForVariableBatchSize).

Reviewers: Luke Chen <showuon@gmail.com>, Manyanda Chitimbo <manyanda.chitimbo@gmail.com>, Ismael Juma <mail@ismaeljuma.com>",2023-06-05 15:04:49,Divij Vaidya,Mixed
17fd30e6b457f097f6a524b516eca1a6a74a9144,"MINOR: Fix flaky DistributedHerderTest cases related to zombie fencing (#13806)

Reviewers: Yash Mayya <yash.mayya@gmail.com>, Chris Egerton <chrise@aiven.io>",2023-06-05 15:50:54,Chris Egerton,Mixed
04f2f6a26ad14dee71a487a13425c26e55156365,"MINOR: Typo and unused method removal (#13739)

clean up unused private method and removed typos

Reviewers:  Divij Vaidya <diviv@amazon.com>,  Manyanda Chitimbo <manyanda.chitimbo@gmail.com>,  Daniel Scanteianu, Josep Prat <josep.prat@aiven.io>",2023-06-06 10:50:56,mojh7,Not TDD
9ebe395c578c9531bae8805471939ad6f65e0b31,"KAFKA-14866: Remove controller module metrics when broker is shutting down (#13473)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Divij Vaidya <diviv@amazon.com>",2023-06-06 11:10:16,hudeqi,Mixed
c8cb85274e9e7c7c797d2d498b54fa58ec238e0e,"MINOR: Refactor DelegatingClassLoader to emit immutable PluginScanResult (#13771)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-06-06 09:37:57,Greg Harris,Mixed
7d147cf2413e5d361422728e5c9306574658c78d,"KAFKA-14462; [14/N] Add PartitionWriter (#13675)

This patch introduces the `PartitionWriter` interface in the `group-coordinator` module. The `ReplicaManager` resides in the `core` module and it is thus not accessible from the `group-coordinator` one. The `CoordinatorPartitionWriter` is basically an implementation of the interface residing in `core` which interfaces with the `ReplicaManager`.

One notable difference from the usual produce path is that the `PartitionWriter` returns the offset following the written records. This is then used by the coordinator runtime to track when the request associated with the write can be completed.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-06-06 16:24:48,David Jacot,Mixed
db9d8457027c1dfb72a33290d18e227d4a02f16d,"KAFKA-14791; Create a builder for PartitionRegistration (#13788)

This creates a builder for PartitionRegistration. The motivation for the builder is that the constructor of PartitionRegistration has four arguments all of type int[] which makes it easy to make a mistake when using it.

Reviewers: José Armando García Sancio <jsancio@apache.org>",2023-06-06 07:58:23,andymg3,Mixed
3d349ae0d687dacb014c57d200a748784e8c6bbe,"MINOR; Add helper util Snapshots.lastContainedLogTimestamp (#13772)

This change refactors the lastContainedLogTimestamp to the Snapshots class, for re-usability. Introduces IdentitySerde based on ByteBuffer, required for using RecordsSnapshotReader. This change also removes the ""recordSerde: RecordSerde[_]"" argument from the KafkaMetadataLog constructor.

Reviewers: José Armando García Sancio <jsancio@apache.org>",2023-06-06 08:29:15,Alok Thatikunta,Mixed
8ad0ed3e618ed6c101907484d6cdbaee90d3d99c,"KAFKA-15021; Skip leader epoch bump on ISR shrink (#13765)

When the KRaft controller removes a replica from the ISR because of the controlled shutdown there is no need for the leader epoch to be increased by the KRaft controller. This is accurate as long as the topic partition leader doesn't add the removed replica back to the ISR.

This change also fixes a bug when computing the HWM. When computing the HWM, replicas that are not eligible to join the ISR but are caught up should not be included in the computation. Otherwise, the HWM will never increase for replica.lag.time.max.ms because the shutting down replica is not sending FETCH request. Without this additional fix PRODUCE requests would timeout if the request timeout is greater than replica.lag.time.max.ms.

Because of the bug above the KRaft controller needs to check the MV to guarantee that all brokers support this bug fix before skipping the leader epoch bump.

Reviewers: David Mao <47232755+splett2@users.noreply.github.com>, Divij Vaidya <diviv@amazon.com>, David Jacot <djacot@confluent.io>",2023-06-07 07:20:40,José Armando García Sancio,Mixed
59d30a06fc1371d01a853139053bd6bd9bb770a0,"KAFKA-10337: await async commits in commitSync even if no offsets given (#13678)

The contract for Consumer#commitSync() guarantees that the callbacks for all prior async commits will be invoked before it returns. Prior to this patch the contract could be violated if an empty offsets map were passed in to Consumer#commitSync().

Reviewers: Philip Nee <philipnee@gmail.com>, David Jacot <djacot@confluent.io>",2023-06-07 16:55:03,Erik van Oosten,Mixed
ff77b3ad041c1a4c80119f960e1f87c07b9e93dd,"KAFKA-14278: Fix InvalidProducerEpochException and InvalidTxnStateException handling in producer clients (#13811)

This PR fixes three issues:

InvalidProducerEpochException was not handled consistently. InvalidProducerEpochException used to be able to be return via both transactional response and produce response, but as of KIP-588 (2.7+), transactional responses should not return InvalidProducerEpochException anymore, only produce responses can. It can happen that older brokers may still return InvalidProducerEpochException for transactional responses; these must be converted to the newer ProducerFencedException. This conversion wasn't done for TxnOffsetCommit (sent to the group coordinator).

InvalidTxnStateException was double-wrapped in KafkaException, whereas other exceptions are usually wrapped only once. Furthermore, InvalidTxnStateException was not handled at all for in AddOffsetsToTxn response, where it should be a possible error as well, according to API documentation.

According to API documentation, UNSUPPORTED_FOR_MESSAGE_FORMAT is not possible for TxnOffsetCommit, but it looks like it is, and it is being handled there, so I updated the API documentation.

Reviewers: Justine Olshan <jolshan@confluent.io>",2023-06-07 09:48:14,Lucas Brutschy,Mixed
513e1c641d63c5e15144f9fcdafa1b56c5e5ba09,"KAFKA-14539: Simplify StreamsMetadataState by replacing the Cluster metadata with partition info map (#13751)

Replace usage of Cluster in StreamsMetadataState with Map<String, List>. Update StreamsPartitionAssignor#onAssignment method to pass existing Map<TopicPartition, PartitionInfo> instead of fake Cluster object.

Behavior remains the same; updated existing unit tests accordingly.

Reviewers:  Walker Carlson <wcarlson@confluent.io>, Bill Bejeck <bbejeck@apache.org>",2023-06-07 15:35:11,Danica Fine,Mixed
d3e0b27b24dc30984894357375f1d47f3848e552,"KAFKA-15040: trigger onLeadershipChange under KRaft mode (#13807)

When received LeaderAndIsr request, we'll notify remoteLogManager about this leadership changed to trigger the following workflow. But LeaderAndIsr won't be sent in KRaft mode, instead, the topicDelta will be received.

This PR fixes this issue by getting leader change and follower change from topicDelta, and triggering rlm.onLeadershipChange to notify remote log manager. Adding tests for remote storage enabled cases.

Reviewers: Satish Duggana <satishd@apache.org>",2023-06-09 09:53:46,Luke Chen,Mixed
7eea2a3908fdcee1627c18827e6dcb5ed0089fdd,"MINOR: Move MockTime to server-common (#13823)

This patch rewrite `MockTime` in Java and moves it to `server-common` module. This is a prerequisite to move `MockTimer` later on to `server-common` as well. 

Reviewers: David Arthur <mumrah@gmail.com>",2023-06-09 08:54:25,David Jacot,Mixed
daba741826ec9b7ceed7ce9ef3396f83157b7f34,"KAFKA-14936: Change Time Ordered Buffer to not require Change<> 0/N (#13830)

Change the TimeOrderedKeyValueBuffer to take three types to include the store type so that it can be used for non change<V> operations as well.

Reviewers: Victoria Xia<victoria.xia@confluent.io> , Gabriel Gama <>",2023-06-10 17:22:32,Walker Carlson,Mixed
5afce2de68517498e23c6c224a686115252d2611,"KAFKA-15077: Code to trim token in FileTokenRetriever (#13835)

The FileTokenRetriever class is used to read the access_token from a file on the clients system and then it is passed along with the jaas config to the OAuthBearerSaslServer. In case the token was sent using FileTokenRetriever on the client side, some EOL character is getting appended to the token, causing authentication to fail with the message:


Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2023-06-11 11:52:25,Sushant Mahajan,Not TDD
6fe74f78dc725466319bd0465764913532949ba3,"KAFKA-10199: Re-add revived tasks to the state updater after handling (#13829)

Fixes a bug regarding the state updater where tasks that experience corruption
during restoration are passed from the state updater to the stream thread
for closing and reviving but then the revived tasks are not re-added to
the state updater.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>, Walker Carlson <wcarlson@confluent.io>",2023-06-11 15:14:46,Bruno Cadonna,Mixed
b7a6a8fd5f03144c2ff964f5531470e456dbb4ba,"KAFKA-15076; KRaft should prefer latest snapshot (#13834)

If the KRaft listener is at offset 0, the start of the log, and KRaft has generated a snapshot, it should prefer the latest snapshot instead of having the listener read from the start of the log.

This is implemented by having KafkaRaftClient send a Listener.handleLoadSnapshot event, if the Listener is at offset 0 and the KRaft partition has generated a snapshot.

Reviewers: Jason Gustafson <jason@confluent.io>, David Arthur <mumrah@gmail.com>",2023-06-12 07:25:42,José Armando García Sancio,Not TDD
7556ce366a6df1f60928e66258e32f9b3b6286c2,"KAFKA-14462; [17/N] Add CoordinatorRuntime (#13795)

This patch introduces the CoordinatorRuntime. The CoordinatorRuntime is a framework which encapsulate all the common features requires to build a coordinator such as the group coordinator. Please refer to the javadoc of that class for the details.

Reviewers: Divij Vaidya <diviv@amazon.com>, Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-06-13 09:46:38,David Jacot,Mixed
dfe050c8bfaf312f1ccc89a1ae2d6cbd0761b88e,"KAFKA-15080; Fetcher's lag never set when partition is idle (#13843)

The PartitionFetchState's lag field is set to None when the state is created and it is updated when bytes are received for a partition. For idle partitions (newly created or not), the lag is never updated because `validBytes > 0` is never true. As a side effect, the partition is considered out-of-sync and could be incorrectly throttled.

Reviewers: Divij Vaidya <diviv@amazon.com>, Jason Gustafson <jason@confluent.io>",2023-06-13 15:18:54,David Jacot,Not TDD
45a279ec7098aa925ac076b962dc923deb2f9d8f,"MINOR: Move Timer/TimingWheel to server-common (#13820)

This patch rewrite `Timer` and the related classes in Java and moves them to `server-common` module. It is basically a one to one rewrite of the Scala code. Note that `MockTimer` is not moved as part of this patch. It will be done separately.

Reviewers: Divij Vaidya <diviv@amazon.com>",2023-06-14 18:21:30,David Jacot,Mixed
4a5d1b320502c808509e9b795bd669030ce03fd2,"KAFKA-14936: Add On Disk Time Ordered Buffer (1/N) (#13756)

KAFKA-14936: Add On Disk Time Ordered Buffer

Add a time ordered key-value buffer stored on disk and implemented using RocksDBTimeOrderedKeyValueSegmentedBytesStore.

This will be used in the stream buffered for joins with a grace period.

Reviewers: Bruno Cadonna <cadonna@confluent.io> Victoria Xia <victoria.xia@confluent.io>",2023-06-14 15:16:55,Walker Carlson,Mixed
e1d59920f4fed5c4bc890e53e249d3439e148bab,"KAFKA-15059: Remove pending rebalance check when fencing zombie source connector tasks (#13819)

Discovered while researching KAFKA-14718

Currently, we perform a check during zombie fencing that causes the round of zombie fencing to fail when a rebalance is pending (i.e., when we've detected from a background poll of the config topic that a new connector has been created, that an existing connector has been deleted, or that a new set of connector tasks has been generated).

It's possible but not especially likely that this check causes issues when running vanilla Kafka Connect. Even when it does, it's easy enough to restart failed tasks via the REST API.

However, when running MirrorMaker 2 in dedicated mode, this check is more likely to cause issues as we write three connector configs to the config topic in rapid succession on startup. And in that mode, there is no API to restart failed tasks aside from restarting the worker that they are hosted on.

In either case, this check can lead to test flakiness in integration tests for MirrorMaker 2 both in dedicated mode and when deployed onto a vanilla Kafka Connect cluster.

This check is not actually necessary, and we can safely remove it. Copied from Jira:

>If the worker that we forward the zombie fencing request to is a zombie leader (i.e., a worker that believes it is the leader but in reality is not), it will fail to finish the round of zombie fencing because it won't be able to write to the config topic with a transactional producer.

>If the connector has just been deleted, we'll still fail the request since we force a read-to-end of the config topic and refresh our snapshot of its contents before checking to see if the connector exists.

>And regardless, the worker that owns the task will still do a read-to-end of the config topic and verify that (1) no new task configs have been generated for the connector and (2) the worker is still assigned the connector, before allowing the task to process any data.

In addition, while waiting on a fix for KAFKA-14718 that adds more granularity for diagnosing failures in the DedicatedMirrorIntegrationTest suite (#13284), some of the timeouts in that test are bumped to work better on our CI infrastructure.

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Yash Mayya <yash.mayya@gmail.com>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>",2023-06-16 11:58:36,Chris Egerton,Not TDD
74238656dcc42e27733bbcb0a2df6d1cd61f09a4,"KAFKA-15066: add ""remote.log.metadata.manager.listener.name"" config to rlmm (#13828)

add ""remote.log.metadata.manager.listener.name"" config to rlmm to allow producer/consumer to connect to the server. Also add tests.

Reviewers: Divij Vaidya <diviv@amazon.com>, Satish Duggana <satishd@apache.org>",2023-06-16 20:56:13,Luke Chen,Mixed
09e8adb330e8dfb45455d00ec12fd28e07cb3aa7,"MINOR:Optimize the use of metrics in ReplicaManager and remove checks (#13705)

Co-authored-by: Deqi Hu <deqi.hu@shopee.com>

Reviewers: Divij Vaidya <diviv@amazon.com>, Manyanda Chitimbo <manyanda.chitimbo@gmail.com>, Kirk True <ktrue@confluent.io>",2023-06-17 10:44:56,hudeqi,Mixed
f4981790c414eafbb0cd29f9ce42297e10420ca6,"KAFKA-15085: Make Timer.java implement AutoCloseable (#13872)

Change Timer.java to implement AutoCloseable because automatic bug finders will flag a warning if an object of a class is marked as AutoCloseable but is not closed properly in the code.

Reviewers:  Divij Vaidya <diviv@amazon.com>",2023-06-19 15:50:30,Joobi S B,Mixed
cd3c0ab1a3de0e02f473edeeb986acff3fc87230,"KAFKA-15060: fix the ApiVersionManager interface

This PR expands the scope of ApiVersionManager a bit to include returning the current
MetadataVersion and features that are in effect. This is useful in general because that information
needs to be returned in an ApiVersionsResponse. It also allows us to fix the ApiVersionManager
interface so that all subclasses implement all methods of the interface. Having subclasses that
don't implement some methods is dangerous because they could cause exceptions at runtime in
unexpected scenarios.

On the KRaft controller, we were previously performing a read operation in the QuorumController
thread to get the current metadata version and features. With this PR, we now read a volatile
variable maintained by a separate MetadataVersionContextPublisher object. This will improve
performance and simplify the code. It should not change the guarantees we are providing; in both
the old and new scenarios, we need to be robust against version skew scenarios during updates.

Add a Features class which just has a 3-tuple of metadata version, features, and feature epoch.
Remove MetadataCache.FinalizedFeaturesAndEpoch, since it just duplicates the Features class.
(There are some additional feature-related classes that can be consolidated in in a follow-on PR.)

Create a java class, EndpointReadyFutures, for managing the futures associated with individual
authorizer endpoints. This avoids code duplication between ControllerServer and BrokerServer and
makes this code unit-testable.

Reviewers: David Arthur <mumrah@gmail.com>, dengziming <dengziming1993@gmail.com>, Luke Chen <showuon@gmail.com>",2023-06-19 16:46:44,Colin P. McCabe,Mixed
b100f1efac77bf795683ab5e68ecf87845372089,"KAFKA-15087 Move/rewrite InterBrokerSendThread to server-commons (#13856)

The Java rewrite is kept relatively close to the Scala original
to minimize potential newly introduced bugs and to make reviewing
simpler. The following details might be of note:
- The `Logging` trait moved to InterBrokerSendThread with the
rewrite of ShutdownableThread has been similarly moved to any
subclasses that currently use it. InterBrokerSendThread's own
logging has been made to use ShutdownableThread's logger which
mimics the prefix/log identifier that the trait provided.
- The case RequestAndCompletionHandler class has been made a
separate POJO class and the internal-use UnsentRequests class
has been kept as a static nested class.
- The relatively commonly used but internal (not part of the
public API) clients classes that InterBrokerSendThread relies on
have been allowlisted in the server-common import control.
- The accompanying test class has also been moved and rewritten
with one new test added and most of the pre-existing tests made
stricter.

Reviewers: David Jacot <djacot@confluent.io>",2023-06-20 16:50:46,Dimitar Dimitrov,Mixed
dfaae317b82035323ba9c693b3ad7f02a6a58395,"MINOR: Upgrade Scala for Java 20/21 support (#13840)

Upgrade to Scala 2.13.11 and Scala 2.12.18. A minor test change was required
to fix compilation with Scala 2.13.11.

Scala 2.13 release notes:
* https://github.com/scala/scala/releases/tag/v2.13.11

Scala 2.12 release notes:
* https://github.com/scala/scala/releases/tag/v2.12.16
* https://github.com/scala/scala/releases/tag/v2.12.17
* https://github.com/scala/scala/releases/tag/v2.12.18

Reviewers: Justine Olshan <jolshan@confluent.io>, Josep Prat <josep.prat@aiven.io>",2023-06-20 10:29:23,Ismael Juma,Not TDD
d751c13950770ab2fee3087c7de8f8e7416b4fd8,"MINOR: Fix typos for connect (#13885)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-06-20 16:16:16,minjian.cai,Not TDD
3d97743c678bc9df534bd0c84b9b60eda20c3a7c,"MINOR: Fix some typos for core (#13882)

Reviewers:  Divij Vaidya <diviv@amazon.com>",2023-06-20 22:52:39,minjian.cai,Mixed
af678a563d9b89e8bd87f77d400b693bd47829c4,"MINOR: fix typos for server common (#13887)

Reviewers: Manyanda Chitimbo <manyanda.chitimbo@gmail.com>, Divij Vaidya <diviv@amazon.com>",2023-06-20 22:56:01,minjian.cai,Not TDD
39a47c89990eb3b8f419e0e8ac8343663c8d35a7,"MINOR: fix typos for group coordinator (#13886)

Reviewers: Manyanda Chitimbo <manyanda.chitimbo@gmail.com>, Divij Vaidya <diviv@amazon.com>",2023-06-20 22:57:26,minjian.cai,Not TDD
474053d2973b8790e50ccfe1bb0699694b0de1c7,"MINOR: fix typos for streams (#13888)

Reviewers: Divij Vaidya <diviv@amazon.com>, Manyanda Chitimbo <manyanda.chitimbo@gmail.com>",2023-06-20 23:03:42,minjian.cai,Mixed
ba5e1acdfb86c8325ed00b69fb6605190c1a9b1c,"MINOR: fix typos for metadata (#13889)

Reviewers: Divij Vaidya <diviv@amazon.com>, Deqi Hu <deqi.hu@shopee.com>",2023-06-21 15:09:15,minjian.cai,Not TDD
88e784f7c6fa7df91965076d8cb0e0e691719cdc,"KAFKA-15084: Remove lock contention from RemoteIndexCache (#13850)

Use thread safe Caffeine to cache indexes fetched from RemoteTier locally. This PR removes a lock contention that led to higher fetch latencies as the IO threads spent time unnecessarily waiting on global cache lock while a single thread fetches the index from remote tier. See PR #13850 for details and rejected alternatives.

Reviewers: Luke Chen <showuon@gmail.com>, Satish Duggana <satishd@apache.org>",2023-06-21 18:22:49,Divij Vaidya,Mixed
d0457f7360e2e3d34800fbd41de429afbaabd101,"KAFKA-15109 Don't skip leader epoch bump while in migration mode (#13890)

While in migration mode, the KRaft controller must always bump the leader epoch when shrinking an ISR. 
This is required to maintain compatibility with the ZK brokers. Without the epoch bump, the ZK brokers
will ignore the partition state change present in the LeaderAndIsrRequest since it would not contain a new
leader epoch.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-06-21 13:09:05,David Arthur,Mixed
3c059133d3008d87f018f2efa4af27027fd5d18e,"MINOR: Fix generated client ids for Connect (#13896)


Reviewers: Chris Egerton <fearthecellos@gmail.com>",2023-06-21 21:44:14,Mickael Maison,Mixed
a81486e4f822b646039586ed0f70f9d75ec3ae36,"KAFKA-14462; [18/N] Add GroupCoordinatorService (#13812)

This patch introduces the GroupCoordinatorService. This is the new (incomplete) implementation of the group coordinator based on the coordinator runtime introduced in https://github.com/apache/kafka/pull/13795.

Reviewers: Divij Vaidya <diviv@amazon.com>, Justine Olshan <jolshan@confluent.io>",2023-06-22 09:06:10,David Jacot,Mixed
1bf703999999123c4ac7901ee45e5523be2236f8,"KAFKA-15098 Allow authorizers to be configured in ZK migration (#13895)

Reviewers: Ron Dagostino <rdagostino@confluent.io>",2023-06-22 09:34:49,David Arthur,Mixed
9c8aaa2c35aabb09bd2d5c3d28d1b4587818b419,"MINOR: Fix lossy conversions flagged by Java 20 (#13582)

An example of the warning:
> warning: [lossy-conversions] implicit cast from long to int in compound assignment is possibly lossy

There should be no change in behavior as part of these changes - runtime logic ensured
we didn't run into issues due to the lossy conversions.

Reviewers: Divij Vaidya <diviv@amazon.com>",2023-06-22 08:05:55,Ismael Juma,Mixed
1dbcb7da9e3625ec2078a82f84542a3127730fef,"KAFKA-14694: RPCProducerIdManager should not wait on new block (#13267)

RPCProducerIdManager initiates an async request to the controller to grab a block of producer IDs and then blocks waiting for a response from the controller.

This is done in the request handler threads while holding a global lock. This means that if many producers are requesting producer IDs and the controller is slow to respond, many threads can get stuck waiting for the lock.

This patch aims to:
* resolve the deadlock scenario mentioned above by not waiting for a new block and returning an error immediately
* remove synchronization usages in RpcProducerIdManager.generateProducerId()
* handle errors returned from generateProducerId() so that KafkaApis does not log unexpected errors
* confirm producers backoff before retrying
* introduce backoff if manager fails to process AllocateProducerIdsResponse

Reviewers: Artem Livshits <alivshits@confluent.io>, Jason Gustafson <jason@confluent.io>",2023-06-22 10:19:39,Jeff Kim,Mixed
6e729869496e36990ca76ffeabfaec3f389fb059,"KAFKA-14784: Connect offset reset REST API (#13818)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-06-23 13:27:46,Yash Mayya,Mixed
c5889fceddb9a0174452ae60a57c8ff3f087a6a4,"MINOR: Split ConsumerCoordinator#testCommitOffsetMetadata onto two test cases testing commitSync and commitAsync  (#13665)

Split ConsumerCoordinator#testCommitOffsetMetadata onto two test cases testing commitSync and commitAsync 

Reviewers:  Luke Chen <showuon@gmail.com>",2023-06-24 12:32:21,Manyanda Chitimbo,Not TDD
fc7d912e8bb856500fa27b7455e6eff098c08196,"KAFKA-15109 Ensure the leader epoch bump occurs for older MetadataVersions (#13910)

This fixes a regression introduced by the previous KAFKA-15109 commit (d0457f7360 on trunk).

Reviewers: Colin P. McCabe <cmccabe@apache.org>, José Armando García Sancio <jsancio@apache.org>",2023-06-27 11:49:20,David Arthur,Mixed
e71f68d6c91394db30bb1219ea882232f7be194d,"MINOR: fix typos for client (#13884)

Reviewers: Luke Chen <showuon@gmail.com>, Divij Vaidya <diviv@amazon.com>, Kirk True <ktrue@confluent.io>",2023-06-28 16:47:42,minjian.cai,Mixed
2f71708955b293658cec3b27e9a5588d39c38d7e,"KAFKA-15028: AddPartitionsToTxnManager metrics (#13798)

Adding the following metrics as per kip-890:

VerificationTimeMs – number of milliseconds from adding partition info to the manager to the time the response is sent. This will include the round trip to the transaction coordinator if it is called. This will also account for verifications that fail before the coordinator is called.

VerificationFailureRate – rate of verifications that returned in failure either from the AddPartitionsToTxn response or through errors in the manager.

AddPartitionsToTxnVerification metrics – separating the verification request metrics from the typical add partitions ones similar to how fetch replication and fetch consumer metrics are separated.

Reviewers: Divij Vaidya <diviv@amazon.com>",2023-06-28 09:00:37,Justine Olshan,Mixed
3a246b1abab0cfa8050546f54c987af2ec6cdd4e,"KAFKA-15078; KRaft leader replys with snapshot for offset 0 (#13845)

If the follower has an empty log, fetches with offset 0, it is more
efficient for the leader to reply with a snapshot id (redirect to
FETCH_SNAPSHOT) than for the follower to continue fetching from the log
segments.

Reviewers: David Arthur <mumrah@gmail.com>, dengziming <dengziming1993@gmail.com>",2023-06-28 14:21:11,José Armando García Sancio,Not TDD
482299c4e2c97315feea3db5d6bf0e5c2c8b8cc7,"KAFKA-14462; [19/N] Add CoordinatorLoader implementation (#13880)

This patch adds a coordinator loader implementation.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-06-29 08:12:53,David Jacot,Mixed
005416879e4c180e8e9dea94a08e57521ac8cf1d,"KAFKA-15053: Use case insensitive validator for security.protocol config (#13831)

Fixed a regression described in KAFKA-15053 that security.protocol only allows uppercase values like PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL. With this fix, both lower case and upper case values will be supported (e.g. PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL, plaintext, ssl, sasl_plaintext, sasl_ssl)

Reviewers: Chris Egerton <chrise@aiven.io>, Divij Vaidya <diviv@amazon.com>",2023-06-29 10:13:21,Bo Gao,Mixed
12be344fdd3b20f338ccab87933b89049ce202a4,"KAFKA-14936: Add Grace period logic to Stream Table Join (2/N) (#13855)

This PR adds the interface for grace period to the Joined object as well as uses the buffer. The majority of it is tests and moving some of the existing join logic.

Reviewers: Victoria Xia <victoria.xia@confluent.io>, Bruno Cadonna <cadonna@apache.org>",2023-06-29 14:14:04,Walker Carlson,Mixed
a81f35c1c8f9dc594aa585618c36f92ade0f86e2,"KAFKA-14831: Illegal state errors should be fatal in transactional producer (#13591)

Poison the transaction manager if we detect an illegal transition in the Sender thread. A ThreadLocal in is stored in TransactionManager so that the Sender can inform TransactionManager which thread it's using.

Reviewers: Daniel Urban <durban@cloudera.com>, Justine Olshan <jolshan@confluent.io>, Jason Gustafson <jason@confluent.io>",2023-06-29 11:21:15,Kirk True,Mixed
1f4cbc5d53259031123b6e9e6bb9a5bbe1e084e8,"MINOR: Add JDK 20 CI build and remove some branch builds (#12948)

It's good for us to add support for Java 20 in preparation for Java 21 - the next LTS.

Given that Scala 2.12 support has been deprecated, a Scala 2.12 variant is not included.

Also remove some branch builds that add load to the CI, but have
low value: JDK 8 & Scala 2.13 (JDK 8 support has been deprecated),
JDK 11 & Scala 2.12 (Scala 2.12 support has been deprecated) and
JDK 17 & Scala 2.12 (Scala 2.12 support has been deprecated).

A newer version of Mockito (4.9.0 -> 4.11.0) is required for Java 20 support, but we
only use it with Scala 2.13+ since it causes compilation errors with Scala 2.12. Similarly,
we upgrade easymock when the Java version is 16 or newer as it's incompatible
with powermock (which doesn't support Java 16 or newer).

Filed KAFKA-15117 for a test that fails with Java 20 (SslTransportLayerTest.testValidEndpointIdentificationCN).

Finally, fixed some lossy conversions that were added after #13582 was submitted.

Reviewers: Ismael Juma <ismael@juma.me.uk>",2023-06-30 01:12:00,Ismael Juma,Not TDD
b2d647904c0d9e02509bc303ae42d880a90d4742,"KAFKA-8982: Add retry of fetching metadata to Admin.deleteRecords (#13760)

Use AdminApiDriver class to refresh the metadata and retry the request that failed with retriable errors.

Reviewers: Luke Chen <showuon@gmail.com>, Divij Vaidya <diviv@amazon.com>, Mickael Maison <mmaison@redhat.com>, Dimitar Dimitrov <30328539+dimitarndimitrov@users.noreply.github.com>",2023-07-03 09:13:55,Gantigmaa Selenge,Mixed
0ae1d228796e100f371cd1f20d826547b6231113,"KAFKA-15135: fix(storage): pass endpoint configurations as client common to TBRLMM (#13938)

Pass endpoint properties from RLM to TBRLMM and validate those are not ignored.

Reviewers: Luke Chen <showuon@gmail.com>",2023-07-03 09:16:15,Jorge Esteban Quilcate Otoya,Mixed
48eb8c90ef5f474e54694b74377d20f9e378174c,"KAFKA-15129: [1/N] Remove metrics in LogCleanerManager when LogCleaner shutdown (#13924)

Reviewers: Divij Vaidya <diviv@amazon.com>, Christo Lolov <lolovc@amazon.com>

---------

Co-authored-by: Deqi Hu <deqi.hu@shopee.com>",2023-07-03 16:14:30,hudeqi,Mixed
5c2492bca71200806ccf776ea31639a90290d43e,"KAFKA-10199: Consider tasks in state updater when computing offset sums (#13925)

With the state updater, the task manager needs also to look into the
tasks owned by the state updater when computing the sum of offsets
of the state. This sum of offsets is used by the high availability
assignor to assign warm-up replicas.
If the task manager does not take into account tasks in the
state updater, a warm-up replica will never report back that
the state for the corresponding task has caught up. Consequently,
the warm-up replica will never be dismissed and probing rebalances
will never end.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Walker Carlson <wcarlson@confluent.io>",2023-07-03 16:35:34,Bruno Cadonna,Mixed
98fbd8afc7f3ba806d742690536090936738f1e7,"KAFKA-14462; [20/N] Refresh subscription metadata on new metadata image (#13901)

This patch adds (1) the logic to propagate a new MetadataImage to the running coordinators; and (2) the logic to ensure that all the consumer groups subscribed to topics with changes will refresh their subscriptions metadata on the next heartbeat. In the mean time, it ensures that freshly loaded consumer groups also refresh their subscriptions metadata on the next heartbeat.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-07-05 18:28:38,David Jacot,Mixed
bd1f02b2beca69a0937bb3df6f1e0ebcc3d9bfeb,"MINOR: Move MockTimer to server-common (#13954)

This patch rewrites MockTimer in Java and moves it from core to server-common. This continues the work started in https://github.com/apache/kafka/pull/13820.

Reviewers: Divij Vaidya <diviv@amazon.com>",2023-07-06 14:56:05,David Jacot,Not TDD
4149e31caddd859376f36f5e020c567b40b9ab9f,"KAFKA-15153: Use Python 'is' instead of '==' to compare for None (#13964)

Reviewers: Divij Vaidya <diviv@amazon.com>

Co-authored-by: d00791190 <dinglan6@huawei.com>",2023-07-06 16:59:13,DL1231,Not TDD
1b925e9ee753390d4633e8e5bd25a00af8d26cb9,"KAFKA-15069: Refactor plugin scanning logic into ReflectionScanner (#13821)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-07-06 13:22:28,Greg Harris,Mixed
574f394a3e711fe70bc979766112089085720c50,"MINOR: Fix regression introduced in #13924 (#13958)

Fixes a regression introduced in PR #13924 by moving the map from static to a instance specific variable.
---------

Co-authored-by: Deqi Hu <deqi.hu@shopee.com>",2023-07-07 10:18:38,hudeqi,Mixed
1d8b07ed6435568d3daf514c2d902107436d2ac8,"KAFKA-15129;[7/N] Remove metrics in TransactionMarkerChannelManager when TransactionCoordinator shutdown (#13962)

Reviewers: Divij Vaidya <diviv@amazon.com>

Co-authored-by: Deqi Hu <deqi.hu@shopee.com>",2023-07-07 10:27:10,hudeqi,Mixed
1223b79973c90240aff6cfda14135b22402e2338,"KAFKA-15149: Fix handling of new partitions in dual-write mode (#13968)

Fixes a bug where we don't send UMR and LISR requests in dual-write mode when new partitions are created. Prior to this patch, KRaftMigrationZkWriter was mutating the internal data-structures of TopicDelta which prevented MigrationPropagator from sending UMR and LISR for the changed partitions.

Reviewers: David Arthur <mumrah@gmail.com>",2023-07-07 10:16:51,andymg3,Not TDD
9cde3a79107130a13a215bf65d6b2b8df93757aa,"KAFKA-14462; [21/N] Add CoordinatorTimer implementation in CoordinatorRuntime (#13961)

This patch adds EventBasedCoordinatorTimer and the CoordinatorTimer interface.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-07-07 22:21:30,David Jacot,Mixed
14a97fafe719e5df7d4d8eb4e9c599f3e6a290c1,"MINOR: some minor shell fixes and improvements (#13940)

Make the output of 'find' and 'ls' sorted alphabetically.

Add GlobComponentTest.java to test globbing.

Add shell/src/test/resources/log4j.properties so that shell JUnit tests show some output

Reviewers: David Arthur <mumrah@gmail.com>",2023-07-07 13:52:47,Colin Patrick McCabe,Not TDD
7bdcb22cf6fde46efa0f129ca7e66d3015033d1a,"MINOR: Refactor & cleanup for RemoteIndexCache (#13936)

- Add new unit tests
- Change the on-disk filename from <offset>_<uuid>_.<indexSuffix> to <offset>_<uuid>.<indexSuffix> i.e. remove trailing underscore after
- Fix a small bug where we were parsing offset as Int when reading the file name from disk. Offset is long.
- Perform input validation in RemoteLogSegmentMetadata.
- Remove an extra loop in cleaner thread. Shutdownable thread already performs looping.

Reviewers: Jorge Esteban Quilcate Otoya <jorge.quilcate@aiven.io>, Satish Duggana <satishd@apache.org>",2023-07-08 12:52:22,Divij Vaidya,Mixed
0e56cc88416faf31485343ebb95948cb5d8fbc06,"KAFKA-15022: [1/N] initial implementation of rack aware assignor (#13851)

Part of KIP-925. Adds first internal classes to track rack.id client/partition metadata.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-07-10 08:41:20,Hao Li,Mixed
8be601d05129b0cfa349a739cf21fbb87351f5e9,"MINOR: Move TROGDOR.md to trogdor module (#13979)

Reviewers: Divij Vaidya <diviv@amazon.com>

---------

Co-authored-by: Deqi Hu <deqi.hu@shopee.com>",2023-07-10 18:11:21,hudeqi,Not TDD
d9a3e60dcc0aab24b609ffa808f169cd2e1eecc3,KAFKA-14718: Wait for MirrorMaker to start before executing test (#13284),2023-07-10 12:53:01,Divij Vaidya,Not TDD
6368d14a1d8c37305290b8b89fb5990ad07aa4db,"KAFKA-14059 Replace PowerMock with Mockito in WorkerSourceTaskTest (#13383)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-07-10 12:58:54,Hector Geraldino,Mixed
9ee28d1fe67d880725130bca84aacef718b11c98,"KAFKA-15145: Don't re-process records filtered out by SMTs on Kafka client retriable exceptions in AbstractWorkerSourceTask (#13955)

Reviewers: Sagar Rao <sagarmeansocean@gmail.com>, Chris Egerton <chrise@aiven.io>",2023-07-10 13:26:58,Yash Mayya,Mixed
51bc41031b91b16ffcbd95832e8a20a00d3b6f81,"KAFKA-15139: Avoid slow Set.removeAll(List) in MirrorCheckpointConnector (#13946)

Reviewed-by: Greg Harris <greg.harris@aiven.io>",2023-07-10 14:35:46,hudeqi,Mixed
b8f3776f2458d0270276bd3d59db66f4c7f3748c,"KAFKA-15155: Follow PEP 8 best practice in Python to check if a container is empty (#13974)

Reviewers: Divij Vaidya <diviv@amazon.com>",2023-07-11 11:01:50,Yi-Sheng Lien,Not TDD
adacfea2d6c133c9bb2a7ac3891dc69eb6f91e03,"KAFKA-12525: Ignoring stale status statuses when reading from Connect status topic (#13453)

During fast consecutive rebalances where a task is revoked from one worker and assigned to another one, it has been observed that there is a small time window and thus a race condition during which a RUNNING status record in the new generation is produced and is immediately followed by a delayed UNASSIGNED status record belonging to the same or a previous generation before the worker that sends this message reads the RUNNING status record that corresponds to the latest generation.
Although this doesn't inhibit the actual execution of tasks, it reports an incorrect status for those tasks(i.e UNASSIGNED). If the users have setup some kind of monitoring on tasks status then this could lead to false alarms for example.
This fix addresses this problem by checking if a status message is stale after reading it and updates it's status only when it is safe to. 

Reviewers: Lucent-Wong <manchesterfans@live.cn>, Chris Egerton <chrise@aiven.io>, Yash Mayya <yash.mayya@gmail.com>, Konstantine Karantasis <k.karantasis@gmail.com>",2023-07-11 08:05:10,vamossagar12,Mixed
7e2f87871371d4d88187f73f43090488612ef42a,"KAFKA-14522 Rewrite/Move of RemoteIndexCache to storage module. (#13275)

KAFKA-14522 Rewrite and Move of RemoteIndexCache to storage module.
Cleanedup index file suffix usages and other minor cleanups

Reviewers: Jun Rao <junrao@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Luke Chen <showuon@gmail.com>, Divij Vaidya <diviv@amazon.com>, Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Jorge Esteban Quilcate Otoya <quilcate.jorge@gmail.com>",2023-07-11 23:55:23,Satish Duggana,Mixed
aafbe3444354cfb0e4a8fdbd3443a63ba867c732,"KAFKA-14462; [22/N] Implement session and revocation timeouts (#13963)

This patch adds the session timeout and the revocation timeout to the new consumer group protocol.

Reviewers: Calvin Liu <caliu@confluent.io>, Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-07-12 11:10:51,David Jacot,Mixed
4e85bc9f80d5dcfcfb256ebbbc752d58fe5e534a,"MINOR: Fix Jmxtool to honour wait option when MBean is not yet avaibale in MBean server (#13995)

In JmxTool.scala, we will wait till all the object names are available from MBean server. But in the newer version, we only wait for subset of object names. Due to this, we may not enforce wait option and prematurely return the result if the objects are not yet registered in MBean sever.

Reviewers: Luke Chen <showuon@gmail.com>, Federico Valeri <fvaleri@redhat.com>",2023-07-12 17:01:10,Manikumar Reddy,Mixed
d114d8e29ca3b8b80bbb4ea693f2a772a0e9b7d9,"KAFKA-14938: Fixing flaky test testConnectorBoundary (#13646)

Reviewers: Sagar Rao <sagarmeansocean@gmail.com>, Yash Mayya <yash.mayya@gmail.com>, 
Sudesh Wasnik <swasnik@confluent.io>, Chris Egerton <chrise@aiven.io>",2023-07-12 11:45:49,Sambhav Jain,Not TDD
5f20750dc14c56538e904c363d27264f02e74d82,"Kafka Streams Threading: Exception handling (#13957)

Catch any exceptions that escape the processing logic
inside TaskExecutors and record them in the TaskManager.
Make sure the TaskExecutor survives, but the task is
unassigned. Add a method to TaskManager to drain the
exceptions. The aim here is that the polling thread will
drain the exceptions to be able to execute the
uncaught exception handler, abort transactions, etc.

Reviewer: Bruno Cadonna <cadonna@apache.org>",2023-07-13 14:33:39,Lucas Brutschy,Mixed
959f9ca4c02817cce85f0375d431ed72f22699e2,"MINOR: Standardize controller log4j output for replaying records (#13703)

Standardize controller log4j output for replaying important records. The log message should include
word ""replayed"" to make it clear that this is a record replay. Log the replay of records for ACLs,
client quotas, and producer IDs, which were previously not logged. Also fix a case where we weren't
logging changes to broker registrations.

AclControlManager, ClientQuotaControlManager, and ProducerIdControlManager didn't previously have a
log4j logger object, so this PR adds one. It also converts them to using Builder objects. This
makes junit tests more readable because we don't need to specify paramaters where the test can use
the default (like LogContexts).

Throw an exception in replay if we get another TopicRecord for a topic which already exists.

Example log messages:
  INFO [QuorumController id=3000] Replayed a FeatureLevelRecord setting metadata version to 3.6-IV0
  DEBUG [QuorumController id=3000] Replayed a ZkMigrationStateRecord which did not alter the state from NONE.
  INFO [QuorumController id=3000] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 0: BrokerRegistrationChangeRecord(brokerId=0, brokerEpoch=3, fenced=-1, inControlledShutdown=0)
  INFO [QuorumController id=3000] Replayed ClientQuotaRecord for ClientQuotaEntity(entries={user=testkit}) setting request_percentage to 0.99.

Reviewers: Divij Vaidya <diviv@amazon.com>, Ron Dagostino <rndgstn@gmail.com>, David Arthur <mumrah@gmail.com>",2023-07-13 13:27:15,Colin Patrick McCabe,Mixed
32ff347b2c0ca21b9c567ab4cfe54869d7148e28,"KAFKA-14462; [23/23] Wire GroupCoordinatorService in BrokerServer (#13991)

This patch wires the new group coordinator in BrokerServer (KRaft only). With this, it is now possible to run a cluster with the new group coordinator and to use the ConsumerGroupHeartbeat API by specifying the following two properties:
- group.coordinator.new.enable = true (to enable the new group coordinator)
- unstable.api.versions.enable = true (to enable unreleased APIs)

Note that the new group coordinator does not support all the existing APIs yet.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-07-14 17:41:06,David Jacot,Mixed
2b19b7325aac0449de15970b4710a83a51ae29ad,"KAFKA-15182: Normalize source connector offsets before invoking SourceConnector::alterOffsets (#14003)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-07-14 12:14:03,Yash Mayya,Mixed
d9253fed5c022c53a43e986c7d738ca25ef7d92b,"MINOR Improve logging during the ZK to KRaft migration (#14008)

* Adds an exponential backoff to 1m while the controller is waiting for brokers to show up
* Increases one-time logs to INFO
* Adds a summary of the migration records
* Use RecordRedactor for summary of migration batches (TRACE only)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-07-14 17:44:00,David Arthur,Mixed
ea0bb001262320bc9233221955a2be31c85993b9,"KAFKA-14884: Include check transaction is still ongoing right before append (take 2) (#13787)

Introduced extra mapping to track verification state.

When verifying, there is a race condition that the add partitions verification response returns that the partition is in the ongoing transaction, but an abort marker is written before we get to append. Therefore, we track any given transaction we are verifying with an object unique to that transaction.

We check this unique state upon the first append to the log. After that, we can rely on currentTransactionFirstOffset. We remove the verification state on appending to the log with a transactional data record or marker.

We will also clean up lingering verification state entries via the producer state entry expiration mechanism. We do not update the the timestamp on retrying a verification for a transaction, so each entry must be verified before producer.id.expiration.ms.

There were a few other fixes:
- Moved the transaction manager handling for failed batch into the future completed exceptionally block to avoid processing it twice (this caused issues in unit tests)
- handle interrupted exceptions encountered when callback thread encountered them
- change handling to throw error if we try to set verification state and leaderLogIfLocal is None.

Reviewers: David Jacot <djacot@confluent.io>, Artem Livshits <alivshits@confluent.io>, Jason Gustafson <jason@confluent.io>",2023-07-14 15:18:11,Justine Olshan,Mixed
9e50f7cdd37f923cfef4711cf11c1c5271a0a6c7,"MINOR: Add ZK dual-write lag metric (#14009)

This patch adds ZKWriteBehindLag metric to the KafkaController mbean as specified in KIP-866

Reviewers: David Arthur <mumrah@gmail.com>",2023-07-16 21:23:01,Hailey Ni,Mixed
cbd5d52ec7b89a5bbbbc245f5373a98d8379ab5a,"KAFKA-9564: Local Tiered Storage implementation for Remote Storage Manager (#13837)

Reviewers: Luke Chen <showuon@gmail.com>, Divij Vaidya <diviv@amazon.com>, Jorge Esteban Quilcate Otoya <quilcate.jorge@gmail.com>, Christo Lolov <lolovc@amazon.com>, Satish Duggana <satishd@apache.org>",2023-07-17 21:49:43,Kamal Chandraprakash,Mixed
fa5b493241d43c6d8809853678dcd05fb8fa518a,"KAFKA-14647: Move TopicFilter to server-common/utils (#13158)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Federico Valeri <fedevaleri@gmail.com>",2023-07-18 10:38:56,vamossagar12,Mixed
0c6b1a4e9a94cc8d7461b78e5bb0b583dc0307d7,"KAFKA-14737: Move kafka.utils.json to server-common (#13585)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Federico Valeri <fedevaleri@gmail.com>",2023-07-18 11:02:40,Omnia G H Ibrahim,Mixed
0b025b771136a8a166d5349b34297dbbbb81c393,"KAFKA-15121: Implement the alterOffsets method in the FileStreamSourceConnector and the FileStreamSinkConnector (#13945)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-07-18 10:37:51,Yash Mayya,Mixed
fd3b1137d2f12bd5c3717fc7ac5ba3d8a96fd951,"KAFKA-14953: Add tiered storage related metrics (#13944)

* KAFKA-14953: Adding RemoteLogManager metrics
In this PR, I have added the following metrics that are related to tiered storage mentioned in[ KIP-405](https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage).
|Metric|Description|
|-----------------------------------------|--------------------------------------------------------------|
| RemoteReadRequestsPerSec                    | Number of remote storage read requests per second               |
| RemoteWriteRequestsPerSec                    | Number of remote storage write requests per second              |
| RemoteBytesInPerSec                                | Number of bytes read from remote storage per second           |
| RemoteReadErrorsPerSec                          | Number of remote storage read errors per second                   |
| RemoteBytesOutPerSec                             | Number of bytes copied to remote storage per second            |
| RemoteWriteErrorsPerSec                          | Number of remote storage write errors per second                   |
| RemoteLogReaderTaskQueueSize             | Number of remote storage read tasks pending for execution.  |
| RemoteLogReaderAvgIdlePercent             | Average idle percent of the remote storage reader thread pool|
| RemoteLogManagerTasksAvgIdlePercent | Average idle percent of RemoteLogManager thread pool          |

Added unit tests for all the rate metrics.

Reviewers: Luke Chen <showuon@gmail.com>, Divij Vaidya <diviv@amazon.com>, Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Jorge Esteban Quilcate Otoya <quilcate.jorge@gmail.com>, Staniel Yao<yaolixinylx@gmail.com>, hudeqi<1217150961@qq.com>, Satish Duggana <satishd@apache.org>",2023-07-18 20:16:19,Abhijeet Kumar,Mixed
a500c3ecf9a5926681eacc778f44076dc699d853,"KAFKA-14500; [5/N] Implement JoinGroup protocol in new GroupCoordinator (#13870)

This patch implements the existing JoinGroup protocol within the new group coordinator. 

Some notable differences:
* Methods return a CoordinatorResult to the runtime framework, which includes records to append to the log as well as a future to complete after the append succeeds/fails.
* The coordinator runtime ensures that only a single thread will be processing a group at any given time, therefore there is no more locking on groups.
* Instead of using on purgatories, we rely on the Timer interface to schedule/cancel delayed operations.

Reviewers: David Jacot <djacot@confluent.io>",2023-07-19 09:15:13,Jeff Kim,Mixed
d5a00cca74decaf7b44238bb6ac57e3c9f9c7218,"KAFKA-15162: Reflectively find plugins in parent ClassLoaders that aren't on the classpath (#13977)

Signed-off-by: Greg Harris <greg.harris@aiven.io>
Reviewed-by: Chris Egerton <chris.egerton@aiven.io>",2023-07-19 12:49:25,Greg Harris,Not TDD
f6e7aa3763373407ab594ddba994d584caa5e469,"KAFKA-15150: Add ServiceLoaderScanner implementation (#13971)

Reviewers: Chris Egerton <chris.egerton@aiven.io>",2023-07-19 16:21:58,Greg Harris,Mixed
334c41d6042bac184ecaa21f230482da1f856ab2,"KAFKA-14734: Use CommandDefaultOptions in StreamsResetter (#13983)

This PR adds CommandDefaultOptions usage like in the other joptsimple based tools. It also moves the associated unit test class from streams to tools module as discussed in #13127 (comment)

Reviewers:  Luke Chen <showuon@gmail.com>, Bruno Cadonna <cadonna@apache.org>, Sagar Rao <sagarmeansocean@gmail.com>",2023-07-20 18:45:05,Federico Valeri,Mixed
e9fe2a2eeaf449cddd7770a1a7fa07bc75918c69,"KAFKA-14936: Check the versioned table's history retention and compare to grace period (4/N) (#13942)

Check the history retention of the ktable of the grace period join.

Reviewers: Reviewers: Victoria Xia <victoria.xia@confluent.io>, Bruno Cadonna <cadonna@apache.org>",2023-07-20 16:01:21,Walker Carlson,Not TDD
ea6e100ec31f6a3e0b90f2504fd5370409809d36,"KAFKA-15216: InternalSinkRecord::newRecord should not ignore new headers (#14044)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-07-20 10:22:35,Yash Mayya,Mixed
125dbb92867c11739afc54c5e546f551f70d7113,"KAFKA-14760: Move ThroughputThrottler from tools to clients, remove tools dependency from connect-runtime (#13313)

Reviewers: Ismael Juma <ismael@juma.me.uk>",2023-07-20 12:58:48,Greg Harris,Not TDD
6bb88ae2f74d89b88e1d1b6228bc3ccc1a52120f,"KAFKA-15022: [2/N] introduce graph to compute min cost (#13996)

Part of KIP-925.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-07-20 16:17:47,Hao Li,Mixed
27ea025e33aab525e96bef24840414f7a4e132f1,"KAFKA-15176: add tests for tiered storage metrics (#13999)

Added tests for metrics:
1. RemoteLogReaderTaskQueueSize
2. RemoteLogReaderAvgIdlePercent
3. RemoteLogManagerTasksAvgIdlePercent

Also, added tests for OffsetOutOfRangeException will be thrown while reading logs

Reviewers: Christo Lolov <christololov@gmail.com>, Satish Duggana <satishd@apache.org>",2023-07-21 10:30:33,Luke Chen,Not TDD
4bba2c8a32a3e35f6870cf3f738c0eef8bb652d2,"KAFKA-14591: Move DeleteRecordsCommand to tools (#13278)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Federico Valeri <fedevaleri@gmail.com>",2023-07-21 17:30:28,Nikolay,Mixed
4daeb2714c29e4a34698292dcad5a64beed72e74,"KAFKA-13431 (KIP-793): Expose the original pre-transform topic partition and offset in sink records (#14024)

Reviewers: Greg Harris <greg.harris@aiven.io>, Chris Egerton <chrise@aiven.io>",2023-07-21 12:06:01,Yash Mayya,Mixed
69659b70fca10349d8c799d29e9115bb5ced64db,"KAFKA-14499: [1/N] Introduce OffsetCommit API version 9 and add new StaleMemberEpochException error (#14046)

This patch does a few things:
1) It introduces version 9 of the OffsetCommit API. This new version has no schema changes but it can return a StaleMemberEpochException if the new consumer group protocol is used. Note the use of `""latestVersionUnstable"": true` in the request schema. This means that this new version is not available yet unless activated.
2) It renames the `generationId` field in the request to `GenerationIdOrMemberEpoch`. This is backward compatible change.
3) It introduces the new StaleMemberEpochException error.
4) It does a minor refactoring in OffsetCommitRequest class.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, David Arthur <mumrah@gmail.com>, Justine Olshan <jolshan@confluent.io>",2023-07-21 20:08:06,David Jacot,Mixed
2528dd41169a95f05117ba01302c5dcce0642ab1,"KAFKA-14499: [2/N] Add OffsetCommit record & related (#14047)

This patch does a few things:
1) It introduces the `OffsetAndMetadata` class which hold the committed offsets in the group coordinator.
2) It adds methods to deal with OffsetCommit records to `RecordHelpers`.
3) It adds `MetadataVersion#offsetCommitValueVersion` to get the version of the OffsetCommit value record that should be used.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, David Arthur <mumrah@gmail.com>, Justine Olshan <jolshan@confluent.io>",2023-07-21 20:09:06,David Jacot,Mixed
1656591d0b339c385d0ba1f938fc94b52e29965d,"KAFKA-14950: implement assign() and assignment() (#13797)

We will explicitly send an assignment change event to the background thread to invoke auto-commit if the group.id is configured. After updating the subscription state, a NewTopicsMetadataUpdateRequestEvent will also be sent to the background thread to update the metadata.

Co-authored-by: Kirk True <kirk@kirktrue.pro>
Reviewers: Jun Rao <junrao@gmail.com>",2023-07-21 13:59:00,Philip Nee,Mixed
cc4e699d4cb2880d05603e2e8310d28e1c9f201a,"MINOR: Minor logging and doc related improvements in topic-based RLMM consumer-manager/task (#14045)

Improved logging and docs on consumer manager/task call paths.

Reviewers: Luke Chen <showuon@gmail.com>, Satish Duggana <satishd@apache.org>",2023-07-22 10:03:35,Jorge Esteban Quilcate Otoya,Mixed
a3204aed2eb6f2fe7d9f300cca686d3bc2a37c7c,"KAFKA-15194: Prepend offset in the filenames used by LocalTieredStorage (#14057)

Reviewers: Divij Vaidya <diviv@amazon.com>",2023-07-22 13:47:26,Owen Leung,Mixed
4981fa939d588645401619bfc3e321dc523d10e7,"KAFKA-14712: Produce correct error msg with correct metadataversion (#13773)

Fix the confusing error message in ImageWriterOptions

Reviewers: Luke Chen <showuon@gmail.com>, David Arthur <mumrah@gmail.com>",2023-07-24 10:37:23,Owen Leung,Mixed
84691b11f64e85a7f3f6fdbafd0f8fb2f8dd630c,"KAFKA-15168: Handle overlapping remote log segments in RemoteLogMetadata cache (#14004)

KAFKA-15168: Handle overlapping remote log segments in RemoteLogMetadata cache

Reviewers: Satish Duggana <satishd@apache.org>, Viktor Nikitash <nikitashvictor@pdffiller.com>, Jorge Esteban Quilcate Otoya <quilcate.jorge@gmail.com>, Abhijeet Kumar <abhijeet.cse.kgp@gmail.com>",2023-07-24 19:36:25,Kamal Chandraprakash,Mixed
38781f9aea2070775ca353f37510effa0e7963ba,"KAFKA-14920: Address timeouts and out of order sequences (#14033)

When creating a verification state entry, we also store sequence and epoch. On subsequent requests, we will take the latest epoch seen and the earliest sequence seen. That way, if we try to append a sequence after the earliest seen sequence, we can block that and retry. This addresses potential OutOfOrderSequence loops caused by errors during verification (coordinator loading, timeouts, etc).

Reviewers:  David Jacot <david.jacot@gmail.com>,  Artem Livshits <alivshits@confluent.io>",2023-07-24 13:08:57,Justine Olshan,Mixed
79b8c969e5371073e04488e0f3490abaca2b4584,"KAFKA-14990: Dynamic producer ID expiration should be applied on a broker restart (#13707)

Dynamic overrides for the producer ID expiration config are not picked up on broker restart in Zookeeper mode. Based on the integration test, this does not apply to KRaft mode.

Adds a broker restart that fails without the corresponding KafkaConfig change.

Reviewers: Justine Olshan <jolshan@confluent.io>",2023-07-24 13:22:25,David Mao,Not TDD
c7de30f38bfd6e2d62a0b5c09b5dc9707e58096b,"KAFKA-15183: Add more controller, loader, snapshot emitter metrics (#14010)

Implement some of the metrics from KIP-938: Add more metrics for
measuring KRaft performance.

Add these metrics to QuorumControllerMetrics:
    kafka.controller:type=KafkaController,name=TimedOutBrokerHeartbeatCount
    kafka.controller:type=KafkaController,name=EventQueueOperationsStartedCount
    kafka.controller:type=KafkaController,name=EventQueueOperationsTimedOutCount
    kafka.controller:type=KafkaController,name=NewActiveControllersCount

Create LoaderMetrics with these new metrics:
    kafka.server:type=MetadataLoader,name=CurrentMetadataVersion
    kafka.server:type=MetadataLoader,name=HandleLoadSnapshotCount

Create SnapshotEmitterMetrics with these new metrics:
    kafka.server:type=SnapshotEmitter,name=LatestSnapshotGeneratedBytes
    kafka.server:type=SnapshotEmitter,name=LatestSnapshotGeneratedAgeMs

Reviewers: Ron Dagostino <rndgstn@gmail.com>",2023-07-24 21:13:58,Colin Patrick McCabe,Mixed
08b3820d5e3994e137fa5ab917adc37a30910144,"KAFKA-15238: Move DLQ reporter setup from the DistributedHerder's tick thread to the sink task thread (#14079)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-07-25 09:03:29,Yash Mayya,Mixed
e794bc719a371f457e03e2b4c54638f37ea26092,"MINOR: Add a Builder for KRaftMigrationDriver (#14062)

Reviewers: Justine Olshan <jolshan@confluent.io>",2023-07-25 16:05:04,David Arthur,Mixed
46a8a2877b18600abb608da5afcb3bef13e882f0,"KAFKA-15218: Avoid NPE thrown while deleting topic and fetch from follower concurrently (#14051)

When deleting topics, we'll first clear all the remoteReplicaMap when stopPartitions here. But this time, there might be fetch request coming from follower, and try to check if the replica is eligible to be added into ISR here. At this moment, NPE will be thrown. Although it's fine since this topic is already deleted, it'd be better to avoid it happen.

Reviewers: Luke Chen <showuon@gmail.com>",2023-07-26 09:51:23,vamossagar12,Mixed
bb677c4959e18efbb3dae0b4bde123fca7c9ba33,"KAFKA-14583: Move ReplicaVerificationTool to tools (#14059)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2023-07-26 12:04:34,Federico Valeri,Mixed
6d81698ba4cb9c62185b0a50cc81ddea3047994d,"KAFKA-15243: Set decoded user names to DescribeUserScramCredentialsResponse (#14094)


Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2023-07-26 19:18:09,sciclon2,Not TDD
a900794ace4dcf1f9dadee27fbd8b63979532a18,"KAFKA-15196 Additional ZK migration metrics (#14028)

This patch adds several metrics defined in KIP-866:

* MigratingZkBrokerCount: the number of zk brokers registered with KRaft
* ZkWriteDeltaTimeMs: time spent writing MetadataDelta to ZK
* ZkWriteSnapshotTimeMs: time spent writing MetadataImage to ZK
* Adds value 4 for ""ZK"" to ZkMigrationState

Also fixes a typo in the metric name introduced in #14009 (ZKWriteBehindLag -> ZkWriteBehindLag)

Reviewers: Luke Chen <showuon@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",2023-07-26 12:54:59,David Arthur,Mixed
ed44bcd71b3b9926c474033882eaa6c1cf35cfa4,"KAFKA-15022: [3/N] use graph to compute rack aware assignment for active stateful tasks (#14030)

Part of KIP-925.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-07-26 16:02:52,Hao Li,Mixed
d2fc9076231261db947168776505f0c21418a25f,"KAFKA-14500; [6/6] Implement SyncGroup protocol in new GroupCoordinator (#14017)

This patch implements the SyncGroup API in the new group coordinator. All the new unit tests are based on the existing scala tests.

Reviewers: David Jacot <djacot@confluent.io>",2023-07-27 08:02:29,Jeff Kim,Mixed
29825ee24f91e17a6193de0755bec668821e94a3,"KAFKA-14499: [3/N] Implement OffsetCommit API (#14067)

This patch introduces the `OffsetMetadataManager` and implements the `OffsetCommit` API for both the old rebalance protocol and the new rebalance protocol. It introduces version 9 of the API but keeps it as unstable for now. The patch adds unit tests to test the API. Integration tests will be done separately.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-07-27 13:18:10,David Jacot,Mixed
6f39ef02ca1cec70067752bfde57537952e5bb42,"MINOR: Adjust Invalid Record Exception for Invalid Txn State as mentioned in KIP-890 (#14088)

Invalid record is a newer error. INVALID_TXN_STATE has been around as long as transactions and is not retriable. This is the desired behavior.",2023-07-27 09:36:32,Justine Olshan,Mixed
e5861eeaae0fabca28e7a512ebc487438eab2bad,"[MINOR] Add latest versions to kraft upgrade kafkatest (#14084)

Reviewers: Ron Dagostino <rndgstn@gmail.com>",2023-07-27 16:12:25,Alyssa Huang,Not TDD
10bcd4fc7f7258c20d5b0cdedf91ebb54697f97a,"KAFKA-15213: provide the exact offset to QuorumController.replay (#13643)

Provide the exact record offset to QuorumController.replay() in all cases. There are several situations
where this is useful, such as logging, implementing metadata transactions, or handling broker
registration records.

In the case where the QC is inactive, and simply replaying records, it is easy to compute the exact
record offset from the batch base offset and the record index.

The active QC case is more difficult. Technically, when we submit records to the Raft layer, it can
choose a batch base offset later than the one we expect, if someone else is also adding records.
While the QC is the only entity submitting data records, control records may be added at any time.
In the current implementation, these are really only used for leadership elections. However, this
could change with the addition of quorum reconfiguration or similar features.

Therefore, this PR allows the QC to tell the Raft layer that a record append should fail if it
would have resulted in a batch base offset other than what was expected. This in turn will trigger a
controller failover. In the future, if automatically added control records become more common, we
may wish to have a more sophisticated system than this simple optimistic concurrency mechanism. But
for now, this will allow us to rely on the offset as correct.

In order that the active QC can learn what offset to start writing at, the PR also adds a new
RaftClient#endOffset function.

At the Raft level, this PR adds a new exception, UnexpectedBaseOffsetException. This gets thrown
when we request a base offset that doesn't match the one the Raft layer would have given us.
Although this exception should cause a failover, it should not be considered a fault. This
complicated the exception handling a bit and motivated splitting more of it out into the new
EventHandlerExceptionInfo class. This will also let us unit test things like slf4j log messages a
bit better.

Reviewers: David Arthur <mumrah@gmail.com>, José Armando García Sancio <jsancio@apache.org>",2023-07-27 17:01:55,Colin Patrick McCabe,Mixed
722b259961c39da83db254eea54c7b87249ab1ad,"KAFKA-14038: Optimise calculation of size for log in remote tier (#14049)

Reviewers: Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Divij Vaidya <diviv@amazon.com>, Luke Chen <showuon@gmail.com>, Satish Duggana <satishd@apache.org>",2023-07-28 11:10:37,Christo Lolov,Mixed
19f9e1e6d0853646b68b08080f8afc5ef0038110,"KAFKA-14501: Implement Heartbeat protocol in new GroupCoordinator (#14056)

This patch implements the existing Heartbeat API in the new Group Coordinator.

Reviewers: David Jacot <djacot@confluent.io>",2023-07-28 15:13:27,Jeff Kim,Mixed
811ae01723e938a7b97ed6de0ace78709472cc9e,"MINOR: Test assign() and assignment() in the integration test (#14086)

A missing piece from KAFKA-14950. This is to test assign() and assignment() in the integration test.

Also fixed an accidental mistake in the committed API.

Reviewers: Jun Rao <junrao@gmail.com>",2023-07-28 09:11:20,Philip Nee,Not TDD
32c39c8149bca18d852b7139a8caffb141dc8840,"KAFKA-15263 Check KRaftMigrationDriver state in each event (#14115)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-07-28 13:02:47,David Arthur,Mixed
3709901c9ee0f61277b122a4863fea46f039335f,"KAFKA-14702: Extend server side assignor to support rack aware replica placement (#14099)

This patch updates the `PartitionAssignor` interface to support rack-awareness. The change introduces the `SubscribedTopicDescriber` interface that can be used to retrieve topic metadata such as the number of partitions or the racks from within an assignor. We use an interface because it allows us to wrap internal data structures instead of having to copy them. It is more efficient.

Reviewers: David Jacot <djacot@confluent.io>",2023-07-28 19:30:04,Ritika Reddy,Mixed
1574b9f16df83c6a392502a9134d4b04647511cf,"MINOR: Code cleanups in group-coordinator module (#14117)

This patch does a few code cleanups in the group-coordinator module.

It renames Coordinator to CoordinatorShard;
It renames ReplicatedGroupCoordinator to GroupCoordinatorShard. I was never really happy with this name. The new name makes more sense to me;
It removes TopicPartition from the GroupMetadataManager. It was only used in log messages. The log context already includes it so we don't have to log it again.
It renames assignors to consumerGroupAssignors.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-07-28 11:28:54,David Jacot,Mixed
b9a45546a7918799b6fb3c0fe63b56f47d8fcba9,"KAFKA-15244: Remove PluginType.from(Class) (#14089)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-08-01 10:05:46,Greg Harris,Mixed
0ce16406e0abbc5d27a0be064f64da74b2e404c5,"KAFKA-15022: [4/N] use client tag assignor for rack aware standby task assignment (#14097)

Part of KIP-925.

For rack aware standby task assignment, we can either use the already existing ""rack tags"" or as a fall-back the newly added ""rack.id"". This PR unifies both without the need to change the actual standby task assignment logic.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-08-01 17:33:24,Hao Li,Mixed
ffe5f9fbefcba0b2fe8808546e6fd0d02492f75f,"KAFKA-15272: Fix the logic which finds candidate log segments to upload it to tiered storage (#14128)

In tiered storage, a segment is eligible for deletion from local disk when it gets uploaded to the remote storage.

If the topic active segment contains some messages and there are no new incoming messages, then the active segment gets rotated to passive segment after the configured log.roll.ms timeout.

The logic to find the candidate segment in RemoteLogManager does not include the recently rotated passive segment as eligible to upload it to remote storage so the passive segment won't be removed even after if it breaches by retention time/size. (ie) Topic won't be empty after it becomes stale.

Added unit test to cover the scenario which will fail without this patch.

Reviewers: Christo Lolov <lolovc@amazon.com>, Luke Chen <showuon@gmail.com>, Satish Duggana <satishd@apache.org>",2023-08-02 12:05:40,Kamal Chandraprakash,Mixed
8aaf7daff393f2b26438fb7fe28016e06e23558c,"KAFKA-15236: Rename tiered storage metrics (#14074)

Rename tiered storage metrics

Reviewers: Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Divij Vaidya <diviv@amazon.com>, Luke Chen <showuon@gmail.com>, Satish Duggana <satishd@apache.org>",2023-08-02 14:57:25,Abhijeet Kumar,Mixed
bb48b157af6ca06972927666a5b6f84b9551fe3a,"KAFKA-15022: [5/N] compute rack aware assignment for standby tasks (#14108)

Part of KIP-925.

Reviewer: Matthias J. Sax <matthias@confluent.io>",2023-08-02 19:20:23,Hao Li,Mixed
d89b26ff443c8dd5d584ad0a979ac3944366cc06,"KAFKA-12969: Add broker level config synonyms for topic level tiered storage configs (#14114)

KAFKA-12969: Add broker level config synonyms for topic level tiered storage configs.

Topic -> Broker Synonym:
local.retention.bytes -> log.local.retention.bytes
local.retention.ms -> log.local.retention.ms

We cannot add synonym for `remote.storage.enable` topic property as it depends on KIP-950

Reviewers: Divij Vaidya <diviv@amazon.com>, Satish Duggana <satishd@apache.org>, Luke Chen <showuon@gmail.com>",2023-08-03 13:56:00,Kamal Chandraprakash,Mixed
b9936d6292f3d7e76260b91e96520f94d5bc9bd7,"KAFKA-7438: Replace PowerMockRunner with MockitoJUnitRunner in RetryUtilTest (#14143)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-08-03 13:07:35,Yash Mayya,Mixed
e0b7499103df9222140cdbf7047494d92913987e,"KAFKA-15106: Fix AbstractStickyAssignor isBalanced predict (#13920)

in 3.5.0 AbstractStickyAssignor may run useless loop in performReassignments  because isBalanced have a trivial mistake, and result in rebalance timeout in some situation.

Co-authored-by: lixy <lixy@tuya.com>
Reviewers: Ritika Reddy <rreddy@confluent.io>, Philip Nee <pnee@confluent.io>, Kirk True <kirk@mustardgrain.com>, Guozhang Wang <wangguoz@gmail.com>",2023-08-03 11:17:08,flashmouse,Mixed
7782741262c08e5735f7c8e09727ec37cb5f7f02,"KAFKA-10199: Change to RUNNING if no pending task to recycle exist (#14145)

A stream thread should only change to RUNNING if there are no
active tasks in restoration in the state updater and if there
are no pending tasks to recycle.

There are situations in which a stream thread might only have
standby tasks that are recycled to active task after a rebalance.
In such situations, the stream thread might be faster in checking
active tasks in restoration then the state updater removing the
standby task to recycle from the state updater. If that happens
the stream thread changes to RUNNING although it should wait until
the standby tasks are recycled to active tasks and restored.

Reviewers: Walker Carlson <wcarlson@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2023-08-04 09:07:58,Bruno Cadonna,Mixed
b3db905b27ff4133f4018ac922c9ce2beb2d6087,"KAFKA-15107: Support custom metadata for remote log segment (#13984)

* KAFKA-15107: Support custom metadata for remote log segment

This commit does the changes discussed in the KIP-917. Mainly, changes the `RemoteStorageManager` interface in order to return `CustomMetadata` and then ensures these custom metadata are stored, propagated, (de-)serialized correctly along with the standard metadata throughout the whole lifecycle. It introduces the `remote.log.metadata.custom.metadata.max.size` to limit the custom metadata size acceptable by the broker and stop uploading in case a piece of metadata exceeds this limit.

On testing:
1. `RemoteLogManagerTest` checks the case when a piece of custom metadata is larger than the configured limit.
2. `RemoteLogSegmentMetadataTest` checks if `createWithUpdates` works correctly, including custom metadata.
3. `RemoteLogSegmentMetadataTransformTest`, `RemoteLogSegmentMetadataSnapshotTransformTest`, and `RemoteLogSegmentMetadataUpdateTransformTest` were added to test the corresponding class (de-)serialization, including custom metadata.
4. `FileBasedRemoteLogMetadataCacheTest` checks if custom metadata are being correctly saved and loaded to a file (indirectly, via `equals`).
5. `RemoteLogManagerConfigTest` checks if the configuration setting is handled correctly.

Reviewers: Luke Chen <showuon@gmail.com>, Satish Duggana <satishd@apache.org>, Divij Vaidya <diviv@amazon.com>",2023-08-04 18:23:25,Ivan Yurchenko,Mixed
748175ce62ea68d2a99ff9f96c7e349e1d0e1b96,"KAFKA-15189: only init remote topic metrics when enabled (#14133)

Only initialize remote topic metrics when system-wise remote storage is enabled to avoid impacting performance for existing brokers. Also add tests.

Reviewers: Divij Vaidya <diviv@amazon.com>, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>",2023-08-05 13:00:16,Luke Chen,Mixed
8dec3e66163420ee0c2c259eef6e0c0f3185ca17,"KAFKA-15022: [6/N] add rack aware assignor configs and update standby optimizer (#14150)

Part of KIP-925.

- Add configs for rack aware assignor
- Update standby optimizer in RackAwareTaskAssignor to have more rounds
- Refactor some method in RackAwareTaskAssignorTest to test utils so that they can also be used in HighAvailabilityTaskAssignorTest and other tests

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-08-07 11:21:55,Hao Li,Mixed
1c04ae8e614533ebca7768c2f929b424213bf09f,"MINOR: Improve JavaDocs of KafkaStreams `context.commit()` (#14163)

Reviewers: Bill Bejeck <bill@confluent.io>",2023-08-08 07:51:59,Matthias J. Sax,Not TDD
60a51170014622f65a22675ac54ec78058299fda,"KAFKA-15022: [7/N] use RackAwareTaskAssignor in HAAssignor (#14139)

Part of KIP-915.

- Change TaskAssignor interface to take RackAwareTaskAssignor
- Integrate RackAwareTaskAssignor to StreamsPartitionAssignor and HighAvailabilityTaskAssignor
- Update HAAssignor tests

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Matthias J. Sax <matthias@confluent.io>",2023-08-08 08:01:05,Hao Li,Mixed
ff4fed5cbe01480f671cc5070fac97d16ca0a5ba,"KAFKA-15031: Add plugin.discovery to Connect worker configuration (KIP-898) (#14055)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-08-08 10:06:35,Greg Harris,Mixed
a1cb4b4025c8bca7c164d9a63fad79455a6aef75,"add changes made before merge (#14137)

Change in response to KIP-941.

New PR due to merge issue.

Changes line 57 in the RangeQuery class file from:

public static <K, V> RangeQuery<K, V> withRange(final K lower, final K upper) {
    return new RangeQuery<>(Optional.of(lower), Optional.of(upper));
}
to

public static <K, V> RangeQuery<K, V> withRange(final K lower, final K upper) {
     return new RangeQuery<>(Optional.ofNullable(lower), Optional.ofNullable(upper));
 }
Testing strategy:

Since null values can now be entered in RangeQuerys in order to receive full scans, I changed the logic defining query starting at line 1085 in IQv2StoreIntegrationTest.java from:

        final RangeQuery<Integer, V> query;
        if (lower.isPresent() && upper.isPresent()) {
            query = RangeQuery.withRange(lower.get(), upper.get());
        } else if (lower.isPresent()) {
            query = RangeQuery.withLowerBound(lower.get());
        } else if (upper.isPresent()) {
            query = RangeQuery.withUpperBound(upper.get());
        } else {
            query = RangeQuery.withNoBounds();
        }
to

query = RangeQuery.withRange(lower.orElse(null), upper.orElse(null));
because different combinations of isPresent() in the bounds is no longer necessary.

Reviewers: John Roesler <vvcephei@apache.org>, Bill Bejeck <bbejeck@apache.org>",2023-08-08 15:03:42,Lucia Cerchie,Not TDD
9bc4a2d4d1e9b4ce0f322ec6c604c7b7ac7c7d26,"KAFKA-15271: Historicalterator can exposes elements that are too new (#14125)

A HistoricalIterator at epoch N is supposed to only reveal elements at epoch N or earlier. However,
due to a bug, we sometimes will reveal elements which are at a newer epoch than N. The bug does
not affect elements that are in the latest epoch (aka topTier). It only affects elements that are
newer than N, but which do not persist until the latest epoch.  This PR fixes the bug and adds a
unit test for this case.

Reviewers: David Arthur <mumrah@gmail.com>",2023-08-08 16:36:59,Colin Patrick McCabe,Mixed
ddeb89f4a9f31b5ff63661e18a94c403a8f45f69,"KAFKA-14595: Move AdminUtils to server-common (#14096)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2023-08-09 10:32:45,Nikolay,Mixed
dafe51b65885c476d3e06d5cad7cb553392cce42,"KAFKA-15100; KRaft data race with the expiration service (#14141)

The KRaft client uses an expiration service to complete FETCH requests that have timed out. This expiration service uses a different thread from the KRaft polling thread. This means that it is unsafe for the expiration service thread to call tryCompleteFetchRequest. tryCompleteFetchRequest reads and updates a lot of states that is assumed to be only be read and updated from the polling thread.

The KRaft client now does not call tryCompleteFetchRequest when the FETCH request has expired. It instead will send the FETCH response that was computed when the FETCH request was first handled.

This change also fixes a bug where the KRaft client was not sending the FETCH response immediately, if the response contained a diverging epoch or snapshot id.

Reviewers: Jason Gustafson <jason@confluent.io>",2023-08-09 07:12:08,José Armando García Sancio,Mixed
87308167b19f6ffee76a144376cea540be028f0a,"KAFKA-15022: [8/N] more tests for HAAssignor (#14164)

Part of KIP-925.

- Add more tests for HighAvailabilityTaskAssignor
- Remove null and optional check for RackAwareTaskAssignor
- Pass rack aware assignor configs to getMainConsumerConfigs so that they can be picked up in rebalance protocol
- Change STATELESS_NON_OVERLAP_COST to 0. It was a mistake to be 1. Stateless tasks should be moved without this cost.
- Update of existing tests

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-08-09 16:42:53,Hao Li,Mixed
96631c25d5feb0d946dace56ddcd02515cc5e3a0,"KAFKA-15022: [9/N] use RackAwareTaskAssignor in StickyTaskAssignor (#14178)

Part of KIP-925.

Use rack aware assignor in StickyTaskAssignor.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-08-09 19:50:43,Hao Li,Mixed
393b563bb5bfc5c8e4f9505f604a1963248f710a,"KAFKA-15288: Change BrokerApiVersionsCommandTest to support kraft mode (#14175)

Use ApiKeys.clientApis() to replace ApiKeys.zkBrokerApis() to support kraft mode.

Reviewers: dengziming <dengziming1993@gmail.com>",2023-08-10 14:26:37,vveicc,Mixed
9318b591d7a57b9db1e7519986d78f0402cd5b5e,"KAFKA-15318: Update the Authorizer via AclPublisher (#14169)

On the controller, move publishing acls to the Authorizer into a dedicated MetadataPublisher,
AclPublisher. This publisher listens for notifications from MetadataLoader, and receives only
committed data. This brings the controller side in line with how the broker has always worked. It
also avoids some ugly code related to publishing directly from the QuorumController. Most important
of all, it clears the way to implement metadata transactions without worrying about Authorizer
state (since it will be handled by the MetadataLoader, along with other metadata image state).

In AclsDelta, we can remove isSnapshotDelta. We always know when the MetadataLoader is giving us a
snapshot. Also bring AclsDelta in line with the other delta classes, where completeSnapshot
calculates the diff between the previous image and the next one. We don't use this delta (since we
just apply the image directly to the authorizer) but we should have it, for consistency.

Finally, change MockAclMutator to avoid the need to subclass AclControlManager.

Reviewers: David Arthur <mumrah@gmail.com>",2023-08-09 23:54:46,Colin Patrick McCabe,Mixed
db34f8b9a1430e440f3a40fc863d2fd70e549bb2,"KAFKA-15291: Connect plugins should declare a version (#14159)

Signed-off-by: Aindriu Lavelle <aindriu.lavelle@aiven.io>
Reviewers: Andrew Schofield, Greg Harris <greg.harris@aiven.io>",2023-08-10 10:45:12,aindriu-aiven,Mixed
b35ee39edafc9f102c455ce82301cf38b0db166c,"KAFKA-15220: Do not returned fenced brokers from getAliveBrokerNode (#14050)

getAliveBrokerNode returns fenced brokers as alive which is inconsistent with methods like
getAliveBrokerNodes. Add a filter to not return fenced brokers and adds a test to validate that
the two functions are consistent.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-08-10 11:06:12,David Mao,Mixed
0ee26640e59958fa547a25af5b03ab1acbae2f93,"KAFKA-15202: Fix MM2 offset translation when syncs are variably spaced (#14156)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-08-10 13:25:50,Greg Harris,Mixed
f2ebd333e880e0099360116299551b8a8142a68b,"KAFKA-13187: Replace EasyMock / PowerMock with Mockito in DistributedHerderTest (#14102)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-08-10 16:47:30,Yash Mayya,Mixed
594156e01bb59aab4d6dcbcb62679df9d83f8849,"KAFKA-15287: Change NodeApiVersions.create() to support both zk and kraft (#14185)

Reviewers: dengziming <dengziming1993@gmail.com>",2023-08-11 10:18:13,vveicc,Not TDD
cdbc9a8d88c1ddc9dd088a33d047783a5b13c282,"KAFKA-15083: add config with ""remote.log.metadata"" prefix (#14151)

When configuring RLMM, the configs passed into configure method is the RemoteLogManagerConfig. But in RemoteLogManagerConfig, there's no configs related to remote.log.metadata.*, ex: remote.log.metadata.topic.replication.factor. So, even if users have set the config in broker, it'll never be applied.

This PR fixed the issue to allow users setting RLMM prefix: remote.log.metadata.manager.impl.prefix (default is rlmm.config.), and then, appending the desired remote.log.metadata.* configs, it'll pass into RLMM, including remote.log.metadata.common.client./remote.log.metadata.producer./ remote.log.metadata.consumer. prefixes.

Ex:

# default value
# remote.log.storage.manager.impl.prefix=rsm.config.
# remote.log.metadata.manager.impl.prefix=rlmm.config.

rlmm.config.remote.log.metadata.topic.num.partitions=50
rlmm.config.remote.log.metadata.topic.replication.factor=4

rsm.config.test=value

Reviewers: Christo Lolov <christololov@gmail.com>, Kamal Chandraprakash <kchandraprakash@uber.com>, Divij Vaidya <diviv@amazon.com>",2023-08-11 10:42:14,Luke Chen,Mixed
f137da04fa71734d176e19f5800622f4b4dfdb66,"KAFKA-14132: Replace Easymock & Powermock with Mockito in KafkaBasedLogTest (#14153)

Reviewers: Yash Mayya <yash.mayya@gmail.com>, Divij Vaidya <diviv@amazon.com>",2023-08-11 10:50:37,bachmanity1,Mixed
4268e502ec403a049c6a01be93195236fddbaad7,"KAFKA-15022: [10/N] docs for rack aware assignor (#14181)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-08-11 11:40:33,Hao Li,Mixed
f5655d31d3d527dae057240570162827c6a79fb2,"KAFKA-15030: Add connect-plugin-path command-line tool (#14064)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-08-11 12:05:51,Greg Harris,Mixed
f6b8b39747112bd8f3418893af760d42a1635648,"MINOR: Fix committed API in the PrototypeAsyncConsumer timeout (#14123)

Discovered the committed() API timeout during the integration test. After investigation, this is because the future was not completed in the ApplicationEventProcessor. Also added toString methods to the event class for debug purposes.

Reviewers: Jun Rao <junrao@gmail.com>",2023-08-11 13:15:30,Philip Nee,Mixed
cfb45b000140729aabc34953a80bc8dc4c9a08d3,"MINOR: Refactor TierStateMachine related tests into a separate test file (#13503)

This PR builds off of KAFKA-14685 and refactors any tests explicitly related to ReplicaFetcherTierStateMachine into a separate testing file ReplicaFetcherTierStateMachineTest.

Reviewers: Jun Rao <junrao@gmail.com>",2023-08-11 14:15:17,Rittika Adhikari,Not TDD
43751d8d0521b1440a823a9430fdb0659ce7c436,"KAFKA-15289: Support KRaft mode in RequestQuotaTest (#14201)

Enable kraft mode for RequestQuotaTest, there are 2 works left to be done.

Reviewers: dengziming <dengziming1993@gmail.com>",2023-08-14 17:04:15,vveicc,Not TDD
5234ddff5025501be2b4fca3ecba4e4eb584bbc5,"KAFKA-15326: [5/N] Processing thread punctuation (#14001)

Implements punctuation inside processing threads. The scheduler
algorithm checks if a task that is not assigned currently can
be punctuated, and returns it when a worker thread asks for the
next task to be processed. Then, the processing thread runs all
punctuations in the punctionation queue.

Piggy-backed: take TaskExecutionMetadata into account when
processing records.

Reviewer: Bruno Cadonna <cadonna@apache.org>",2023-08-14 17:17:28,Lucas Brutschy,Mixed
67b527460e155f1f5e850bb7fd65c7c373367b48,"KAFKA-14937: Refactoring for client code to reduce boilerplate (#13990)

Move common code from the client implementations to the ClientUtils
class or (consumer) Utils class, where passible.

There are a number of places in the client code where the same basic
calls are made by more than one client implementation. Minor
refactoring will reduce the amount of boilerplate code necessary for
the client to construct its internal state.


Reviewers: Lianet Magrans <lianetmr@gmail.com>, Jun Rao <junrao@gmail.com>",2023-08-14 10:08:20,Kirk True,Mixed
5a67b080c7d7814c38a83a25ab951e65743fae81,"MINOR: Fix a race when query isUnderMinIsr (#14138)

When the leader becomes the follower, we first remove the ISR and then reset the leader. If we call isUnderMinIsr in between, we will get an answer with true which is a race bug.

Reviewers: Justine Olshan <jolshan@confluent.io>",2023-08-14 16:14:29,Calvin Liu,Mixed
adc16d0f310dc1350bca66d5da013d599b990cfa,"KAFKA-14538: Implement KRaft metadata transactions in QuorumController

Implement the QuorumController side of KRaft metadata transactions.

As specified in KIP-868, this PR creates a new metadata version, IBP_3_6_IV1, which contains the
three new records: AbortTransactionRecord, BeginTransactionRecord, EndTransactionRecord.

In order to make offset management unit-testable, this PR moves it out of QuorumController.java and
into OffsetControlManager.java. The general approach here is to track the ""last stable offset,"" which is
calculated by looking at the latest committed offset and the in-progress transaction (if any). When
a transaction is aborted, we revert back to this last stable offset. We also revert back to it when
the controller is transitioning from active to inactive.

In a follow-up PR, we will add support for the transaction records in MetadataLoader. We will also
add support for automatically aborting pending transactions after a controller failover.

Reviewers: David Arthur <mumrah@gmail.com>",2023-08-14 16:58:56,Colin Patrick McCabe,Mixed
696a56dd2ba54beed41748ef8cce958dadd6b375,"KAFKA-15295: Add config validation when remote storage is enabled on a topic (#14176)

Add config validation which verifies that system level remote storage is enabled when enabling remote storage for a topic. In case verification fails, it throws InvalidConfigurationException.

Reviewers: Christo Lolov <lolovc@amazon.com>, Divij Vaidya <diviv@amazon.com>,  Luke Chen <showuon@gmail.com>",2023-08-15 20:43:11,Kamal Chandraprakash,Mixed
c199840f0add1c191c4333dc58baae49594734a8,"MINOR: Fix the ZkMigrationState metric in KafkaController

This patch fixes an issue for ZK controllers where we were emitting the ZkMigrationState enum
rather than a value. This can lead to downstream failures with JMX metrics since the RMI protocol
will marshal the ZkMigrationState object returned by the gauge. Any downstream consumer of this
metric (like jconsole or a metrics exporter) will not be able to unmarshal the value since the
ZkMigrationState class will not be present.

The fix is simply to emit the byte value of this enum.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Alok Thatikunta <athatikunta@confluent.io>",2023-08-15 12:29:59,David Arthur,Not TDD
b97e8203eb1fb016cd7cccd3dbf5fecc716969be,"MINOR: CommitRequestManager should only poll when the coordinator node is known (#14179)

As title, we discovered a flaky bug during testing that the commit request manager would seldomly throw a NOT_COORDINATOR exception, which means the request was routed to a non-coordinator node. We discovered that if we don't check the coordinator node in the commitRequestManager, the request manager will pass on an empty node to the NetworkClientDelegate, which implies the request can be sent to any node in the cluster. This behavior is incorrect as the commit requests need to be routed to a coordinator node.

Because the timing coordinator's discovery during integration testing isn't entirely deterministic; therefore, the test became extremely flaky. After fixing this: The coordinator node is mandatory before attempt to enqueue these commit request to the NetworkClient.

Reviewers: Jun Rao <junrao@gmail.com>",2023-08-15 15:01:28,Philip Nee,Mixed
35e925f3535e7774520317310505fcde946228d5,"KAFKA-15102: Add replication.policy.internal.topic.separator.enabled property to MirrorMaker 2 (KIP-949) (#14082)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-08-15 19:58:52,Omnia G.H Ibrahim,Mixed
ee27773549646602b955343dba680efaa5227286,"KAFKA-15329: Make default remote.log.metadata.manager.class.name as topic based RLMM (#14202)

As described in the KIP here the default value of remote.log.metadata.manager.class.name should be TopicBasedRemoteLogMetadataManager

Reviewers: Luke Chen <showuon@gmail.com>, Kamal Chandraprakash <kchandraprakash@uber.com>, Divij Vaidya <diviv@amazon.com>",2023-08-16 09:46:17,vamossagar12,Mixed
a9efca0bf63110d68f84fc9841d8a31f245e10e0,"KAFKA-14759: Move Mock, Schema, and Verifiable connectors to new test-plugins module (#13302)

Reviewers: Hector Geraldino <hgeraldino@gmail.com>, Chris Egerton <chrise@aiven.io>",2023-08-16 10:30:24,Greg Harris,Mixed
6bd17419b76f8cf8d7e4a11c071494dfaa72cd50,"KAFKA-15228: Add sync-manifests command to connect-plugin-path (KIP-898) (#14195)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-08-16 11:37:33,Greg Harris,Mixed
de409b389d26f7681fba8583db2b96584258aa48,"KAFKA-15177: Implement KIP-875 SourceConnector::alterOffset API in MirrorMaker 2 connectors (#14005)

Reviewers: Yash Mayya <yash.mayya@gmail.com>, Greg Harris <greg.harris@aiven.io>",2023-08-17 09:33:59,Chris Egerton,Mixed
7802c264c96ae27167cf38c263b86398aa0ea3fe,"MINOR: Allow writing tombstone offsets for arbitrary partitions in the FileStreamSourceConnector (#14234)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-08-17 14:13:53,Yash Mayya,Mixed
3f4816dd3eafaf1a0636d3ee689069f897c99e28,"KAFKA-15345; KRaft leader notifies leadership when listener reaches epoch start (#14213)

In a non-empty log the KRaft leader only notifies the listener of leadership when it has read to the leader's epoch start offset. This guarantees that the leader epoch has been committed and that the listener has read all committed offsets/records.

Unfortunately, the KRaft leader doesn't do this when the log is empty. When the log is empty the listener is notified immediately when it has become leader. This makes the API inconsistent and harder to program against.

This change fixes that by having the KRaft leader wait for the listener's nextOffset to be greater than the leader's epochStartOffset before calling handleLeaderChange.

The RecordsBatchReader implementation is also changed to include control records. This makes it possible for the state machine learn about committed control records. This additional information can be used to compute the committed offset or for counting those bytes when determining when to snapshot the partition.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Jason Gustafson <jason@confluent.io>",2023-08-17 18:40:17,José Armando García Sancio,Mixed
4f88fb28f38f3e461377bf688520b28a3f209b5d,"KAFKA-15130: Delete remote segments when deleting a topic (#13947)

* Delete remote segments when deleting a topic

Co-authored-by: Kamal Chandraprakash <kchandraprakash@uber.com>
Co-authored-by: d00791190 <dinglan6@huawei.com>",2023-08-18 18:21:09,DL1231,Mixed
3ad5f42f595e4eef3a5787ce34e2676ed58bee3d,"Handle case of default broker in config migration (#14237)

When collecting the set of broker IDs during the migration, don't try to parse the default broker resource `""""` as a broker ID.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-08-18 12:44:01,David Arthur,Not TDD
b36cf4ef977fb14bc57683630a9f3f3680705550,"HOTIFX: fix Kafka Streams upgrade path from 3.4 to 3.5 (#14103)

KIP-904 introduced a backward incompatible change that requires a 2-bounce rolling upgrade.
The new ""3.4"" upgrade config value is not recognized by `AssignorConfiguration` though and thus crashed Kafka Streams if use.

Reviewers: Farooq Qaiser <fqaiser94@gmail.com>, Bruno Cadonna <bruno@confluent.io>",2023-08-18 11:06:08,Matthias J. Sax,Mixed
82ae77f94566881d957929acbdc3197e60f7f5f8,"KAFKA-15226: Add connect-plugin-path and plugin.discovery system test (#14230)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-08-18 15:28:43,Greg Harris,Not TDD
d0b7677c2c9a8265643a90175f86987521615849,"KAFKA-14936: Add restore logic (3/N)  (#14027)

Added restore logic for the buffer in grace period joins.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bbejeck@gmail.com>",2023-08-18 22:00:04,Walker Carlson,Mixed
4c7e0a9fa66fd1becc590d6060228b0305dd400b,"MINOR: Decouple purging committed records from committing (#14227)

Currently, Kafka Streams only tries to purge records whose
offset are committed from a repartition topic when at
least one offset was committed in the current commit.
The coupling between committing some offsets and purging
records is not needed and might delay purging of records.
For example, if a in-flight call for purging records has not
completed yet when a commit happens, a new call
is not issued.
If then the earlier in-flight call for purging records
finally completes but the next commit does not commit any
offsets, Streams does not issue the call for purging records
whose offset were committed in the previous commit
because the purging call was still in-flight.

This change issues calls for purging records during any commit
if the purge interval passed, even if no offsets were committed
in the current commit.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>, Walker Carlson <wcarlson@confluent.io>",2023-08-19 12:13:30,Bruno Cadonna,Mixed
05c329e61fbfddc1f972403fbec0a24c45d4e173,"KAFKA-10199: Change to RUNNING if no pending task to init exist (#14249)

A stream thread should only change to RUNNING if there are no
active tasks in restoration in the state updater and if there
are no pending tasks to recycle and to init.

Usually all pending tasks to init are added to the state updater
in the same poll iteration that handles the assignment. However,
if during an initialization of a task a LockException the task
is re-added to the tasks to init and initialization is retried
in the next poll iteration.

A LockException might occur when a state directory is still locked
by another thread, when the rebalance just happened.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>, Walker Carlson <wcarlson@confluent.io>",2023-08-19 19:00:23,Bruno Cadonna,Mixed
c2759df0676cef252596239baf8f1f361e76c49f,"KAFKA-15219: KRaft support for DelegationTokens (#14083)

Reviewers: David Arthur <mumrah@gmail.com>, Ron Dagostino <rndgstn@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, Viktor Somogyi <viktor.somogyi@cloudera.com>",2023-08-19 14:01:08,Proven Provenzano,Mixed
6492164d9c099ae3091cd508df98453c954b7e13,"KAFKA-15167: Tiered Storage Test Harness Framework (#14116)

`TieredStorageTestHarness` is a base class for integration tests exercising the tiered storage functionality. This uses  `LocalTieredStorage` instance as the second-tier storage system and `TopicBasedRemoteLogMetadataManager` as the remote log metadata manager.

Co-authored-by: Alexandre Dupriez <alexandre.dupriez@gmail.com>
Co-authored-by: Kamal Chandraprakash <kamal.chandraprakash@gmail.com>",2023-08-20 17:15:52,Kamal Chandraprakash,Not TDD
4b383378a0fd19d6d3c9ae7c2175fa3459661a04,"KAFKA-15380: Execute action queue after callback request (#14197)

KIP-890 part 1 introduced the callback request type. It is used to execute a callback after KafkaApis.handle has returned. We did not account for tryCompleteActions at the end of handle when making this change.

In tests, we saw produce p99 increase dramatically (likely because we have to wait for another request before we can complete DelayedProduce). As a result, we should add the tryCompleteActions after the callback as well. In testing, this improved the produce performance.

Reviewers: Artem Livshits <alivshits@confluent.io>, Jason Gustafson <jason@confluent.io>",2023-08-21 08:44:00,Justine Olshan,Mixed
ad76497b12b0d81a98dc6e230e5516adffbfa0ee,"KAFKA-14936: fix grace period partition issue (#14269)

Move the store creation to builder pattern and recover mintimestamp

Reviewers: John Roesler<vvcephei@apache.org>, Bill Bejeck <bbejeck@gmail.com>",2023-08-21 16:08:38,Walker Carlson,Not TDD
418b8a6e5939903c4b9561a2be7dd2fa8e29c271,"KAFKA-14538 Metadata transactions in MetadataLoader (#14208)

This PR contains three main changes:

- Support for transactions in MetadataLoader
- Abort in-progress transaction during controller failover
- Utilize transactions for ZK to KRaft migration

A new MetadataBatchLoader class is added to decouple the loading of record batches from the
publishing of metadata in MetadataLoader. Since a transaction can span across multiple batches (or
multiple transactions could exist within one batch), some buffering of metadata updates was needed
before publishing out to the MetadataPublishers. MetadataBatchLoader accumulates changes into a
MetadataDelta, and uses a callback to publish to the publishers when needed.

One small oddity with this approach is that since we can ""splitting"" batches in some cases, the
number of bytes returned in the LogDeltaManifest has new semantics. The number of bytes included in
a batch is now only included in the last metadata update that is published as a result of a batch.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-08-21 16:02:14,David Arthur,Mixed
8394ddc0d26399dc20ddff802886fa0b1f41f420,"MINOR: Move delegation token support to Metadata Version 3.6-IV2 (#14270)

#14083 added support for delegation tokens in KRaft and attached that support to the existing
MetadataVersion 3.6-IV1. This patch moves that support into a separate MetadataVersion 3.6-IV2.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-08-22 16:04:53,Ron Dagostino,Mixed
e9f358eef6a5f48530ecfe0ca6fca689410b499c,"KAFKA-14937; [2/N]: Refactoring for client code to reduce boilerplate (#14218)

This PR main refactoring relates to :

1. serializers/deserializers used in clients - unified in a Deserializers class
2. logic for configuring ClusterResourceListeners moved to ClientUtils
3. misc refactoring of the new async consumer in preparation for upcoming Request Managers

Reviewers: Jun Rao <junrao@gmail.com>",2023-08-22 21:43:06,Lianet Magrans,Mixed
9972297e510d74bd5dedbffe5dfb7a9f1c0a123f,"KAFKA-14780: Fix flaky test 'testSecondaryRefreshAfterElapsedDelay' (#14078)

""The test RefreshingHttpsJwksTest#testSecondaryRefreshAfterElapsedDelay relies on the actual system clock, which makes it frequently fail. The fix adds a second constructor that allows for passing a ScheduledExecutorService to manually execute the scheduled tasks before refreshing. The fixed task is much more robust and stable.

Co-authored-by: Fei Xie <feixie@MacBook-Pro.attlocal.net>

Reviewers: Divij Vaidya <diviv@amazon.com>, Luke Chen <showuon@gmail.com>",2023-08-24 10:59:16,olalamichelle,Mixed
87a30b73b561b205eeabae66aeba529a9307dfa0,"KAFKA-15391: Handle concurrent dir rename which makes log-dir to be offline unexpectedly (#14280)

A race condition between async flush and segment rename (for deletion purpose) might cause the entire log directory to be marked offline when we delete a topic. This PR fixes the bug by ignoring NoSuchFileException when we flush a directory.

Reviewers: Divij Vaidya <diviv@amazon.com>",2023-08-24 10:24:01,Okada Haruki,Mixed
25b128de81f826d0e0fe415acecf8b6d4cf837f4,"KAFKA-14991: KIP-937-Improve message timestamp validation (#14135)

This implementation introduces two new configurations `log.message.timestamp.before.max.ms` and `log.message.timestamp.after.max.ms` and deprecates `log.message.timestamp.difference.max.ms`.

The default value for all these three configs is maintained to be Long.MAX_VALUE for backward compatibility but with the newly added configurations we can have a finer control when validating message timestamps that are in the past and the future compared to the broker's timestamp.

To maintain backward compatibility if the default value of `log.message.timestamp.before.max.ms` is not changed, we are assuming users are still using the deprecated config `log.message.timestamp.difference.max.ms` and validation is done using its value. This ensures that existing customers who have customized the value of `log.message.timestamp.difference.max.ms` will continue to see no change in behavior.

Reviewers: Divij Vaidya <diviv@amazon.com>, Christo Lolov <lolovc@amazon.com>",2023-08-24 12:04:55,Mehari Beyene,Mixed
88d2c4460a1c8c8cf5dbcc9edb43f42fe898ca00,"KAFKA-15400: Use readLock when removing an item from the RemoteIndexCache (#14283)

- Caffeine cache is thread safe, we want to hold the writeLock only during the close.
- Fix the flaky tests

Reviewers: Divij Vaidya <diviv@amazon.com>",2023-08-24 13:42:13,Kamal Chandraprakash,Mixed
89aaecafae30fc2adc51d2fade89af4e9745598e,"KAFKA-15290: Handle topic-level dynamic remote storage enable configuration (#14238)

* KAFKA-15290: Handle topic-level dynamic remote log storage enable configuration.

To onboard existing topics to tiered storage, bootstrap the remote-log-components when updating the dynamic `remote.storage.enable` config on the topic.

Reviewers: Christo Lolov <lolovc@amazon.com>, Divij Vaidya <diviv@amazon.com, Luke Chen <showuon@gmail.com>, Satish Duggana <satishd@apache.org>",2023-08-24 21:05:48,Kamal Chandraprakash,Not TDD
880288879e8200cd22951e67a50df166edcc1b33,"KAFKA-15377: Don't expose externalized secret values in tasks-config API endpoint (#14244)

Reviewers: Greg Harris <greg.harris@aiven.io>",2023-08-24 15:44:53,Yash Mayya,Mixed
d4ab3ae85a35483c15f0ceb0002eb2d81ad79ad2,"KAFKA-14888: Added remote log segments retention mechanism based on time and size. (#13561)

This change introduces a remote log segment segment retention cleanup mechanism.

RemoteLogManager runs retention cleanup activity tasks on each leader replica. It assesses factors such as overall size and retention duration, subsequently removing qualified segments from remote storage. This process also involves adjusting the log-start-offset within the UnifiedLog accordingly. It also cleans up the segments which have epochs earlier than the earliest leader epoch in the current leader. 

Co-authored-by: Satish Duggana <satishd@apache.org>
Co-authored-by: Kamal Chandraprakash <kamal.chandraprakash@gmail.com>

Reviewers: Jun Rao <junrao@gmail.com>, Divij Vaidya <diviv@amazon.com, Luke Chen <showuon@gmail.com>, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>, Christo Lolov <lolovc@amazon.com>, Jorge Esteban Quilcate Otoya <quilcate.jorge@gmail.com>, Alexandre Dupriez <alexandre.dupriez@gmail.com>, Nikhil Ramakrishnan <ramakrishnan.nikhil@gmail.com>",2023-08-25 05:27:59,Satish Duggana,Mixed
f2d499e25a1ab8674dda7c6e5a05a12fb8687dbd,"KAFKA-15389: Don't publish until we have replayed at least one record (#14282)

When starting up a controller for the first time (i.e., with an empty log), it is possible for
MetadataLoader to publish an empty MetadataImage before the activation records of the controller
have been written. While this is not a bug, it could be confusing. This patch closes that gap by
waiting for at least one controller record to be committed before the MetadataLoader starts publishing
images.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-08-25 10:41:43,David Arthur,Mixed
ff3e6842ff99a600fc02e69ebefb09eef93decb3,"KAFKA-15181: Wait for RemoteLogMetadataCache to initialize after assigning partitions (#14127)

This PR adds the following changes to the `TopicBasedRemoteLogMetadataManager`

1. Added a guard in RemoteLogMetadataCache so that the incoming request can be served from the cache iff the corresponding user-topic-partition is initalized
2. Improve error handling in ConsumerTask thread so that is not killed when there are errors in reading the internal topic
3. ConsumerTask initialization should handle the case when there are no records to read
and some other minor changes

Added Unit Tests for the changes

Co-authored-by: Kamal Chandraprakash <kamal.chandraprakash@gmail.com>

Reviewers: Luke Chen <showuon@gmail.com>, Jorge Esteban Quilcate Otoya <quilcate.jorge@gmail.com>, Christo Lolov <lolovc@amazon.com>, Satish Duggana <satishd@apache.org>",2023-08-26 05:52:26,Abhijeet Kumar,Mixed
b41b2dfcf2f0f9e458374fb9b0842bcc8739f130,"KAFKA-15353: make sure AlterPartitionRequest.build() is idempotent (#14236)

As described in https://issues.apache.org/jira/browse/KAFKA-15353
When the AlterPartitionRequest version is < 3 and its builder.build is called multiple times, both newIsrWithEpochs and newIsr will all be empty. This can happen if the sender retires on errors.

Reviewers: Luke Chen <showuon@gmail.com>",2023-08-28 17:59:48,Calvin Liu,Mixed
4590d565ef08e48411123aa1ecbb46bd8130a3de,"KAFKA-15399: Enable OffloadAndConsumeFromLeader test (#14285)

Reviewers: Divij Vaidya <diviv@amazon.com>, Christo Lolov <lolovc@amazon.com>, Satish Duggana <satishd@apache.org>",2023-08-28 12:29:50,Kamal Chandraprakash,Not TDD
68b7031dc443b6f6b5dfac81316ab22fe250ec54,"KAFKA-14499: [4/N] Implement OffsetFetch API (#14120)

This patch implements the OffsetFetch API in the new group coordinator.

I found out that implementing the `RequireStable` flag is hard (to not say impossible) in the current model. For the context, the flag is here to ensure that an OffsetRequest request does not return stale offsets if there are pending offsets to be committed. In the scala code, we basically check the pending offsets data structure and if they are any pending offsets, we return the `UNSTABLE_OFFSET_COMMIT` error. This tells the consumer to retry.

In our new model, we don't have the pending offsets data structure. Instead, we use a timeline data structure to handle all the pending/uncommitted changes. Because of this we don't know whether offsets are pending for a particular group. Instead of doing this, I propose to not return the `UNSTABLE_OFFSET_COMMIT` error anymore. Instead, when `RequireStable` is set, we use a write operation to ensure that we read the latest offsets. If they are uncommitted offsets, the write operation ensures that the response is only return when they are committed. This gives a similar behaviour in the end.

Reviewers: Justine Olshan <jolshan@confluent.io>",2023-08-28 07:02:56,David Jacot,Mixed
945d21953e93409290a68dced0d366380866fb26,"KAFKA-14875: Implement wakeup (#14118)

Summary
Implemented wakeup() mechanism using a WakeupTrigger class to store the pending wakeup item, and when wakeup() is invoked, it checks whether there's an active task or a wakeup task.

If there's an active task: the task will be completed exceptionally and the atomic reference will be freed up.
If there an wakedup task, which means wakeup() was invoked before a blocking call was issued. Therefore, the current task will be completed exceptionally immediately.

This PR also addressed minor issues such as:

Throwing WakeupException at the right place: As wakeups are thrown by completing an active future exceptionally. The WakeupException is wrapped inside of the ExecutionException.

mockConstruction is a thread-lock mock; therefore, we need to free up the reference before completing the test. Otherwise, other tests will continue using the thread-lock mock.

Reviewers: Lianet Magrans <lianetmr@gmail.com>, Jun Rao <junrao@gmail.com>",2023-08-29 12:03:15,Philip Nee,Mixed
1c5020e1429d1dadcb59955395afa87ada99f670,"KAFKA-13327: Gracefully report connector validation errors instead of returning 500 responses (#14303)

Reviewers: Yash Mayya <yash.mayya@gmail.com>, Greg Harris <greg.harris@aiven.io>",2023-08-29 15:44:22,Chris Egerton,Mixed
efec0f5756510bb02ee578b1a01dd8388237c14b,"KAFKA-15267: Do not allow Tiered Storage to be disabled while topics have remote.storage.enable property (#14161)

The purpose of this change is to not allow a broker to start up with Tiered Storage disabled (remote.log.storage.system.enable=false) while there are still topics that have 'remote.storage.enable' set.

Reviewers: Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Divij Vaidya <diviv@amazon.com>, Satish Duggana <satishd@apache.org>, Luke Chen <showuon@gmail.com>",2023-08-30 05:34:20,Christo Lolov,Mixed
703e1d9faafbf07795261b3233ab985583f17fcb,"KAFKA-15375: fix broken clean shutdown detection logic in LogManager

When running in kraft mode, LogManager.startup is called in a different thread than the main broker (#14239)
startup thread (by BrokerMetadataPublisher when the first metadata update is received.) If a fatal
error happens during broker startup, before LogManager.startup is completed, LogManager.shutdown may
 mark log dirs as clean shutdown improperly.

This PR includes following change:
1. During LogManager startup time:
  - track hadCleanShutdwon info for each log dir
  - track loadLogsCompleted status for each log dir
2. During LogManager shutdown time:
  - do not write clean shutdown marker file for log dirs which have hadCleanShutdown==false and loadLogsCompleted==false

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-08-30 09:19:24,Vincent Jiang,Mixed
95e1cdc4efbc720687cefad5bacd053565d03614,"HOTFIX: avoid placement of unnecessary transient standby tasks & improve assignor logging (#14149)

Minor fix to avoid creating unnecessary standby tasks, especially when these may be surprising or unexpected as in the case of an application with num.standby.replicas = 0 and warmup replicas disabled.

The ""bug"" here was introduced during the fix for an issue with cooperative rebalancing and in-memory stores. The fundamental problem is that in-memory stores cannot be unassigned from a consumer for any period, however temporary, without being closed and losing all the accumulated state. This caused some grief when the new HA task assignor would assign an active task to a node based on the readiness of the standby version of that task, but would have to remove the active task from the initial assignment so it could first be revoked from its previous owner, as per the cooperative rebalancing protocol. This temporary gap in any version of that task among the consumer's assignment for that one intermediate rebalance would end up causing the consumer to lose all state for it, in the case of in-memory stores.

To fix this, we simply began to place standby tasks on the intended recipient of an active task awaiting revocation by another consumer. However, the fix was a bit of an overreach, as we assigned these temporary standby tasks in all cases, regardless of whether there had previously been a standby version of that task. We can narrow this down without sacrificing any of the intended functionality by only assigning this kind of standby task where the consumer had previously owned some version of it that would otherwise potentially be lost.

Also breaks up some of the long log lines in the StreamsPartitionAssignor and expands the summary info while moving it all to the front of the line (following reports of missing info due to truncation of long log lines in larger applications)",2023-08-30 13:29:38,A. Sophie Blee-Goldman,Mixed
16dc983ad67767ee8debd125a3f8b150a91c7acf,"Kafka Streams Threading: Timeout behavior (#14171)

Implement setting and clearing task timeouts, as well as changing the output on exceptions to make
it similar to the existing code path. 

Reviewer: Walker Carlson <wcarlson@apache.org>",2023-08-31 15:21:01,Lucas Brutschy,Mixed
d0f3cf1f9fa53b7d8663ca23bf42b5c6847e07ab,"KAFKA-15351: Ensure log-start-offset not updated to local-log-start-offset when remote storage enabled (#14301)

When tiered storage is enabled on the topic, and the last-standing-replica is restarted, then the log-start-offset should not reset its offset to first-local-log-segment-base-offset.

Reviewers: Satish Duggana <satishd@apache.org>, Luke Chen <showuon@gmail.com>, Divij Vaidya <diviv@amazon.com>, Christo Lolov <lolovc@amazon.com>",2023-09-01 06:33:33,Kamal Chandraprakash,Mixed
dcff0878c48803e2d68f7e43c1e73735b643ace0,"KAFKA-14499: [5/N] Refactor GroupCoordinator.fetchOffsets and GroupCoordinator.fetchAllOffsets (#14310)

This patch refactors the GroupCoordinator.fetchOffsets and GroupCoordinator.fetchAllOffsets methods to take an OffsetFetchRequestGroup and to return an OffsetFetchResponseGroup. It prepares the ground for adding the member id and the member epoch to the OffsetFetchRequest. This change also makes those two methods more aligned with the others in the interface.

Reviewers: Calvin Liu <caliu@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-09-01 03:45:24,David Jacot,Mixed
1bb8c11f5aa07709ce1b1b6ef684a6750242d4b0,"KAFKA-14965 - OffsetsRequestsManager implementation & API integration (#14308)

Implementation of the OffsetRequestsManager, responsible for building requests and processing responses for requests related to partition offsets.

In this PR, the manager includes support for ListOffset requests, generated when the user makes any of the following consumer API calls:

beginningOffsets
endOffsets
offsetsForTimes
All previous consumer API calls interact with the OffsetsRequestsManager by generating a ListOffsetsApplicationEvent.

Includes tests to cover the new functionality and to ensure no API level changes are introduced.

This covers KAFKA-14965 and KAFKA-15081.

Reviewers: Philip Nee <pnee@confluent.io>, Kirk True <kirk@mustardgrain.com>, Jun Rao<junrao@gmail.com>",2023-09-01 13:57:17,Lianet Magrans,Mixed
cc53889aaae8371964f9734a30da570afd0b7916,"KAFKA-15429: reset transactionInFlight on StreamsProducer close (#14326)

Resets the value of transactionInFlight to false when closing the
StreamsProducer. This ensures we don't try to commit against a
closed producer

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2023-09-02 18:14:14,Rohan,Mixed
5074c8038e44620b48d7700226810b983febd864,"KAFKA-15260: RLM Task should handle uninitialized RLMM for the associated topic-parititon (#14113)

This change is about RLM task handling retriable exception when it tries to copy segments to remote but the RLMM is not yet initialized. On encountering the exception, we log the error and throw the exception back to the caller. We also make sure that the failure metrics are updated since this is a temporary error because RLMM is not yet initialized.

Added unit tests to verify RLM task does not attempt to copy segments to remote on encountering the retriable exception and that failure metrics remain unchanged.

Reviewers: Satish Duggana <satishd@apache.org>, Luke Chen <showuon@gmail.com>, Kamal Chandraprakash<kamal.chandraprakash@gmail.com>",2023-09-04 09:13:04,Abhijeet Kumar,Mixed
caaa4c55fee68c5893d54ffe84287f3b5205fff1,"KAFKA-15410: Expand partitions, segment deletion by retention and enable remote log on topic integration tests (1/4) (#14307)

Added the below integration tests with tiered storage
 - PartitionsExpandTest
 - DeleteSegmentsByRetentionSizeTest
 - DeleteSegmentsByRetentionTimeTest and
 - EnableRemoteLogOnTopicTest
 - Enabled the test for both ZK and Kraft modes.

These are enabled for both ZK and Kraft modes.

Reviewers: Satish Duggana <satishd@apache.org>, Luke Chen <showuon@gmail.com>, Christo Lolov <lolovc@amazon.com>, Divij Vaidya <diviv@amazon.com>",2023-09-05 05:13:16,Kamal Chandraprakash,Not TDD
b892acae5e026e1affd51ef9756772807674b964,"KAFKA-15424: Make the transaction verification a dynamic configuration (#14324)

This will allow enabling and disabling transaction verification (KIP-890 part 1) without having to roll the cluster.

Tested that restarting the cluster persists the configuration.

If a verification is disabled/enabled while we have an inflight request, depending on the step of the process, the change may or may not be seen in the inflight request (enabling will typically fail unverified requests, but we may still verify and reject when we first disable) Subsequent requests/retries will behave as expected for verification.

Sequence checks will continue to take place after disabling until the first message is written to the partition (thus clearing the verification entry with the tentative sequence) or the broker restarts/partition is reassigned which will clear the memory. On enabling, we will only track sequences that for requests received after the verification is enabled.

Reviewers: Jason Gustafson <jason@confluent.io>, Satish Duggana <satishd@apache.org>",2023-09-04 20:40:50,Justine Olshan,Mixed
9f2ac375c282e1471a2d385704e1f7c128f34bb6,"KAFKA-15410: Reassign replica expand, move and shrink integration tests (2/4) (#14328)

- Updated the log-start-offset to the correct value while building the replica state in ReplicaFetcherTierStateMachine#buildRemoteLogAuxState

Integration tests added:
1. ReassignReplicaExpandTest
2. ReassignReplicaMoveTest and
3. ReassignReplicaShrinkTest

Reviewers: Satish Duggana <satishd@apache.org>, Luke Chen <showuon@gmail.com>",2023-09-05 19:28:17,Kamal Chandraprakash,Mixed
b49013b73efa25466652d8d8122974e60c927ec4,"KAFKA-9800: Exponential backoff for Kafka clients - KIP-580 (#14111)

Implementation of KIP-580 to add exponential back-off to situations in which retry.backoff.ms
is used to delay backoff attempts. This KIP adds exponential backoff behavior with a maximum
controlled by a new config retry.backoff.max.ms, together with a +/- 20% of jitter to spread the
retry attempts of the client fleet.

Reviewers: Mayank Shekhar Narula <mayanks.narula@gmail.com>, Milind Luthra <i.milind.luthra@gmail.com>, Kirk True <kirk@mustardgrain.com>, Jun Rao<junrao@gmail.com>",2023-09-05 11:57:51,Andrew Schofield,Mixed
80982c4ae3fe6be127b48ec09caff11ab5f87c69,"KAFKA-15410: Delete topic integration test with LocalTieredStorage and TBRLMM (3/4) (#14329)

Added delete topic integration tests for tiered storage enabled topics with LocalTieredStorage and TBRLMM

Reviewers: Satish Duggana <satishd@apache.org>, Divij Vaidya <diviv@amazon.com>, Luke Chen <showuon@gmail.com>",2023-09-06 05:50:12,Kamal Chandraprakash,Mixed
7054625c45dc6edb3c07271fe4a6c24b4638424f,"KAFKA-14499: [6/N] Add MemberId and MemberEpoch to OffsetFetchRequest (#14321)

This patch adds the MemberId and the MemberEpoch fields to the OffsetFetchRequest. Those fields will be populated when the new consumer group protocol is used to ensure that the member fetching the offset has the correct member id and epoch. If it does not, UNKNOWN_MEMBER_ID or STALE_MEMBER_EPOCH are returned to the client.

Our initial idea was to implement the same for the old protocol. The field is called GenerationIdOrMemberEpoch in KIP-848 to materialize this. As a second though, I think that we should only do it for the new protocol. The effort to implement it in the old protocol is not worth it in my opinion.

Reviewers: Ritika Reddy <rreddy@confluent.io>, Calvin Liu <caliu@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-09-05 23:36:38,David Jacot,Mixed
65e2ecffabad8ade39f201766702162874e9d561,"KAFKA-15435 Fix counts in MigrationManifest (#14342)

Reviewers: Liu Zeyu <zeyu.luke@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",2023-09-06 13:02:13,David Arthur,Mixed
6d762480c94d826a434eaa7b7688e22d92b28072,"KAFKA-15351: Update log-start-offset after leader election for topics enabled with remote storage (#14340)

On leadership failover, the new leader's start offset may be older than the start offset of old leader. This works fine for local storage scenario because the new leader still contains data associated with stale start offset. But in case of remote storage, although new leader has a stale offset, the data associated with it has been deleted from remote by the old leader. Hence, we end up in a situation where leader has a start offset but no data associated with it.

This commit fixes the situation by ensuring that on every leadership failover, for topics with remote storage, the leader will update it's start offset from the base of first segment in current leader chain present in the remote storage (if any).

Reviewers: Satish Duggana <satishd@apache.org>, Luke Chen <showuon@gmail.com>, Christo Lolov <lolovc@amazon.com>, Divij Vaidya <diviv@amazon.com>",2023-09-07 16:32:16,Kamal Chandraprakash,Mixed
90e646052a17e3f6ec1a013d76c1e6af2fbb756e,"KAFKA-14509; [1/2] Define ConsumerGroupDescribe API request and response schemas and classes. (#14124)

This patch adds the schemas of the new ConsumerGroupDescribe API (KIP-848) and adds an handler to the KafkaApis.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, David Jacot <djacot@confluent.io>",2023-09-07 08:05:04,Max Riedel,Mixed
6e818c6b021499976a8aed316bbde6b464439b20,"KAFKA-15410: Delete records with tiered storage integration test (4/4) (#14330)

* Added the integration test for DELETE_RECORDS API for tiered storage enabled topic
* Added validation checks before removing remote log segments for log-start-offset breach

Reviewers: Satish Duggana <satishd@apache.org>, Luke Chen <showuon@gmail.com>, Christo Lolov <lolovc@amazon.com>",2023-09-07 21:02:39,Kamal Chandraprakash,Not TDD
88b554fdbd47d4820059bc3633f5b2e3d2adb12d,"KAFKA-15179: Add integration tests for the file sink and source connectors (#14279)

Reviewers: Ashwin Pankaj <apankaj@confluent.io>, Chris Egerton <chrise@aiven.io>",2023-09-07 12:24:13,Yash Mayya,Not TDD
0029bc4897e603614a49e0b0f1e623abbe650c61,"KAFKA-14595: ReassignPartitionsCommandArgsTest rewritten in java (#14217)

Reviewers: Taras Ledkov <tledkov@apache.org>, Greg Harris <greg.harris@aiven.io>",2023-09-07 10:12:07,Nikolay,Not TDD
77a91be22ed90920460580ee7d14aed016c8044e,"KAFKA-15425: Fail fast in Admin::listOffsets when topic (but not partition) metadata is not found (#14314)

This restores previous behavior for Admin::listOffsets, which was to fail immediately if topic metadata could not be found, and only retry if metadata for one or more specific partitions could not be found.

There is a subtle difference here: prior to https://github.com/apache/kafka/pull/13432, the operation would be retried if any metadata error was reported for any individual topic partition, even if an error was also reported for the entire topic. With this change, the operation always fails if an error is reported for the entire topic, even if an error is also reported for one or more individual topic partitions.

I am not aware of any cases where brokers might return both topic- and topic partition-level errors for a metadata request, and if there are none, then this change should be safe. However, if there are such cases, we may need to refine this PR to remove the discrepancy in behavior.

Reviewers: Justine Olshan <jolshan@confluent.io>",2023-09-07 14:02:57,Chris Egerton,Not TDD
41b695b6e30baa4243d9ca4f359b833e17ed0e77,"KAFKA-15369: Implement KIP-919: Allow AC to Talk Directly with Controllers (#14306)

Implement KIP-919: Allow AdminClient to Talk Directly with the KRaft Controller Quorum and add
Controller Registration. This KIP adds a new version of DescribeClusterRequest which is supported
by KRaft controllers. It also teaches AdminClient how to use this new DESCRIBE_CLUSTER request to
talk directly with the controller quorum. This is all gated behind a new MetadataVersion,
IBP_3_7_IV0.

In order to share the DESCRIBE_CLUSTER logic between broker and controller, this PR factors it out
into AuthHelper.computeDescribeClusterResponse.

The KIP adds three new errors codes: MISMATCHED_ENDPOINT_TYPE, UNSUPPORTED_ENDPOINT_TYPE, and
UNKNOWN_CONTROLLER_ID. The endpoint type errors can be returned from DescribeClusterRequest

On the controller side, the controllers now try to register themselves with the current active
controller, by sending a CONTROLLER_REGISTRATION request. This, in turn, is converted into a
RegisterControllerRecord by the active controller. ClusterImage, ClusterDelta, and all other
associated classes have been upgraded to propagate the new metadata. In the metadata shell, the
cluster directory now contains both broker and controller subdirectories.

QuorumFeatures previously had a reference to the ApiVersions structure used by the controller's
NetworkClient. Because this PR removes that reference, QuorumFeatures now contains only immutable
data. Specifically, it contains the current node ID, the locally supported features, and the list
of quorum node IDs in the cluster.

Reviewers: David Arthur <mumrah@gmail.com>, Ziming Deng <dengziming1993@gmail.com>, Luke Chen <showuon@gmail.com>",2023-09-07 15:21:52,Colin Patrick McCabe,Mixed
a2de7d32c89a7d9e68a0568adf7489165485862b,"KAFKA-14274 #1: basic refactoring (#14305)

This change introduces some basic clean up and refactoring for forthcoming commits related to the revised fetch code for the consumer threading refactor project.

Reviewers: Christo Lolov <lolovc@amazon.com>, Jun Rao <junrao@gmail.com>",2023-09-07 15:23:44,Kirk True,Mixed
54ab5b29e47fd3f399e0575df2f490a33f12804b,"KAFKA-15416: Fix flaky TopicAdminTest::retryEndOffsetsShouldRetryWhenTopicNotFound test case (#14313)

Reviewers: Philip Nee <pnee@confluent.io>, Greg Harris <greg.harris@aiven.io>",2023-09-07 19:24:17,Chris Egerton,Mixed
b24ccd65b7ae9585de19a9cc1b2bf6a10a542cd8,"KAFKA-15441 Allow broker heartbeats to complete in metadata transaction (#14351)

This patch allows broker heartbeat events to be completed while a metadata transaction is in-flight.

More generally, this patch allows any RUNS_IN_PREMIGRATION event to complete while the controller
is in pre-migration mode even if the migration transaction is in-flight.

We had a problem with broker heartbeats timing out because they could not be completed while a large
ZK migration transaction was in-flight. This resulted in the controller fencing all the ZK brokers which 
has many undesirable downstream effects. 

Reviewers: Akhilesh Chaganti <akhileshchg@users.noreply.github.com>, Colin Patrick McCabe <cmccabe@apache.org>",2023-09-08 16:36:13,David Arthur,Mixed
672ea644f002e9d5a858a8c19b95de1199bcca5c,"MINOR: Removed the RSM and RLMM classpath config validator (#14358)

- RSM and RLMM classpath can be empty since it's optional so removed the non-empty string validator
- Fix getting the `localTieredStorage` by brokerId after stopping a broker.

Reviewers: Christo Lolov <lolovc@amazon.com>, Luke Chen <showuon@gmail.com>, Satish Duggana <satishd@apache.org>",2023-09-09 19:02:42,Kamal Chandraprakash,Not TDD
b72d92919f71f7360cd712741c0470759fc10239,"KAFKA-14581: Moving GetOffsetShell to tools (#13562)

This PR moves GetOffsetShell from core module to tools module with rewriting from Scala to Java.

Reviewers: Federico Valeri fedevaleri@gmail.com, Ziming Deng dengziming1993@gmail.com, Mickael Maison mimaison@apache.org.",2023-09-11 10:30:22,Ruslan Krivoshein,Mixed
07a18478be51ae32e9a9a1954f5ecb9eea792443,"KAFKA-15326: [7/N] Processing thread non-busy waiting (#14180)

Avoid busy waiting for processable tasks. We need to be a bit careful here to not have the task executors to sleep when work is available. We have to make sure to signal on the condition variable any time a task becomes ""processable"". Here are some situations where a task becomes processable:

- Task is unassigned from another TaskExecutor.
- Task state is changed (should only happen inside when a task is locked inside the polling phase).
- When tasks are unlocked.
- When tasks are added.
- New records available.
- A task is resumed.

So in summary, we

- We should probably lock tasks when they are paused and unlock them when they are resumed. We should also wake the task executors after every polling phase. This belongs to the StreamThread integration work (separate PR). We add DefaultTaskManager.signalProcessableTasks for this.
- We need to awake the task executors in DefaultTaskManager.unassignTask, DefaultTaskManager.unlockTasks and DefaultTaskManager.add.


Reviewers: Walker Carlson <wcarlson@confluent.io>, Bruno Cadonna <cadonna@apache.org>",2023-09-11 09:58:20,Lucas Brutschy,Mixed
6123071fc05f714f8781edac6686c9c4e98fdd35,"KAFKA-14499: [7/7] Add integration tests for OffsetCommit API and OffsetFetch API (#14353)

This patch adds integration tests for the OffsetCommit API and the OffsetFetch API. The tests runs against the old and the new group coordinator and with the new and the old consumer rebalance protocol.

Reviewers: Ritika Reddy <rreddy@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-09-11 10:48:02,David Jacot,Mixed
39cc19c9924cd5589dc5b98b75ec8d380c159205,"MINOR: rename BrokerToControllerChannelManager to NodeToControllerChannelManager (#14356)

Reviewers: David Jacot <david.jacot@gmail.com>",2023-09-11 11:04:38,Colin Patrick McCabe,Mixed
7483991a0122c1c9493464efbcda1c8a93c74fd6,"KAFKA-15352: Update log-start-offset before initiating deletion of remote segments (#14349)

This change is about the current leader updating the log-start-offset before the segments are deleted from remote storage. This will do a best-effort mechanism for followers to receive log-start-offset from the leader and they can update their log-start-offset before it becomes a leader. 

Reviewers: Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Divij Vaidya <diviv@amazon.com>, Luke Chen <showuon@gmail.com>, Satish Duggana <satishd@apache.org>",2023-09-12 10:12:30,Christo Lolov,Mixed
a63bf93dcea092642314765fbcf09b3cf2c6798e,"KAFKA-14993: Improve TransactionIndex instance handling while copying to and fetching from RSM (#14363)

- Updated the contract for RSM's fetchIndex to throw a ResourceNotFoundException instead of returning an empty InputStream when it does not have a TransactionIndex.
- Updated the LocalTieredStorage implementation to adhere to the new contract.
- Added Unit Tests for the change.

Reviewers: Satish Duggana <satishd@apache.org>, Luke Chen <showuon@gmail.com>, Divij Vaidya <diviv@amazon.com>, Christo Lolov <lolovc@amazon.com>, Kamal Chandraprakash<kamal.chandraprakash@gmail.com>",2023-09-12 17:54:20,Abhijeet Kumar,Mixed
50693198e3b41160cab592fc48d603879e6b0cce,"KAFKA-15450 Don't allow ZK migration with JBOD (#14367)

Reviewers: Ron Dagostino <rndgstn@gmail.com>",2023-09-12 10:27:50,David Arthur,Mixed
8a7e5e8ea0fe7793514b083d970fb5b1e87ba08d,"MINOR: Fix errors in javadoc and docs in tiered storage (#14379)

Reviewers: Satish Duggana <satishd@apache.org>",2023-09-13 12:45:36,Luke Chen,Not TDD
e9057aab37a1aedc2917f82922aff11661d9a001,"KAFKA-14502; Implement LeaveGroup protocol in new GroupCoordinator (#14147)

This patch implements the LeaveGroup API in the new group coordinator.

Reviewers: David Jacot <djacot@confluent.io>",2023-09-13 01:43:37,Jeff Kim,Mixed
0e47fa75371dda275de73610b414c16a639895f3,"KAFKA-15275 - Client state machine basic components, states and initial transitions (#14323)

Initial definition of the core components for maintaining group membership on the client following the new consumer group protocol.

This PR includes:
- Membership management for keeping member state and assignment, based on the heartbeat responses received.
- Assignor selection logic to support server side assignors.
This only includes the basic initial states and transitions, to be extended as we implement the protocol.

This is intended to be used from the heartbeat and assignment requests manager that actually build and process the heartbeat and assignment related requests.

Reviewers: Philip Nee <pnee@confluent.io>, Kirk True <ktrue@confluent.io>, David Jacot <djacot@confluent.io>",2023-09-13 05:07:56,Lianet Magrans,Mixed
a7e865c0a756504cc7ae6f4eb0772cadd3333c53,"KAFKA-15115 - KAFKA-15163; Reset/Validate positions implementation & API integration (#14346)

Implementation of the required functionality for resetting and validating positions in the new async consumer.

This PR includes:
1. New async application events ResetPositionsApplicationEvent and ValidatePositionsApplicationEvent, both handled by the same OfffsetsRequestManager.
2. Integration of the reset/validate functionality in the new async consumer, to update fetch positions using the partitions offsets.
3. Minor refactoring to extract functionality that is reused from both consumer implementations (moving logic without changes from OffsetFetcher into OffsetFetchUtils, and from OffsetsForLeaderEpochClient into OffsetsForLeaderEpochUtils)

Reviewers: Philip Nee <pnee@confluent.io>, Kirk True <kirk@mustardgrain.com>, Jun Rao<junrao@gmail.com>",2023-09-13 07:49:41,Lianet Magrans,Mixed
5aecd2825644728f68a26558c957f5dfd4643423,"KAFKA-15459: Convert coordinator retriable errors to a known producer response error (#14378)

KIP-890 Part 1 tries to address hanging transactions on old clients. Thus, the produce version can not be bumped and no new errors can be added. Before we used the java client's notion of retriable and abortable errors -- retriable errors are defined as such by extending the retriable error class, fatal errors are defined explicitly, and abortable errors are the remaining. However, many other clients treat non specified errors as fatal and that means many retriable errors kill the application.

Stuck between having specific errors for Java clients that are handled correctly (ie we retry) or specific fatal errors for cases that should not be fatal, we opted for a middle ground of non-specific error, but a message in the response to specify.

Converting some of the coordinator error codes to NOT_ENOUGH_REPLICAS which is a known produce response.
Also correctly add the old errors to the produce response. (We were not doing this correctly before)

Added tests for the new errors and messages.

Reviewers: Jason Gustafson <jason@confluent.io>, David Jacot <djacot@confluent.io>",2023-09-13 14:21:58,Justine Olshan,Mixed
dacb3b31d989f4ead56a56e47f27e37ac85d7b33,"KAFKA-15439: Transactions test with tiered storage (#14347)

This test extends the existing TransactionsTest. It configures the broker and topic with tiered storage and expects at-least one log segment to be uploaded to the remote storage.

Reviewers: Luke Chen <showuon@gmail.com>, Satish Duggana <satishd@apache.org>,  Divij Vaidya <diviv@amazon.com>",2023-09-14 09:52:13,Kamal Chandraprakash,Not TDD
2a41beb0f49f947cfa7dfd99101c8b1ba89842cb,"MINOR: Check the existence of AppInfo for the given ID before creating a new mbean of the same name (#14287)

When using kafka consumer in apache pinot , we did see couple of WARN as we are trying to create kafka consumer class with the same name . We currently have to use a added suffix to create a new mBean as each new kafka consumer in same process creates a mBean . Adding support here to skip creation of mBean if its already existing

Reviewers: Satish Duggana <satishd@apache.org>, Luke Chen <showuon@gmail.com>",2023-09-14 14:53:57,Eaugene Thomas,Mixed
f309299f3cf92c3ed6fe545c628117b9028c2917,"KAFKA-14503: Implement ListGroups (#14271)

This patch implements the ListGroups API in the new group coordinator.

Reviewers: David Jacot <djacot@confluent.io>",2023-09-14 23:45:03,zhaohaidao,Mixed
f46db86d34f9e5fe1b0d7604306a5108a89c113e,"KAFKA-15273: Log common name of expired client certificates (#14130)

This contribution extends the TrustManager created by the DefaultSSLEngineFactory class with code that checks for any invalid certificate whether it is just expired but valid otherwise. If this is the case, it extracts the common name and logs it. Apart from that, the trust manager will behave exactly as the default one.

Extensive unit tests are included in this pull request for ensuring that the modified trust manager will behave exactly as the default one, except for logging expired certificates common name. The test code generates several certificate chains with valid, invalid and expired end certificates, root CAs and even intermediate CAs.

This contribution is my original work and I license the work to the project under the project's open source license.


Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2023-09-15 21:06:37,Eike Thaden,Mixed
e1dc6d9f3493eb35e3d3eef1d70c2d1fc94d74c2,"KAFKA-14274 [2-5/7]: Introduction of more infrastructure for forthcoming fetch request manager (#14359)

This continues the work of providing the groundwork for the fetch
refactoring work by introducing some new classes and refactoring the
existing code to use the new classes where applicable.

Changes:

* Minor clean up of the events classes to make data immutable,
  private, and implement toString().
* Added IdempotentCloser which prevents a resource from being closed
  more than once. It's general enough that it could be used elsewhere
  in the project, but it's limited to the consumer internals for now.
* Split core Fetcher code into classes to buffer raw results
  (FetchBuffer) and to collect raw results into ConsumerRecords
  (FetchCollector). These can be tested and changed in isolation from
  the core fetcher logic.
* Added NodeStatusDetector which abstracts methods from
  ConsumerNetworkClient so that it and NetworkClientDelegate can be
  used in AbstractFetch via the interface instead of using
  ConsumerNetworkClient directly.

Reviewers: Jun Rao <junrao@gmail.com>",2023-09-16 09:15:37,Kirk True,Mixed
f041efa5fd82d6a435be80481e40a7bfcd56ed19,"KAFKA-13973: Fix inflated block cache metrics (#14317)

All block cache metrics are being multiplied by the total number of
column families. In a `RocksDBTimestampedStore`, we have 2 column
families (the default, and the timestamped values), which causes all
block cache metrics in these stores to become doubled.

The cause is that our metrics recorder uses `getAggregatedLongProperty`
to fetch block cache metrics. `getAggregatedLongProperty` queries the
property on each column family in the database, and sums the results.

Since we always configure all column families to share the same block
cache, that causes the same block cache to be queried multiple times for
its metrics, with the results added togehter, effectively multiplying
the real value by the total number of column families.

To fix this, we should simply use `getLongProperty`, which queries a
single column family (the default one). Since all column families share
the same block cache, querying just one of them will give us the correct
metrics for that shared block cache.

Note: the same block cache is shared among all column families of a store
irrespective of whether the user has configured a shared block cache
across multiple stores.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bruno Cadonna <cadonna@apache.org>",2023-09-18 11:09:10,Nick Telford,Not TDD
1c402297d60152722cf5544a14ca5271d576d55e,"KAFKA-15306 - Integrating committed offsets for updating fetch positions (#14385)

Support for using committed offsets to update fetch positions.

This PR includes:
* movingrefreshCommittedOffsets function out of the existing ConsumerCoordinator so it can be reused (no code changes)
* using the above refreshCommittedOffsets for updating fetch positions if the consumer has enabled the Kafka-based offsets management by defining a groupId

Reviewers: Jun Rao <junrao@gmail.com>",2023-09-18 12:21:19,Lianet Magrans,Mixed
7872a1ff5b2e9a0fbbe3d71180a97e29f1549d4f,"KAFKA-14855: Harden integration testing logic for asserting that a connector is deleted (#14371)

Reviewers: Sagar Rao <sagarmeansocean@gmail.com>, Chris Egerton <chrise@aiven.io>",2023-09-19 11:39:39,Yash Mayya,Not TDD
b088307612b59d9864fb7e3096dc9a0b47d7273d,"KAFKA-15473: Hide duplicate plugins in /connector-plugins (#14398)

Reviewers: Yash Mayya <yash.mayya@gmail.com>, Sagar Rao <sagarmeansocean@gmail.com>, Hector Geraldino <hgeraldino@gmail.com>, Chris Egerton <chrise@aiven.io>",2023-09-19 12:37:21,Greg Harris,Mixed
7d45d849f8e4592a135c7f75f15e710bfab0a651,"KAFKA-15458: Fully resolve endpoint information before registering controllers (#14376)

Endpoint information provided by KafkaConfig can be incomplete in two ways. One is that endpoints
using ephemeral ports will show up as using port 0. Another is that endpoints binding to 0.0.0.0
will show up with a null or blank hostname. Because we were not accounting for this in controller
registration, it was leading to a null pointer dereference when we tried to register a controller
using an endpoint defined as PLAINTEXT://:9092.

This PR adds a ListenerInfo class which can fix both of the causes of incomplete endpoint
information. It also handles serialization to and from various RPC and record formats.
This allows us to remove a lot of boilerplate code and standardize the handling of listeners
between BrokerServer and ControllerServer.

Reviewers: David Arthur <mumrah@gmail.com>",2023-09-20 11:44:00,Colin Patrick McCabe,Mixed
fcd382138e7c9db4fceb90424aef7ee1db695240,"MINOR: Used Admin instead of AdminClient to create Admin (#14411)

 Used Admin instead of AdminClient to create Admin

Reviewers: Ziming Deng <dengziming1993@gmail.com>",2023-09-21 11:01:08,Wuzhengyu97,Not TDD
47a1a7c70ed3f53583c33b8a00348e6e5a800d28,"MINOR: Add additional tests for RemoteLogManager (#14311)

Reviewers: Divij Vaidya <diviv@amazon.com>",2023-09-21 10:36:22,Nikhil Ramakrishnan,Mixed
7d89bdc3f0d1b7c477f728449841c45fcfbb5724,"KAFKA-14960: TopicMetadata request manager (#14386)

TopicMetadataRequestManager is responsible for sending topic metadata requests. The manager manages API requests and build the request accordingly. All topic metadata requests are chained, if requesting the same topic, to avoid sending requests repeatedly.

Co-authored-by: Lianet Magrans <lmagrans@confluent.io>
Co-authored-by: Kirk True <kirk@kirktrue.pro>

Reviewers: Kirk True <kirk@kirktrue.pro>, Lianet Magrans <lianetmr@gmail.com>, Jun Rao <junrao@gmail.com>",2023-09-21 08:07:21,Philip Nee,Mixed
daf8a0dedacceb46d6ec2bcc16181abf5963377b,"KAFKA-14595 ReassignPartitionsUnitTest rewritten in java (#14355)

This PR is part of #13247
It contains changes to rewrite single test in java.
Intention is reduce changes in parent PR.

Reviewers: Luke Chen <showuon@gmail.com>, Taras Ledkov <tledkov@apache.org>",2023-09-23 09:45:14,Nikolay,Not TDD
98febb989abd1bdb624420f21122c477f2614a08,"KAFKA-15485: Fix ""this-escape"" compiler warnings introduced by JDK 21 (1/N) (#14427)

This is one of the steps required for kafka to compile with Java 21.

For each case, one of the following fixes were applied:
1. Suppress warning if fixing would potentially result in an incompatible change (for public classes)
2. Add final to one or more methods so that the escape is not possible
3. Replace method calls with direct field access.

In addition, we also fix a couple of compiler warnings related to deprecated references in the `core` module.

See the following for more details regarding the new lint warning:
https://www.oracle.com/java/technologies/javase/21-relnote-issues.html#JDK-8015831

Reviewers: Divij Vaidya <diviv@amazon.com>, Satish Duggana <satishd@apache.org>, Chris Egerton <chrise@aiven.io>",2023-09-24 05:59:29,Ismael Juma,Mixed
7ba6d7a0b439cd7be7918b77c6b08425d6b37526,"MINOR: Update to Scala 2.13.12 (#14430)

It offers a quickfix action for certain errors, includes a number of bug fixes and it
introduces a new warning by default (https://github.com/scala/scala/pull/10462).

In addition to the scala version bump, we also fix the new compiler warnings and
bump the scalafmt version (the previous version failed with the new scala version).

Release notes: https://github.com/scala/scala/releases/tag/v2.13.12

Reviewers: Divij Vaidya <diviv@amazon.com>, Satish Duggana <satishd@apache.org>",2023-09-24 06:05:12,Ismael Juma,Not TDD
a15012078b9fa7a31ede40121bbb509cb17af793,"KAFKA-15479: Remote log segments should be considered once for retention breach (#14407)

When a remote log segment contains multiple epoch, then it gets considered for multiple times during breach by retention size/time/start-offset. This will affect the deletion by remote log retention size as it deletes the number of segments less than expected. This is a follow-up of KAFKA-15352

Reviewers: Divij Vaidya <diviv@amazon.com>, Christo Lolov <lolovc@amazon.com>, Satish Duggana <satishd@apache.org>",2023-09-25 17:41:53,Kamal Chandraprakash,Mixed
99e6f12dd09952fccde8f4826b65cadab332c2dc,"KAFKA-15485: Support Java 21 (3/3) (#14433)

* Update CI to build with Java 21 instead of Java 20
* Disable spotbugs when building with Java 21 as it doesn't support it yet (filed KAFKA-15492 for
   addressing this)
* Disable SslTransportLayerTest.testValidEndpointIdentificationCN with Java 21 (same as Java 20)

Reviewers: Divij Vaidya <diviv@amazon.com>",2023-09-25 05:17:08,Ismael Juma,Not TDD
08aa33127a4254497456aa7a0c1646c7c38adf81,"MINOR: Push logic to resolve the transaction coordinator into the AddPartitionsToTxnManager (#14402)

This patch refactors the ReplicaManager.appendRecords method and the AddPartitionsToTxnManager class in order to move the logic to identify the transaction coordinator based on the transaction id from the former to the latter. While working on KAFKA-14505, I found pretty annoying that we require to pass the transaction state partition to appendRecords because we have to do the same from the group coordinator. It seems preferable to delegate that job to the AddPartitionsToTxnManager.

Reviewers: Justine Olshan <jolshan@confluent.io>",2023-09-25 09:05:30,David Jacot,Mixed
170550af40d80eb3585b4115b8dff125337952c2,"KAFKA-15502: Update SslEngineValidator to handle large stores (#14445)

We have observed an issue where inter broker SSL listener is not coming up when running with TLSv3/JDK 17 .
SSL debug logs shows that TLSv3 post handshake messages >16K are not getting read and causing SslEngineValidator process to stuck while validating the provided trust/key store.

- Right now, WRAP returns if there is already data in the buffer. But if we need more data to be wrapped for UNWRAP to succeed, we end up looping forever. To fix this, now we always attempt WRAP and only return early on BUFFER_OVERFLOW.
- Update SslEngineValidator to unwrap post-handshake messages from peer when local handshake status is FINISHED.

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2023-09-26 11:16:30,Manikumar Reddy,Mixed
7107a750ba17c50c3b0a1e74e644c378f3bc59f5,"KAFKA-15248 (KIP-959): Add BooleanConverter to Kafka Connect (#14093)

Reviewers: Yash Mayya <yash.mayya@gmail.com>, Sagar Rao <sagarmeansocean@gmail.com>, Qichao Chu <5326144+ex172000@users.noreply.github.com>",2023-09-26 12:42:16,Hector Geraldino,Mixed
9c2e5daf606aebb343224f943b8e6bac4351c193,"MINOR: Revert log level changes in LogCaptureAppender (#14436)

LogCaptureAppender sets the log level in various tests to check if a certain log message is produced. The log level is however never reverted, changing the log level across the board and introducing flakiness due to non-determinism since the log level depends on execution order. Some log messages change the timing inside tests significantly.

Reviewer: Bruno Cadonna <cadonna@apache.org>",2023-09-26 10:49:41,Lucas Brutschy,Not TDD
a46da90b8f6cca04dd0f89fa774267898c039e47,"KAFKA-10199: Add missing catch for lock exception (#14403)

The state directory throws a lock exception during initialization if a task state directory is still locked by the stream thread that previously owned the task. When this happens, Streams catches the lock exception, ignores the exception, and tries to initialize the task in the next exception.

In the state updater code path, we missed catching the lock exception when Streams recycles a task. That leads to the lock exception thrown to the exception handler, which is unexpected and leads to test failures.

Reviewer: Lucas Brutschy <lbrutschy@confluent.io>",2023-09-26 10:58:37,Bruno Cadonna,Mixed
2d04370bca7ab5995371ce5501b2248c279e1d6f,"KAFKA-10199: Fix restoration behavior for paused tasks (#14437)

State updater can get into a busy loop when all tasks are paused, because changelogReader will never return that all changelogs have been read completely. Fix this, by awaiting if updatingTasks is empty.

Related and included: if we are restoring and all tasks are paused, we should return immediately from StoreChangelogReader.

Reviewer: Bruno Cadonna <cadonna@apache.org>",2023-09-26 14:05:55,Lucas Brutschy,Mixed
65efb981347d6f81fb2713cd27cdfdfa9d8781b9,"KAFKA-10199: Do not process when in PARTITIONS_REVOKED (#14265)

When a Streams application is subscribed with a pattern to
input topics and an input topic is deleted, the stream thread
transists to PARTITIONS_REVOKED and a rebalance is triggered.
This happens inside the poll call. Sometimes, the poll call
returns before a new assignment is received. That means, Streams
executes the poll loop in state PARTITIONS_REVOKED.

With the state updater enabled processing is also executed in states
other than RUNNING and so processing is also executed when the
stream thread is in state PARTITION_REVOKED. However, that triggers
an IllegalStateException with error message:
No current assignment for partition TEST-TOPIC-A-0
which is a fatal error.

This commit prevents processing when the stream thread is in state
PARTITIONS_REVOKED.

Reviewer: Lucas Brutschy <lbrutschy@confluent.io>",2023-09-26 15:25:30,Bruno Cadonna,Mixed
079e5d647ce39cf2ab5b5f37c5ce28b59fb6db13,"KAFKA-15326: [8/N] Move consumer interaction out of processing methods (#14226)

The process method inside the tasks needs to be called from within
the processing threads. However, it currently interacts with the
consumer in two ways:

* It resumes processing when the PartitionGroup buffers are empty
* It fetches the lag from the consumer

We introduce updateLags() and 
resumePollingForPartitionsWithAvailableSpace() methods that call into
the task from the polling thread, in order to set up the consumer
correctly for the next poll, and extract metadata from the consumer
after the poll.

Reviewer: Bruno Cadonna <bruno@confluent.io>",2023-09-26 18:17:23,Lucas Brutschy,Mixed
fcac880fd54efbec3fe385000cf990a19972dafa,"KAFKA-15466: Add KIP-919 support for some admin APIs (#14399)

Add support for --bootstrap-controller in the following command-line tools:
    - kafka-cluster.sh
    - kafka-configs.sh
    - kafka-features.sh
    - kafka-metadata-quorum.sh

To implement this, the following AdminClient APIs now support the new bootstrap.controllers
configuration:
    - Admin.alterConfigs
    - Admin.describeCluster
    - Admin.describeConfigs
    - Admin.describeFeatures
    - Admin.describeMetadataQuorum
    - Admin.incrementalAlterConfigs
    - Admin.updateFeatures

Command-line tool changes:
    - Add CommandLineUtils.initializeBootstrapProperties to handle parsing --bootstrap-controller
      in addition to --bootstrap-server.
    - Add --bootstrap-controller to ConfigCommand.scala, ClusterTool.java, FeatureCommand.java, and
      MetadataQuorumCommand.java.

KafkaAdminClient changes:
    - Add the AdminBootstrapAddresses class to handle extracting bootstrap.servers or
      bootstrap.controllers from the config map for KafkaAdminClient.
    - In AdminMetadataManager, store the new usingBootstrapControllers boolean. Generalize
      authException to encompass the concept of fatal exceptions in general. (For example, the
      fatal exception where we talked to the wrong node type.) Treat
      MismatchedEndpointTypeException and UnsupportedEndpointTypeException as fatal exceptions.
    - Extend NodeProvider to include information about whether bootstrap.controllers is supported.
    - Modify the APIs described above to support bootstrap.controllers.

Server-side changes:
    - Support DescribeConfigsRequest on kcontrollers.
    - Add KRaftMetadataCache to the kcontroller to simplify implemeting describeConfigs (and
      probably more APIs in the future). It's mainly a wrapper around MetadataImage, so there is
      essentially no extra resource consumption.
    - Split RuntimeLoggerManager out of ConfigAdminManager to handle the incrementalAlterConfigs
      support for BROKER_LOGGER. This is now supported on kcontrollers as well as brokers.
    - Fix bug in AuthHelper.computeDescribeClusterResponse that resulted in us always sending back
      BROKER as the endpoint type, even on the kcontroller.

Miscellaneous:
    - Fix a few places in exceptions and log messages where we wrote ""broker"" instead of ""node"".
      For example, an exception in NodeApiVersions.java, and a log message in NetworkClient.java.
    - Fix the slf4j log prefix used by KafkaRequestHandler logging so that request handlers on a
      controller don't look like they're on a broker.
    - Make the FinalizedVersionRange constructor public for the sake of a junit test.
    - Add unit and integration tests for the above.

Reviewers: David Arthur <mumrah@gmail.com>, Doguscan Namal <namal.doguscan@gmail.com>",2023-09-26 14:43:42,Colin Patrick McCabe,Mixed
86450bf9aca481113fadbb0ecf0eb4b180762a30,"KAFKA-15498: bump snappy-java version to 1.1.10.4 (#14434)

bump snappy-java version to 1.1.10.4, and add more tests to verify the compressed data can be correctly decompressed and read.

For LogCleanerParameterizedIntegrationTest, we increased the message size for snappy decompression since in the new version of snappy, the decompressed size is increasing compared with the previous version. But since the compression algorithm is not kafka's scope, all we need to do is to make sure the compressed data can be successfully decompressed and parsed/read.

Reviewers: Divij Vaidya <diviv@amazon.com>, Ismael Juma <ismael@juma.me.uk>, Josep Prat <josep.prat@aiven.io>, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>",2023-09-27 19:00:50,Luke Chen,Not TDD
673a25acc3ac231c5fc1bfe0fcdd3c7e57f2de91,"KAFKA-10199: Do not unlock state directories of tasks in state updater (#14442)

When Streams completes a rebalance, it unlocks state directories
all unassigned tasks. Unfortunately, when the state updater is enabled,
Streams does not look into the state updater to determine the
unassigned tasks.
This commit corrects this by adding the check.

Reviewer: Lucas Brutschy <lbrutschy@confluent.io>",2023-09-27 17:51:30,Bruno Cadonna,Mixed
aa399a335f75122d258c5cef1ffc3604b42f4052,"KAFKA-15499: Fix the flaky DeleteSegmentsDueToLogStartOffsetBreach test (#14439)

DeleteSegmentsDueToLogStartOffsetBreach configures the segment such that it can hold at-most 2 record-batches. And, it asserts that the local-log-start-offset based on the assumption that each segment will contain exactly two messages.

During leader switch, the segment can get rotated and may not always contain two records. Previously, we were checking whether the expected local-log-start-offset is equal to the base-offset-of-the-first-local-log-segment. With this patch, we will scan the first local-log-segment for the expected offset.

Reviewers: Divij Vaidya <diviv@amazon.com>",2023-09-28 15:04:37,Kamal Chandraprakash,Not TDD
dedfed06f7a472424080456c997f5200c6bef196,"KAFKA-15510: Fix follower's lastFetchedEpoch when fetch response has … (#14457)

When a fetch response has no record for a partition, validBytes is 0. We shouldn't set the last fetched epoch to logAppendInfo.lastLeaderEpoch.asScala since there is no record and it is Optional.empty. We should use currentFetchState.lastFetchedEpoch instead.

Reviewers: Divij Vaidya <diviv@amazon.com>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>, Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2023-09-28 14:14:42,chern,Not TDD
bcfc9543d141db9cf5b40f54dc971d7812f94319,"MINOR: Move TopicIdPartition class to server-common (#14418)

This patch moves the TopicIdPartition from the metadata module to the server-common module so it can be used by the group-coordinator module as well.

Reviewers: Sagar Rao <sagarmeansocean@gmail.com>, David Jacot <djacot@confluent.io>",2023-09-28 13:55:44,Ritika Reddy,Mixed
b0fd99106d3f814026f0c6ab7a58c54d65b96a3b,"MINOR: Close UnifiedLog created in tests to avoid resource leak (#14453)

Reviewers: Divij Vaidya <diviv@amazon.com>, Luke Chen <showuon@gmail.com>",2023-09-29 12:00:01,Gantigmaa Selenge,Mixed
13b119aa62bb654eed9e6ac3235dd4f242d11636,"KAFKA-15511: Handle CorruptIndexException in RemoteIndexCache (#14459)

A bug in the RemoteIndexCache leads to a situation where the cache does not replace the corrupted index with a new index instance fetched from remote storage. This commit fixes the bug by adding correct handling for `CorruptIndexException`.

Reviewers: Divij Vaidya <diviv@amazon.com>, Satish Duggana <satishd@apache.org>, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>, Alexandre Dupriez <duprie@amazon.com>",2023-09-29 12:26:46,iit2009060,Mixed
6acf69d7a257b83fbf3103772ca8d68093718274,"MINOR: Remove the client side assignor from the ConsumerGroupHeartbeat API (#14469)

As a first step, we plan to release a preview of the new consumer group rebalance protocol without the client side assignor. This patch removes all the related fields from the ConsumerGroupHeartbeat API for now. Removing fields is fine here because this API is not released yet and not exposed by default. We will add them back while bumping the version of the request when we release this part in the future.

Reviewers: Justine Olshan <jolshan@confluent.io>",2023-10-02 04:59:20,David Jacot,Mixed
6263197a62389c9dce0210cd9d65a6e601345edc,"KAFKA-15326: [9/N] Start and stop executors and cornercases (#14281)

* Implements start and stop of task executors
* Introduce flush operation to keep consumer operations out of the processing threads
* Fixes corner case: handle requested unassignment during shutdown
* Fixes corner case: handle race between voluntary unassignment and requested unassigment
* Fixes corner case: task locking future completes for the empty set
* Fixes corner case: we should not reassign a task with an uncaught exception to a task executor
* Improved logging
* Number of threads controlled from outside, of the TaskManager

Reviewers: Bruno Cadonna <bruno@confluent.io>",2023-10-02 15:41:21,Lucas Brutschy,Mixed
b6c7855475397166c4fbc79071b4aa93696519e5,"KAFKA-15449: Verify transactional offset commits (KIP-890 part 1) (#14370)

Previous commits left out TxnOffsetCommits which go through the group coordinator (not directly from the producer).

I've wired up the methods to include the transactional id and state partition to do the verification.

I've also updated UnifiedLog to verify on client and coordinator requests that are transactional.
I've not updated any sequence check logic since the sequence is always 0 on group coordinator initiated writes.

Added returned errors to Response files. Both InvalidPidMapping and InvalidTxnState will be returned and be fatal for the transactional OffsetCommit requests.

Reviewers:  David Jacot <david.jacot@gmail.com>,  Artem Livshits <alivshits@confluent.io>",2023-10-02 10:40:06,Justine Olshan,Mixed
8f8dbad564ffd9be409bb85edadbc40659cd0a56,"KAFKA-14595 ReassignPartitionsIntegrationTest rewritten in java (#14456)

This PR is part of #13247
It contains ReassignPartitionsIntegrationTest rewritten in java.
Goal of PR is reduce changes size in main PR.

Reviewers: Taras Ledkov  <tledkov@apache.org>, Justine Olshan <jolshan@confluent.io>",2023-10-02 13:22:17,Nikolay,Not TDD
7553d3f562f3af6c7f9b062b9220bcad80b00478,"KAFKA-14593: Move LeaderElectionCommand to tools (#13204)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Federico Valeri <fedevaleri@gmail.com>",2023-10-03 11:59:56,Omnia G.H Ibrahim,Mixed
2c925e9f334b0aa6c52df343c2394f00f86ac2ff,"KAFKA-15526: Simplify the LogAppendInfo class (#14470)

The LogAppendInfo class is a bit bloated in terms of class fields. That's because it is used as an umbrella class for both leader log appends and follower log appends and needs to carry fields for both. This makes the constructor for the class a bit cludgy to use. It also ends up being a bit confusing when fields are important and when they aren't. I noticed there were a few fields that didn't seem necessary.

Below is a description of changes:

firstOffset is a LogOffsetMetadata but there are no readers of the field that use anything but the messageOffset field - simplified to a long.
LogAppendInfo.errorMessage is only set in one context - when calling LogAppendInfo.unknownLogAppendInfoWithAdditionalInfo. When we use this constructor, we pass up the original exception in LogAppendResult anyway, so the field is redundant with the LogAppendResult.exception field. This allows us to simplify the handling in KAFKA-15459: Convert coordinator retriable errors to a known producer response error #14378 since there are no custom error messages we just return whatever is in the exception message.
We only use targetCompressionType when constructing the LogValidator - just inline the call instead of including it in the LogAppendInfo.
offsetsMonotonic is only used when not assigning offsets to throw an exception - just throw the exception instead of setting a field to throw later.
shallowCount is only there to determine whether there are any messages in the append. Instead, we can just check validBytes which is incremented with a non-zero value every time we increment shallowCount.

Reviewers: Justine Olshan <jolshan@confluent.io>",2023-10-03 17:32:44,David Mao,Mixed
a12f9f97c98f31d8d957ff9b816c4f73b84e0d9d,"KAFKA-14506: Implement DeleteGroups API and OffsetDelete API (#14408)

This patch implements DeleteGroups and OffsetDelete API in the new group coordinator.

Reviewers: yangy0000, Ritika Reddy <rreddy@confluent.io>, Jeff Kim <jeff.kim@confluent.io>, David Jacot <djacot@confluent.io>",2023-10-04 02:30:45,Dongnuo Lyu,Mixed
59e59fc545b17c2893120d616ea4ed170af730b8,"MINOR: Add LEAVE_GROUP_EPOCH to GroupMetadataManager (#14463)

Replacing the use a hardcoded -1 with a constant (`LEAVE_GROUP_EPOCH`) that provides more clarity. Since static members also have a magic number (-2), this will motivate future commits to use constants instead of hardcoded values.

Reviewers: Sagar Rao <sagarmeansocean@gmail.com>, David Jacot <djacot@confluent.io>",2023-10-04 03:09:16,Kirk True,Mixed
c32d2338a7e0079e539b74eb16f0095380a1ce85,"KAFKA-10199: Enable state updater by default (#13927)

Now that the implementation for the state updater is done, we can enable it by default.

This PR enables the state updater by default and fixes code that made assumptions that are not true when the state updater is enabled (mainly tests).

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Walker Carlson <wcarlson@confluent.io>",2023-10-04 13:58:44,Bruno Cadonna,Mixed
d817b1b5900e16d76ceae570d6e93d4d57783b73,"KAFKA-15415: On producer-batch retry, skip-backoff on a new leader (#14384)

When producer-batch is being retried, new-leader is known for the partition Vs the leader used in last attempt, then it is worthwhile to retry immediately to this new leader. A partition-leader is considered to be newer, if the epoch has advanced.

Reviewers: Walker Carlson <wcarlson@apache.org>, Kirk True <kirk@kirktrue.pro>, Andrew Schofield <andrew_schofield@uk.ibm.com",2023-10-05 09:11:47,Mayank Shekhar Narula,Mixed
3c054833acd90a0df647a1f9a1407c2219983369,"KAFKA-15552 Fix Producer ID ZK migration (#14506)

This patch fixes a problem where we migrate the current producer ID batch to KRaft instead of the next producer ID batch. Since KRaft stores the next batch in the log, we end up serving up a duplicate batch to the first caller of AllocateProducerIds once the KRaft controller has taken over.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-10-05 21:49:31,David Arthur,Mixed
4a6e6c7d8c2d2226046ca88027f2cc44bbea3bf6,"KAFKA-14504: Implement DescribeGroups API (#14462)

This patch implements DescribeGroups API in the new group coordinator.

Reviewers: David Jacot <djacot@confluent.io>",2023-10-06 02:25:17,Dongnuo Lyu,Mixed
7e1c453af9533aba8c19da2d08ce6595c1441fc0,"KAFKA-15356: Generate and persist directory IDs (#14291)

Reviewers: Proven Provenzano <pprovenzano@confluent.io>, Ron Dagostino <rdagostino@confluent.io>",2023-10-06 13:03:40,Igor Soarez,Mixed
1c3eb4395a15cf4f45b6dc0d39effb3dc087f5a4,"KAFKA-14912:Add a dynamic config for remote index cache size (#14381)

Reviewers: Luke Chen <showuon@gmail.com>, Satish Duggana <satishd@apache.org>, Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Divij Vaidya <diviv@amazon.com>, Subhrodip Mohanta <hello@subho.xyz>",2023-10-08 13:24:09,hudeqi,Mixed
6c23a900fcbb2b8c2c092a355921b3424041ab4f,"KAFKA-15278: Implement HeartbeatRequestManager to handle heartbeat requests (#14364)

HeartbeatRequestManager is responsible for handling the ConsumerGroupHeartbeat request and response.  The manager has the following responsibilities:
1. Sending the request to the GroupCoordinator when it is possible and necessary
2. Handling the response and update the `MembershipManagerImpl` based on the error/response it receives.
3. Handles request retries and fatal failures

For Successful heartbeat response:
- Updates the MembershipManager

For Failures handling:
- Retriables Errors: backoff and retries
- Fenced: Transition to a fenced state and reset the epoch, and retry in the next poll
- Fatal: Propagate the error to the user and fail the state machine

Reviewers: Kirk True <ktrue@confluent.io>, Lianet Magrans <lianetmr@gmail.com>, David Jacot <djacot@confluent.io>",2023-10-09 08:35:42,Philip Nee,Mixed
6e164bb9ace3ea7a1a9542904d1a01c9fd3a1b48,"KAFKA-14927: Add validation to be config keys in ConfigCommand tool (#14514)

Added validation in ConfigCommand tool, only allow characters
'([a-z][A-Z][0-9][._-])*' for config keys.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2023-10-10 13:19:13,Aman Singh,Mixed
99ce2e081c575eeb6f02a046e3b6530ca6402ad2,"KAFKA-15169: Added TestCase in RemoteIndexCache (#14482)

est Cases Covered

    1. Index Files already exist on disk but not in Cache i.e. RemoteIndexCache should not call remoteStorageManager to fetch it instead cache it from the local index file present.
    2. RSM returns CorruptedIndex File i.e. RemoteIndexCache should throw CorruptedIndexException instead of successfull execution.
    3. Deleted Suffix Indexes file already present on disk i.e. If cleaner thread is slow , then there is a chance of deleted index files present on the disk while in parallel same index Entry is invalidated. To understand more refer https://issues.apache.org/jira/browse/KAFKA-15169

Reviewers: Divij Vaidya <diviv@amazon.com>, Luke Chen <showuon@gmail.com>, Kamal Chandraprakash<kamal.chandraprakash@gmail.com>",2023-10-11 10:58:17,Arpit Goyal,Mixed
3c9031c62455e4eaa3f5d16a3bba94d7e3159fb6,"KAFKA-15507: Make AdminClient throw non-retriable exception for a new call while closing (#14455)

AdminClient will throw IllegalStateException instead of TimeoutException if it receives new calls while closing down. This is more consistent with how Consumer and Producer clients handle new calls after closed down.

Reviewers: Luke Chen <showuon@gmail.com>, Kirk True <kirk@kirktrue.pro>, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>, vamossagar12 <sagarmeansocean@gmail.com>",2023-10-11 11:41:46,Gantigmaa Selenge,Mixed
d46781d4db3f9330c64a01078b96637f75a02419,"KAFKA-15221; Fix the race between fetch requests from a rebooted follower. (#14053)

A race can happen in the following sequence.
1. Stale Fetch triggers the ISR expansion.
2. The first time we check whether the replica is eligible. Catch up? Yes. broker epoch match? Yes (the metadata cache update has not happened)
3. Metadata cache update happens.
4. During the second time check the eligibility
    a. Catch up? Yes
    b. A new fetch request comes in. It cancels the replica caught-up and updates the broker epoch
    c. broker epoch match? Yes. New fetch epoch = new metadata cache epoch
5. Send an AlterPartition request with the new broker epoch.
----------------
The solution is to make sure that the 4.a) ,4.c) and 5) use the same replica state.

Reviewers: David Mao <47232755+splett2@users.noreply.github.com>, David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>",2023-10-11 09:44:36,Calvin Liu,Mixed
5dd155f350e6f9092bd7734dbf0600dc4af80bfe,"KAFKA-15571: `StateRestoreListener#onRestoreSuspended` is never called because `DelegatingStateRestoreListener` doesn't implement `onRestoreSuspended` (#14519)

With https://issues.apache.org/jira/browse/KAFKA-10575 StateRestoreListener#onRestoreSuspended was added. But local tests show that it is never called because DelegatingStateRestoreListener was not updated to call a new method

Reviewers: Anna Sophie Blee-Goldman <sophie@responsive.dev>, Bruno Cadonna <cadonna@confluent.io>",2023-10-11 16:04:34,Levani Kokhreidze,Not TDD
aec07f76d763068feb6c1d19e4fc326cffd9c620,"KAFKA-15537: Fix metadata downgrade documentation (#14484)

In KIP-778 we introduced the ""unsafe"" (lossy) downgrade in case metadata has changes in one of the versions between target and current, as defined in MetadataVersion.

The documentation says it is possible:

""Note that the cluster metadata version cannot be downgraded to a pre-production 3.0.x, 3.1.x, or 3.2.x version once it has been upgraded. However, it is possible to downgrade to production versions such as 3.3-IV0, 3.3-IV1, etc.""

The command line tool shows that this doesn't work:

bin/kafka-features.sh --bootstrap-server :9092 downgrade --metadata 3.4 --unsafe
Could not downgrade metadata.version to 8. Invalid metadata.version 8. Unsafe metadata downgrade is not supported in this version.
1 out of 1 operation(s) failed.

In addition to unsafe, also safe metadata downgrades are not supported in practice. For example, when you upgrade to 3.5, you land on 3.5-IV2 as metadata version, which has metadata changes and won't let you to downgrade. This is true for every other release at the moment.

This change fixes the documentation to reflect that, and improves the error messages.

Signed-off-by: Federico Valeri <fedevaleri@gmail.com>

Reviewers: Luke Chen <showuon@gmail.com>, Jakub Scholz <github@scholzj.com>",2023-10-12 11:12:44,Federico Valeri,Mixed
7b5d640cc656443a078bda096d01910b3edfdb37,"KAFKA-14987; Implement Group/Offset expiration in the new coordinator (#14467)

This patch implements the groups and offsets expiration in the new group coordinator.

Reviewers: Ritika Reddy <rreddy@confluent.io>, David Jacot <djacot@confluent.io>",2023-10-11 23:45:13,Jeff Kim,Mixed
c7f730d9d9a95ce43b19a8af06e9f5be5e25609b,"MINOR: Only commit running active and standby tasks when tasks corrupted (#14508)

When tasks are found corrupted, Kafka Streams tries to commit
the non-corrupted tasks before closing and reviving the corrupted
active tasks. Besides active running tasks, Kafka Streams tries
to commit restoring active tasks and standby tasks. However,
restoring active tasks do not need to be committed since they
do not have offsets to commit and the current code does not
write a checkpoint. Furthermore, trying to commit restoring
active tasks with the state updater enabled results in the
following error:

java.lang.UnsupportedOperationException: This task is read-only
at org.apache.kafka.streams.processor.internals.ReadOnlyTask.commitNeeded(ReadOnlyTask.java:209)
...

since commitNeeded() is not a read-only method for active tasks.

In future, we can consider writing a checkpoint for active
restoring tasks in this situation. Additionally, we should
fix commitNeeded() in active tasks to be read-only.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Lucas Brutschy <lbrutschy@confluent.io>",2023-10-12 13:24:54,Bruno Cadonna,Mixed
4cf86c5d2f6355c5684ecedeb1bf96e90877244d,"KAFKA-15492: Upgrade and enable spotbugs when building with Java 21 (#14533)

Spotbugs was temporarily disabled as part of KAFKA-15485 to support Kafka build with JDK 21. This PR upgrades the spotbugs version to 4.8.0 which adds support for JDK 21 and enables it's usage on build again.

Reviewers: Divij Vaidya <diviv@amazon.com>",2023-10-12 14:09:10,Ismael Juma,Not TDD
58dfa1cc815e3bd36e67407b190c60025338f355,"MINOR - KAFKA-15550: Validation for negative target times in offsetsForTimes (#14503)

The current KafkaConsumer offsetsForTimes fails with IllegalArgumentException if negative target timestamps are provided as arguments. This change includes the same validation and tests for the new consumer implementation (and some improved comments for the updateFetchPositions)

Reviewer: Lucas Brutschy <lbrutschy@confluent.io>",2023-10-13 09:59:57,Lianet Magrans,Mixed
4bad90835b1bb7a4fe63410e3ddbb11d0eec4a4d,"KAFKA-15465: Don't throw if MirrorMaker not authorized to create internal topics. (#14388)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ahmed Hibot",2023-10-13 12:53:09,Omnia G.H Ibrahim,Mixed
cd1b7639cbeaf615bf370ec8f52ba746b03a39a9,"MINOR: cleanup some warning in Kafka Streams examples (#14547)

Reviewers: Guozhang Wang <wangguoz@gmail.com>",2023-10-13 19:00:22,Matthias J. Sax,Not TDD
1c8bb61a43d3ad1fd7a10eb3947342ceba783c4e,"KAFKA-15387: Deprecate Connect's redundant task configurations endpoint (#14361)

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Sagar Rao <sagarmeansocean@gmail.com>",2023-10-14 14:46:50,Yash Mayya,Not TDD
b0b8693c725c1edd6256f707d6bee903d5d5fa19,"KAFKA-15536: Dynamically resize remoteIndexCache (#14511)

Dynamically resize remoteIndexCache

Reviewers: Christo Lolov <lolovc@amazon.com>, Luke Chen <showuon@gmail.com>, Divij Vaidya <diviv@amazon.com>, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>",2023-10-16 15:24:36,hudeqi,Mixed
4150595b0a2e0f45f2827cebc60bcb6f6558745d,"KAFKA-14684: Replace EasyMock/PowerMock with Mockito in WorkerSinkTaskThreadedTest (#14505)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Christo Lolov <christololov@gmail.com>",2023-10-16 11:24:52,Hector Geraldino,Not TDD
1073d434ec98e64afca1979cd18d3244b133e688,"KAFKA-14481: Move LogSegment/LogSegments to storage module (#14529)

A few notes:
* Delete a few methods from `UnifiedLog` that were simply invoking the related method in `LogFileUtils`
* Fix `CoreUtils.swallow` to use the passed in `logging`
* Fix `LogCleanerParameterizedIntegrationTest` to close `log` before reopening
* Minor tweaks in `LogSegment` for readability
 
For broader context on this change, please check:

* KAFKA-14470: Move log layer to storage module

Reviewers: Divij Vaidya <diviv@amazon.com>, Satish Duggana <satishd@apache.org>",2023-10-16 06:37:30,Ismael Juma,Mixed
5c9db5e7353372234c967e27fc6467fb49a48bab,"KAFKA-15390: Do not return fenced broker in FetchResponse.preferredReplica (#14272)

Do not return fenced brokers from metadataCache.getPartitionReplicaEndpoints, since that could lead to
them getting used as preferred read replicas.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-10-16 15:08:40,dengziming,Not TDD
da314ee48c31f85e99301c37f26710f67383e8de,"KAFKA-15532: non active controllers return 0 for ZkWriteBeforelag (#14478)

Since only the active controller is performing the dual-write to ZK during a migration, it should be the only controller
to report the ZkWriteBehindLag metric.

Currently, if the controller fails over during a migration, the previous active controller will incorrectly report its last
value for ZkWriteBehindLag forever. Instead, it should report zero.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, David Arthur <mumrah@gmail.com>",2023-10-16 15:22:50,mannoopj,Mixed
69e591db3a7329a8bb984f068596d8658a8618b3,"MINOR: Rewrite/Move KafkaNetworkChannel to the `raft` module (#14559)

This is now possible since `InterBrokerSend` was moved from `core` to `server-common`.
Also rewrite/move `KafkaNetworkChannelTest`.

The scala version of `KafkaNetworkChannelTest` passed with the changes here (before I
deleted it).

Reviewers: Justine Olshan <jolshan@confluent.io>, José Armando García Sancio <jsancio@users.noreply.github.com>",2023-10-16 20:10:31,Ismael Juma,Mixed
9af1e74b5e94536ebf2526af82d9d585a0e1e820,"KAFKA-14596: Move TopicCommand to tools (#13201)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Federico Valeri <fedevaleri@gmail.com>",2023-10-17 11:40:15,Omnia G.H Ibrahim,Mixed
e7e399b9409b42f82d7ce57b99a461c465e5849d,"MINOR: allow removing a suspended task from task registry. (#14555)

When we get a suspended task re-assigned in the eager rebalance protocol, we have to add the task back to the state updater so that it has a chance to catch up with its change log.

This was prevented by a check in Tasks, which disallows removing SUSPENDED tasks from the task registry. I couldn't find a reason why this must be an invariant of the task registry, so this weakens the check.

The error happens in the integration between TaskRegistry and TaskManager. However, this change anyway adds unit tests to more closely specify the intended behavior of the two modules.

Reviewers: Bruno Cadonna <bruno@confluent.io>",2023-10-17 14:32:41,Lucas Brutschy,Mixed
abee8f711c5c9ab6cae80406ce8ccd65f62841ce,"KAFKA-14519; [1/N] Implement coordinator runtime metrics (#14417)

Implements the following metrics:

kafka.server:type=group-coordinator-metrics,name=num-partitions,state=loading
kafka.server:type=group-coordinator-metrics,name=num-partitions,state=active
kafka.server:type=group-coordinator-metrics,name=num-partitions,state=failed
kafka.server:type=group-coordinator-metrics,name=event-queue-size
kafka.server:type=group-coordinator-metrics,name=partition-load-time-max
kafka.server:type=group-coordinator-metrics,name=partition-load-time-avg
kafka.server:type=group-coordinator-metrics,name=thread-idle-ratio-min
kafka.server:type=group-coordinator-metrics,name=thread-idle-ratio-avg
The PR makes these metrics generic so that in the future the transaction coordinator runtime can implement the same metrics in a similar fashion.

Also, CoordinatorLoaderImpl#load will now return LoadSummary which encapsulates the start time, end time, number of records/bytes.

Co-authored-by: David Jacot <djacot@confluent.io>

Reviewers:  Ritika Reddy <rreddy@confluent.io>, Calvin Liu <caliu@confluent.io>, David Jacot <djacot@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-10-17 16:06:23,Jeff Kim,Mixed
9b468fb278701be836a2641650356907bf84860a,"MINOR: Do not end Javadoc comments with `**/` (#14540)

Reviewers: Bruno Cadonna <bruno@confluent.io>, Bill Bejeck <bill@confluent.io>, Hao Li <hli@confluent.io>, Josep Prat <josep.prat@aiven.io>",2023-10-17 21:11:04,Matthias J. Sax,Not TDD
8aee2976699072c8f2af1dfccdc8f7a133b6113d,"MINOR: Various Java cleanups in core (#14561)


Reviewers: Josep Prat <josep.prat@aiven.io>",2023-10-18 11:49:25,Mickael Maison,Mixed
48449b68fd70c96451e03afe7d3cd5b2800240fa,"KAFKA-15554: Client state changes for handling one assignment at a time & minor improvements (#14413)

This patch includes:
- target assignment changes : accepting only one at a time according to the updated protocol.
- changes for error handling, leaving responsibility in the heartbeatManager and exposing only the functionality for when the state needs to be updated (on successful HB, on fencing, on fatal failure)
- allow transitions for failures when joining
- tests & minor improvements/fixes addressing initial version review

Reviewers: Kirk True <ktrue@confluent.io>, Philip Nee <pnee@confluent.io>, David Jacot <djacot@confluent.io>",2023-10-18 08:10:18,Lianet Magrans,Mixed
26aa353dc1c34f932e6d05d5b270a7f3690c36cf,"KAFKA-15616: Client telemetry states and transition (KIP-714) (#14566)

Part of KIP-714.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Philip Nee <pnee@confluent.io>, Kirk True <ktrue@confluent.io>, Walker Carlson <wcarlson@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2023-10-18 21:43:05,Apoorv Mittal,Mixed
8f3731e2bd14485ab6a5e29afe9bfbfdc1aee432,"KAFKA-15454: Add support for OffsetCommit version 9 in admin client (#14571)

This patch adds support for OffsetCommit version 9 in the admin client. It mainly allows handling two new error codes `STALE_MEMBER_EPOCH` and `GROUP_ID_NOT_FOUND ` introduced as part of KIP-848.

Reviewers: David Jacot <djacot@confluent.io>",2023-10-19 07:48:12,vamossagar12,Not TDD
36abc8dcea1a418550875e2a8684b9c9d400464d,"KAFKA-15604: Telemetry API request and response schemas and classes (KIP-714) (#14554)

Initial PR for [KIP-714](https://cwiki.apache.org/confluence/display/KAFKA/KIP-714%3A+Client+metrics+and+observability) - [KAFKA-15601](https://issues.apache.org/jira/browse/KAFKA-15601).

This PR defines json request and response schemas for the new Telemetry APIs and implements the corresponding java classes.

Reviewers: 
Andrew Schofield <andrew_schofield@uk.ibm.com>, Kirk True <ktrue@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Walker Carlson <wcarlson@apache.org>",2023-10-19 10:55:21,Apoorv Mittal,Mixed
bbdf6de88a00a8836f6b278a8affd7bc53d2a748,"KAFKA-15527: Add reverseRange and reverseAll query over kv-store in IQv2 (#14477)

Implements KIP-985.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-10-19 10:16:19,Hanyu Zheng,Not TDD
14029e2ddd1f5084d426ea8280abfad249988c0a,"KAFKA-15582: Identify clean shutdown broker (#14465)

The PR includes:

* Added a new class of CleanShutdownFile which helps write and read from a clean shutdown file.
* Updated the BrokerRegistration API.
* Client side handling for the broker epoch.
* Minimum work on the controller side.

Reviewers: Jun Rao <junrao@gmail.com>",2023-10-19 10:25:23,Calvin Liu,Mixed
af747fbfed7e81617c3b3ad0e4dc8c857aa9502b,"KAFKA-15581: Introduce ELR (#14312)

This patch introduces preliminary changes for Eligible Leader Replicas (KIP-966)

* New MetadataVersion 16 (3.7-IV1)
* New record versions for PartitionRecord and PartitionChangeRecord
* New tagged fields on PartitionRecord and PartitionChangeRecord
* New static config ""eligible.leader.replicas.enable"" to gate the whole feature

Reviewers: Artem Livshits <alivshits@confluent.io>, David Arthur <mumrah@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",2023-10-19 14:05:15,Calvin Liu,Mixed
c81a7252195261f649faba166ee723552bed4d81,"KAFKA-15534: Inject request completion time when the request failed (#14532)

Currently, we aren't able to access the request completion time if the request is completed exceptionally, which results in many system calls. This is not ideal because these system calls can add up. Instead, time is already retrieved on the top of the background thread event loop, which is then propagated into the NetworkClientDelegate.poll.

In this PR - I store the completion time in the handler, so that it becomes accessible in the callbacks.

Reviewer: Bruno Cadonna <cadonna@apache.org>",2023-10-20 09:47:25,Philip Nee,Mixed
091eb9b349ea2a383affd3089500ed855c5e4e17,"KAFKA-15428: Cluster-wide dynamic log adjustments for Connect (#14538)

Reviewers: Greg Harris <greg.harris@aiven.io>, Yang Yang <yayang@uber.com>, Yash Mayya <yash.mayya@gmail.com>",2023-10-20 09:52:37,Chris Egerton,Mixed
4083cd627e9b62a979d1f3b312b6bacbbbee822c,"KAFKA-15607: Fix NPE in MirrorCheckpointTask::syncGroupOffset (#14587)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-10-20 12:17:51,hudeqi,Mixed
e8c89693300660240cd85fb79344d01316fe1267,"KAFKA-15626: Replace verification guard object with an specific type (#14568)

I've added a new class with an incrementing atomic long to represent the verification guard. Upon creation of verification guard, we will increment this value and assign it to the guard.

The expected behavior is the same as the object guard, but with better debuggability with the string value and type safety (I found a type safety issue in the current code when implementing this)

Reviewers: Ismael Juma <ismael@juma.me.uk>, Artem Livshits <alivshits@confluent.io>",2023-10-20 14:26:20,Justine Olshan,Mixed
4371214fbef1e6c1719ce740f408d962d4b25007,"KAFKA-15378: fix streams upgrade system test (#14539)

Fixing bad test setup. We tried to fix an upgrade bug for FK-joins in 3.1 release, but it later turned out that the PR was not sufficient to fix it. We finally fixed in 3.4 release.

This PR updates the system test matrix to only test working versions with FK-joins, limited to available test versions.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Hao Li <hli@confluent.io>, Mickael Maison <mickael.maison@gmail.com>",2023-10-20 16:20:00,Matthias J. Sax,Not TDD
9c77c17c4eae19af743e551e8e7d8b49b07c4e99,"KAFKA-15664: Add 3.4 Streams upgrade system tests (#14601)


Reviewers: Luke Chen <showuon@gmail.com>,  Matthias J. Sax <mjsax@apache.org>",2023-10-23 10:33:59,Mickael Maison,Not TDD
1a3aca305e7f51dc491723b80c3d60b4ba4b6f1d,"KAFKA-15457: Add support for OffsetFetch version 9 in admin client (#14611)

This patch adds support for OffsetFetch version 9 in the admin client. It mainly allows handling two new error codes `STALE_MEMBER_EPOCH` and `UNKNOWN_MEMBER_ID`  introduced as part of KIP-848.

Reviewers: David Jacot <djacot@confluent.io>",2023-10-23 02:42:21,vamossagar12,Not TDD
27a155c80a5cab62e625d9f49a313a8227f599ab,"MINOR: Fix typos in build.gradle, tests and trogdor (#14574)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, hudeqi <1217150961@qq.com>",2023-10-23 12:30:57,shuoer86,Not TDD
8b9f6d17f2a62f7dbb1810de8aaac248a84556cc,"KAFKA-15093: Add 3.5 Streams upgrade system tests (#14602)


Reviewers: Matthias J. Sax <mjsax@apache.org>",2023-10-23 13:26:50,Mickael Maison,Not TDD
4612fe42af0df0a4c1affaf66c55d01eb6267ce3,"KAFKA-15481: Fix concurrency bug in RemoteIndexCache (#14483)

RemoteIndexCache has a concurrency bug which leads to IOException while fetching data from remote tier.

The bug could be reproduced as per the following order of events:-

Thread 1 (cache thread): invalidates the entry, removalListener is invoked async, so the files have not been renamed to ""deleted"" suffix yet.
Thread 2: (fetch thread): tries to find entry in cache, doesn't find it because it has been removed by 1, fetches the entry from S3, writes it to existing file (using replace existing)
Thread 1: async removalListener is invoked, acquires a lock on old entry (which has been removed from cache), it renames the file to ""deleted"" and starts deleting it
Thread 2: Tries to create in-memory/mmapped index, but doesn't find the file and hence, creates a new file of size 2GB in AbstractIndex constructor. JVM returns an error as it won't allow creation of 2GB random access file.

This commit fixes the bug by using EvictionListener instead of RemovalListener to perform the eviction atomically with the file rename. It handles the manual removal (not handled by EvictionListener) by using computeIfAbsent() and enforcing atomic cache removal & file rename.

Reviewers: Luke Chen <showuon@gmail.com>, Divij Vaidya <diviv@amazon.com>, Arpit Goyal 
<goyal.arpit.91@gmail.com>, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>",2023-10-23 14:50:46,Jotaniya Jeel,Mixed
d144b7ee387308a59e52cbdabc7b66dd3b2926cc,"KAFKA-15326: [10/N] Integrate processing thread (#14193)

- Introduce a new internal config flag to enable processing threads
- If enabled, create a scheduling task manager inside the normal task manager (renamings will be added on top of this), and use it from the stream thread
- All operations inside the task manager that change task state, lock the corresponding tasks if processing threads are enabled.
- Adds a new abstract class AbstractPartitionGroup. We can modify the underlying implementation depending on the synchronization requirements. PartitionGroup is the unsynchronized subclass that is going to be used by the original code path. The processing thread code path uses a trivially synchronized SynchronizedPartitionGroup that uses object monitors. Further down the road, there is the opportunity to implement a weakly synchronized alternative. The details are complex, but since the implementation is essentially a queue + some other things, it should be feasible to implement this lock-free.
- Refactorings in StreamThreadTest: Make all tests use the thread member variable and add tearDown in order avoid thread leaks and simplify debugging. Make the test parameterized on two internal flags: state updater enabled and processing threads enabled. Use JUnit's assume to disable all tests that do not apply.
Enable some integration tests with processing threads enabled.

Reviewer: Bruno Cadonna <bruno@confluent.io>",2023-10-24 10:17:55,Lucas Brutschy,Mixed
2b233bfa5f35bf237effe8c5202fd2b80c601943,"KAFKA-14274 [6, 7]: Introduction of fetch request manager (#14406)

Changes:

1. Introduces FetchRequestManager that implements the RequestManager
   API for fetching messages from brokers. Unlike Fetcher, record
   decompression and deserialization is performed on the application
   thread inside CompletedFetch.
2. Restructured the code so that objects owned by the background thread
   are not instantiated until the background thread runs (via Supplier)
   to ensure that there are no references available to the
   application thread.
3. Ensuring resources are properly using Closeable and using
   IdempotentCloser to ensure they're only closed once.
4. Introduces ConsumerTestBuilder to reduce a lot of inconsistency in
   the way the objects were built up for tests.

Reviewers: Philip Nee <pnee@confluent.io>, Lianet Magrans <lianetmr@gmail.com>, Jun Rao<junrao@gmail.com>",2023-10-24 13:03:05,Kirk True,Mixed
339d2556c64e9ec379eb94db547d56878e68f438,"KAFKA-15605: Fix topic deletion handling during ZK migration (#14545)

This patch adds reconciliation logic to migrating ZK brokers to deal with pending topic deletions as well as missed StopReplicas.

During the hybrid mode of the ZK migration, the KRaft controller is asynchronously sending UMR and LISR to the ZK brokers to propagate metadata. Since this process is essentially ""best effort"" it is possible for a broker to miss a StopReplicas. The new logic lets the ZK broker examine its local logs compared with the full set of replicas in a ""Full"" LISR. Any local logs which are not present in the set of replicas in the request are removed from ReplicaManager and marked as ""stray"".

To avoid inadvertent data loss with this new behavior, the brokers do not delete the ""stray"" partitions. They will rename the directories and log warning messages during log recovery. It will be up to the operator to manually delete the stray partitions. We can possibly enhance this in the future to clean up old stray logs.

This patch makes use of the previously unused Type field on LeaderAndIsrRequest. This was added as part of KIP-516 but never implemented. Since its introduction, an implicit 0 was sent in all LISR. The KRaft controller will now send a value of 2 to indicate a full LISR (as specified by the KIP). The presence of this value acts as a trigger for the ZK broker to perform the log reconciliation.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-10-26 18:13:52,David Arthur,Mixed
68a5072f54aa73460743b36c06f52b6263549a17,"KAFKA-15578: System Tests for running old protocol with new coordinator (#14524)

This patch adds configs to facilitate the testing with the new group coordinator (KIP-848) in kraft mode. Only one test files is converted at the moment. The others will follow.

Reviewers: Ian McDonald <imcdonald@confluent.io>, David Jacot <djacot@confluent.io>",2023-10-27 10:33:40,Ritika Reddy,Not TDD
37715862d701d9b1e340b8dd96d29b5591187d64,"KAFKA-15704: Set missing ZkMigrationReady field on ControllerRegistrationRequest

This field was missed by the initial KIP-919 PR(s). The result is that migrations can't begin since
the controllers will never become ready. This patch fixes that as well as pulls over some fixes
from the 3.6 branch.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-10-27 14:16:24,David Arthur,Mixed
fa36a7f2d664bac8524f830663023b83f5ee090b,"MINOR: Push down logic from TransactionManager to TxnPartitionEntry (#14591)

And encapsulate TxnPartitionEntry state.

This makes it easier to understand the behavior and the paths through
which the state is updated.

Reviewers: Justine Olshan <jolshan@confluent.io>",2023-10-28 07:27:20,Ismael Juma,Mixed
2e2f32c05008cdd7009e5f76fdd92f98996aab84,"KAFKA-15628: Refactor ConsumerRebalanceListener invocation for reuse (#14638)

Straightforward refactoring to extract an inner class and methods related to `ConsumerRebalanceListener` for reuse in the KIP-848 implementation of the consumer group protocol. Also using `Optional` to explicitly mark when a `ConsumerRebalanceListener` is in use or not, allowing us to make some (forthcoming) optimizations when there is no listener to invoke.

Reviewers: David Jacot <djacot@confluent.io>",2023-10-30 11:51:30,Kirk True,Mixed
4d047114518ea30519a31b6297f2bf906e59841e,"KAFKA-15602: revert KAFKA-4852 (#14617)

This PR reverts
 - https://github.com/apache/kafka/commit/51dbd175b08e78aeca03d6752847aa5f23c98659
 - https://github.com/apache/kafka/commit/496ae054c2d43c0905167745bfb2f4a0725e9fc2

Reviewers:  Philip Nee <pnee@confluent.io>, Guozhang Wang <guozhang@confluent.io>",2023-10-30 13:14:15,Matthias J. Sax,Not TDD
8f8ad6db384ce30e8a5d848d3ed826a3f7a54dfe,"KAFKA-15582: Move the clean shutdown file to the storage package (#14603)

A follow-up change to move the clean shutdown file to the storage package.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",2023-10-30 16:27:40,Calvin Liu,Mixed
57fd8f4c36af05156168056d3e181072804d104d,"KAFKA-15632: Drop the invalid remote log metadata events (#14576)

Reviewers: Christo Lolov <lolovc@amazon.com>, Luke Chen <showuon@gmail.com>, Satish Duggana <satishd@apache.org>",2023-10-31 15:21:33,Kamal Chandraprakash,Mixed
a48ca490e45b4af06c7cc60233f95702e347d248,"KAFKA-15643: Fix error logged when unload is called on a broker that was never a coordinator. (#14657)

When a new leader is elected for a __consumer_offset partition, the followers are notified to unload the state. However, only the former leader is aware of it. The remaining follower prints out the following error:
`ERROR [GroupCoordinator id=1] Execution of UnloadCoordinator(tp=__consumer_offsets-1, epoch=0) failed due to This is not the correct coordinator.. (org.apache.kafka.coordinator.group.runtime.CoordinatorRuntime)`
The error is actually correct and expected when in the remaining follower case, however this could be misleading. This patch handles the case gracefully.

Reviewers: David Jacot <djacot@confluent.io>",2023-10-31 03:09:32,Ritika Reddy,Mixed
7bdd1a015e2a91192c0ea07b39bd4d9195472763,"KAFKA-15647: Fix the different behavior in error handling between the old and new group coordinator (#14589)

In `KafkaApis.scala`, we build the API response differently if exceptions are thrown during the API execution. Since the new group coordinator only populates the response with error code instead of throwing an exception when an error occurs, there may be different behavior between the existing group coordinator and the new one.

This patch:
- Fixes the response building in `KafkaApis.scala` for the two APIs affected by such difference -- OffsetFetch and OffsetDelete.
- In `GroupCoordinatorService.java`, returns a response with error code instead of a failed future when the coordinator is not active.

Reviewers: David Jacot <djacot@confluent.io>",2023-10-31 03:11:52,Dongnuo Lyu,Mixed
47b468bb8ce893e7b5d867adf0da1470fae7d638,"MINOR: Remove ambiguous constructor (#14598)

One of the comments in https://issues.apache.org/jira/browse/KAFKA-15534 : #14532

that the constructor taking a BiConsumer is rather confusing. Removing this constructor and allow the request to take a callback using whenComplete method.

Reviewers: Kirk True <ktrue@confluent.io>, Bruno Cadonna <cadonna@apache.org>",2023-10-31 16:05:43,Philip Nee,Mixed
b5c24974ae2967824d1ec34b5b02121399a5e2f9,"Kafka 12317:  Relax non-null key requirement in Kafka Streams (#14174)

[KIP-962](https://cwiki.apache.org/confluence/display/KAFKA/KIP-962%3A+Relax+non-null+key+requirement+in+Kafka+Streams)

The key requirments got relaxed for the followinger streams dsl operator:

left join Kstream-Kstream: no longer drop left records with null-key and call ValueJoiner with 'null' for right value.
outer join Kstream-Kstream: no longer drop left/right records with null-key and call ValueJoiner with 'null' for right/left value.
left-foreign-key join Ktable-Ktable: no longer drop left records with null-foreign-key returned by the ForeignKeyExtractor and call ValueJoiner with 'null' for right value.
left join KStream-Ktable: no longer drop left records with null-key and call ValueJoiner with 'null' for right value.
left join KStream-GlobalTable: no longer drop records when KeyValueMapper returns 'null' and call ValueJoiner with 'null' for right value.

Reviewers: Walker Carlson <wcarlson@apache.org>",2023-10-31 11:09:42,Florin Akermann,Not TDD
ed3fa83d385bbe2fa6dc4943660f56fec708bbc8,"KAFKA-15669: Implement telemetry metric naming strategy (KIP-714) (#14619)

The PR defines the naming convention for telemetry metric names for KIP-714 - jira. Telemetry metric name should be dot separated and tags should be snake case.

PR adds the interface which will be used in MetricsReporter implementation to construct metric names.

Reviewers: Xavier Léauté <xvrl@apache.org>, Walker Carlson <wcarlson@apache.org>, Matthias J. Sax <mjsax@apache.org>, Andrew Schofield <andrew_schofield@uk.ibm.com>",2023-10-31 15:35:02,Apoorv Mittal,Mixed
76b1b50b644149e77ee1ec42d882e2cb80742bdf,"KAFKA-14595 Move ReassignPartitionsCommand to java (#13247)

This PR contains changes required to move PartitionReassignmentState class to java code.

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Justine Olshan <jolshan@confluent.io>, Federico Valeri <fedevaleri@gmail.com>, Taras Ledkov Taras Ledkov <tledkov@apache.org>, Kamal Chandraprakash<kamal.chandraprakash@gmail.com>,",2023-10-31 17:29:05,Nikolay,Not TDD
eca85029904612d35da00ff34e9118d96968bd4e,"KAFKA-14484: [1/N] Move PartitionMetadataFile to storage module (#14607)

This PR moves PartitionMetadataFile to the storage module.

Existing unit tests in UnifiedLogTest like testLogFlushesPartitionMetadataOnAppend should suffice.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Jun Rao <junrao@gmail.com>",2023-11-01 09:40:45,Alok Thatikunta,Mixed
a9565a799f3f87eb1d932b114dde7373748551ac,"KAFKA-15627: KIP-951's Leader discovery optimisations on the client (#14685)

This implements the leader discovery optimisations for the client on [KIP-951](https://cwiki.apache.org/confluence/display/KAFKA/KIP-951%3A+Leader+discovery+optimisations+for+the+client).

Optimisation1: On discovering a new leader, produce-batch should skip any retry-backoff. This was implemented in [KAFKA-15415](https://issues.apache.org/jira/browse/KAFKA-15415)
Optimisation2: FetchResponse/ProduceResponse would return new leader info. This information is then used to update the Metadata cached.
This PR focuses on optimisation2 from above. Additionally it fixes a bug that got introduced to MetadataCache.java, details inline in a comment.

Reviewers: Walker Carlson <wcarlson@apache.org>, Andrew Schofield <andrew_schofield@uk.ibm.com>, Kirk True <ktrue@confluent.io>",2023-11-01 14:53:55,Mayank Shekhar Narula,Mixed
d33a4a880fca916c04c0b051cbfc46cda652876b,"KAFKA-15614: [Minor] Renaming getter and correcting code comments (#14684)

Reviewers:  Andrew Schofield <aschofield@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2023-11-01 21:45:31,Apoorv Mittal,Mixed
7b0c07640c22cd3ecbc689832e7948ee96640a7f,"KAFKA-15562: ensure commit request manager handles errors correctly (#14639)

The current commitRequestManager lacks logic handling various failures. In the patch I addressed the following gap:

 * Network disconnection should disconnect the coordinator node
 * Handling and testing various of fatal and retriable errors scenarios
 * Ensure the time returned in the poll results is Long.MAX or the minimum of all the inflight request's remainingBackoffMs. Because we need to respect the backoff.

Reviewer: Lucas Brutschy <lbrutschy@confluent.io>",2023-11-02 09:58:31,Philip Nee,Mixed
9911fab1a1a95b7783c21fef75f043ea42fea790,"KAFKA-15432: RLM Stop partitions should not be invoked for non-tiered storage topics (#14667)

Reviewers: Christo Lolov <lolovc@amazon.com>, Divij Vaidya <diviv@amazon.com>, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>",2023-11-02 10:00:15,hudeqi,Mixed
6e44a3f12d753d10881ba9dc5e93205486e3981c,"KAFKA-15679: Consumer configurations for group protocol (#14642)

This patch adds the `group.protocol` and `group.remote.assignor` configurations as described in KIP-848.

Reviewers: Kirk True <ktrue@confluent.io>, Lucas Brutschy <lbrutschy@confluent.io>, Andrew Schofield <aschofield@confluent.io>, David Jacot <djacot@confluent.io>",2023-11-02 05:26:20,Philip Nee,Mixed
0390d5b1a24f6f4d0f431928dd009aeb76b3895d,"KAFKA-15355: Message schema changes (#14290)

Reviewers: Christo Lolov <lolovc@amazon.com>, Colin P. McCabe <cmccabe@apache.org>, Proven Provenzano <pprovenzano@confluent.io>, Ron Dagostino <rdagostino@confluent.io>",2023-11-02 09:46:05,Igor Soarez,Mixed
4d8efa94cbe6fd74d23dae2608058db52521bb2c,"MINOR: MetaProperties refactor, part 1 (#14678)

Since we have added directory.id to MetaProperties, it is no longer safe
to assume that all directories on a node contain the same MetaProperties.
Therefore, we should get rid of places where we are using a single
MetaProperties object to represent the settings of an entire cluster.
This PR removes a few such cases. In each case, it is sufficient just to
pass cluster ID.

The second part of this change refactors KafkaClusterTestKit so that we
convert paths to absolute before creating BrokerNode and ControllerNode
objects, rather than after. This prepares the way for storing an
ensemble of MetaProperties objects in BrokerNode and ControllerNode,
which we will do in a follow-up change.

Reviewers: Ron Dagostino <rndgstn@gmail.com>",2023-11-02 10:26:52,Colin Patrick McCabe,Mixed
a672a19e8093ee45dc37e6f4a86e32dbd0ad6e15,"MINOR: small optimization for DirectoryId.random

DirectoryId.random doesn't need to instantiate the first 100 IDs to check if an ID is one of them.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Justine Olshan <jolshan@confluent.io>, Proven Provenzano <93720617+pprovenzano@users.noreply.github.com>",2023-11-02 11:29:11,Colin P. McCabe,Mixed
e3dd60ef3cd22d4547b967309d988ab5801e27e7,HOTFIX: fix checkstyle,2023-11-02 11:35:44,Colin P. McCabe,Mixed
a53147e7d904de4efffca6c3db0f2137d522a2ec,"KAFKA-15673: Adding client metrics resource types (KIP-714) (#14621)

This PR adds resources to store and handle client metrics needed for KIP-714.

Changes include:

Adding CLIENT_METRICS to resource type
Corresponding DYNAMIC client configurations in resources.
Changes to support dynamic loading of configuration on changes.
Changes to support API calls to fetch data stored against the new resource.
Test cases for the changes.

Reviewers: Andrew Schofield <andrew_schofield@uk.ibm.com>, Philip Nee <pnee@confluent.io>, Jun Rao <junrao@gmail.com>",2023-11-03 14:51:50,Apoorv Mittal,Mixed
1e7e9ce91897e03f5611cd74f6e34f723a586ab6,"KAFKA 14515: Optimized Uniform Rack Aware Assignor (#14416)

This patch adds the Optimized Uniform Rack Aware Assignor.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, David Jacot <djacot@confluent.io>",2023-11-05 22:33:48,Ritika Reddy,Mixed
ca05da95c337f051e721464588d1b6678e8f2afb,"KAFKA-15680: Fix sink task partition-count metric when cooperative consumer protocol is used (#14630)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-11-06 11:32:05,kumarpritam863,Mixed
505e5b3eaa62696c038e53104d568d23512559a6,"KAFKA-15584: Leader election with ELR (#14593)

The patch includes the following changes as part of KIP-966

* Allow ISR shrink to empty
* Allow leader election with ELR members
* Allow electing the last known leader

Reviewers: Artem Livshits <alivshits@confluent.io>, David Arthur <mumrah@gmail.com>",2023-11-06 17:21:51,Calvin Liu,Mixed
febf0fb5739ea86a6082e4c93da0101d216e5279,"KAFKA-15774: introduce internal StoreFactory (#14659)

This PR sets up the necessary prerequisites to respect configurations such as dsl.default.store.type and the dsl.store.suppliers.class (introduced in #14648) without requiring them to be passed in to StreamBuilder#new(TopologyConfig) (passing them only into new KafkaStreams(...).

It essentially makes StoreBuilder an external-only API and internally it uses the StoreFactory equivalent. It replaces KeyValueStoreMaterializer with an implementation of StoreFactory that creates the store builder only after configure() is called (in a Future PR we will create the missing equivalents for all of the places where the same thing happens for window stores, such as in all the *WindowKStreamImpl classes)

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2023-11-06 17:30:58,Almog Gavra,Mixed
edc7e10a745c350ad1efa9e4866370dc8ea0e034,"KAFKA-15583: Enforce HWM advance only if partition is not under-min-ISR (#14594)

Only advance the HWM for a partition if the ISR set is equal to or above the min ISR config. This patch also sets an upper bound on the min ISR config so it cannot exceed the number of replicas.

Reviewers: David Arthur <mumrah@gmail.com>",2023-11-07 10:24:40,Calvin Liu,Mixed
91fa196930ece7342f38a5404dfc09cf607916eb,"KAFKA-15653: Pass requestLocal as argument to callback so we use the correct one for the thread (#14629)

With the new callback mechanism we were accidentally passing context with the wrong request local. Now include a RequestLocal as an explicit argument to the callback.

Also make the arguments passed through the callback clearer by separating the method out.

Added a test to ensure we use the request handler's request local and not the one passed in when the callback is executed via the request handler.

Reviewers: Ismael Juma <ismael@juma.me.uk>,  Divij Vaidya <diviv@amazon.com>, David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>, Artem Livshits <alivshits@confluent.io>, Jun Rao <junrao@gmail.com>,",2023-11-07 15:14:17,Justine Olshan,Mixed
f1e58a35d7aebbe72844faf3e5019d9aa7a85e4a,"MINOR: Do not checkpoint standbys when handling corrupted tasks (#14709)

When a task is corrupted, uncorrupted tasks are committed. That is also true for standby tasks. Committing standby tasks actually means that they are checkpointed.

When the state updater is enabled, standbys are owned by the state updater. The stream thread should not checkpoint them when handling corrupted tasks. That is not a big limitation since the state updater periodically checkpoints standbys anyway. Additionally, when handling corrupted tasks the important thing is to commit active running tasks to abort the transaction. Committing standby tasks do not abort any transaction.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Lucas Brutschy <lbrutschy@confluent.io>",2023-11-08 16:09:24,Bruno Cadonna,Mixed
81cceedf7e7985160397459ca0f7a6fbbfd3b019,"MINOR: Delete task-level commit sensor (#14677)

The task-level commit metrics were removed without deprecation in KIP-447 and the corresponding PR #8218. However, we forgot to update the docs and to remove the code that creates the task-level commit sensor.
This PR removes the task-level commit metrics from the docs and removes the code that creates the task-level commit sensor. The code was effectively dead since it was only used in tests.

Reviewers: Guozhang Wang <wangguoz@gmail.com>, Matthias J. Sax <matthias@confluent.io>",2023-11-09 15:37:13,Bruno Cadonna,Mixed
39c6170aa96e4c9840ac469d1b43bb059f0513af,"KAFKA-15693: Immediately reassign lost connectors and tasks when scheduled rebalance delay is disabled (#14647)

Reviewers: Sagar Rao <sagarmeansocean@gmail.com>, Yash Mayya <yash.mayya@gmail.com>",2023-11-09 10:48:43,Chris Egerton,Mixed
7060c08d6f9b0408e7f40a90499caf2e636fac61,"MINOR: Rewrite the meta.properties handling code in Java and fix some issues #14628 (#14628)

meta.properties files are used by Kafka to identify log directories within the filesystem.
Previously, the code for handling them was in BrokerMetadataCheckpoint.scala. This PR rewrites the
code for handling them as Java and moves it to the apache.kafka.metadata.properties namespace. It
also gets rid of the separate types for v0 and v1 meta.properties objects. Having separate types
wasn't so bad back when we had a strict rule that zk clusters used v0 and kraft clusters used v1.
But ZK migration has blurred the lines. Now, a zk cluster may have either v0 or v1, if it is
migrating, and a kraft cluster may have either v0 or v1, at any time.

The new code distinguishes between an individual meta.properties file, which is represented by
MetaProperties, and a collection of meta.properties files, which is represented by
MetaPropertiesEnsemble. It is useful to have this distinction, because in JBOD mode, even if some
log directories are inaccessible, we can still use the ensemble to extract needed information like
the cluster ID. (Of course, even when not in JBOD mode, KRaft servers have always been able to
configure a metadata log directory separate from the main log directory.)

Since we recently added a unique directory.id to each meta.properties file, the previous convention
of passing a ""canonical"" MetaProperties object for the cluster around to various places in the code
needs to be revisited. After all, we can no longer assume all of the meta.properties files are the
same. This PR fixes these parts of the code. For example, it fixes the constructors of
ControllerApis and RaftManager to just take a cluster ID, rather than a MetaProperties object. It
fixes some other parts of the code, like the constructor of SharedServer, to take a
MetaPropertiesEnsemble object.

Another goal of this PR was to centralize meta.properties validation a bit more and make it
unit-testable. For this purpose, the PR adds MetaPropertiesEnsemble.verify, and a few other
verification methods. These enforce invariants like ""the metadata directory must be readable,"" and
so on.

Reviewers: Igor Soarez <soarez@apple.com>, David Arthur <mumrah@gmail.com>, Divij Vaidya <diviv@amazon.com>, Proven Provenzano <pprovenzano@confluent.io>",2023-11-09 09:32:35,Colin Patrick McCabe,Mixed
fa472d26a5b13b2125229527be99cd080eb3a122,"MINOR: Update BrokerRegistration to use a Builder

Update BrokerRegistration to use a Builder. This fixes the proliferation of different constructors,
and makes it clear what arguments are being used where.

Reviewers: Colin P. McCabe <cmccabe@confluent.io>",2023-11-09 10:08:31,Proven Provenzano,Mixed
eaa6b8abdd543fd1fc7152fbdb76643aad6223d6,"KAFKA-15360: Include dirs in BrokerRegistration #14392

BrokerLifecycleManager should send the offline log directories in the BrokerHeartbeatRequests it
sends. Also, when handling BrokerHeartbeatResponses, do so by enqueing a BrokerLifecycleManager
event, rather than trying to do the handling directly in the callback.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Proven Provenzano <pprovenzano@confluent.io>",2023-11-09 11:01:01,Igor Soarez,Mixed
f38b0d886c01bf4e83a08ca7c8a4da01c2d0c686,"KAFKA-15661: KIP-951: Server side changes (#14444)

This is the server side changes to populate the fields in KIP-951. On NOT_LEADER_OR_FOLLOWER errors in both FETCH and PRODUCE the new leader ID and epoch are retrieved from the local cache through ReplicaManager and included in the response, falling back to the metadata cache if they are unavailable there. The endpoint for the new leader is retrieved from the metadata cache. The new fields are all optional (tagged) and an IBP bump was required.

https://cwiki.apache.org/confluence/display/KAFKA/KIP-951%3A+Leader+discovery+optimisations+for+the+client

https://issues.apache.org/jira/browse/KAFKA-15661

Protocol changes: #14627

Testing
Benchmarking described here https://cwiki.apache.org/confluence/display/KAFKA/KIP-951%3A+Leader+discovery+optimisations+for+the+client#KIP951:Leaderdiscoveryoptimisationsfortheclient-BenchmarkResults
./gradlew core:test --tests kafka.server.KafkaApisTest

Reviewers: Justine Olshan <jolshan@confluent.io>, David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>, Fred Zheng <zhengyd2014@gmail.com>, Mayank Shekhar Narula <mayanks.narula@gmail.com>,  Yang Yang <yayang@uber.com>, David Mao <dmao@confluent.io>, Kirk True <ktrue@confluent.io>",2023-11-09 21:07:21,Crispin Bernier,Mixed
989618a56e3d98432371b9ee1ded1d791c7984e9,"KAFKA-15800: Prevent DataExceptions from corrupting KafkaOffsetBackingStore (#14718)

Signed-off-by: Greg Harris <greg.harris@aiven.io>

Reviewers: Yash Mayya <yash.mayya@gmail.com>",2023-11-10 08:40:16,Greg Harris,Mixed
a98bd7d65fb5a3a188ff524db7619dc7fe4257fa,"Revert ""KAFKA-15661: KIP-951: Server side changes (#14444)"" (#14738)

This reverts commit f38b0d8.

Trying to find the root cause of org.apache.kafka.tiered.storage.integration.ReassignReplicaShrinkTest failing in CI.

Reviewers: Justine Olshan <jolshan@confluent.io>",2023-11-11 18:12:17,David Jacot,Mixed
832627fc78484fdc7c8d6da8a2d20e7691dbf882,"MINOR: Various cleanups in metadata (#14734)

- Remove unused code, suppression
- Simplify/fix test assertions
- Javadoc cleanups

Reviewers: Josep Prat <josep.prat@aiven.io>",2023-11-14 09:25:09,Mickael Maison,Mixed
bd030f34995d18879d36549173752f1a92515c1b,"KAFKA-15824 SubscriptionState's maybeValidatePositionForCurrentLeader should handle partition which isn't subscribed yet (#14757)

See the motivation in jira description https://issues.apache.org/jira/browse/KAFKA-15824

This was discovered as ReassignReplicaShrinkTest started to fail with KIP-951 changes. KIP-951 changes since then have been reverted(PR), would be put back once this is in.

Reviewers: Walker Carlson <wcarlson@apache.org>, Andrew Schofield <aschofield@confluent.io>",2023-11-14 17:46:58,Mayank Shekhar Narula,Mixed
1bc4de75a2f870c31ad0025ff4feab063c5a5267,"KAFKA-15470: Allow creating connectors in a stopped state (#14704)

Reviewers: Chris Egerton <chrise@aiven.io>",2023-11-15 11:37:50,Yash Mayya,Mixed
22f7ffe5e1623d279096b45ab475768eeb05eee1,"KAFKA-15277: Design & implement support for internal Consumer delegates (#14670)

The consumer refactoring project introduced another `Consumer` implementation, creating two different, coexisting implementations of the `Consumer` interface:

* `KafkaConsumer` (AKA ""existing"", ""legacy"" consumer)
* `PrototypeAsyncConsumer` (AKA ""new"", ""refactored"" consumer)

The goal of this task is to refactor the code via the delegation pattern so that we can keep a top-level `KafkaConsumer` but then delegate to another implementation under the covers. There will be two delegates at first:

* `LegacyKafkaConsumer`
* `AsyncKafkaConsumer`

`LegacyKafkaConsumer` is essentially a renamed `KafkaConsumer`. That implementation handles the existing group protocol. `AsyncKafkaConsumer` is renamed from `PrototypeAsyncConsumer` and will implement the new consumer group protocol from KIP-848. Both of those implementations will live in the `internals` sub-package to discourage their use.

This task is part of the work to implement support for the new KIP-848 consumer group protocol.

Reviewers: Philip Nee <pnee@confluent.io>, Andrew Schofield <aschofield@confluent.io>, David Jacot <djacot@confluent.io>",2023-11-15 05:00:40,Kirk True,Mixed
0489b7cd331b22b5a2912e79e1cfa517ba6cecc9,"KAFKA-15346: add support for 'single key single timestamp' IQs with versioned state stores (KIP-960) (#14596)

This PR implements KIP-960 which add support for `VersionedKeyQuery`.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-11-15 17:34:54,Alieh,Mixed
875e610a2ba7ccc3514740db91743b9716411ff4,"KAFKA-15802: Validate remote segment state before fetching index (#14727) (#14759)

Reviewers: Satish Duggana <satishd@apache.org>, Divij Vaidya <diviv@amazon.com>, Christo Lolov <lolovc@amazon.com>, Luke Chen <showuon@gmail.com>, Kamal Chandraprakash<kamal.chandraprakash@gmail.com>",2023-11-16 08:52:01,Jorge Esteban Quilcate Otoya,Mixed
3fd6293449a0e92b709d2f74f0c444a05f52a287,"KAFKA-15755: LeaveGroupResponse v0 - v2 loses its member under certain error conditions (#14635)

This patch fixes a bug in the LeaveGroupResponse construction. Basically, when a top level error is set, no members are expected but the current check always requires one for versions prior to version 3.

Reviewers: David Jacot <djacot@confluent.io>",2023-11-16 01:17:33,Robert Wagner,Mixed
a8622faf471da9291596d4dae1eb9044d07f2b8c,"KAFKA-15799 Handle full metadata updates on ZK brokers (#14719)

This patch adds the concept of a ""Full"" UpdateMetadataRequest, similar to what is used in
LeaderAndIsr. A new tagged field is added to UpdateMetadataRequest at version 8 which allows the
KRaft controller to indicate if a UMR contains all the metadata or not. Since UMR is implicitly
treated as incremental by the ZK broker, we needed a way to detect topic deletions when the KRaft
broker sends a metadata snapshot to the ZK broker. By sending a ""Full"" flag, the broker can now
compare existing topic IDs to incoming topic IDs and calculate which topics should be removed from
the MetadataCache.

This patch only removes deleted topics from the MetadataCache. Partition/log management was
implemented in KAFKA-15605.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-11-16 14:38:44,David Arthur,Mixed
b1d83e2b04c92cebb5687c55ef2797186dbd0cf2,"Revert ""Revert ""KAFKA-15661: KIP-951: Server side changes (#14444)"" (#14738)"" (#14747)

This KIP-951 commit was reverted to investigate the org.apache.kafka.tiered.storage.integration.ReassignReplicaShrinkTest test failure (#14738).

A fix for that was merged in #14757, hence unreverting this change.

This reverts commit a98bd7d.

Reviewers: Justine Olshan <jolshan@confluent.io>, Mayank Shekhar Narula <mayanks.narula@gmail.com>",2023-11-16 15:42:34,Crispin Bernier,Mixed
a03a71d7b5f123304d98f0de07cd56c2534d381a,"KAFKA-15357: Aggregate and propagate assignments

A new AssignmentsManager accumulates, batches, and sends KIP-858
assignment events to the Controller. Assignments are sent via
AssignReplicasToDirs requests.

Move QuorumTestHarness.formatDirectories into TestUtils so it can be
used in other test contexts.

Fix a bug in ControllerRegistration.java where the wrong version of the
record was being generated in ControllerRegistration.toRecord.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Proven Provenzano <pprovenzano@confluent.io>, Omnia G H Ibrahim <o.g.h.ibrahim@gmail.com>",2023-11-16 16:19:49,Igor Soarez,Mixed
b1796ce6d2c04444a62393fbfd7c61811e001d67,"KAFKA-15849: Fix ListGroups API when runtime partition size is zero (#14785)

When the group coordinator does not host any __consumer_offsets partitions, the existing ListGroup implementation won't schedule any operation, thus a `new CompletableFuture<>()` is returned directly and never gets completed. This patch fixes the issue.

Reviewers: David Jacot <djacot@confluent.io>",2023-11-17 04:48:02,Dongnuo Lyu,Mixed
b9556611cdab932bdbae667bd3fd0287fa912a40,"KAFKA-15833: Restrict Consumer API to be used from one thread (#14779)

The legacy consumer detects any concurrent operations from different
threads. This was not enforced in the new consumer. To avoid inconsistencies
in the behavior, we enforce the same restriction in the new consumer.

Reviewers: Bruno Cadonna <cadonna@apache.org>",2023-11-19 21:24:28,Lucas Brutschy,Mixed
df78204e05bb1c416d977a0a36f4c263251ae4ef,"KAFKA-15854: Move Java classes from `kafka.server` to the `server` module (#14796)

We only move Java classes that have minimal or no dependencies on Scala classes in this PR.

Details:
* Configured `server` module in build files.
* Changed `ControllerRequestCompletionHandler` to be an interface since it has no implementations.
* Cleaned up various import control files.
* Minor build clean-ups for `server-common`.
* Disabled `testAssignmentAggregation` when executed with Java 8, this is an existing issue (see #14794).

For broader context on this change, please check:
* KAFKA-15852: Move server code from `core` to `server` module

Reviewers: Divij Vaidya <diviv@amazon.com>",2023-11-19 22:09:19,Ismael Juma,Mixed
e63f23718fdec514582fe1107536c1d2bacf72a1,"KAFKA-15174: Ensure CommitAsync propagate the exception to the user (#14680)

The commit covers a few important points:

- Exception handling: We should be thrown RetriableCommitException when the commit exception is retriable. We should throw FencedIdException on commit and poll similar to the current implementation. Other errors should be thrown as it is.
- Callback invocation: The callbacks need to be invoked on the main/application thread; however, the future is completed in the background thread. To achieve this, I created an Invoker class with a queue, so that this callback can be invoked during the consumer.poll()
Note: One change I made is to remove the DefaultOffsetCommit callback. Since the callback is purely for logging, I think it is reasonable for us to move the logging to the background thread instead of relying on the application thread to trigger the logging.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2023-11-20 09:15:48,Philip Nee,Mixed
feee616f738a059d6de3e5ec32fba6e9c2b23fb9,"MINOR: Query before creating the internal remote log metadata topic (#14755)

When a node starts (or) restarts, then we send a CREATE_TOPICS request to the controller to create the internal __remote_log_metadata topic.

Topic creation event is costly and handled by the controller. During re-balance, the controller can have pending requests in its queue and can lead to CREATE_TOPICS timeout. Instead of firing the CREATE_TOPICS request when a node restarts, send a METADATA request (topic describe) which is handled by the least loaded node before sending a request to create the topic.

Reviewers: Satish Duggana <satishd@apache.org>, Christo Lolov <lolovc@amazon.com>",2023-11-20 14:50:11,Kamal Chandraprakash,Mixed
6499cb041247c28652c9ad7e4763afb82b6fcd05,"KAFKA-15574; [1/N]: Client state machine updates (#14690)

Updates for the Client state machine, Heartbeat and Commit managers, to support required states and transitions as the member interacts with a consumer group based on heartbeat requests. 

Includes support for the subscribe and unsubscribe API calls, that drive the full lifecycle of a member as it joins a group, reconciles assignments, commits offsets if needed, handles fencing and fatal errors, and leaves the group.

This also includes support for topic ID only when needed for the reconciliation process.

Reviewers: Kirk True <ktrue@confluent.io>, Philip Nee <pnee@confluent.io>, Andrew Schofield <aschofield@confluent.io>, David Jacot <djacot@confluent.io>",2023-11-20 07:20:14,Lianet Magrans,Mixed
4eb8ae68ca1a8c783356e35e863806d4899d4fb7,"KAFKA-15836: KafkaConsumer subscribes to multiple topics does not respect max.poll.records (#14789)

When returning fetched records, the code was not properly honouring max.poll.records.
When it had fetched records for multiple topic-partitions, it was intended to accumulate records up to
max.poll.records. Actually, whenever it accumulated records from a partition, it was prepared to add
max.poll.records for that partition regardless of how many records it had already accumulated,
rather than reducing the number of records to add based on records already added from other partitions.

I added a test case which failed before the code change in the PR and passes afterwards.

Reviewers: Kirk True <ktrue@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-11-20 08:18:54,Andrew Schofield,Not TDD
e905ef1edfb92d8771e8c2a9a668f32210ad7e07,"MINOR: Small LogValidator clean ups (#14697)

This patch contains a few small clean-ups in LogValidator and associated classes:

1. Set shallowOffsetOfMaxTimestamp consistently as the last offset in the
   batch for v2 compressed and non-compressed data.
2. Rename `RecordConversionStats` to `RecordValidationStats` since one of its
   fields `temporaryMemoryBytes` does not depend on conversion.
3. Rename `batchIndex` in `recordIndex` in loops over the records in each batch
   inside `LogValidator`.

Reviewers: Qichao Chu <5326144+ex172000@users.noreply.github.com>, Jun Rao <junrao@gmail.com>",2023-11-20 10:40:45,Jason Gustafson,Mixed
c7c82baf873011a0d79ab0bcfcde53205c26af4c,"MINOR: Always send cumulative failed dirs in HB request (#14770)

Instead of only sending failed log directory UUIDs in the heartbeat
request until a successful response is received, the broker sends
the full cumulative set of failed directories since startup time.

This aims to simplify the handling of log directory failure in the
controller side, considering overload mode handling of heartbeat
requests, which returns an undifferentiated reply.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Proven Provenzano <pprovenzano@confluent.io>",2023-11-20 16:18:38,Igor Soarez,Mixed
07fee62afe98fc631dec9797b0fd2a7e29b8c7ed,"KAFKA-14519; [2/N] New coordinator metrics (#14387)

This patch copy over existing metrics and add new consumer group metrics to the new GroupCoordinatorService.

Now that each coordinator is responsible for a topic partition, this patch introduces a GroupCoordinatorMetrics that records gauges for global metrics such as the number of generic groups in PreparingRebalance state, etc. For GroupCoordinatorShard specific metrics, GroupCoordinatorMetrics will activate new GroupCoordinatorMetricsShards that will be responsible for incrementing/decrementing TimelineLong objects and then aggregate the total amount across all shards.

As the CoordinatorRuntime/CoordinatorShard does not care about group metadata, we have introduced a CoordinatorMetrics.java/CoordinatorMetricsShard.java so that in the future transaction coordinator metrics can also be onboarded in a similar fashion.

Main files to look at:

GroupCoordinatorMetrics.java
GroupCoordinatorMetricsShard.java
CoordinatorMetrics.java
CoordinatorMetricsShard.java
CoordinatorRuntime.java
Metrics to add after #14408 is merged:

offset deletions sensor (OffsetDeletions); Meter(offset-deletion-rate, offset-deletion-count)
Metrics to add after https://issues.apache.org/jira/browse/KAFKA-14987 is merged:

offset expired sensor (OffsetExpired); Meter(offset-expiration-rate, offset-expiration-count)

Reviewers: Justine Olshan <jolshan@confluent.io>",2023-11-20 21:38:50,Jeff Kim,Mixed
7826d5fc8ab695a5ad927338469ddc01b435a298,"MINOR: Mark ConsumerGroupHeartbeat API (v1), OffsetCommit API (v9) and OffsetFetch API (v9) as stable (KIP-848) (#14801)

We plan to ship an early access of KIP-848 in AK 3.7. Therefore, we need to mark the ConsumerGroupHeartbeat API (v1), OffsetCommit API (v9) and OffsetFetch API (v9) as stable.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-11-21 02:51:59,David Jacot,Mixed
70bd8aeb08ab03221dbd67f43f0bb237e03d5e0e,"KAFKA-15837: Throw error on use of Consumer.poll(long timeout) in AsyncKafkaConsumer (#14810)

Consumer.poll(long timeout) has been deprecated for many years and will finally be removed
in Apache Kafka 4.0. The new consumer under development does not support the deprecated
method, which has different timeout behaviour than Consumer.poll(Duration). Rather than
implement a dead method and immediately throw it away, the new consumer throws an exception
if this deprecated method is called.

Reviewer: Bruno Cadonna <cadonna@apache.org>",2023-11-21 15:02:16,Andrew Schofield,Mixed
e90692246ad76ec9c5710603faaec4dcb057bc81,"KAFKA-15362: Resolve offline replicas in metadata cache (#14737)

The metadata cache now considers registered log directories
and directory assignments when determining offline replicas.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Proven Provenzano <pprovenzano@confluent.io>",2023-11-21 09:40:04,Igor Soarez,Mixed
24aa9e0f411d8eaa773f24efc7d34091ea43a503,"KAFKA-15327: Ensure the commit manager commit on close (#14710)

When shutting down the network thread, we need to do the following:

 - autocommit the current progress
 - send a leave group heartbeat (KIP-848)
 - Send out the pending request (for example, unsent commits) and complete them within the timebound

In this commit, we add a closing procedure to the ConsumerNetworkThread. The actions can be summarized into the following:

- Make sure we have a reachable coordinator node, if not, try to discover one
- Once the node is discovered, prepare the requests (we need the node prior to sending because we need to know the destination)
 - Continue to poll until either: 1. timer runs out of time or 2. all requests are completed.

After the closingTasks are done: we then perform the last poll for the request managers, via the pollOnClose method, to send out the remaining requests. For commit request manager, we need to send out the unsent commits and block until 1. timer runs out or 2. all requests are completed.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2023-11-21 21:45:03,Philip Nee,Mixed
93096532195d1e9730be8664f6f6cc84fb77eb41,"KAFKA-15215: [KIP-954] support custom DSL store providers (#14648)

Implementation for KIP-954: support custom DSL store providers

Testing Strategy:
- Updated the topology tests to ensure that the configuration is picked up in the topology builder
- Manually built a Kafka Streams application using a customer DslStoreSuppliers class and verified that it was used

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Guozhang Wang <guozhang.wang.us@gmail.com>",2023-11-21 13:51:39,Almog Gavra,Mixed
209f268d6c375c1c16c4b26c609985b64b327e96,"KAFKA-15860: ControllerRegistration must be written out to the metadata image (#14807)

The ControllerRegistration records added in KIP-919 should be written out to the metadata
image, not just the log.

Reviewers: José Armando García Sancio <jsancio@apache.org>",2023-11-22 21:25:21,Colin Patrick McCabe,Mixed
55017a4f6886dbe1ed1eb31e4aaf2b9dee260ac6,"KAFKA-15484: General Rack Aware Assignor (#14481)

This patch adds the second part of the Uniform Assignor, used when the subscriptions of each member in a consumer group are different.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, David Jacot <djacot@confluent.io>",2023-11-23 01:18:50,Ritika Reddy,Mixed
75572f904b99cec5c57967cde68eac789feda6fa,"KAFKA-15555: Ensure wakeups are handled correctly in poll() (#14746)

We need to be careful when aborting a long poll with wakeup() since the
consumer might never return records if the poll is interrupted after the
consumer position has been updated but the records have not been returned
to the caller of poll().

This PR avoid wake-ups during this critical period.

Reviewers: Philip Nee <pnee@confluent.io>, Kirk True <ktrue@confluent.io>, Lucas Brutschy <lbrutschy@confluent.io>",2023-11-23 10:53:17,Bruno Cadonna,Mixed
891dd2a58a26a9c6c6dbc49a4611fc203209a327,"KAFKA-15756: [1/2] Migrate existing integration tests to run old protocol in new coordinator (#14781)

This patch updates the testing framework to support running tests with kraft and the new group coordinator introduced in the context of KIP-848. This can be done by using `kraft+kip-848` as a quorum. Note that this is temporary until we make it the default and only option in 4.0. To verify this, this patch also enables kraft and kraft+kip-848 in PlaintextConsumerTest and its parent classes.

Reviewers: David Jacot <djacot@confluent.io>",2023-11-23 02:05:54,Dongnuo Lyu,Not TDD
d5a8b892ae5884663be29e74a6bed5cbb2f0f7a8,"KAFKA-15856: Add integration tests for JoinGroup API and SyncGroup API (#14800)

This patch adds integration tests for JoinGroup API and SyncGroup API.

Reviewers: David Jacot <djacot@confluent.io>",2023-11-23 02:30:48,Dongnuo Lyu,Mixed
768a458b126c81a57e654b67befe7eb59beb2e17,"KAFKA-15803: Update leader epoch in commitAsync and committed (#14817)

To align the new consumer completely with the legacy consumer,
we need to update the latest seen leader epoch in the metadata
both when we commit offsets with a leader epoch using
commitAsync and when we fetch the latest committed offsets
using committed.

We add unit tests to AsyncKafkaConsumer to test that
metadata is correctly updated. We also add a corresponding test
for commitSync, which already had the leader epoch logic.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Bruno Cadonna <cadonna@apache.org>",2023-11-24 10:47:31,Lucas Brutschy,Mixed
95f41d59b389b6f25000b7bc4ddb948cfdb90448,"KIP-978: Allow dynamic reloading of certificates with different DN / SANs (#14756)

This PR implements KIP-978: Allow dynamic reloading of certificates with different DN / SANs. It adds two new options ssl.allow.dn.changes and ssl.allow.san.changes that can be used to enable dynamic reloading of certificates even if their DN / SANs change. They both default to false to maintain the current behavior by default.

Reviewers: Mickael Maison <mimaison@apache.org>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>",2023-11-24 16:41:16,Jakub Scholz,Mixed
a42c8463364d14806a46d1f2ea41df9526dd2233,"KAFKA-15241: Compute tiered copied offset by keeping the respective epochs in scope (#14787)

""findHighestRemoteOffset"" does not take into account the leader-epoch end offset. This can cause log divergence between the local and remote log segments when there is unclean leader election.

To handle it correctly, the logic to find the highest remote offset can be updated to:
find-highest-remote-offset = min(end-offset-for-epoch-in-the-checkpoint, highest-remote-offset-for-epoch)

Discussion thread: https://github.com/apache/kafka/pull/14004#discussion_r1266864272

Reviewers: Satish Duggana <satishd@apache.org>, Christo Lolov <lolovc@amazon.com>",2023-11-27 09:10:46,Kamal Chandraprakash,Mixed
47e37772c7cd947b082817653bea087f0ab7e103,"KAFKA-15817: Avoid reconnecting to the same IP address (#14813)

If multiple addresses are available. This change is a follow-up to #9902. When re-resolving DNS after disconnecting, it is possible (likely, even) that we will resolve the same set of addresses in the same order, meaning we could attempt to reconnect to the same IP that we just disconnected from. In the case where we disconnected from the IP address because it has become unhealthy (due to a load balancer going down or a network routing layer restarting, for example), the client will need to time out before connecting to the next IP. This essentially unifies the behavior before and after KAFKA-12193: re-resolve after disconnecting while still progressing through the IP list.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>, Andrew Schofield <aschofield@confluent.io>",2023-11-27 10:54:33,Bob Barrett,Not TDD
b34d75c31369f38b17d119b136417ed3494f6c7c,"MINOR: Fix flaky BrokerLifecycleManagerTest (#14836)

Fix some flakiness introduced by ""MINOR: Always send cumulative failed dirs in HB request""

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-11-27 14:09:45,Igor Soarez,Not TDD
fade3d10ea07eea5d6076b8fb1b68e2db5ffec48,"KAFKA-15047: Roll active segment when it breaches the retention policy (#14766)

Roll the active segment and offload it to remote storage once it breaches the retention time policy.

A segment is eligible for deletion once it gets uploaded to the remote storage. We have checks to allow only the passive segments to be uploaded, so the active segment never gets removed at all even if breaches the retention time. For low-throughput/stale topics, the active segment can hold the data beyond the configured retention time by the user.

Reviewers: Satish Duggana <satishd@apache.org>, Christo Lolov <lolovc@amazon.com>",2023-11-28 09:38:11,Kamal Chandraprakash,Mixed
bbd75b80cef2e9ec5413486228bc531725e2fc79,"KAFKA-15022: Detect negative cycle from one source (#14696)

Introduce a dummy node connected to every other node and run Bellman-ford from the dummy node once instead of from every node in the graph.

Reviewers: Qichao Chu (@ex172000), Matthias J. Sax <matthias@confluent.io>",2023-11-28 00:29:00,Hao Li,Mixed
db626a48042387d49983fc37e66728a7a3343aea,"KAFKA-15582 Unset the previous broker epoch if version < 2 (#14784)

When using older versions of the broker registration RPC, make sure that the new PreviousBrokerEpoch field is set to the default value when building the request object.

Reviewers: David Arthur <mumrah@gmail.com>",2023-11-28 10:36:59,Calvin Liu,Mixed
38f2faf83f7e83823767aa71b8fd0850dae93b6e,"KAFKA-15681: Add support of client-metrics in kafka-configs.sh (KIP-714) (#14632)

The PR adds support of alter/describe configs for client-metrics as defined in KIP-714

Reviewers: Andrew Schofield <aschofield@confluent.io>, Jun Rao <junrao@gmail.com>",2023-11-28 09:24:25,Apoorv Mittal,Mixed
bb1c4465c92d890fdb6fa2ebb2c2d2f1b8648feb,"KAFKA-14516: [1/N] Static Member leave, join, re-join request using ConsumerGroupHeartbeats (#14432)

This patch add the support for static membership to the new consumer group protocol. With a static member can join, re-join, temporarily leave and leave. When a member leaves with the expectation to rejoin, it must rejoin within the session timeout. It is kicks out from the consumer group otherwise.

Reviewers: David Jacot <djacot@confluent.io>",2023-11-28 10:08:16,vamossagar12,Mixed
009b57d870cee1045a6e7a06b8351e1f975a7b3e,"KAFKA-15618: Kafka metrics collector and supporting classes (KIP-714) (#14620)

The PR outlines classes to collect metrics for client by KafkaMetricsCollector implementation. The MetricsCollector defines mechanism to collect client metrics in sum and gauge metrics format. This requires to define cumulative and delta telemetry metrics while collecting raw metrics.

Singl point metric class helps creating OTLP format Metric object wrapped over Single point metric class itself.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Xavier Léauté <xavier@confluent.io>, Philip Nee <pnee@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2023-11-28 22:07:22,Apoorv Mittal,Mixed
14571054aaecdb80e73ddc7cb8f6ae11a6356b9f,"KAFKA-15904: Only add directory.id to meta.properties when migrating or in kraft mode

Only add directory.id to meta.properties when migrating to kraft mode, or already in
kraft mode. This prevents incompatibilities with older Kafka releases, which checked
that each directory in a JBOD ensemble had the same meta.properties values.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-11-28 23:14:10,Proven Provenzano,Not TDD
7999fd35d74670fa22e7c9e601e12096c3953df3,"KAFKA-15887: Ensure FindCoordinatorRequest is sent before closing (#14842)

A few bugs was created from the previous issues. These are:

* During testing or some edge cases, the coordinator request manager might hold on to an inflight request forever. Therefore, when invoking coordinatorRequestManager.poll(), nothing would return. Here we explicitly create a FindCoordinatorRequest regardless of the current request state because we want to actively search for a coordinator
* ensureCoordinatorReady() might be stuck in an infinite loop forever if the client fail to do so. Even the consumer would be able to shutdown eventually, this is undesirable.
* The current asyncConsumerTest mixes background/network thread shutdown with the consumer shutdown. As the goal of the module is unit testing, we should try to test the shutdown procedure separately. Therefore, this PR adds a Mockito.doAnswer call to the applicationEventHandler.close(). Tests that are testing shutdown are calling shutdown() explicitly.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2023-11-29 11:16:43,Philip Nee,Mixed
5ae0b49839f3585c35393a9399d1cbb0ceaf0e67,"KAFKA-14505; [1/N] Add support for transactional writes to CoordinatorRuntime (#14844)

This patch adds support for transactional writes to the CoordinatorRuntime framework. This mainly consists in adding CoordinatorRuntime#scheduleTransactionalWriteOperation and in adding the producerId and producerEpoch to various interfaces. The patch also extends the CoordinatorLoaderImpl and the CoordinatorPartitionWriter accordingly.

Reviewers: Justine Olshan <jolshan@confluent.io>",2023-11-29 08:54:23,David Jacot,Mixed
f1819f44807553926160db631a0f0d061995d441,"KAFKA-15778 & KAFKA-15779: Implement metrics manager (KIP-714) (#14699)

The PR provide implementation for client metrics manager along with other classes. Manager is responsible to support 3 operations:

UpdateSubscription - From kafka-configs.sh and reload from metadata cache.
Process Get Telemetry Request - From KafkaApis.scala
Process Push Telemetry Request - From KafkaApis.scala
Manager maintains an in-memory cache to keep track of client instances against their instance id.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Jun Rao <junrao@gmail.com>",2023-11-29 09:20:07,Apoorv Mittal,Mixed
d71d0639d9d5ae39153d3e1f52f8ba8bd2ae8044,"KAFKA-15046: Get rid of unnecessary fsyncs inside UnifiedLog.lock to stabilize performance (#14242)

While any blocking operation under holding the UnifiedLog.lock could lead to serious performance (even availability) issues, currently there are several paths that calls fsync(2) inside the lock
In the meantime the lock is held, all subsequent produces against the partition may block
This easily causes all request-handlers to be busy on bad disk performance
Even worse, when a disk experiences tens of seconds of glitch (it's not rare in spinning drives), it makes the broker to unable to process any requests with unfenced from the cluster (i.e. ""zombie"" like status)
This PR gets rid of 4 cases of essentially-unnecessary fsync(2) calls performed under the lock:
(1) ProducerStateManager.takeSnapshot at UnifiedLog.roll
I moved fsync(2) call to the scheduler thread as part of existing ""flush-log"" job (before incrementing recovery point)
Since it's still ensured that the snapshot is flushed before incrementing recovery point, this change shouldn't cause any problem
(2) ProducerStateManager.removeAndMarkSnapshotForDeletion as part of log segment deletion
This method calls Utils.atomicMoveWithFallback with needFlushParentDir = true internally, which calls fsync.
I changed it to call Utils.atomicMoveWithFallback with needFlushParentDir = false (which is consistent behavior with index files deletion. index files deletion also doesn't flush parent dir)
This change shouldn't cause problems neither.
(3) LeaderEpochFileCache.truncateFromStart when incrementing log-start-offset
This path is called from deleteRecords on request-handler threads.
Here, we don't need fsync(2) either actually.
On unclean shutdown, few leader epochs might be remained in the file but it will be handled by LogLoader on start-up so not a problem
(4) LeaderEpochFileCache.truncateFromEnd as part of log truncation
Likewise, we don't need fsync(2) here, since any epochs which are untruncated on unclean shutdown will be handled on log loading procedure

Reviewers: Luke Chen <showuon@gmail.com>, Divij Vaidya <diviv@amazon.com>, Justine Olshan <jolshan@confluent.io>, Jun Rao <junrao@gmail.com>",2023-11-29 09:43:44,Okada Haruki,Mixed
c0ec8131d82a8906a73f57fe161d6457ba53f75a,"KAFKA-15865: Remove autocommit completion event (#14831)

There is no callback associated with autocommit, so I do not think we need this event. This closes KAFKA-15865.

Reviewers: Bruno Cadonna <cadonna@apache.org>",2023-11-29 19:02:08,Lucas Brutschy,Mixed
e7b9bd5a26983e0072524f85be742b7eea9f170a,"KAFKA-15022: add config for balance subtopology in rack aware task assignment (#14711)

Part of KIP-925.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-11-29 11:33:52,Hao Li,Mixed
a94bc8d6d52ac4cf0bfd85b04271681f2081a31e,"KAFKA-15922: Add a MetadataVersion for JBOD (#14860)

Assign MetadataVersion.IBP_3_7_IV2 to JBOD.

Move KIP-966 support to MetadataVersion.IBP_3_7_IV3.

Create MetadataVersion.LATEST_PRODUCTION as the latest metadata version that can be used when formatting a
new cluster, or upgrading a cluster using kafka-features.sh. This will allow us to clearly distinguish between stable
and unstable metadata versions for the first time.

Reviewers: Igor Soarez <soarez@apple.com>, Ron Dagostino <rndgstn@gmail.com>, Calvin Liu <caliu@confluent.io>, Proven Provenzano <pprovenzano@confluent.io>",2023-11-30 10:35:13,Colin Patrick McCabe,Mixed
37416e1aebae33d01d5059ba906ec8e0e1107284,"KAFKA-15489: resign leadership when no fetch or fetch snapshot from majority voters (#14428)

In KIP-595, we expect to piggy-back on the `quorum.fetch.timeout.ms` config, and if the leader did not receive Fetch requests from a majority of the quorum for that amount of time, it would begin a new election, to resolve the network partition in the quorum. But we missed this implementation in current KRaft. Fixed it in this PR.

The commit include:
1. Added a timer with timeout configuration in `LeaderState`, and check if expired each time when leader is polled. If expired, resigning the leadership and start a new election.

2. Added `fetchedVoters` in `LeaderState`, and update the value each time received a FETCH or FETCH_SNAPSHOT request, and clear it and resets the timer if the majority - 1 of the remote voters sent such requests.

Reviewers: José Armando García Sancio <jsancio@apache.org>",2023-11-30 11:34:44,Luke Chen,Mixed
f1cd11dcc53ae1d7483c0c13b6f8242d540c25e0,"KAFKA-15629: Proposal to introduce IQv2 Query Types: TimestampedKeyQuery and TimestampedRangeQuery (#14570)

Implements KIP-992.

Adds TimestampedKeyQuery and TimestampedRangeQuery (IQv2) for ts-ks-store, plus changes semantics of existing KeyQuery and RangeQuery if issues against a ts-kv-store, now unwrapping value-and-timestamp and only returning the plain value.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-11-30 12:14:23,Hanyu Zheng,Not TDD
6b87c8529113939f3a3709603b6f37d733daf49a,"KAFKA-15886: Always specify directories for new partition registrations

When creating partition registrations directories must always be defined.

If creating a partition from a PartitionRecord or PartitionChangeRecord from an older version that
does not support directory assignments, then DirectoryId.MIGRATING is assumed.

If creating a new partition, or triggering a change in assignment, DirectoryId.UNASSIGNED should be
specified, unless the target broker has a single online directory registered, in which case the
replica should be assigned directly to that single directory.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-11-30 14:10:47,Igor Soarez,Mixed
1750d735cdf8b29e641486d5b5e1311d9c462733,"KAFKA-15842: Correct handling of KafkaConsumer.committed for new consumer (#14859)

This PR fixes some details of the interface to KafkaConsumer.committed which were different between the existing consumer and the new consumer.

Adds a unit test that validates the behaviour is the same for both consumer implementations.

Reviewers: Kirk True <ktrue@confluent.io>, Bruno Cadonna <cadonna@apache.org>",2023-12-01 14:37:21,Andrew Schofield,Mixed
21edb7078814e5cac41051b170b3ed5ecf4057d5,"KAFKA-15890: Consumer.poll with long timeout unaware of assigned partitions (#14835)

In the new consumer, Consumer.poll(Duration timeout) blocks for the entire duration. If the consumer is joining a group and has not yet received its assignments, the poll begins before an assignment has yet been received. Because the poll is blocked, it does not notice when partitions are assigned, and it subsequently does not return any records. The old consumer only blocks for the duration of the heartbeat interval and loops for until the poll timeout has passed, and is thus able to check for assignments received.

When this problem has been fixed, there remains another which prevents the group becoming stable. Because the consumer repeatedly sends the list of topic-partitions that it has been assigned to the group coordinator, the coordinator responds with the list of topic-partitions, which causes the consumer to remain reconciling indefinitely. By making the building of ConsumerGroupHeartbeatRequest stateful, the loop is ended and the group becomes stable as expected.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>, Kirk True <ktrue@confluent.io>, Lianet Magrans <lianetmr@gmail.com>",2023-12-01 15:41:30,Andrew Schofield,Mixed
bfee3b3c6ba88a0c3392794b4b6d9f0093670f21,"KAFKA-15690: Fix restoring tasks on partition loss, flaky EosIntegrationTest (#14869)

The following race can happen in the state updater code path

Task is restoring, owned by state updater
We fall out of the consumer group, lose all partitions
We therefore register a ""TaskManager.pendingUpdateAction"", to CLOSE_DIRTY
We also register a ""StateUpdater.taskAndAction"" to remove the task
We get the same task reassigned. Since it's still owned by the state updater, we don't do much
The task completes restoration
The ""StateUpdater.taskAndAction"" to remove will be ignored, since it's already restored
Inside ""handleRestoredTasksFromStateUpdater"", we close the task dirty because of the pending update action
We now have the task assigned, but it's closed.
To fix this particular race, we cancel the ""close"" pending update action. Furthermore, since we may have made progress in other threads during the missed rebalance, we need to add the task back to the state updater, to at least check if we are still at the end of the changelog. Finally, it seems we do not need to close dirty here, it's enough to close clean when we lose the task, related to KAFKA-10532.

This should fix the flaky EOSIntegrationTest.

Reviewers: Bruno Cadonna <cadonna@apache.org>",2023-12-01 18:57:27,Lucas Brutschy,Mixed
b22bbd656c6fd5784417c92bbc4652672ff554bc,"MINOR: cleanup internal Iterator impl (#14889)

makeNext() is internal and visibility should not be extended to `public`

Reviewers: Walker Carlson <wcarlson@confluent.io>",2023-12-01 11:53:07,Matthias J. Sax,Not TDD
bce2d4a8b6dd592011fae11dc4e13f34a8f5a398,"KAFKA-15953: Refactor polling delays (#14897)

Caches the maximum time to wait in the consumer network thread so the application thread is better isolated from the request managers.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2023-12-03 23:09:12,Andrew Schofield,Mixed
0cf227dd4f774e4d3942b3fb87e3f2e13dc8c297,"KAFKA-14438: Throw if async consumer configured with invalid group ID (#14872)

Verifies that the group ID passed into the async consumer is valid. That is, if the group ID is not null, it is not empty or it does not consist of only whitespaces.

This change stores the group ID in the group metadata because KAFKA-15281 about the group metadata API will build on that.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>, Kirk True <ktrue@confluent.io>",2023-12-03 23:11:41,Bruno Cadonna,Mixed
b7c99e22a77392d6053fe231209e1de32b50a98b,"KAFKA-14509: [2/N] Implement server side logic for ConsumerGroupDescribe API (#14544)

This patch implements the ConsumerGroupDescribe API.

Reviewers: David Jacot <djacot@confluent.io>",2023-12-04 07:19:28,Max Riedel,Mixed
7a6d2664cd773c5f8e6a57d615953e05e228e04e,"KAFKA-15663, KAFKA-15794: Telemetry reporter and request handling (KIP-714) (#14909)

Part of KIP-714.

Implements ClientTelemetryReporter which manages the lifecycle for client metrics collection. The reporter also defines TelemetrySender which will be used by Network clients to send API calls to broker.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Philip Nee <pnee@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2023-12-04 11:44:56,Apoorv Mittal,Mixed
a83bc2d977d2af85d4edfc8096854137481001e9,"KAFKA-13988: Enable replicating from latest offset with MirrorMaker 2 (#14567)

Reviewers: hudeqi <1217150961@qq.com>, Federico Valeri <fedevaleri@gmail.com>, Greg Harris <gharris1727@gmail.com>",2023-12-04 16:37:37,Chris Egerton,Mixed
463ed09f4eba0ccd5020f323a720ed6563a34410,"KAFKA-15830: Add telemetry API handling (KIP-714) (#14767)

The PR adds handling of telemetry APIs in KafkaAPIs.scala which calls the respective manager to handle the API calls. Also the telemetry plugin which if registered in configs get registered for exporting client metrics.

Reviewers: Jun Rao <junrao@gmail.com>",2023-12-04 16:00:35,Apoorv Mittal,Mixed
ebae7b26b5537b0ee15f10529b5736566da1deac,"MINOR: fix bug where we weren't registering SnapshotEmitterMetrics (#14918)

Fix a bug where we weren't properly exposing SnapshotEmitterMetrics. Add a test.

Reviewers: David Arthur <mumrah@gmail.com>",2023-12-04 21:32:12,Colin Patrick McCabe,Not TDD
26274afd05bc54bf8b3f8439b6918047a9c9fc23,"MINOR: Ensure that DisplayName is set in all parameterized tests (#14850)

This is a follow-up to https://github.com/apache/kafka/pull/14687 as we found out that some parameterized tests do not include the test method name in their name. For the context, the JUnit XML report does not include the name of the method by default but only rely on the display name provided.

Reviewers: David Arthur <mumrah@gmail.com>",2023-12-04 23:58:48,David Jacot,Not TDD
8038bc934205fb75e4c2f08525956467cf9065ae,"KAFKA-14987 [2/2]; customize retry backoff for group/offsets expiration (#14870)

The group expiration log becomes noisy when we encounter a retry-able error as the retry backoff is fixed to 500 ms. Allow customizable retry backoff so that even in the case of failure we have a longer delay. The current default for offsetsRetentionCheckIntervalMs is set to 10 minutes so even if the operation fails we will ""retry"" after 10 minutes. 

Reviewers: David Jacot <djacot@confluent.io>",2023-12-05 00:18:56,Jeff Kim,Mixed
783698c525947d7ea81587ee964dd62b0da349c7,"KAFKA-15645: Move ReplicationQuotasTestRig to tools module (#14588)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Justine Olshan <jolshan@confluent.io>, Taras Ledkov <tledkov@apache.org>",2023-12-05 10:03:33,Nikolay,Not TDD
587f50d48f832f2ce76ed8f47b6ea472da3b0848,"KAFKA-15831: KIP-1000 protocol and admin client (#14811)

This adds the new ListClientMetricsResources RPC to the Kafka protocol and puts support
into the Kafka admin client. The broker-side implementation in this PR is just to return an empty
list. A future PR will obtain the list from the config store.

Includes a few unit tests for what is a very simple RPC. There are additional tests already written and
waiting for the PR that delivers the kafka-client-metrics.sh tool which builds on this PR.

Reviewers: Jun Rao <junrao@gmail.com>",2023-12-05 07:14:06,Andrew Schofield,Mixed
2b99d0e45027c88ae2347fa8f7d1ff4b2b919089,"KAFKA-15901: Client changes for registering telemetry and API calls (KIP-714) (#14843)

The PR adds changes for the client APIs to register ClientTelemetryReporter, if enabled, and periodically report client metrics. The changes include front facing API changes with NetworkCLient issuing telemetry APIs.

The PR build is dependent on: #14620, #14724

Reviewers: Philip Nee <pnee@confluent.io>, Andrew Schofield <aschofield@confluent.io>, Kirk True <ktrue@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Walker Carlson <wcarlson@apache.org>",2023-12-05 11:50:33,Apoorv Mittal,Mixed
45f5d0f6213f9bc501a09c78228b373e3a735149,"KAFKA-15662: Add support for clientInstanceIds in Kafka Stream (#14908)

- Part of KIP-714
- Add new configs and public API for Kafka Streams
- Implement support to get admin client instance id

Reviewers: Andrew Schofield <aschofield@confluent.io>, Lucas Brutschy <lbrutschy@confluent.io>, Apoorv Mittal <amittal@confluent.io>, Walker Carlson <wcarlson@confluent.io>",2023-12-05 12:19:56,Matthias J. Sax,Mixed
b02a18a6e4117b50a0093344c39e5e9d9ac38c88,"KAFKA-15816: Fix leaked sockets in clients tests (#14750)

Signed-off-by: Greg Harris <greg.harris@aiven.io>
Reviewers: Mickael Maison <mickael.maison@gmail.com>",2023-12-05 14:34:52,Greg Harris,Not TDD
4a958c6cb12392746b100431f2ff8ab3c5f53b1a,"Kafka-14748: Relax non-null FK left-join requirement (#14107)

Relax non-null FK left-join requirement.

Testing Strategy: Inject extractor which returns null on first or second element.

Reviewers: Walker Carlson <wcarlson@apace.org>",2023-12-05 18:04:32,Florin Akermann,Not TDD
f6560ab1cd226bbb33c6380d33bd6caddbdb3e68,"KAFKA-15022: introduce interface to control graph constructor (#14714)

Part of KIP-925.

Refactor graph construction and assignment in RackAwareAssignor to new interface.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-12-05 22:00:04,Hao Li,Mixed
6df192b6cb1397a6e6173835bbbd8a3acb7e3988,"KAFKA-15281: Implement the groupMetadata Consumer API (#14879)

Implements the groupMetadata() API on the async consumer.

Reviewers: Kirk True <ktrue@confluent.io>, Andrew Schofield <aschofield@confluent.io>, Lucas Brutschy <lbrutschy@confluent.io>",2023-12-06 08:46:57,Bruno Cadonna,Mixed
83110e2d425b49fed8ad5fdc6e93579423c73289,"KAFKA-15448: Streams Standby Update Listener (KIP-988) (#14735)

Implementation for KIP-988, adds the new StandbyUpdateListener interface

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Colt McNealy <colt@littlehorse.io>",2023-12-06 01:27:38,Eduwer Camacaro,Mixed
eec1530da0b2faeb9a580ce1fa7461b3bcaf0c61,"KAFKA-15445: Add JVM Docker image (#14552)

This PR aims to add Apache Kafka JVM Docker image as per the following KIP - https://cwiki.apache.org/confluence/display/KAFKA/KIP-975%3A+Docker+Image+for+Apache+Kafka

Reviewers:  Ismael Juma <ismael@juma.me.uk>, Ashwin Pankaj <apankaj@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>, Sanjay Awatramani <sawatramani@confluent.io>, 
Nikita Konev",2023-12-06 15:59:13,Vedarth Sharma,Mixed
f05b342b3957e2813a960ddaff7e39b0731bb23f,"MINOR: Allow local-log segment deletion when log-start-offset incremented. (#14905)

DELETE_RECORDS API can move the log-start-offset beyond the highest-copied-remote-offset. In such cases, we should allow deletion of local-log segments since they won't be eligible for upload to remote storage.

Reviewers: Satish Duggana <satishd@apache.org>, Luke Chen <showuon@gmail.com>",2023-12-06 16:59:16,Kamal Chandraprakash,Mixed
c575ba238dc5d85a04d0ee7c533b1de5360460a1,"KAFKA-15280: Implement client support for KIP-848 server-side assignors (#14878)

* Validate the client’s configuration for server-side assignor selection defined in config group.remote.assignor
* Include the assignor taken from config in the ConsumerGroupHeartbeat request, in the ServerAssignor field 
* Properly handle UNSUPPORTED_ASSIGNOR errors that may be returned to the HB response if the server does not support the assignor defined by the consumer. 
Includes a simple integration tests for sending an invalid assignor to the broker, and for using the range assignor with a single consumer.

Reviewers: David Jacot <djacot@confluent.io>, Lianet Magrans <lianetmr@gmail.com>, Bruno Cadonna <cadonna@apache.org>",2023-12-06 15:22:11,Lucas Brutschy,Mixed
71b4cbae378ea2a1b751c0fb9bf6a647df848610,"KAFKA-15972: Add support to exclude labels for telemetry metrics (KIP-714) (#14924)

Changes in the PR are to support excluding client_id label when sending telemetry metrics.

Some of the labels/tags which are present in metric should be skipped while collecting telemetry as data might already be known to broker hence, we should minimize the data transfer. One of such labels is client_id which is already present in RequestContext hence broker can append that label prior emitting metrics to telemetry backend.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Walker Carlson <wcarlson@apache.org>",2023-12-06 08:54:13,Apoorv Mittal,Mixed
9658942366a8fb4a0093754602ceccc9bd635be2,"KAFKA-15347: add support for 'single key multi timestamp' IQs with versioned state stores (KIP-968) (#14626)

Implements KIP-968.

Add new query type MultiVersionedKeyQuery for IQv2 supported by versioned state stores.",2023-12-06 07:56:12,Alieh Saeedi,Mixed
6be2e5c131ee646cc2f8512c4042015d0794a9be,"KAFKA-15022: tests for HA assignor and StickyTaskAssignor (#14921)

Part of KIP-925.

Tests for HAAssignor and StickyAssignor.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-12-06 08:12:47,Hao Li,Not TDD
b888fa1ec9d543ee798840509eda3326d6fa0a0d,"KAFKA-15910: New group coordinator needs to generate snapshots while loading (#14849)

After the new coordinator loads a __consumer_offsets partition, it logs the following exception when making a read operation (fetch/list groups, etc):

 ```
java.lang.RuntimeException: No in-memory snapshot for epoch 740745. Snapshot epochs are:
at org.apache.kafka.timeline.SnapshotRegistry.getSnapshot(SnapshotRegistry.java:178)
at org.apache.kafka.timeline.SnapshottableHashTable.snapshottableIterator(SnapshottableHashTable.java:407)
at org.apache.kafka.timeline.TimelineHashMap$ValueIterator.<init>(TimelineHashMap.java:283)
at org.apache.kafka.timeline.TimelineHashMap$Values.iterator(TimelineHashMap.java:271)
```
 
This happens because we don't have a snapshot at the last updated high watermark after loading. We cannot generate a snapshot at the high watermark after loading all batches because it may contain records that have not yet been committed. We also don't know where the high watermark will advance up to so we need to generate a snapshot for each offset the loader observes to be greater than the current high watermark. Then once we add the high watermark listener and update the high watermark we can delete all of the older snapshots. 

Reviewers: David Jacot <djacot@confluent.io>",2023-12-06 08:38:05,Jeff Kim,Mixed
bdf6d46b41bba22d5a9adf6eb1c87e46d8b9c095,"MINOR: Add junit properties to display parameterized test names (#14687)

In many parameterized tests, the display name is broken. Example - `testMetadataFetch` appears as `[1] true`, `[2] false`  [link](https://ci-builds.apache.org/job/Kafka/job/kafka-pr/job/PR-14607/9/testReport/junit/org.apache.kafka.clients.producer/KafkaProducerTest/) 
This is because the constant in `@ParameterizedTest`
```java
String DEFAULT_DISPLAY_NAME = ""[{index}] {argumentsWithNames}"";
```

This PR adds a new `junit-platform.properties` which overrides to add a `{displayName}` which shows the `the display name of the method`

For existing tests which override the name, should work as is. The precedence rules are explained

> 1. `name` attribute in `@ParameterizedTest`, if present
> 2. value of the `junit.jupiter.params.displayname.default` configuration parameter, if present
> 3. `DEFAULT_DISPLAY_NAME` constant defined in `@ParameterizedTest`

Source: https://junit.org/junit5/docs/current/user-guide/#writing-tests-parameterized-tests-display-names

Sample test run output 
Before: `[1] true` [link](https://ci-builds.apache.org/job/Kafka/job/kafka-pr/job/PR-14607/9/testReport/junit/org.apache.kafka.clients.producer/KafkaProducerTest/)
After: `testMetadataExpiry(boolean).false` [link](https://ci-builds.apache.org/job/Kafka/job/kafka-pr/job/PR-14687/1/testReport/junit/org.apache.kafka.clients.producer/KafkaProducerTest/)

Reviewers: Divij Vaidya <diviv@amazon.com>, Bruno Cadonna <cadonna@apache.org>, David Jacot <djacot@confluent.io>",2023-12-06 08:42:45,Alok Thatikunta,Not TDD
8ed53a15ee6c9be416717d1740e8e37252cc4991,"KAFKA-15932: Wait for responses in consumer operations (#14912)

The Kafka consumer makes a variety of requests to brokers such as fetching committed offsets and updating metadata. In the LegacyKafkaConsumer, the approach is typically to prepare RPC requests and then poll the network to wait for responses. In the AsyncKafkaConsumer, the approach is to enqueue an ApplicationEvent for processing by one of the request managers on the background thread. However, it is still important to wait for responses rather than spinning enqueuing events for the request managers before they have had a chance to respond.

In general, the behaviour will not be changed by this code. The PlaintextConsumerTest.testSeek test was flaky because operations such as KafkaConsumer.position were not properly waiting for a response which meant that subsequent operations were being attempted in the wrong state. This test is no longer flaky.

Reviewers: Kirk True <ktrue@confluent.io>, Lianet Magrans <lianetmr@gmail.com>, Bruno Cadonna <cadonna@apache.org>",2023-12-06 18:47:26,Andrew Schofield,Mixed
46852eea1c620ff786f4c4c1ff4cbd47f912a1d9,"KAFKA-15871: kafka-client-metrics.sh (#14926)

Initial implementation of kafka-client-metrics.sh tools for KIP-714 and KIP-1000.

Reviewers: Igor Soarez <soarez@apple.com>, Jun Rao <junrao@gmail.com>",2023-12-06 10:10:10,Andrew Schofield,Mixed
dc09d7a4e0998a58d8ddcdb7718d897407ff6b06,"KAFKA-15684: Support to describe all client metrics resources (KIP-714) (#14933)

Improvement for KIP-1000 to list client metrics resources in KafkaApis.scala. Using functionality exposed by KIP-1000 to support describe all metrics operations for KIP-714.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Jun Rao <junrao@gmail.com>",2023-12-06 11:09:42,Apoorv Mittal,Mixed
f467f6bb4f91a773a04106da7430798be9926fd6,"KAFKA-15361: Process and persist dir info with broker registration (#14838)

Part of JBOD KIP-858, https://cwiki.apache.org/confluence/display/KAFKA/KIP-858%3A+Handle+JBOD+broker+disk+failure+in+KRaft

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Proven Provenzano <pprovenzano@confluent.io>, Ron Dagostino <rdagostino@confluent.io>",2023-12-06 16:40:43,Igor Soarez,Mixed
969bc7749ccf3c2df352c8b9579fa820682f8722,"KAFKA-15980: Add the CurrentControllerId metric (#14749)

Add the CurrentControllerId metric as described in KIP-1001. This gives us an easy way to identify the current controller by looking at the metrics of any Kafka node (broker or controller).

Reviewers: David Arthur <mumrah@gmail.com>",2023-12-06 21:03:33,Colin Patrick McCabe,Mixed
522c2864cd53e1a61dbc296a8cda062abf1002c5,"KAFKA-14505; [2/N] Implement TxnOffsetCommit API (#14845)

This patch implements the TxnOffsetCommit API. When a transactional offset commit is received, it is stored in the pending transactional offsets structure and waits there until the transaction is committed or aborted. Note that the handling of the transaction completion is not implemented in this patch.

Reviewers: Justine Olshan <jolshan@confluent.io>",2023-12-07 02:51:22,David Jacot,Mixed
964e73178b5b8363cd2685ce6872905ef0c04dee,"KAFKA-14132; Replace EasyMock with Mockito in StandaloneHerderTest (#12728)

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chris Egerton <chrise@aiven.io>",2023-12-07 10:01:17,Matthew de Detrich,Not TDD
32576f61ce8ef36f4ab265e66815fbd45a158cc5,"MINOR: always register before touch in BrokerHeartbeatManager (#14934)

BrokerHeartbeatManager should require a call to register(brokerId) before touch(brokerId)

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ron Dagostino <rndgstn@gmail.com>",2023-12-07 10:13:39,Igor Soarez,Mixed
7dabd27f8d4961921e0acd531b0f8bf85776fc17,"KAFKA-15662: Add support for clientInstanceIds in Kafka Stream (#14922)

Part of KIP-714.

Adds support to expose main consumer client instance id.

Reviewers: Walker Carlson <wcarlson@confluent.io>, Lucas Brutschy <lbrutschy@confluent.io>",2023-12-07 10:39:39,Matthias J. Sax,Mixed
498f3f010fb03466f21ebc61232002042167700a,"MINOR: Support to update Async Consumer group member label (KIP-714) (#14946)

Part of KIP-714.

As KIP-848 introduced a new Kafka Consumer, KIP-714 required changes to capture group_member_id.
This change also includes a fix to update labels, as earlier calling updateLabels multiple times for same key
would have added new resource attribute every time. Now it updates the map and then construct the labels, 
which updates the existing labels with new value.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Philip Nee <pnee@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2023-12-07 10:53:05,Apoorv Mittal,Mixed
c515bf51f820f26ff6be6b0fde03b47b69a10b00,"KAFKA-15426: Process and persist directory assignments

Handle AssignReplicasToDirs requests, persist metadata changes
with new directory assignments and possible leader elections.

Reviewers: Proven Provenzano <pprovenzano@confluent.io>, Ron Dagostino <rndgstn@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",2023-12-07 11:44:45,Igor Soarez,Mixed
ec92410e5949c244946ab882d13f267eb13813b9,"KAFKA-15363: Broker log directory failure changes (#14790)

Part of JBOD KIP-858, https://cwiki.apache.org/confluence/display/KAFKA/KIP-858%3A+Handle+JBOD+broker+disk+failure+in+KRaft

Reviewers: Igor Soarez <i@soarez.me>, Colin P. McCabe <cmccabe@apache.org>, Ron Dagostino <rdagostino@confluent.io>",2023-12-07 20:44:56,Omnia Ibrahim,Mixed
b96ded9859bf358ad918b6b801cb0c8ac22f5e30,"Revert ""MINOR: Add junit properties to display parameterized test names (#14687)"" (#14961)

This reverts commit bdf6d46b41bba22d5a9adf6eb1c87e46d8b9c095. We found out that this commit introduced flakiness in Streams' tests. We will revise it.

Reviewers: Bruno Cadonna <cadonna@apache.org>",2023-12-07 23:20:03,David Jacot,Not TDD
fb5d45d26e45b32875f264246b99f378d89fc9a7,"KAFKA-15662: Add support for clientInstanceIds in Kafka Stream (#14935)

Part of KIP-714.

Add support to collect client instance id of the global consumer.

Reviewers: Walker Carlson <wcarlson@confluent.io>, Lucas Brutschy <lbrutschy@confluent.io>",2023-12-08 09:42:32,Matthias J. Sax,Mixed
9de72daa509f934f56544ec1d082d27fd0b6b0c2,"KAFKA-15361: Migrating brokers must register with directory list (#14976)

KAFKA-15361 (#14838) introduced a check for non empty directory list on brokerregistration requests
from MetadataVersion.IBP_3_7_IV2 or later, which enables directory assignment. However, ZK brokers
weren't yet registering yet with a directory list. This patch addresses that. We also make the
directory list non-optional in BrokerLifecycleManager.

Reviewers: Ron Dagostino <rndgstn@gmail.com>, Colin P. McCabe <cmccabe@apache.org>, Proven Provenzano <pprovenzano@confluent.io>",2023-12-08 10:16:48,Igor Soarez,Mixed
dc857fb6bf61765413214e3935f2cf60e9b70fa1,"KAFKA-13328, KAFKA-13329 (1): Add preflight validations for key, value, and header converter classes (#14304)

Reviewers: Yash Mayya <yash.mayya@gmail.com>, Greg Harris <greg.harris@aiven.io>",2023-12-08 15:00:44,Chris Egerton,Mixed
02d9f46f3aebb446737a3353bf8d9f4eedc10089,"MINOR: allow JBOD during ZK migration (#14968)

Allow using JBOD during ZK migration if MetadataVersion is at or above 3.7-IV2.

Reviewers: Ron Dagostino <rndgstn@gmail.com>, Colin P. McCabe <cmccabe@apache.org>, Proven Provenzano <pprovenzano@confluent.io>",2023-12-08 14:38:57,Proven Provenzano,Mixed
93b6df6173da98a1f41f21bd90a3bada662f3e93,"KAFKA-15364: Handle log directory failure in the Controller (#14902)

When log directories fail, the broker will send a heartbeat listing the failed directories. This
PR implements processing offline directories in the controller's broker heartbeat handling. We
update broker registrations and generate leadership/ISR changes as necessary.

Co-authored-by: Colin P. McCabe <cmccabe@apache.org>
Reviewers: Ron Dagostino <rndgstn@gmail.com>",2023-12-08 14:44:14,Igor Soarez,Mixed
8c184b47430c85c1e6bed65c1656f49ed15e5536,"MINOR: Fix some AssignmentsManager bugs (#14954)

- Add proper start & stop for AssignmentsManager's event loop
- Dedupe queued duplicate assignments
- Fix bug where directory ID is resolved too late

Co-authored-by: Gaurav Narula <gaurav_narula2@apple.com>
Reviewers: Colin P. McCabe <cmccabe@apache.org>",2023-12-08 15:37:23,Igor Soarez,Mixed
32fdb8d173dfc1e92f4f0d3b3cf5b0b9d294b4dd,"KAFKA-15956: MetadataShell must take the log directory lock when reading (#14899)

MetadataShell should take an advisory lock on the .lock file of the directory it is reading from.
Add an integration test of this functionality in MetadataShellIntegrationTest.java.

Note: in build.gradle, I had to add some dependencies on server-common's test files in order to use
MockFaultHandler, etc.

MetadataBatchLoader.java: fix a case where a log message was incorrect.  The intention was to print
the number equivalent to (offset + index).  Instead it was printing the offset, followed by the
index. So if the offset was 100 and the index was 1, 1001 would be printed rather than 101.

Co-authored-by: Igor Soarez <i@soarez.me>
Reviewers: David Arthur <mumrah@gmail.com>, José Armando García Sancio <jsancio@apache.org>",2023-12-10 19:18:34,Colin Patrick McCabe,Not TDD
131581a2b41b7a8a2a8e261aa0d7b2f84334ca02,"MINOR: Remove `SubscribedTopicRegex` field from `ConsumerGroupHeartbeatRequest` (#14956)

The support for regular expressions has not been implemented yet in the new consumer group protocol. This patch removes the `SubscribedTopicRegex` from the `ConsumerGroupHeartbeatRequest` in preparation for 3.7. It seems better to bump the version and add it back when we implement the feature, as part of https://issues.apache.org/jira/browse/KAFKA-14517, instead of having an unused field in the request.

Reviewers: Sagar Rao <sagarmeansocean@gmail.com>, Justine Olshan <jolshan@confluent.io>",2023-12-10 23:53:08,David Jacot,Not TDD
f80f991c79ea644daca6d668746ecda8abb52b5b,"KAFKA-15978: Update member information on HB response (#14945)

In the new consumer, the commit request manager and the membership manager are separate components. The commit request manager is initialised with group information that it uses to construct `OffsetCommit` requests. However, the initial value of the member ID is `""""` in some cases. When the consumer joins the group, it receives a `ConsumerGroupHeartbeat` response which tells it the member ID. The member ID was not being passed to the commit request manager, so it sent invalid `OffsetCommit` requests that failed with `UNKNOWN_MEMBER_ID`.

Reviewers: Bruno Cadonna <cadonna@apache.org>, David Jacot <djacot@confluent.io>",2023-12-10 23:56:54,Andrew Schofield,Not TDD
f52575b17225828d2ff11996030ab7304667deab,"KAFKA-15662: Add support for clientInstanceIds in Kafka Stream (#14948)

Part of KIP-714.

Adds support to expose producer client instance id.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2023-12-11 00:20:01,Matthias J. Sax,Mixed
85cee984ac09d7bdb46634413f70fc74afe60d1f,"MINOR: Fix rack-aware assignment tests (#14965)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2023-12-11 01:38:57,Hao Li,Mixed
07490b929bdf923195632bed7b494aa7d22d9f31,"KAFKA-15365: Broker-side replica management changes (#14881)

Reviewers: Igor Soarez <soarez@apple.com>, Ron Dagostino <rndgstn@gmail.com>, Proven Provenzano <pprovenzano@confluent.io>",2023-12-11 09:34:22,Omnia Ibrahim,Mixed
bf5d3cfd4eed060a6c1ebba10136b926e9b08e8c,"KAFKA-15363: Run completion handlers for duped AssignmentEvent (#14982)


Reviewers: Omnia G H Ibrahim <o.g.h.ibrahim@gmail.com>, Ron Dagostino <rdagostino@confluent.io>",2023-12-11 10:09:16,Igor Soarez,Mixed
839e75a72968b697b05c6265219fc3bba583dd40,"KAFKA-15574; [2/N]: Client state machine updates (#14857)

This patch updates the client state machine, including:
* handling transitions to fatal and fenced while member is leaving the group.
* minor improvements addressing comments.
* support for static member leave group.
* minor fixes for handling assignments received.

Reviewers: David Jacot <djacot@confluent.io>",2023-12-11 11:05:27,Lianet Magrans,Mixed
2a5fbf28820ddcde5ead605e070391059d5d2e18,"KAFKA-15563: Provide informative error messages when Connect REST requests time out (#14562)

Reviewers: Greg Harris <greg.harris@aiven.io>",2023-12-11 16:48:16,Chris Egerton,Mixed
75ad8841611d95d67ccb1c1ed21de31b0dc74f5f,"KAFKA-15906: Emit latest MM2 offset syncs every offset.flush.interval.ms (#14967)

Signed-off-by: Greg Harris <greg.harris@aiven.io>
Reviewers: Chris Egerton <chrise@aiven.io>",2023-12-11 16:39:54,Greg Harris,Mixed
ccb36fe0c7d27667c30d5b0379758bec4dcecb52,"KAFKA-15358: Added QueuedReplicaToDirAssignments metric (#14942)

Reviewers: Igor Soarez <i@soarez.me>, Ron Dagostino <rdagostino@confluent.io>",2023-12-12 03:17:00,Michael Westerby,Mixed
5b478aebfdf6f1d908b5ce76087058c68caa049a,"KAFKA-15818: ensure leave group on max poll interval (#14873)

Currently, poll interval is not being respected during consumer#poll. When the user stops polling the consumer, we should assume either the consumer is too slow to respond or is already dead. In either case, we should let the group coordinator kick the member out of the group and reassign its partition after the rebalance timeout expires.

If the consumer comes back alive, we should send a heartbeat and the member will be fenced and rejoin. (and the partitions will be revoked).

This is the same behavior as the current implementation.

Reviewers: Lucas Brutschy <lucasbru@apache.org>, Bruno Cadonna <cadonna@apache.org>, Lianet Magrans <lianetmr@gmail.com>",2023-12-12 10:06:34,Philip Nee,Mixed
be531c681c8b12258abb7199567ce49f84b0d9b4,"KAFKA-15695: Update the local log start offset of a log after rebuilding the auxiliary state (#14649)

Reviewers: Satish Duggana <satishd@apache.org>, Luke Chen <showuon@gmail.com>,  Divij Vaidya <diviv@amazon.com>, Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Alexandre Dupriez <alexandre.dupriez@gmail.com>",2023-12-12 21:43:42,Nikhil Ramakrishnan,Mixed
083aa61a96bc3d2ca5d612239b7dc7b50f17df2e,"KAFKA-15662: Add support for clientInstanceIds in Kafka Stream (#14936)

Part of KIP-714.

Add support to collect client instance id of the restore consumer.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2023-12-12 08:54:45,Matthias J. Sax,Mixed
3f7eadaa00b95ceea79776fd75b4651c054bee38,"KAFKA-15372: Reconfigure dedicated MM2 connectors after leadership change (#14293)

Signed-off-by: Greg Harris <greg.harris@aiven.io>
Reviewers: Chris Egerton <chrise@aiven.io>",2023-12-12 13:57:56,Greg Harris,Not TDD
fb3a0592627081ca5cf5532dab98391072615233,"MINOR: Rename and update test files for docker image (#14991)

Update the port mapping in test compose files to align with the recommendations in example files

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2023-12-13 11:59:48,Vedarth Sharma,Not TDD
b08fb14bed8cd80be3a19cc1ac284cb01283a416,"KAFKA-15775: New consumer listTopics and partitionsFor (#14962)

Implement Consumer.listTopics and Consumer.partitionsFor in the new consumer. The topic metadata request manager already existed so this PR adds expiration to requests, removes some redundant state checking and adds tests.

Reviewers: Lucas Brutschy <lucasbru@apache.org>",2023-12-13 08:47:25,Andrew Schofield,Mixed
0d9ee03742e6ab73dc66ef9a9f673a7dbc128e80,"KAFKA-15981: update Group size only when groups size changes (#14988)

Currently, we increment generic group metrics whenever we create a new Group object when we load a partition. This is incorrect as the partition may contain several records for the same group if in the active segment or if the segment has not yet been compacted.

The same applies to removing groups; we can possibly have multiple group tombstone records. Instead, only increment the metric if we created a new group and only decrement the metric if the group exists.

Reviewers: David Jacot <djacot@confluent.io>",2023-12-13 00:01:56,Jeff Kim,Mixed
87e3cbe4daa084964596d3f6f79041d85548426b,"MINOR: Add junit properties to display parameterized test names (#14983)

In many parameterized tests, the display name is broken. Example - testMetadataFetch appears as [1] true, [2] false link
This is because the constant in @ParameterizedTest

String DEFAULT_DISPLAY_NAME = ""[{index}] {argumentsWithNames}"";

This PR adds a new junit-platform.properties which overrides to add a {displayName} which shows the the display name of the method

For existing tests which override the name, should work as is. The precedence rules are explained

    name attribute in @ParameterizedTest, if present
    value of the junit.jupiter.params.displayname.default configuration parameter, if present
    DEFAULT_DISPLAY_NAME constant defined in @ParameterizedTest

Source: https://junit.org/junit5/docs/current/user-guide/#writing-tests-parameterized-tests-display-names

Sample test run output
Before: [1] true link
After: testMetadataExpiry(boolean).false link

This commit is an extension of https://github.com/apache/kafka/commit/bdf6d46b41bba22d5a9adf6eb1c87e46d8b9c095 which needed to reverted due to introduces test failures.

Reviewers: David Jacot <djacot@confluent.io>, Lucas Brutschy <lbrutschy@confluent.io>",2023-12-13 09:42:18,Bruno Cadonna,Not TDD
a1e985d22fcc847da9c1ac696a08954fc134de55,"KAFKA-15237: Implement write operation timeout (#14981)

This patch ensure that `offset.commit.timeout.ms` is enforced. It does so by adding a timeout to the CoordinatorWriteEvent.

Reviewers: David Jacot <djacot@confluent.io>",2023-12-13 11:30:53,vamossagar12,Mixed
a87e86e015f61de9a66012fd542dbf0417eb0387,"KAFKA-15883: Implement RemoteCopyLagBytes (#14832)

This pull request implements the first in the list of metrics in KIP-963: Additional metrics in Tiered Storage.

Since each partition of a topic will be serviced by its own RLMTask we need an aggregator object for a topic. The aggregator object in this pull request is BrokerTopicAggregatedMetric. Since the RemoteCopyLagBytes is a gauge I have introduced a new GaugeWrapper. The GaugeWrapper is used by the metrics collection system to interact with the BrokerTopicAggregatedMetric. The RemoteLogManager interacts with the BrokerTopicAggregatedMetric directly.

Reviewers: Luke Chen <showuon@gmail.com>, Satish Duggana <satishd@apache.org>, Kamal Chandraprakash<kamal.chandraprakash@gmail.com>",2023-12-14 09:21:37,Christo Lolov,Mixed
e4249b69bda215d308ac5580a89fcc58ca054b97,"KAFKA-15784: Ensure atomicity of in memory update and write when transactionally committing offsets (#14774)

Rewrote the verification flow to pass a callback to execute after verification completes.
For the TxnOffsetCommit, we will call doTxnCommitOffsets. This allows us to do offset validations post verification.

I've reorganized the verification code and group coordinator code to make these code paths clearer. The followup refactor (https://issues.apache.org/jira/browse/KAFKA-15987) will further clean up the produce verification code.

Reviewers: Artem Livshits <alivshits@confluent.io>, Jason Gustafson <jason@confluent.io>, David Jacot <djacot@confluent.io>, Jun Rao <junrao@gmail.com>",2023-12-13 17:45:09,Justine Olshan,Mixed
5e17dabbc8e7ae1136857d7f4b34336a4f4ad140,"MINOR: Client state machine fix for ignoring new assignments when leaving (#15003)

This includes a fix for properly handling cases where the member might receive a new assignment from the broker when the member is already getting ready to leave the group. The expectation is that the member should just ignore the new assignment and continue with the leave group process.

Reviewer: Bruno Cadonna <cadonna@apache.org>",2023-12-14 08:35:52,Lianet Magrans,Mixed
067c95d502990b92f301c992db1a89869aeb6115,"MINOR: Client state machine fix for fencing while preparing to leave #15004 

This includes a fix to better handle the case where a member gets fenced while preparing to leave the group. The logic was already making sure that the member ignores the fencing (no callbacks triggered or rejoin), but this PR adds the right transition to stop sending heartbeats while the leaving process completes (because the member is not part of the group anymore from the broker point of view).

Reviewer: Bruno Cadonna <cadonna@apache.org>",2023-12-14 09:03:32,Lianet Magrans,Mixed
b0e99b55934923bae4cd74639d9cdd64b4744036,"KAFKA-15922: Bump MetadataVersion to support JBOD with KRaft (#14984)

Moves ELR from MetadataVersion IBP_3_7_IV3 into the new IBP_3_8_IV0 because the ELR feature was not completed before 3.7 reached feature freeze.  Leaves IBP_3_7_IV3 empty -- it is a no-op and is not reused for anything.  Adds the new MetadataVersion IBP_3_7_IV4 for the FETCH request changes from KIP-951, which were mistakenly never associated with a MetadataVersion.  Updates the LATEST_PRODUCTION MetadataVersion to IBP_3_7_IV4 to declare both KRaft JBOD and the KIP-951 changes ready for production use.

Reviewers: Omnia G H Ibrahim <o.g.h.ibrahim@gmail.com>, Ron Dagostino <rdagostino@confluent.io>, Ismael Juma <ismael@juma.me.uk>, José Armando García Sancio <jsancio@apache.org>, Justine Olshan <jolshan@confluent.io>",2023-12-14 10:08:54,Proven Provenzano,Mixed
9dc9040f330988eea049c59cb23417f2021ffbc4,"KAFKA-15276: Implement event plumbing for ConsumerRebalanceListener callbacks (#14640)

This patch adds the logic for coordinating the invocation of the `ConsumerRebalanceListener` callback invocations between the background thread (in `MembershipManagerImpl`) and the application thread (`AsyncKafkaConsumer`) and back again. It allowed us to enable more tests from `PlaintextConsumerTest` to exercise the code herein.

Reviewers: David Jacot <djacot@confluent.io>",2023-12-15 00:42:31,Kirk True,Mixed
52496dcd385acc6fcbae93396c47f90c0cf5cfb6,"KAFKA-16013: Add metric for expiration rate of delayed remote fetch (#15014)

Add metric for the number of expired remote fetches per second, and corresponding unit test to verify that the metric is marked on expiration.

kafka.server:type=DelayedRemoteFetchMetrics,name=ExpiresPerSec

Reviewers: Luke Chen <showuon@gmail.com>, Satish Duggana <satishd@apache.org>, Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Christo Lolov <lolovc@amazon.com>",2023-12-15 19:21:39,Nikhil Ramakrishnan,Mixed
3bd8ec16f680e9195e1028d30dab48771fc9fb54,"MINOR: Transform new coordinator error before returning to client (#15001)

This was missing from https://issues.apache.org/jira/browse/KAFKA-14500. The existing coordinator transforms the log append error before returning to client. Apply the same transformation.

Reviewers: David Jacot <djacot@confluent.io>",2023-12-15 06:33:25,Jeff Kim,Mixed
7f763d327fbde2e9849a6548efee4ce165b6fcb1,"KAFKA-16007 Merge batch records during ZK migration (#15007)

To avoid creating lots of small KRaft batches during the ZK migration, this patch adds a mechanism to merge batches into sizes of at least 1000. This has the effect of reducing the number of batches sent to Raft which reduces the amount of time spent blocking.

Since migrations use metadata transactions, the batch boundaries for migrated records are not significant. Even in light of that, this implementation does not break up existing batches. It will only combine them into a larger batch to meet the minimum size.

Reviewers: José Armando García Sancio <jsancio@apache.org>",2023-12-15 19:33:15,David Arthur,Mixed
c240993be2178a7142e1fd6aa78b986d94be7d9f,"KAFKA-16014: Add RemoteLogSizeComputationTime metric (#15021)

Reviewers: Satish Duggana <satishd@apache.org>, Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Christo Lolov <lolovc@amazon.com>",2023-12-18 21:39:43,Luke Chen,Mixed
f385ef468b57b02b064451306ebed3c11e37889d,"KAFKA-15364: Replay BrokerRegistrationChangeRecord.logDirs (#14998)

Any directory changes must be considered when replaying
BrokerRegistrationChangeRecord. This is necessary
to persist directory failures in the cluster metadata,
which #14902 missed.

Reviewers: Omnia G.H Ibrahim <o.g.h.ibrahim@gmail.com>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>",2023-12-18 15:43:28,Igor Soarez,Mixed
0cb7d747fbd94ae2387cdd1da5729b4bbbec6f2a,"KAFKA-15913: Migrate async consumer tests to mocks (#14930)

Use mocks to test the AsyncKafkaConsumer

Eliminate the use of ConsumerTestBuilder
Mock all resources that were previously retrieved via leaking
the background thread with mockito spys
Always use the default constructor of AsyncKafkaConsumer as
much as possible, inject mocks via factories.
Timeouts are mocked directly by timeout exceptions instead
of waiting for futures to time out.
I did not port the autocommit mocking code, because it was mostly
testing the integration of foreground and background thread (or
making the spy's work which broke during the autocommit on close)
and is currently being reimplemented anyway.

New test runs 10x faster.

Reviewers: Bruno Cadonna <cadonna@apache.org>",2023-12-18 22:41:57,Lucas Brutschy,Mixed
7b21da9712c6eead69150b508cb2e21103744a71,"KAFKA-15158: Add metrics for RemoteDelete and BuildRemoteLogAuxState (#14375)

This PR implements part of KIP-963, specifically for adding new metrics.
The metrics added in this PR are:
    RemoteDeleteRequestsPerSec (emitted when expired log segments on remote storage being deleted)
    RemoteDeleteErrorsPerSec (emitted when failed to delete expired log segments on remote storage)
    BuildRemoteLogAuxStateRequestsPerSec (emitted when building remote log aux state for replica fetchers)
    BuildRemoteLogAuxStateErrorsPerSec (emitted when failed to build remote log aux state for replica fetchers)

Reviewers: Luke Chen <showuon@gmail.com>, Nikhil Ramakrishnan <ramakrishnan.nikhil@gmail.com>, Christo Lolov <lolovc@amazon.com>, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>, Divij Vaidya <diviv@amazon.com>, Satish Duggana <satishd@apache.org>",2023-12-19 15:02:45,Gantigmaa Selenge,Mixed
5e37ec80f840be78d12694ea967d409d943f9a03,"KAFKA-15696: Refactor closing consumer (#14937)

We drive the consumer closing via events, and rely on the still-lived network thread to complete these operations.

This ticket encompasses several different tickets:
KAFKA-15696/KAFKA-15548

When closing the consumer, we need to perform a few tasks. And here is the top level overview:
We want to keep the network thread alive until we are ready to shut down, i.e., no more requests need to be sent out. To achieve so, I implemented a method, signalClose() to signal the managers to prepare for shutdown. Once we signal the network thread to close, the manager will prepare for the request to be sent out on the next event loop. The network thread can then be closed after issuing these events. The application thread's task is pretty straightforward, 1. Tell the background thread to perform n events and 2. Block on certain events until succeed or the timer runs out. Once all requests are sent out, we close the network thread and other components as usual.

Here I outline the changes in detail

AsyncKafkaConsumer: Shutdown procedures, and several utility functions to ensure proper exceptions are thrown during shutdown
AsyncKafkaConsumerTest: I examine each individual test and fix ones that are blocking for too long or logging errors
CommitRequestManager: signalClose()
FetchRequestManagerTest: changes due to change in pollOnClose()
ApplicationEventProcessor: handle CommitOnClose and LeaveGroupOnClose. Latter, it triggers leaveGroup() which should be completed on the next heartbeat (or we time out on the application thread)

Reviewers:  Lucas Brutschy <lbrutschy@confluent.io>, Kirk True <ktrue@confluent.io>",2023-12-19 13:20:33,Philip Nee,Mixed
05014badf2f8ae1e7ff8e0e4684eb746c3f65d7e,"KAFKA-15208: Upgrade Jackson dependencies to version 2.16.0 (#13662)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Divij Vaidya <diviv@amazon.com>",2023-12-19 15:31:24,Said Boudjelda,Mixed
f3038d5e7326b3104a35797ec19f359c923a5040,"KAFKA-15870: Move new group coordinator metrics from Yammer to Metrics (#14848)

This patch moves all the newly introduced metrics to the Kafka Metrics.

Reviewers: David Jacot <djacot@confluent.io>",2023-12-19 23:37:40,Jeff Kim,Mixed
db8af514264491e52d737300bf703d473e3c676a,"MINOR: Client state machine fix for transition to stable on initial empty assignment (#15033)

This includes a fix for ensuring that a member transitions to STABLE when joining a group, in the case where it receives an initial empty assignment.

Reviewer: Bruno Cadonna <cadonna@apache.org>",2023-12-20 09:22:54,Lianet Magrans,Mixed
4e11de00a7cefa9e77d848603a52131c86fce4b5,"KAFKA-16014: Add RemoteLogMetadataCount metric (#15026)

Reviewers: Christo Lolov <lolovc@amazon.com>, Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Satish Duggana <satishd@apache.org>",2023-12-20 14:21:30,Luke Chen,Mixed
919b585da0c824efa5250a9fda62b42468caabc6,"KAFKA-15874: Add metric and request log attribute for deprecated request api versions (KIP-896) (#15032)

Breakdown of this PR:
* Extend the generator to support deprecated api versions
* Set deprecated api versions via the request json files
* Expose the information via metrics and the request log

The relevant section of the KIP:

> * Introduce metric `kafka.network:type=RequestMetrics,name=DeprecatedRequestsPerSec,request=(api-name),version=(api-version),clientSoftwareName=(client-software-name),clientSoftwareVersion=(client-software-version)`
> * Add boolean field `requestApiVersionDeprecated`  to the request
header section of the request log (alongside `requestApiKey` ,
`requestApiVersion`, `requestApiKeyName` , etc.).

Unit tests were added to verify the new generator functionality,
the new metric and the new request log attribute.

Reviewers: Jason Gustafson <jason@confluent.io>",2023-12-20 05:13:36,Ismael Juma,Mixed
1a97de2fe6a00b5353bea0153132e0a622b9f619,"KAFKA-16002: Implement RemoteCopyLagSegments, RemoteDeleteLagBytes and RemoteDeleteLagSegments (#15005)

This pull request aims to implement RemoteCopyLagSegments, RemoteDeleteLagBytes and RemoteDeleteLagSegments from KIP-963.

Reviewers: Luke Chen <showuon@gmail.com>, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>",2023-12-21 14:27:12,Christo Lolov,Mixed
d59d61325872d256474ba30ea858a0f3877c8331,"KAFKA-16013: Throw an exception in DelayedRemoteFetch for follower fetch replicas. (#15015)

Follow-up for KAFKA-16013: Add metric for expiration rate of delayed remote fetch 

Reviewers: Nikhil Ramakrishnan <ramakrishnan.nikhil@gmail.com>, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>,  Satish Duggana <satishd@apache.org>",2023-12-21 15:45:24,Luke Chen,Mixed
19727f8d51ac56a00f7159705349c981a063df8f,"KAFKA-16017: Checkpoint restored offsets instead of written offsets (#15044)

Kafka Streams checkpoints the wrong offset when a task is closed during
restoration. If under exactly-once processing guarantees a
TaskCorruptedException happens, the affected task is closed dirty, its
state content is wiped out and the task is re-initialized. If during
the following restoration the task is closed cleanly, the task writes
the offsets that it stores in its record collector to the checkpoint
file. Those offsets are the offsets that the task wrote to the changelog
topics. In other words, the task writes the end offsets of its changelog
topics to the checkpoint file. Consequently, when the task is
initialized again on the same Streams client, the checkpoint file is
read and the task assumes it is fully restored although the records
between the last offsets the task restored before closing clean and
the end offset of the changelog topics are missing locally.

The fix is to clear the offsets in the record collector on close.

Reviewer: Lucas Brutschy <lbrutschy@confluent.io>",2023-12-21 10:15:04,Bruno Cadonna,Mixed
75dcc8dadf16bab8966117c635043b85a65ad27d,"KAFKA-16036; Add `group.coordinator.rebalance.protocols` and publish all new configs (#15053)

This patch adds the group.coordinator.rebalance.protocols configuration which accepts a list of protocols to enable. At the moment, only generic and consumer are supported and it is not possible to disable generic yet. When consumer is enabled, the new consumer rebalance protocol (KIP-848) is enabled alongside the new group coordinator. This patch also publishes all the new configurations introduced by KIP-848.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Stanislav Kozlovski <stanislav@confluent.io>",2023-12-21 04:43:57,David Jacot,Mixed
6250049e107f2279fa866bc61e5150187f7c1a7f,"KAFKA-13950: Fix resource leak in error scenarios (#12228)

We are not properly closing Closeable resources in the code base at multiple places especially when we have an exception. This code change fixes multiple of these leaks.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Luke Chen <showuon@gmail.com>, Mickael Maison <mickael.maison@gmail.com>",2023-12-21 13:47:22,Divij Vaidya,Mixed
461328607655b46d6017b07135a1d15634192a69,"KAFKA-16030: new group coordinator should check if partition goes offline during load (#15043)

The new coordinator stops loading if the partition goes offline during load. However, the partition is still considered active. Instead, we should return NOT_LEADER_OR_FOLLOWER exception during load.

Another change is that we only want to invoke CoordinatorPlayback#updateLastCommittedOffset if the current offset (last written offset) is greater than or equal to the current high watermark. This is to ensure that in the case the high watermark is ahead of the current offset, we don't clear snapshots prematurely.

Reviewers: David Jacot <djacot@confluent.io>",2023-12-21 06:17:35,Jeff Kim,Mixed
818336c561965c3642732dd866ed172468846a50,"KAFKA-15456: Commit/Fetch error handling improvements and V9 support (#14557)

This patch includes multiple fixes for OffsetFetch and OffsetCommit related to error handling and retries, introducing support for new errors as defined in the requests version 9.

- Fixes for OffsetFetch and OffsetCommit error handling (retry when applicable, properly time-bound retries)
- Fixes for commitSync retried and commitAsync not retried
- Support for OffsetFetch and OffsetCommit v9, retried with backoff with the latest memberID/epoch if the member is still in the group, or failed if the member is not in the group anymore (left/failed/fenced). 
- Minor refactoring for removing unneeded group state and generation info and other minor clean up.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Kirk True <ktrue@confluent.io>, Bruno Cadonna <cadonna@apache.org>, Lucas Brutschy <lbrutschy@confluent.io>, David Jacot <djacot@confluent.io>",2023-12-21 06:48:34,Lianet Magrans,Mixed
79757b30813c8b15548adad18b1a6c99d6f65ac9,"KAFKA-14505; [3/N] Wire WriteTxnMarkers API (#14985)

This patch wires the handling of makers written by the transaction coordinator via the WriteTxnMarkers API. In the old group coordinator, the markers are written to the logs and the group coordinator is informed to materialize the changes as a second step if the writes were successful. This approach does not really work with the new group coordinator for mainly two reasons: 1) The second step would actually fail while the coordinator is loading and there is no guarantee that the loading has picked up the write or not; 2) It does not fit well with the new memory model where the state is snapshotted by offset. In both cases, it seems that having a single writer to the `__consumer_offsets` partitions is more robust and preferable.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2023-12-21 10:59:41,David Jacot,Mixed
98aca56ee53d4af5e9314e45fbd9f048745c3328,"KAFKA-16040; Rename `Generic` to `Classic` (#15059)

People has raised concerned about using `Generic` as a name to designate the old rebalance protocol. We considered using `Legacy` but discarded it because there are still applications, such as Connect, using the old protocol. We settled on using `Classic` for the `Classic Rebalance Protocol`.

The changes in this patch are extremely mechanical. It basically replaces the occurrences of `generic` by `classic`.

Reviewers: Divij Vaidya <diviv@amazon.com>, Lucas Brutschy <lbrutschy@confluent.io>",2023-12-21 13:39:17,David Jacot,Mixed
d4f3bf93d315db245f44001aec0965fe7c34fb99,"KAFKA-16014: Implement RemoteLogSizeBytes (#15050)

This pull request aims to implement RemoteLogSizeBytes from KIP-963.

Reviewers: Kamal Chandraprakash <kamal.chandraprakash@gmail.com>,  Satish Duggana <satishd@apache.org>, Luke Chen <showuon@gmail.com>",2023-12-22 15:00:44,Christo Lolov,Mixed
c963a71be0e1f1674b2738f4bfd23400036683eb,"KAFKA-16026: Send Poll event to the background thread (#15035)

related to KAFKA-15818

This is a bug in the AsyncKafkaConsumer poll loop that it does not send an event to the network thread to acknowledge user poll. This causes a few issues:

Autocommit won't work without user setting the timer
the member will just leave the group after rebalance timeout and never able to rejoin.
In this PR, a few subtle changes are made to address this issue

Hook up poll event to the AsyncKafkaConsumer#poll. It is only fired once per invocation
Upon entering staled state, we need to reset HeartbeatState otherwise we will get an invalid request
We will clear and current assignment and remove all assigned partitions once the heartbeat is sent. See changes in onHeartbeatRequestSent

Reviewers: David Jacot <djacot@confluent.io>, Bruno Cadonna <cadonna@apache.org>, Andrew Schofield <aschofield@confluent.io>",2023-12-22 15:21:39,Philip Nee,Mixed
18a65b25c18c30ce8ed87ffaee5b982c211e3636,"KAFKA-16046: fix stream-stream-join store types (#15061)

Before #14648, the KStreamImplJoin class would always create non-timestamped persistent windowed stores. After that PR, the default was changed to create timestamped stores. This wasn't compatible because, during restoration, timestamped stores have their values transformed to prepend the timestamp to the value. This caused serialization errors when trying to read from the store because the deserializers did not expect the timestamp to be prepended.

To fix this, we allow creating non-timestamped stores using the DslWindowParams

Testing was done both manually as well as adding a unit test to ensure that the stores created are not timestamped. I also confirmed that the only place in the code persistentWindowStore was used before #14648 was in the StreamJoined code.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2023-12-22 15:23:58,Almog Gavra,Not TDD
45bd19f2efc6c6a681297ae8f28afc26c133445c,"KAFKA-14588: Move ConfigType to server-common (#14867)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2023-12-22 18:35:27,Nikolay,Mixed
c0967aa6159c447c30cc43ea0e3ca5b1d7db8908,"KAFKA-16012: Ensure new leader information merged correctly with the current metadata (#15023)

A small bug in KIP-951 that when we perform metadata update during the leader change, we replace all topic metadata with the partial response from the fetch response, which leads to the consumer only fetching from a subset of partitions.

In this PR, the predicate we pass in to MetadataCache#mergeWith always return true, because we always want to retain the current topic metadata.

Reviewers: Justine Olshan <jolshan@confluent.io>",2023-12-22 16:06:18,Philip Nee,Mixed
ee65ca22b5cd15f54a852848626dc6fb3d9473d6,"KAFKA-16021: Eagerly look up StringSerializer encoding during configure (#15024)

This commit changes the validation for the correctness of encoding defined in properties from (de)seralization time to initialization time.

Reviewers: Divij Vaidya <diviv@amazon.com>",2023-12-24 21:27:59,Stig Døssing,Not TDD
f80686b4acb8c6ad0b836be2d3bf453d4d15ea73,"MINOR: Improve code style (#15074)

Reviewers: Divij Vaidya <diviv@amazon.com>",2023-12-26 12:21:12,DL1231,Mixed
ae4d308f6806fac398665723041ca62fca78abee,"KAFKA-16015: Fix custom timeouts overwritten by defaults in LeaderElectionCommand (#15030)

This commit fixes a bug in LeaderElectionCommand due to which custom timeout configuration was not being respected.

Reviewers: Divij Vaidya <diviv@amazon.com>, Proven Provenzano <pprovenzano@confluent.io>",2023-12-29 10:50:26,Sergio Troiano,Mixed
cd1eb634c506e861d7445b2b5a3f40258d77fa17,"KAFKA-15816: Fix leaked sockets in runtime tests (#14764)

This commit fixes to prevent socket leaks, mostly through clients that are left open.

Reviewers: Mickael Maison <mickael.maison@gmail.com>",2024-01-01 11:38:11,Greg Harris,Not TDD
e01eed32ab2a223f8231a7d7e6c4eef05a7fed6f,"KAFKA-9545: Fix IllegalStateException in updateLags (#15096)

We attempt to update lags when in state PENDING_SHUTDOWN or PARTITIONS_REVOKED. In these states,
however, our representation of the assignment may not be up-to-date with the subscription
object inside the consumer. This can cause a bug, in particular, when we subscribe to a
set of topics via a regular expression, and the underlying topic is deleted. The consumer
subscription may reflect that topic deletion already, while our internal state still
contains references to the deleted topic, because `onAssignment` has not yet been
executed. Therefore, we will attempt to call `currentLag` on partitions that are not
assigned to us any more inside the consumer, leading to an `IllegalStateException`.

This bug causes flakiness of the test
`RegexSourceIntegrationTest.testRegexMatchesTopicsAWhenDeleted`.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bruno Cadonna <cadonna@apache.org>",2024-01-02 16:35:31,Lucas Brutschy,Mixed
e6875f378c628c6a024faf1731118de857cca707,"KAFKA-16046: also fix stores for outer join (#15073)

This is the corollary to #15061 for outer joins, which don't use timestamped KV stores either (compared to just window stores).

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Lucas Brutschy <lbrutschy@confluent.io>",2024-01-02 15:07:46,Almog Gavra,Not TDD
105db82956e8a2a22d0a16aaae57fa69a5aeeec4,"KAFKA-15373: fix exception thrown in Admin#describeTopics for unknown ID (#14599)

Throw UnknownTopicIdException instead of InvalidTopicException when no name is found for the topic ID.

Similar to #6124 for describeTopics using a topic name. MockAdminClient already makes use of UnknownTopicIdException for this case.

Reviewers: Justine Olshan <jolshan@confluent.io>, Ashwin Pankaj <apankaj@confluent.io>",2024-01-03 17:56:17,Michael Edgar,Mixed
eccfb03e9aebdde52c592bd068ef1a2b7c926c7c,"MINOR: Small cleanups in Connect (#15128)


Reviewers: Divij Vaidya <diviv@amazon.com>",2024-01-05 11:00:10,Mickael Maison,Mixed
599e22b84214d7ee7e1749fd3059584f32f80132,"MINOR: Move Raft io thread implementation to Java (#15119)

This patch moves the `RaftIOThread` implementation into Java. I changed the name to `KafkaRaftClientDriver` since the main thing it does is drive the calls to `poll()`. There shouldn't be any changes to the logic.

Reviewers: José Armando García Sancio <jsancio@apache.org>",2024-01-05 09:27:36,Jason Gustafson,Mixed
c0b649345580e4dfb2ebb88d3aaace71afe70d75,"KAFKA-16077: Streams with state updater fails to close task upon fencing (#15117)

* KAFKA-16077: Streams fails to close task after restoration when input partitions are updated

There is a race condition in the state updater that can cause the following:

 1. We have an active task in the state updater
 2. We get fenced. We recreate the producer, transactions now uninitialized. We ask the state updater to give back the task, add a pending action to close the task clean once it’s handed back
 3. We get a new assignment with updated input partitions. The task is still owned by the state updater, so we ask the state updater again to hand it back and add a pending action to update its input partition
 4. The task is handed back by the state updater. We update its input partitions but forget to close it clean (pending action was overwritten)
 5. Now the task is in an initialized state, but the underlying producer does not have transactions initialized

This can cause an IllegalStateException: `Invalid transition attempted from state UNINITIALIZED to state IN_TRANSACTION` when running in EOSv2.

To fix this, we introduce a new pending action CloseReviveAndUpdateInputPartitions that is added when we handle a new assignment with updated input partitions, but we still need to close the task before reopening it.

We should not remove the task twice, otherwise, we'll end up in this situation

1. We have an active task in the state updater
2. We get fenced. We recreate the producer, transactions now uninitialized. We ask the state updater to give back the task, add a pending action to close the task clean once it’s handed back
3. The state updater moves the task from the updating tasks to the removed tasks
4. We get a new assignment with updated input partitions. The task is still owned by the state updater, so we ask the state updater again to hand it back (adding a task+remove into the task and action queue) and add a pending action to close, revive and update input partitions
5. The task is handed back by the state updater. We close revive and update input partitions, and add the task back to the state updater
6. The state updater executes the ""task+remove"" action that is still in its task + action queue, and hands the task immediately back to the main thread
7. The main thread discoveres a removed task that was not restored and has no pending action attached to it. IllegalStateException

Reviewers: Bruno Cadonna <cadonna@apache.org>",2024-01-05 19:32:33,Lucas Brutschy,Mixed
da2aa68269462dcc1852cedb1428082504de8b5b,"KAFKA-14588: Move ConfigEntityName to server-common (#14868)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>",2024-01-08 12:41:43,Nikolay,Mixed
116762fdcecc2328762b1813e1354b4a56669794,"KAFKA-16016: Add docker wrapper in core and remove docker utility script (#15048)

Migrates functionality provided by utility to Kafka core. This wrapper will be used to generate property files and format storage when invoked from docker container.

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-01-08 18:07:38,Vedarth Sharma,Mixed
f1a0207cbbbb7802a16d38c3cad37143b2918007,"KAFKA-16025: Fix orphaned locks when rebalancing and store cleanup race on unassigned task directories (#15088)

KAFKA-16025 describes the race condition sequence in detail. When this occurs, it can cause the impacted task's initializing to block indefinitely, blocking progress on the impacted task, and any other task assigned to the same stream thread. The fix I have implemented is pretty simple, simply re-check whether a directory is still empty after locking it during the start of rebalancing, and if it is, unlock it immediately. This preserves the idempotency of the method when it coincides with parallel state store cleanup executions.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2024-01-08 14:49:48,sanepal,Mixed
ac7ddc7d461a8872cb84d2cc3ce4cbe60f16ea94,"MINOR: Remove classic group preparing rebalance sensor (#15143)

Remove ""group-rebalance-rate"" and ""group-rebalance-count"" metrics from the new coordinator as this is not part of KIP-848.

Reviewers: David Jacot <djacot@confluent.io>",2024-01-09 01:10:21,Jeff Kim,Mixed
aa7ba7bd5afd570c6dcf0db7d180d5a04ca084b4,"KAFKA-16094: BrokerRegistrationRequest.logDirs field must be ignorable (#15153)

3.7 brokers must be able to register with 3.6 and earlier controllers. Currently, this is broken
because we will unconditionally try to set logDirs, but this field cannot be sent with
BrokerRegistrationRequest versions older than v2. This PR marks the logDirs field as ""ignorable.""
Marking the field as ""ignorable"" means that we will still be able to send the
BrokerRegistrationRequest even if the schema doesn't support logDirs.

Reviewers: Ron Dagostino  <rdagostino@confluent.io>",2024-01-09 15:04:27,Colin Patrick McCabe,Not TDD
0349f2310c0b8bc94cda673ac66dba1012d2dba6,"KAFKA-16097: Add suspended tasks back to the state updater when reassigned (#15163)

When a partition is revoked, the corresponding task gets a pending action
""SUSPEND"". This pending action may overwrite a previous pending action.

If the task was previously removed from the state updater, e.g. because
we were fenced, the pending action is overwritten with suspend, and in
handleAssigned, upon reassignment of that task, then SUSPEND action is
removed.

Then, once the state updater executes the removal, no pending action
is registered anymore, and we run into an IllegalStateException.

This commit solves the problem by adding back reassigned tasks to the
state updater, since they may have been removed from the state updater
for another reason than being restored completely.

Reviewers: Bruno Cadonna <cadonna@apache.org>",2024-01-10 10:21:38,Lucas Brutschy,Mixed
dbf00bcf45d30f2c9567585f15121fe46b030d4c,"KAFKA-16093: Fix spurious REST-related warnings on Connect startup (#15149)

Reviewers: Sagar Rao <sagarmeansocean@gmail.com>, Greg Harris <greg.harris@aiven.io>",2024-01-10 09:03:23,Chris Egerton,Mixed
fbbfafe1f556f424bf511697db6f399e5a622aa3,"KAFKA-16098: Verify pending recycle action when standby is re-assigned (#15168)

When a standby is recycled to an active and then re-assigned as
a standby again, it might happen that the recycling is still
pending when the standby is reassigned. That causes an illegal
state exception from the main consumer since the active task
that results from the recycling is actually not assigned to
the main consumer anymore, but it was re-assigned as a
standby in the most recent rebalance.

Reviewer: Lucas Brutschy <lbrutschy@confluent.io>",2024-01-10 17:59:06,Bruno Cadonna,Mixed
13a83d58f897de2f55d8d3342ffb058b230a9183,"KAFKA-15853: Move ProcessRole to server module (#15166)

Prepare to move KafkaConfig (#15103).

Reviewers: Ismael Juma <ismael@juma.me.uk>",2024-01-10 15:13:06,Omnia Ibrahim,Mixed
cd3b3d9804f3b5193870ada2aeea00045acc2c30,"MINOR: fix custom retry backoff in new group coordinator (#15170)

When a retryable write operation fails, we retry with the default 500ms backoff. If a custom retry backoff was used to originally schedule the operation, we should retry with the same custom backoff instead of the default.

Reviewers: David Jacot <djacot@confluent.io>",2024-01-11 00:28:32,Jeff Kim,Mixed
da175b5ff70f3ce923058c6cf4a496318bfc439e,"KAFKA-16083: Exclude throttle time when expiring inflight requests on a connection (#15130)

When expiring inflight requests, the network client does not take throttle time into account. If a connection has multiple inflight requests (default of 5) and each request is throttled then some of the requests can incorrectly marked as expired. Subsequently the connection is closed and the client establishes a new connection to the broker. This behavior leads to unnecessary connections to the broker, leads to connection storms and increases latencies.",2024-01-11 10:32:24,Aadithya Chandra,Mixed
dba789dc93d8dee2965ea41df49f0c981f5dfa6f,"KAFKA-15853: Move OffsetConfig to group-coordinator module (#15161)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, David Jacot <djacot@confluent.io>, Nikolay <nizhikov@apache.org>",2024-01-11 10:19:42,Omnia Ibrahim,Mixed
a8203f9c7a2c449ee59ee29d775409b2f1e00d07,"KAFKA-14505; [4/N] Wire transaction verification (#15142)

This patch wires the transaction verification in the new group coordinator. It basically calls the verification path before scheduling the write operation. If the verification fails, the error is returned to the caller.

Note that the patch uses `appendForGroup`. I suppose that we will move away from using it when https://github.com/apache/kafka/pull/15087 is merged.

Reviewers: Justine Olshan <jolshan@confluent.io>",2024-01-11 04:58:57,David Jacot,Mixed
6ff21ee1e009a5a2729bb105591a9bfa16c6c4c5,"MINOR: Disalow using a group id with only whitespaces in the new consumer group protocol (#15173)

This patch strengthen the validation of the group id when the new consumer group protocol is used.

Reviewers: Divij Vaidya <diviv@amazon.com>",2024-01-11 07:04:18,David Jacot,Mixed
65424ab484b8175386b53ee5d56c980d078c29a1,"MINOR: New year code cleanup - include final keyword (#15072)

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ismael Juma <ismael@juma.me.uk>, Sagar Rao <sagarmeansocean@gmail.com>",2024-01-11 17:53:35,Divij Vaidya,Not TDD
e9f2218d9475d803d9708c5651ef4b9c93db71ae,"KAFKA-15853: Move ReplicationQuotaManagerConfig to server module (#15160)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Nikolay <nizhikov@apache.org>",2024-01-12 10:47:26,Omnia Ibrahim,Mixed
6b9cb5ccbfaf8fa9e76db3425a5ad08bbcda3446,"KAFKA-14505; [5/N] Add `UNSTABLE_OFFSET_COMMIT` error support (#15155)

This patch adds `UNSTABLE_OFFSET_COMMIT` errors support in the new group coordinator. `UNSTABLE_OFFSET_COMMIT` errors for partitions with unstable offset commits. Here unstable means that there are ongoing transactions.

Reviewers: Justine Olshan <jolshan@confluent.io>",2024-01-12 05:33:39,David Jacot,Mixed
21227bda61e75e3a8f1401ff94b27e9161cd3f1b,"KAFKA-15816: Fix leaked sockets in core tests (#14754)

Signed-off-by: Greg Harris <greg.harris@aiven.io>
Reviewers: Mickael Maison <mickael.maison@gmail.com>",2024-01-12 13:18:03,Greg Harris,Not TDD
3a6e699f1332b40bd670288587bcc342ef1e190d,"KAFKA-16118; Coordinator unloading fails when replica is deleted (#15182)

When a replica is deleted, the unloading procedure of the coordinator is called with an empty leader epoch. However, the current implementation of the new group coordinator throws an exception in this case. My bad. This patch updates the logic to handle it correctly.

We discovered the bug in our testing environment. We will add a system test or an integration test in a subsequent patch to better exercise this path.

Reviewers: Justine Olshan <jolshan@confluent.io>",2024-01-12 15:34:52,David Jacot,Mixed
988aea3f58f2a198dea7018c4adfd7cfd09855a3,"KAFKA-16051: Fixed deadlock in StandaloneHerder (#15080)

Reviewers: Greg Harris <greg.harris@aiven.io>, Sagar Rao <sagarmeansocean@gmail.com>",2024-01-12 15:46:17,Octavian Ciubotaru,Mixed
ef92deee9d6cf59c912e2556b221d9da60058c0c,"KAFKA-15388: Handling remote segment read in case of log compaction (#15060)

Fetching from remote log segment implementation does not handle the topics that had retention policy as compact earlier and changed to delete. It always assumes record batch will exist in the required segment for the requested offset. But there is a possibility where the requested offset is the last offset of the segment and has been removed due to log compaction. Then it requires iterating over the next higher segment for further data as it has been done for local segment fetch request.

This change partially addresses the above problem by iterating through the remote log segments to find the respective segment for the target offset.

Reviewers: Satish Duggana <satishd@apache.org>, Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Divij Vaidya <diviv@amazon.com>, Christo Lolov <lolovc@amazon.com>",2024-01-15 05:15:58,Arpit Goyal,Mixed
d0f845a5e1a2ecceadca3978cdc6adb1eeed27e3,"KAFKA-16120: Fix partition reassignment during ZK migration

When we are migrating from ZK mode to KRaft mode, the brokers pass through a phase where they are
running in ZK mode, but the controller is in KRaft mode (aka a kcontroller). This is called ""hybrid
mode."" In hybrid mode, the KRaft controllers send old-style controller RPCs to the remaining ZK
mode brokers. (StopReplicaRequest, LeaderAndIsrRequest, UpdateMetadataRequest, etc.)

To complete partition reassignment, the kcontroller must send a StopReplicaRequest to any brokers
that no longer host the partition in question. Previously, it was sending this StopReplicaRequest
with delete = false. This led to stray partitions, because the partition data was never removed as
it should have been. This PR fixes it to set delete = true. This fixes KAFKA-16120.

There is one additional problem with partition reassignment in hybrid mode, tracked as KAFKA-16121.
The issue is that in ZK mode, brokers ignore any LeaderAndIsr request where the partition leader
epoch is less than or equal to the current partition leader epoch. However, when in hybrid mode,
just as in KRaft mode, we do not bump the leader epoch when starting a new reassignment, see:
`triggerLeaderEpochBumpIfNeeded`. This PR resolves this problem by adding a special case on the
broker side when isKRaftController = true.

Reviewers: Akhilesh Chaganti <akhileshchg@users.noreply.github.com>, Colin P. McCabe <cmccabe@apache.org>",2024-01-14 20:32:58,David Mao,Not TDD
b16df3b103d915d33670b8156217fc6c2b473f61,"KAFKA-16133 - Reconciliation auto-commit fix (#15194)

This fixes an issue with the time boundaries used for the auto-commit performed when partitions are revoked.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-01-15 21:50:09,Lianet Magrans,Mixed
0015d0f01b130992acc37da85da6ee2088186a1f,"KAFKA-16126: Kcontroller dynamic configurations may fail to apply at startup

Some kcontroller dynamic configurations may fail to apply at startup. This happens because there is
a race between registering the reconfigurables to the DynamicBrokerConfig class, and receiving the
first update from the metadata publisher. We can fix this by registering the reconfigurables first.
This seems to have been introduced by the ""MINOR: Install ControllerServer metadata publishers
sooner"" change.

Reviewers: Ron Dagostino  <rdagostino@confluent.io>",2024-01-16 16:03:17,Colin P. McCabe,Not TDD
26465c64092868c972e2a0e4d9a4fc0ed13a7a39,"KAFKA-16097: Disable state updater in trunk (#15204)

Several problems are still appearing while running 3.7 with
the state updater. This change will disable the state updater
by default also in trunk.

Reviewers: Bruno Cadonna <cadonna@apache.org>",2024-01-17 15:25:26,Lucas Brutschy,Not TDD
2df8c1ca3de0bf428e90e3fbff311a24062a27bc,"KAFKA-15807: Added support for compression of metrics (KIP-714) (#15148)

Part of KIP-714.

Adds support for compression/decompression of metrics.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Philip Nee <pnee@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2024-01-17 13:49:57,Apoorv Mittal,Mixed
6c14d779989dc7fec5f03c18830f1f3b80ad693e,"KAFKA-16131: Only update directoryIds if the metadata version supports DirectoryAssignment (#15197)

We only want to send directory assignments if the metadata version supports it.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2024-01-17 14:06:38,Proven Provenzano,Mixed
7bf7fd99a50ba2dd71c41cd4c3623a3adce092b6,"KAFKA-16078: Be more consistent about getting the latest MetadataVersion

This PR creates MetadataVersion.latestTesting to represent the highest metadata version (which may be unstable) and MetadataVersion.latestProduction to represent the latest version that should be used in production. It fixes a few cases where the broker was advertising that it supported the testing versions even when unstable metadata versions had not been configured.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Ismael Juma <ismael@juma.me.uk>",2024-01-17 14:59:22,David Arthur,Mixed
96f852f9e7d14c2eb8fe98fc2a90da917917377a,"MINOR: log new coordinator partition load schedule time (#15017)

The current load summary exposes the time from when the partition load operation is scheduled to when the load completes. We are missing the information of how long the scheduled operation stays in the scheduler. Log that information.

Reviewers: David Jacot <djacot@confluent.io>",2024-01-18 02:28:17,Jeff Kim,Mixed
2f2a0d799abb22ffdf3c76035261ac6589b7e7f2,"KAFKA-15853: Move ClientQuotaManagerConfig outside of core (#15159)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Nikolay <NIzhikov@gmail.com>",2024-01-18 16:15:13,Omnia Ibrahim,Mixed
72b70288eb8027bca8c1bd8e13bf04602cc8cf1a,"KAFKA-5863: Avoid NPE when RestClient calls expecting no-content receive content. (#13294)

Signed-off-by: Greg Harris <greg.harris@aiven.io>
Reviewers: Hector Geraldino <hgeraldino@gmail.com>, Yash Mayya <yash.mayya@gmail.com>",2024-01-18 11:41:27,Greg Harris,Mixed
e45e032b8d90435de2f338f77a732c88f8cca66e,"KAFKA-16087: Avoid data race which drops wrong record when errors.tolerance=all (#15154)

Signed-off-by: Greg Harris <greg.harris@aiven.io>
Reviewers: Chris Egerton <chrise@aiven.io>",2024-01-18 13:26:26,Greg Harris,Mixed
7090a5231a3748b7edf1eb2c189e9f903a306a69,"KAFKA-16113: Add committed and commit sensor to record metrics (#15210)

This commit adds a sensor to the CommitRequestManager to record the necessary metrics, i.e.:

commit-latency-avg
commit-latency-max
commit-rate
commit-total
committed-time-ns-total

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-01-19 13:24:31,Philip Nee,Mixed
aaccf542d126a6415988ee0fa53ec87c715eb622,"KAFKA-16141: Fix StreamsStandbyTask system test (#15217)

KAFKA-15629 added `TimestampedByteStore` interface to
`KeyValueToTimestampedKeyValueByteStoreAdapter` which break the restore
code path and thus some system tests.

This PR reverts this change for now.

Reviewers: Almog Gavra <almog.gavra@gmail.com>, Walker Carlson <wcarlson@confluent.io>",2024-01-19 09:23:42,Matthias J. Sax,Not TDD
556dc2a93f979ed88479a712748f304978089a88,"KAFKA-15811: Enhance request context with client socket port information (KIP-714) (#15190)

PR adds support to capture client socket port information in Request Context. The port from request context is used as matching criteria in filtering clients and shall be used by metrics plugin to fetch port from request context.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Jun Rao <junrao@gmail.com>",2024-01-19 10:28:07,Apoorv Mittal,Mixed
93971465b644ccd7eab76fa23a436608a562e2a0,"KAFKA-15827: Prevent KafkaBasedLog subclasses from leaking passed-in clients (#14763)

Signed-off-by: Greg Harris <greg.harris@aiven.io>
Reviewers: Chris Egerton <chrise@aiven.io>",2024-01-19 12:50:01,Greg Harris,Mixed
cf90382fb92374f526a2b18fa124e2f5e2ed5249,"KAFKA-16147; Partition is assigned to two members at the same time (#15212)

We had a case where a partition got assigned to two members and we found a bug in the partition epochs bookkeeping. Basically, when a member has a partition pending revocation re-assigned to him before the revocation is completed, the partition epoch is lost. Here is an example of such transition:

```
[2024-01-16 12:10:52,613] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=7] [GroupId rdkafkatest_rnd53b4eb0c2de343_0113u] Member M2 transitioned from CurrentAssignment(memberEpoch=11, previousMemberEpoch=9, targetMemberEpoch=14, state=revoking, assignedPartitions={}, partitionsPendingRevocation={EnZMikZURKiUoxZf0rozaA=[0, 1, 2, 3, 4, 5, 6, 7]}, partitionsPendingAssignment={IKXGrFR1Rv-Qes7Ummas6A=[0, 5]}) to CurrentAssignment(memberEpoch=15, previousMemberEpoch=11, targetMemberEpoch=15, state=stable, assignedPartitions={EnZMikZURKiUoxZf0rozaA=[0, 1, 2, 3, 4, 5, 6, 7]}, partitionsPendingRevocation={}, partitionsPendingAssignment={}). (org.apache.kafka.coordinator.group.GroupMetadataManager)
```

This patch fixes the bug and also strengthen the partition epochs bookkeeping to not accept such invalid transitions.

Reviewers: Justine Olshan <jolshan@confluent.io>",2024-01-22 01:16:20,David Jacot,Mixed
62ce551826192ef6137bc3ce670277f79bd3dee2,"KAFKA-15853: Move KafkaConfig.Defaults to server module (#15158)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ismael Juma <ismael@juma.me.uk> , David Jacot <djacot@confluent.io>, Nikolay <NIzhikov@gmail.com>",2024-01-22 15:29:11,Omnia Ibrahim,Not TDD
d1d6b5096f2fc91621192d88a98703d7d9c278fc,"KAFKA-16166: Generify RetryWithToleranceOperator, ErrorReporter, and WorkerTask (#15233)

Signed-off-by: Greg Harris <greg.harris@aiven.io>
Reviewers: Chris Egerton <chrise@aiven.io>",2024-01-22 16:56:52,Greg Harris,Mixed
70bd4ce8a7e20c6a4b176595fbcd6477c91a34e1,"KAFKA-16144: skip checkQuorum for only 1 voter case (#15235)

When there's only 1 voter, there will be no fetch request from other voters. In this case, we should still not expire the checkQuorum timer because there's just 1 voter.

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Federico Valeri <fedevaleri@gmail.com>, José Armando García Sancio <jsancio@apache.org>",2024-01-23 10:17:53,Luke Chen,Mixed
4d6a422e8607c257e58b6956061732dc33621fc2,"KAFKA-14505; [7/N] Always materialize the most recent committed offset (#15183)

When transactional offset commits are eventually committed, we must always keep the most recent committed when we have a mix of transactional and regular offset commits. We achieve this by storing the offset of the offset commit record along side the committed offset in memory. Without preserving information of the commit record offset, compaction of the __consumer_offsets topic itself may result in the wrong offset commit being materialized.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2024-01-22 23:26:40,David Jacot,Mixed
e00d36b9c00da2415cf243ecc3e274b7081ef377,"KAFKA-15468 [1/2]: Prevent transaction coordinator reloads on already loaded leaders (#15139)

This originally was #14489 which covered 2 aspects -- reloading on partition epoch changes where leader epoch did not change and reloading when leader epoch changed but we were already the leader.

I've cut out the second part of the change since the first part is much simpler.

Redefining the TopicDelta fields to better distinguish when a leader is elected (leader epoch bump) vs when a leader has isr/replica changes (partition epoch bump). There are some cases where we bump the partition epoch but not the leader epoch. We do not need to do operations that only care about the leader epoch bump. (ie -- onElect callbacks)

Reviewers: Artem Livshits <alivshits@confluent.io>, José Armando García Sancio <jsancio@apache.org>",2024-01-23 14:58:53,Justine Olshan,Not TDD
208f9e7765361a2d96c4da3f116117a8ca46e145,"KAFKA-15813: Evict client instances from cache (KIP-714) (#15234)

KIP-714 requires client instance cache in broker which should also have a time-based eviction policy where client instances which are not actively sending metrics should be evicted. KIP mentions This client instance specific state is maintained in broker memory up to MAX(60*1000, PushIntervalMs * 3) milliseconds.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Jun Rao <junrao@gmail.com>",2024-01-23 15:06:02,Apoorv Mittal,Mixed
70e0dbd7954c68910b8d7de75e3deb680dd53357,"Delete unused classes (#14797)

Reviewers: Mickael Maison <mickael.maison@gmail.com>",2024-01-23 22:04:44,Ismael Juma,Not TDD
839cd1438bd6c62a795c3bce8fd31e523fadbb33,"KAFKA-16107: Stop fetching while onPartitionsAssign completes (#15215)

This ensures that no records are fetched, or positions initialized, while the onPartitionsAssigned callback completes in the new async consumer Application thread. This is achieved using an internal mark in the subscription state, so that the partitions are not considered fetchable or requiring initializing positions until the callback completes.

Reviewers: David Jacot <djacot@confluent.io>",2024-01-24 04:34:35,Lianet Magrans,Mixed
7e5ef9b509a00973d271def5f70ca2062208e778,"KAFKA-15585: Implement DescribeTopicPartitions RPC on broker (#14612)

This patch implements the new DescribeTopicPartitions RPC as defined in KIP-966 (ELR). Additionally, this patch adds a broker config ""max.request.partition.size.limit"" which limits the number of partitions returned by the new RPC.

Reviewers: Artem Livshits <alivshits@confluent.io>, Jason Gustafson <jason@confluent.io>, David Arthur <mumrah@gmail.com>",2024-01-24 15:16:09,Calvin Liu,Mixed
c6194bbb0ac7415373d3d428155e340f867eb703,"MINOR: populate TopicName in ConsumerGroupDescribe (#15205)

The patch populates the topic name of `ConsumerGroupDescribeResponseData.TopicPartitions` with the corresponding topic id in `ConsumerGroupDescribe`.

Reviewers: David Jacot <djacot@confluent.io>",2024-01-25 05:16:33,Dongnuo Lyu,Mixed
80a1bf8f5695a8565965860400b7bafc31affa8c,"KAFKA-16003: Always create the /config/topics ZNode even for topics without configs (#15022)


Reviewers: Luke Chen <showuon@gmail.com>",2024-01-25 15:46:24,Mickael Maison,Not TDD
e7fa0edd6351c0949b9082c626597046e9def854,"KAFKA-14505; [8/8] Update offset delete paths (#15221)

This is the last patch to complete the implementation of the transactional offsets. This patch updates the following paths:
* delete offsets - the patch ensures that a tombstone is written for pending transactional offsets too.
* delete all offsets - the patch ensures that all pending transactional offsets are deleted too.
* expire offsets - the patch ensures that an offset for a partition is not expire is there is a pending transaction.
* replay offset record - the patch ensures that all pending transactional offsets are removed when a tombstone is received.

Reviewers: Ritika Reddy <rreddy@confluent.io>, Dongnuo Lyu <dlyu@confluent.io>, Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2024-01-26 05:16:22,David Jacot,Mixed
4e6920cc5faf1876d0a8a5cdad3c328b182113ce,"KAFKA-16196: Handle invalid whole value casts in the Cast transform gracefully (#15267)

Reviewers: Chris Egerton <chrise@aiven.io>",2024-01-26 19:04:39,Yash Mayya,Mixed
44272eaa77afb14058104182397d8608c5e275c4,"KAFKA-16032: Fixes for commit/fetch error handling (#15202)

This includes multiple fixes for offsets commit/fetch error handling:
* ensure the right exceptions are thrown for each expected error
* ensure KafkaException is thrown for all unexpected errors
* properly handle disconnection exceptions (added for fetch, fixed for commit)

Reviewers: David Jacot <djacot@confluent.io>",2024-01-26 05:42:54,Lianet Magrans,Mixed
5eb82010ef35f1f34b2ef122b02bdb98b6810e05,"KAFKA-15987: Refactor ReplicaManager code for transaction verification (#15087)

I originally did some refactors in #14774, but we decided to keep the changes minimal since the ticket was a blocker. Here are those refactors:

* Removed separate append paths so that produce, group coordinator, and other append paths all call appendRecords
* AppendRecords has been simplified
* Removed unneeded error conversions in verification code since group coordinator and produce path convert errors differently, removed test for that
* Fixed incorrect capital param name in KafkaRequestHandler
* Updated ReplicaManager test to handle produce appends separately when transactions are used.

Reviewers: David Jacot <djacot@confluent.io>, Jason Gustafson <jason@confluent.io>",2024-01-26 10:01:03,Justine Olshan,Mixed
13c0c5ee97058d77b5bf9959629d1ee6d451787b,"KAFKA-14589 ConsumerGroupServiceTest rewritten in java (#15248)

This PR is part of #14471
Is contains single test rewritten in java.
Intention of separate PR is to reduce changes and simplify review.

Reviewers: Justine Olshan <jolshan@confluent.io>",2024-01-26 10:32:48,Nikolay,Not TDD
33a4709490f6bf8c8844a26dd22f9df1764e9701,"Handle retriable errors in TxnOffsetCommits (#15266)

https://issues.apache.org/jira/browse/KAFKA-14417 updated all transactional APIs to handle retriable errors except for TxnOffsetCommit.

NetworkExceptions have been causing flaky failures in TransactionsBounceTest -- this should hopefully fix that.

Reviewers: Luke Chen <showuon@gmail.com>, Jason Gustafson <jason@confluent.io>",2024-01-26 10:59:21,Justine Olshan,Mixed
93712eca15d5df916cde8ba3dc88451c1737e98d,"KAFKA-15594: Add version 3.6 to Kafka Streams system tests (#15151)

Reviewers: Walker Carlson <wcarlson@confluent.io>",2024-01-26 14:59:24,Matthias J. Sax,Not TDD
70b8c5ae8e9336dbf4792e2d3cf100bbd70d6480,"KAFKA-16085: Add metric value consolidated for topics on a broker for tiered storage. (#15133)

In BrokerTopicMetrics group, we'll provide not only the metric for per topic, but also the all topic aggregated metric value. The beanName is like this:
kafka.server:type=BrokerTopicMetrics,name=RemoteCopyLagSegments
kafka.server:type=BrokerTopicMetrics,name=RemoteCopyLagSegments,topic=Leader

This PR is to add the missing all topic aggregated metric value for tiered storage, specifically for gauge type metrics.

Reviewers: Divij Vaidya <divijvaidya13@gmail.com>, Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Christo Lolov <lolovc@amazon.com>",2024-01-27 19:13:24,Luke Chen,Mixed
82920ffad00285c11453e64e220ac0ec2666ac54,"KAFKA-16095: Update list group state type filter to include the states for the new consumer group type (#15211)

While using —list —state the current accepted values correspond to the classic group type states. This patch adds the new states introduced by KIP-848. It also make the matching on the server case insensitive.

Co-authored-by: d00791190 <dinglan6@huawei.com>

Reviewers: Ritika Reddy <rreddy@confluent.io>, David Jacot <djacot@confluent.io>",2024-01-29 07:19:05,DL1231,Mixed
1a54c25fdfff351fd1b35d60dbc95232c550f3a1,"KAFKA-15942: Implement ConsumerInterceptors in the async consumer (#15000)

We need to make sure to call the consumer interceptor and test its integration.

This is adding the required call in commitSync and commitAsync. The calls in commitAsync are executed using the same mechanism as commit callbacks, to ensure that we are calling the interceptors from a single thread, as is intended in the original KIP.

The interceptors also need to be invoked on auto-commits which are executed in the commit request manager. For this purpose, we share the OffsetCommitCallbackInvoker class with the background thread (it is already accessed implicitly from the background thread through a future lambda). This is done analogous to the RebalanceListenerInvoker.

Co-authored-by: John Doe zh2725284321@gmail.com
Reviewers: Bruno Cadonna <bruno@confluent.io>, Andrew Schofield <aschofield@confluent.io>, Philip Nee <pnee@confluent.io>",2024-01-29 21:26:44,Lucas Brutschy,Mixed
16ed7357b1899d4711c93c1fa094369f8b92480b,"KAFKA-16171: Fix ZK migration controller race #15238

This patch causes the active KRaftMigrationDriver to reload the /migration ZK state after electing
itself as the leader in ZK. This closes a race condition where the previous active controller could
make an update to /migration after the new leader was elected. The update race was not actually a
problem regarding the data since both controllers would be syncing the same state from KRaft to ZK,
but the change to the znode causes the new controller to fail on the zk version check on
/migration.

This patch also fixes a as-yet-unseen bug where the active controllers failing to elect itself via
claimControllerLeadership would not retry.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2024-01-29 13:51:45,David Arthur,Not TDD
f7feb43af351efa25be37cb78814c19bd28a22a2,"KAFKA-14616: Fix stray replica of recreated topics in KRaft mode

When a broker is down, and a topic is deleted, this will result in that broker seeing ""stray
replicas"" the next time it starts up. These replicas contain data that used to be important, but
which now needs to be deleted. Stray replica deletion is handled during the initial metadata
publishing step on the broker.

Previously, we deleted these stray replicas after starting up BOTH LogManager and ReplicaManager.
However, this wasn't quite correct. The presence of the stray replicas confused ReplicaManager.
Instead, we should delete the stray replicas BEFORE starting ReplicaManager.

This bug triggered when a topic was deleted and re-created while a broker was down, and some of the
replicas of the re-created topic landed on that broker. The impact was that the stray replicas were
deleted, but the new replicas for the next iteration of the topic never got created. This, in turn,
led to persistent under-replication until the next time the broker was restarted.

Reviewers: Luke Chen <showuon@gmail.com>, Omnia G H Ibrahim <o.g.h.ibrahim@gmail.com>, Gaurav Narula <gaurav_narula2@apple.com>",2024-01-29 22:36:09,Colin P. McCabe,Mixed
4c6f975ab3deba517c6621c4a051e9beb1240bbc,"KAFKA-16162: resend broker registration on metadata update to IBP 3.7-IV2

We update metadata update handler to resend broker registration when
metadata has been updated to >= 3.7IV2 so that the controller becomes
aware of the log directories in the broker.

We also update DirectoryId::isOnline to return true on an empty list of
log directories while the controller awaits broker registration.

Co-authored-by: Proven Provenzano <pprovenzano@confluent.io>

Reviewers: Omnia G H Ibrahim <o.g.h.ibrahim@gmail.com>, Luke Chen <showuon@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",2024-01-30 10:00:07,Gaurav Narula,Mixed
3e9ef708536612fdfd581623a74e6366c5aea0f6,"KAFKA-15853: Move PasswordEncoder to server-common (#15246)


Reviewers: Luke Chen <showuon@gmail.com>, Omnia Ibrahim <o.g.h.ibrahim@gmail.com>",2024-01-30 19:08:50,Mickael Maison,Mixed
016bd682fe6353016e01ea69848d0d68bec86a90,"KAFKA-16186: Broker metrics for client telemetry (KIP-714) (#15251)

Add the broker metrics defined in KIP-714.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Jun Rao <junrao@gmail.com>",2024-01-30 15:03:09,Apoorv Mittal,Mixed
0472db2cd39d4f53c3855063117bdae15f4d0d86,"MINOR: Uniformize error handling/transformation in GroupCoordinatorService (#15196)

This patch uniformizes the error handling in the GroupCoordinatorService with the aim to reuse the same error translation for all operations. It also ensures that exceptions are unwrapped if needed.

Reviewers: Dongnuo Lyu <dlyu@confluent.io>, Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2024-01-30 23:23:58,David Jacot,Mixed
6dd517daac34a8f1f0167abbc66bc80f2cdcec7e,"KAFKA-14505; [6/N] Avoid recheduling callback in request thread (#15176)

This patch removes the extra hop via the request thread when the new group coordinator verifies a transaction. Prior to it, the ReplicaManager would automatically re-schedule the callback to a request thread. However, the new group coordinator does not need this as it already schedules the write into its own thread. With this patch, the decision to re-schedule on a request thread or not is left to the caller.

Reviewers: Artem Livshits <alivshits@confluent.io>, Justine Olshan <jolshan@confluent.io>",2024-01-30 23:27:11,David Jacot,Mixed
6363edecd208b0edd1ed09d88acff8e4c4a7a778,"KAFKA-16203: Fix bug on auto-commit empty offsets blocking inflight (#15282)

Fixes a bug with the auto-commit logic. When auto-committing empty offsets, the operation completes without generating a request, but mistakenly leaves the inflight request flag on. This makes that following auto-commits won't generate requests, even if offsets have been consumed.

Reviewers: David Jacot <djacot@confluent.io>",2024-01-31 00:26:49,Lianet Magrans,Mixed
127fe7d2765cfdcee6243cbc62a77a7760b3c84c,"KAFKA-15853: Move AuthorizerUtils and its dependencies to server module (#15167)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2024-01-31 15:38:14,Omnia Ibrahim,Mixed
a5888aabb20c66cce1110179ee6bba2844e21466,"KAFKA-16198: Reconciliation may lose partitions when topic metadata is delayed (#15271)

The current reconciliation code in AsyncKafkaConsumers MembershipManager may lose part of the server-provided assignment when metadata is delayed. The reason is incorrect handling of partially resolved topic names, as in this example:

We get assigned T1-1 and T2-1
We reconcile T1-1, T2-1 remains in assignmentUnresolved since the topic id T2 is not known yet
We get new cluster metadata, which includes T2, so T2-1 is moved to assignmentReadyToReconcile
We call reconcile -- T2-1 is now treated as the full assignment, so T1-1 is being revoked
We end up with assignment T2-1, which is inconsistent with the broker-side target assignment.
Generally, this seems to be a problem around semantics of the internal collections assignmentUnresolved and assignmentReadyToReconcile. Absence of a topic in assignmentReadyToReconcile may either mean revocation of the topic partition(s), or unavailability of a topic name for the topic, depending on the context.

This change reimplements that part of the internal state of MembershipManagerImpl with simpler and more correct invariants by using a single collection currentTargetAssignment which is based on topic IDs and always corresponds to the latest assignment received from the broker. During every attempted reconciliation, all topic IDs will be resolved from the local cache, which should not introduce a lot of overhead. assignmentUnresolved and assignmentReadyToReconcile are removed.

This change is in line with the goal of using topic IDs instead of topic names in the consumer internal state, and fixes the bug of losing partitions when delayed metadata arrives.

A unit test testing the above situation is added.

Note, that this change does not fully the reconciliation problems, because if a new assignment or new metadata arrives during an ongoing reconciliation, it will rely on the broker to re-send the assignment for it to be applied. This will be solved in a separate change (KAFKA-15832).

Reviewers: Lianet Magrans <lianetmr@gmail.com>, David Jacot <djacot@confluent.io>",2024-02-01 08:54:59,Lucas Brutschy,Mixed
af41fc361487dc9001ec83ea000c852b91fcdbd5,"KAFKA-16168; Implement GroupCoordinator.onPartitionsDeleted (#15237)

This patch implements `GroupCoordinator.onPartitionsDeleted` that is called whenever a partition is deleted and must deleted all the offsets related to them. The patch uses a naive approach similar to the one used in the old coordinator. It basically iterates over all the regular end pending offsets and deletes the ones matching the deleted partition set.

Reviewers: Justine Olshan <jolshan@confluent.io>",2024-02-01 00:28:32,David Jacot,Mixed
6c09cc9586f823dff32c96131f6f377afaebbd2a,"KAFKA-16189; Extend admin to support ConsumerGroupDescribe API (#15253)

This patch extends the Admin client to support describing new consumer groups with the ConsumerGroupDescribe API introduced in KIP-848. Users will continue to use the `Admin#describeConsumerGroups` API. The admin client does all the magic. Basically, the admin client always tries to describe the requested groups with the ConsumerGroupDescribe API to start with. If all the groups are there, great, the job is done. If there are groups unresolved groups due to a UNSUPPORTED_VERSION or GROUP_ID_NOT_FOUND error, the admin client tries with the DescribeGroups API. The patch also adds fields to the data structure returned by `Admin#describeConsumerGroups` as stated in the KIP.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Bruno Cadonna <bruno@confluent.io>",2024-02-01 00:30:56,David Jacot,Mixed
7bc4afee11353eccc5d31491693d1dc6e0bba6f7,"KAFKA-15675: Improve worker liveness check during Connect integration tests (#15249)

Reviewers: Greg Harris <greg.harris@aiven.io>, Yash Mayya <yash.mayya@gmail.com>",2024-02-01 09:20:24,Chris Egerton,Not TDD
8da6508966014898f51a8f899c2df9ab3f9ceb5c,"KAFKA-16107 [2/N]: Fix inverted args & more tests (#15285)

Small fix for argument order in onPartitionsAssigned callback, and more tests for disabling/enabling partitions while callback runs.

Reviewers: David Jacot <djacot@confluent.io>",2024-02-01 08:02:24,Lianet Magrans,Mixed
4f0a40590833a141c78341ce95ffc782747c5ac8,"KAFKA-15575: Begin enforcing 'tasks.max' property for connectors (#15180)

Reviewers: Ashwin Pankaj <apankaj@confluent.io>, Greg Harris <greg.harris@aiven.io>",2024-02-01 11:33:04,Chris Egerton,Mixed
12ce9c7f98c1617824d7bd86f9cc1f4560646e26,"KAFKA-16216: Reduce batch size for initial metadata load during ZK migration

During migration from ZK mode to KRaft mode, there is a step where the kcontrollers load all of the
data from ZK into the metadata log. Previously, we were using a batch size of 1000 for this, but
200 seems better. This PR also adds an internal configuration to control this batch size, for
testing purposes.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2024-02-01 15:48:52,David Arthur,Mixed
f0087ac6a8a7b1005e9588e42b3679146bd3eb13,"KAFKA-16115: Adding missing heartbeat metrics (#15216)

Add a HeartbeatMetrics module to measure various metrics related to the heartbeat. Here is the highlight of the changes:

HeartMetrics encapsulate a heartbeat sensor
Add metrics suffix types to the AbstractConsumerMetrics so that it can be extended to different metric groups
Non-related refactor:

Rename the metric classes to ""MetricManager"" the reason being ""Metrics"" seems to relate to the Metric class however these managers are merely containers holding sensor references for recording purposes.
Created OffsetCommitMetricsManager so that we are more consistent with the metrics management
Extended KafkaConsumerMetrics to the AbstractConsumerMetrics so that the groupName is consistently created (without random concatenation)
Some follow ups:

Refactor commit sensor by introducing a CommitMetrics module so that we can keep most of the metrics in one place and let it be a bit more consistent stylistically
Possibly refactor fetch manager metrics

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-02-02 15:06:41,Philip Nee,Mixed
3d95a69a28c2d16e96618cfa9a1eb69180fb66ea,"KAFKA-16195: ignore metadata.log.dir failure in ZK mode (#15262)

In KRaft mode, or on ZK brokers that are migrating to KRaft, we have a local __cluster_metadata
log. This log is stored in a single log directory which is configured via metadata.log.dir. If
there is no metadata.log.dir given, it defaults to the first entry in log.dirs. In the future we
may support multiple metadata log directories, but we don't yet. For now, we must abort the
process when this log directory fails.

In ZK mode, it is not necessary to abort the process when this directory fails, since there is no
__cluster_metadata log there. This PR changes the logic so that we check for whether we're in ZK
mode and do not abort in that scenario (unless we lost the final remaining log directory. of
course.)

Reviewers: Luke Chen <showuon@gmail.com>, Colin P. McCabe <cmccabe@apache.org>, Omnia G H Ibrahim <o.g.h.ibrahim@gmail.com>, Proven Provenzano <pprovenzano@confluent.io>",2024-02-02 09:47:14,Gaurav Narula,Mixed
4169ac9f5dc819c0495247c2230e96581800b1c7,"KAFKA-16180: Fix UMR and LAIR handling during ZK migration (#15293)

While migrating from ZK mode to KRaft mode, the broker passes through a ""hybrid"" phase, in which it
receives LeaderAndIsrRequest and UpdateMetadataRequest RPCs from the KRaft controller. For the most
part, these RPCs can be handled just like their traditional equivalents from a ZK-based controller.
However, there is one thing that is different: the way topic deletions are handled.

In ZK mode, there is a ""deleting"" state which topics enter prior to being completely removed.
Partitions stay in this state until they are removed from the disks of all replicas. And partitions
associated with these deleting topics show up in the UMR and LAIR as having a leader of -2 (which
is not a valid broker ID, of course, because it's negative). When brokers receive these RPCs, they
know to remove the associated partitions from their metadata caches, and disks. When a full UMR or
ISR is sent, deleting partitions are included as well.

In hybrid mode, in contrast, there is no ""deleting"" state. Topic deletion happens immediately. We
can do this because we know that we have topic IDs that are never reused. This means that we can
always tell the difference between a broker that had an old version of some topic, and a broker
that has a new version that was re-created with the same name. To make this work, when handling a
full UMR or LAIR, hybrid brokers must compare the full state that was sent over the wire to their
own local state, and adjust accordingly.

Prior to this PR, the code for handling those adjustments had several major flaws. The biggest flaw
is that it did not correctly handle the ""re-creation"" case where a topic named FOO appears in the
RPC, but with a different ID than the broker's local FOO. Another flaw is that a problem with a
single partition would prevent handling the whole request.

In ZkMetadataCache.scala, we handle full UMR requests from KRaft controllers by rewriting the UMR
so that it contains the implied deletions. I fixed this code so that deletions always appear at the
start of the list of topic states. This is important for the re-creation case since it means that a
single request can both delete the old FOO and add a new FOO to the cache. Also, rather than
modifying the requesst in-place, as the previous code did, I build a whole new request with the
desired list of topic states. This is much safer because it avoids unforseen interactions with
other parts of the code that deal with requests (like request logging). While this new copy may
sound expensive, it should actually not be. We are doing a ""shallow copy"" which references the
previous list topic state entries.

I also reworked ZkMetadataCache.updateMetadata so that if a partition is re-created, it does not
appear in the returned set of deleted TopicPartitions. Since this set is used only by the group
manager, this seemed appropriate. (If I was in the consumer group for the previous iteration of
FOO, I should still be in the consumer group for the new iteration.)

On the ReplicaManager.scala side, we handle full LAIR requests by treating anything which does not
appear in them as a ""stray replica."" (But we do not rewrite the request objects as we do with UMR.)
I moved the logic for finding stray replicas from ReplicaManager into LogManager. It makes more
sense there, since the information about what is on-disk is managed in LogManager. Also, the stray
replica detection logic for KRaft mode is there, so it makes sense to put the stray replica
detection logic for hybrid mode there as well.

Since the stray replica detection is now in LogManager, I moved the unit tests there as well.
Previously some of those tests had been in BrokerMetadataPublisherTest for historical reasons.

The main advantage of the new LAIR logic is that it takes topic ID into account. A replica can be a
stray even if the LAIR contains a topic of the given name, but a different ID. I also moved the
stray replica handling earlier in the becomeLeaderOrFollower function, so that we could correctly
handle the ""delete and re-create FOO"" case.

Reviewers: David Arthur <mumrah@gmail.com>",2024-02-02 15:49:10,Colin Patrick McCabe,Mixed
3db14ec62a462a21f9196bad2f6cc325e30754c6,"KAFKA-16157: fix topic recreation handling with offline disks (#15263)

In Kraft mode, the broker fails to handle topic recreation correctly with broken disks. This is because ReplicaManager tracks HostedPartitions which are on an offline disk but it doesn't associate TopicId information with them.

This change updates HostedPartition.Offline to associate topic id information. We also update the log creation logic in Partition::createLogInAssignedDirectoryId to not just rely on targetLogDirectoryId == DirectoryId.UNASSIGNED to determine if the log to be created is ""new"".

Please refer to the comments in https://issues.apache.org/jira/browse/KAFKA-16157 for more information.

Reviewers: Luke Chen <showuon@gmail.com>, Omnia Ibrahim <o.g.h.ibrahim@gmail.com>, Gaurav Narula <gaurav_narula2@apple.com>",2024-02-03 14:40:40,Gaurav Narula,Mixed
68745ef21a9d8fe0f37a8c5fbc7761a598718d46,"KAFKA-15460: Add group type filter to List Groups API (#15152)

This patch adds the support for filtering groups by types (Classic or Consumer) to both the old and the new group coordinators.

Reviewers: David Jacot <djacot@confluent.io>",2024-02-05 00:56:39,Ritika Reddy,Mixed
c000b1fae2bd7d4b76713a53508f128a13431ab6,"MINOR: Fix some MetadataDelta handling issues during ZK migration (#15327)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2024-02-07 12:54:59,David Arthur,Mixed
489a7dd71eebbf4f5effedeea1f3341854ddc75e,"MINOR: Improve Code Style (#15319)

- Removing ! and Unused Imports
- Put a space after the control structure's defining keyword.
- remove unnecessary whitespace a space after the method name in higher-order function invocations.

Reviewers: Divij Vaidya <diviv@amazon.com>",2024-02-09 12:07:20,"Gyeongwon, Do",Mixed
d233eb98f7c7e55fe0dd673dbc058ddf619663a7,"KAFKA-14957: Update-Description-String (#13909)

HTML code for configs is auto-generated and for Kafka Streams config `state.dir` produces a confusing default value.
This PR adds a new property `alternativeString` to set a ""default"" value which should be rendered in HTML instead of the actual default value.

Reviewers: Manyanda Chitimbo <manyanda.chitimbo@gmail.com>, @eziosudo <eziosudo@gmail.com>, Matthias J. Sax <matthias@confluent.io>",2024-02-10 12:46:51,Owen Leung,Mixed
6a4078ddde7888ca12582b6dff13f9ece0cf4d59,"KAFKA-16215; KAFKA-16178; Fix member not rejoining after error (#15311)

This fixes a bug that was causing that members wouldn't rejoin the group after receiving an error in the heartbeat response (ex. fenced, not coordinator, as reported in KAFKA-16215 and KAFKA-16178). The issue was that when receiving a response with error, the response receive time was not being updated, so following heartbeat would be skipped, considering that there was already a previous one inflight.

Reviewers: Andrew Schofield <aschofield@confluent.io>, David Jacot <djacot@confluent.io>",2024-02-11 23:16:57,Lianet Magrans,Mixed
c6f4c604d8e50ad9e182eeb66f0d1650aa44f277,"KAFKA-15832: Trigger client reconciliation based on manager poll (#15275)

Currently, the reconciliation logic on the client is triggered when a new target assignment is received and resolved, or when new unresolved target assignments are discovered in metadata.

This change improves this by triggering the reconciliation logic on each poll iteration, to reconcile whatever is ready to be reconciled. This would require changes to support poll on the MembershipManager, and integrate it with the current polling logic in the background thread. Receiving a new target assignment from the broker, or resolving new topic names via a metadata update could only ensure that the #assignmentReadyToReconcile is properly updated (currently done), but wouldn't trigger the #reconcile() logic, leaving that to the #poll() operation.

Reviewers: David Jacot <djacot@confluent.io>, Lianet Magrans <lianetmr@gmail.com>",2024-02-12 15:43:21,Lucas Brutschy,Mixed
794c52802c0bcc2676d750613fefe14006d03a44,"KAFKA-14683: Migrate WorkerSinkTaskTest to Mockito (2/3) (#15313)

Reviewers: Greg Harris <greg.harris@aiven.io>",2024-02-12 11:15:27,Hector Geraldino,Mixed
88c5543ccfb517ceba8dc56d22576efdf2540e0e,"KAFKA-14589: [1/3] Tests of ConsoleGroupCommand rewritten in java (#15256)

This PR is part of #14471
Is contains some of ConsoleGroupCommand tests rewritten in java.
Intention of separate PR is to reduce changes and simplify review.

Reviewers: Luke Chen <showuon@gmail.com>",2024-02-13 11:02:36,Nikolay,Mixed
fed3c3da842867510888d34ccc25d24a7a16c64e,"KAFKA-14822: Allow restricting File and Directory ConfigProviders to specific paths (#14995)


Reviewers: Greg Harris <gharris1727@gmail.com>, Mickael Maison <mickael.maison@gmail.com>",2024-02-13 18:28:28,Gantigmaa Selenge,Mixed
8c0488b887be4a9178563f1d72514010f83b8614,"MINOR: ignore heartbeat response if leaving (#15362)

When the consumer enters state LEAVING, it sets the epoch to the leave epoch,
such as -1. When the timing is right, we may get a heartbeat response after
entering the state LEAVING, which resets the epoch to the member epoch on
the server. The result is that the consumer never leaves the group.

Seems like c6f4c604d8e50ad9e182eeb66f0d1650aa44f277 changed the timing inside
the consumer to relatively frequently triggers this problem inside
`DescribeConsumerGroupTest`.

We fix it by ignoring any heartbeat responses when we are in state LEAVING.

Reviewers: David Jacot <djacot@confluent.io>",2024-02-13 19:08:13,Lucas Brutschy,Mixed
0bf830fc9c3915bc99b6e487e6083dabd593c5d3,"KAFKA-14576: Move ConsoleConsumer to tools (#15274)


Reviewers: Josep Prat <josep.prat@aiven.io>, Omnia Ibrahim <o.g.h.ibrahim@gmail.com>",2024-02-13 19:24:07,Mickael Maison,Mixed
d24abe0edebad37e554adea47408c3063037f744,"MINOR: Refactor GroupMetadataManagerTest (#15348)

`GroupMetadataManagerTest` class got a little under control. We have too many things defined in it. As a first steps, this patch extracts all the inner classes. It also extracts all the helper methods. However, the logic is not changed at all.

Reviewers: Omnia Ibrahim <o.g.h.ibrahim@gmail.com>, Justine Olshan <jolshan@confluent.io>",2024-02-13 23:29:29,David Jacot,Mixed
ff90f78c700c582f9800013faad827c36b45ceb7,"KAFKA-16226; Reduce synchronization between producer threads (#15323)

As this [JIRA](https://issues.apache.org/jira/browse/KAFKA-16226) explains, there is increased synchronization between application-thread, and the background thread as the background thread started to synchronized methods Metadata.currentLeader() in [original PR](https://github.com/apache/kafka/pull/14384). So this PR does the following changes
1. Changes background thread, i.e. RecordAccumulator's partitionReady(), and drainBatchesForOneNode(), to not use `Metadata.currentLeader()`. Instead rely on `MetadataCache` that is immutable. So access to it is unsynchronized.
2.  This PR repurposes `MetadataCache` as an immutable snapshot of Metadata. This is a wrapper around public `Cluster`. `MetadataCache`'s API/functionality should be extended for internal client usage Vs public `Cluster`. For example, this PR adds `MetadataCache.leaderEpochFor()`
3. Rename `MetadataCache` to `MetadataSnapshot` to make it explicit its immutable.

**Note both `Cluster` and `MetadataCache` are not syncronized, hence reduce synchronization from the hot path for high partition counts.**

Reviewers: Jason Gustafson <jason@confluent.io>",2024-02-15 09:26:47,Mayank Shekhar Narula,Mixed
553f45bca8a936d971af03e1552f2fe3f9c54fac,"MINOR: Fix toString method of IsolationLevel (#14782)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Ashwin Pankaj <apankaj@confluent.io>",2024-02-15 19:07:18,"Minha, Jeong",Mixed
14d5e170706be0b843d08147a1046fafb442f9be,"KAFKA-16165: Fix invalid transition on poll timer expiration (#15375)

This fixes an invalid transition (leaving->stale) that was discovered in the system tests. The underlying issue was that the poll timer expiration logic was blindly forcing a transition to stale and sending a leave group, without considering that the member could be already leaving.
The fix included in this PR ensures that the poll timer expiration logic, whose purpose is to leave the group, is only applied if the member is not already leaving. Note that it also fixes the transition out of the STALE state, that should only happen when the poll timer is reset.

As a result of this changes:

If the poll timer expires while the member is not leaving, the poll timer expiration logic is applied: it will transition to stale, send a leave group, and remain in STALE state until the timer is reset. At that point the member will transition to JOINING to rejoin the group.
If the poll timer expires while the member is already leaving, the poll timer expiration logic does not apply, and just lets the HB continue. Not that this would be the case of member in PREPARE_LEAVING waiting for callbacks to complete (needs to continue sending HB), or LEAVING (needs to send the last HB to leave).

Reviewers: Kirk True <ktrue@confluent.io>, Andrew Schofield <aschofield@confluent.io>, Lucas Brutschy <lbrutschy@confluent.io>",2024-02-16 11:38:46,Lianet Magrans,Mixed
756f44a3e582902827ae45daf382556c7fba99a0,"KAFKA-15665: Enforce partition reassignment should complete when all target replicas are in ISR (#15359)

When completing the partition reassignment, the new ISR should have all the target replicas.

Reviewers: Justine Olshan <jolshan@confluent.io>, David Mao <dmao@confluent.io>",2024-02-16 10:27:43,Calvin Liu,Mixed
1442862bbd7195b4dde76f9076cf94fcd500d3b9,"KAFKA-16009: Fix PlaintextConsumerTest. testMaxPollIntervalMsDelayInRevocation (#15383)

The wake-up mechanism in the new consumer is preventing from committing within a rebalance listener callback. The reason is that we are trying to register two wake-uppable actions at the same time.

The fix is to register the wake-uppable action more closely to where we are in fact blocking on it, so that the action is not registered when we execute rebalance listeneners and callback listeners.

Reviewers: Bruno Cadonna <cadonna@apache.org>",2024-02-19 15:33:37,Lucas Brutschy,Mixed
b71999be95325f6ea54e925cbe5b426425781014,"MINOR: Clean up core modules (#15279)

This PR cleans up: metrics, migration, network, raft, security, serializer, tools, utils, and zookeeper package classes

Mark methods and fields private where possible
Annotate public methods and fields
Remove unused classes and methods
Make sure Arrays are not printed with .toString
Optimize minor warnings

Reviewers: Mickael Maison <mickael.maison@gmail.com>",2024-02-19 16:54:50,Josep Prat,Not TDD
5854139cd8a75fec387183189c6cd1f32e891e57,"KAFKA-16243: Make sure that we do not exceed max poll interval inside poll (#15372)

The consumer keeps a poll timer, which is used to ensure liveness of the application thread. The poll timer automatically updates while the Consumer.poll(Duration) method is blocked, while the newer consumer only updates the poll timer when a new call to Consumer.poll(Duration) is issued. This means that the kafka-console-consumer.sh tools, which uses a very long timeout by default, works differently with the new consumer, with the consumer proactively rejoining the group during long poll timeouts.

This change solves the problem by (a) repeatedly sending PollApplicationEvents to the background thread, not just on the first call of poll and (b) making sure that the application thread doesn't block for so long that it runs out of max.poll.interval.

An integration test is added to make sure that we do not rejoin the group when a long poll timeout is used with a low max.poll.interval.

Reviewers: Lianet Magrans <lianetmr@gmail.com>, Andrew Schofield <aschofield@confluent.io>, Bruno Cadonna <cadonna@apache.org>",2024-02-20 10:48:36,Lucas Brutschy,Not TDD
4c70581eb63fe74494fbabf5a90e87c38e17996d,"KAFKA-15770: IQv2 must return immutable position (#15219)

ConsistencyVectorIntegrationTest failed frequently because the return
Position from IQv2 is not immutable while the test assume immutability.
To return a Position with a QueryResult that does not change, we need to
deep copy the Position object.

Reviewers: John Roesler <john@confluent.io>, Lucas Brutschy <lbrutschy@confluent.io>",2024-02-20 12:24:32,Matthias J. Sax,Mixed
77ba06fa620ad9cc42af92f42354661308676135,"KAFKA-16033: Commit retry logic fixes (#15357)

This change modifies the commit manager for improved retry logic & fixing bugs:

- defines high level functions for each of the different types of commit: commitSync, commitAsync, autoCommitSync (used from consumer close), autoCommitAsync (on interval), autoCommitNow (before revocation).
 - moves retry logic to these caller functions, keeping a common response error handling that propagates errors that each caller functions retry as it needs.

Fixes the following issues:

- auto-commit before revocation should retry with latest consumed offsets
- auto-commit before revocation should only reset the timer once, when the rebalance completes
- StaleMemberEpoch error (fatal) is considered retriable only when committing offsets before revocation, where it is retried with backoff if the member has a valid epoch. All other commits will fail fatally on stale epoch. Note that auto commit on the interval (autoCommitAsync) does not have any specific retry logic for the stale epoch, but will effectively retry on the next interval (as it does for any other fatal error)
- fix duplicated and noisy logs for auto-commit

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-02-21 11:08:37,Lianet Magrans,Mixed
02ebfc6108c86d8f7c74396f440ae5336e0bcae2,"KAFKA-16194: Do not return records from poll if group metadata unknown (#15369)

Due to the asynchronous nature of the async consumer, it might happen that on the application thread the group metadata is not known after the first poll returns records. If the offsets of those records are then send to a transaction with

txnProducer.sendOffsetsToTransaction(offsetsToCommit, groupMetadata);

and then the transaction is committed, the group coordinator will raise an error saying that the member is not known since the member in groupMetadata is still -1 before the metadata is updated.

This commit avoids this error by not returning any records from poll() until the group metadata is updated, i.e., the member ID and the generation ID (a.k.a. member epoch) are known. This check is only done if group management is used.

Additionally, this commit resets the group metadata when the consumer unsubscribes.

Reviewer: Lucas Brutschy <lbrutschy@confluent.io>",2024-02-21 18:19:38,Bruno Cadonna,Mixed
06392f7ae272af33e6789ce48fc840005fa24899,"MINOR: Update of the PAPI testing classes to the latest implementation (#12740)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2024-02-22 18:15:24,Daan Gerits,Not TDD
2185004083ebb8f0b3a443132b5a33908c459c65,"KAFKA-16251: Fix for not sending heartbeat while fenced (#15392)

Fix to ensure that a consumer that has been fenced by the coordinator stops sending heartbeats while it is on the FENCED state releasing its assignment (waiting for the onPartitionsLost callback to complete). Once the callback completes, the member transitions to JOINING and it's then when it should resume sending heartbeats again.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-02-23 10:56:05,Lianet Magrans,Mixed
7ac50a86113c9a489667451eecf61b6ab80870db,"KAFKA-16152: Fix PlaintextConsumerTest.testStaticConsumerDetectsNewPartitionCreatedAfterRestart (#15419)

The group coordinator expects the instance ID to always be sent when
leaving the group in a static membership configuration, see

https://github.com/apache/kafka/blob/ea9450767932eb3d63aeefd5af07dbc54cb92c31/group-coordinator/src/main/java/org/apache/kafka/coordinator/group/GroupMetadataManager.java#L814

The failure was silent, because the group coordinator does not log
failed requests and the consumer doesn't wait for the heartbeat response
during close.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Kirk True <ktrue@confluent.io>, Bruno Cadonna <cadonna@apache.org>",2024-02-23 16:43:50,Lucas Brutschy,Not TDD
474f8c1ad620d1f982ac15cd418ae8462dec4d9e,"KAFKA-16286; Notify listener of latest leader and epoch (#15397)

KRaft was only notifying listeners of the latest leader and epoch when the replica transition to a new state. This can result in the listener never getting notified if the registration happened after it had become a follower.

This problem doesn't exists for the active leader because the KRaft implementation attempts to notified the listener of the latest leader and epoch when the replica is the active leader.

This issue is fixed by notifying the listeners of the latest leader and epoch after processing the listener registration request.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2024-02-23 12:56:25,José Armando García Sancio,Mixed
b4e96913cc6c827968e47a31261e0bd8fdf677b5,"KAFKA-16265: KIP-994 (Part 1) Minor Enhancements to ListTransactionsRequest (#15384)

Introduces a new filter in ListTransactionsRequest API. This enables caller to filter on transactions that have been running for longer than a certain duration of time.

This PR includes the following changes:

bumps version for ListTransactionsRequest API to 1. Set the durationFilter to -1L when communicating with an older broker that does not support version 1.
bumps version for ListTransactionsResponse to 1 without changing the response structure.
adds durationFilter option to kafka-transactions.sh --list
Tests:

Client side test to build request with correct combination of duration filter and API version: testBuildRequestWithDurationFilter
Server side test to filter transactions based on duration: testListTransactionsFiltering
Added test case for kafka-transactions.sh change in TransactionsCommandTest

Reviewers: Justine Olshan <jolshan@confluent.io>, Raman Verma <rverma@confluent.io>",2024-02-24 06:09:23,Yang Yu,Mixed
9bc9fae9425e4dac64ef078cd3a4e7e6e09cc45a,"KAFKA-16258: callback to release assignment when stale member leaves group (#15415)

Introduce call to onPartitionsLost callback to release assignment when a consumer pro-actively leaves the group due to poll timer expired.

When the poll timer expires, the member sends a leave group request (reusing same existing LEAVING state and logic), and then transitions to STALE to release it assignment and wait for the poll timer reset. Once both conditions are met, the consumer transitions out of the STALE state to rejoin the group. Note that while on this STALE state, the member is not part of the group so it does not send heartbeats.

This PR also includes the fix to ensure that while STALE or in any other state where the member is not in the group, heartbeat responses that may be received are ignored.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-02-26 11:39:33,Lianet Magrans,Mixed
027fad4b2a0d173df075f82e93501afb645ecc12,"KAFKA-16277: AbstractStickyAssignor - Sort owned TopicPartitions by partition when reassigning (#15416)

Treats KAFKA-16277 - CooperativeStickyAssignor does not spread topics evenly among consumer group

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2024-02-26 13:33:16,Cameron Redpath,Mixed
1c9f360f4af00c8cfcc18df3a10fb66ae1cf6b8e,"KAFKA-15215: migrate StreamedJoinTest to Mockito (#15424)

Migrate StreamedJoinTest to Mockito

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, 
Divij Vaidya <diviv@amazon.com>",2024-02-26 18:52:25,Almog Gavra,Not TDD
5d6936a4992b77ef68da216a7c2dbf1f8c9f909e,"KAFKA-16305: Avoid optimisation in handshakeUnwrap (#15434)

Performs additional unwrap during handshake after data from client is processed to support openssl, which needs the extra unwrap to complete handshake.

Reviewers: Ismael Juma <ismael@juma.me.uk>, Rajini Sivaram <rajinisivaram@googlemail.com>",2024-02-28 09:37:58,Gaurav Narula,Mixed
53c41aca7ba9469a0145023112f5fad254da4fa8,"KAFKA-16116: Rebalance Metrics for AsyncKafkaConsumer (#15339)

Adding the following rebalance metrics to the consumer:

rebalance-latency-avg
rebalance-latency-max
rebalance-latency-total
rebalance-rate-per-hour
rebalance-total
failed-rebalance-rate-per-hour
failed-rebalance-total

Due to the difference in protocol, we need to redefine when rebalance starts and ends.
Start of Rebalance:
Current: Right before sending out JoinGroup
ConsumerGroup: When the client receives assignments from the HB

End of Rebalance - Successful Case:
Current: Receiving SyncGroup request after transitioning to ""COMPLETING_REBALANCE""
ConsumerGroup: After completing reconciliation and right before sending out ""Ack"" heartbeat

End of Rebalance - Failed Case:
Current: Any failure in the JoinGroup/SyncGroup response
ConsumerGroup: Failure in the heartbeat

Note: Afterall, we try to be consistent with the current protocol. Rebalances start and end with sending and receiving network requests. Failures in network requests signify the user failures in rebalance. And it is entirely possible to have multiple failures before having a successful one.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-02-28 10:52:01,Philip Nee,Mixed
52289c92be45ba3758d07376d9c64ddadbecb544,"MINOR: Optimize EventAccumulator (#15430)

`poll(long timeout, TimeUnit unit)` is either used with `Long.MAX_VALUE` or `0`. This patch replaces it with `poll` and `take`. It removes the `awaitNanos` usage.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2024-02-28 05:38:02,David Jacot,Mixed
55a6d30ccbe971f4d2e99aeb3b1a773ffe5792a2,"KAFKA-16154: Broker returns offset for LATEST_TIERED_TIMESTAMP (#15213)

This is the first part of the implementation of KIP-1005

The purpose of this pull request is for the broker to start returning the correct offset when it receives a -5 as a timestamp in a ListOffsets API request

Reviewers: Luke Chen <showuon@gmail.com>, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>, Satish Duggana <satishd@apache.org>",2024-02-29 08:19:55,Christo Lolov,Mixed
96c68096a26ea5e7c2333308dfbaef47cb1eac72,"KAFKA-15462: Add Group Type Filter for List Group to the Admin Client  (#15150)

In KIP-848, we introduce the notion of Group Types based on the protocol type that the members in the consumer group use. As of now we support two types of groups:
* Classic : Members use the classic consumer group protocol ( existing one )
* Consumer : Members use the consumer group protocol introduced in KIP-848.
Currently List Groups allows users to list all the consumer groups available. KIP-518 introduced filtering the consumer groups by the state that they are in. We now want to allow users to filter consumer groups by type.

This patch includes the changes to the admin client and related files. It also includes changes to parameterize the tests to include permutations of the old GC and the new GC with the different protocol types.

Reviewers: David Jacot <djacot@confluent.io>",2024-02-29 00:38:42,Ritika Reddy,Mixed
f8eb4294d67b37e854aa14fb989d5e074df82ac2,"KAFKA-16191: Clean up of consumer client internal events (#15438)

There are a few minor issues with the event sub-classes in the
org.apache.kafka.clients.consumer.internals.events package that should be cleaned up:

- Update the names of subclasses to remove ""Application"" or ""Background""
- Make toString() final in the base classes and clean up the implementations of toStringBase()
- Fix minor whitespace inconsistencies
- Make variable/method names consistent

Reviewer: Bruno Cadonna <cadonna@apache.org>",2024-02-29 11:22:23,Kirk True,Mixed
c8843f06841d7f3c94b640ec9dbf69ec4682ec11,"KAFKA-16167: Disable wakeups during autocommit on close (#15445)

When the consumer is closed, we perform a sychronous autocommit. We don't want to be woken up here, because we are already executing a close operation under a deadline. This is in line with the behavior of the old consumer.

This fixes PlaintextConsumerTest.testAutoCommitOnCloseAfterWakeup which is flaky on trunk - because we return immediately from the synchronous commit with a WakeupException, which causes us to not wait for the commit to finish and thereby sometimes miss the committed offset when a new consumer is created.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bruno Cadonna <cadonna@apache.org>",2024-03-01 11:14:13,Lucas Brutschy,Mixed
8e1516f88b88b2c815ccbca074af5a5c2d14b5c9,"KAFKA-16261: updateSubscription fails if already empty subscription (#15440)

The internal SubscriptionState object keeps track of whether the assignment is user-assigned, or auto-assigned. If there are no assigned partitions, the assignment resets to NONE. If you call SubscriptionState.assignFromSubscribed in this state it fails.

This change makes sure to check SubscriptionState.hasAutoAssignedPartitions() so that assignFromSubscribed is going to be permitted.

Also, a minor refactoring to make clearing the subscription a bit easier to follow in MembershipManagerImpl.

Testing via new unit test.

Reviewers: Bruno Cadonna <cadonna@apache.org>, Andrew Schofield <aschofield@confluent.io>",2024-03-01 16:42:08,Lucas Brutschy,Mixed
52a3fa07446f9c108399d47dbfb1685989a5d6eb,"KAFKA-15878: KIP-768 - Extend support for opaque (i.e. non-JWT) tokens in SASL/OAUTHBEARER (#14818)

# Overview
* This change pertains to [SASL/OAUTHBEARER ](https://kafka.apache.org/documentation/#security_sasl_oauthbearer)  mechanism of Kafka authentication. 
* Kafka clients can use [SASL/OAUTHBEARER ](https://kafka.apache.org/documentation/#security_sasl_oauthbearer)   mechanism by overriding the [custom call back handlers](https://kafka.apache.org/documentation/#security_sasl_oauthbearer_prod) . 
* [KIP-768](https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=186877575) available from v3.1  further extends the mechanism with a production grade implementation. 
* Kafka's [SASL/OAUTHBEARER ](https://kafka.apache.org/documentation/#security_sasl_oauthbearer)  mechanism currently **rejects the non-JWT (i.e. opaque) tokens**. This is because of a more restrictive set of characters than what [RFC-6750](https://datatracker.ietf.org/doc/html/rfc6750#section-2.1) recommends. 
* This JIRA can be considered an extension of [KIP-768](https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=186877575) to support the opaque tokens as well apart from the JWT tokens.
 
# Solution
* Have updated the regex in the the offending class to be compliant with the [RFC-6750](https://datatracker.ietf.org/doc/html/rfc6750#section-2.1)
* Have provided a supporting test case that includes the possible character set defined in [RFC-6750](https://datatracker.ietf.org/doc/html/rfc6750#section-2.1)

---------

Co-authored-by: Anuj Sharma <philomath.anuj@gmail.com>
Co-authored-by: Jamie Holmes <jamie.holmes@tesco.com>
Co-authored-by: Christopher Webb <31657038+cwebbtw@users.noreply.github.com>
Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Kirk True <ktrue@confluent.io>",2024-03-02 00:43:56,Jamie,Mixed
7dbdc15c668dfb5a4a91c79f339c22fb7178c368,"KAFKA-15625: Do not flush global state store at each commit (#15361)

Global state stores are currently flushed at each commit, which may impact performance, especially for EOS (commit each 200ms).
The goal of this improvement is to flush global state stores only when the delta between the current offset and the last checkpointed offset exceeds a threshold.
This is the same logic we apply on local state store, with a threshold of 10000 records.
The implementation only flushes if the time interval elapsed and the threshold of 10000 records is exceeded.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Bruno Cadonna <cadonna@apache.org>",2024-03-04 10:19:59,Ayoub Omari,Not TDD
aa0443eb607c2d1d3004312f55f7583102127cb8,"KAFKA-16285: Make group metadata available when a new assignment is set (#15426)

Currently, in the async Kafka consumer updates to the group metadata
that are received by the heartbeat are propagated to the application thread
in form of an event. Group metadata is updated when a new assignment is
received. The new assignment is directly set in the subscription without
sending an update event from the background thread to the application thread.
That means that there might be a delay between the application thread being
aware of the update to the assignment and the application thread being
aware of the update to the group metadata. This delay can cause stale
group metadata returned by the application thread that then causes
issues when data of the new assignment is committed. A concrete
example is
producer.sendOffsetsToTransaction(offsetsToCommit, groupMetadata)
The offsets to commit might already stem from the new assignment
but the group metadata might relate to the previous assignment.

Reviewers: Kirk True <ktrue@confluent.io>, Andrew Schofield <aschofield@confluent.io>, Lucas Brutschy <lbrutschy@confluent.io>",2024-03-04 12:42:24,Bruno Cadonna,Mixed
4f92a3f0afda96c04059be81cf7867a0bbc7c276,"KAFKA-14747: record discarded FK join subscription responses (#15395)

A foreign-key-join might drop a ""subscription response"" message, if the value-hash changed.
This PR adds support to record such event via the existing ""dropped records"" sensor.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2024-03-04 15:56:40,Ayoub Omari,Mixed
99e511c706b7da08b559a3ff6a2c207cacd47b86,"KAFKA-16288, KAFKA-16289: Fix Values convertToDecimal exception and parseString corruption (#15399)

* KAFKA-16288: Prevent ClassCastExceptions for strings in Values.convertToDecimal
* KAFKA-16289: Values inferred schemas for map and arrays should ignore element order

Signed-off-by: Greg Harris <greg.harris@aiven.io>
Reviewers: Chris Egerton <chrise@aiven.io>",2024-03-04 15:59:47,Greg Harris,Mixed
47792770a28a0b4a6c321a1822b522f4e81068d6,"KAFKA-16169: FencedException in commitAsync not propagated without callback (#15437)

The javadocs for commitAsync() (w/o callback) say:

@throws org.apache.kafka.common.errors.FencedInstanceIdException 
if this consumer instance gets fenced by broker.
If no callback is passed into commitAsync(), no offset commit callback invocation is submitted. However, we only check for a FencedInstanceIdException when we execute a callback. When the consumer gets fenced by another consumer with the same group.instance.id, and we do not use a callback, we miss the exception.

This change modifies the behavior to propagate the FencedInstanceIdException even if no callback is used. The code is kept very similar to the original consumer.

We also change the order - first try to throw the fenced exception, then execute callbacks. That is the order in the original consumer so it's safer to keep it this way.

For testing, we add a unit test that verifies that the FencedInstanceIdException is thrown in that case.

Reviewers: Philip Nee <pnee@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2024-03-05 09:44:51,Lucas Brutschy,Mixed
eea369af947dcff567f849183ba2217ac5e9a2ba,"KAFKA-14588 Log cleaner configuration move to CleanerConfig (#15387)

In order to move ConfigCommand to tools we must move all it's dependencies which includes KafkaConfig and other core classes to java. This PR moves log cleaner configuration to CleanerConfig class of storage module.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-03-05 18:11:56,Nikolay,Mixed
2c1943d836d828755af382b9d7996ff092854fe2,"MINOR: remove test constructor for PartitionAssignment (#15435)

Remove the test constructor for PartitionAssignment and remove the TODO.
Also add KRaftClusterTest.testCreatePartitions to get more coverage for
createPartitions.

Reviewers: David Arthur <mumrah@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-03-05 12:02:19,Colin Patrick McCabe,Mixed
554fa57af85ec337a556f35cbc6d2970ff252dc4,"KAFKA-16209 : fetchSnapshot might return null if topic is created before v2.8 (#15444)

Change the function with a better way to deal with the NULL pointer exception.

Reviewers: Luke Chen <showuon@gmail.com>",2024-03-06 09:00:58,John Yu,Mixed
e81379d3fea956dd8900b7f4b68e0c1328401871,"KAFKA-15417: flip joinSpuriousLookBackTimeMs and emit non-joined items (#14426)

Kafka Streams support asymmetric join windows. Depending on the window configuration
we need to compute window close time etc differently.

This PR flips `joinSpuriousLookBackTimeMs`, because they were not correct, and
introduced the `windowsAfterIntervalMs`-field that is used to find if emitting records can be skipped.

Reviewers: Hao Li <hli@confluent.io>, Guozhang Wang <guozhang.wang.us@gmail.com>, Matthias J. Sax <matthias@confluent.io>",2024-03-05 17:06:20,Victor van den Hoven,Not TDD
f6198bc075f7e8e6af9e1fb53875e92de5057872,"KAFKA-14589 [3/4] Tests of ConsoleGroupCommand rewritten in java  (#15365)

Is contains some of ConsoleGroupCommand tests rewritten in java.
Intention of separate PR is to reduce changes and simplify review.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-03-06 17:13:39,Nikolay,Not TDD
62998b72642109ac455564d26c08e37eb0e9f0ea,"KAFKA-14683: Migrate WorkerSinkTaskTest to Mockito (3/3) (#15316)

Reviewers: Greg Harris <greg.harris@aiven.io>",2024-03-06 10:31:33,Hector Geraldino,Mixed
ccf4bd5f4621b80f5b1d3700df30e3b444381927,"MINOR: Add 3.7 to Kafka Streams system tests (#15443)

Reviewers: Bruno Cadonna <bruno@confluent.io>",2024-03-06 12:02:58,Matthias J. Sax,Not TDD
ba0db81e5307cf090dc5876f3c61ddbe5fef2284,"KAFKA-16246: Cleanups in ConsoleConsumer (#15457)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Omnia Ibrahim <o.g.h.ibrahim@gmail.com>",2024-03-07 09:39:16,Dmitry Werner,Mixed
86e7885a81c7132e522d2c59dc6fcf81026cc60d,"KAFKA-16100: Add timeout to all the CompletableApplicationEvents (#15455)

This is part of the larger task of enforcing the timeouts for application events, per KAFKA-15974.

This takes a first step by adding a Timer to all of the CompletableApplicationEvent subclasses. For the few classes that already included a timeout, this refactors them to use the Timer mechanism instead.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Bruno Cadonna <cadonna@apache.org>",2024-03-07 15:00:21,Kirk True,Mixed
1d50cbeda85bd3409cff17fd5114e73f25cf865c,"KAFKA-16319: Divide DeleteTopics requests by leader node (#15479)


Reviewers: Reviewers: Mickael Maison <mickael.maison@gmail.com>, Kirk True <kirk@kirktrue.pro>, Daniel Gospodinow <dgospodinov@confluent.io>",2024-03-07 16:24:11,Andrew Schofield,Mixed
f5c4d522fd79775692441cd75f6f733324f2e7e9,"MINOR: Add read/write all operation (#15462)

There are a few cases in the group coordinator service where we want to read from or write to each of the known coordinators (each of __consumer_offsets partitions). The current implementation needs to get the list of the known coordinators then schedules the operation and finally aggregate the results. This patch is an attempt to streamline this by adding multi read/write to the runtime.

Reviewers: Omnia Ibrahim <o.g.h.ibrahim@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-03-07 07:51:04,David Jacot,Mixed
d8dd068a626dcab538c2b234ffd8799a94b2f0ed,"KAFKA-15964: fix flaky StreamsAssignmentScaleTest (#15485)

This PR bumps some timeouts due to slow Jenkins builds.

Reviewers: Bruno Cadonna <bruno@confluent.io>",2024-03-07 09:17:52,Matthias J. Sax,Not TDD
b9a5b4a8053c1fa65e27a9f93440194b0dd5eec4,"KAFKA-10892: Shared Readonly State Stores ( revisited ) (#12742)

Implements KIP-813.

Reviewers: Matthias J. Sax <matthias@confluent.io>, Walker Carlson <wcarlson@confluent.io>",2024-03-08 10:57:56,Daan Gerits,Mixed
3fcaa9ccc0e36d05626e6c122c67258773bb6a9b,"MINOR: remove the copy constructor of LogSegment (#15488)

In the LogSegment, the copy constructor is only used in LogLoaderTest

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-03-10 03:06:41,Johnny Hsu,Not TDD
808bf07fb71e83432a09abe4e3fcc09d4ddc28eb,"MINOR: Cleanup log.dirs in ReplicaManagerTest on JVM exit (#15289)

- Scala TestUtils now delegates to the function in JTestUtils
- The function is modified such that we delete the rootDir on JVM exit if it didn't exist prior to the function being invoked.

Reviewers: Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-03-10 03:12:39,Gaurav Narula,Not TDD
66ed6d3b268cf481852297ee08ecc67d0f919aec,"KAFKA-16146: Checkpoint log-start-offset for remote log enabled topics (#15201)

The log-start-offset was not getting flushed to the checkpoint file due to the check where we compare the log-start-offset with the localLog first segment base offset only. This change makes sure that tiered storage enabled topics will always try to add their entries in the log-start-offset checkpoint file.

Reviewers: Jun Rao <junrao@gmail.com>, Satish Duggana <satishd@apache.org>",2024-03-11 14:50:29,Kamal Chandraprakash,Mixed
58ddd693e69599b177d09c2e384f31e7f5e11171,"KAFKA-16227: Avoid IllegalStateException during fetch initialization (#15491)

The AsyncKafkaConsumer might throw an IllegalStateException during
the initialization of a new fetch. The exception is caused by
 the partition being unassigned by the background thread before
the subscription state is accessed during initialisation.

This commit avoids the IllegalStateException by verifying that
the partition was not unassigned each time the subscription state
is accessed.

Reviewer: Lucas Brutschy <lbrutschy@confluent.io>",2024-03-12 11:04:37,Bruno Cadonna,Mixed
aa7bef414e2e08fbe35923979e0c8fc8438e594e,"MINOR: Resolve SSLContextFactory.getNeedClientAuth deprecation (#15468)

Reviewers: Mickael Maison <mickael.maison@gmail.com>",2024-03-13 11:45:38,Greg Harris,Mixed
e164d4d4264b6d663952c6a65f2fda46a4cc9e04,"KAFKA-16249; Improve reconciliation state machine (#15364)

This patch re-work the reconciliation state machine on the server side with the goal to fix a few issues that we have recently discovered.
* When a member acknowledges the revocation of partitions (by not reporting them in the heartbeat), the current implementation may miss it. The issue is that the current implementation re-compute the assignment of a member whenever there is a new target assignment installed. When it happens, it does not consider the reported owned partitions at all. As the member is supposed to only report its own partitions when they change, the member is stuck.
* Similarly, as the current assignment is re-computed whenever there is a new target assignment, the rebalance timeout, as it is currently implemented, becomes useless. The issue is that the rebalance timeout is reset whenever the member enters the revocation state. In other words, in the current implementation, the timer is reset when there are no target available even if the previous revocation is not completed yet.

The patch fixes these two issues by not automatically recomputing the assignment of a member when a new target assignment is available. When the member must revoke partitions, the coordinator waits. Otherwise, it recomputes the next assignment. In other words, revoking is really blocking now.

The patch also proposes to include an explicit state in the record. It makes the implementation cleaner and it also makes it more extensible in the future.

The patch also changes the record format. This is a non-backward compatible change. I think that we should do this change to cleanup the record. As KIP-848 is only in early access in 3.7 and that we clearly state that we don't plane to support upgrade from it, this is acceptable in my opinion.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2024-03-14 00:54:28,David Jacot,Mixed
37212bb242f937c0f0f8936350777686528291a4,"MINOR: AddPartitionsToTxnManager performance optimizations (#15454)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Justine Olshan <jolshan@confluent.io>",2024-03-14 18:53:26,David Mao,Mixed
178761eb36a3d0e82526a9694378fc2c9bdc7dd6,"KAFKA-14683 Cleanup WorkerSinkTaskTest (#15506)

1) Rename WorkerSinkTaskMockitoTest back to WorkerSinkTaskTest
2) Tidy up the code a bit
3) rewrite ""fail"" by ""assertThrow""

Reviewers: Omnia Ibrahim <o.g.h.ibrahim@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-03-15 03:50:57,Hector Geraldino,Not TDD
834efa66062687f520a9e936a5ee2798310d8bcf,"KAFKA-16342 fix getOffsetByMaxTimestamp for compressed records (#15474)

Fix getOffsetByMaxTimestamp for compressed records.

This PR adds:

1) For inPlaceAssignment case, compute the correct offset for maxTimestamp when traversing the batch records, and set to ValidationResult in the end, instead of setting to last offset always.

2) For not inPlaceAssignment, set the offsetOfMaxTimestamp for the log create time, like non-compressed, and inPlaceAssignment cases, instead of setting to last offset always.

3) Add tests to verify the fix.

Reviewers: Jun Rao <junrao@apache.org>, Chia-Ping Tsai <chia7712@gmail.com>",2024-03-15 06:09:45,Luke Chen,Mixed
e4c53d093eb70c29395e98b732749964572085a8,"KAFKA-15206: Fix the flaky RemoteIndexCacheTest.testClose test (#15523)

It is possible that due to resource constraint, ShutdownableThread#run might be called later than the ShutdownableThread#close method.

Reviewers: Luke Chen <showuon@gmail.com>, Divij Vaidya <diviv@amazon.com>",2024-03-15 10:33:40,Kamal Chandraprakash,Mixed
fa190cf18e6101b8e0212b6f79bb585ccfeb0437,"MINOR: Only enable replay methods to modify timeline data structure (#15528)

The patch prevents the main method (the method generating records) from modifying the timeline data structure `groups`  by calling `getOrMaybeCreateConsumerGroup` in kip-848 new group coordinator. Only replay methods are able to add the newly created group to `groups`.

Reviewers: David Jacot <djacot@confluent.io>",2024-03-15 05:24:59,Dongnuo Lyu,Mixed
af0ec247ccf7b1d97ca684109854bf1881fd11bb,"KAFKA-16231: Update consumer_test.py to support KIP-848’s group protocol config (#15330)

Added a new optional group_protocol parameter to the test methods, then passed that down to the setup_consumer method.

Unfortunately, because the new consumer can only be used with the new coordinator, this required a new @matrix block instead of adding the group_protocol=[""classic"", ""consumer""] to the existing blocks 😢

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-03-15 14:17:22,Kirk True,Mixed
e878654e95c3f82863a7b199fc3af56994f9841c,"MINOR: Cleanup BoundedList to Make Constructors More Safe (#15507)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-03-15 21:18:24,Chris Holland,Mixed
3f666026260472179c17ded967a8d9577107e1f0,"KAFKA-16190: Member should send full heartbeat when rejoining (#15401)

When the consumer rejoins, heartbeat request builder make sure that all fields are sent in the heartbeat request.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-03-15 18:41:25,TapDang,Mixed
359982328840226fecd9e655197fee07a6bdc538,"MINOR: Remove unused client side assignor fields/classes (#15545)

In https://github.com/apache/kafka/pull/15364, we introduced, thoughtfully, a non-backward compatible record change for the new consumer group protocol. So it is a good opportunity for cleaning unused fields, mainly related to the client side assignor logic which is not implemented yet. It is better to introduce them when we need them and more importantly when we implement it.

Note that starting from 3.8, we won't make such changes anymore. Non-backward compatible changes are still acceptable now because we clearly said that upgrade won't be supported from the KIP-848 EA.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-03-18 00:52:08,David Jacot,Mixed
e9c50b1f4b0e15b5b016256fb8e31ce704a8c166,"KAFKA-16369: Broker may not shut down when SocketServer fails to bind as Address already in use (#15530)

* KAFKA-16369: wait on enableRequestProcessingFuture

Add a Wait in in KafkaServer (ZK mode) for all the SocketServer ports
to be open, and the Acceptors to be started

The BrokerServer (KRaft mode) had such a wait,
which was missing from the KafkaServer (ZK mode).

Add unit test.",2024-03-18 10:14:43,Edoardo Comar,Mixed
5c929874b88b3b96f650de0f733d93d42ac535a4,"KAFKA-16312, KAFKA-16185: Local epochs in reconciliation (#15511)

The goal of this commit is to change the following internals of the reconciliation:

- Introduce a ""local epoch"" to the local target assignment. When a new target is received by the server, we compare it with the current value. If it is the same, no change. Otherwise, we bump the local epoch and store the new target assignment. Then, on the reconciliation, we also store the epoch in the reconciled assignment and keep using target != current to trigger the reconciliation.
- When we are not in a group (we have not received an assignment), we use null to represent the local target assignment instead of an empty list, to avoid confusions with an empty assignment received by the server. Similarly, we use null to represent the current assignment, when we haven't reconciled the assignment yet.
We also carry the new epoch into the request builder to ensure that we report the owned partitions for the last local epoch.
- To address KAFKA-16312 (call onPartitionsAssigned on empty assignments after joining), we apply the initial assignment returned by the group coordinator (whether empty or not) as a normal reconciliation. This avoids introducing another code path to trigger rebalance listeners - reconciliation is the only way to transition to STABLE. The unneeded parts of reconciliation (autocommit, revocation) will be skipped in the existing. Since a lot of unit tests assumed that not reconciliation behavior is invoked when joining the group with an empty assignment, this required a lot of the changes in the unit tests.

Reviewers: Lianet Magrans <lianetmr@gmail.com>, David Jacot <djacot@confluent.io>",2024-03-18 11:52:23,Lucas Brutschy,Mixed
1d6e0b872757317a23203e114303fbfb0a0a0c84,"KAFKA-16352: Txn may get get stuck in PrepareCommit or PrepareAbort state (#15524)

Now the removal of entries from the transactionsWithPendingMarkers map
checks the value and all pending marker operations keep the value along
with the operation state.  This way, the pending marker operation can
only delete the state it created and wouldn't accidentally delete the
state from a different epoch (which could lead to ""stuck"" transactions).

Reviewers: Justine Olshan <jolshan@confluent.io>",2024-03-18 19:08:55,Artem Livshits,Mixed
bf3f088c944763d8418764064f593d0bf06fbcc3,"KAFKA-16341 fix the LogValidator for non-compressed type (#15476)

- Fix the verifying logic. If it's LOG_APPEND_TIME, we choose the offset of the first record. Else, we choose the record with the maxTimeStamp.
- rename the shallowOffsetOfMaxTimestamp to offsetOfMaxTimestamp

Reviewers: Jun Rao <junrao@gmail.com>, Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-03-19 23:00:30,Johnny Hsu,Mixed
c66d66dc67b3aacb60f438bb4c5c1c132e8be4f2,"KAFKA-16367; Full ConsumerGroupHeartbeat response must be sent when full request is received (#15533)

This patch fixes a bug in the logic which decides when a full ConsumerGroupHeartbeat response must be returned to the client. Prior to it, the logic only relies on the `ownedTopicPartitions` field to check whether the response was a full response. This is not enough because `ownedTopicPartitions` is also set in different situations. This patch changes the logic to check `ownedTopicPartitions`, `subscribedTopicNames` and `rebalanceTimeoutMs` as they are the only three non optional fields.

Reviewers: Lianet Magrans <lianetmr@gmail.com>, Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2024-03-19 13:48:41,David Jacot,Mixed
34d365fd8a8e387e2650e3d9e492403d6bca9064,"KAFKA-16222: desanitize entity name when migrate client quotas (#15481)

The entity name is sanitized when it's in Zk mode.
We didn't desanitize it when we migrate client quotas. Add Sanitizer.desanitize to fix it.

Reviewers: Luke Chen <showuon@gmail.com>",2024-03-20 14:53:23,PoAn Yang,Not TDD
b6183a41342c765daec9c88f9d2723a221131960,"KAFKA-14589 ConsumerGroupCommand rewritten in java (#14471)

This PR contains changes to rewrite ConsumerGroupCommand in java and transfer it to tools module

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-03-20 15:34:45,Nikolay,Mixed
3e3c618bdc90ea225632a6aeecb0e65b5ac8294f,"KAFKA-16313: Offline group protocol migration (#15546)

This patch enables an empty classic group to be automatically converted to a new consumer group and vice versa.

Reviewers: David Jacot <djacot@confluent.io>",2024-03-20 00:49:11,Dongnuo Lyu,Mixed
f1d741a9c1057eb40a57d6ffbc81edb7e529e1f5,"KAFKA-16392: Stop emitting warning log message when parsing source connector offsets with null partitions (#15562)

Reviewers: Yash Mayya <yash.mayya@gmail.com>",2024-03-20 15:54:22,Chris Egerton,Mixed
03f7b5aa3abe9ee3b0474508a7797e0b992ec1f7,"KAFKA-16206: Fix unnecessary topic config deletion during ZK migration (#14206)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Ron Dagostino <rndgstn@gmail.com>",2024-03-21 15:38:42,Alyssa Huang,Not TDD
7e85d7d32e8cb4f3fa9b01fd4197ee43d64ba6d0,"MINOR: KRaft upgrade tests should only use latest stable mv (#15566)

This should help us avoid testing MVs before they are usable (stable).
We revert back from testing 3.8 in this case since 3.7 is the current stable version.

Reviewers: Proven Provenzano <pprovenzano@confluent.io>, Justine Olshan <jolshan@confluent.io>",2024-03-21 11:06:40,Alyssa Huang,Not TDD
2e8d69b78ca52196decd851c8520798aa856c073,"KAFKA-16314: Introducing the AbortableTransactionException (#15486)

As a part of KIP-890, we are introducing a new class of Exceptions which when encountered shall lead to Aborting the ongoing Transaction. The following PR introduces the same with client side handling and server side changes.

On client Side, the code attempts to handle the exception as an Abortable error and ensure that it doesn't take the producer to a fatal state. For each of the Transactional APIs, we have added the appropriate handling. For the produce request, we have verified that the exception transitions the state to Aborted.
On the server side, we have bumped the ProduceRequest, ProduceResponse, TxnOffestCommitRequest and TxnOffsetCommitResponse Version. The appropriate handling on the server side has been added to ensure that the new error case is sent back only for the new clients. The older clients will continue to get the old Invalid_txn_state exception to maintain backward compatibility.

Reviewers: Calvin Liu <caliu@confluent.io>, Justine Olshan <jolshan@confluent.io>",2024-03-22 11:26:07,Sanskar Jhajharia,Mixed
0f216b644874f2f89285f9d4736b50246cd5b0a2,"MINOR: Tuple2 replaced with Map.Entry (#15560)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-03-23 11:44:05,Nikolay,Not TDD
0434c29e58ee3019d289745fff3fd1b248224ada,"KAFKA-16408  kafka-get-offsets / GetOffsetShell doesn't handle --version or --help (#15583)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-03-25 12:12:23,Dmitry Werner,Mixed
7b2fc469adc58329a96d238bf80eef10f4fb0b22,"KAFKA-16410  kafka-leader-election / LeaderElectionCommand doesn't set exit code on error (#15591)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-03-25 12:31:37,Kuan-Po (Cooper) Tseng,Mixed
be17df6fdac5cf269d8f80b49f209fb20de70eed,"KAFKA-16374; High watermark updates should have a higher priority (#15534)

When the group coordinator is under heavy load, the current mechanism to release pending events based on updated high watermark, which consist in pushing an event at the end of the queue, is bad because pending events pay the cost of the queue twice. A first time for the handling of the first event and a second time for the handling of the hwm update. This patch changes this logic to push the hwm update event to the front of the queue in order to release pending events as soon as as possible.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2024-03-25 01:20:10,David Jacot,Mixed
0104cd04316a74127be2502a01b5b356a2a06087,"KAFKA-16375: Fix for rejoin while reconciling (#15579)

This PR includes a fix to properly identify a reconciliation that should be interrupted and not applied because the member has rejoined. It does so simply based on a flag (not epochs, server or local). If the member has rejoined while reconciling, the reconciliation will be interrupted.

This also ensures that the check to abort the reconciliation is performed on all the 3 stages of the reconciliation that could be delayed: commit, onPartitionsRevoked, onPartitionsAssigned.

Reviewers: David Jacot <djacot@confluent.io>, Lucas Brutschy <lbrutschy@confluent.io>",2024-03-25 11:30:08,Lianet Magrans,Mixed
f8ce7feebcede6c6da93c649413a64695bc8d4c1,"KAFKA-15950: Serialize heartbeat requests (#14903)

In between HeartbeatRequest being sent and the response being handled,
i.e. while a HeartbeatRequest is in flight, an extra request may be
immediately scheduled if propagateDirectoryFailure, setReadyToUnfence,
or beginControlledShutdown is called.

To prevent the extra request, we can avoid the extra requests by checking
whether a request is in flight, and delay the scheduling if necessary.

Some of the tests in BrokerLifecycleManagerTest are also improved to
remove race conditions and reduce flakiness.

Reviewers: Colin McCabe <colin@cmccabe.xyz>, Ron Dagostino <rdagostino@confluent.io>, Jun Rao <junrao@gmail.com>",2024-03-25 10:31:19,Igor Soarez,Mixed
da6bb365bc68a5d46ab37963429c39d972e011cd,"KAFKA-16224: Do not retry committing if topic or partition deleted (#15581)

Current logic for auto-committing offsets when partitions are revoked
will retry continuously when getting UNKNOWN_TOPIC_OR_PARTITION,
leading to the member not completing the revocation in time.

This commit considers error UNKNOWN_TOPIC_OR_PARTITION to be fatal
in the context of an auto-commit of offsets before a revocation,
even though the error is defined as retriable. This ensures that
the revocation can finish in time.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Lucas Brutschy <lbrutschy@confluent.io>, Lianet Magrans <lianetmr@gmail.com>",2024-03-25 20:59:41,Bruno Cadonna,Mixed
ad960635a90ead44f4a696c0da7777b5d06f5837,"KAFKA-16386: Convert NETWORK_EXCEPTIONs from KIP-890 transaction verification (#15559)

KIP-890 Part 1 introduced verification of transactions with the
transaction coordinator on the `Produce` and `TxnOffsetCommit` paths.
This introduced the possibility of new errors when responding to those
requests. For backwards compatibility with older clients, a choice was
made to convert some of the new retriable errors to existing errors that
are expected and retried correctly by older clients.

`NETWORK_EXCEPTION` was forgotten about and not converted, but can occur
if, for example, the transaction coordinator is temporarily refusing
connections. Now, we convert it to:
 * `NOT_ENOUGH_REPLICAS` on the `Produce` path, just like the other
   retriable errors that can arise from transaction verification.
 * `COORDINATOR_LOAD_IN_PROGRESS` on the `TxnOffsetCommit` path. This
   error does not force coordinator lookup on clients, unlike
   `COORDINATOR_NOT_AVAILABLE`. Note that this deviates from KIP-890,
   which says that retriable errors should be converted to
   `COORDINATOR_NOT_AVAILABLE`.

Reviewers: Artem Livshits <alivshits@confluent.io>, David Jacot <djacot@confluent.io>, Justine Olshan <jolshan@confluent.io>",2024-03-25 16:08:23,Sean Quah,Mixed
fa1cf7975e4005f59bf7a1ffc49e9d018c0eb572,"KAFKA-16409: DeleteRecordsCommand should use standard exception handling (#15586)

DeleteRecordsCommand should use standard exception handling

Reviewers: Luke Chen <showuon@gmail.com>",2024-03-26 08:44:59,PoAn Yang,Mixed
2d4abb85bf4a3afb1e3359a05786ab8f3fda127e,"KAFKA-16415 Fix handling of ""--version"" option in ConsumerGroupCommand (#15592)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-03-26 15:44:23,Dmitry Werner,Not TDD
6f8d4fe26b7ceaa369c5e974a8cf54cc2714f9a7,"KAFKA-15949: Unify metadata.version format in log and error message (#15505)

There were different words for metadata.version like metadata version or metadataVersion. Unify format as metadata.version.

Reviewers: Luke Chen <showuon@gmail.com>",2024-03-26 20:09:29,PoAn Yang,Mixed
8d914b543d5d23031fe178d424f45789eaa8d1fc,"KAFKA-16411: Correctly migrate default client quota entities (#15584)

KAFKA-16222 fixed a bug whereby we didn't undo the name sanitization used on client quota entity names
stored in ZooKeeper. However, it incorrectly claimed to fix the handling of default client quota
entities. It also failed to correctly re-sanitize when syncronizing the data back to ZooKeeper.

This PR fixes ZkConfigMigrationClient to do the sanitization correctly on both the read and write
paths. We do de-sanitization before invoking the visitors, since after all it does not make sense to
do the same de-sanitization step in each and every visitor.

Additionally, this PR fixes a bug causing default entities to be converted incorrectly. For example,
ClientQuotaEntity(user -> null) is stored under the /config/users/<default> znode in ZooKeeper. In
KRaft it appears as a ClientQuotaRecord with EntityData(entityType=users, entityName=null).
Prior to this PR, this was being converted to a ClientQuotaRecord with EntityData(entityType=users,
entityName=""""). That represents a quota on the user whose name is the empty string (yes, we allow
users to name themselves with the empty string, sadly.)

The confusion appears to have arisen because for TOPIC and BROKER configurations, the default
ConfigResource is indeed the one named with the empty (not null) string. For example, the default
topic configuration resource is ConfigResource(name="""", type=TOPIC).  However, things are different
for client quotas. Default client quota entities in KRaft (and also in AdminClient) are represented
by maps with null values. For example, the default User entity is represented by Map(""user"" ->
null).  In retrospect, using a map with null values was a poor choice; a Map<String,
Optional<String>> would have made more sense. However, this is the way the API currently is and we
have to convert correctly.

There was an additional level of confusion present in KAFKA-16222 where someone thought that using
the ZooKeeper placeholder string ""<default>"" in the AdminClient API would yield a default client
quota entity. Thise seems to have been suggested by the ConfigEntityName class that was created
recently. In fact, <default> is not part of any public API in Kafka. Accordingly, this PR also
renames ConfigEntityName.DEFAULT to ZooKeeperInternals.DEFAULT_STRING, to make it clear that the
string <default> is just a detail of the ZooKeeper implementation.  It is not used in the Kafka API
to indicate defaults. Hopefully this will avoid confusion in the future.

Finally, the PR also creates KRaftClusterTest.testDefaultClientQuotas to get extra test coverage of
setting default client quotas.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Igor Soarez <soarez@apple.com>",2024-03-26 16:49:38,Colin Patrick McCabe,Mixed
932647606504125e5c3ba0ae9470b4af335a0885,"KAFKA-16391: remove .lock file when FileLock#destroy (#15568)

Currently, server adds a .lock file to each log folder. The file is useless after server is down.

Reviewers: Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-03-27 11:13:54,PoAn Yang,Not TDD
6f38fe5e0a6e2fe85fec7cb9adc379061d35ce45,"KAFKA-14588 ZK configuration moved to ZkConfig (#15075)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-03-27 22:37:01,Nikolay,Mixed
cf1ba099c0723f9cf65dda4cd334d36b7ede6327,"MINOR: Renaming the `Abortable_Transaction` error to `Transaction_Abortable` (#15609)

This is a follow-up to this PR (https://github.com/apache/kafka/pull/15486) which introduced the new ABORTABLE_TRANSACTION error as a part of KIP-890 efforts. However on further discussion, we seem to gain consensus that the error should be rather named as TRANSACTION_ABORTABLE.

This PR aims to address the same. There are no changes in the code apart from that.

Reviewers: Justine Olshan <jolshan@confluent.io>, Igor Soarez <soarez@apple.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-03-28 03:13:32,Sanskar Jhajharia,Mixed
355873aa54439790d37a6b7c1c9d0c072511e47a,"MINOR: Use CONFIG suffix in ZkConfigs (#15614)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>, Omnia Ibrahim <o.g.h.ibrahim@gmail.com>
Co-authored-by: n.izhikov <n.izhikov@vk.team>",2024-03-28 15:52:34,Nikolay,Mixed
8b274d8c1bfbfa6d4319ded884a11da790d7bf77,"KAFKA-7663: Reprocessing on user added global stores restore (#15414)

When custom processors are added via StreamBuilder#addGlobalStore they will now reprocess all records through the custom transformer instead of loading directly.

We do this so that users that transform the records will not get improperly formatted records down stream.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2024-03-28 10:30:18,Walker Carlson,Mixed
71bcac3b6ada9872dcdec48f72372d6c5b041c0a,"MINOR: AbstractConfig cleanup (#15597)

Signed-off-by: Greg Harris <greg.harris@aiven.io>

Reviewers: Chris Egerton <chrise@aiven.io>, Mickael Maison <mickael.maison@gmail.com>, Omnia G H Ibrahim <o.g.h.ibrahim@gmail.com>, Matthias J. Sax <matthias@confluent.io>",2024-03-28 13:27:41,Greg Harris,Mixed
bf5e04e41626322eb60402266e7f28a262db4b4c,"KAFKA-16349: Prevent race conditions in Exit class from stopping test JVM (#15484)

Signed-off-by: Greg Harris <greg.harris@aiven.io>
Reviewers: Chris Egerton <chrise@aiven.io>",2024-03-28 20:07:42,Greg Harris,Not TDD
7c3a596688501223f2b53ed05fca7c8b9d39c3ca,"KAFKA-16397 Use ByteBufferOutputStream to avoid array copy (#15589)

Reviewers: Apoorv Mittal <amittal@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-03-29 20:28:19,John Yu,Mixed
2118d858053df9494ae0c314c3d32a9f7756e9ac,"KAFKA-16223 Replace EasyMock/PowerMock with Mockito for KafkaConfigBackingStoreTest (1/3) (#15520)

Reviewers: Greg Harris <greg.harris@aiven.io>",2024-03-29 15:39:36,Hector Geraldino,Mixed
6e4a098055d5ef852022a76a6ea48ccb880f6342,"KAFKA-16217: Stop the abort transaction try loop when closing producers (#15541)

This is a mitigation fix for the https://issues.apache.org/jira/browse/KAFKA-16217. Exceptions should not block closing the producers.
This PR reverts a part of the change #13591

Reviewers: Kirk True <ktrue@confluent.io>, Justine Olshan <jolshan@confluent.io>",2024-03-29 16:54:55,Calvin Liu,Mixed
d8673b26bf20634a2caf784159701062212cb103,"KAFKA-15899 [1/2] Move kafka.security package from core to server module (#15572)

1) This PR moves kafka.security classes from core to server module.
2) AclAuthorizer not moved, because it has heavy dependencies on core classes that not rewrited from scala at the moment.
3) AclAuthorizer will be deleted as part of ZK removal

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-03-30 11:54:22,Nikolay,Mixed
d4caa1c10ec81b9c87eaaf52b73c83d5579b68d3,"MINOR: Remove redundant ApiVersionsResponse#filterApis (#15611)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-03-31 11:22:16,Kuan-Po (Cooper) Tseng,Not TDD
40e87ae35beb389d6419d32130174d7c68fa4d19,"KAFKA-15823: disconnect from controller on AuthenticationException (#14760)

This PR changes the handling of authenticationException on a request from the node to the controller.

We disconnect controller connection and invalidate the cache so that the next run of the thread will establish a connection with the (potentially) updated controller.

Reviewers: Luke Chen <showuon@gmail.com>, Igor Soarez <soarez@apple.com>, Omnia Ibrahim <o.g.h.ibrahim@gmail.com>",2024-04-01 11:55:08,Gaurav Narula,Not TDD
2f733ac58386a1669bd021e673fae581172e2b56,"KAFKA-16161: Avoid empty remote metadata snapshot file in partition dir (#15636)

Avoid empty remote metadata snapshot file in partition dir

Reviewers: Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>, Satish Duggana <satishd@apache.org>",2024-04-02 10:07:54,Kamal Chandraprakash,Mixed
2932eb2b4c5cd848c7821932de6c17c85763b936,"KAFKA-16365: AssignmentsManager callback handling issues (#15521)

When moving replicas between directories in the same broker, future replica promotion hinges on acknowledgment from the controller of a change in the directory assignment.

ReplicaAlterLogDirsThread relies on AssignmentsManager for a completion notification of the directory assignment change.

In its current form, under certain assignment scheduling, AssignmentsManager both miss completion notifications, or prematurely trigger them.

Reviewers: Luke Chen <showuon@gmail.com>, Omnia Ibrahim <o.g.h.ibrahim@gmail.com>, Gaurav Narula <gaurav_narula2@apple.com>",2024-04-02 11:11:32,Igor Soarez,Mixed
b3116f4f76ebc8a074e0d7ce38bf46981da44723,"KAFKA-16148: Implement GroupMetadataManager#onUnloaded (#15446)

This patch completes all awaiting futures when a group is unloaded.

Reviewers: David Jacot <djacot@confluent.io>",2024-04-02 03:16:02,Jeff Kim,Mixed
ee61bb721eecb0404929f125fe43392f3d024453,"KAFKA-15417: move outerJoinBreak-flags out of the loop (#15510)

Follow up PR for https://github.com/apache/kafka/pull/14426 to fix a bug introduced by the previous PR.

Cf https://github.com/apache/kafka/pull/14426#discussion_r1518681146

Reviewers: Matthias J. Sax <matthias@confluent.io>",2024-04-02 06:46:54,Victor van den Hoven,Not TDD
3208c5f487b6c7279499167580a8e175a790bcf6,"MINOR: AbstractConfig cleanup Part 2 (#15639)

Reviewers:  Manikumar Reddy <anikumar.reddy@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-04-03 20:05:16,Greg Harris,Mixed
376e9e20dbf7c7aeb6f6f666d47932c445eb6bd1,"KAFKA-15586: Clean shutdown detection - server side (#14706)

If the broker registers with the same broker epoch as the previous session, it is recognized as a clean shutdown. Otherwise, it is an unclean shutdown. This replica will be removed from any ELR.

Reviewers: Artem Livshits <alivshits@confluent.io>, David Arthur <mumrah@gmail.com>",2024-04-04 09:12:05,Calvin Liu,Mixed
a2ee0855ee5e73f3a74555d52294bb4acfd28945,"KAFKA-16471 invoke SSLEngine::closeInbound on SslTransportLayer close (#15655)

Invokes `SSLEngine::closeInbound` after we flush close_notify alert tothe socket. This fixes memory leak in Netty/OpenSSL based SSLEngine which only free native resources once closeInbound has been invoked.

Reviewers: Omnia Ibrahim <o.g.h.ibrahim@gmail.com>, Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-04-05 12:11:03,Gaurav Narula,Mixed
5e4c7dae22975e7482ea5d4f8c69dd6c97404e99,"KAFKA-15915: Flaky ProducerIdManagerTest error injection fix (#15605)

testUnrecoverableErrors was flaky as the wanted error either affected the next block request (prefecthing) or just missed that.

First I tried to wait for the background thread to be finished before setting the Errors.X. But then it consistently failed, because the generateProducerId call does prefetching too and after a successful producer id generation we set the error and expected that it will fail again with coordinator-load-in-progress exception but since the block was prefetched, it was able to serve us with a proper producer id.

    calling generateProducerId --> no current block exists, so requesting block --> CoordinatorLoadInProgressException
    asserting exception
    calling generateProducerId again --> prefetching, requesting the next block --> giving back the producer id from the first block
    asserting received producer id
    setting error -- waiting for the background callback(s) to be finished first
    calling generateProducerId, expecting CoordinatorLoadInProgressException, but --> works like 2), just the prefetching callback is failing due to the error we set before

Note: without the waiting for the background thread completions the error setting could happened before the 2) step's callback or after that, the test was written in a way that it expected to happen before the cb.

This was the point I realised that we need to have a queue to control the responses rather than trying to do it in the middle of the test method.

Errors can be passed in a queue at creation of the mock id manager instead modifying on-the-fly.
In the queue we're specifying Errors, how the background thread (which imitates the controllerChannel) should behave, return an error or a proper response and call the callback accordingly with that.

I was able to simplify the mock manager id class as well, no need for the maybeRequestNextBlock overriding if the errors are handled this way via a queue.

Reviewers: Igor Soarez <soarez@apple.com>, Daniel Urban <urb.daniel7@gmail.com>, Viktor Somogyi-Vass <viktorsomogyi@gmail.com>",2024-04-05 14:59:27,Andras Katona,Mixed
5c1b819b02ae9905fba4c2bdcb38998e5817566f,"KAFKA-16472 Fix integration tests in Java with parameter name (#15663)

Following test cases don't really run kraft case. The reason is that the test info doesn't contain parameter name, so it always returns false in TestInfoUtils#isKRaft.

1) TopicCommandIntegrationTest
2) DeleteConsumerGroupsTest
3) AuthorizerIntegrationTest
4) DeleteOffsetsConsumerGroupCommandIntegrationTest

We can fix it by adding options.compilerArgs << '-parameters' after

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-06 10:43:22,PoAn Yang,Not TDD
e798bed19808157ccae6503253a926653561bc0d,"KAFKA-16234: Log directory failure re-creates partitions in another logdir automatically (#15335)

This pr fixes the bug created by #15263 which caused topic partition to be recreated whenever the original log dir is offline: Log directory failure re-creates partitions in another logdir automatically

Reviewers: Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>, Igor Soarez <soarez@apple.com>, Gaurav Narula <gaurav_narula2@apple.com>, Proven Provenzano <pprovenzano@confluent.io>",2024-04-06 14:36:26,Omnia Ibrahim,Mixed
31e8a7fb04ac833629d04e73de90ef9e09e8989c,"MINOR: Default test name added to tools (#15666)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-07 21:35:00,Nikolay,Not TDD
4b2278ff9c8c6a02be8a40005ee3ed593e1c7112,"MINOR: Default test name added to core (#15667)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-07 21:43:16,Nikolay,Not TDD
4e0578fb814e99da2a8f4d6adc123fe87c8f24f3,"KAFKA-16156: beginningOrEndOffsets does not need to build an OffsetAndTimestamps object upon completion (#15525)

A subtle difference in the behavior of the two API causes the failures with Invalid negative timestamp.

In this PR, the list offsets response will be processed differently based on the API. For beginingOffsets/endOffsets - the offset response should be directly returned.

For offsetsForTimes - A OffsetAndTimestamp object is constructed for each requested TopicPartition before being returned.

The reason beginningOffsets and endOffsets - We are expecting a -1 timestamp from the response which subsequently causes the invalid timestamp exception because the original code tries to construct an OffsetAndTimestamp object upon returning.

In this PR, the following missing tasks are added:

short-circuit both beginningOrEndOffsets
Test both API (beginningOrEndOffsets, OffsetsForTime)
Seems like we don't have tests for this API: Note it is presented in other IntegrationTests but they are added to test Async consumer

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>, Lianet Magrans <lianetmr@gmail.com>",2024-04-08 13:04:58,Philip Nee,Mixed
169ed60fe14304040a858529e465cca49c3e4d21,"KAFKA-16477 Detect thread leaked client-metrics-reaper in tests (#15668)

After profiling the kafka tests, tons of client-metrics-reaper thread not cleanup after BrokerServer shutdown.
The thread client-metrics-reaper comes from ClientMetricsManager#expirationTimer, and BrokerServer#shudown doesn't close ClientMetricsManager which let the thread still runs in background.

Reviewers: Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-04-09 05:07:33,Kuan-Po (Cooper) Tseng,Mixed
f895ab5145077c5efa10a4a898628d901b01e2c2,"KAFKA-16455: Check partition exists before send reassignments to server in ReassignPartitionsCommand (#15659)

Currently, when executing kafka-reassign-partitions.sh with the --execute option, if a partition number specified in the JSON file does not exist, this check occurs only when submitting the reassignments to alterPartitionReassignments on the server-side.

We can perform this check in advance before submitting the reassignments to the server side.

Reviewers: Luke Chen <showuon@gmail.com>",2024-04-09 07:56:31,Kuan-Po (Cooper) Tseng,Not TDD
a95a40d1402bc07d7183b4114373309c8ad4a514,"KAFKA-16485: Broker metrics to follow kebab/hyphen case (KIP-714) (#15680)

Updates the broker metrics name to kebab/hyphen case. Also removed the redundant client-metrics- prefix in all metrics as the group name in client-metrics itself.

Reviewers: David Jacot <djacot@confluent.io>, Jun Rao <junrao@gmail.com>",2024-04-09 09:03:13,Apoorv Mittal,Mixed
3ad648243c72adbd7ba6e52cbaff143b551884b1,"KAFKA-13907 Fix hanging ServerShutdownTest.testCleanShutdownWithKRaftControllerUnavailable (#12174)

Add new method shutdown(Duration) to accept timeout argument. We can leverage the new method to run non-graceful shutdown in testing.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-10 00:43:12,Igor Soarez,Not TDD
9a6760f13040acbbfbe2ca3d0df457c3fbc95a9f,"KAFKA-16310 ListOffsets doesn't report the offset with maxTimestamp a… (#15621)

We do iterate the records to find the offsetOfMaxTimestamp instead of returning the cached one when handling ListOffsetsRequest.MAX_TIMESTAMP, since it is hard to align all paths to get correct offsetOfMaxTimestamp. The known paths are shown below.

1. convertAndAssignOffsetsNonCompressed -> we CAN get correct offsetOfMaxTimestamp when validating all records
2. assignOffsetsNonCompressed -> ditto
3. validateMessagesAndAssignOffsetsCompressed -> ditto
4. validateMessagesAndAssignOffsetsCompressed#buildRecordsAndAssignOffsets -> ditto
5. appendAsFollow#append#analyzeAndValidateRecords -> we CAN'T get correct offsetOfMaxTimestamp as iterating all records is expensive when fetching records from leader
6. LogSegment#recover -> ditto

Reviewers: Jun Rao <junrao@gmail.com>",2024-04-10 11:36:07,Chia-Ping Tsai,Mixed
a4d6456872dc428dc331d6ea1c6e728648947f98,"KAFKA-15538: Client support for java regex based subscription (#15585)

Fully implemented legacy subscription using Pattern for AsyncKafkaConsumer.
Enabled related tests for subscription using Pattern in PlaintextConsumerTest.

Reviewers: Lianet Magrans <lianetmr@gmail.com>, Kirk True <ktrue@confluent.io>, David Jacot <djacot@confluent.io>, Bruno Cadonna <cadonna@apache.org>",2024-04-10 09:20:46,Phuc-Hong-Tran,Not TDD
dd80a90dc4652dbed6e96fad7372a28e3f24ba4b,"KAFKA-16004: auto-commit inflight improved logs, docs and tests (#15669)

Minor changes for improving the logging and docs related to the auto-commit inflight logic, also adding tests to ensure the expected behaviour:

- auto-commit on the interval does not send a request if another one inflight, and it sends the next as soon as a response is received (without waiting for the full interval again)
- auto-commit before revocation always send a request (even if another one from auto-commit on interval is in-flight), to ensure the latest is committed before revoking partitions.

No changes in logic, just adding tests, docs and minor refactoring.

Reviewer: Bruno Cadonna <cadonna@apache.org>",2024-04-10 09:24:45,Lianet Magrans,Mixed
5c855be0150f3c7db6a023d909c79f0c5e1fba14,"MINOR: Remove dead code of metric forward-rate (#15686)

Kafka Streams announced the removal  of metric forward-rate in
KIP-444 and removed it completely in AK 3.0. However, we forgot
to remove some code for this metric.
This commit removes the code to create the metric forward-rate.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Matthias J. Sax <matthias@confluent.io>",2024-04-10 09:28:11,Bruno Cadonna,Mixed
e5a3f991005dcc9c544918879bdd6127e1ff9aed,"KAFKA-16433: BeginningAndEndOffsets and OffsetsForTimes should send an event and return empty with zero timeout provided (#15688)

beginningOrEndOffset and offsetforTimes should send a ListOffsetEvent and return empty results if the provided timeout is zero.

A minor change to the mock timer with zero timeout in AsyncConsumerTest.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-04-10 11:27:35,Philip Nee,Mixed
f6c9feea76d01a46319b0ca602d70aa855057b07,"KAFKA-16297: Race condition while promoting future replica (#15557)

If a future replica doesn't get promoted, any directory reassignment sent to the controller should be reversed.

The current logic is already addressing the case when a replica hasn't yet been promoted and the controller hasn't yet acknowledged the directory reassignment. However, it doesn't cover the case where the replica does not get promoted due to a directory failure after the controller has acknowledged the reassignment but before the future replica catches up again and is promoted to main replica.

Reviewers: Luke Chen <showuon@gmail.com>",2024-04-10 17:57:05,Igor Soarez,Mixed
e2e2f82f2b688e5da9ba99e7dff6d7d7ca8eb1b1,"KAFKA-15853 Move Sasl and SSL configs out of core (#15656)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-10 21:57:52,Omnia Ibrahim,Mixed
dc9fbe453c872280711d396cc812dd23be362513,"KAFKA-16389: ConsumerEventHandler does not support incremental assignment changes causing failure in system test (#15661)

The current AssignmentValidationTest only tests EAGER assignment protocol and does not support incremental assignment like CooperativeStickyAssignor and consumer protocol. Therefore in the ConsumerEventHandler, I subclassed the existing handler overridden the assigned and revoke event handling methods, to permit incremental changes to the current assignments.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>, Kirk True <ktrue@confluent.io>",2024-04-10 18:52:05,Philip Nee,Mixed
619f27015fbe8db6b46cb0d671395696d9725369,"KAFKA-16294: Add group protocol migration enabling config (#15411)

This patch adds the `group.consumer.migration.policy` config which controls how consumer groups can be converted from classic group to consumer group and vice versa. The config is kept as an internal one while we develop the feature.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, David Jacot <djacot@confluent.io>",2024-04-10 10:59:26,Dongnuo Lyu,Mixed
b67a3fa79dab8bb253be353fb35d9e9f8536d750,"KAFKA-16509: CurrentControllerId metric is unreliable in ZK mode (#15695)

The CurrentControllerId metric added by KIP-1001 is unreliable in ZK
mode. Sometimes when there is no active ZK-based controller, it still
shows the previous controller ID. Instead, it should show -1 in that
situation.

This PR fixes that by using the controller ID from the
KafkaController.scala, which is obtained directly from the controller
znode. It also adds a new test, ControllerIdMetricTest.scala.

Reviewers: David Arthur <mumrah@gmail.com>",2024-04-11 09:34:27,Colin Patrick McCabe,Not TDD
a50ea8d4def1de26788b0713a97b5f5d850d03c3,"KAFKA-16473: Use correct cluster ID when formatting log dir. (#15658)

This fixes an issue that when starting a Docker container for the first time, the cluster ID used when formatting the log dir would not be $CLUSTER_ID but Some($CLUSTER_ID) (KAFKA-16473).

In order to be able to test the formatStorageCmd method which contained the bug, the method has been made package private.

Reviewers: cooper.tseng@suse.com, Vedarth Sharma <142404391+VedarthConfluent@users.noreply.github.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-04-12 11:30:27,Sebastian Marsching,Mixed
15c4ade06af839e93dbf5d8c37530bab66c56062,"MINOR: Improve logging in AssignmentsManager (#15522)

At the moment it can be a bit difficult to troubleshoot issues related to the AssignmentsManager. Mainly because:

    Topic partitions are logged with topic ID and partition index but without the topic name.
    Directory IDs are logged without the directory path.
    Assignment reasons aren't tracked.

This patch addresses the three issues.

Reviewers: Luke Chen <showuon@gmail.com>",2024-04-12 14:13:40,Igor Soarez,Mixed
61baa7ac6bb871797197d9289a848a0d4f587ced,"KAFKA-15853 Move transactions configs out of core (#15670)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-13 00:29:51,Omnia Ibrahim,Mixed
e02ffd852fae7c1d2681621be7eb888e3805e027,"KAFKA-16463 Delete metadata log on ZK broker startup (#15648)

This patch changes the behavior of the migrating ZK broker to always delete the local metadata log
during startup. This deletion is done immediately before creating the RaftManager which will
re-create the log directory and let the broker re-replicate the log from the active controller.

This new behavior is only present for ZK brokers that having migrations enabled. KRaft brokers,
even those with migrations enabled, will not delete their local metadata log. KRaft controllers are
not impacted by this change.

The rationale for this change is to make it easier for operators to re-attempt a ZK to KRaft
migration after having reverted back to ZK mode. If an operator has reverted back to ZK mode, there
will be an invalid metadata log on the disk of each broker. In order to re-attempt the migration in
the future, this log needs to be deleted. This can be pretty burdensome to the operator for large
clusters, especially since the log deletion must be done while the broker is offline.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Igor Soarez <soarez@apple.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-04-12 10:21:30,David Arthur,Mixed
0b4e9afee2ace7edf6ff8690e070100b98627836,"MINOR: Various cleanups in shell (#15712)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-14 15:42:04,Mickael Maison,Mixed
4caf88853c4505f79b83f7a724722b4b2980990b,"MINOR: Various cleanups in trogdor (#15708)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-15 16:09:59,Mickael Maison,Mixed
3617dda9a5415ee1597967f754985fb73a5350c6,"MINOR: Various cleanups in storage (#15711)


Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-15 13:30:41,Mickael Maison,Mixed
395fdae5f23bb8202cfc5b0a0e4630e9c32e0edd,"MINOR: Various cleanups in tools (#15709)


Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-15 17:25:17,Mickael Maison,Mixed
2b9729ba771ae139dd9931cb7cdc7247f80ee842,"MINOR: Various cleanups in server and server-common (#15710)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-16 15:20:49,Mickael Maison,Mixed
8c0458861c92d0a85969e99cb3b62c3256ad21e8,"KAFKA-15853 Move KafkaConfig Replication properties and docs out of … (#15575)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-16 15:28:35,Omnia Ibrahim,Mixed
a1ca788c993e3b217a0904c3f4768f0682dc840b,"KAFKA-15517: Improve MirrorMaker logging in case of authorization errors (#15558)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2024-04-16 12:09:14,Dmitry Werner,Mixed
ebeef4eb64a36d46565629d2a370eeb1635a7293,"KAFKA-16556: SubscriptionState should not prematurely reset 'pending' partitions (#15724)

Partitions that are marked as pendingOnAssignedCallback should not be reset in resetInitializingPositions(). Pending partitions are omitted from the set returned by initializingPartitions(). As a result, the Consumer does not include them in the set of partitions for which it attempts to load committed offsets. The code used by the Consumer to reset positions (resetInitializingPositions()) should likewise skip partitions marked as pending.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-04-16 14:49:02,Kirk True,Mixed
4954c578d43e4306cf24638569122fb4b63b709f,"KAFKA-16559 allow defining number of disks per broker in TestKitNodes (#15730)

Reviewers: Igor Soarez <soarez@apple.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-04-17 13:45:37,Gaurav Narula,Not TDD
44196984bd244b1e1cc1a3bcda85035d3dee2dc8,"KAFKA-16363 Storage tool crashes if dir is unavailable (#15733)

Reviewers: Igor Soarez <soarez@apple.com>, Federico Valeri <fedevaleri@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-04-17 19:03:51,Michael Westerby,Mixed
a9f65a5d7ff86fb31d020c7c6bb4afa48521810f,"KAFKA-16436; Online upgrade triggering and group type conversion (#15662)

This patch introduces the conversion from a classic group to a consumer group when a member joins with the new consumer group protocol (epoch is 0) but only if the conversion is enabled.

Reviewers: David Jacot <djacot@confluent.io>",2024-04-17 04:57:44,Dongnuo Lyu,Mixed
363f4d28472793029f7ed3c0f156406f11a3bd7e,"KAFKA-15853 Move consumer group and group coordinator configs out of core (#15684)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-17 20:41:22,Omnia Ibrahim,Mixed
7b1c777b3385f7376252c7a87ab95fb2de815bc4,"MINOR: Various cleanups in connect (#15734)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-17 20:47:25,Mickael Maison,Mixed
a3dcbd4e28a35f79f75ec1bf316ef0b39c0df164,"KAFKA-16073: Increment the local-log-start-offset before deleting segments in memory table (#15631)

Co-authored-by: hzh0425 <642256541@qq.com>

Reviewers: Luke Chen <showuon@gmail.com>, Jun Rao <junrao@gmail.com>",2024-04-17 09:41:29,Kamal Chandraprakash,Mixed
aee9724ee15ed539ae73c09cc2c2eda83ae3c864,"MINOR: Remove unneeded explicit type arguments (#15736)


Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-17 21:55:58,Mickael Maison,Not TDD
53ff1a5a589eb0e30a302724fcf5d0c72c823682,"KAFKA-15585: DescribeTopicPartitions client side change. (#15470)

Add the support for DescribeTopicPartitions API to AdminClient. For this initial implementation, we are simply loading all of the results into memory on the client side. 

Reviewers: Andrew Schofield <aschofield@confluent.io>, Kirk True <ktrue@confluent.io>, David Jacot <djacot@confluent.io>, Artem Livshits <alivshits@confluent.io>, David Arthur <mumrah@gmail.com>",2024-04-18 12:09:14,Calvin Liu,Mixed
5d3f8670b4e80e1cdcb2d9de57a34d80e6a5608d,"KAFKA-16280: Expose method to determine metric measurability (KIP-1019) (#15681)

Implements KIP-1019, which exposes method to check if metric is of type Measurable.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2024-04-18 18:13:29,Apoorv Mittal,Mixed
f22ad6645bfec0b38e820e0090261c9f6b421a74,"KAFKA-16272: Adding new coordinator related changes for connect_distributed.py (#15594)

Summary of the changes:

Parameterizes the tests to use new coordinator and pass in consumer group protocol. This would be applicable to sink connectors only.
Enhances the sink connector creation code in system tests to accept a new optional parameter for consumer group protocol to be used.
Sets the consumer group protocol via consumer.override. override config when the new group coordinator is enabled.
Note about testing: There are 288 tests that need to be run and running on my local takes a lot of time. I will try to post the test results once I have a full run.

Reviewers: Kirk True <ktrue@confluent.io>, Lucas Brutschy <lbrutschy@confluent.io>, Philip Nee <pnee@confluent.io>",2024-04-19 17:29:50,vamossagar12,Not TDD
ecb2dd4cdc4b83df7a97dc37e4e419ad4490ae10,"KAFKA-15853 Move KafkaConfig log properties and docs out of core (#15569)

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Nikolay <nizhikov@apache.org>, Federico Valeri <fvaleri@redhat.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-04-20 04:14:23,Omnia Ibrahim,Mixed
0308543d596d564b68dcac371a8e3af69e06caea,"KAFKA-16082 Avoid resuming future replica if current replica is in the same directory (#15136)

It is observed that for scenario (3), i.e. a broker crashes while it
waits for the future replica to catch up for the second time and the
`dir1` is unavailable when the broker is restarted, the
broker tries to create the partition in `dir2` according to the metadata
in the controller. However, ReplicaManager also tries to resume the
stale future replica which was abandoned when the broker crashed. This
results in the renaming of the future replica to fail eventually because
the directory for the topic partition already exists in `dir2` and the
broker then marks `dir2` as offline.

This PR attempts to fix this behaviour by ignoring any future replicas
which are in the same directory as where the log exists. It further
marks the stale future replica for deletion.

Reviewers: Omnia Ibrahim <o.g.h.ibrahim@gmail.com>,  Igor Soarez <soarez@apple.com>, Proven Provenzano <pprovenzano@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-04-20 04:18:51,Gaurav Narula,Not TDD
ced79ee12f295ebe30a4dc9a90228a18c9fc94df,"KAFKA-16552 Create an internal config to control InitialTaskDelayMs in LogManager to speed up tests (#15719)

Reviewers: Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-04-20 20:34:02,Kuan-Po (Cooper) Tseng,Mixed
5e96e5c898c01d1e8c223d9201ad28b1608dd6df,"KAFKA-15853 Refactor KafkaConfig to use PasswordEncoderConfigs (#15770)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-22 00:47:57,Omnia Ibrahim,Mixed
ed47e37b28341a181b0114827e1b5474bcc368c9,"KAFKA-16103: AsyncConsumer should await pending async commits on commitSync and close (#15613)

The javadoc for KafkaConsumer.commitSync says:

Note that asynchronous offset commits sent previously with the {@link #commitAsync(OffsetCommitCallback)}
(or similar) are guaranteed to have their callbacks invoked prior to completion of this method.

This is not always true in the async consumer, where there is no code at all to make sure that the callback is executed before commitSync returns.

Similarly, the async consumer is also missing logic to await callback execution in close. While the javadoc doesn't explicitly promise callback execution, it promises ""completing commits"", which one would reasonably expect to include callback execution. Also, the legacy consumer contains some code to execute callbacks before closing.

This change proposed a number of fixes to clean up the callback execution guarantees in the async consumer:

We keep track of the incomplete async commit
futures and wait for them to complete before returning from
commitSync or close (if there is time).
Since we need to block to make sure that our previous commits are
completed, we allow the consumer to wake up.
Some similar gaps are addressed in the legacy consumer, see #15693

Testing
Two new integration tests and a couple of unit tests.

Reviewers: Bruno Cadonna <cadonna@apache.org>, Kirk True <ktrue@confluent.io>, Lianet Magrans <lianetmr@gmail.com>",2024-04-22 13:26:15,Lucas Brutschy,Mixed
59c781415fc37c89aa087d7c2999cec7f82f6188,"MINOR: Fix io-[wait-]ratio metrics description (#15722)

Implementation of KIP-773 deprecated iotime-total and io-waittime-total metrics. It wasn't expected to mark io-ratio and io-wait-ratio deprecated. However, now they have *Deprecated* in their description. Here is the reason:

    register io-ratio (desc: *Deprecated* The fraction of time ...) -> registered
    register iotime-total (desc: *Deprecated* The total time ...) -> registered
    register io-ratio (desc: The fraction of time ...) -> skipped, the same name already exists in registry
    register io-time-ns-total (desc: The total time ...) -> registered

As a result, io-ratio has incorrect description. The same for io-wait-ratio. This PR fixes these descriptions..

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-22 21:50:38,Eugene Mitskevich,Mixed
b254e787cbdefb38344c6a0da2b965e6d7707d27,"KAFKA-16466: Log exception message for non-fault errors in QuorumController (#15701)

The generic error handler of QuorumController didn't log the exception message for non-fault errors, which includes very useful debugging info.

Reviewers: Igor Soarez <soarez@apple.com>",2024-04-23 02:01:36,ilyazr,Mixed
18572f5f8f00ff679682858de3b952f4b90bc0ca,"MINOR: Reduce the time taken to execute the TieredStorage tests. (#15780)

Reduce the time taken to execute the TieredStorage tests

Reviewers: Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-04-23 10:21:46,Kamal Chandraprakash,Not TDD
1b301b30207ed8fca9f0aea5cf940b0353a1abca,"KAFKA-15853 Move socket configs into org.apache.kafka.network.SocketServerConfigs (#15772)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-23 17:39:36,Omnia Ibrahim,Mixed
b6e70e9a54f9bafe49f33b56ef089601bef3db91,"MINOR: Add test for PartitionMetadataFile (#15714)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-24 13:01:35,"Cheng-Kai, Zhang",Not TDD
cfe5ab5cf23543392a240a7abc38279f343501c3,"KAFKA-15853 Move quota configs into server-common package (#15774)

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-04-24 13:05:18,Omnia Ibrahim,Mixed
a38185280ca011d4caced05171e94ac53cda964d,"KAFKA-16424: remove truncated logs after alter dir (#15616)

If there are some logs to be deleted during the log dir movement, we'll send for a scheduler to do the deletion later.
However, when the log dir movement completed, the future log is renamed, the async log deletion will fail with no file existed error.

Signed-off-by: PoAn Yang <payang@apache.org>

Reviewers: Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>, SoontaekLim <soontaek.lim@neya.kr>, Johnny Hsu <johnnyhsu@fb.com>",2024-04-24 17:51:29,PoAn Yang,Not TDD
b8b2415d5e006cf91c0f74dcf60b764933c9c1d0,"KAFKA-16592 Add a new constructor which invokes the existing constructor with default value for alternativeString (#15762)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-24 20:58:29,vamossagar12,Not TDD
864744ffd4ddc3b0d216a3049ee0c61e9c0d3ad1,"KAFKA-16610 Replace ""Map#entrySet#forEach"" by ""Map#forEach"" (#15795)


Reviewers: Apoorv Mittal <amittal@confluent.io>, Igor Soarez <soarez@apple.com>",2024-04-25 01:52:24,"TingIāu ""Ting"" Kì",Mixed
dc1d8fc330b35f517c8e939b80d6fab4244fa052,"KAFKA-16554: Online downgrade triggering and group type conversion (#15721)

Online downgrade from a consumer group to a classic group is triggered when the last consumer that uses the consumer protocol leaves the group. A rebalance is manually triggered after the group conversion. This patch adds consumer group downgrade validation and conversion.

Reviewers: David Jacot <djacot@confluent.io>",2024-04-25 07:44:25,Dongnuo Lyu,Mixed
0a6d5ff23cd3792ed6401f1fffa8189d0f2f05ca,"MINOR: Various cleanups in core (#15786)


Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Omnia Ibrahim <o.g.h.ibrahim@gmail.com>",2024-04-25 16:45:00,Mickael Maison,Mixed
6feae817d25d3ffd97916f53c0183f88494a23c3,"MINOR: Rename RaftConfig to QuorumConfig (#15797)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-26 03:08:31,Omnia Ibrahim,Mixed
df4ef5a6210c01661a068123d52af7bf8ba6769d,"MINOR: Various cleanups in metadata (#15806)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-26 05:50:40,Mickael Maison,Mixed
025f9816f1a15d14aab25c9e8e5b03a87f0cefe2,"MINOR: fix javadoc warnings (#15527)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-26 08:31:52,Gaurav Narula,Not TDD
82844c01d8e0111e9d0eb5cb37293e3b248b147b,"KAFKA-16528: Client HB timing fix (#15698)

Fix for resetting HB timer when the request is sent, rather than when a response is received. This ensures a more accurate timing of the HB, so that a member always sends HB on the interval (not in the interval + any delay in receiving the response).
This change, along with the logic already in place for checking in-flights, ensures that if the interval expires but there is a HB in-flight, the next HB is only send after the response for the in-flight is received, without waiting for another full interval. This is btw consistent with the timer reset & inflight behaviour for the auto-commit interval.

Reviewers: Kirk True <ktrue@confluent.io>, Bruno Cadonna <cadonna@apache.org>",2024-04-26 09:29:59,Lianet Magrans,Mixed
2db87f04b807b6ea6ba6cdd43fc05852cb1938e9,"KAFKA-16298: Ensure rebalance listener exceptions are propagated to the user on consumer poll (#15742)

When user-defined rebalance listeners fail with an exception, the expectation is that the error should be propagated to the user as a KafkaException and break the poll loop (behavior in the legacy coordinator). The new consumer executes callbacks in the application thread, and sends an event to the background with the callback result and error if any, passing the error along with the event here to the background thread, but does not seem to propagate the exception to the user.

Reviewers: Lianet Magrans <lianetmr@gmail.com>, Kirk True <ktrue@confluent.io>, Bruno Cadonna <cadonna@apache.org>",2024-04-26 10:28:57,Lucas Brutschy,Mixed
e7792258df934a5c8470c2925c5d164c7d5a8e6c,"MINOR: Various cleanups in raft (#15805)


Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-26 15:20:09,Mickael Maison,Not TDD
d88c15fc3ed0d13e380b29df3559591c59fbf4c5,"KAFKA-15853 Move KRAFT configs out of KafkaConfig (#15775)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-27 07:02:31,Omnia Ibrahim,Mixed
cc5955d5b2848c9e235e69bc44f2f511bc4ae4a7,"MINOR: Various cleanups in generator (#15807)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-27 07:16:29,Mickael Maison,Not TDD
5de5d967adffd864bad3ec729760a430253abf38,"KAFKA-16560 Refactor/cleanup BrokerNode/ControllerNode/ClusterConfig (#15761)

* Make ClusterConfig immutable
* Make BrokerNode immutable
* Refactor out build argument in ControllerNode
* Add setPrefix and replace put property with set map in ClusterConfig
* Remove rollingBrokerRestart from ClusterInstance interface
* Refactor KRaftClusterTest#doOnStartedKafkaCluster

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-28 02:00:56,Kuan-Po (Cooper) Tseng,Mixed
ec151c82783f75de3ee755c80ba9ccfbe338c512,"KAFKA-16563: retry pollEvent in KRaftMigrationDriver for retriable errors (#15732)

When running ZK migrating to KRaft process, we encountered an issue that the migrating is hanging and the ZkMigrationState cannot move to MIGRATION state. And it is because the pollEvent didn't retry with the retriable MigrationClientException (ZK client retriable errors) while it should. This PR fixes it and add test. And because of this, the poll event will not poll anymore, which causes the KRaftMigrationDriver hanging.

Reviewers: Luke Chen <showuon@gmail.com>, Igor Soarez<soarez@apple.com>, Akhilesh C <akhileshchg@users.noreply.github.com>",2024-04-29 17:44:47,Luke Chen,Mixed
636e65aa6b3558a7ae239ce69579b62ab3377fcb,"KAFKA-16465: Fix consumer sys test revocation validation (#15778)

This fixes a consumer system test that was failing for the new protocol. The failure was because the test was expecting the eager behaviour of partitions being revoked on every rebalance, and it was wrongfully applying it to the runs with the new protocol too.
This same situation was previously identified and fixed in other parts of the sys test with #15661.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-04-29 11:56:36,Lianet Magrans,Mixed
e1bfaec49d57a03bb699a5ec0c17d89d200dce1b,"KAFKA-15853 Move metrics configs out of KafkaConfig  (#15822)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-30 01:19:05,Omnia Ibrahim,Mixed
81c24d6bf8a3bf2e234796964b23f0aecd7d5162,"KAFKA-15588 ConfigCommandIntegrationTest rewritten in java (#15645)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-30 01:46:08,Nikolay,Not TDD
6d436a8f989fde5458d030acb3d529964388f0ff,"KAFKA-16627 Remove ClusterConfig parameter in BeforeEach and AfterEach (#15824)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-04-30 08:40:28,Kuan-Po (Cooper) Tseng,Not TDD
7c0a302c4da9d53a8fddc504a9fac8d8afecbec8,"KAFKA-16555: Consumer's RequestState has incorrect logic to determine if inflight (#15723)

In some cases, the network layer is very fast and can process a response and send out a follow-up request within the same millisecond timestamp. This is causing problems due to the way we determine if we already have an inflight request.

The previous logic for tracking inflight status used timestamps: if the timestamp from the last received response was less than the timestamp from the last sent request, we'd interpret that as having an inflight request. However, this approach would incorrectly return false from RequestState.requestInFlight() if the two timestamps were equal.

One result of this faulty logic is that in such cases, the consumer would accidentally send multiple heartbeat requests to the consumer group coordinator. The consumer group coordinator would interpret these requests as 'join group' requests and create members for each request. Therefore, the coordinator was under the false understanding that there were more members in the group than there really were. Consequently, if your luck was really bad, the coordinator might assign partitions to one of the duplicate members. Those partitions would be assigned to a phantom consumer that was not reading any data, and this led to flaky tests.

This change introduces a stupid simple flag to RequestState that is set in onSendAttempt and cleared in onSuccessfulAttempt, onFailedAttempt, and reset. A new unit test has been added and this has been tested against all of the consumer unit and integration tests, and has removed all known occurrences of phantom consumer group members in the system tests.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>, Lianet Magrans <lianetmr@gmail.com>, Philip Nee <pnee@confluent.io>",2024-04-30 10:00:17,Kirk True,Mixed
1e8415160f96eb579ceaa3f89b3362f1deeccf6b,"MINOR: Add replayRecords to CoordinatorResult (#15818)

The patch adds a boolean attribute `replayRecords` that specifies whether the records should be replayed.

Reviewers: David Jacot <djacot@confluent.io>",2024-04-30 09:14:02,Dongnuo Lyu,Not TDD
4825c89d14e5f1b2da7e1f48dac97888602028d7,"KAFKA-16588 broker shutdown hangs when log.segment.delete.delay.ms is zero (#15773)

Instead of entering pending forever, this PR invoke next schedule after 1ms. However, the side effect is busy-waiting. Hence, This PR also update the docs to remind users about that - the issue about smaller log.segment.delete.delay.ms

Reviewers: Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-05-01 17:11:20,PoAn Yang,Mixed
89d8045a15b622805f65c3c6fbfde82606921f65,"KAFKA-16647 Remove setMetadataDirectory from BrokerNode/ControllerNode (#15833)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-02 09:04:15,Kuan-Po (Cooper) Tseng,Mixed
cdc4caa578778719684edda5dbb2f0786e67f202,"KAFKA-14588 UserScramCredentialsCommandTest rewritten in Java (#15832)


Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Igor Soarez <soarez@apple.com>",2024-05-02 10:35:10,Nikolay,Not TDD
a3f24149905886ac719901eeab8dc6d7b3c79614,"KAFKA-16624: Don't generate useless PartitionChangeRecord on older MV (#15810)

Fix a case where we could generate useless PartitionChangeRecords on metadata versions older than
3.6-IV0. This could happen in the case where we had an ISR with only one broker in it, and we were
trying to go down to a fully empty ISR. In this case, PartitionChangeBuilder would block the record
to going down to a fully empty ISR (since that is not valid in these pre-KIP-966 metadata
versions), but it would still emit the record, even though it had no effect.

Reviewers: Igor Soarez <soarez@apple.com>",2024-05-02 09:23:25,Colin Patrick McCabe,Mixed
87390f961f3bd0c582d0926cb9c4fe00d9298b6f,"KAFKA-16572 allow defining number of disks per broker in ClusterTest (#15745)

Reviewers: Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-05-03 14:24:59,PoAn Yang,Mixed
240243b91d69c2b65b5e456065fdcce90c121b04,"KAFKA-10199: Accept only one task per element in output queue for failed tasks (#15849)

Currently, the state updater writes multiple tasks per exception in the output
queue for failed tasks. To add the functionality to remove tasks synchronously
from the state updater, it is simpler that each element of the output queue for
failed tasks holds one single task.

This commit refactors the class that holds exceptions and failed tasks
in the state updater -- i.e., ExceptionAndTasks -- to just hold one single
task.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-05-03 10:52:12,Bruno Cadonna,Mixed
2c0b8b692071b6d436fa7e9dc90a1592476a6b17,"MINOR: ConsumerGroup#getOrMaybeCreateMember should not add the member to the group (#15847)

While reviewing https://github.com/apache/kafka/pull/15785, I noticed that the member is added to the group directly in `ConsumerGroup#getOrMaybeCreateMember`. This does not hurt but confuses people because the state must not be mutated at this point. It should only be mutated when records are replayed. I think that it is better to remove it in order to make it clear.

Reviewers: Dongnuo Lyu <dlyu@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-05-03 06:24:26,David Jacot,Mixed
9b8aac22ec7ce927a2ceb2bfe7afd57419ee946c,"KAFKA-16427 KafkaConsumer#position() does not respect timeout when group protocol is CONSUMER (#15843)

The AsyncKafkaConsumer implementation of position(TopicPartition, Duration) was not updating its internal Timer, causing it to execute the loop forever. Adding a call to update the Timer at the bottom of the loop fixes the issue.

An integration test was added to catch this case; it fails without the newly added call to Timer.update(long).

Reviewers: Lianet Magrans <lianetmr@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-05-04 10:29:27,Kirk True,Not TDD
bfe81d622979809325c31d549943c40f6f0f7337,"KAFKA-16207; KRaft's internal log listener to update voter set (#15671)

Adds support for the KafkaRaftClient to read the control records KRaftVersionRecord and VotersRecord in the snapshot and log. As the control records in the KRaft partition are read, the replica's known set of voters are updated. This change also contains the necessary changes to include the control records when a snapshot is generated by the KRaft state machine.

It is important to note that this commit changes the code and the in-memory state to track the sets of voters but it doesn't change any data that is externally exposed. It doesn't change the RPCs, data stored on disk or configuration.

When the KRaft replica starts the PartitionListener reads the latest snapshot and then log segments up to the LEO, updating the in-memory state as it reads KRaftVersionRecord and VotersRecord. When the replica (leader and follower) appends to the log, the PartitionListener catches up to the new LEO. When the replica truncates the log because of a diverging epoch, the PartitionListener also truncates the in-memory state to the new LEO. When the state machine generate a new snapshot the PartitionListener trims any prefix entries that are not needed. This is all done to minimize the amount of data tracked in-memory and to make sure that it matches the state on disk.

To implement the functionality described above this commit also makes the following changes:

Adds control records for KRaftVersionRecord and VotersRecord. KRaftVersionRecord describes the finalized kraft.version supported by all of the replicas. VotersRecords describes the set of voters at a specific offset.

Changes Kafka's feature version to support 0 as the smallest valid value. This is needed because the default value for kraft.version is 0.

Refactors FileRawSnapshotWriter so that it doesn't directly call the onSnapshotFrozen callback. It adds NotifyingRawSnapshotWriter for calling such callbacks. This reorganization is needed because in this change both the KafkaMetadataLog and the KafkaRaftClient need to react to snapshots getting frozen.

Cleans up KafkaRaftClient's initialization. Removes initialize from RaftClient - this is an implementation detail that doesn't need to be exposed in the interface. Removes RaftConfig.AddressSpec and simplifies the bootstrapping of the static voter's address. The bootstrapping of the address is delayed because of tests. We should be able to simplify this further in future commits.

Update the DumpLogSegment CLI to support the new control records KRaftVersionRecord and VotersRecord.

Fix the RecordsSnapshotReader implementations so that the iterator includes control records. RecordsIterator is extended to support reading the new control records.
Improve the BatchAccumulator implementation to allow multiple control records in one control batch. This is needed so that KRaft can make sure that VotersRecord is included in the same batch as the control record (KRaftVersionRecord) that upgrades the kraft.version to 1.

Add a History interface and default implementation TreeMapHistory. This is used to track all of the sets of voters between the latest snapshot and the LEO. This is needed so that KafkaRaftClient can query for the latest set of voters and so that KafkaRaftClient can include the correct set of voters when the state machine generates a new snapshot at a given offset.

Add a builder pattern for RecordsSnapshotWriter. The new builder pattern also implements including the KRaftVersionRecord and VotersRecord control records in the snapshot as necessary. A KRaftVersionRecord should be appended if the kraft.version is greater than 0 at the snapshot's offset. Similarly, a VotersRecord should be appended to the snapshot with the latest value up to the snapshot's offset.

Reviewers: Jason Gustafson <jason@confluent.io>",2024-05-04 12:43:16,José Armando García Sancio,Mixed
970ac0788122e3163c34e54a8e0510ab66329cc4,"KAFKA-16659 KafkaConsumer#position() does not respect wakup when group protocol is CONSUMER (#15853)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-06 08:45:11,PoAn Yang,Not TDD
55a00be4e973f3f4c8869b6f70de1e285719e890,"MINOR: Replaced Utils.join() with JDK API. (#15823)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-06 15:13:01,Chia Chuan Yu,Mixed
366aeab488c996e5012c2934996c4370637e6d5f,"KAFKA-10199: Add remove operation with future to state updater (#15852)

Adds a remove operation to the state updater that returns a future
instead of adding the removed tasks to an output queue. Code that
uses the state updater can then wait on the future.

Reviewer: Lucas Brutschy <lbrutschy@confluent.io>",2024-05-06 11:27:40,Bruno Cadonna,Mixed
6a8977e2125039fdeb276e53ac52b70a2fa488cb,"KAFKA-14588 [3/N] ConfigCommandTest rewritten in java (#15850)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-06 18:44:34,Nikolay,Mixed
5c96ad61d95245c1333ecdb65562d421a1186c5b,"KAFKA-16393 read/write sequence of buffers correctly (#15571)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-06 19:11:04,Okada Haruki,Mixed
4c4ae6e39c4e273b0267b8272230ba19a29fc77b,"KAFKA-16608 Honour interrupted thread state on KafkaConsumer.poll (#15803)

The contract of KafkaConsumer.poll(Duration) says that it throws InterruptException ""if the calling thread is interrupted before or while this function is called"". The new KafkaConsumer implementation was not doing this if the thread was interrupted before the poll was called, specifically with a very short timeout. If it ever waited for records, it did check the thread state. If it did not wait for records because of a short timeout, it did not.

Some of the log messages in the code erroneously mentioned timeouts, when they really meant interruption.

Also adds a test for this specific scenario.

Reviewers: Lianet Magrans <lianetmr@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-05-07 08:22:41,Andrew Schofield,Mixed
fe8ccbc92c2b1e75f2dddd81066b3dca0065e1cf,"KAFKA-16539 Fix IncrementalAlterConfigs during ZK migration (#15744)

This patch fixes two issues with IncrementalAlterConfigs and the ZK migration. First, it changes the handling of IncrementalAlterConfigs to check if the controller is ZK vs KRaft and only forward for KRaft. Second, it adds a check in KafkaZkClient#setOrCreateEntityConfigs to ensure a ZK broker is not directly modifying configs in ZK if there is a KRaft controller. This closes the race condition between KRaft taking over as the active controller and the ZK brokers learning about this.

*Forwarding*

During the ZK migration, there is a time when the ZK brokers are running with migrations enabled, but KRaft has yet to take over as the controller. Prior to KRaft taking over as the controller, the ZK brokers in migration mode were unconditionally forwarding IncrementalAlterConfigs (IAC) to the ZK controller. This works for some config types, but breaks when setting BROKER and BROKER_LOGGER configs for a specific broker. The behavior in KafkaApis for IAC was to always forward if the forwarding manager was defined. Since ZK brokers in migration mode have forwarding enabled, the forwarding would happen, and the special logic for BROKER and BROKER_LOGGER would be missed, causing the request to fail.

With this fix, the IAC handler will check if the controller is KRaft or ZK and only forward for KRaft.

*Protected ZK Writes*

As part of KIP-500, we moved most (but not all) ZK mutations to the ZK controller. One of the things we did not move fully to the controller was entity configs. This is because there was some special logic that needed to run on the broker for certain config updates. If a broker-specific config was set, AdminClient would route the request to the proper broker. In KRaft, we have a different mechanism for handling broker-specific config updates.

Leaving this ZK update on the broker side would be okay if we were guarding writes on the controller epoch, but it turns out KafkaZkClient#setOrCreateEntityConfigs does unprotected ""last writer wins"" updates to ZK. This means a ZK broker could update the contents of ZK after the metadata had been migrated to KRaft. No good! To fix this, this patch adds a check on the controller epoch to KafkaZkClient#setOrCreateEntityConfigs but also adds logic to fail the update if the controller is a KRaft controller.

The new logic in setOrCreateEntityConfigs adds STALE_CONTROLLER_EPOCH as a new exception that can be thrown while updating configs.

Reviewers:  Luke Chen <showuon@gmail.com>, Akhilesh Chaganti <akhileshchg@users.noreply.github.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-05-07 08:29:57,David Arthur,Mixed
0df340d64d3eddf4a7b57057274fb6807f366f43,"KAFKA-16470 kafka-dump-log --offsets-decoder should support new records (#15652)

When the consumer group protocol is used in a cluster, it is, at the moment, impossible to see all records stored in the __consumer_offsets topic with kafka-dump-log --offsets-decoder. It does not know how to handle all the new records.

This patch refactors the OffsetsMessageParser used internally by kafka-dump-log to use the RecordSerde used by the new group coordinator. It ensures that the tool is always in sync with the coordinator implementation. The patch also changes the format to using the toString'ed representations of the records instead of having custom logic to dump them. It ensures that all the information is always dumped. The downside of the latest is that inner byte arrays (e.g. assignment in the classic protocol) are no longer deserialized. Personally, I feel like that it is acceptable and it is actually better to stay as close as possible to the actual records in this tool. It also avoids issues like https://issues.apache.org/jira/browse/KAFKA-15603.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-07 08:49:31,David Jacot,Mixed
0de3b7c40b0c15d3193de3d152f8993e0058009c,"KAFKA-16593 Rewrite DeleteConsumerGroupsTest by ClusterTestExtensions (#15766)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-07 14:04:32,"TingIāu ""Ting"" Kì",Not TDD
459eaec666c54020fc859174004806ff4ee5cef3,"KAFKA-16615; JoinGroup API for upgrading ConsumerGroup (#15798)

The patch implements JoinGroup API for the new consumer groups. It allow members using the classic rebalance protocol with the consumer embedded protocol to join a new consumer group.

Reviewers: David Jacot <djacot@confluent.io>",2024-05-06 23:59:10,Dongnuo Lyu,Mixed
ea485a7061146976566004159e6d3a7582e03d13,"KAFKA-16665: Allow to initialize newly assigned partition's positions without allowing fetching while callback runs (#15856)

Fix to allow to initialize positions for newly assigned partitions, while the onPartitionsAssigned callback is running, even though the partitions remain non-fetchable until the callback completes.

Before this PR, we were not allowing initialization or fetching while the callback was running. The fix here only allows to initialize the newly assigned partition position, and keeps the existing logic for making sure that the partition remains non-fetchable until the callback completes.

The need for this fix came out in one of the connect system tests, that attempts to retrieve a newly assigned partition position with a call to consumer.position from within the onPartitionsAssigned callback (WorkerSinkTask). With this PR, we allow to make such calls (test added), which is the behaviour of the legacy consumer.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-05-07 10:40:00,Lianet Magrans,Mixed
cb35ddc5ca233d5cca6f51c1c41b952a7e9fe1a0,"KAFKA-10199: Remove lost tasks in state updater with new remove (#15870)

Uses the new remove operation of the state updater that returns a future to remove lost tasks from the state udpater.

Reviewer: Lucas Brutschy <lbrutschy@confluent.io>",2024-05-07 14:26:23,Bruno Cadonna,Mixed
21bf715622e9d05984fa8a2a1f9f12d54b76ce41,"KAFKA-16307; Fix coordinator thread idle ratio (#15835)

This PR fixes the thread idle ratio. We take a similar approach to the kafka request handler idle ratio: https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/server/KafkaRequestHandler.scala#L108-L117

Instead of calculating the actual ratio per thread, we record the time each thread stays idle while waiting for a new event, divided by the number of threads as an approximation.

Reviewers: David Jacot <djacot@confluent.io>",2024-05-07 06:21:09,Jeff Kim,Mixed
05df10449eb9c95fe6d6055b302c84686be8058d,"KAFKA-13328, KAFKA-13329 (2): Add custom preflight validation support for connector header, key, and value converters (#14309)

Reviewers:  Greg Harris <greg.harris@aiven.io>",2024-05-07 11:30:57,Chris Egerton,Not TDD
a4c6cefd10f3db206c17b69fac5bab71521f28f9,"KAFKA-14226: Introduce FieldPath abstraction and nested path support for ExtractField SMT (#15379)

Reviewers: Chris Egerton <chrise@aiven.io>",2024-05-07 14:07:18,Jorge Esteban Quilcate Otoya,Mixed
525b9b1d7682ae2a527ceca83fedca44b1cba11a,"KAFKA-15018: Write connector tombstone offsets to secondary store before primary store (#13801)

Reviewers: Chris Egerton <chrise@aiven.io>",2024-05-07 14:29:02,vamossagar12,Mixed
8655094e6c991cc4b40c5e3721ae4a9d69adc843,"KAFKA-16511: Fix the leaking tiered segments during segment deletion (#15817)

When there are overlapping segments in the remote storage, then the deletion may fail to remove the segments due to isRemoteSegmentWithinLeaderEpochs check. Once the deletion starts to fail for a partition, then segments won't be eligible for cleanup. The one workaround that we have is to move the log-start-offset using the kafka-delete-records script.

Reviewers: Luke Chen <showuon@gmail.com>, Satish Duggana <satishd@apache.org>",2024-05-08 15:21:23,Kamal Chandraprakash,Mixed
f7b242f94e8de91af81dc805e8f8a9fb3f59056f,"KAFKA-10199: Revoke tasks from state updater with new remove  (#15871)

Uses the new remove operation of the state updater that returns
a future to remove revoked tasks from the state updater.

Reviewer: Lucas Brutschy <lbrutschy@confluent.io>",2024-05-08 09:53:58,Bruno Cadonna,Mixed
f74f596bc7d35fcea97edcd83244e5d6aee308d2,"KAFKA-16640 Replace TestUtils#resource by scala.util.Using (#15881)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-08 15:56:27,"TingIāu ""Ting"" Kì",Not TDD
c64a315fd554809e3a5274a136ce0e3ec210dea9,"MINOR: Made the supportedOperation variable name more verbose (#15892)

As a part of https://github.com/apache/kafka/commit/2e8d69b78ca52196decd851c8520798aa856c073, we had introduced the TransactionAbortableException in AK. On more detailed analysis we figured out that the enum SupportedOperation was a bit misleading. Hence updated the same to TransactionSupportedOperation to allow a better and more defined function signature

Reviewers: Justine Olshan <jolshan@confluent.io>",2024-05-08 10:14:12,Sanskar Jhajharia,Mixed
5a9ccb6b7733a910b2f3a6a9433fd09cfef394c1,"KAFKA-16445: Add PATCH method for connector config (#6934)

Reviewers: Chris Egerton <chrise@aiven.io>",2024-05-09 21:59:09,Ivan Yurchenko,Mixed
7e9ab4b2c6851c55fcfb59bf28dcbc9190f2a459,"KAFKA-16484 Support to define per broker/controller property by ClusterConfigProperty (#15715)

Introduce a new field id in annotation ClusterConfigProperty. The main purpose of new field is to define specific broker/controller(kraft) property. And the default value is -1 which means the ClusterConfigProperty will apply to all broker/controller.

Note that under Type.KRAFT mode, the controller id starts from 3000, and then increments by one each time. Other modes the broker/controller id starts from 0 and then increments by one.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-10 10:31:45,Kuan-Po (Cooper) Tseng,Mixed
4e4f7d3231b32ad702f74fd0a05eb7f597366391,"KAFKA-15804: Close SocketServer channels when calling shutdown before enableRequestProcessing (#14729)

Signed-off-by: Greg Harris <greg.harris@aiven.io>
Reviewers: Chris Egerton <chrise@aiven.io>, hudeqi <1217150961@qq.com>, Qichao Chu <qichao@uber.com>",2024-05-10 13:56:50,Greg Harris,Mixed
ef7b48e66ab72ff6030299e191c6949d44d17c8f,"Allowing WriteTxnMarkers API to run with AlterCluster permissions (#15837)

https://issues.apache.org/jira/browse/KAFKA-16513

https://cwiki.apache.org/confluence/display/KAFKA/KIP-1037%3A+Allow+WriteTxnMarkers+API+with+Alter+Cluster+Permission

Reviewers: Christo Lolov <christo_lolov@yahoo.com>,  Luke Chen <showuon@gmail.com>, Justine Olshan <jolshan@confluent.io>",2024-05-10 15:30:57,Sid Yagnik,Mixed
4dff60df678c12c71c66a2e7a5c2a5b3f99921b8,"MINOR: fix LogValidatorTest#checkNonCompressed (#15904)

Reviewers: Jun Rao <junrao@apache.org>",2024-05-11 09:50:52,Chia-Ping Tsai,Not TDD
47841e0bb96321e2399f15e5522ef38d14612600,"KAFKA-9401 Reduce contention for Fetch requests (#15836)

KIP-227 introduced in-memory caching of FetchSessions. Brokers with a large number of Fetch requests suffer from contention on trying to acquire a lock on FetchSessionCache.

This change aims to reduce lock contention for FetchSessionCache by sharding the cache into multiple segments, each responsible for an equal range of sessionIds. Assuming Fetch requests have a uniform distribution of sessionIds, the probability of contention on a segment is reduced by a factor of the number of segments.

We ensure backwards compatibility by ensuring total number of cache entries remain the same as configured and sessionIds are randomly allocated.

Reviewers: Igor Soarez <soarez@apple.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-05-11 23:19:59,Gaurav Narula,Mixed
334d5d58bb73ca04d04be90dec8c4e49000577ec,"KAFKA-16677 Replace ClusterType#ALL and ClusterType#DEFAULT by Array (#15897)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-13 14:24:59,PoAn Yang,Mixed
8a9dd2beda90f04180e71b406657d9da388d359e,"KAFKA-16663; Cancel write timeout TimerTask on successful event completion (#15902)

Write events create and add a TimerTask to schedule the timeout operation. The issue is that we pile up the number of timer tasks which are essentially no-ops if replication was successful. They stay in memory for 15 seconds (default write timeout) and as the rate of write increases, the impact on memory usage increases.

Instead, cancel the corresponding write timeout task when the write event is committed to the log. This also applies to complete transaction events.

Reviewers: David Jacot <djacot@confluent.io>",2024-05-13 00:18:32,Jeff Kim,Mixed
cfffe4e2e855d9e05955823f687a83de59fe1732,"KAFKA-10199: Handle assignment with new remove operation in state updater (#15882)

Uses the new remove operation of the state updater that returns
a future to handle task assignment.

Reviewer: Lucas Brutschy <lbrutschy@confluent.io>",2024-05-13 11:12:30,Bruno Cadonna,Mixed
ee16eee5debe653b005afc5a3f4e0bf5486b09b0,"KAFKA-16587: Add subscription model information to group state (#15785)

This patch introduces the SubscriptionType to the group state and passes it along to the partition assignor. A group is ""homogeneous"" when all the members are subscribed to the same topics; or it is ""heterogeneous"" otherwise. This mainly helps the uniform assignor because it does not have to re-compute this information to determine which algorithm to use.

trunk:
Benchmark                                       (assignmentType)  (assignorType)  (isRackAware)  (memberCount)  (partitionsToMemberRatio)  (subscriptionModel)  (topicCount)  Mode  Cnt    Score    Error  Units
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false            100                         10          HOMOGENEOUS           100  avgt    5    0.136 ±  0.001  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false            100                         10          HOMOGENEOUS          1000  avgt    5    0.198 ±  0.002  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false           1000                         10          HOMOGENEOUS           100  avgt    5    1.767 ±  0.138  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false           1000                         10          HOMOGENEOUS          1000  avgt    5    1.540 ±  0.020  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false          10000                         10          HOMOGENEOUS           100  avgt    5   32.419 ±  7.173  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false          10000                         10          HOMOGENEOUS          1000  avgt    5   26.731 ±  1.985  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL         UNIFORM          false            100                         10          HOMOGENEOUS           100  avgt    5    0.242 ±  0.006  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL         UNIFORM          false            100                         10          HOMOGENEOUS          1000  avgt    5    1.002 ±  0.006  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL         UNIFORM          false           1000                         10          HOMOGENEOUS           100  avgt    5    2.544 ±  0.168  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL         UNIFORM          false           1000                         10          HOMOGENEOUS          1000  avgt    5   10.749 ±  0.207  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL         UNIFORM          false          10000                         10          HOMOGENEOUS           100  avgt    5   26.832 ±  0.154  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL         UNIFORM          false          10000                         10          HOMOGENEOUS          1000  avgt    5  106.209 ±  0.301  ms/op
JMH benchmarks done

patch:
Benchmark                                       (assignmentType)  (assignorType)  (isRackAware)  (memberCount)  (partitionsToMemberRatio)  (subscriptionType)  (topicCount)  Mode  Cnt   Score   Error  Units
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false            100                         10         HOMOGENEOUS           100  avgt    5   0.131 ± 0.001  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false            100                         10         HOMOGENEOUS          1000  avgt    5   0.185 ± 0.004  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false           1000                         10         HOMOGENEOUS           100  avgt    5   1.943 ± 0.091  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false           1000                         10         HOMOGENEOUS          1000  avgt    5   1.450 ± 0.139  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false          10000                         10         HOMOGENEOUS           100  avgt    5  30.803 ± 2.644  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false          10000                         10         HOMOGENEOUS          1000  avgt    5  24.251 ± 1.230  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL         UNIFORM          false            100                         10         HOMOGENEOUS           100  avgt    5   0.155 ± 0.004  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL         UNIFORM          false            100                         10         HOMOGENEOUS          1000  avgt    5   0.235 ± 0.010  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL         UNIFORM          false           1000                         10         HOMOGENEOUS           100  avgt    5   1.602 ± 0.046  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL         UNIFORM          false           1000                         10         HOMOGENEOUS          1000  avgt    5   1.901 ± 0.174  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL         UNIFORM          false          10000                         10         HOMOGENEOUS           100  avgt    5  16.098 ± 1.905  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL         UNIFORM          false          10000                         10         HOMOGENEOUS          1000  avgt    5  17.681 ± 0.174  ms/op
JMH benchmarks done

Reviewers: David Jacot <djacot@confluent.io>",2024-05-13 02:19:05,Ritika Reddy,Mixed
576facfdf220c05a70cd3e7f3dc59e1036c60636,"KAFKA-16696 Removed the in-memory implementation of RSM and RLMM (#15911)

Reviewers: Satish Duggana <satishd@apache.org>, Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-05-13 19:26:49,Kamal Chandraprakash,Mixed
6161fd0db28281cd7cf2ac6392d4a5a7dc766234,"KAFKA-14588 [2/N] ConfigCommandTest rewritten in java (#15873)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-13 19:45:28,Nikolay,Mixed
5439914c32fa00d634efa7219699f1bc21add839,"KAFKA-10199: Shutdown with new remove operation in state updater (#15894)

Uses the new remove operation of the state updater that returns
a future to shutdown the task manager.

Reviewer: Lucas Brutschy <lbrutschy@confluent.io>",2024-05-13 14:33:58,Bruno Cadonna,Mixed
f9169b7d3a91fbb229517ba0a19d10edd23233c8,"KAFKA-16735; Deprecate offsets.commit.required.acks (#15931)

This patch deprecates `offsets.commit.required.acks` in Apache Kafka 3.8 as described in KIP-1041: https://cwiki.apache.org/confluence/x/9YobEg.

Reviewers: Justine Olshan <jolshan@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-05-13 11:30:34,David Jacot,Not TDD
e18f61ce46ae677fde75a9b93c334e48b491482b,"KAFKA-16695: Improve expired poll logging (#15909)

Improve consumer log for expired poll timer, by showing how much time was the max.poll.interval.ms exceeded. This should be helpful in guiding the user to tune that config on the common case of long-running processing causing the consumer to leave the group. Inspired by other clients that log such information on the same situation.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Matthias Sax <mjsax@apache.org>, 
Andrew Schofield <andrew_schofield@live.com>, Kirk True <kirk@kirktrue.pro>",2024-05-13 18:04:54,Lianet Magrans,Mixed
ccd83cafea6957fe61a07cf306b5cb1b92ed4523,"KAFKA-16694; Remove Rack Awareness Code from the Server Side Assignors (#15903)

Reviewers: David Jacot <djacot@confluent.io>",2024-05-14 00:13:35,Ritika Reddy,Mixed
0587a9af3d3dec4859475dcf48463083647c1eb9,"MINOR: Various cleanups in clients tests (#15877)


Reviewers: Chia-Ping Tsai <chia7712@gmail.com>,  Lianet Magrans <lianetmr@gmail.com>",2024-05-14 10:19:00,Mickael Maison,Mixed
8ac32d6c1942e4cea4e110520400c99359aa0d70,"KAFKA-16702 Fix producer leaks in KafkaLog4jAppenderTest (#15922)

The tests testRealProducerConfigWithSyncSendShouldNotThrowException and testRealProducerConfigWithSyncSendAndNotIgnoringExceptionsShouldThrowException create real producer instances, which are leaked when the test exits.

Instead, each test should be followed by a cleanup operation where the registered appender is removed and closed.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-14 21:53:29,Greg Harris,Mixed
440f5f6c09720bb9414524781342bbf35973c281,"MINOR; Validate at least one control record (#15912)

Validate that a control batch in the batch accumulator has at least one control record.

Reviewers: Jun Rao <junrao@apache.org>, Chia-Ping Tsai <chia7712@apache.org>",2024-05-14 10:02:29,José Armando García Sancio,Mixed
57d30d3450998465177f92516a41218dbe8d4340,"KAFKA-16699: Have Streams treat InvalidPidMappingException like a ProducerFencedException (#15919)

KStreams is able to handle the ProducerFenced (among other errors) cleanly. It does this by closing the task dirty and triggering a rebalance amongst the worker threads to rejoin the group. The producer is also recreated. Due to how streams works (writing to and reading from various topics), the application is able to figure out the last thing the fenced producer completed and continue from there. InvalidPidMappingException should be treated the same way.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Justine Olshan <jolshan@confluent.io>",2024-05-14 11:07:55,Walker Carlson,Mixed
0e023e1f736ea03568032cc282803df8e61eb451,"MINOR: Add classic member session timeout to ClassicMemberMetadata (#15921)

The heartbeat api to the consumer group with classic protocol members schedules the session timeout. At present, there's no way to get the classic member session timeout in heartbeat to consumer group.

This patch stores the session timeout into the ClassicMemberMetadata in ConsumerGroupMemberMetadataValue and update it when it's provided in the join request.

Reviewers: David Jacot <djacot@confluent.io>",2024-05-14 20:41:20,Dongnuo Lyu,Mixed
f0291ac74b88b988c4ab07c16286942838ba4556,"KAFKA-15170: Fix rack-aware assignment in AbstractStickyAssignor  (#13965)

This PR fixes two kinds of bugs in the new(ish) rack-aware part of the sticky assignment algorithm:

First, when reassigning ""owned partitions"" to their previous owners, we now have to take the rack placement into account and might not immediately assign a previously-owned partition to its old consumer during this phase. There is a small chance this partition will be assigned to its previous owner during a later stage of the assignment, but if it's not then by definition it has been ""revoked"" and must be removed from the assignment during the adjustment phase of the CooperativeStickyAssignor according to the cooperative protocol. We need to make sure any partitions removed in this way end up in the ""partitionsTransferringOwnership"".

Second, the sticky algorithm works in part by keeping track of how many consumers are still ""unfilled"" when they are at the ""minQuota"", meaning we may need to assign one more partition to get to the expected number of consumers at the ""maxQuota"". During the rack-aware round-robin assignment phase, we were not properly clearing the set of unfilled & minQuota consumers once we reached the expected number of ""maxQuota"" consumers (since by definition that means no more minQuota consumers need to or can be given any more partitions since that would bump them up to maxQuota and exceed the expected count). This bug would result in the entire assignment being failed due to a correctness check at the end which verifies that the ""unfilled members"" set is empty before returning the assignment. An IllegalStateException would be thrown, failing the rebalancing and sending the group into an endless rebalancing loop until/unless it was lucky enough to produce a new assignment that didn't hit this bug

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2024-05-14 17:06:05,flashmouse,Mixed
0c5e8d396601c06faab174b582ef6ffc17b560f8,"KAFKA-15045: (KIP-924 pt. 2) Implement ApplicationState and KafkaStreamsState (#15920)

This PR implements read-only container classes for ApplicationState and KafkaStreamsState, and initializes those within StreamsPartitionAssignor#assign.

New internal methods were also added to the ClientState to easily pass this data through to the KafkaStreamsState.

One test was added to check the lag sorting within the implementation of KafkaStreamsState, which is the counterpart to the test that existed for the ClientState class.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2024-05-14 17:29:54,Antoine Pourchet,Mixed
eb5559a40e6cd07626cf77890326547e18f09613,"KAFKA-16686 Wait for given offset in TopicBasedRemoteLogMetadataManagerTest (#15885)

Some tests in TopicBasedRemoteLogMetadataManagerTest flake because waitUntilConsumerCatchesUp may break early before consumer manager has caught up with all the events.

This PR adds an expected offsets for leader/follower metadataOffset partitions and ensures we wait for the offset to be at least equal to the argument to avoid flakyness.

Reviewers: Satish Duggana <satishd@apache.org>, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-05-15 12:59:38,Gaurav Narula,Mixed
bf88013a2812cab65bc70667e451e0a15d26b73c,"MINOR: Rename `Record` to `CoordinatorRecord` (#15949)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-15 13:57:19,David Jacot,Mixed
d2e6c8663266c7afde30e7ef69d78443cb07634d,"KAFKA-10199: Remove queue-based remove from state updater (#15896)

Removes the unused remove operation from the state updater
that asynchronously removed tasks and put them into an
output queue.

Reviewer: Lucas Brutschy <lbrutschy@confluent.io>",2024-05-15 09:48:33,Bruno Cadonna,Mixed
3f8d11f047bf2f388fee7e8b5ddb359b47cee554,"KAFKA-16577: New consumer fails with stop within allotted timeout in consumer_test.py system test (#15784)

The KafkaAsyncConsumer would occasionally fail to stop when wakeup() was invoked. It turns out that there's a race condition between the thread that invokes wakeup() and the thread that is performing an action on the consumer. If the operation's Future is already completed by thread A when thread B invoke's completeExceptionally() inside wakeup(), the WakeupException will be ignored. We should use the return value from completeExceptionally() to determine if that call actually triggered completion of the Future. If that method returns false, that signals that the Future was already completed, and the exception we passed to completeExceptionally() was ignored. Therefore, we then need to return a new WakeupFuture instead of null so that the next call to setActiveTask() will throw the WakeupException.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-05-15 11:14:31,Kirk True,Mixed
bb3ff0f84a0a4c6d213fbe50eb2c3d3a8cdecdf0,"KAFKA-16759: Handle telemetry push response while terminating (#15957)

When client telemetry is configured in a cluster, Kafka producers and consumers push metrics to the brokers periodically. There is a special push of metrics that occurs when the client is terminating. A state machine in the client telemetry reporter controls its behaviour in different states.

Sometimes, when a client was terminating, it was attempting an invalid state transition from TERMINATING_PUSH_IN_PROGRESS to PUSH_NEEDED when it receives a response to a PushTelemetry RPC. This was essentially harmless because the state transition did not occur but it did cause unsightly log lines to be generated. This PR performs a check for the terminating states when receiving the response and simply remains in the current state.

I added a test to validate the state management in this case. Actually, the test passes before the code change in the PR, but with unsightly log lines.


Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>,  Apoorv Mittal <amittal@confluent.io>",2024-05-15 21:40:34,Andrew Schofield,Mixed
ba19eedb90fc3a3efc97714e3ea125647338fc66,"KAFKA-7342: Migrate tests in remaining packages in o.a.k.streams (#15963)

Migrates tests in the following packages (excluding subpackages)
to JUnit 5:
- org.apache.kafka.streams.internals
- org.apache.kafka.streams.kstream
- org.apache.kafka.streams.processor
- org.apache.kafka.streams.query
- org.apache.kafka.streams.state
- org.apache.kafka.streams.tests
- org.apache.kafka.streams.utils

Reviewer: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-15 20:28:34,Bruno Cadonna,Mixed
a1c2c68db11ed7e4d21e8cf88f9b1935c6ef787f,"KAFKA-16712 Fix race in TopicBasedRemoteLogMetadataManagerMultipleSubscriptionsTest (#15962)

TopicBasedRemoteLogMetadataManagerMultipleSubscriptionsTest has a race when it sets RemoteLogMetadataTopicPartitioner using the setter.

This change fixes the race condition by passing the RemoteLogMetadataTopicPartitioner instance in a Function<Integer, RemoteLogMetaedataTopicPartitioner> which is used in configure() in TopicBasedRemoteLogMetadataManager.

It also improves the waitingFor condition by spying on RemotePartitionMetadataStore and awaiting on Phasers to ensure ConsumerManager makes progress before performing assertions.

Reviewers: Kamal Chandraprakash <kamal.chandraprakash@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-05-16 14:56:06,Gaurav Narula,Not TDD
5da4b238d68321ca71cf9cb89b54be16f435aceb,"MINOR: Remove unused method in ToolsUtils (#15967)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-16 15:40:50,Mickael Maison,Mixed
dac569b9671b13525492d6950a5b759850ccd75d,"KAFKA-16668 Add tags support in ClusterTestExtension  (#15861)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-16 18:02:13,Johnny Hsu,Mixed
7b1fe33d01cb3de9f457a7e4d711eacb7c8f1c4a,"KAFKA-14588 [3/N] ConfigCommandTest rewritten in java (#15930)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-16 18:06:59,Nikolay,Mixed
2c51594607616c4b8a0c350040fd6bec64e26acd,"MINOR: rewrite TopicBasedRemoteLogMetadataManagerTest by ClusterTestExtensions (#15917)

Reviewers: Kamal Chandraprakash <kamal.chandraprakash@gmail.com>, Luke Chen <showuon@gmail.com>",2024-05-16 21:26:08,Chia-Ping Tsai,Mixed
056d232f4e28bf8e67e00f8ed2c103fdb0f3b78e,"KAFKA-16526; Quorum state data version 1 (#15859)

Allow KRaft replicas to read and write version 0 and 1 of the quorum-state file. Which version is written is controlled by the kraft.version. With kraft.version 0, version 0 of the quorum-state file is written. With kraft.version 1, version 1 of the quorum-state file is written. Version 1 of the quorum-state file adds the VotedDirectoryId field and removes the CurrentVoters. The other fields removed in version 1 are not important as they were not overwritten or used by KRaft.

In kraft.version 1 the set of voters will be stored in the kraft partition log segments and snapshots.

To implement this feature the following changes were made to KRaft.

FileBasedStateStore was renamed to FileQuorumStateStore to better match the name of the implemented interface QuorumStateStore.

The QuorumStateStore::writeElectionState was extended to include the kraft.version. This version is used to determine which version of QuorumStateData to store. When writing version 0 the VotedDirectoryId is not persisted but the latest value is kept in-memory. This allows the replica to vote consistently while they stay online. If a replica restarts in the middle of an election it will forget the VotedDirectoryId if the kraft.version is 0. This should be rare in practice and should only happen if there is an election and failure while the system is upgrading to kraft.version 1.

The type ElectionState, the interface EpochState and all of the implementations of EpochState (VotedState, UnattachedState, FollowerState, ResignedState, CandidateState and LeaderState) are extended to support the new voted directory id.

The type QuorumState is changed so that local directory id is used. The type is also changed so that the latest value for the set of voters and the kraft version is query from the KRaftControlRecordStateMachine.

The replica directory id is read from the meta.properties and passed to the KafkaRaftClient. The replica directory id is guaranteed to be set in the local replica.

Adds a new metric for current-vote-directory-id which exposes the latest in-memory value of the voted directory id.

Renames VoterSet.VoterKey to ReplicaKey.

It is important to note that after this change, version 1 of the quorum-state file will not be written by kraft controllers and brokers. This change adds support reading and writing version 1 of the file in preparation for future changes.

Reviewers: Jun Rao <junrao@apache.org>",2024-05-16 09:53:36,José Armando García Sancio,Mixed
fafa3c76dc93f3258b2cea49dfd1dc7a724a213c,"KAFKA-15045: (KIP-924 pt. 4) Generify rack graph solving utilities (#15956)

The graph solving utilities are currently hardcoded to work with ClientState, but don't actually depend on anything in those state classes.

This change allows the MinTrafficGraphConstructor and BalanceSubtopologyGraphConstructor to be reused with KafkaStreamsStates instead.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Almog Gavra <almog@responsive.dev>",2024-05-16 11:37:59,Antoine Pourchet,Mixed
f9db4fa19cce975a6bbaeb09fbe9c91b81846b5a,"KAFKA-16787: Remove TRACE level logging from AsyncKafkaConsumer hot path (#15981)

Removed unnecessarily verbose logging.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-05-17 08:57:23,Kirk True,Not TDD
b8c96389b47df0dbd53fcba9404363dcdf43604d,"KAFKA-16762: SyncGroup API for upgrading ConsumerGroup (#15954)

This patch implements the sync group api for the consumer groups that are in the mixed mode. In classicGroupSyncToConsumerGroup, the assignedPartitions calculated in the JoinGroup will be returned as the assignment in the sync response and the member session timeout will be rescheduled.

Reviewers: David Jacot <djacot@confluent.io>",2024-05-17 07:12:40,Dongnuo Lyu,Mixed
7fea279ff99a3ba9fc974946d4e9705d512337b1,"KAFKA-16763 Upgrade to scala 2.12.19 and scala 2.13.14 (#15958)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-18 00:36:38,Ken Huang,Not TDD
69fc4c5da419cb6e0b812c512046675458332977,"MINOR: Migrate tests in o.a.k.streams to JUnit 5 (except KafkaStreamsTest) (#15942)

Reviewers: Christo Lolov <lolovc@amazon.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-05-18 03:31:05,Bruno Cadonna,Not TDD
92489995f3e99919386adae8ad283e8eab322b27,"KAFKA-16544 DescribeTopicsResult#allTopicIds and DescribeTopicsResult#allTopicNames should return null instead of throwing NPE (#15979)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-18 03:41:10,Kuan-Po (Cooper) Tseng,Mixed
6aac009a2dc6912160ec02c0eac86597d68e8e50,"MINOR: Remove deprecated constructors from Connect's Kafka*BackingStore classes (#15865)

- These constructors were deprecated over 3 years ago in KAFKA-10021: Changed Kafka backing stores to use shared admin client to get end offsets and create topics #9780.
- While these classes are not a part of Connect's public API, deprecation was still introduced instead of outright removal because they are useful utility classes that might've been used outside of Connect.
- The KafkaOffsetBackingStore's deprecated constructor was removed in KAFKA-14785: Connect offset read REST API #13434.
- This patch removes the deprecated constructors for KafkaConfigBackingStore and KafkaStatusBackingStore.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-18 04:09:30,Yash Mayya,Mixed
3e15ab98ec66257af4cbe1f2edc7dbcf8cc792f0,"KAFKA-16992: InvalidRequestException: ADD_PARTITIONS_TO_TXN with version 4 which is not enabled when upgrading from kafka (#15971)

We weren't enabling discoverBrokerVersions to check the supported versions in the AddPartitionsToTxnManager. This means that any verification request (or any AddPartitionsToTxnRequest version) from a newer broker would fail when sending to an older broker.

The bulk of this change is adding additional transactions system tests for old versions.
One test upgrades the cluster completely. This didn't catch the issue but could be useful.

The other test forces a new broker to send a verification request to an older one. Without the discoverBrokerVersions change, all tests between mixed brokers failed. (We introduced a new request version in 3.8 -- which is a separate version from the one that caused the bug for 3.5 -> 3.6) With the addition, the tests all passed.

I also manually ran a test for 3.5 -> 3.6 since the issue there was slightly different and was caused by the unstableLatestVersion flag being enabled. This change should fix this as well. 👍

Reviewers:  David Jacot <djacot@confluent.io>",2024-05-17 21:35:28,Justine Olshan,Mixed
412b05df001df399a873b74093e26b1f6f70ef44,"KAFKA-16789 Fix thread leak detection for event handler threads (#15984)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-19 18:21:56,Gaurav Narula,Mixed
476d323f5a6e3d811f94a5d859cdc364e4bc479b,"KAFKA-16197: Print Connect worker specific logs on poll timeout expiry (#15305)

Reviewers: Luke Chen <showuon@gmail.com>, Greg Harris <greg.harris@aiven.io>",2024-05-20 17:00:04,vamossagar12,Mixed
b4c2d6680141d8ed2057bd9208cfad96cbdb99e6,"KAFKA-16770; [1/N] Coalesce records into bigger batches (#15964)

We have discovered during large scale performance tests that the current write path of the new coordinator does not scale well. The issue is that each write operation writes synchronously from the coordinator threads. Coalescing records into bigger batches helps drastically because it amortizes the cost of writes. Aligning the batches with the snapshots of the timelines data structures also reduces the number of in-flight snapshots.

This patch is the first of a series of patches that will bring records coalescing into the coordinator runtime. As a first step, we had to rework the PartitionWriter interface and move the logic to build MemoryRecords from it to the CoordinatorRuntime. The main changes are in these two classes. The others are related mechanical changes.

Reviewers: Justine Olshan <jolshan@confluent.io>",2024-05-20 23:47:09,David Jacot,Mixed
c10bb58d1c963049a0d407d3825a470685052cbd,"KAFKA-14588 [4/N] ConfigCommandTest rewritten in java (#15839)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-21 16:39:39,Nikolay,Mixed
b5a013e4564ad93026b9c61431e4573a39bec766,"KAFKA-16513; Add test for WriteTxnMarkers with AlterCluster permission

In #15837, we introduced the change to allow calling the WriteTxnMarkers API with AlterCluster permissions. This PR proposes 2 enhancements:

- When a WriteTxnMarkers request is received, it is first authorized against the alter cluster permission. If the user does not have this permission, a 'deny' will be logged. However, if the user does have the cluster action permission, the request will be successfully authorized.  Don't log the first deny to avoid confusion.
- Add a `WriteTxnMarkersRequest` to be called from the test `testAuthorizationWithTopicExisting`, so that the request can be exercised and verified with both possible permissions.

Author: Nikhil Ramakrishnan <nikrmk@amazon.com>

Reviewers: Christo Lolov <lolovc@amazon.com>

Closes #15952 from nikramakrishnan/kip1037-addTest",2024-05-21 10:34:28,Nikhil Ramakrishnan,Mixed
89083520efb268d8b950fbe4f41347ef4263a34f,"KAFKA-16654 Refactor kafka.test.annotation.Type and ClusterTestExtensions (#15916)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-21 22:29:06,TaiJuWu,Not TDD
affe8da54c96d4038481c3807d059134961445a3,"KAFKA-7632: Support Compression Levels (KIP-390) (#15516)


Reviewers: Jun Rao <jun@confluent.io>,  Luke Chen <showuon@gmail.com>
Co-authored-by: Lee Dongjin <dongjin@apache.org>",2024-05-21 17:58:49,Mickael Maison,Mixed
e93aae0664f9cef69b6a14d9fdeabb7e7786194d,"KAFKA-16783: Migrate RemoteLogMetadataManagerTest to new test infra (#15983)

1. Replace TopicBasedRemoteLogMetadataManagerWrapperWithHarness with RemoteLogMetadataManagerTestUtils#builder in RemoteLogMetadataManagerTest.
2. Use ClusterTestExtention for RemoteLogMetadataManagerTest.

Signed-off-by: PoAn Yang <payang@apache.org>

Reviewers: Luke Chen <showuon@gmail.com>",2024-05-22 11:28:01,PoAn Yang,Not TDD
271c04bd17677faf99cb0ec5586f7ef97e007418,"KAFKA-15444: Native docker image for Apache Kafka (KIP-974)  (#15927)

This PR aims to add Docker Image for GraalVM based Native Kafka Broker as per the following KIP - https://cwiki.apache.org/confluence/display/KAFKA/KIP-974%3A+Docker+Image+for+GraalVM+based+Native+Kafka+Broker

This PR adds the following functionalities:

Ability to build the docker image for Native Apache Kafka
   - Dockerfile
   - Launch script
   - metadata configs required by graalVM native-image: link
Add Kafka startup ability in the KafkaDockerWrapper.scala
Ability to build and test the image - integrated with the existing JVM docker image framework.",2024-05-22 10:52:46,Krishna Agarwal,Not TDD
5552f5c26df4eb07b2d6ee218e4a29e4ca790d5c,"KAFKA-15541: Add num-open-iterators metric (#15975)

Part of [KIP-989](https://cwiki.apache.org/confluence/x/9KCzDw).

This new `StateStore` metric tracks the number of `Iterator` instances
that have been created, but not yet closed (via `AutoCloseable#close()`).

This will aid users in detecting leaked iterators, which can cause major
performance problems.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2024-05-21 23:29:50,Nick Telford,Mixed
a98c9be6b00806c870c542c2a6ecbd247e2bf712,"KAFKA-15974: Enforce that event processing respects user-provided timeout (#15640)

The intention of the CompletableApplicationEvent is for a Consumer to enqueue the event and then block, waiting for it to complete. The application thread will block up to the amount of the timeout. This change introduces a consistent manner in which events are expired out by checking their timeout values.

The CompletableEventReaper is a new class that tracks CompletableEvents that are enqueued. Both the application thread and the network I/O thread maintain their own reaper instances. The application thread will track any CompletableBackgroundEvents that it receives and the network I/O thread will do the same with any CompletableApplicationEvents it receives. The application and network I/O threads will check their tracked events, and if any are expired, the reaper will invoke each event's CompletableFuture.completeExceptionally() method with a TimeoutException.

On closing the AsyncKafkaConsumer, both threads will invoke their respective reapers to cancel any unprocessed events in their queues. In this case, the reaper will invoke each event's CompletableFuture.completeExceptionally() method with a CancellationException instead of a TimeoutException to differentiate the two cases.

The overall design for the expiration mechanism is captured on the Apache wiki and the original issue (KAFKA-15848) has more background on the cause.

Note: this change only handles the event expiration and does not cover the network request expiration. That is handled in a follow-up Jira (KAFKA-16200) that builds atop this change.

This change also includes some minor refactoring of the EventProcessor and its implementations. This allows the event processor logic to focus on processing individual events rather than also the handling of batches of events.

Reviewers: Lianet Magrans <lianetmr@gmail.com>, Philip Nee <pnee@confluent.io>, Bruno Cadonna <cadonna@apache.org>",2024-05-22 18:11:10,Kirk True,Mixed
e4e1116156d44d5e7a52ad8fb51a57d5e5755710,"MINOR: Move Throttler to storage module (#16023)


Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-22 18:47:31,Mickael Maison,Mixed
ef2c5e41a5418d83cb56b71b897e8ff8ced03c68,"KAFKA-15045: (KIP-924 pt. 5) Add rack information to ApplicationState (#15972)

This rack information is required to compute rack-aware assignments, which many of the current assigners do.

The internal ClientMetadata class was also edited to pass around this rack information.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2024-05-22 13:24:26,Antoine Pourchet,Mixed
27a6c156c49e375edea0e6f33a35c64c615db1b5,"KAFKA-15045: (KIP-924 pt. 7) Simplify requirements for rack aware graphs (#16004)

Rack aware graphs don't actually need any topology information about the system, but rather require a simple ordered (not sorted) grouping of tasks.

This PR changes the internal constructors and some interface signatures of RackAwareGraphConstructor and its implementations to allow reuse by future components that may not have access to the actual subtopology information.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2024-05-22 13:25:18,Antoine Pourchet,Mixed
bef83ce89bb6a869cf884b37d5b5f86d8f243488,"KAFKA-15541: Add iterator-duration metrics (#16028)

Part of [KIP-989](https://cwiki.apache.org/confluence/x/9KCzDw).

This new `StateStore` metric tracks the average and maximum amount of
time between creating and closing Iterators.

Iterators with very high durations can indicate to users performance
problems that should be addressed.

If a store reports no data for these metrics, despite the user opening
Iterators on the store, it suggests those iterators are not being
closed, and have therefore leaked.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2024-05-22 21:34:31,Nick Telford,Mixed
e692feed34c59c71fe0277d08141e023c0d28d73,"MINOR: fix flaky testRecordThreadIdleRatio (#15987)

DelayEventAccumulator should return immediately if there are no events in the queue. Also removed some unused fields inside EventProcessorThread.

Reviewers: Gaurav Narula <gaurav_narula2@apple.com>, Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>",2024-05-22 23:24:23,Jeff Kim,Mixed
14b5c4d1e8589ff61faf855e6b64766001e06ecf,"KAFKA-16793; Heartbeat API for upgrading ConsumerGroup (#15988)

This patch implements the heartbeat api to the members that use the classic protocol in a ConsumerGroup.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, David Jacot <djacot@confluent.io>",2024-05-22 23:27:00,Dongnuo Lyu,Mixed
ab0cc72499eedd5b5da7232d4a799103d17802fd,"MINOR: Move parseCsvList to server-common (#16029)


Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-23 16:01:45,Mickael Maison,Mixed
5a4898450d0125f819f8b5ca5cce53e26ea053af,"KAFKA-15649: Handle directory failure timeout (#15697)

A broker that is unable to communicate with the controller will shut down
after the configurable log.dir.failure.timeout.ms.

The implementation adds a new event to the Kafka EventQueue. This event
is deferred by the configured timeout and will execute the shutdown
if the heartbeat communication containing the failed log dir is still
pending with the controller.

Reviewers: Igor Soarez <soarez@apple.com>",2024-05-23 16:36:39,Viktor Somogyi-Vass,Mixed
0ba15ad4d1bd7318d626430035a1666eb16f844d,"KAFKA-15905 Restarts of MirrorCheckpointTask should not permanently i… (#15910)

* KAFKA-15905 Restarts of MirrorCheckpointTask should not permanently interrupt offset translation

MirrorCheckpointTask reloads the last checkpoint at start,
OffsetSyncStore stores OffsetSyncs before reading till end.

If CheckpointTask cannot read checkpoints at startup,
use previous OffsetSyncStore load logic, with
warning log message about degraded offset translation.

Also addresses KAFKA-16622 Mirromaker2 first Checkpoint not emitted until
consumer group fully catches up once because the OffsetSyncStore store
is populated before reading to log end.

Co-Authored-By: Adrian Preston <prestona@uk.ibm.com>
Reviewers: Greg Harris <greg.harris@aiven.io>",2024-05-23 17:17:56,Edoardo Comar,Mixed
4020307ac2842a35cac8c974ec3ab90153893194,"KAFKA-16795 Fix broken compatibility in kafka.tools.NoOpMessageFormatter, kafka.tools.DefaultMessageFormatter, and kafka.tools.LoggingMessageFormatter (#16020)

This commit allows users to apply the scala version Formatters, but users will receive the warning messages about deprecation. 

This compatibility support will be removed from 4.0.0
 
Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-24 02:51:26,Kuan-Po (Cooper) Tseng,Mixed
11ad5e8bca2444d8c51cd6b81ee84dcb41a047c2,"MINOR: Refactor Values class to fix checkstyle, add benchmark, optimize exceptions (#15469)

Signed-off-by: Greg Harris <greg.harris@aiven.io>
Reviewers: Mickael Maison <mickael.maison@gmail.com>",2024-05-23 13:23:18,Greg Harris,Mixed
6941598f710e094fbb272c6f8c243d891ad5c877,"KAFKA-16826: Integrate Native Docker Image with github actions (#16045)

This PR integrates the Native docker image with the existing github action jobs for the jvm docker image of AK.

The integration is done to the following actions:

docker_build_and_test.yml: Builds the docker image and runs sanity tests and CVE scan
docker_rc_release.yml: Builds the RC docker image for both amd and arm platform and pushes it to the dockerhub.
docker_promote.yml: Promotes the RC docker image to the released image tag

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Vedarth Sharma <142404391+VedarthConfluent@users.noreply.github.com>",2024-05-24 12:16:01,Krishna Agarwal,Not TDD
520aa8665c8bad19c55d74e6b8ac14a4e17de789,"KAFKA-16626; Lazily convert subscribed topic names to topic ids (#15970)

This patch aims to remove the data structure that stores the conversion from topic names to topic ids which was taking time similar to the actual assignment computation. Instead, we reuse the already existing ConsumerGroupMember.subscribedTopicNames() and do the conversion to topic ids when the iterator is requested.

Reviewers: David Jacot <djacot@confluent.io>",2024-05-24 00:51:50,Jeff Kim,Mixed
0143c72e501afd76f89c2da9e4537be5ea11d4a0,"KAFKA-16815: Handle FencedInstanceId in HB response (#16047)

Handle FencedInstanceIdException that a consumer may receive in the heartbeat response. This will be the case when a static consumer is removed from the group by and admin client, and another member joins with the same group.instance.id (allowed in). The first member will receive a FencedInstanceId on its next heartbeat. The expectation is that this should be handled as a fatal error.

There are no actual changes in logic with this PR, given that without being handled, the FencedInstanceId was being treated as an ""unexpected error"", which are all treated as fatal errors, so the outcome remains the same. But we're introducing this small change just for accuracy in the logic and the logs: FencedInstanceId is expected during heartbeat, a log line is shown describing the situation and why it happened (and it's treated as a fatal error, just like it was before this PR).

This PR also improves the test to ensure that the error propagated to the app thread matches the one received in the HB.

Reviewers: Andrew Schofield <aschofield@confluent.io>, David Jacot <djacot@confluent.io>",2024-05-24 05:19:43,Lianet Magrans,Mixed
2432a1866e7bd270f1073cea7c9594e111aed78b,"KAFKA-16373: KIP-1028:  Adding code to support Apache Kafka Docker Official Images (#16027)

This PR aims to add JVM based Docker Official Image for Apache Kafka as per the following KIP - https://cwiki.apache.org/confluence/display/KAFKA/KIP-1028%3A+Docker+Official+Image+for+Apache+Kafka

This PR adds the following functionalities:
Introduces support for Apache Kafka Docker Official Images via:

GitHub Workflows:

- Workflow to prepare static source files for Docker images
- Workflow to build and test Docker official images
- Scripts to prepare source files and perform Docker image builds and tests

A new directory for Docker official images, named docker/docker_official_images. This is the new directory to house all Docker Official Image assets.

Co-authored-by: Vedarth Sharma <vesharma@confluent.io>

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Vedarth Sharma <vesharma@confluent.io>",2024-05-24 22:21:02,KrishVora01,Not TDD
90892ae99fb09f62197c50fedc320ecebe09baad,"KAFKA-16516: Fix the controller node provider for broker to control channel

Fix the code in the RaftControllerNodeProvider to query RaftManager to find Node information,
rather than consulting a static map. Add a RaftManager.voterNode function to supply this
information. In KRaftClusterTest, add testControllerFailover to get more coverage of controller
failovers.

Reviewers: José Armando García Sancio <jsancio@apache.org>",2024-05-24 09:52:47,Colin P. McCabe,Not TDD
d585a494a4871eaecdddf98f8655b8f30c5bd834,"KAFKA-16831: CoordinatorRuntime should initialize MemoryRecordsBuilder with max batch size write limit (#16059)

CoordinatorRuntime should initialize MemoryRecordsBuilder with max batch size write limit. Otherwise, we default the write limit to the min buffer size of 16384 for the write limit. This causes the coordinator to threw RecordTooLargeException even when it's under the 1MB max batch size limit.

Reviewers: David Jacot <djacot@confluent.io>",2024-05-24 13:33:57,Jeff Kim,Mixed
a8d166c00e6023b478a30092b1b92ded395cfc6e,"KAFKA-16625; Reverse lookup map from topic partitions to members (#15974)

This patch speeds up the computation of the unassigned partitions by exposing the inverted target assignment. It allows the assignor to check whether a partition is assigned or not.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, David Jacot <djacot@confluent.io>",2024-05-25 09:06:15,Ritika Reddy,Mixed
d9ee9c96dd5081f3b494f5fc820fb3f51328993f,"KAFKA-15541: Use LongAdder instead of AtomicInteger (#16076)

`LongAdder` performs better than `AtomicInteger` when under contention
from many threads. Since it's possible that many Interactive Query
threads could create a large number of `KeyValueIterator`s, we don't
want contention on a metric to be a performance bottleneck.

The trade-off is memory, as `LongAdder` uses more memory to space out
independent counters across different cache lines. In practice, I don't
expect this to cause too many problems, as we're only constructing 1
per-store.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2024-05-25 12:22:56,Nick Telford,Mixed
524ad1e14b1f3ff2c5eff703fdf3534092ca58fd,"KAFKA-16452: Don't throw OOORE when converting the offset to metadata (#15825)

Don't throw OFFSET_OUT_OF_RANGE error when converting the offset to metadata, and next time the leader should increment the high watermark by itself after receiving fetch requests from followers. This can happen when checkpoint files are missing and being elected as a leader. 

Reviewers: Luke Chen <showuon@gmail.com>, Jun Rao <junrao@apache.org>",2024-05-27 17:44:23,Kamal Chandraprakash,Mixed
da3304ecb6f2e41de5891ee1128a8aba7330f8bd,"KAFKA-16371; fix lingering pending commit when handling OFFSET_METADATA_TOO_LARGE (#16072)

This patch was initially created in #15536.

When there is a commit for multiple topic partitions and some, but not all, exceed the offset metadata limit, the pending commit is not properly cleaned up leading to UNSTABLE_OFFSET_COMMIT errors when trying to fetch the offsets with read_committed. This change makes it so the invalid commits are not added to the pendingOffsetCommits set.

Co-authored-by: Kyle Phelps <kyle.phelps@datadoghq.com>

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Justine Olshan <jolshan@confluent.io>",2024-05-27 08:10:37,David Jacot,Mixed
91284d8d7b38d350a63b4086d2f12918e5bc31dc,"KAFKA-16709: abortAndPauseCleaning only when future log is not existed (#15951)

When doing alter replica logDirs, we'll create a future log and pause log cleaning for the partition( here). And this log cleaning pausing will resume after alter replica logDirs completes (here). And when in the resuming log cleaning, we'll decrement 1 for the LogCleaningPaused count. Once the count reached 0, the cleaning pause is really resuming. (here). For more explanation about the logCleaningPaused state can check here.

But, there's still one factor that could increase the LogCleaningPaused count: leadership change (here). When there's a leadership change, we'll check if there's a future log in this partition, if so, we'll create future log and pauseCleaning (LogCleaningPaused count + 1). So, if during the alter replica logDirs:

1. alter replica logDirs for tp0 triggered (LogCleaningPaused count = 1)
2. tp0 leadership changed (LogCleaningPaused count = 2)
3. alter replica logDirs completes, resuming logCleaning (LogCleaningPaused count = 1)
4. LogCleaning keeps paused because the count is always >  0

This PR fixes this issue by only abortAndPauseCleaning when future log is not existed. We did the same check in alterReplicaLogDirs. So this change can make sure there's only 1 abortAndPauseCleaning for either abortAndPauseCleaning or maybeAddLogDirFetchers. Tests also added.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Igor Soarez <soarez@apple.com>",2024-05-28 12:23:34,Luke Chen,Mixed
64f699aeea681f54f9a4c973509c953c0501820d,"KAFKA-15853: Move general configs out of KafkaConfig (#16040)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-05-28 16:22:54,Omnia Ibrahim,Mixed
a649bc457faa0f4b682e831d61d27fb289659cba,"KAFKA-16711: Make sure to update highestOffsetInRemoteStorage after log dir change (#15947)

Reviewers: Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Satish Duggana <satishd@apache.org>",2024-05-28 21:35:49,Luke Chen,Mixed
4d04eb83ea2cf67484d81e30603e976f63616428,"KAFKA-16796 Introduce new org.apache.kafka.tools.api.Decoder to replace kafka.serializer.Decoder (#16064)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-29 03:13:33,PoAn Yang,Mixed
4eb60b5104c3e7a6d9d6943b18abc3c2d26bea3a,"KAFKA-16507 Add KeyDeserializationException and ValueDeserializationException with record content (#15691)

Implements KIP-1036.

Add raw ConsumerRecord data to RecordDeserialisationException to make DLQ implementation easier.

Reviewers: Kirk True <ktrue@confluent.io>, Andrew Schofield <aschofield@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2024-05-28 14:56:47,Frederik Rouleau,Mixed
59ba55514208176bd2fb6af2dbe2a2cbb7990ba4,"KAFKA-15541: Add oldest-iterator-open-since-ms metric (#16041)

Part of [KIP-989](https://cwiki.apache.org/confluence/x/9KCzDw).

This new `StateStore` metric tracks the timestamp that the oldest
surviving Iterator was created.

This timestamp should continue to climb, and closely track the current
time, as old iterators are closed and new ones created. If the timestamp
remains very low (i.e. old), that suggests an Iterator has leaked, which
should enable users to isolate the affected store.

It will report no data when there are no currently open Iterators.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2024-05-28 16:23:23,Nick Telford,Mixed
8d243dfbd415b5b34515695b72379d1489297a23,"KAFKA-15045: (KIP-924 pt. 12) Wiring in new assignment configs and logic (#16074)

This PR creates the new public config of KIP-924 in StreamsConfig and uses it to instantiate user-created TaskAssignors. If such a TaskAssignor is found and successfully created we then use that assignor to perform the task assignment, otherwise we revert back to the pre KIP-924 world with the internal task assignors.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Almog Gavra <almog@responsive.dev>",2024-05-28 18:01:18,Antoine Pourchet,Mixed
eefd114c4ac386a5cf5b425d74cd47456d8ce9c1,"KAFKA-16832; LeaveGroup API for upgrading ConsumerGroup (#16057)

This patch implements the LeaveGroup API to the consumer groups that are in the mixed mode.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, David Jacot <djacot@confluent.io>",2024-05-28 23:21:30,Dongnuo Lyu,Mixed
897cab2a614407149bbdd96697d7bc27be89505b,"KAFKA-16399: Add JBOD support in tiered storage (#15690)

After JBOD is supported in KRaft, we should also enable JBOD support in tiered storage. Unit tests and Integration tests are also added.

Reviewers: Satish Duggana <satishd@apache.org>, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>, Igor Soarez <soarez@apple.com>, Mickael Maison <mickael.maison@gmail.com>",2024-05-29 15:30:18,Luke Chen,Mixed
b73f4798a4895fa4ed0510c289c776cc06b68e7e,"KAFKA-16362: Fix type-unsafety in KStreamKStreamJoin caused by isLeftSide (#15601)

The introduced changes provide a cleaner definition of the join side in KStreamKStreamJoin. Before, this was done by using a Boolean flag, which led to returning a raw LeftOrRightValue without generic arguments because the generic type arguments depended on the boolean input.

Reviewers: Greg Harris <greg.harris@aiven.io>, Bruno Cadonna <cadonna@apache.org>",2024-05-29 13:12:54,Ramin Gharib,Mixed
2d9994e0de915037525f041ff9a9b9325f838938,"KAFKA-16722: Introduce ConsumerGroupPartitionAssignor interface (#15998)

KIP-932 introduces share groups to go alongside consumer groups. Both kinds of group use server-side assignors but it is unlikely that a single assignor class would be suitable for both. As a result, the KIP introduces specific interfaces for consumer group and share group partition assignors.

This PR introduces only the consumer group interface, `o.a.k.coordinator.group.assignor.ConsumerGroupPartitionAssignor`. The share group interface will come in a later release. The existing implementations of the general `PartitionAssignor` interface have been changed to implement `ConsumerGroupPartitionAssignor` instead and all other code changes are just propagating the change throughout the codebase.

Note that the code in the group coordinator that actually calculates assignments uses the general `PartitionAssignor` interface so that it can be used with both kinds of group, even though the assignors themselves are specific.

Reviewers: Apoorv Mittal <amittal@confluent.io>, David Jacot <djacot@confluent.io>",2024-05-29 08:31:52,Andrew Schofield,Mixed
0f0c9ecbf330923ad653cc2ff4fca6c4dced1cf7,"KAFKA-16771 First log directory printed twice when formatting storage (#16010)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-30 01:08:17,gongxuanzhang,Mixed
862ea12cd7ea0d7914a089f3181996c54412945e,"MINOR: Fix rate metric spikes (#15889)

Rate reports value in the form of sumOrCount/monitoredWindowSize. It has a bug in monitoredWindowSize calculation, which leads to spikes in result values.

Reviewers: Jun Rao <junrao@gmail.com>",2024-05-29 13:14:37,Eugene Mitskevich,Mixed
3f3f3ac155be19ae6aff7401ba643be8d5624280,"MINOR: Delete KafkaSecurityConfigs class (#16113)

Reviewers: Omnia Ibrahim <o.g.h.ibrahim@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-05-30 05:55:24,Mickael Maison,Mixed
5e3df22095fb68ebb472243aca5d2ab55df74c71,"KAFKA-16308 [1/N]: Create FeatureVersion interface and add `--feature` flag and handling to StorageTool (#15685)

As part of KIP-1022, I have created an interface for all the new features to be used when parsing the command line arguments, doing validations, getting default versions, etc.

I've also added the --feature flag to the storage tool to show how it will be used.

Created a TestFeatureVersion to show an implementation of the interface (besides MetadataVersion which is unique) and added tests using this new test feature.

I will add the unstable config and tests in a followup.

Reviewers: David Mao <dmao@confluent.io>, David Jacot <djacot@confluent.io>, Artem Livshits <alivshits@confluent.io>, Jun Rao <junrao@apache.org>",2024-05-29 16:36:06,Justine Olshan,Mixed
3d14690cbfe97dda05dc9896047e38d851076fd4,"KAFKA-16790: Update RemoteLogManager configuration in broker server (#16005)

n BrokerServer.scala, brokerMetadataPublishers are configured and when there are metadata updates remoteLogManager is not configured by then.
Ex : remoteLogManager.foreach(rlm => rlm.onLeadershipChange(partitionsBecomeLeader.asJava, partitionsBecomeFollower.asJava, topicIds)) in ReplicaManager is invoked after publishers are instantiated, and here rlm has relevant managers configured.

This change makes sure rlm is configured before the brokerMetadataPublishers initialization.

Reviewers: Luke Chen <showuon@gmail.com>, Nikhil Ramakrishnan <nikrmk@amazon.com>",2024-05-30 08:21:30,Murali Basani,Mixed
2a6078a4ce47f5974a3ac818bfe1c524fe94d232,"MINOR: Prevent consumer protocol to be used in ZK mode (#16121)

This patch disallows enabling the new consumer rebalance protocol in ZK mode.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Justine Olshan <jolshan@confluent.io>",2024-05-29 23:02:21,David Jacot,Mixed
3f70c46874e1dd9591443392f51ff1efc9fdc40e,"KAFKA-16448: Add ProcessingExceptionHandler in Streams configuration (#16092)

This PR is part of KAFKA-16448 which aims to bring a ProcessingExceptionHandler to Kafka Streams in order to deal with exceptions that occur during processing.

This PR brings ProcessingExceptionHandler in Streams configuration.

Co-authored-by: Dabz <d.gasparina@gmail.com>
Co-authored-by: sebastienviale <sebastien.viale@michelin.com>

Reviewer: Bruno Cadonna <cadonna@apache.org>",2024-05-30 10:39:38,Loïc GREFFIER,Mixed
8068a086a3f41b9f7e4d4a1dab3338f029089f23,"MINOR: Remove KafkaConfig dependency in KafkaRequestHandler (#16108)


Reviewers: Luke Chen <showuon@gmail.com>, Apoorv Mittal <amittal@confluent.io>",2024-05-30 11:51:24,Mickael Maison,Mixed
32b2b73f673ecd41d17c03e99db3746c517990c4,"KAFKA-16844: Add ByteBuffer support for Connect ByteArrayConverter (#16101)

Reviewers: Chris Egerton <chrise@aiven.io>",2024-05-30 11:26:25,Fan Yang,Mixed
fea3eeb7f7354f33042bd977802196d593f1ddad,"Revert ""KAFKA-16448: Add ProcessingExceptionHandler in Streams configuration (#16092)"" (#16141)

This reverts commit 3f70c46874e1dd9591443392f51ff1efc9fdc40e.

Reviewer: Lucas Brutschy <lbrutschy@confluent.io>",2024-05-30 17:52:07,Bruno Cadonna,Mixed
bb7db87f9883a7023b28f1150085b0914c011379,"KAFKA-15265: Add Remote Log Manager quota manager (#15625)

Added the implementation of the quota manager that will be used to throttle copy and fetch requests from the remote storage. Reference KIP-956

Reviewers: Luke Chen <showuon@gmail.com>, Kamal Chandraprakash <kchandraprakash@uber.com>, Jun Rao <junrao@gmail.com>",2024-05-30 09:06:49,Abhijeet Kumar,Mixed
bb6a042e99a3d011968a75f4e2bfb51d57637a25,"KAFKA-16827: Integrate kafka native-image with system tests (#16046)

This PR does following things

System tests should bring up Kafka broker in the native mode
System tests should run on Kafka broker in native mode
Extract out native build command so that it can be reused.
Allow system tests to run on Native Kafka broker using Docker mechanism

To run system tests by bringing up Kafka in native mode:
Pass kafka_mode as native in the ducktape globals:--globals '{\""kafka_mode\"":\""native\""}'

Running system tests by bringing up kafka in native mode via docker mechanism
_DUCKTAPE_OPTIONS=""--globals '{\""kafka_mode\"":\""native\""}'"" TC_PATHS=""tests/kafkatest/tests/""  bash tests/docker/run_tests.sh

To only bring up ducker nodes to cater native kafka
bash tests/docker/ducker-ak up -m native

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2024-05-30 22:24:23,Krishna Agarwal,Not TDD
e974914ca52509a2396e3939a6db6a4e9f9c7dfa,"MINOR: Code Cleanup - Connect Module (#16066)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-31 04:55:00,Sanskar Jhajharia,Mixed
a8e99eb969539bd38ae6ee572791b974b41f8433,"KAFKA-16833 Fixing PartitionInfo and Cluster equals and hashCode (#16062)

Reviewers: Andrew Schofield <aschofield@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-05-31 05:00:42,Alyssa Huang,Mixed
7c1bb1585f31b1ec68b0f327e831ec2a909d824a,"KAFKA-16308 [2/N]: Allow unstable feature versions and rename unstable metadata config (#16130)

As per KIP-1022, we will rename the unstable metadata versions enabled config to support all feature versions.

Features is also updated to return latest production and latest testing versions of each feature.

A feature is production ready when the corresponding metadata version (bootstrapMetadataVersion) is production ready.

Adds tests for the feature usage of the unstableFeatureVersionsEnabled config

Reviewers: David Jacot <djacot@confluent.io>, Jun Rao <junrao@gmail.com>",2024-05-30 14:52:50,Justine Olshan,Mixed
3d125a23224682a90c624b0cbe696c934d0b7aba,"MINOR: Add more unit tests to LogSegments (#16085)

add more unit tests to LogSegments and do some small refactor in LogSegments.java

Reviewers: Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-05-31 16:07:38,Kuan-Po (Cooper) Tseng,Mixed
eb39031cd03fe94c8262f8c982222801842f6e6f,"KAFKA-16766: offset fetch timeout exception in new consumer consistent with legacy (#16125)

* Timeout exception fetching offsets

* Tests",2024-05-31 10:33:20,Lianet Magrans,Mixed
0971924ebc7e65eb7055010d2400626d31967d8c,"KAFKA-16824: Utils.getHost and Utils.getPort do not catch a lot of invalid host and ports. (#16048)

Modify regex of HOST_PORT_PATTERN to prevent malformed hosts and ports.

Reviewers: Luke Chen <showuon@gmail.com>",2024-05-31 16:50:27,"TingIāu ""Ting"" Kì",Mixed
21caf6b123dd70a68d258fd925785a529f3a48d9,"KAFKA-16629 Add broker-related tests to ConfigCommandIntegrationTest (#15840)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-05-31 20:24:33,Ken Huang,Mixed
ba61ff0cd94dd50401998fff1be7f646d1239000,"KAFKA-16860; [1/2] Introduce group.version feature flag (#16120)

This patch introduces the `group.version` feature flag with one version:
1) Version 1 enables the new consumer group rebalance protocol (KIP-848).

Reviewers: Justine Olshan <jolshan@confluent.io>",2024-05-31 12:48:55,David Jacot,Mixed
ca9f4aeda769e05222e1734dd93ab95dc27d47eb,"KAFKA-16639 Ensure HeartbeatRequestManager generates leave request regardless of in-flight heartbeats. (#16017)

Fix the bug where the heartbeat is not sent when a newly created consumer is immediately closed.

When there is a heartbeat request in flight and the consumer is then closed. In the current code, the HeartbeatRequestManager does not correctly send the closing heartbeat because a previous heartbeat request is still in flight. However, the closing heartbeat is only sent once, so in this situation, the broker will not know that the consumer has left the consumer group until the consumer's heartbeat times out.
This situation causes the broker to wait until the consumer's heartbeat times out before triggering a consumer group rebalance, which in turn affects message consumption.

Reviewers: Lianet Magrans <lianetmr@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-06-01 04:14:15,"TingIāu ""Ting"" Kì",Mixed
fb566e48bf05d749f8db8da803a3570acf25bb11,"KAFKA-16864; Optimize uniform (homogenous) assignor (#16088)

This patch optimizes uniform (homogenous) assignor by avoiding creating a copy of all the assignments. Instead, the assignor creates a copy only if the assignment is updated. It is a sort of copy-on-write. This change reduces the overhead of the TargetAssignmentBuilder when ran with the uniform (homogenous) assignor.

Trunk:

```
Benchmark                                     (memberCount)  (partitionsToMemberRatio)  (topicCount)  Mode  Cnt   Score   Error  Units
TargetAssignmentBuilderBenchmark.build                10000                         10           100  avgt    5  24.535 ± 1.583  ms/op
TargetAssignmentBuilderBenchmark.build                10000                         10          1000  avgt    5  24.094 ± 0.223  ms/op
JMH benchmarks done
```

```
Benchmark                                       (assignmentType)  (assignorType)  (isRackAware)  (memberCount)  (partitionsToMemberRatio)  (subscriptionType)  (topicCount)  Mode  Cnt   Score   Error  Units
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL         UNIFORM          false          10000                         10         HOMOGENEOUS           100  avgt    5  14.697 ± 0.133  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL         UNIFORM          false          10000                         10         HOMOGENEOUS          1000  avgt    5  15.073 ± 0.135  ms/op
JMH benchmarks done
```

Patch:

```
Benchmark                                     (memberCount)  (partitionsToMemberRatio)  (topicCount)  Mode  Cnt  Score   Error  Units
TargetAssignmentBuilderBenchmark.build                10000                         10           100  avgt    5  3.376 ± 0.577  ms/op
TargetAssignmentBuilderBenchmark.build                10000                         10          1000  avgt    5  3.731 ± 0.359  ms/op
JMH benchmarks done
```

```
Benchmark                                       (assignmentType)  (assignorType)  (isRackAware)  (memberCount)  (partitionsToMemberRatio)  (subscriptionType)  (topicCount)  Mode  Cnt  Score   Error  Units
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL         UNIFORM          false          10000                         10         HOMOGENEOUS           100  avgt    5  1.975 ± 0.086  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL         UNIFORM          false          10000                         10         HOMOGENEOUS          1000  avgt    5  2.026 ± 0.190  ms/op
JMH benchmarks done
```

Reviewers: Ritika Reddy <rreddy@confluent.io>, Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2024-05-31 13:17:59,David Jacot,Mixed
e33eb82fedc7cc1d9031c68190b4da1052eda3d7,"KAFKA-16574 The metrics of LogCleaner disappear after reconfiguration (#15863)

Reviewers: Gaurav Narula <gaurav_narula2@apple.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-06-02 01:02:03,Chia Chuan Yu,Mixed
8ace33b47fc078d89a104043b12ca95f6e1da637,"KAFKA-16757: Fix broker re-registration issues around MV 3.7-IV2 (#15945)

When upgrading from a MetadataVersion older than 3.7-IV2, we need to resend the broker registration, so that the controller can record the storage directories. The current code for doing this has several problems, however. One is that it tends to trigger even in cases where we don't actually need it. Another is that when re-registering the broker, the broker is marked as fenced.

This PR moves the handling of the re-registration case out of BrokerMetadataPublisher and into BrokerRegistrationTracker. The re-registration code there will only trigger in the case where the broker sees an existing registration for itself with no directories set.  This is much more targetted than the original code.

Additionally, in ClusterControlManager, when re-registering the same broker, we now preserve its fencing and shutdown state, rather than clearing those. (There isn't any good reason re-registering the same broker should clear these things... this was purely an oversight.) Note that we can tell the broker is ""the same"" because it has the same IncarnationId.

Reviewers: Gaurav Narula <gaurav_narula2@apple.com>, Igor Soarez <soarez@apple.com>",2024-06-01 23:51:39,Colin Patrick McCabe,Mixed
2c82ecd67f2f6b412f625e8efc1457e7fb7f74dd,"KAFKA-16807 DescribeLogDirsResponseData#results#topics have unexpected topics having empty partitions (#16042)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-02 17:33:02,Ken Huang,Mixed
b05f82d44489b5744a1470d49896e322528c25da,"KAFKA-16785 Migrate TopicBasedRemoteLogMetadataManagerRestartTest to new test infra (#16170)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-02 22:18:53,Kuan-Po (Cooper) Tseng,Not TDD
850769322937345ce838656054371a4cb778bb05,"KAFKA-16859 Cleanup check if tiered storage is enabled (#16153)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-03 11:04:58,Ken Huang,Mixed
8f82f14a483d827d4653fb27b09945df936f49f6,"KAFKA-16713: Define initial set of RPCs for KIP-932 (#16022)

This PR defines the initial set of RPCs for KIP-932. The RPCs for the admin client and state management are not in this PR.

Reviewers: Apoorv Mittal <amittal@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-06-03 11:52:35,Andrew Schofield,Not TDD
734d309a2973884cd175b29c1f9c95947e1c0b80,"KAFKA-16852 Adding two thread pools kafka-16852 (#16154)

Reviewers: Christo Lolov <lolovc@amazon.com>, Chia-Ping Tasi <chia7712@gmail.com>",2024-06-03 09:52:54,Murali Basani,Mixed
979f8d9aa3e8840951a151ab83eb006f8e7c1314,"MINOR: Small refactor in TargetAssignmentBuilder (#16174)

This patch is a small refactoring which mainly aims at avoid to construct a copy of the new target assignment in the TargetAssignmentBuilder because the copy is not used by the caller. The change relies on the exiting tests and it does not really have an impact on performance (e.g. validated with TargetAssignmentBuilderBenchmark).

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-03 11:32:39,David Jacot,Mixed
7973aa6a39249f0afc141cddf46560bdae546337,"KAFKA-16861: Don't convert to group to classic if the size is larger than group max size. (#16163)

Fix the bug where the group downgrade to a classic one when a member leaves, even though the consumer group size is still larger than `classicGroupMaxSize`.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>",2024-06-03 11:36:07,"TingIāu ""Ting"" Kì",Mixed
8a882a77a47cbc269818ea76a02a56c0a60b743b,"KAFKA-16105: Reset read offsets when seeking to beginning in TBRLMM (#15165)

Reviewers: Greg Harris <greg.harris@aiven.io>, Luke Chen <showuon@gmail.com>, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>",2024-06-03 13:46:40,Anatoly Popov,Mixed
459da4795a511f6933e940fcf105a824bd9e589c,"KAFKA-16525; Dynamic KRaft network manager and channel (#15986)

Allow KRaft replicas to send requests to any node (Node) not just the nodes configured in the
controller.quorum.voters property. This flexibility is needed so KRaft can implement the
controller.quorum.voters configuration, send request to the dynamically changing set of voters and
send request to the leader endpoint (Node) discovered through the KRaft RPCs (specially
BeginQuorumEpoch request and Fetch response).

This was achieved by changing the RequestManager API to accept Node instead of just the replica ID.
Internally, the request manager tracks connection state using the Node.idString method to match the
connection management used by NetworkClient.

The API for RequestManager is also changed so that the ConnectState class is not exposed in the
API. This allows the request manager to reclaim heap memory for any connection that is ready.

The NetworkChannel was updated to receive the endpoint information (Node) through the outbound raft
request (RaftRequent.Outbound). This makes the network channel more flexible as it doesn't need to
be configured with the list of all possible endpoints. RaftRequest.Outbound and
RaftResponse.Inbound were updated to include the remote node instead of just the remote id.

The follower state tracked by KRaft replicas was updated to include both the leader id and the
leader's endpoint (Node). In this comment the node value is computed from the set of voters. In
future commit this will be updated so that it is sent through KRaft RPCs. For example
BeginQuorumEpoch request and Fetch response.

Support for configuring controller.quorum.bootstrap.servers was added. This includes changes to
KafkaConfig, QuorumConfig, etc. All of the tests using QuorumTestHarness were changed to use the
controller.quorum.bootstrap.servers instead of the controller.quorum.voters for the broker
configuration. Finally, the node id for the bootstrap server will be decreasing negative numbers
starting with -2.

Reviewers: Jason Gustafson <jason@confluent.io>, Luke Chen <showuon@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",2024-06-03 14:24:48,José Armando García Sancio,Mixed
c3a1bef4296ef306646f9fa44b92bc6de08d628b,"KAFKA-16715: Create KafkaShareConsumer interfaces (#16134)

This PR introduces ShareConsumer and KafkaShareConsumer. It is focused entirely on the minimal additions required to introduce the external programming interfaces.

Reviewers: Apoorv Mittal <amittal@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-06-04 09:05:59,Andrew Schofield,Mixed
53d592e369f9ea5d3a25d828bbc1c4845a8a1f92,"MINOR: Fix type in MetadataVersion.IBP_4_0_IV0 (#16181)

This patch fixes a typo in MetadataVersion.IBP_4_0_IV0. It should be 0 not O.

Reviewers: Justine Olshan <jolshan@confluent.io>, Jun Rao <junrao@gmail.com>,  Chia-Ping Tsai <chia7712@gmail.com>",2024-06-03 20:48:04,David Jacot,Mixed
64c50a274ba23abb1c0635a3064b2cd8a9eaa408,"KAFKA-16880 Update equals and hashcode methods for two attributes  (#16173)

Reviewers: Kamal Chandraprakash <kamal.chandraprakash@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-06-04 14:05:00,Murali Basani,Mixed
d7bc43ed06bbdb0864863541df51544dbe234e5d,"KAFKA-16664; Re-add EventAccumulator.poll(long, TimeUnit) (#16144)

We have revamped the thread idle ratio metric in https://github.com/apache/kafka/pull/15835. https://github.com/apache/kafka/pull/15835#discussion_r1588068337 describes a case where the metric loses accuracy and in order to set a lower bound to the accuracy, this patch re-adds a poll with a timeout that was removed as part of https://github.com/apache/kafka/pull/15430.

Reviewers: David Jacot <djacot@confluent.io>",2024-06-03 23:27:35,Jeff Kim,Mixed
e4ff54073a5957af50626f63f59d15c26c16370d,"MINOR: Code Cleanup (Clients Module) (#16049)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-04 16:49:59,Sanskar Jhajharia,Mixed
eea9ebf8a31126f797a4a325995e5e04d4993b74,"KAFKA-16047: Use REQUEST_TIMEOUT_MS_CONFIG in AdminClient.fenceProducers (#16151)

Use REQUEST_TIMEOUT_MS_CONFIG in AdminClient.fenceProducers, 
or options.timeoutMs if specified, as transaction timeout.

No transaction will be started with this timeout, but
ReplicaManager.appendRecords uses this value as its timeout.
Use REQUEST_TIMEOUT_MS_CONFIG like a regular producer append
to allow for replication to take place.

Co-Authored-By: Adrian Preston <prestona@uk.ibm.com>",2024-06-04 11:45:11,Edoardo Comar,Mixed
0409003c4395580b3d0b9e861e27ce61295fcdcf,"KAFKA-16837, KAFKA-16838: Ignore task configs for deleted connectors, and compare raw task configs before publishing them (#16122)

Reviewers: Mickael Maison <mickael.maison@gmail.com>",2024-06-04 09:36:24,Chris Egerton,Mixed
078dd9a311a5e9ddb9d0b49a1164c50dadde3a27,"KAFKA-16821; Member Subscription Spec Interface (#16068)

This patch reworks the `PartitionAssignor` interface to use interfaces instead of POJOs. It mainly introduces the `MemberSubscriptionSpec` interface that represents a member subscription and changes the `GroupSpec` interfaces to expose the subscriptions and the assignments via different methods.

The patch does not change the performance.

before:
```
Benchmark                                     (memberCount)  (partitionsToMemberRatio)  (topicCount)  Mode  Cnt  Score   Error  Units
TargetAssignmentBuilderBenchmark.build                10000                         10           100  avgt    5  3.462 ± 0.687  ms/op
TargetAssignmentBuilderBenchmark.build                10000                         10          1000  avgt    5  3.626 ± 0.412  ms/op
JMH benchmarks done
```

after:
```
Benchmark                                     (memberCount)  (partitionsToMemberRatio)  (topicCount)  Mode  Cnt  Score   Error  Units
TargetAssignmentBuilderBenchmark.build                10000                         10           100  avgt    5  3.677 ± 0.683  ms/op
TargetAssignmentBuilderBenchmark.build                10000                         10          1000  avgt    5  3.991 ± 0.065  ms/op
JMH benchmarks done
```

Reviewers: David Jacot <djacot@confluent.io>",2024-06-04 06:44:37,Ritika Reddy,Mixed
16359e70d3ae1daa82c2e1fffe79ebfd6a63e8e4,"KAFKA-16583: Handle PartitionChangeRecord without directory IDs (#16118)

When PartitionRegistration#merge() reads a PartitionChangeRecord
from an older MetadataVersion, with a replica assignment change
and without #directories() set, it produces a direcotry assignment
of DirectoryId.UNASSIGNED. This is problematic because the MetadataVersion
may not yet support directory assignments, leading to a
UnwritableMetadataException in PartitionRegistration#toRecord.

Since the Controller always sets directories on PartitionChangeRecord
if the MetadataVersion supports it, via PartitionChangeBuilder,
there's no need for PartitionRegistration#merge() to populate
directories upon a replica assignment change.

Reviewers: Luke Chen <showuon@gmail.com>",2024-06-04 15:37:20,Igor Soarez,Mixed
55d38efcc5505a5a1bddb08ba05f4d923f8050f9,"KAFKA-15852: Move LinuxIoMetricsCollector to server module (#16178)


Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-04 16:42:35,Mickael Maison,Mixed
5ce4b91dfa67233321c2cd206cf03c84cb435a73,"KAFKA-15045: (KIP-924 pt. 16) TaskAssignor.onAssignmentComputed handling (#16147)

This PR takes care of making the call back toTaskAssignor.onAssignmentComputed.

It also contains a change to the public AssignmentConfigs API, as well as some simplifications of the StickyTaskAssignor.

This PR also changes the rack information fetching to happen lazily in the case where the TaskAssignor makes its decisions without said rack information.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2024-06-04 11:33:48,Antoine Pourchet,Mixed
cda2df5feb0f4c4226f5c3a6e3f55ecdbf071e2c,"KAFKA-16882 Migrate RemoteLogSegmentLifecycleTest to ClusterInstance infra (#16180)

- Removed the RemoteLogSegmentLifecycleManager
- Removed the TopicBasedRemoteLogMetadataManagerWrapper, RemoteLogMetadataCacheWrapper, TopicBasedRemoteLogMetadataManagerHarness and TopicBasedRemoteLogMetadataManagerWrapperWithHarness

Reviewers: Kuan-Po (Cooper) Tseng <brandboat@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-06-05 03:11:30,Kamal Chandraprakash,Mixed
8b3c77c6711d8c1424659a1b4621a8c823fa2236,"KAFKA-15305 The background thread should try to process the remaining task until the shutdown timer is expired. (#16156)

Reviewers: Lianet Magrans <lianetmr@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-06-05 04:21:20,"TingIāu ""Ting"" Kì",Mixed
9ceed8f18f43aa3d5deb4c5a946da590f7ba90d6,"KAFKA-16535: Implement AddVoter, RemoveVoter, UpdateVoter RPCs

Implement the add voter, remove voter, and update voter RPCs for
KIP-853. This is just adding the RPC handling; the current
implementation in RaftManager just throws UnsupportedVersionException.

Reviewers: Andrew Schofield <aschofield@confluent.io>, José Armando García Sancio <jsancio@apache.org>",2024-06-04 14:07:48,Colin P. McCabe,Not TDD
7e0caad96eb13988bce1a6afa774b0ddbd5ec3c7,"MINOR: Cleanup unused references in core (#16192)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-05 05:12:33,Igor Soarez,Mixed
01e9918530edd32986215ad016b678822d7bb131,"KAFKA-16814 KRaft broker cannot startup when `partition.metadata` is missing (#16165)

When starting up kafka logManager, we'll check stray replicas to avoid some corner cases. But this check might cause broker unable to startup if partition.metadata is missing because when startup kafka, we load log from file, and the topicId of the log is coming from partition.metadata file. So, if partition.metadata is missing, the topicId will be None, and the LogManager#isStrayKraftReplica will fail with no topicID error.

The partition.metadata missing could be some storage failure, or another possible path is unclean shutdown after topic is created in the replica, but before data is flushed into partition.metadata file. This is possible because we do the flush in async way here.

When finding a log without topicID, we should treat it as a stray log and then delete it.

Reviewers: Luke Chen <showuon@gmail.com>, Gaurav Narula <gaurav_narula2@apple.com>",2024-06-05 07:56:18,Kuan-Po (Cooper) Tseng,Mixed
252c1acac357708f98403a12f3ef3eb91e3735ac,"KAFKA-16740: Adding skeleton code for Share Fetch and Acknowledge RPC (KIP-932) (#16184)

The PR adds skeleton code for Share Fetch and Acknowledge RPCs. The changes include:

1. Defining RPCs in KafkaApis.scala
2. Added new SharePartitionManager class which handles the RPCs handling
3. Added SharePartition class which manages in-memory record states and for fetched data.


Reviewers: David Jacot <djacot@confluent.io>, Andrew Schofield <aschofield@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-06-05 10:25:24,Apoorv Mittal,Mixed
7ddfa64759d494ae85d67efd4d49cf673e7962bc,"MINOR: Adjust validateOffsetCommit/Fetch in ConsumerGroup to ensure compatibility with classic protocol members (#16145)

During online migration, there could be ConsumerGroup that has members that uses the classic protocol. In the current implementation, `STALE_MEMBER_EPOCH` could be thrown in ConsumerGroup offset fetch/commit validation but it's not supported by the classic protocol. Thus this patch changed `ConsumerGroup#validateOffsetCommit` and `ConsumerGroup#validateOffsetFetch` to ensure compatibility.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, David Jacot <djacot@confluent.io>",2024-06-04 23:08:38,Dongnuo Lyu,Mixed
02c794dfd3bda12066031155bd62234ad863860b,"KAFKA-15776: Introduce remote.fetch.max.timeout.ms to configure DelayedRemoteFetch timeout (#14778)

KIP-1018, part1, Introduce remote.fetch.max.timeout.ms to configure DelayedRemoteFetch timeout

Reviewers: Luke Chen <showuon@gmail.com>",2024-06-05 14:42:23,Kamal Chandraprakash,Mixed
bd9d68f24a5aae0054fd93a1a848d2cf0dfdde30,"KAFKA-15265: Integrate RLMQuotaManager for throttling fetches from remote storage (#16071)

Reviewers: Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Luke Chen <showuon@gmail.com>, Satish Duggana <satishd@apache.org>",2024-06-05 19:12:25,Abhijeet Kumar,Mixed
f2aafcc66faca4d07a27e4ef90158136cb317b44,"MINOR: Cleanups in Shell Module (#16204)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-05 22:36:01,Sanskar Jhajharia,Mixed
52514a89e34b28fa6564d5c93c15461c6fab3f0f,"KAFKA-16858: Throw DataException from validateValue on array and map schemas without inner schemas (#16161)

Signed-off-by: Greg Harris <greg.harris@aiven.io>
Reviewers: Chris Egerton <chrise@aiven.io>",2024-06-05 11:35:32,Greg Harris,Mixed
0109a3f7189d332c333cad0625b54779bf8f9cd4,"KAFKA-15045: (KIP-924 pt. 17) State store computation fixed (#16194)

Fixed the calculation of the store name list based on the subtopology being accessed.

Also added a new test to make sure this new functionality works as intended.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2024-06-05 13:09:37,Antoine Pourchet,Mixed
896af1b2f2f2a7d579e0aef074bcb2004c0246f2,"MINOR: Raft module Cleanup (#16205)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-06 04:16:59,Sanskar Jhajharia,Not TDD
1134520decfca990410acce2ec1a8cba5c8c2cb4,"KAFKA-16573: Specify node and store where serdes are needed (#15790)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bruno Cadonna <bruno@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2024-06-05 15:05:04,Ayoub Omari,Mixed
3835515feaf7cb5bb7de3c4d63794e79100eb62a,"KAFKA-16541 Fix potential leader-epoch checkpoint file corruption (#15993)

A patch for KAFKA-15046 got rid of fsync on LeaderEpochFileCache#truncateFromStart/End for performance reason, but it turned out this could cause corrupted leader-epoch checkpoint file on ungraceful OS shutdown, i.e. OS shuts down in the middle when kernel is writing dirty pages back to the device.

To address this problem, this PR makes below changes: (1) Revert LeaderEpochCheckpoint#write to always fsync
(2) truncateFromStart/End now call LeaderEpochCheckpoint#write asynchronously on scheduler thread
(3) UnifiedLog#maybeCreateLeaderEpochCache now loads epoch entries from checkpoint file only when current cache is absent

Reviewers: Jun Rao <junrao@gmail.com>",2024-06-06 15:10:13,Okada Haruki,Mixed
f880ad6ccfe59695634a43ae878de620d02b4f9e,"KAFKA-16530: Fix high-watermark calculation to not assume the leader is in the voter set (#16079)

1. Changing log message from error to info - We may expect the HW calculation to give us a smaller result than the current HW in the case of quorum reconfiguration. We will continue to not allow the HW to actually decrease.
2. Logic for finding the updated LeaderEndOffset for updateReplicaState is changed as well. We do not assume the leader is in the voter set and check the observer states as well.
3. updateLocalState now accepts an additional ""lastVoterSet"" param which allows us to update the leader state with the last known voters. any nodes in this set but not in voterStates will be added to voterStates and removed from observerStates, any nodes not in this set but in voterStates will be removed from voterStates and added to observerStates

Reviewers: Luke Chen <showuon@gmail.com>, José Armando García Sancio <jsancio@apache.org>",2024-06-06 14:30:49,Alyssa Huang,Mixed
b74b182841a340b7b92d852142201cd5c1ee1b85,"KAFKA-16786: Remove old assignment strategy usage in new consumer (#16214)

Remove usage of the partition.assignment.strategy config in the new consumer. This config is deprecated with the new consumer protocol, so the AsyncKafkaConsumer should not use or validate the property.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-06-06 09:45:36,Lianet Magrans,Mixed
226f3c57e3a19de227d6b34828fd5e3a535e6778,"MINOR: Code cleanup in metadata module (#16065)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2024-06-06 15:18:23,Sanskar Jhajharia,Mixed
a41f7a4e13bfdb21fcd84dcf0baad3f2f4511479,"KAFKA-16884 Refactor RemoteLogManagerConfig with AbstractConfig (#16199)

Reviewers: Greg Harris <gharris1727@gmail.com>, Kamal Chandraprakash <kamal.chandraprakash@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-06-07 00:06:25,Murali Basani,Mixed
79ea7d6122ac4dbc1441e9efbddae44b1a9c93f9,"MINOR: Various cleanups in clients (#16193)


Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-06 20:28:39,Mickael Maison,Mixed
7d832cf74fd403a8bca168a83340c19f9afe1a42,"KAFKA-14701; Move `PartitionAssignor` to new `group-coordinator-api` module (#16198)

This patch moves the `PartitionAssignor` interface and all the related classes to a newly created `group-coordinator/api` module, following the pattern used by the storage and tools modules.

Reviewers: Ritika Reddy <rreddy@confluent.io>, Jeff Kim <jeff.kim@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-06-06 12:19:20,David Jacot,Mixed
8a2bc3a22188fbdb506b6f4bec6d3f8eb59d4c3f,"KAFKA-16903: Consider produce error of different task (#16222)

A task does not know anything about a produce error thrown
by a different task. That might lead to a InvalidTxnStateException
when a task attempts to do a transactional operation on a producer
that failed due to a different task.

This commit stores the produce exception in the streams producer
on completion of a send instead of the record collector since the
record collector is on task level whereas the stream producer
is on stream thread level. Since all tasks use the same streams
producer the error should be correctly propagated across tasks
of the same stream thread.

For EOS alpha, this commit does not change anything because
each task uses its own producer. The send error is still
on task level but so is also the transaction.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2024-06-06 12:19:52,Bruno Cadonna,Mixed
ee834d9214b9961d0afaee030c7a46487c71e543,"KAFKA-15045: (KIP-924 pt. 19) Update to new AssignmentConfigs (#16219)

This PR updates all of the streams task assignment code to use the new AssignmentConfigs public class.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2024-06-06 14:20:48,Antoine Pourchet,Mixed
c01279b92acefd9135089588319910bac79bfd4c,"KAFKA-16905: Fix blocking DescribeCluster call in AdminClient DescribeTopics (#16217)

Reviewers: Andrew Schofield <aschofield@confluent.io>, Lianet Magrans <lianetmr@gmail.com>, David Arthur <mumrah@gmail.com>",2024-06-06 18:11:43,Apoorv Mittal,Not TDD
271a1b42cd5400f401b6b2d8d3a25a6a32986601,"KAFKA-16223 Migrate KafkaConfigBackingStoreTest to Mockito (#16126)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-07 07:02:14,Johnny Hsu,Not TDD
d6cd83e2fb2bab4526f07e067277b34e482f6678,"KAFKA-16200: Enforce that RequestManager implementations respect user-provided timeout (#16031)

Improve consistency and correctness for user-provided timeouts at the Consumer network request layer, per the Java client Consumer timeouts design (https://cwiki.apache.org/confluence/display/KAFKA/Java+client+Consumer+timeouts). While the changes introduced in KAFKA-15974 enforce timeouts at the Consumer's event layer, this change enforces timeouts at the network request layer.

The changes mostly fit into the following areas:

1. Create shared code and idioms so timeout handling logic is consistent across current and future RequestManager implementations
2. Use deadlineMs instead of expirationMs, expirationTimeoutMs, retryExpirationTimeMs, timeoutMs, etc.
3. Update ""preemptive pruning"" to remove expired requests that have had at least one attempt

Reviewers: Lianet Magrans <lianetmr@gmail.com>, Bruno Cadonna <cadonna@apache.org>",2024-06-07 09:53:27,Kirk True,Mixed
7c0fff7c36ddd4c4ab44b5aefdb7f6bb72662054,"KAFKA-16606 Gate JBOD configuration on 3.7-IV2 (#15834)

Support for multiple log directories in KRaft exists from
MetataVersion 3.7-IV2.

When migrating a ZK broker to KRaft, we already check that
the IBP is high enough before allowing the broker to startup.

With KIP-584 and KIP-778, Brokers in KRaft mode do not require
the IBP configuration - the configuration is deprecated.
In KRaft mode inter.broker.protocol.version defaults to
MetadataVersion.MINIMUM_KRAFT_VERSION (IBP_3_0_IV1).

Instead KRaft brokers discover the MetadataVersion by reading
the ""metadata.version"" FeatureLevelRecord from the cluster metadata.

This change adds a new configuration validation step upon discovering
the ""metadata.version"" from the cluster metadata.

Reviewers: Mickael Maison <mickael.maison@gmail.com>",2024-06-07 09:11:57,Igor Soarez,Mixed
5cd6944eaac074a0acbddf247f9c794f8d488da1,"KAFKA-16493: Avoid unneeded subscription regex check if metadata version unchanged (#15869)

This PR includes changes for AsyncKafkaConsumer to avoid evaluating the subscription regex on every poll if metadata hasn't changed. The metadataVersionSnapshot was introduced to identify whether metadata has changed or not, if yes then the current subscription regex will be evaluated.

This is the same mechanism used by the LegacyConsumer.

Reviewers: Lianet Magrans <lianetmr@gmail.com>, Matthias J. Sax <matthias@confluent.io>",2024-06-07 10:30:07,Phuc-Hong-Tran,Mixed
96036aee855ba0ec1d562904636ea0ff433bce7f,"KAFKA-16916: Fixing error in completing future (#16249)

Fix to complete Future which was stuck due the exception.getCause() throws an error.

The fix in the #16217 unblocked blocking thread but exception in catch block from blocking get call was wrapped in ExecutionException which is not the case when moved to async workflow hence getCause is not needed.

Reviewers: Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-06-08 14:25:54,Apoorv Mittal,Not TDD
55945580472218b306616122ba3889ba644aa700,"KAFKA-16886: Detect replica demotion in AssignmentsManager (#16232)

JBOD Brokers keep the Controller up to date with replica-to-directory
placement via AssignReplicasToDirsRequest. These requests are queued,
compacted and sent by AssignmentsManager.

The Controller returns the error NOT_LEADER_OR_FOLLOWER when handling
a AssignReplicasToDirsRequest from a broker that is not a replica.

A partition reassignment can take place, removing the Broker
as a replica before the AssignReplicasToDirsRequest successfully
reaches the Controller. AssignmentsManager retries failed
requests, and will continuously try to propagate this assignment,
until the Broker either shuts down, or is added back as a replica.

When encountering a NOT_LEADER_OR_FOLLOWER error, AssignmentsManager
should assume that the broker is no longer a replica, and stop
trying to propagate the directory assignment for that partition.

Reviewers: Luke Chen <showuon@gmail.com>",2024-06-08 14:10:23,Igor Soarez,Mixed
3d5d1504f791b89dae943283f8d027fb4d1f4bc5,"KAFKA-16878 Remove powermock and easymock from code base (#16236)

Reviewers: TaiJuWu <tjwu1217@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-06-09 00:17:43,PoAn Yang,Not TDD
816209d18770b85c510e65b4940a26b0e0e5fd45,"KAFKA-10787 Apply spotless to transaction-coordinator and server-common (#16172)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-09 05:36:17,gongxuanzhang,Mixed
824900b97a3b674d5c46bf54226745196f433d7e,"KAFKA-15045: (KIP-924 pt. 18) Better assignment testing (#16201)

Added more testing for the StickyTaskAssignor, which includes a large-scale test with rack aware enabled.

Also added a no-op change to StreamsAssignmentScaleTest.java to allow for rack aware optimization testing.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2024-06-08 19:48:43,Antoine Pourchet,Mixed
e5b8712993d342d0dd2be69c3fc78d6493366f93,"KAFKA-16885 Renamed the enableRemoteStorageSystem to isRemoteStorageSystemEnabled (#16256)

Reviewers: Kamal Chandraprakash <kchandraprakash@uber.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-06-10 02:14:15,Chia Chuan Yu,Mixed
2533a07ad0eb2eb65feec5b3b12f8989f5e28267,"KAFKA-16448: Add ProcessingExceptionHandler in Streams configuration (#16188)

This PR is part of KAFKA-16448 which aims to bring a ProcessingExceptionHandler to Kafka Streams in order to deal with exceptions that occur during processing.

This PR brings ProcessingExceptionHandler in Streams configuration.

Co-authored-by: Dabz <d.gasparina@gmail.com>
Co-authored-by: sebastienviale <sebastien.viale@michelin.com>

Reviewer: Bruno Cadonna <cadonna@apache.org>",2024-06-10 13:23:10,Loïc GREFFIER,Mixed
40de07dab52b0f4c1024ad7ee5d0afc878ba7014,"KAFKA-14509; [4/4] Handle includeAuthorizedOperations in ConsumerGroupDescribe API (#16158)

This patch implements the handling of `includeAuthorizedOperations` flag in the ConsumerGroupDescribe API.

Reviewers: David Jacot <djacot@confluent.io>",2024-06-10 05:07:45,Max Riedel,Mixed
049cfeac027451a13031807ea28f121a0176e254,"MINOR: Rename uniform assignor's internal builders (#16233)

This patch renames the uniform assignor's builders to match the `SubscriptionType` which is used to determine which one is called. It removes the abstract class `AbstractUniformAssignmentBuilder` which is not necessary anymore. It also applies minor refactoring.

Reviewers: Ritika Reddy <rreddy@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-06-10 05:26:56,David Jacot,Mixed
f359908fcdc38c2fbc34278d6787d92564a8b251,"KAFKA-15776: Support added to update remote.fetch.max.wait.ms dynamically (#16203)

Reviewers: Satish Duggana <satishd@apache.org>, Luke Chen <showuon@gmail.com>",2024-06-10 20:42:12,Kamal Chandraprakash,Mixed
1426e8e92061276c6af548b152ffe9f585e6806e,"KAFKA-16764: New consumer should throw InvalidTopicException on poll when invalid topic in metadata. (#16043)

Propagate metadata error from background thread to application thread.
So, this fix ensures that metadata errors are thrown to the user on consumer.poll()

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>, Philip Nee <pnee@confluent.io>, Lianet Magrans <lianetmr@gmail.com>",2024-06-10 18:30:29,"Gyeongwon, Do",Mixed
eec8fd6a98cf0e7ddf4c75ec3e4ea429d1be2fb7,"KAFKA-9228: Restart tasks on runtime-only connector config changes (#16053)

Reviewers: Greg Harris <greg.harris@aiven.io>",2024-06-10 17:02:08,Chris Egerton,Mixed
68070c94a6bd5141c720aaff85fa545da3a7a1b5,"KAFKA-16724: Added support for fractional throughput and monotonic payload in kafka-producer-perf-test.sh

Added support for fractional throughput and monotonic payload in kafka-producer-perf-test.sh.
https://cwiki.apache.org/confluence/display/KAFKA/KIP-932%3A+Queues+for+Kafka#KIP932:QueuesforKafka-kafka-producer-perf-test.sh

Reviewers: Andrew Schofield <aschofield@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-06-11 11:19:31,ShivsundarR,Mixed
af86e56fcdf20d35b04639399cc81b3a1223fe6b,"KAFKA-10787 Apply spotless to tools and tools-api module (#16262)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-11 14:48:14,gongxuanzhang,Mixed
99eacf1b61a30090ecf1f4c28d81367615c511f3,"KAFKA-16914: Added share group dynamic and broker configs (#16268)

KIP-932 introduces a bunch of broker and dynamic configs for share groups. This PR adds those new configs. The changes include:

1. Defined ShareGroupConfigs class which stores various share group configurations.
2. Use the defined share configs in KafkaConfig.scala for making it available to BrokerServer
3. Adds a few tests to validate the conditions on these new configs.


 Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2024-06-11 16:10:15,Abhinav Dixit,Mixed
b7dcae44ffb29f854385cef959519a3d0baad55e,"KAFKA-16373: KIP-1028: Modfiying download url for kafka dockerfile (#16281)

This PR modifies the download url from https://downloads.apache.org/kafka/ to https://archive.apache.org/dist/kafka/ as the former is not permanent.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>, Vedarth Sharma <vesharma@confluent.io>",2024-06-11 21:02:33,KrishVora01,Not TDD
f3dbd7ed08a0a7af0e69de1ccca8b6171b698a62,"KAFKA-16904: Metric to measure the latency of remote read requests (#16209)

Reviewers: Satish Duggana <satishd@apache.org>, Christo Lolov <lolovc@amazon.com>, Luke Chen <showuon@gmail.com>",2024-06-11 21:07:12,Kamal Chandraprakash,Mixed
aecaf4447561edd8da9f06e3abdf46f382dc9d89,"KAFKA-16520: Support KIP-853 in DescribeQuorum (#16106)

Add support for KIP-953 KRaft Quorum reconfiguration in the DescribeQuorum request and response.
Also add support to AdminClient.describeQuorum, so that users will be able to find the current set of
quorum nodes, as well as their directories, via these RPCs.

Reviewers: Luke Chen <showuon@gmail.com>, Colin P. McCabe <cmccabe@apache.org>, Andrew Schofield <aschofield@confluent.io>",2024-06-11 10:01:35,Nikolay,Mixed
98f7da9172c080592c22b241e2760435d2b48195,"KAFKA-16930; UniformHeterogeneousAssignmentBuilder throws NPE when one member has no subscriptions (#16283)

Fix the following NPE:

```
java.lang.NullPointerException: Cannot invoke ""org.apache.kafka.coordinator.group.assignor.MemberAssignment.targetPartitions()"" because the return value of ""java.util.Map.get(Object)"" is null
	at org.apache.kafka.coordinator.group.assignor.GeneralUniformAssignmentBuilder.canMemberParticipateInReassignment(GeneralUniformAssignmentBuilder.java:248)
	at org.apache.kafka.coordinator.group.assignor.GeneralUniformAssignmentBuilder.balance(GeneralUniformAssignmentBuilder.java:336)
	at org.apache.kafka.coordinator.group.assignor.GeneralUniformAssignmentBuilder.buildAssignment(GeneralUniformAssignmentBuilder.java:157)
	at org.apache.kafka.coordinator.group.assignor.UniformAssignor.assign(UniformAssignor.java:84)
	at org.apache.kafka.coordinator.group.consumer.TargetAssignmentBuilder.build(TargetAssignmentBuilder.java:302)
	at org.apache.kafka.coordinator.group.GroupMetadataManager.updateTargetAssignment(GroupMetadataManager.java:1913)
	at org.apache.kafka.coordinator.group.GroupMetadataManager.consumerGroupHeartbeat(GroupMetadataManager.java:1518)
	at org.apache.kafka.coordinator.group.GroupMetadataManager.consumerGroupHeartbeat(GroupMetadataManager.java:2254)
	at org.apache.kafka.coordinator.group.GroupCoordinatorShard.consumerGroupHeartbeat(GroupCoordinatorShard.java:308)
	at org.apache.kafka.coordinator.group.GroupCoordinatorService.lambda$consumerGroupHeartbeat$0(GroupCoordinatorService.java:298)
	at org.apache.kafka.coordinator.group.runtime.CoordinatorRuntime$CoordinatorWriteEvent.lambda$run$0(CoordinatorRuntime.java:769)
	at org.apache.kafka.coordinator.group.runtime.CoordinatorRuntime.withActiveContextOrThrow(CoordinatorRuntime.java:1582)
	at org.apache.kafka.coordinator.group.runtime.CoordinatorRuntime.access$1400(CoordinatorRuntime.java:96)
	at org.apache.kafka.coordinator.group.runtime.CoordinatorRuntime$CoordinatorWriteEvent.run(CoordinatorRuntime.java:767)
	at org.apache.kafka.coordinator.group.runtime.MultiThreadedEventProcessor$EventProcessorThread.handleEvents(MultiThreadedEventProcessor.java:144)
	at org.apache.kafka.coordinator.group.runtime.MultiThreadedEventProcessor$EventProcessorThread.run(MultiThreadedEventProcessor.java:176) 
```

Reviewers: Lianet Magrans <lianetmr@gmail.com>, Justine Olshan <jolshan@confluent.io>",2024-06-11 11:43:56,David Jacot,Mixed
8b6013f851fec537401f29769be5608c2d246747,"KAFKA-15045: (KIP-924 pt. 21) UUID to ProcessId migration (#16269)

This PR changes the assignment process to use ProcessId instead of UUID.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2024-06-11 12:24:44,Antoine Pourchet,Mixed
23fe71d579f84d59ebfe6d5a29e688315cec1285,"KAFKA-15265: Integrate RLMQuotaManager for throttling copies to remote storage (#15820)

- Added the integration of the quota manager to throttle copy requests to the remote storage. Reference KIP-956
- Added unit-tests for the copy throttling logic.

Reviewers: Satish Duggana <satishd@apache.org>, Luke Chen <showuon@gmail.com>, Kamal Chandraprakash<kamal.chandraprakash@gmail.com>",2024-06-12 06:27:02,Abhijeet Kumar,Mixed
0782232fbeb6313a316b930d12508d1d6148f3c9,"KAFKA-15045: (KIP-924 pt. 22) Add RackAwareOptimizationParams and other minor TaskAssignmentUtils changes (#16294)

We now provide a way to more easily customize the rack aware
optimizations that we provide by way of a configuration class called
RackAwareOptimizationParams.

We also simplified the APIs for the optimizeXYZ utility functions since
they were mutating the inputs anyway.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2024-06-11 21:31:43,Antoine Pourchet,Mixed
39ffdea6d321ef3dd5e787aef1b1102c33448c0f,"KAFKA-10199: Enable state updater by default (#16107)

We have already enabled the state updater by default once.
However, we ran into issues that forced us to disable it again.
We think that we fixed those issues. So we want to enable the
state updater again by default.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2024-06-12 07:51:38,Bruno Cadonna,Not TDD
638844f833b165d6f9ca52c173858d26b7254fac,"KAFKA-16770; [2/2] Coalesce records into bigger batches (#16215)

This patch is the continuation of https://github.com/apache/kafka/pull/15964. It introduces the records coalescing to the CoordinatorRuntime. It also introduces a new configuration `group.coordinator.append.linger.ms` which allows administrators to chose the linger time or disable it with zero. The new configuration defaults to 10ms.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2024-06-11 23:29:50,David Jacot,Mixed
b5fb6543a202f826461d5074ef0ea8f6022566e0,"KAFKA-15265: Dynamic broker configs for remote fetch/copy quotas (#16078)

Reviewers: Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Satish Duggana <satishd@apache.org>",2024-06-12 19:47:46,Abhijeet Kumar,Mixed
79b9c44acdbc8c3618bc61a6268791412593bf74,"KAFKA-10787 Apply spotless to connect module (#16299)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-12 22:19:47,gongxuanzhang,Mixed
46eb0814f63236fa3c3532975ba76180485933fb,"KAFKA-10787 Apply spotless to log4j-appender, trogdor, jmh-benchmarks, examples, shell and generator (#16296)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-12 22:23:39,gongxuanzhang,Mixed
9368ef81b5cc6ce149979ff916c14709d1f2e491,"KAFKA-16865: Add IncludeTopicAuthorizedOperations option for DescribeTopicPartitionsRequest (#16136)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>, Calvin Liu <caliu@confluent.io>, Andrew Schofield <andrew_schofield@live.com>, Apoorv Mittal <amittal@confluent.io>",2024-06-12 17:04:24,Gantigmaa Selenge,Mixed
615e6e705c6fe56d1badcd7e85581efd6abb75c6,"KAFKA-16570 FenceProducers API returns ""unexpected error"" when succes… (#16229)

KAFKA-16570 FenceProducers API returns ""unexpected error"" when successful

* Client handling of ConcurrentTransactionsException as retriable
* Unit test
* Integration test

Reviewers: Chris Egerton <chrise@aiven.io>, Justine Olshan <jolshan@confluent.io>",2024-06-12 17:07:33,Edoardo Comar,Mixed
dd755b7ea95b3f9c277d9778d6624ab05407cac6,"KAFKA-8206: KIP-899: Allow client to rebootstrap  (#13277)

This commit implements KIP-899: Allow producer and consumer clients to rebootstrap. It introduces the new setting `metadata.recovery.strategy`, applicable to all the types of clients.

Reviewers: Greg Harris <gharris1727@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2024-06-12 20:48:32,Ivan Yurchenko,Mixed
16e2b68b73426fc6b77efa9a820afadc9b412627,"KAFKA-15045: (KIP-924 pt. 23) More TaskAssignmentUtils tests (#16292)

Also moved the assignment validation test from StreamsPartitionAssignorTest to TaskAssignmentUtilsTest.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2024-06-12 14:25:47,Antoine Pourchet,Mixed
cf5a86b654fd0be0c15bd47ca711bcea75d9d800,"KAFKA-16890: Compute valid log-start-offset when deleting overlapping remote segments (#16237)

The listRemoteLogSegments returns the metadata list sorted by the start-offset. However, the returned metadata list contains all the uploaded segment information including the duplicate and overlapping remote-log-segments. The reason for duplicate/overlapping remote-log-segments cases is explained [here](https://github.com/apache/kafka/blob/trunk/storage/src/main/java/org/apache/kafka/server/log/remote/metadata/storage/RemoteLogLeaderEpochState.java#L103).

The list returned by the RLMM#listRemoteLogSegments can contain the duplicate segment metadata at the end of the list. So, while computing the next log-start-offset we should take the maximum of segments (end-offset + 1).

Reviewers: Satish Duggana <satishd@apache.org>",2024-06-13 05:18:30,Kamal Chandraprakash,Mixed
e76e1da5ea5cca0df90880481ee092b1766831c4,"KAFKA-16935: Automatically wait for cluster startup in embedded Connect integration tests (#16288)

Reviewers: Greg Harris <gharris1727@gmail.com>",2024-06-12 20:18:23,Chris Egerton,Not TDD
fe988889600dfb8145d2fb4de319630bf1cad314,"MINOR: Improving log for outstanding requests on close and cleanup (#16304)

Reviewers: Andrew Schofield <aschofield@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-06-13 14:31:16,Lianet Magrans,Mixed
e59c887bfd5b7bdb9e1407d70e24d9706e930618,"KAFKA-16557 Implemented OffsetFetchRequestState toStringBase and added a test for it (#16291)

Reviewers: Lianet Magrans <lianetmr@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-06-13 15:30:05,brenden20,Mixed
103ff5c0f06a35c725c87d534ad591e9e95534ff,"KAFKA-15045: (KIP-924 pt. 24) internal TaskAssignor rename to LegacyTaskAssignor (#16318)

Since the new public API for TaskAssignor shared a name, this rename will prevent users from confusing the internal definition with the public one.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2024-06-13 00:32:39,Antoine Pourchet,Mixed
596b94507244114fdf9e44711fe56505885188ab,"KAFKA-16643 Add ModifierOrder checkstyle rule (#15890)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-13 15:39:32,gongxuanzhang,Mixed
ea606665139a8c7ff3ba4a85e0e99314403729fd,"KAFKA-16921 [1/N] Migrate all junit 4 code to junit 5 for connect module (#16253)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-13 16:11:37,Ken Huang,Not TDD
11c85a93c3f38f467e6da393b82dab51750d2701,"MINOR: Make online downgrade failure logs less noisy and update the timeouts scheduled in `convertToConsumerGroup` (#16290)

This patch: 
- changes the order of the checks in `validateOnlineDowngrade`, so that only when the last member using the consumer protocol leave and the group still has classic member(s), `online downgrade is disabled` is logged if the policy doesn't allow downgrade.
- changes the session timeout in `convertToConsumerGroup` from `consumerGroupSessionTimeoutMs` to `member.classicProtocolSessionTimeout().get()`.

Reviewers: David Jacot <djacot@confluent.io>",2024-06-13 02:11:01,Dongnuo Lyu,Mixed
4333af5c9f89e5e8bfd67f4919fe2958484f6a22,"KAFKA-15045: (KIP-924 pt. 25) Rename old internal StickyTaskAssignor to LegacyStickyTaskAssignor (#16322)

To avoid confusion in 3.8/until we fully remove all the old task assignors and internal config, we should rename the old internal assignor classes like the StickyTaskAssignor so that they won't be mixed up with the new version of the assignor (which is also named StickyTaskAssignor)

Reviewers: Bruno Cadonna <cadonna@apache.org>, Josep Prat <josep.prat@aiven.io>",2024-06-13 11:27:50,A. Sophie Blee-Goldman,Mixed
6af937639da5bb6942a2964fe3a83611d274cd8d,"KAFKA-16076 Fix Missing thread interrupt call in RestClient class  (#16282)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-14 08:07:13,abhi-ksolves,Mixed
133f2b0f311ba1fd5a999f477bad38370c1772ca,"KAFKA-16879 SystemTime should use singleton mode (#16266)

Reviewers: Greg Harris <gharris1727@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-06-14 08:49:19,dujian0068,Not TDD
a5c71bd6cbf5b94076dedcd9bf5c655772bead43,"KAFKA-16948: Reset tier lag metrics on becoming follower (#16321)

When the node transitions from a leader to a follower for a partition, then the tier-lag metrics should be reset to zero. Otherwise, it would lead to false positive in metrics. Addressed the concurrency issue while emitting the metrics.

Reviewers: Satish Duggana <satishd@apache.org>, Francois Visconte <f.visconte@gmail.com>,",2024-06-14 09:50:12,Kamal Chandraprakash,Mixed
6d9ef0e12ab8dc63611cb100a0d610c5c000478c,"KAFKA-10787 Apply spotless to `group-coordinator` and `group-coordinator-api`  (#16298)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-14 12:46:28,gongxuanzhang,Mixed
1565d41cd740b62d5543e9c94c023b37ca4303a9,"KAFKA-16752: Implemented acquire functionality for Fetch (KIP-932) (#16274)

The implementation for share-fetch next-fetch-offset in share partition and acquiring records from log.

The Next Fetch Offset (NFO) determines where the Share Partition should initiate the next data read from the Replica Manager. While it typically aligns with the last offset of the most recently returned batch, last offset + 1, there are exceptions. Messages marked available again due to release acknowledgements or lock timeouts can cause the NFO to shift.

The acquire method caches the batches as acquired in-memory and spawns a timer task for lock timeout.

Cache
Per-offset Metadata: Simple to implement but inefficient. Every offset requires in-memory storage and traversal, leading to high memory usage and processing overhead, especially for per-batch acknowledgements (mostly the way records would be acknowledged).

Per-Replica Fetch Batch: This approach aligns with the Replica Manager fetch batches. Since a full Replica Manager batch is retrieved whenever the requested offset falls within that batch's boundaries, a single Share Fetch request will likely receive an entire Replica Manager batch. However, there's a trade-off. Replica Manager batches are based on producer batching. If producers don't batch effectively, the in-flight metadata becomes heavily reliant on the producer's batching behavior.

For per-message acknowledgements, per-offset tracking will be necessary which again requires splitting in-flight batches based on state. Splitting bacthes is inefficient as it requires cache update wshich maintains sorted order. Therefore, we propose a hybrid approach:

Implemented a combination of option 2 (per-in-flight batch tracking) with option 1 (per-offset tracking). This aligns well with Replica Manager batching.

States shall be maintained per in-flight batch. If state inconsistencies arise within in-flight batches due to per-message acknowledgements, switch state tracking for the respective batch to option 1 (per-offset tracking).


Reviewers:  Andrew Schofield <aschofield@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>, Abhinav Dixit <144765188+adixitconfluent@users.noreply.github.com>",2024-06-14 10:31:56,Apoorv Mittal,Mixed
46714dbaed066e8d482d4976259bdc500c97cc47,"KAFKA-16933: New consumer unsubscribe close commit fixes (#16272)

Fixes for the leave group flow (unsubscribe/close):

Fix to send Heartbeat to leave group on close even if the callbacks fail
fix to ensure that if a member gets fenced while blocked on callbacks (ex. on unsubscribe), it will clear its epoch to not include it in commit requests
fix to avoid race on the subscription state object on unsubscribe, updating it only on the background thread when the callbacks to leave complete (success or failure).
Also improving logging in this area.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>, Philip Nee <pnee@confluent.io>",2024-06-14 13:03:58,Lianet Magrans,Mixed
8f6e0513df2c1f97179fd5cc593bee9c1d078356,"KAFKA-16747: Implemented share sessions and contexts for share fetch requests (#16263)

About

KIP-932 introduces share sessions for share groups. This PR implements share sessions and contexts for incoming share fetch requests on broker. The changes include:

Defined CachedSharePartition class which are stored in share sessions.
Defined ShareSessionKey, ShareSession classes.
Defined ShareSessionCache class which caches all the share sessions and has evict policy defined as per KIP-932

Defined the 2 types of contexts -
a. ShareSessionContext - for share session fetch request.
b. FinalContext - for final share fetch request (epoch = -1).

Defined newContext function which returns the created/updated context on receiving share fetch request on broker.

Testing
The added code has been tested with the help of unit tests present in the PR.

Reviewers:  Andrew Schofield <aschofield@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>, Apoorv Mittal <apoorvmittal10@gmail.com>",2024-06-14 16:55:27,Abhinav Dixit,Mixed
e99da2446c275c06521ddd24b38799fd6565414a,"KAFKA-15853: Move KafkaConfig.configDef out of core (#16116)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-06-14 17:26:00,Omnia Ibrahim,Mixed
4e2f26bfc66367877c41149f1205d301b5bef932,"KAFKA-16917 DescribeTopicsResult should use mutable map in order to keep compatibility (#16250)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-14 23:48:35,"TingIāu ""Ting"" Kì",Mixed
8682334b6ad6f2eb5c2d2741e549839dd2f7fd28,"KAFKA-16921 [2/N] migrate connect module to junit 5 (#16328)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-15 00:25:41,PoAn Yang,Not TDD
09bc5be63e16aaf19e2325099c9c6b5c07f4606f,"KAFKA-16946: Utils.getHost/getPort cannot parse SASL_PLAINTEXT://host:port (#16319)

In previous PR(#16048), I mistakenly excluded the underscore (_) from the set of valid characters for the protocol,
resulting in the inability to correctly parse the connection string for SASL_PLAINTEXT. This bug fix addresses the
issue and includes corresponding tests.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Luke Chen <showuon@gmail.com>",2024-06-14 13:07:11,"TingIāu ""Ting"" Kì",Mixed
8f86b9c4ec04c235bb8198bec734cfff13f97bbc,"KAFKA-16637 AsyncKafkaConsumer removes offset fetch responses from cache too aggressively (#16310)

Allow the committed offsets fetch to run for as long as needed. This handles the case where a user invokes Consumer.poll() with a very small timeout (including zero).

Reviewers: Andrew Schofield <aschofield@confluent.io>, Lianet Magrans <lianetmr@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-06-15 08:48:53,Kirk True,Mixed
817da3fb5d6d89a786b02448b3503f3afbef56ca,"KAFKA-16895 fix off-by-one bug in RemoteCopyLagSegments (#16210)

Reviewers: Kamal Chandraprakash <kchandraprakash@uber.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-06-15 09:10:25,Francois Visconte,Mixed
d239dde8f61849b91605844ffba5108eeacdf73b,"KAFKA-10787 Apply spotless to raft module (#16278)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-15 11:28:36,gongxuanzhang,Mixed
3a9d877686d0b330a2ab4b8191bbaf90c227d9d9,"MINOR: refactor BuiltInPartitioner to remove mockRandom from production code (#16277)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-15 12:18:42,gongxuanzhang,Mixed
adee6bae45e728f8e2ae1ec8a7232c64ff7c0426,"KAFKA-16740: Added additional APIs for Share Partition (#16340)

Added additional APIs for SharePartition which shall be used by SharePartitionManager.

The lock API on SharePartition helps not issuing concurrent fetch request on replica manager for same SharePartition. The updateCacheAndOffsets API helps to update the cache and corresponding offsets when an exception is encountered in SharePartitionManager because of movement of Log Start Offset.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2024-06-15 12:25:05,Apoorv Mittal,Mixed
fecbfb813322a28e037ba6de5ae3e89e06206820,"KAFKA-16950: Define Persister interfaces and RPCs (#16335)

Define the interfaces and RPCs for share-group persistence. (KIP-932). This PR is just RPCs and interfaces to allow building of the broker components which depend upon them. The implementation will follow in subsequent PRs.

Reviewers:  Manikumar Reddy <manikumar.reddy@gmail.com>, Apoorv Mittal <apoorvmittal10@gmail.com>",2024-06-15 20:52:49,Andrew Schofield,Not TDD
4e846038a6313e28d3b3ee3d3c3163d1f26356bf,"KAFKA-10787 Apply spotless to `metadata` and `server` and `storage`  module (#16297)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-16 05:28:50,gongxuanzhang,Mixed
9c7d81b43662eb1af53508566206ffcc26b47e16,"KAFKA-10190 Set dynamic broker configs for entity default (#16280)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-17 13:53:13,Harry Fallows,Not TDD
21d60eabab8a14c8002611c65e092338bf584314,"KAFKA-16673; Simplify `GroupMetadataManager#toTopicPartitions` by using `ConsumerProtocolSubscription` instead of `ConsumerPartitionAssignor.Subscription` (#16309)

In `GroupMetadataManager#toTopicPartitions`, we generate a list of `ConsumerGroupHeartbeatRequestData.TopicPartitions` from the input deserialized subscription. Currently the input subscription is `ConsumerPartitionAssignor.Subscription`, where the topic partitions are stored as (topic-partition) pairs, whereas in `ConsumerGroupHeartbeatRequestData.TopicPartitions`, we need the topic partitions to be stored as (topic-partition list) pairs.

`ConsumerProtocolSubscription` is an intermediate data structure in the deserialization where the topic partitions are stored as (topic-partition list) pairs. This pr uses `ConsumerProtocolSubscription` instead as the input subscription to make `toTopicPartitions` more efficient. 

Reviewers: David Jacot <djacot@confluent.io>",2024-06-17 02:47:52,Dongnuo Lyu,Mixed
09b4ef416aa54a4e65b297f7e6b47a04e88556f5,"KAFKA-10787 Apply spotless to `stream:test-utils` and `:streams:upgrade-system-tests-xxxx`  (#16357)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-17 19:48:44,gongxuanzhang,Not TDD
92d8d4bd1f05a7a5c19e4dfe5c53de33e282ec9c,"KAFKA-16970 Fix hash implementation of `ScramCredentialValue`, `ScramCredentialData`, and `ContextualRecord` (#16359)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-17 22:29:22,"TingIāu ""Ting"" Kì",Mixed
1a7ba667ad733806c0d6c194a6c69ab5fcc8e3b3,"MINOR improve startup log in QuorumController (#15926)

Reviewers: David Arthur <mumrah@gmail.com>",2024-06-17 11:04:12,ChickenchickenLove,Mixed
6c4e77707978a43a2994de013335d71bc063ff38,"KAFKA-16954: fix consumer close to release assignment in background (#16343)

This PR fixes consumer close to avoid updating the subscription state object in the app thread. Now the close simply triggers an UnsubscribeEvent that is handled in the background to trigger callbacks, clear assignment, and send leave heartbeat. Note that after triggering the event, the unsubscribe will continuously process background events until the event completes, to ensure that it allows for callbacks to run in the app thread.
The logic around what happens if the unsubscribe fails remain unchanged: close will log, keep the first exception and carry on.

It also removes the redundant LeaveOnClose event (it used to do the the exact same thing as the UnsubscribeEvent, both calling membershipMgr.leaveGroup).

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-06-17 21:27:33,Lianet Magrans,Mixed
ceab1fe658eff6345dd0520d515d11411b0b8087,"KAFKA-16969: Log error if config conficts with MV (#16366)

When broker configuration is incompatible with the current Metadata Version the Broker should log an error-level message but avoid shutting down.

Reviewers: Luke Chen <showuon@gmail.com>",2024-06-18 11:10:34,Igor Soarez,Mixed
8abeaf3cb495bb4bf05e11c1be45967d6e4730f8,"KAFKA-15265: Reapply dynamic remote configs after broker restart (#16353)

The below remote log configs can be configured dynamically:
1. remote.log.manager.copy.max.bytes.per.second
2. remote.log.manager.fetch.max.bytes.per.second and
3. remote.log.index.file.cache.total.size.bytes

If those values are configured dynamically, then during the broker restart, it ensures the dynamic values are loaded instead of the static values from the config.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Satish Duggana <satishd@apache.org>, Luke Chen <showuon@gmail.com>",2024-06-18 09:39:35,Kamal Chandraprakash,Mixed
3a3f9ce48e59fafefd8b3fae50e5d8428b6bb4f0,"KAFKA-16921 [4/N] Migrate test of connect module to Junit5 (Runtime direct) (#16351)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-18 18:09:40,gongxuanzhang,Not TDD
5a331acad02df254db29b3b619a11528883da979,"KAFKA-10787 apply spotless to `streams:examples` and `streams-scala` (#16378)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-18 18:56:46,gongxuanzhang,Mixed
2fd00ce53678509c9f2cfedb428e37a871e3d530,"KAFKA-16952: Do not bump broker epoch when re-registering the same incarnation (#16333)

* KAFKA-16952: Do not bump broker epoch when re-registering the same incarnation

As part of KIP-858 (Handle JBOD broker disk failure in KRaft), we added some code that caused the
broker to re-register itself when transitioning from a MetadataVersion that did not support broker
directory IDs, to one that did. This code was necessary because otherwise the controller would not
be aware of what directories the broker held.

However, prior to this PR, the re-registration process acted exactly like a full registration. That
is, it bumped the broker epoch (which is meant to only be bumped on broker restart). This PR fixes
the code to keep the broker epoch the same if the incarnation ID is the same.

There are some other minor improvements here:

- The previous logic relied on a complicated combination of request version and previous broker
  epoch to understand if the request came from the same broker or not. This is not needed: either
  the incarnation ID is the same and it's the same process, or it is not and it isn't.

- We now log whether we're amending a registration, registering a previously unknown broker, or
  replacing a previous registration.

- Move changes to the HeartbeatManager to the end of the function, so that we will not do them if
  any validation step fails. Log4j messages are also generated at the end, for the same reason.

Reviewers: Ron Dagostino <rndgstn@gmail.com>",2024-06-18 07:03:15,Colin Patrick McCabe,Mixed
8199290500980b5a469a463dab6050a314c1529e,"MINOR: consumer log fixes (#16345)

Reviewers: Kirk True <kirk@kirktrue.pro>, Chia-Ping Tsai <chia7712@gmail.com>",2024-06-18 22:51:33,Lianet Magrans,Mixed
c4a3d2475f740033b71a32973286c6b411f4d19e,"MINOR: Refresh of the docs (#16375)


Reviewers: Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-06-18 17:15:47,Mickael Maison,Mixed
f2a552a1ebaa0ce933f90343655b63e2472856d9,"KAFKA-16753: Implement share acknowledge API in partition (KIP-932) (#16339)

The share-partition leader keeps track of the state and delivery attempts for in-flight records. However, delivery attempts tracking follows atleast-once semantics.

The consumer processes the records and acknowledges them upon successful consumption. This successful attempt triggers a transition to the ""Acknowledged"" state.

The code implements the functionality to acknowledge the offset/batches in the request to in-memory cached data.

Reviewers:  Andrew Schofield <aschofield@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-06-18 22:37:59,Apoorv Mittal,Mixed
96989e4b6483e2e24883de20ff2cbcd2d3b39dbf,"KAFKA-10787 Apply spotless to core module (#16392)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-19 14:24:42,gongxuanzhang,Mixed
4de6a90801e3a9d51beb22821893a85cea76ac3a,"KAFKA-16921 [6/N] Remove junit 4 dependency from connect:runtime module (#16383)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-19 14:39:16,Ken Huang,Not TDD
a0bfc64470bf90aac88d5bca793f14f8342b6edc,"KAFKA-15774: use the default dsl store supplier for fkj subscriptions (#16380)

Foreign key joins have an additional ""internal"" state store used for subscriptions, which is not exposed for configuration via Materialized or StoreBuilder which means there is no way to plug in a different store implementation via the DSL operator. However, we should respect the configured default dsl store supplier if one is configured, to allow these stores to be customized and conform to the store type selection logic used for other DSL operator stores

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2024-06-19 00:32:59,Rohan,Mixed
c0add50a991a1f9d57d9f00a8b205583a513ee92,"MINOR: Add interface for aliveBroker and isShutDwon for Brokers. (#16323)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-19 22:32:08,TaiJuWu,Not TDD
a6718dbbdbcf3c71a8a3ab9844107cd994ceec25,"KAFKA-16725: Adjust share group configs to match KIP (#16368)

A few of the share group configs in KIP-932 were defined with limits that do not match KIP-932. This PR corrects the limits.


Reviewers:  Manikumar Reddy <manikumar.reddy@gmail.com>, Apoorv Mittal <apoorvmittal10@gmail.com>",2024-06-19 21:31:29,Andrew Schofield,Mixed
26b9163487a9faf6afd78abea6b65e710ed82ed1,"KAFKA-15623 (2/N) Migrate remaining tests in streams module to JUnit 5 (integration & internals) (#16360)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-20 09:24:44,Kuan-Po (Cooper) Tseng,Not TDD
ee550c4b770402a35f2972bbbe6b75d58af8c938,"KAFKA-16973; Fix caught-up condition (#16367)

When a write operation does not have any records, the coordinator runtime checked whether the state machine is caught-up to decide whether the operation should wait until the state machine is committed up to the operation point or the operation should be completed. The current implementation assumes that there will always be a pending write operation waiting in the deferred queue when the state machine is not fully caught-up yet. This is true except when the state machine is just loaded and not caught-up yet.

This patch fixes the issue by always comparing the last written offset and the last committed offset.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-20 00:53:48,David Jacot,Mixed
80f31224aad543dbfc892bce1ad73b6bb693855a,"KAFKA-10787 Apply spotless to `clients` module  (#16393)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-20 17:43:25,gongxuanzhang,Mixed
4fe08f3b297064794d8ff0c38d537f2dd32de1e8,"KAFKA-16976 Update the current/dynamic config inside RemoteLogManagerConfig (#16394)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-20 23:33:35,Kamal Chandraprakash,Mixed
64702bcf6f883d266ccffcec458b4c3c0706ad75,"KAFKA-16862: Refactor ConsumerTaskTest to be deterministic and avoid tight loops (#16303)

Reviewers: Greg Harris <greg.harris@aiven.io>",2024-06-20 12:35:14,Wang Xiaoqing,Mixed
d646a09dd0b03e6823f6d8b65f8b5c8619826a31,"KAFKA-16531: calculate check-quorum when leader is not in voter set (#16211)

In the check-quorum calculation, the leader should not assume that it is part of the voter set. This may happen when the leader is removing itself from the voter set. This PR improves it by checking if leader is in the voter set or not, and decide how many follower fetches required. Also add tests.

Co-authored-by: Colin P. McCabe <cmccabe@apache.org>

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, José Armando García Sancio <jsancio@apache.org>",2024-06-21 11:22:24,Luke Chen,Mixed
8d925353822ea36a0db5358c17f29e910265c1e6,"KAFKA-10787 apply spotless to connect:runtime module (#16412)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-21 16:04:51,gongxuanzhang,Mixed
9b5b434e2a6b2d5290ea403fc02859b1c523d8aa,"KAFKA-16999: Integrating persister API in Partition initilization (KIP-932) (#16397)

Integrated Persister Read API while initilazing Share Partition.
The share partition checks for any pre-existing data from persister and initializes the state accordingly.

Reviewers:  Andrew Schofield <aschofield@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>, Abhinav Dixit <adixit@confluent.io>",2024-06-21 14:14:11,Apoorv Mittal,Mixed
645eefe95aa764fdcd1c6390bb2a2e8dc14cde84,"KAFKA-17007 Fix SourceAndTarget#equal (#16416)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-21 20:52:07,PoAn Yang,Mixed
7d702e17604c6cc95e4e8bfdea58b04be3f5ffc3,"KAFKA-16749: Implemented share fetch messages (KIP-932) (#16377)

Share group consumers use the ShareFetch API to retrieve messages they've claimed (acquired records) from the leader brokers of share partitions.

The replica manager provides an API to retrieve messages directly from the underlying topic partition. The implementation of the fetch messages uses replica manager to fetch messages from specific offset known by share partition leader.

The requests are sent to a queue and processed asynchronously.

Reviewers:  Andrew Schofield <aschofield@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-06-21 20:24:21,Apoorv Mittal,Mixed
7fe3374f7a6d956777b6b007300fa3fea6cf7118,"KAFKA-15713 KRaft support in AclCommandTest (#15830)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-22 21:29:23,Pavel Pozdeev,Mixed
8a109d87d1673d1540054b1202ad94789ac5cea4,"KAFKA-17009 Add unit test to query nonexistent replica by describeReplicaLogDirs (#16423)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-23 16:25:57,Ken Huang,Not TDD
fd00a3e58a5024c0f4008eb432c66fef52f38fba,"KAFKA-16998 Fix warnings in our Github actions (#16410)

Reviewers: Vedarth Sharma <vesharma@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-06-24 12:53:49,Kuan-Po (Cooper) Tseng,Not TDD
0e346d31036d06f88b0344ed7d0452460ce11c7e,"KAFKA-15623 (4/N) Migrate streams tests (processor) module to JUnit 5 (#16396)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-24 13:06:35,"TingIāu ""Ting"" Kì",Not TDD
f4cbf71ea68f5bda3afbb2d3a8411658e57516e8,"KAFKA-16965: Throw cause of TimeoutException (#16344)

Add the cause of TimeoutException for Producer send() errors.

Reviewers: Matthias J. Sax <matthias@confluent.io>,  Lianet Magrans <lianetmr@gmail.com>, Artem Livshits <alivshits@confluent.io>, Justine Olshan <jolshan@confluent.io>",2024-06-24 14:51:27,Alieh Saeedi,Mixed
3f3b070a6a239dc801d4dd83c8ee55ccf497346b,"KAFKA-16755: Implement lock timeout functionality in SharePartition (#16414)

Implemented acquisition lock timeout functionality in SharePartition. Implemented the following functions -

1. releaseAcquisitionLockOnTimeout - This function is executed when the acquisition lock timeout is reached. The function releases the acquired records.
2. releaseAcquisitionLockOnTimeoutForCompleteBatch - Function which releases acquired records due to acquisition lock timeout maintained at a batch level.
3. releaseAcquisitionLockOnTimeoutForPerOffsetBatch - Function which releases acquired records due to acquisition lock timeout maintained at an offset level.

Reviewers:  Andrew Schofield <aschofield@confluent.io>, Apoorv Mittal <apoorvmittal10@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>,",2024-06-25 12:37:28,Abhinav Dixit,Mixed
87f8147ed0ef4bfe32936bc17240eed91abc29aa,"KAFKA-16855 : Part 1 - New fields tieredEpoch and tieredState  (#16257)

Add field tieredEpoch to RemoteLogSegmentMetadata
Update relevant tests
Add two fields tieredEpoch and tieredState to TopicRecord.json

Reviewers: Luke Chen <showuon@gmail.com>, Christo Lolov <lolovc@amazon.com>",2024-06-25 15:00:12,Murali Basani,Mixed
63304fb6e5e1d754f81fe76b3da8e86c80bbdaaf,"KAFKA-17028: FindCoordinator v6 initial implementation (#16440)

KIP-932 introduces FindCoordinator v6 for finding share coordinators. The initial implementation:

Checks that share coordinators are only requested with v6 or above.
Share coordinator requests are authorized as cluster actions (this is for inter-broker use only)
Responds with COORDINATOR_NOT_AVAILABLE because share coordinators are not yet available.
When the share coordinator code is delivered, the request handling will be gated by configurations which enable share groups and the share coordinator specifically. If these are not enabled, COORDINATOR_NOT_AVAILABLE is the response.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2024-06-25 21:13:16,Andrew Schofield,Mixed
adee6f0cc11c37edaf7b47c1f77457d66e80ebe4,"KAFKA-16527; Implement request handling for updated KRaft RPCs (#16235)

Implement request handling for the updated versions of the KRaft RPCs (Fetch, FetchSnapshot, Vote,
BeginQuorumEpoch and EndQuorumEpoch). This doesn't add support for KRaft replicas to send the new
version of the KRaft RPCs. That will be implemented in KAFKA-16529.

All of the RPCs responses were extended to include the leader's endpoint for the listener of the
channel used in the request. EpochState was extended to include the leader's endpoint information
but only the FollowerState and LeaderState know the leader id and its endpoint(s).

For the Fetch request, the replica directory id was added. The leader now tracks the follower's log
end offset using both the replica id and replica directory id.

For the FetchSnapshot request, the replica directory id was added. This is not used by the KRaft
leader and it is there for consistency with Fetch and for help debugging.

For the Vote request, the replica key for both the voter (destination) and the candidate (source)
were added. The voter key is checked for consistency. The candidate key is persisted when the vote
is granted.

For the BeginQuorumEpoch request, all of the leader's endpoints are included. This is needed so
that the voters can return the leader's endpoint for all of the supported listeners.

For the EndQuorumEpoch request, all of the leader's endpoints are included. This is needed so that
the voters can return the leader's endpoint for all of the supported listeners. The successor list
has been extended to include the directory id. Receiving voters can use the entire replica key when
searching their position in the successor list.

Updated the existing test in KafkaRaftClientTest and KafkaRaftClientSnapshotTest to execute using
both the old version and new version of the RPCs.

Reviewers: Luke Chen <showuon@gmail.com>, Colin P. McCabe <cmccabe@apache.org>",2024-06-25 13:45:15,José Armando García Sancio,Mixed
93dd9acad0c7b7694ae34235ff9dd52a7a5c958b,"KAFKA-17003: Implemented SharePartitionManager close() functionality (#16431)

About
Implemented close() functionality of SharePartitionManager to avoid any chances of memory leak. The functionality will be utilized when the sharePartitionObject is closed, at the time when BrokerServer is killed.

Testing
Added unit tests to cover the new functionality added.

Reviewers:  Andrew Schofield <aschofield@confluent.io>, Apoorv Mittal <apoorvmittal10@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-06-26 17:12:01,Abhinav Dixit,Mixed
399949ebcf3815e088a62495996100f27f637ec0,"KAFKA-16751: Implemented release acquired records functionality in SharePartitionManager  (#16446)

About
Implemented releaseAcquiredRecords functionality in SharePartitionManager which will act as a bridge between the call from KafkaApis to SharePartition for releasing the acquired records when a share session gets closed.

Testing
The added function has been tested with unit tests.

Reviewers:  Andrew Schofield <aschofield@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>, Apoorv Mittal <apoorvmittal10@gmail.com>",2024-06-27 02:18:54,Abhinav Dixit,Mixed
9b4f13efbc0674ec63835ceee728f5ec62e69171,"KAFKA-15623 Remove junit 4 from stream module  (#16447)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-27 15:11:32,Ken Huang,Not TDD
49e9bd4a5ba055b7d6e9d166ca87b75e75f738fa,"KAFKA-16754: Implemented release acquired records functionality to SharePartition (#16430)

About
Implemented release acquired records functionality in SharePartition. This functionality is used when a share session gets closed, hence all the acquired records should either move to AVAILABLE or ARCHIVED state. Implemented the following functions -

1. releaseAcquiredRecords - This function is executed when the acquisition lock timeout is reached. The function releases the acquired records.
2. releaseAcquiredRecordsForCompleteBatch - Function which releases acquired records maintained at a batch level.
3. releaseAcquiredRecordsForPerOffsetBatch - Function which releases acquired records maintained at an offset level.

Testing
Added unit tests to cover the new functionality added.


Reviewers:  Andrew Schofield <aschofield@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>, Apoorv Mittal <apoorvmittal10@gmail.com>",2024-06-27 15:33:46,Abhinav Dixit,Mixed
60114a46a775e597410131dd67ac236d62f57b0c,"KAFKA-16822: Abstract consumer group to share functionality with share group (KIP-932) (#16054)

Abstracted code for 2 classes `ConsumerGroup` and `ConsumerGroupMember` to `ModernGroup` and `ModernGroupMember` respectively. The new abstract classes are created to share common functionality with `ShareGroup` and `ShareGroupMember` which are being introduced with KIP-932.

The patch is majorly code refactoring from existing classes to abstract classes. Also created a new package called `modern` where `MemberState` class is moved, in upcoming patches, I will move common classes for `Share` and `Consumer` Group in `modern` package itself. 

Reviewers: Lianet Magrans <lianetmr@gmail.com>, Andrew Schofield <aschofield@confluent.io>, David Jacot <djacot@confluent.io>",2024-06-27 05:42:58,Apoorv Mittal,Mixed
1040d783720f5d202127ec7a62946f4ec2e6ad80,"KAFKA-10787 Apply spotless to all module (#16467)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-27 20:50:06,gongxuanzhang,Mixed
ebaa108967fca35b2fce1d9052e3641046e510fd,"KAFKA-16968: Introduce 3.8-IV0, 3.9-IV0, 3.9-IV1

Create 3 new metadata versions:

- 3.8-IV0, for the upcoming 3.8 release.
- 3.9-IV0, to add support for KIP-1005.
- 3.9-IV1, as the new release vehicle for KIP-966.

Create ListOffsetRequest v9, which will be used in 3.9-IV0 to support KIP-1005. v9 is currently an unstable API version.

Reviewers: Jun Rao <junrao@gmail.com>, Justine Olshan <jolshan@confluent.io>",2024-06-27 14:03:03,Colin Patrick McCabe,Mixed
9be27e715a209a892941bf35e66859d9c39c28c4,"MINOR; Fix incompatible change to the kafka config (#16464)

Prior to KIP-853, users were not allow to enumerate listeners specified in `controller.listener.names` in the `advertised.listeners`. This decision was made in 3.3 because the `controller.quorum.voters` property is in effect the list of advertised listeners for all of the controllers.

KIP-853 is moving away from `controller.quorum.voters` in favor of a dynamic set of voters. This means that the user needs to have a way of specifying the advertised listeners for controller.

This change allows the users to specify listener names in `controller.listener.names` in `advertised.listeners`. To make this change forwards compatible (use a valid configuration from 3.8 in 3.9), the controller's advertised listeners are going to get computed by looking up the endpoint in `advertised.listeners`. If it doesn't exist, the controller will look up the endpoint in the `listeners` configuration.

This change also includes a fix the to the BeginQuorumEpoch request where the default value for VoterId was 0 instead of -1.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2024-06-27 21:24:25,José Armando García Sancio,Mixed
b0054f3a2f28ebd19045a4b8a8d356987275965b,"KAFKA-16536; Use BeginQuorumEpoch as leader heartbeat (#16399)

With KIP-853, the leader's endpoint is sent to the other voters using the BeginQuorumEpoch RPC. The remote replicas never store the leader's endpoint. That means that leaders need to resend the leader's endpoint if a voter restarts.

This change accomplishes this by sending the BeginQuorumEpoch as a heartbeat. The period is sent to the half the fetch timeout to prevent voters from transitioning to the candidate state when restarting.

Reviewers: José Armando García Sancio <jsancio@apache.org>",2024-06-28 10:27:30,Alyssa Huang,Mixed
33f5995ec379f0d18c6981106838c605ee94be7f,"MINOR: Eliminate warnings for AdminUtils#assignReplicasToBrokersRackAware (#16470)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-06-30 22:15:55,Logan Zhu,Not TDD
15a4501bded513822485dd85fa6258e16f1571ca,"KAFKA-16508: Streams custom handler should handle the timeout exceptions (#16450)

For a non-existing output topic, Kafka Streams ends up in an infinite retry loop, because the returned TimeoutException extends RetriableException.

This PR updates the error handling pass for this case and instead of retrying calls the ProductionExceptionHandler to allow breaking the infinite retry loop.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2024-06-30 11:52:36,Alieh Saeedi,Mixed
9a78122fb0b1b37961139d5c62e49fa758dc08ac,"MINOR: Refactor GroupMetadataManager#consumerGroupHeartbeat and GroupMetadataManager#classicGroupJoinToConsumerGroup (#16371)

This patch is an attempt to simplifying GroupMetadataManager#consumerGroupHeartbeat and GroupMetadataManager#classicGroupJoinToConsumerGroup by sharing more of the common logic. It slightly change how static members are replaced too. Now, we generate the records to replace the member and then we update the member if needed.

Reviewers: Dongnuo Lyu <dlyu@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Justine Olshan <jolshan@confluent.io>",2024-06-30 23:16:52,David Jacot,Mixed
206d0f809ad8438e9d89b7f731a8b995f952f0c0,"KAFKA-16909 Refactor GroupCoordinatorConfig with AbstractConfig (#16458)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-01 23:31:53,Kuan-Po (Cooper) Tseng,Mixed
e7a75805fe0f156d580683d17c226dc76aa189fa,"KAFKA-17050: Revert `group.version` (#16482)

This patch partially reverts `group.version` in trunk. I kept the `GroupVersion` class but removed it from `Features` so it is not advertised. I also kept all the changes in the test framework. I removed the logic to require `group.version=1` to enable the new consumer rebalance protocol. The new protocol is enabled based on the static configuration.

For the context, I prefer to revert it in trunk now so we don't forget to revert it in the 3.9 release. I will bring it back for the 4.0 release.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-02 07:21:18,David Jacot,Mixed
e55c28c60b0f021b12c93fa04e360ce7a2e0a5ac,"KAFKA-16750: Added acknowledge code in SharePartitionManager including unit tests (#16457)

About
This PR adds acknowledge code in SharePartitionManager. Internally, the record acknowledgements happen at the SharePartition level. SharePartitionManager identifies the SharePartitions and calls their acknowledge method to actually acknowledge the individual records

Testing
Added unit tests to cover the new functionality added in SharePartitionManagerTest

Reviewers: Apoorv Mittal <apoorvmittal10@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-07-02 22:25:14,Chirag Wadhwa,Mixed
6897b06b03917847f599c9e30897228233eee78a,"KAFKA-3346 Rename Mode to ConnectionMode (#16403)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-03 02:46:04,abhi-ksolves,Mixed
2bc5e011210d11d383fce21d070fd99d50c5a9fb,"KAFKA-17051 ApiKeys#toHtml should exclude the APIs having unstable latest version (#16480)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-03 02:52:14,Ken Huang,Mixed
f2dbc55d24ad2acea425e52161adbcfdd8c01551,"KAFKA-17047: Refactored group coordinator classes to modern package (KIP-932) (#16474)

Following the discussion and suggestion by @dajac, https://github.com/apache/kafka/pull/16054#discussion_r1613638293, the PR refactors the common classes to build TargetAssignment in `modern` package. `consumer` package has been moved inside `modern` package with classes exclusive to `consumer group`.

This PR completes the refactoring and base to introduce `share` package inside `modern`. The subsequent PRs will define the implementation specific to Share Groups while re-using the common functionality from `modern` package classes. 

Reviewers: Andrew Schofield <aschofield@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>",2024-07-03 00:16:40,Apoorv Mittal,Mixed
b2da186f21490ddf9922a7ad834e830deee1f7a8,"KAFKA-15265: Remote fetch throttle metrics (#16087)

As part of [KIP-956](https://cwiki.apache.org/confluence/display/KAFKA/KIP-956+Tiered+Storage+Quotas), we have added quota for remote fetches from remote storage. In this PR, we are adding the following metrics for remote fetch throttling.

remote-fetch-throttle-time-avg : The average time in millis remote fetches was throttled by a broker 
remote-fetch-throttle-time-max : The max time in millis remote fetches was throttled by a broker

Reviewers: Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Luke Chen <showuon@gmail.com>, Satish Duggana <satishd@apache.org>",2024-07-03 14:11:18,Abhijeet Kumar,Mixed
35baa0ac4fcb7f21bb0df037d0756429db5d3bb2,"KAFKA-17026: Implement updateCacheAndOffsets functionality on LSO movement (#16459)

Implemented the functionality which takes care of archiving the records when LSO moves past them. Implemented the following functions -

1. updateCacheAndOffsets - Updates the cached state, start and end offsets of the share partition as per the new log start offset. The method is called when the log start offset is moved for the share partition.
2. archiveAvailableRecordsOnLsoMovement - This function archives all the available records when they are behind the LSO.
3. archivePerOffsetBatchRecords - It archives all the available records in the per offset tracked batch passed to this function.
4. archiveCompleteBatch - It archives all the available records of the complete batch passed to this function.

Reviewers:  Andrew Schofield <aschofield@confluent.io>,Apoorv Mittal <apoorvmittal10@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-07-03 16:01:44,Abhinav Dixit,Mixed
e93242283d1b7c4855e97009adc130373e7bbec7,"KAFKA-15917: Wait for zombie sink tasks' consumers to commit offsets before trying to modify their offsets in integration tests (#15302)

Reviewers: Yash Mayya <yash.mayya@gmail.com>, Greg Harris <greg.harris@aiven.io>",2024-07-03 10:25:23,Chris Egerton,Not TDD
ae192bdd41a6058a889dcf0bc961dceb3631a4a6,"KAFKA-16754: Removing partitions from release API (KIP-932) (#16513)

The release API exposed Partitions which should be an internal implementation detail for releaseAcquiredRecords API. Also lessen the scope for cached topic partitions method as it's not needed.


Reviewers:  Andrew Schofield <aschofield@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>, Abhinav Dixit <adixit@confluent.io>",2024-07-03 20:19:03,Apoorv Mittal,Mixed
27220d146c5d043da4adc3d636036bd6e7b112d2,"KAFKA-10816: Add health check endpoint for Kafka Connect (#16477)

Reviewers: Greg Harris <gharris1727@gmail.com>",2024-07-03 14:15:15,Chris Egerton,Mixed
9f7afafefe5e918a6f88c1d7f27aeb7755155133,"KAFKA-16529; Implement raft response handling (#16454)

This change implements response handling for the new version of Vote, Fetch, FetchSnapshot, BeginQuorumEpoch and EndQuorumEpoch. All of these responses were extended to include the leader's endpoint when the leader is known.

This change also includes sending the new version of the requests for Vote, Fetch, FetchSnapshot, BeginQuorumEpoch and EndQuorumEpoch. The two most notable changes are that:
1.  The leader is going to include all of its endpoints in the BeginQuorumEpoch and EndQuorumEpoch requests.
2. The replica is going to include the destination replica key for the Vote and BeginQuorumEpoch request.

QuorumState was extended so that the replica transitions to UnattachedState instead of FollowerState during startup, if the leader is known but the leader's endpoint is not known. This can happen if the known leader is not part of the voter set replicated by the replica. The expectation is that the replica will rediscover the leader from Fetch responses from the bootstrap servers or from the BeginQuorumEpoch request from the leader.

To make sure that replicas never forget the leader of a given epoch the unattached state was extended to allow an optional leader id for when the leader is known but the leader's endpoint is not known.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2024-07-03 16:52:35,José Armando García Sancio,Mixed
641469e4ac15fafc362dab5aa5db49979782d5f0,"KAFKA-17069: Remote log copy throttle metrics (#16086)

As part of KIP-956, we have added quota for remote copies to remote storage. In this PR, we are adding the following metrics for remote copy throttling.
1. remote-copy-throttle-time-avg 	The average time in millis remote copies was throttled by a broker
2. remote-copy-throttle-time-max 	The max time in millis remote copies was throttled by a broker

Added unit test for the metrics.

Reviewers: Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Luke Chen <showuon@gmail.com>, Satish Duggana <satishd@apache.org>",2024-07-04 12:27:59,Abhijeet Kumar,Mixed
efe7ccaf772a23e73f10a8731202025f05f40ea9,"KAFKA-17058; Extend CoordinatorRuntime to support non-atomic writes (#16498)

The group coordinator has (internal) write operations that could generate a large number of records (e.g. expiring offsets and groups). At the moment, those operations are limited by the maximum message size. If they hit it, they are basically stuck forever. This patch extends the CoordinatorRuntime to support non-atomic writes and it changes those internal operations to be non-atomic.

Reviewers: Dongnuo Lyu <dlyu@confluent.io>, Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>",2024-07-04 04:51:08,David Jacot,Mixed
e0dcfa7b51f82264af9d4a656ef577ae00c0cd45,"KAFKA-16741: Add share group classes for Heartbeat API (1/N) (KIP-932) (#16516)

Defined share group, member and sinmple assignor classes with API definition for Share Group Heartbeat and Describe API.

The ShareGroup and ShareGroupMember extends the common ModernGroup and ModernGroupMember respectively.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-07-04 20:31:47,Apoorv Mittal,Mixed
42f267a853734effc7aff24e30ec812aba84f834,"KAFKA-16944; Rewrite Range Assignor (#16504)

The server side range assignor was made to be sticky i.e. partitions from the existing assignment are retained as much as possible. During a rebalance, the expected behavior is to achieve co-partitioning for members that are subscribed to the same set of topics with equal number of partitions.

However, there are cases where this cannot be achieved efficiently with the current algorithm. There is no easy way to implement stickiness and co-partitioning and hence we have resorted to recomputing the target assignment every time.

In case of static membership, instanceIds are leveraged to ensure some form of stickiness.

```
Benchmark                                       (assignmentType)  (assignorType)  (isRackAware)  (memberCount)  (partitionsToMemberRatio)  (subscriptionType)  (topicCount)  Mode  Cnt    Score    Error  Units
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false            100                         10         HOMOGENEOUS           100  avgt    5    0.052 ±  0.001  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false            100                         10         HOMOGENEOUS          1000  avgt    5    0.454 ±  0.003  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false           1000                         10         HOMOGENEOUS           100  avgt    5    0.476 ±  0.046  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false           1000                         10         HOMOGENEOUS          1000  avgt    5    3.102 ±  0.055  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false          10000                         10         HOMOGENEOUS           100  avgt    5    5.640 ±  0.223  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false          10000                         10         HOMOGENEOUS          1000  avgt    5   37.947 ±  1.000  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false            100                         10       HETEROGENEOUS           100  avgt    5    0.172 ±  0.001  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false            100                         10       HETEROGENEOUS          1000  avgt    5    1.882 ±  0.006  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false           1000                         10       HETEROGENEOUS           100  avgt    5    1.730 ±  0.036  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false           1000                         10       HETEROGENEOUS          1000  avgt    5   17.654 ±  1.160  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false          10000                         10       HETEROGENEOUS           100  avgt    5   18.595 ±  0.316  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false          10000                         10       HETEROGENEOUS          1000  avgt    5  172.398 ±  2.251  ms/op
JMH benchmarks done

Benchmark                                     (memberCount)  (partitionsToMemberRatio)  (topicCount)  Mode  Cnt   Score   Error  Units
TargetAssignmentBuilderBenchmark.build                  100                         10           100  avgt    5   0.071 ± 0.004  ms/op
TargetAssignmentBuilderBenchmark.build                  100                         10          1000  avgt    5   0.428 ± 0.026  ms/op
TargetAssignmentBuilderBenchmark.build                 1000                         10           100  avgt    5   0.659 ± 0.028  ms/op
TargetAssignmentBuilderBenchmark.build                 1000                         10          1000  avgt    5   3.346 ± 0.102  ms/op
TargetAssignmentBuilderBenchmark.build                10000                         10           100  avgt    5   8.947 ± 0.386  ms/op
TargetAssignmentBuilderBenchmark.build                10000                         10          1000  avgt    5  40.240 ± 3.113  ms/op
JMH benchmarks done
```

Reviewers: David Jacot <djacot@confluent.io>",2024-07-04 10:33:09,Ritika Reddy,Mixed
376365d9da8099e3eb9175090cc456f55985fcb0,"MINOR; Add property methods to LogOffsetMetadata (#16521)

This change simply adds property methods to LogOffsetMetadata. It
changes all of the callers to use the new property methods instead of
using the fields directly.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2024-07-04 15:03:32,José Armando García Sancio,Mixed
4a49a1249d6a2e4523e1d63f8c4f95761df32263,"KAFKA-17059 Remove `dynamicConfigOverride` from KafkaConfig (#16523)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-05 07:11:02,"TingIāu ""Ting"" Kì",Not TDD
79244fe2353107a4c0a96ce034c7e38293778314,"KAFKA-13403 Fix broker crash due to race condition when deleting topics (#11438)

Update the walkFileTree override implementation to handle parallel file deletion.
So as to prevent crashing of Kafka broker process when logs are deleted by
other threads due to retention expiry.

Reviewers: Luke Chen <showuon@gmail.com>, Divij Vaidya <diviv@amazon.com>, Igor Soarez <soarez@apple.com>",2024-07-06 08:18:35,Arun Mathew,Mixed
932759bd70ce646ced5298a2ad8db02c0cea3643,"KAFKA-16731: Added share group metrics class. (#16488)

Added ShareGroupMetrics inner class to SharePartitionManager.
Added code to record metrics at various checkpoints in code.

Reviewers:  Andrew Schofield <aschofield@confluent.io>,Apoorv Mittal <apoorvmittal10@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-07-07 17:51:13,Sushant Mahajan,Mixed
d45596a2a1f001529ebb5b16f3e33e60a1d41703,"MINOR: Move related getters to RemoteLogManagerConfig (#16538)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-08 01:00:42,Kuan-Po Tseng,Mixed
a533e246e3ed5f6f6c5be4ebf9d29ae75cab557e,"KAFKA-17081 Tweak GroupCoordinatorConfig: re-introduce local attributes and validation (#16524)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-08 01:15:18,Kuan-Po Tseng,Mixed
e2ec389a7c6570e673c070a0b0ba7f6f21bd2b53,"KAFKA-15838: KIP-1040: Add replace.null.with.default to InsertField, ExtractField, HeaderFrom, Cast, SetSchemaMetadata, TimestampConverter, MaskField transforms (#15756)

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Greg Harris <greg.harris@aiven.io>",2024-07-08 11:09:54,Fiore Mario Vitale,Mixed
25230b538841a5e7256b1b51725361dd59435901,"KAFKA-10199: Close pending active tasks to init on partitions lost (#16545) (#16550)

With enabled state updater tasks that are created but not initialized
are stored in a set. In each poll iteration the stream thread drains
that set, intializes the tasks, and adds them to the state updater.

On partition lost, all active tasks are closed.

This commit ensures that active tasks pending initialization in
the set mentioned above are closed cleanly on partition lost.

Reviewer: Lucas Brutschy <lbrutschy@confluent.io>",2024-07-08 21:14:15,Bruno Cadonna,Mixed
67e68596329df1d990310f02767a47512a44d568,"KAFKA-17071: SharePartition - Add more unit tests and minor enhancement (#16530)

The PR contains the following -

1. Added minor enhancement to not have a write state RPC call in case we have 0 states to be updated.
2. Removed unutilized function deliveryCount()
3. Added more unit tests covering functionalities across SharePartition.java

Reviewers:  Andrew Schofield <aschofield@confluent.io>, Apoorv Mittal <apoorvmittal10@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-07-09 11:45:15,Abhinav Dixit,Mixed
0781151794c8468e686b75cdd8ae0b6d16399cdf,"KAFKA-16254: Allow MM2 to fully disable offset sync feature (#15999)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chris Egerton <fearthecellos@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>, Igor Soarez <soarez@apple.com>",2024-07-09 12:38:03,Omnia Ibrahim,Mixed
5608b5cc3abce876e1081de75875a8ee39521630,"KAFKA-16684: Remove caching in FetchResponse.responseData (#16532)

The response data should change accordingly to the input, however
with the current design, it will not change even if the input changes.
We remove this cache logic to avoid returning wrong data.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Apoorv Mittal <apoorvmittal10@gmail.com>, Igor Soarez <soarez@apple.com>",2024-07-09 15:46:22,Ken Huang,Not TDD
cfc7bb90ae40669d6eb284ae1987ce93b14990f4,"KAFKA-16345: Optionally URL-encode clientID and clientSecret in authorization header (#15475)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Kirk True <kirk@kirktrue.pro>",2024-07-09 18:53:45,bachmanity1,Mixed
f369771bf2088ac03bfd1ec0469e6568014d6b2a,"KAFKA-16851: Add remote.log.disable.policy (#16132)

Add a remote.log.disable.policy on a topic-level only as part of KIP-950

Reviewers: Kamal Chandraprakash <kchandraprakash@uber.com>, Luke Chen <showuon@gmail.com>, Murali Basani <muralidhar.basani@aiven.io>",2024-07-10 11:18:48,Christo Lolov,Mixed
8491e84aad1254a99beb1b5326c52cc59593c56a,"KAFKA-16228: Add remote log metadata flag to the dump log tool (#16475)

This change adds the --remote-log-metadata-decoder flag to the kafka-dump-log.sh tool. This new flag can be used to decode the payload of the __remote_log_metadata records produced by the default RemoteLogMetadataManager.

Reviewers: Luke Chen <showuon@gmail.com>, Divij Vaidya <diviv@amazon.com>",2024-07-10 11:20:18,Federico Valeri,Mixed
0b11971f2c94f7aadc3fab2c51d94642065a72e5,"KAFKA-17016 Align the behavior of GaugeWrapper and MeterWrapper (#16426)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-10 15:26:17,PoAn Yang,Mixed
25d775b742406477a0ff678b9990ed149d2157cc,"KAFKA-15853 Refactor ShareGroupConfig with AbstractConfig (#16506)

Reviewers: Andrew Schofield <aschofield@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-07-11 01:37:50,Omnia Ibrahim,Mixed
ede289db93f6d191319ec03af69542b44be34953,"KAFKA-17011: Fix a bug preventing features from supporting v0 (#16421)

As part of KIP-584, brokers expose a range of supported versions for each feature. For example, metadata.version might be supported from 1 to 21. (Note that feature level ranges are always inclusive, so this would include both level 1 and 21.)

These supported ranges are supposed to be able to include 0. For example, it should be possible for a broker to support a kraft.version between 0 and 1. However, in older software versions, there is an assertion in org.apache.kafka.common.feature.SupportedVersionRange that prevents this. This causes problems when the older software attempts to deserialize an ApiVersionsResponse containing such a range.

In order to resolve this dilemma, this PR bumps the version of ApiVersionsRequest from 3 to 4. Clients which send v4 promise to be able to handle ranges including 0. Clients which send v3 will not be exposed to these ranges. The feature will show up as having a minimum version of 1 instead. This work is part
of KIP-1022.

Similarly, this PR also introduces a new version of BrokerRegistrationRequest, and specifies that the
older versions of that RPC cannot handle supported version ranges including 0. Therefore, 0 is translated to 1 in the older requests.

Reviewers: Jun Rao <junrao@apache.org>, Chia-Ping Tsai <chia7712@gmail.com>, Justine Olshan <jolshan@confluent.io>",2024-07-10 16:10:25,Colin Patrick McCabe,Mixed
d7fbdcfd839acbf4983e123ee971f3e4b1ac73f5,"KAFKA-17085: Handle tasks in state updater before tasks in task registry (#16555) (#16561)

When a active tasks are revoked they land as suspended tasks in the
task registry. If they are then reassigned, the tasks are resumed
and put into restoration. On assignment, we first handle the tasks
in the task registry and then the tasks in the state updater. That
means that if a task is re-assigned after a revocation, we remove
the suspended task from the task registry, resume it, add it
to the state updater, and then remove it from the list of tasks
to create. After that we iterate over the tasks in the state
updater and remove from there the tasks that are not in the list
of tasks to create. However, now the state updater contains the
resumed tasks that we removed from the task registry before but
are no more in the list of tasks to create. In other words, we
remove the resumed tasks from the state updater and close them
although we just got them assigned.

This commit ensures that we first handle the tasks in the
state updater and then the tasks in the task registry.

Cherry-pick of 4ecbb75

Reviewer: Lucas Brutschy <lbrutschy@confluent.io>",2024-07-11 10:41:55,Bruno Cadonna,Mixed
a0309be7f4d1aa641a5657e3ccc430ab5fe17c16,"KAFKA-17098: Re-add task to state updater if transit to RUNNING fails (#16570)

When Streams tries to transit a restored active task to RUNNING, the
first thing it does is getting the committed offsets for this task.
If getting the offsets expires a timeout, Streams does not re-throw
the error initially, but tries to get the committed offsets later
until a Streams-specific timeout is hit.

Restored active tasks from the state updater are removed from the
output queue of the restored tasks in the state updater. If a
timeout occurs, the restored task is neither added to the
task registry nor re-added to the state updater. The task is lost
since it is not maintained anywhere. This means the task is also
not closed. When the same task is created again on the same
stream thread since the stream thread does not know about this
lost task, the state stores are opened again and RocksDB will
throw the ""No locks available"" error.

This commit re-adds the task to the state updater if the
committed request times out.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-07-11 17:45:56,Bruno Cadonna,Mixed
7495e70365ebeba4806fc4da23c2ca75fa191649,"KAFKA-16532; Support for first leader bootstrapping the voter set (#16518)

The first leader of a KRaft topic partition must rewrite the content of the bootstrap checkpoint (0-0.checkpoint) to the log so that it is replicated. Bootstrap checkpoints are not replicated to the followers.

The control records for KRaftVersionRecord and VotersRecord in the bootstrap checkpoint will be written in one batch along with the LeaderChangeMessage. The leader will write these control records before accepting data records from the state machine (Controller).

The leader determines that the bootstrap checkpoint has not been written to the log if the latest set of voters is located at offset -1. This is the last contained offset for the bootstrap checkpoint (0-0.checkpoint).

This change also improves the RaftClientTestContext to allow for better testing of the reconfiguration functionality. This is mainly done by allowing the voter set to be configured statically or through the bootstrap checkpoint.

Reviewers: José Armando García Sancio <jsancio@apache.org>, Colin P. McCabe <cmccabe@apache.org>
Co-authors: José Armando García Sancio <jsancio@apache.org>",2024-07-12 13:44:21,Alyssa Huang,Mixed
4cec840baf2b32261751e8d48c80c273390696a8,"KAFKA-16661: Added a lower `log.initial.task.delay.ms` value (#16221)

added a lower log.initial.task.delay.ms value to integration test framework to 500ms

Reviewers: Luke Chen <showuon@gmail.com>",2024-07-15 17:06:54,Vinay Agarwal,Not TDD
6e9c039eeaffa4591e226dc4da1199664f7ea2cc,"KAFKA-17097 Add replace.null.with.default configuration to ValueToKey and ReplaceField (#16571)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-15 18:12:59,PoAn Yang,Mixed
0b6086ed88e00248e0383d3663615bd1257165d5,"KAFKA-16741: Add ShareGroupHeartbeat API support - 2/N (KIP-932) (#16573)

ShareGroupHeartbeat API support as defined in KIP-932. The heartbeat persists Group and Member information on __consumer_offsets topic.

The PR also moves some of the ShareGroupConfigs to GroupCoordinatorConfigs as they should only be used in group coordinator.


Reviewers: Andrew Schofield <aschofield@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-07-15 16:14:55,Apoorv Mittal,Mixed
8aee314a4664bee46a351a21ec2ebb64a0d193e9,"KAFKA-16667 Avoid stale read in KRaftMigrationDriver (#15918)

When becoming the active KRaftMigrationDriver, there is another race condition similar to KAFKA-16171. This time, the race is due to a stale read from ZK. After writing to /controller and /controller_epoch, it is possible that a read on /migration is not linearized with the writes that were just made. In other words, we get a stale read on /migration. This leads to an inability to sync metadata to ZK due to incorrect zkVersion on the migration ZNode.

The non-linearizability of reads is in fact documented behavior for ZK, so we need to handle it.

To fix the stale read, this patch adds a write to /migration after updating /controller and /controller_epoch. This allows us to learn the correct zkVersion for the migration ZNode before leaving the BECOME_CONTROLLER state.

This patch also adds a check on the current leader epoch when running certain events in KRaftMigrationDriver. Historically, we did not include this check because it is not necessary for correctness. Writes to ZK are gated on the /controller_epoch zkVersion, and RPCs sent to brokers are gated on the controller epoch. However, during a time of rapid failover, there is a lot of processing happening on the controller (i.e., full metadata sync to ZK and full UMRs sent to brokers), so it is best to avoid running events we know will fail.

There is also a small fix in here to improve the logging of ZK operations. The log message are changed to past tense to reflect the fact that they have already happened by the time the log message is created.

Reviewers: Igor Soarez <soarez@apple.com>",2024-07-15 09:32:06,David Arthur,Not TDD
3a442ffe32ba38c0fcde329851dc9bad2bf560a2,"KAFKA-16743,KAFKA-16744: KafkaApis support for share group heartbeat and describe (#16574)

Added handling of share group heartbeat and describe in KafkaApis. The Implementation of heartbeat and describe is with group coordinator.

Reviewers:  Manikumar Reddy <manikumar.reddy@gmail.com>, Rahul <rahul.nirgude@mastercard.com>",2024-07-15 19:06:20,Apoorv Mittal,Mixed
20ee83c462f544d73518bd7ee05d21d971c56f24,"KAFKA-17102 FetchRequest#forgottenTopics would return incorrect data (#16557)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-16 05:12:43,Ken Huang,Mixed
808498e9391dab292a7ccd8a0bf3713f444f9d2f,"KAFKA-14401: Fail kafka log read end requests if underneath work thread fails (#14372)

Reviewers: Chris Egerton <chrise@aiven.io>",2024-07-15 20:55:52,vamossagar12,Mixed
1e16e16f64709bdbd2234cce171608e2cc0ed56b,"KAFKA-16730: Initial version of share group consumer client code (#16461)

This is the initial version of the share group consumer client code. It implements the complete ShareConsumer interface.

There are unit tests, but not integration tests yet since those would depend upon complete broker code, which is not available at this point.

Reviewers: Apoorv Mittal <apoorvmittal10@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>,  Lianet Magrans <lianetmr@gmail.com>",2024-07-16 16:45:38,Andrew Schofield,Mixed
4d3e366bc2487ca0c2321e6e6d7786fb6ed0efa5,"KAFKA-16772: Introduce kraft.version to support KIP-853 (#16230)

Introduce the KRaftVersion enum to describe the current value of kraft.version. Change a bunch of places in the code that were using raw shorts over to using this new enum.

In BrokerServer.scala, fix a bug that could cause null pointer exceptions during shutdown if we tried to shut down before fully coming up.

Do not send finalized features that are finalized as level 0, since it is a no-op.

Reviewers: dengziming <dengziming1993@gmail.com>, José Armando García Sancio <jsancio@apache.org>",2024-07-16 09:31:10,Colin Patrick McCabe,Mixed
d0f71486c20f6fb18a1901db49086ddb678689e2,"MINOR: Improve the logging of IllegalStateException exceptions thrown from SslFactory (#16346)

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Rajini Sivaram <rajinisivaram@googlemail.com>",2024-07-16 11:01:53,Alyssa Huang,Mixed
6cffed56f6a140d37bc0f210d4e786f78dc1631a,"KAFKA-16943: Synchronously verify Connect worker startup failure in InternalTopicsIntegrationTest (#16451)

Reviewers: Chris Egerton <chrise@aiven.io>",2024-07-16 14:20:44,Zhengke Zhou,Not TDD
b015a83f6d286965af999c39c0902584fb6fb9de,"KAFKA-17017 AsyncKafkaConsumer#unsubscribe clean the assigned partitions (#16449)

Reviewers: Lianet Magrans <lianetmr@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-07-17 04:18:33,PoAn Yang,Mixed
24ed31739e2efc337f53040366c38dedae543308,"KAFKA-16853: Split RemoteLogManagerScheduledThreadPool (#16502)

As part of KIP-950, we want to split the RemoteLogManagerScheduledThreadPool into separate thread pools (one for copy and another for expiration). In this change, we are splitting it into three thread pools (one for copy, one for expiration, and another one for follower). We are reusing the same thread pool configuration for all three thread pools. We can introduce new user-facing configurations later.

Reviewers: Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Luke Chen <showuon@gmail.com>, Christo Lolov <lolovc@amazon.com>, Satish Duggana <satishd@apache.org>",2024-07-17 16:43:23,Abhijeet Kumar,Mixed
a66a59f427b30611175fd029d86832d00aa5aabd,"KAFKA-17148: Remove print MetaPropertiesEnsemble from kafka-storage tool (#16607)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Greg Harris <greg.harris@aiven.io>",2024-07-17 08:16:29,Dmitry Werner,Mixed
53ec055394d4ac1cffe23faec679b5cf5b234a15,"KAFKA-17105: Prevent redundant restarts for newly-created connectors (#16581)

Reviewers: Greg Harris <greg.harris@aiven.io>",2024-07-17 14:33:47,Chris Egerton,Mixed
c97421c100715a3ad70024b8ef37a0b433292c5d,"KAFKA-17150: Use Utils.loadClass instead of Class.forName to resolve aliases correctly (#16608)

Signed-off-by: Greg Harris <greg.harris@aiven.io>
Reviewers: Chris Egerton <chrise@aiven.io>, Chia-Ping Tsai <chia7712@gmail.com>, Josep Prat <josep.prat@aiven.io>",2024-07-17 16:00:45,Greg Harris,Not TDD
94f5a4f63e7a385325fc9a0f7d592a417d25711f,"KAFKA-17135 Add unit test for `ProducerStateManager#readSnapshot` and `ProducerStateManager#writeSnapshot` (#16603)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-18 18:23:29,Kuan-Po Tseng,Mixed
6acc220e03a3d38d1ceb26926f072db56809ef1b,"KAFKA-15773 Group protocol configuration should be validated (#16543)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-18 18:31:36,PoAn Yang,Mixed
7e3dde99d7fac8b1eb14dacf4dd8f7137d78bf80,"MINOR: Various cleanups in raft (#16611)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-18 18:48:29,Mickael Maison,Mixed
f595802cc752ed01dc74e9ab932209fe25a9d10b,"KAFKA-16975 The error message of creating `__cluster_metadata` should NOT be ""Authorization failed"" (#16372)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-18 19:06:45,Kuan-Po Tseng,Mixed
4fd0f4095e441fd18a40294d1b00228310f6835d,"KAFKA-17118 remove useless code in StorageTool (#16622)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-19 10:04:32,xijiu,Mixed
43fdc6ae08d289c5c18e66b1f111b7354c6f7350,"KAFKA-17122 Change the type of `clusterId` from `UUID` to `String` (#16590)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-19 10:37:58,Volk,Mixed
cd48fa682d780730cf331dc29b1259489ef5112b,"KAFKA-17077 The node.id is inconsistent to broker.id when ""broker.id.generation.enable=true"". (#16540)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-19 10:41:53,TengYao Chi,Mixed
66655ab49a9401a62e1e99e637e0c5bd5a1ba550,"KAFKA-17095 Fix the typo from ""CreateableTopicConfig"" to ""CreatableTopicConfig"" (#16623)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-19 11:09:08,"Chung, Ming-Yen",Mixed
931bb62a2340a563e598e522b196c07b870c285c,"KAFKA-16984: Complete consumer leave on response to leave request (#16569)

Improvement to ensure that the consumer unsubscribe operation waits for a response to the leave group request before moving on to close the consumer. This makes it consistent with the behaviour of the legacy consumer.

This will avoid undesired interactions on close, that triggers a leave group, and shuts down the network thread when it completes (which before this PR could led to responses to disconnected clients).

Note that this PR does not change the transitions of the state machine on leave group, only the completion of the leave group future.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>, Kirk True <ktrue@confluent.io>",2024-07-19 10:08:40,Lianet Magrans,Mixed
4de83d38c926bd991ce3e2d2804537a392ae6691,"KAFKA-16448: Catch and handle processing exceptions (#16093)

This PR is part of KAFKA-16448 (KIP-1033) which aims to bring a ProcessingExceptionHandler to Kafka Streams in order to deal with exceptions that occur during processing.

This PR actually catches processing exceptions.

Authors:
@Dabz
@sebastienviale
@loicgreffier

Reviewers: Apoorv Mittal <apoorvmittal10@gmail.com>, Bruno Cadonna <cadonna@apache.org>",2024-07-19 11:24:25,Loïc GREFFIER,Mixed
0696fbc73242368e60a8f72dbf0e219f1c7662c5,"KAFKA-17172 Add `@Tag(""integration"")` to ClusterTest, ClusterTemplate, and ClusterTests (#16640)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-21 14:40:45,Dmitry Werner,Mixed
e9a8c3c455f097144f06794533f93db181ad46bd,"KAFKA-17153 KafkaMetricsGroup#newGauge should accept functional interface instead of `com.yammer.metrics.core.Gague` (#16618)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-21 18:17:04,Kuan-Po Tseng,Not TDD
defcbb51ee98ae766e4fcf41ed7631ef1b0cdd15,"KAFKA-17082 replace kafka.utils.LogCaptureAppender with org.apache.kafka.common.utils.LogCaptureAppender (#16601)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-21 18:22:05,PoAn Yang,Not TDD
7a8f89e0a074d11ab82c4a5bcde63db10d1e5407,"KAFKA-17168 The logPrefix of RemoteLogReader/RemoteStorageThreadPool is not propagated correctly (#16642)

Reviewers: Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-07-21 22:19:15,Kuan-Po Tseng,Not TDD
90b779b7bb8b813e52ea21ce88c209e71b475ec9,"MINOR: Various cleanups in metadata (#16610)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-22 10:26:09,Mickael Maison,Mixed
44a44b753f45bb5bba67812e59e1b21e930f4a9d,"KAFKA-17166 Use NoOpScheduler to rewrite LogManagerTest#testLogRecoveryMetrics (#16641)

Reviewers: Okada Haruki <ocadaruma@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-07-22 22:05:50,PoAn Yang,Not TDD
98979e73841e9f2b9429e1c11ae63c448efc1957,"MINOR: Move a few configs to SocketServerConfigs (#16634)


Move queued.max.requests, queued.max.request.bytes and num.network.threads to SocketServerConfigs

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-22 19:21:59,Mickael Maison,Mixed
9db5c2481f8cefb5ec9a97d6e715a350dbc929c7,"KAFKA-16535; Implement KRaft add voter handling

This change implements the AddVoter RPC. The high-level algorithm is as follow:

1. Check that the leader has fenced the previous leader(s) by checking that the HWM is known;
   otherwise, return the REQUEST_TIMED_OUT error.
2. Check that the cluster supports kraft.version 1; otherwise return the UNSUPPORTED_VERSION error.
3. Check that there are no uncommitted voter changes; otherwise return the REQUEST_TIMED_OUT error.
4. Check that the new voter's id is not part of the existing voter set, otherwise return the
   DUPLICATE_VOTER error.
5. Send an API_VERSIONS RPC to the first (default) listener to discover the supported kraft.version
   of the new voter.
6. Check that the new voter supports the current kraft.version, otherwise return the
   INVALID_REQUEST error.
7. Check that the new voter is caught up to the log end offset of the leader, otherwise return a
   REQUEST_TIMED_OUT error.
8. Append the updated VotersRecord to the log. The KRaft internal listener will read this
   uncommitted record from the log and add the new voter to the set of voters.
9.  Wait for the VotersRecord to commit using the majority of the new set of voters. Return a
    REQUEST_TIMED_OUT error if it doesn't commit in time.
10. Send the AddVoter successful response to the client.

The leader implements the above algorithm by tracking 3 events: the ADD_VOTER request is received,
the API_VERSIONS response is received and finally the HWM is updated.

The state of the ADD_VOTER operation is tracked by LeaderState using the AddVoterHandlerState. The
algorithm is implemented by the AddVoterHandler type.

This change also fixes a small issue introduced by the bootstrap checkpoint (0-0.checkpoint). The
internal partition listener (KRaftControlRecordStateMachine) and the external partition listener
(KafkaRaftClient.ListenerContext) were using ""nextOffset = 0"" as the initial state of the reading
cursor. This was causing the bootstrap checkpoint to keep getting reloaded until the leader wrote a
record to the log. Changing the initial offset (nextOffset) to -1 allows the listeners to
distinguish between the initial state (nextOffset == -1) and the bootstrap checkpoint was loaded
but the log segment is empty (nextOffset == 0).

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2024-07-22 13:07:38,José Armando García Sancio,Not TDD
a5bfc2190c3448039c9361909e547f64f7fdb6e2,"KAFKA-16791 Add thread detection to ClusterTestExtensions (#16499)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-23 11:16:31,PoAn Yang,Mixed
a012af5fb4331be06cb1162decfdd50c3e0bd781,"KAFKA-17149 Move ProducerStateManagerTest to storage module (#16645)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-23 20:08:08,Ken Huang,Not TDD
c71eb60a3b2e30cc376b81144cf9c2c411d8f28b,"MINOR: Extract SockerServer inner classes to server module (#16632)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-23 20:19:41,Mickael Maison,Not TDD
956d740c46942d31d18e4c61a832d9b5f4afa7e1,"KAFKA-16068: Use TestPlugins mechanism in ConnectorValidationIntegrationTest to prevent ERROR-level log spam in unrelated test suites (#16647)

Reviewers: Greg Harris <greg.harris@aiven.io>",2024-07-23 13:15:03,Chris Egerton,Not TDD
539f466ccb112167b1b55a0bd3c67123aaae5f6a,"KAFKA-17168 Remove the logPrefix to print the thread name (#16657)

Reviewers: Kuan-Po (Cooper) Tseng <brandboat@gmail.com>, Satish Duggana <satishd@apache.org>, Chia-Ping Tsai <chia7712@gmail.com>",2024-07-24 16:54:02,Kamal Chandraprakash,Not TDD
4fa1c21940c19284685a13296b888e9a5052ec3b,"KAFKA-17104 InvalidMessageCrcRecordsPerSec is not updated in validating LegacyRecord (#16558)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-24 19:25:11,TaiJuWu,Mixed
3e2de237be40b76f4d98841f12ba7fb72173899e,"KAFKA-17021 Migrate AclCommandTest to new test infra (#16500)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-25 00:12:47,Dmitry Werner,Not TDD
ee68f3215f6561e484decc48cb56f28b378b1009,"KAFKA-16666 Migrate `TransactionLogMessageFormatter` to tools module (#16019)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-25 00:42:25,Ken Huang,Mixed
a38829e61b9b4f8efce7ac7e7ca47c86e240e790,"KAFKA-16765: Close leaked accepted sockets in EchoServer, NioEchoServer,  ServerShutdownTest (#16576)

Reviewers: Greg Harris <greg.harris@aiven.io>",2024-07-24 10:20:51,Zhengke Zhou,Not TDD
437b86cd20ab500ee26e9555ad489f19fa8fb571,"KAFKA-17176 Move FileLock to server-common module (#16671)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-25 14:24:27,Kuan-Po Tseng,Mixed
41beee508e41b255d0766917894d63e56ceb7220,"KAFKA-16558: Implemented HeartbeatRequestState toStringBase() and added a test for it (#16373)

Reviewers: Kirk True <kirk@kirktrue.pro>, Matthias J. Sax <matthias@confluent.io>",2024-07-25 13:27:17,brenden20,Mixed
a0f6e6f816c6ac3fbbc4e0dc503dc43bfacfe6c7,"KAFKA-16192: Introduce transaction.version and usage of flexible records to coordinators (#16183)

This change includes adding transaction.version (part of KIP-1022)

New transaction version 1 is introduced to support writing flexible fields in transaction state log messages.

Transaction version 2 is created in anticipation for further KIP-890 changes.

Neither are made production ready. Tests for the new transaction version and new MV are created.

Also include change to not report a feature as supported if the range is 0-0.

Reviewers: Jun Rao <junrao@apache.org>, David Jacot <djacot@confluent.io>, Artem Livshits <alivshits@confluent.io>, Colin P. McCabe <cmccabe@apache.org>",2024-07-26 11:38:44,Justine Olshan,Mixed
da32dcab2c4abd5d12c928dfcb4a2f25a2891195,"KAKFA-16537; Implement remove voter RPC (#16670)

Implement the RemoveVoter RPC. The general algorithm is as follow:

1. Check that the leader has fenced the previous leader(s) by checking that the HWM is known;
  otherwise return the REQUEST_TIMED_OUT error.
2. Check that the cluster supports kraft.version 1; otherwise return the UNSUPPORTED_VERSION error.
3. Check that there are no uncommitted voter changes; otherwise return the REQUEST_TIMED_OUT error.
4. Append the updated VotersRecord to the log. The KRaft internal listener will read this uncommitted
  record from the log and add the new voter to the set of voters.
5. Wait for the VotersRecord to commit using the majority of the new set of voters. Return a 
  REQUEST_TIMED_OUT error if it doesn't commit in time.
6. Send the RemoveVoter successful response to the client.
7. Resign the leadership if the leader is not in the new voter set

One thing to note is that now that KRaft supports both the remove voter and add voter RPC. Only one
change can be pending at once. This is achieved in the following ways. The AddVoter RPC checks if
there are pending AddVoter or RemoveVoter RPC. The RemoveVoter RPC checks if there are any
pending AddVoter or RemoveVoter RPC. Both RPCs check that there is no uncommitted VotersRecord.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2024-07-26 16:25:41,José Armando García Sancio,Mixed
da8fe6355b345adb7455860f32e6b397c722c07a,"KAFKA-16915; LeaderChangeMessage supports directory id (#16668)

Extend LeaderChangeMessage schema to support version 1 of the message. The leader will continue to write version 0 of the schema. This is needed so that in the future the leader can write version 1 of the message and be guaranteed that all of the replicas in the cluster support version 1 of the schema.

Reviewers: José Armando García Sancio <jsancio@apache.org>",2024-07-28 11:12:42,Alyssa Huang,Not TDD
d260b061803e3b9a2b4a0414f9a4f44b1f8d8f46,"KAFKA-17060 Rename LegacyKafkaConsumer to ClassicKafkaConsumer (#16683)

Reviewers: Andrew Schofield <aschofield@confluent.io>, Lianet Magrans <lianetmr@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-07-29 20:56:23,Kirk True,Mixed
61f61d62403e6b547a3a333895395ceff6d7afe5,"KAFKA-14569: Migrate Connect's integration test EmbeddedKafkaCluster from ZK to KRaft mode (#16599)

Reviewers: Omnia Ibrahim <o.g.h.ibrahim@gmail.com>, Mickael Maison <mickael.maison@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-07-29 10:43:55,Chris Egerton,Not TDD
2cf87bff9b6b5136a22539edf48b2d7cc668bdf9,"KAFKA-16953; Properly implement the sending of DescribeQuorumResponse (#16637)

This change allows the KRaft leader to send the DescribeQuorumResponse version based on the schema version used by the client.

Reviewers: José Armando García Sancio <jsancio@apache.org>",2024-07-29 14:36:17,Alyssa Huang,Mixed
6ff51bc388dac55e04343fe4247b1080f1241dab,"KAFKA-17210: Broker fixes for smooth concurrent fetches on share partition (#16711)

Identified a couple of reliability issues with broker code for share groups 

1. Broker seems to get stuck at times when using multiple share consumers due to a corner case where the second last fetch request did not contain any topic partition to fetch, because of which the broker could never complete the last request. This results in a share fetch request getting stuck.

2. Since persister would not perform any business logic around sending state batches for a share partition, there could be scenarios where it sends state batches with no AVAILABLE records. This could cause a breach on the limit of in-flight messages we have configured, and hence broker would never be able to complete the share fetch requests.

Reviewers:  Andrew Schofield <aschofield@confluent.io>, Apoorv Mittal <apoorvmittal10@gmail.com>,  Manikumar Reddy <manikumar.reddy@gmail.com>",2024-07-30 01:16:58,Abhinav Dixit,Mixed
b6d5f0556ccde4490cf76a3af53244915e2d7f99,"KAFKA-16448: Add ErrorHandlerContext in production exception handler (#16433)

This PR is part of KIP-1033 which aims to bring a ProcessingExceptionHandler to Kafka Streams in order to deal with exceptions that occur during processing.

This PR expose the new ErrorHandlerContext as a parameter to the Production exception handler and deprecate the previous handle signature.

Co-authored-by: Dabz <d.gasparina@gmail.com>
Co-authored-by: loicgreffier <loic.greffier@michelin.com>

Reviewers: Bruno Cadonna <bruno@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2024-07-29 20:17:15,Sebastien Viale,Mixed
faaef527d7fa5fc05f92853e0b28b6b5cdbf6a23,"KAFKA-16448: Add ErrorHandlerContext in deserialization exception handler (#16432)

This PR is part of KIP1033 which aims to bring a ProcessingExceptionHandler to Kafka Streams in order to deal with exceptions that occur during processing.

This PR expose the new ErrorHandlerContext as a parameter to the Deserialization exception handlers and deprecate the previous handle signature.

Co-authored-by: Dabz <d.gasparina@gmail.com>
Co-authored-by: loicgreffier <loic.greffier@michelin.com>

Reviewers: Bruno Cadonna <bruno@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2024-07-29 20:33:33,Sebastien Viale,Mixed
1b11fef5bb9b753a2ef8916efdf3f66167e66976,"KAFKA-17205: Allow topic config validation in controller level in KRaft mode (#16693)

Reviewers: Kamal Chandraprakash <kamal.chandraprakash@gmail.com>, Christo Lolov <lolovc@amazon.com>",2024-07-30 17:07:09,Luke Chen,Mixed
e299a006c8c0e4e78aa1082359b0054118f9ff15,"KAFKA-17214: Add 3.8.0 version to streams system tests (#16728)

* KAFKA-17214: Add 3.8.0 version to streams system tests

Reviewers: Bill Bejeck <bbejeck@gmail.com>",2024-07-30 19:04:38,Josep Prat,Not TDD
1084d3b9c95aecccbe3c82e84ae4c8f406fc68e1,"KAFKA-17175 Remove interface `BrokerNode` and `ControllerNode` (#16666)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-31 01:54:02,TengYao Chi,Mixed
7c0a96d08d81c2f91c10c601f1e0fd6f4f5f6268,"KAFKA-17185 Declare Loggers as static to prevent multiple logger instances (#16680)

As discussed in #16657 (comment) , we should make logger as static to avoid creating multiple logger instances.
I use the regex private.*Logger.*LoggerFactory to search and check all the results if certain logs need to be static.

There are some exceptions that loggers don't need to be static:
1) The logger in the inner class. Since java8 doesn't support static field in the inner class.
        https://github.com/apache/kafka/blob/trunk/clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetchRequestManagerTest.java#L3676

2) Custom loggers for each instance (non-static + non-final). In this case, multiple logger instances is actually really needed.
        https://github.com/apache/kafka/blob/trunk/storage/src/test/java/org/apache/kafka/server/log/remote/storage/LocalTieredStorage.java#L166

3) The logger is initialized in constructor by LogContext. Many non-static but with final modifier loggers are in this category, that's why I use .*LoggerFactory to only check the loggers that are assigned initial value when declaration.
    
4) protected final Logger log = Logger.getLogger(getClass())
    This is for subclass can do logging with subclass name instead of superclass name.
    But in this case, if the log access modifier is private, the purpose cannot be achieved since subclass cannot access the log defined in superclass. So if access modifier is private, we can replace getClass() with <className>.class

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-31 02:37:36,"Chung, Ming-Yen",Not TDD
010ab19b724ae011e85686ce47320f4f85d9a11f,"KAFKA-16972 Move BrokerTopicMetrics to org.apache.kafka.storage.log.metrics (#16387)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-31 03:07:09,PoAn Yang,Mixed
0dc9b9e4eec124df9f5c92b41db2b4fb7bd49600,"KAFKA-16448: Handle fatal user exception during processing error (#16675)

This PR is part of KIP-1033 which aims to bring a ProcessingExceptionHandler to Kafka Streams in order to deal with exceptions that occur during processing.

This PR catch the exceptions thrown while handling a processing exception

Co-authored-by: Dabz <d.gasparina@gmail.com>
Co-authored-by: loicgreffier <loic.greffier@michelin.com>

Reviewers: Bruno Cadonna <bruno@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2024-07-30 22:58:07,Sebastien Viale,Mixed
fa682623b9ad593eb1886642f67ef6686c8a11d4,"KAFKA-16666 Migrate OffsetMessageFormatter to tools module (#16689)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-07-31 15:18:14,Ken Huang,Mixed
51c1e1e147272b84b8e338264ae16ad9a2ecbe67,"KAFKA-17188: Ensure login and callback handler are closed upon encountering LoginException (#16724)

Reviewers: TengYao Chi <kitingiao@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>",2024-07-31 08:51:54,Philip Nee,Mixed
8d8c367066f59d888d6aa2011b840915cd07a3c2,"KAFKA-17192 Fix MirrorMaker2 worker config does not pass config.provi… (#16678)

Reviewers: Chris Egerton <chrise@aiven.io>",2024-07-31 16:50:22,Kondrat Bertalan,Mixed
f1ef7a5a9f87cda7ae1209fc2285259eba4204ca,"KAFKA-16448: Handle processing exceptions in punctuate (#16300)

This PR is part of KIP-1033 which aims to bring a ProcessingExceptionHandler to Kafka Streams in order to deal with exceptions that occur during processing.

This PR actually catches processing exceptions from punctuate.

Co-authored-by: Dabz <d.gasparina@gmail.com>
Co-authored-by: loicgreffier <loic.greffier@michelin.com>

Reviewers: Bruno Cadonna <bruno@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2024-07-31 15:53:47,Sebastien Viale,Mixed
7d88bde9a9a0000e69fe69baadd0859d594dc7a0,"MINOR: Cleanup storage module (#16207)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-02 00:37:50,Sanskar Jhajharia,Mixed
15fa241ceac3ff461311de389073292cf4df3c55,"KAFKA-17234: Partition.tryCompleteDelayedRequests should not throw (#16760)

`Partition.tryCompleteDelayedRequests` should not throw since the
contexts it is called from are not expecting it, and the exceptions are
not related to those contexts.

Reviewers: Justine Olshan <jolshan@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-08-01 10:46:04,Colin Patrick McCabe,Mixed
902fc33b27aa7a505b86a80b51b537922238118e,"KAFKA-17230: Fix for consumer node latency metrics (#16755)

Kafka Consumer client registers node/connection latency metrics in Selector.java but the values against the metric is never recorded. This seems to be an issue since inception. 

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Andrew Schofield <aschofield@confluent.io>, Jun Rao <junrao@gmail.com>",2024-08-01 12:04:19,Apoorv Mittal,Mixed
bc4df734b5c00730b8910866ce96d7cf0713593c,"KAFKA-16521; kafka-metadata-quorum describe command changes for KIP-853 (#16759)

describe --status now includes directory id and endpoint information for voter and observers.
describe --replication now includes directory id.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, José Armando García Sancio <jsancio@apache.org>",2024-08-01 15:28:57,Alyssa Huang,Mixed
704476885ffb40cd3bf9b8f5c368c01eaee0a737,"KAFKA-16666 Migrate GroupMetadataMessageFormatter` to tools module (#16748)

we need to migate GroupMetadataMessageFormatter from scala code to java code,and make the message format is json pattern

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-02 11:53:57,Ken Huang,Mixed
5afdb17092f99d956bf65fcb543de0b15c04e01f,"MINOR: Fix consumer group warmup in MirroMaker 2 integration tests (#16771)

Reviewers: Greg Harris <greg.harris@aiven.io>",2024-08-02 13:57:05,Chris Egerton,Not TDD
3922cadc5d2fb52bca150b09aac278b4dc450ec2,"KAFKA-9738: Deprecate old Processor API (#16742)

Implements KIP-1070, which deprecates:
 - Transformer
 - TransformerSupplier
 - ValueTransformer
 - ValueTransformerSupplier
 - MockProcessorContext

Reviewers: Bill Bejeck <bill@confluent.io>",2024-08-02 12:55:53,Matthias J. Sax,Mixed
02f541d4ea51ee9034f92d249dde96bc70860e5e,"KAFKA-16518: Implement KIP-853 flags for storage-tool.sh (#16669)

As part of KIP-853, storage-tool.sh now has two new flags: --standalone, and --initial-voters. This PR implements these two flags in storage-tool.sh.

There are currently two valid ways to format a cluster:

The pre-KIP-853 way, where you use a statically configured controller quorum. In this case, neither --standalone nor --initial-voters may be specified, and kraft.version must be set to 0.

The KIP-853 way, where one of --standalone and --initial-voters must be specified with the initial value of the dynamic controller quorum. In this case, kraft.version must be set to 1.

This PR moves the formatting logic out of StorageTool.scala and into Formatter.java. The tool file was never intended to get so huge, or to implement complex logic like generating metadata records. Those things should be done by code in the metadata or raft gradle modules. This is also useful for junit tests, which often need to do formatting. (The 'info' and 'random-uuid' commands remain in StorageTool.scala, for now.)

Reviewers: José Armando García Sancio <jsancio@apache.org>",2024-08-02 15:47:45,Colin Patrick McCabe,Mixed
6e324487fa93c540ef611eb9c9694c464fdecd3c,"KAFKA-16480: ListOffsets change should have an associated API/IBP version update (#16781)

   1. Use oldestAllowedVersion as 9 if using ListOffsetsRequest#EARLIEST_LOCAL_TIMESTAMP or ListOffsetsRequest#LATEST_TIERED_TIMESTAMP.
   2. Add test cases to ListOffsetsRequestTest#testListOffsetsRequestOldestVersion to make sure requireTieredStorageTimestamp return 9 as minVersion.
   3. Add EarliestLocalSpec and LatestTierSpec to OffsetSpec.
   4. Add more cases to KafkaAdminClient#getOffsetFromSpec.
   5. Add testListOffsetsEarliestLocalSpecMinVersion and testListOffsetsLatestTierSpecSpecMinVersion to KafkaAdminClientTest to make sure request builder has oldestAllowedVersion as 9.

Signed-off-by: PoAn Yang <payang@apache.org>

Reviewers: Luke Chen <showuon@gmail.com>",2024-08-03 14:27:27,PoAn Yang,Mixed
9f7e8d478a9252f03f6adae3736d13799f137d6a,"KAFKA-16855: remote log disable policy in KRaft (#16653)

Reviewers: Kamal Chandraprakash <kamal.chandraprakash@gmail.com>, Christo Lolov <lolovc@amazon.com>",2024-08-03 09:38:41,Luke Chen,Mixed
8438c4339e0a103d95575336a9f3653698cd0b8e,"KAFKA-17245: Revert TopicRecord changes. (#16780)

Revert KAFKA-16257 changes because KIP-950 doesn't need it anymore.

Reviewers: Luke Chen <showuon@gmail.com>",2024-08-03 20:15:51,TengYao Chi,Mixed
2a7bad8ca00deddb6a70530f53fa59af99a25e66,"MINOR: Fix consumer log on fatal error & improve memberId logging (#16720)

Fix log on consumer fatal error, to show member ID only if present. If no member ID the log will clearly indicate that the member has no member ID (instead of showing empty as it used to)

Apply same fix consistently to all other log lines that include member ID.

Reviewers: Kirk True <kirk@kirktrue.pro>, PoAn Yang <payang@apache.org>, TengYao Chi <kitingiao@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-08-04 02:18:14,Lianet Magrans,Mixed
2c9d7afe4c60656d10f5b15367e3fb65173d0372,"MINOR: add helper method to `ClusterInstance` to wait topic deletion (#16627)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-04 02:35:00,TaiJuWu,Not TDD
7c539f902983a76f14d0cd993e7d6dcbfdacd909,"KAFKA-16448: Unify error-callback exception handling (#16745)

Follow up code cleanup for KIP-1033.

This PR unifies the handling of both error cases for exception handlers:
 - handler throws an exception
 - handler returns null

The unification happens for all 5 handler cases:
 - deserialzation
 - production / serialization
 - production / send
 - processing
 - punctuation

Reviewers:  Sebastien Viale <sebastien.viale@michelin.com>, Loic Greffier <loic.greffier@michelin.com>, Bill Bejeck <bill@confluent.io>",2024-08-03 12:40:51,Matthias J. Sax,Mixed
84add30ea549dbd87a239a443ce36d3e10ce336a,"KAFKA-16154: Broker returns offset for LATEST_TIERED_TIMESTAMP (#16783)

This pr support EarliestLocalSpec LatestTierSpec in GetOffsetShell, and add integration tests.

Reviewers: Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>, PoAn Yang <payang@apache.org>",2024-08-05 10:41:14,Kuan-Po Tseng,Mixed
0b78d8459cc8963ad9c324639f304277a76560ff,"MINOR: Remove ConsumerTestBuilder.java (#16691)

The purpose of this PR is to remove ConsumerTestBuilder.java since it is no longer needed. The following PRs have eliminated the use of ConsumerTestBuilder:
#14930
#16140
#16200
#16312

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-05 11:05:53,brenden20,Not TDD
e49c8df1f784e6e800526c61addab305bbfcb6e5,"KAFKA-16533; Update voter handling

Add support for handling the update voter RPC. The update voter RPC is used to automatically update
the voters supported kraft versions and available endpoints as the operator upgrades and
reconfigures the KRaft controllers.

The add voter RPC is handled as follow:

1. Check that the leader has fenced the previous leader(s) by checking that the HWM is known;
   otherwise, return the REQUEST_TIMED_OUT error.

2. Check that the cluster supports kraft.version 1; otherwise, return the UNSUPPORTED_VERSION error.

3. Check that there are no uncommitted voter changes, otherwise return the REQUEST_TIMED_OUT error.

4. Check that the updated voter still supports the currently finalized kraft.version; otherwise
   return the INVALID_REQUEST error.

5. Check that the updated voter is still listening on the default listener.

6. Append the updated VotersRecord to the log. The KRaft internal listener will read this
   uncommitted record from the log and update the voter in the set of voters.

7. Wait for the VotersRecord to commit using the majority of the voters. Return a REQUEST_TIMED_OUT
   error if it doesn't commit in time.

8. Send the UpdateVoter successful response to the voter.

This change also implements the ability for the leader to update its own entry in the voter
set when it becomes leader for an epoch. This is done by updating the voter set and writing a
control batch as the first batch in a new leader epoch.

Finally, fix a bug in KafkaAdminClient's handling of removeRaftVoterResponse where we tried to cast
the response to the wrong type.

Reviewers: Alyssa Huang <ahuang@confluent.io>, Colin P. McCabe <cmccabe@apache.org>",2024-08-05 11:32:21,José Armando García Sancio,Mixed
c18463ec2d723e46c5b4e4d71d712c1c86f0e893,"MINOR: Rethrow caught exception instead of wrapping into LoginException (#16769)

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>",2024-08-06 09:48:07,Philip Nee,Mixed
7c5d339d0774088129c19a5a1bcb6639cd22474a,"KAFKA-17227: Refactor compression code to only load codecs when used (#16782)


Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Josep Prat <josep.prat@aiven.io>",2024-08-06 11:01:21,Mickael Maison,Mixed
1db84c1a113cb3b115ff3565b5b368643338b6c9,"KAFKA-16745: Implemented handleShareFetchRequest RPC including unit tests (#16456)

Implemented handleShareFetch request RPC in KafkaApis.scala. This method is called whenever the client sends a Share Fetch request to the broker. Although Share Fetch request support acknowledgements, since the logic for acknowledging records is not completely implemented in SharePartitionManager.java class, this method currently includes placeholder code for acknowledging, which will be replaced by the actual functionality in the upcoming PRs.

Reviewers:  Apoorv Mittal <apoorvmittal10@gmail.com>, Abhinav Dixit <adixit@confluent.io>, Jun Rao <junrao@gmail.com>",2024-08-06 07:59:04,Chirag Wadhwa,Mixed
5fac9057496ded1de838f6283aa7430b7794d354,"KAFKA-17222 Remove the subclass of KafkaMetricsGroup (#16752)

The method overrides of metricName in KafkaMetricsGroup are no longer required since there's a new constructor that implement this with the same behavior.

Reviewers: PoAn Yang <payang@apache.org>, Chia-Ping Tsai <chia7712@gmail.com>",2024-08-07 01:26:49,bboyleonp666,Mixed
96816a3ed74857cc7631174b2c189ed8b1d9807c,"KAFKA-16742: Add share group describe in coordinator (KIP-932) (#16797)

Share group describe functionality for KIP-932

Reviewers:  Andrew Schofield <aschofield@confluent.io>,  Manikumar Reddy <manikumar.reddy@gmail.com>",2024-08-07 14:53:01,Apoorv Mittal,Mixed
b9099301fbd0a5b35e46b4f9ac026263c753cce6,"KAFKA-16716: Add admin list and describe share groups (#16827)

Adds the methods to the admin client for listing and describing share groups.
There are some unit tests, but integration tests will be in a follow-on PR.

Reviewers:  Manikumar Reddy <manikumar.reddy@gmail.com>",2024-08-08 00:46:25,Andrew Schofield,Mixed
164f89960575c4ac1acdc6408e650c1567ee9515,"KAFKA-17236: Handle local log deletion when remote.log.copy.disabled=true (#16765)

Handle local log deletion when remote.log.copy.disabled=true based on the KIP-950.

When tiered storage is disabled or becomes read-only on a topic, the local retention configuration becomes irrelevant, and all data expiration follows the topic-wide retention configuration exclusively.

- added remoteLogEnabledAndRemoteCopyEnabled method to check if this topic enables tiered storage and remote log copy is enabled. We should adopt local.retention.ms/bytes when remote.storage.enable=true,remote.log.copy.disable=false.
- Changed to use retention.bytes/retention.ms when remote copy disabled.
- Added validation to ask users to set local.retention.ms == retention.ms and local.retention.bytes == retention.bytes
- Added tests

Reviewers: Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Satish Duggana <satishd@apache.org>, Christo Lolov <lolovc@amazon.com>",2024-08-08 17:07:40,Luke Chen,Mixed
0dc74c5556ef5b35caadcc9a0e2ee968b6958fce,"KAFKA-17232: Do not generate task configs in MirrorCheckpointConnector if initial consumer group load times out (#16767)

Reviewers: Hongten <hongtenzone@foxmail.com>, Chris Egerton <chrise@aiven.io>",2024-08-08 09:58:11,TengYao Chi,Mixed
0cbc5e083a936025a85f127102dc1032f6cf4fd9,"KAFKA-17217: Batched acknowledge requests per node in ShareConsumeRequestManager (#16727)

In ShareConsumeRequestManager, currently every time we perform a commitSync/commitAsync/acknowledgeOnClose we create one AcknowledgeRequestState for each call. But this can be optimised further as we can batch up the acknowledgements to be sent to the same node before the next poll() is invoked.

This will ensure that between 2 polls, the acknowledgements are accumulated in one request per node and then sent during poll, resulting in lesser RPC calls.

To achieve this, we are storing a pair of acknowledge request states for every node, the first value denotes the requestState for commitAsync() and the second value denotes the requestState for commitSync() and acknowledgeOnClose(). All the acknowledgements to be sent to a particular node are stored in the corresponding acknowledgeRequestState based on whether it was synchronous or asynchronous.

Reviewers:  Andrew Schofield <aschofield@confluent.io>,  Manikumar Reddy <manikumar.reddy@gmail.com>",2024-08-08 20:43:37,ShivsundarR,Mixed
3066019efa1cabe7fe52bb7ac663d4363bb9be84,"KAFKA-16521: Have Raft endpoints printed as name://host:port (#16830)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2024-08-08 09:22:23,Alyssa Huang,Mixed
130af384810aa1520b9d17710badf0a120d4d99c,"KAFKA-17223 Retrying the call after encoutering UnsupportedVersionException will cause ConcurrentModificationException (#16753)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-09 01:07:54,PoAn Yang,Mixed
4e862c0903195eb11a715271c29304d28036273d,"KAFKA-15875: Stops leak Snapshot in public methods (#16807)

* KAFKA-15875: Stops leak Snapshot in public methods

The Snapshot class is package protected but it's returned in
several public methods in SnapshotRegistry.
To prevent this accidental leakage, these methods are made
package protected as well. For getOrCreateSnapshot a new
method called IdempotentCreateSnapshot is created that returns void.
* Make builer package protected, replace <br> with <p>

Reviewers: Greg Harris <greg.harris@aiven.io>",2024-08-08 20:05:47,Josep Prat,Not TDD
6a44fb154d37d45fe9aeb050a6f1eb129c451f92,"KAFKA-16523; kafka-metadata-quorum: support add-controller and remove-controller (#16774)

This PR adds support for add-controller and remove-controller in the kafka-metadata-quorum.sh
command-line tool. It also fixes some minor server-side bugs that blocked the tool from working.

In kafka-metadata-quorum.sh, the implementation of remove-controller is fairly straightforward. It
just takes some command-line flags and uses them to invoke AdminClient. The add-controller
implementation is a bit more complex because we have to look at the new controller's configuration
file. The parsing logic for the advertised.listeners and listeners server configurations that we
need was previously implemented in the :core module. However, the gradle module where
kafka-metadata-quorum.sh lives, :tools, cannot depend on :core. Therefore, I moved listener parsing
into SocketServerConfigs.listenerListToEndPoints. This will be a small step forward in our efforts
to move Kafka configuration out of :core.

I also made some minor changes in kafka-metadata-quorum.sh and Kafka-storage-tool.sh to handle
--help without displaying a backtrace on the screen, and give slightly better error messages on
stderr. Also, in DynamicVoter.toString, we now enclose the host in brackets if it contains a colon
(as IPV6 addresses can).

This PR fixes our handling of clusterId in addRaftVoter and removeRaftVoter, in two ways. Firstly,
it marks clusterId as nullable in the AddRaftVoterRequest.json and RemoveRaftVoterRequest.json
schemas, as it was always intended to be. Secondly, it allows AdminClient to optionally send
clusterId, by using AddRaftVoterOptions and RemoveRaftVoterOptions. We now also remember to
properly set timeoutMs in AddRaftVoterRequest. This PR adds unit tests for
KafkaAdminClient#addRaftVoter and KafkaAdminClient#removeRaftVoter, to make sure they are sending
the right things.

Finally, I fixed some minor server-side bugs that were blocking the handling of these RPCs.
Firstly, ApiKeys.ADD_RAFT_VOTER and ApiKeys.REMOVE_RAFT_VOTER are now marked as forwardable so that
forwarding from the broker to the active controller works correctly. Secondly,
org.apache.kafka.raft.KafkaNetworkChannel has now been updated to enable API_VERSIONS_REQUEST and
API_VERSIONS_RESPONSE.

Co-authored-by: Murali Basani muralidhar.basani@aiven.io
Reviewers: José Armando García Sancio <jsancio@apache.org>, Alyssa Huang <ahuang@confluent.io>",2024-08-08 15:54:12,Colin Patrick McCabe,Mixed
8ce514a52ef579721cb831ad528a4c8d2d8135b4,"KAFKA-16534; Implemeent update voter sending (#16837)

This change implements the KRaft voter sending UpdateVoter request. The
UpdateVoter RPC is used to update a voter's listeners and supported
kraft versions. The UpdateVoter RPC is sent if the replicated voter set
(VotersRecord in the log) doesn't match the local voter's supported
kraft versions and controller listeners.

To not starve the Fetch request, the UpdateVoter request is sent at most
every 3 fetch timeouts. This is required to make sure that replication
is making progress and eventually the voter set in the replicated log
matches the local voter configuration.

This change also modifies the semantic for UpdateVoter. Now the
UpdateVoter response is sent right after the leader has created the new
voter set. This is required so that updating voter can transition from
sending UpdateVoter request to sending Fetch request. If the leader
waits for the VotersRecord control record to commit before sending the
UpdateVoter response, it may never send the UpdateVoter response. This
can happen if the leader needs that voter's Fetch request to commit the
control record.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2024-08-08 16:16:09,José Armando García Sancio,Mixed
7a8edffad10c5b58fee19985f157942425b103a9,"KAFKA-17267; Don't return REQUEST_TIMED_OUT for OFFSET_FETCHes (#16825)

When handling an OFFSET_FETCH request requiring stable offsets, the new
group coordinator may encounter a timeout under some circumstances, such
as a zombie coordinator or a lagging __consumer_offsets replica that has
not yet dropped out of the ISR. Existing and older clients do not expect
the REQUEST_TIMED_OUT error code won't retry, so remap it to
NOT_COORDINATOR to trigger a coordinator lookup and retry.

Reviewers: David Jacot <djacot@confluent.io>",2024-08-09 01:06:38,Sean Quah,Mixed
ed0e1086a9754fcffdad4467cf004ab027e9a283,"KAFKA-17228; Static member using new protocol should always replace the one using the old protocol (#16800)

This patch enables the static member using the old protocol to be replaced in ConsumerGroupHeartbeat even if it hasn't sent a request to leave the group.

This helps in cases where existing static member rejoins and triggers a group upgrade, because the classic static consumer doesn't send leave group request before shutting down.

Reviewers: TengYao Chi <kitingiao@gmail.com>, David Jacot <djacot@confluent.io>",2024-08-09 01:11:34,Dongnuo Lyu,Mixed
0a4a12fbc4df0ac4b141a869d3880b15b66a7759,"KAFKA-17225: Refactor consumer membership managers (#16751)

The initial drop of ShareMembershipManager contained a lot of code duplicated from MembershipManagerImpl. The plan was always to share as much code as possible between the membership managers for consumer groups and share groups. This issue refactors the membership managers so that almost all of the code is in common.

Reviewers:  Lianet Magrans <lianetmr@gmail.com>,  Chia Chuan Yu <yujuan476@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-08-09 16:18:07,Andrew Schofield,Mixed
6f18f6f33561a91990ed693e54692f02d1bb974a,"KAFKA-16328 Remove Deprecated config from StreamsConfig (#16805)

- StreamsConfig#RETRIES_CONFIG was deprecated in AK 2.7 and is no longer in use.
- StreamsConfig#DEFAULT_WINDOWED_KEY_SERDE_INNER_CLASS and
- StreamsConfig#DEFAULT_WINDOWED_VALUE_SERDE_INNER_CLASS were deprecated in AK 3.0.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-10 00:16:52,TengYao Chi,Mixed
98cdf9717049e87ba34bb5161276577fcb8bd1c4,"KAFKA-17240 Try to complete delyed ops for all purgatories even though one of delayed op throws exception (#16777)

Make DelayedOperations#checkAndCompleteAll has chance to complete delayed ops even though there is a exception caused by one of delayed op.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-10 00:26:49,PoAn Yang,Mixed
e1b2adea07cebaac6d1138ec18778c575aef57f4,"KAFKA-17190: AssignmentsManager gets stuck retrying on deleted topics (#16672)

In MetadataVersion 3.7-IV2 and above, the broker's AssignmentsManager sends an RPC to the
controller informing it about which directory we have chosen to place each new replica on.
Unfortunately, the code does not check to see if the topic still exists in the MetadataImage before
sending the RPC. It will also retry infinitely. Therefore, after a topic is created and deleted in
rapid succession, we can get stuck including the now-defunct replica in our subsequent
AssignReplicasToDirsRequests forever.

In order to prevent this problem, the AssignmentsManager should check if a topic still exists (and
is still present on the broker in question) before sending the RPC. In order to prevent log spam,
we should not log any error messages until several minutes have gone past without success.
Finally, rather than creating a new EventQueue event for each assignment request, we should simply
modify a shared data structure and schedule a deferred event to send the accumulated RPCs. This
will improve efficiency.

Reviewers: Igor Soarez <i@soarez.me>, Ron Dagostino <rndgstn@gmail.com>",2024-08-10 12:31:45,Colin Patrick McCabe,Mixed
b4d5f163a9c5a480efe0a1de3bebf12e35be2a7f,"KAFKA-17067; Fix KRaft transition to CandidateState (#16820)

Only voters should be able to transition to Candidate state. This removes VotedState as one of the EpochStates and moves voted information into UnattachedState.

Reviewers: José Armando García Sancio <jsancio@apache.org>",2024-08-10 07:43:16,Alyssa Huang,Mixed
49fc14f6116a697550339a8804177bd9290d15db,"KAFKA-17273 Migrate BootstrapControllersIntegrationTest to use ClusterTestExtensions (#16822)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-11 19:48:13,PoAn Yang,Not TDD
126b25b51d69cf3ec87d795e5197af08ab7f0dc4,"KAFKA-17288 Removed tracking partition member epoch (KIP-932) (#16828)

Partition epochs are tracked for consumer groups where epoch is the current assigned member epoch. As share groups have partitions shared hence maintaing the partition epochs is not required.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-08-12 07:17:46,Apoorv Mittal,Mixed
38ebb8f48a8e580740ce98d152227489c76734ca,"KAFKA-17270 Let test code use Exit.java rather than Exit.scala (#16821)

Exit.scala is a wrapper around Exit.java, and its main benefit is that it allows methods to throw exceptions by returning Nothing. This benefit is minimal, and since we are planning to phase out Scala code, it would be better to use Exit.java directly and remove Exit.scala.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-12 07:42:28,TengYao Chi,Mixed
bbdf79e1b4ffd4960f42ec128edbced11349c538,"KAFKA-14511; Extend AlterIncrementalConfigs API to support group config (#15067)

This patch add resources to store and handle consumer group's config.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>, David Jacot <djacot@confluent.io>",2024-08-12 00:40:13,DL1231,Mixed
f47b526eb4fe0e4bbf594c08f0e056d7aaaf8e8d,"KAFKA-17289: ShareGroupDescribe integration test (#16846)

Introduces a simple integration test for ShareGroupDescribe.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2024-08-12 18:01:51,Andrew Schofield,Not TDD
5b47975bb96325de65ba370c7412923ec00804a9,"KAFKA-16746: Implemented handleShareAcknowledgeRequest RPC including unit tests (#16792)

Implemented handleShareAcknowledge request RPC in KafkaApis.scala. This method is called whenever the client sends a Share Acknowledge request to the broker. The acknowledge logic is handles asynchronously and the results are handled appropriately.

Reviewers:  Apoorv Mittal <apoorvmittal10@gmail.com>, Jun Rao <junrao@gmail.com>",2024-08-12 07:41:59,Chirag Wadhwa,Mixed
132e0970fbcba984f601dd9b0fb0f0af5c354eb1,"KAFKA-17018: update MetadataVersion for the Kafka release 3.9 (#16841)

- Mark 3.9-IV0 as stable. Metadata version 3.9-IV0 should return Fetch version 17.

- Move ELR to 4.0-IV0. Remove 3.9-IV1 since it's no longer needed.

- Create a new 4.0-IV1 MV for KIP-848.

Reviewers: Jun Rao <junrao@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>, Justine Olshan <jolshan@confluent.io>",2024-08-12 16:30:43,Colin Patrick McCabe,Mixed
deab703e432656e89fca26f0149c44b2cea0f755,"KAFKA-17292: Introduce share coordinator protocol config (#16847)

Add the ""share"" group coordinator rebalance protocol as the way to enable KIP-932. It is also necessary to turn on the new group coordinator.

Reviewers:  Apoorv Mittal <apoorvmittal10@gmail.com>,  Manikumar Reddy <manikumar.reddy@gmail.com>",2024-08-13 08:58:27,Andrew Schofield,Mixed
5b9cbcf886d0666849e81d0fbb8c19d3531c1143,"KAFKA-16689 Move LogValidatorTest to storage module (#16167)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-13 23:04:31,TaiJuWu,Not TDD
ad08ec600fa2b250884e456f18b47c77bf4071dc,"KAFKA-16682 Rewrite JaasTestUtils by Java (#16579)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-14 02:11:33,TengYao Chi,Not TDD
8d29bc1fa8ce75b6807b957ea35ad39e8dd9e04a,"KAFKA-17247 Revised share group record schemas (#16786)

In KIP-932, the group coordinator does not persist assignments for share groups. While this sounds like a good idea in terms of minimising overhead for data which doesn't strictly need to be recoverable, it significantly adds to the complexity of working with the coordinator framework.

This PR revises the definitions of the share group record schemas following more closely the schemas used for consumer groups, and eliminating the need to maintain soft state alongside the group coordinator's timeline structure.

Reviewers: Apoorv Mittal <apoorvmittal10@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-08-14 02:21:00,Andrew Schofield,Mixed
75bcb9eb42fb305bce0eecd4dda265f935cbd108,"KAFKA-17239 add request-latency metrics for node in admin client (#16832)

Reviewers: TengYao Chi <kitingiao@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-08-14 04:33:47,xijiu,Mixed
d64f4b9cd044bd599a0bd35dc3d7226c3f2d70f1,"KAFKA-16714: kafka-share-groups.sh list and describe (#16835)

Introduces kafka-share-groups.sh for listing and describing share groups. The PR also contains the remaining options in the command parser and usage message in preparation of their implementation.

Reviewers:  Manikumar Reddy <manikumar.reddy@gmail.com>, Apoorv Mittal <apoorvmittal10@gmail.com>",2024-08-14 16:22:26,Andrew Schofield,Mixed
3a0efa2845e6a0d237772adfe6364579af50ce18,"KAFKA-14510; Extend DescribeConfigs API to support group configs (#16859)

This patch extends the DescribeConfigs API to support group configs.

Reviewers: Andrew Schofield <aschofield@confluent.io>, David Jacot <djacot@confluent.io>",2024-08-14 06:37:57,DL1231,Not TDD
5dd4d84eecbff0ddc6d066941fca53f6e64dd275,"KAFKA-17272: [1/2] System test framework for consumer protocol migration (#16845)

This patch adds the necessary framework for system tests of consumer protocol upgrade/downgrade paths. The change mainly includes
- adding `ConsumerProtocolConsumerEventHandler` for the consumers using the new protocol.
- some other fixes to consumer_test.py with the new framework which fixes
  - [KAFKA-16576](https://issues.apache.org/jira/browse/KAFKA-16576): fixed by getting `partition_owner` after the group is fully stabilized.
  - [KAFKA-17219](https://issues.apache.org/jira/browse/KAFKA-17219): The first issue is the same as KAFKA-16576. The second issue is fixed by taking `num_rebalances` after the group is fully stabilized.
  - [KAFKA-17295](https://issues.apache.org/jira/browse/KAFKA-17295): Same as KAFKA-17219 second issue. Fixed by taking `num_rebalances` after the group is fully stabilized.

A test result of `tests/kafkatest/tests/client` is [here](https://confluent-open-source-kafka-branch-builder-system-test-results.s3-us-west-2.amazonaws.com/trunk/2024-08-13--001.54e3cf70-869c-465c-bd7a-2ec0c26b2f05--1723594100--confluentinc--kip-848-migration-system-test-framework-comment-aug12--2388f23da7/report.html).

Reviewers: David Jacot <djacot@confluent.io>",2024-08-14 06:47:51,Dongnuo Lyu,Mixed
0f7cd4dcdeb2c705c01743927e36b66b06010f20,"KAFKA-17304; Make RaftClient API for writing to log explicit (#16862)

RaftClient API is changed to separate the batch accumulation (RaftClient#prepareAppend) from scheduling the append of accumulated batches (RaftClient#schedulePrepatedAppend) to the KRaft log. This change is needed to better match the controller's flow of replaying the generated records before replicating them. When the controller replay records it needs to know the offset associated with the record. To compute a table offset the KafkaClient needs to be aware of the records and their log position.

The controller uses this new API by generated the cluster metadata records, compute their offset using RaftClient#prepareAppend, replay the records in the state machine, and finally allowing KRaft to append the records with RaftClient#schedulePreparedAppend.

To implement this API the BatchAccumulator is changed to also support this access pattern. This is done by adding a drainOffset to the implementation. The batch accumulator is allowed to return any record and batch that is less than the drain offset.

Lastly, this change also removes some functionality that is no longer needed like non-atomic appends and validation of the base offset.

Reviewers: Colin Patrick McCabe <cmccabe@apache.org>, David Arthur <mumrah@gmail.com>",2024-08-14 15:42:04,José Armando García Sancio,Mixed
b767c655279083c0a7e958e3f319fe2cead13ddc,"KAFKA-17326 The LIST_OFFSET request is removed from the ""Api Keys"" page (#16870)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-15 18:59:38,Ken Huang,Mixed
7031855570ce922b78c1fd73dd8ef463e352f5c7,"KAFKA-17318 ConsumerRecord.deliveryCount and remove deprecations (#16872)

Reviewers: Apoorv Mittal <apoorvmittal10@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-08-16 00:11:08,Andrew Schofield,Mixed
81f0b13a700f0d29fd7148b52776a80f48fd72be,"KAFKA-17238 Move VoterSet and ReplicaKey from raft.internals to raft (#16775)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-16 00:24:51,TengYao Chi,Mixed
8cfd6312644260717d67fd4dd87dc6794fde52bb,"KAFKA-16723 : Added kafka-console-share-consumer.sh tool. (#16860)

Added kafka-console-share-consumer.sh which will start a share consumer on a share group.
This tool helps to read data from Kafka topics using share groups and outputs it to standard output.

Reviewers:  Andrew Schofield <aschofield@confluent.io>, Apoorv Mittal <apoorvmittal10@gmail.com>,  Manikumar Reddy <manikumar.reddy@gmail.com>",2024-08-16 15:26:54,ShivsundarR,Mixed
9f330c374d1b6d0e50b54ad2d979c57d9672bb87,"KAFKA-16753: [MINOR] Addressing additional review comments (#16894)

Reviewers: Jun Rao <junrao@gmail.com>",2024-08-16 11:59:57,Apoorv Mittal,Mixed
20c3e7324b0fd102382b4c23c86f45fa79cb6690,"KAFKA-16842; Fix config validation and support unknown voters (#16892)

This change fixes the Kafka configuration validation to take into account the reconfiguration changes to configuration and allows KRaft observers to start with an unknown set of voters.

For the Kafka configuration validation the high-level change is that now the user only needs to specify either the controller.quorum.bootstrap.servers property or the controller.quorum.voters property. The other notable change in the configuration is that controller listeners can now be (and should be) specified in advertise.listeners property.

Because Kafka can now be configured without any voters and just the bootstrap servers. The KRaft client needs to allow for an unknown set of voters during the initial startup. This is done by adding the VoterSet#empty set of voters to the KRaftControlRecordStateMachine.

Lastly the RaftClientTestContext type is updated to support this new configuration for KRaft and a test is added to verify that observers can start and send Fetch requests when the voters are unknown.

Reviewers: David Arthur <mumrah@gmail.com>",2024-08-16 15:53:13,José Armando García Sancio,Mixed
c5e91546721b6b160732667ca7450d22927cc3b3,"KAFKA-17342 Moved common coordinator code to separate module (#16883)

There is a lot of code in group-coordinator which is not share/consumer/classic group specific.

Since we are introducing a share-coordinator as part of KIP-932 (in a new module), it would make sense to get the common coordinator functionality into a separate common coordinator module so that share-coordinator need not depend on group-coordinator.

Reviewers: Apoorv Mittal <apoorvmittal10@gmail.com>, David Jacot <djacot@confluent.io>, Andrew Schofield <aschofield@confluent.io>, Jeff Kim <jeff.kim@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-08-18 21:48:44,Sushant Mahajan,Mixed
2f0ae82d4a2205c8056b8e92a954ffbed9fa65fc,"KAFKA-12989 MockClient should respect the request matcher passed to prepareUnsupportedVersionResponse (#16849)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-19 23:19:01,PoAn Yang,Not TDD
3db6e68c4c5e5071de938cfeba7d8ea4e7d81328,"KAFKA-17346: Create :share Gradle module (#16888)

Establishes the new `:share` Gradle module. This module is intended to be used for server-side KIP-932 classes that are not part of the new share group coordinator.

This patch relocates and renames some existing classes. A small amount of compatibility changes were also made, but do not affect any logic.

Reviewers: Andrew Schofield <aschofield@confluent.io>, David Arthur <mumrah@gmail.com>",2024-08-19 16:13:08,Apoorv Mittal,Mixed
34475070e144192266e58c4a1e60939f4ba92b95,"KAFKA-17368 Add delivery count to kafka-console-share-consumer.sh (#16925)

Now that ConsumerRecord.deliveryCount() exists, enhance kafka-console-share-consumer.sh to exploit it. Added support to the DefaultMessageFormatter and the option print.delivery to the usage message for kafka-console-share-consumer.sh. Note that it was not added to kafka-console-consumer.sh even though the option would be recognised - this is because delivery with a consumer group does not count deliveries, and the result would include Delivery:NOT_PRESENT for all records if it was enabled - not really that useful with a consumer group.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-20 06:19:36,Andrew Schofield,Mixed
ee71156295fd32927644ac10771fd60c3d23d63d,"KAFKA-17332; Controller always flush and can call resign on observers (#16907)

This change includes two improvements.

When the leader removes itself from the voters set clients of RaftClient may call resign. In those cases the leader is not in the voter set and should not throw an exception.

Controllers that are observers must flush the log on every append because leader may be trying to add them to the voter set. Leader always assume that voters flush their disk before sending a Fetch request.

Reviewers: David Arthur <mumrah@gmail.com>, Alyssa Huang <ahuang@confluent.io>",2024-08-19 20:44:23,José Armando García Sancio,Mixed
c3d552d27302cfc66c2b6d7b47f1feea70d5c693,"KAFKA-12824 Remove Deprecated method KStream#branch (#16803)

The method branch in both Java and Scala KStream class was deprecated in version 2.8:

1) org.apache.kafka.streams.scala.kstream.KStream#branch
2) org.apache.kafka.streams.kstream.KStream#branch(org.apache.kafka.streams.kstream.Predicate<? super K,? super V>...)
3) org.apache.kafka.streams.kstream.KStream#branch(org.apache.kafka.streams.kstream.Named, org.apache.kafka.streams.kstream.Predicate<? super K,? super V>...)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-20 09:05:13,TengYao Chi,Mixed
42715654095d019effc478ab343c0132e02aa70f,"KAFKA-16900 kafka-producer-perf-test reports error when using transaction. (#16646)

Currently, users need to set --transaction-duration-ms to enable transactions in kafka-producer-perf-test, which is not straightforward. A better approach is to enable transactions when a transaction ID is provided.

This PR allows enabling transaction in kafka-producer-perf-test by either

- set transaction.id=<id> via --producer-props or
- set transaction.id=<id> in config file via --producer.config or
- set --transaction-id <id> or
- set --transaction-duration-ms=<ms>

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-20 10:23:55,Kuan-Po Tseng,Mixed
f6bfa9406ca88d611e9c9ea0120b16d37e6ce015,"KAFKA-17350: Improve share group describe for empty groups (#16897)

When you use kafka-share-groups.sh --describe for an empty group, it prints an empty table consisting of only the table header. kafka-consumer-groups.sh summarises the group status to make the output more informative and only prints the table if it contains more than zero rows.

This PR applies this principle across all of the variants of describing share groups which makes the output much nicer where the output would otherwise be strangely empty.

Reviewers:  Manikumar Reddy <manikumar.reddy@gmail.com>",2024-08-20 12:05:08,Andrew Schofield,Mixed
932e84096a96e199c0772c81bddf3ea3789377ba,"KAFKA-17325: Updated result handling in ShareConsumeRequestManager::commitAsync(). (#16903)

Currently we were not updating the result count when we merged commitAsync() requests into one batch in ShareConsumeRequestManager, so this led to lesser acknowledgements sent to the application thread (ShareConsumerImpl) than expected.
Fix : Now if the acknowledge response came from a commitAsync, then we do not wait for other requests to complete, we always prepare a background event to be sent.

This PR also fixes a bug in ShareConsumeRequestManager, where during the final ShareAcknowledge sent during close(), we also pick up any piggybacked acknowledgements which were waiting to be sent along with ShareFetch.

 Reviewers:  Andrew Schofield <aschofield@confluent.io>,  Manikumar Reddy <manikumar.reddy@gmail.com>",2024-08-20 16:44:53,ShivsundarR,Mixed
c2074388232602ecdd64eea6d11f59686e3c7ca9,"KAFKA-17279: Handle retriable errors from offset fetches (#16826)

Handle retriable errors from offset fetches in ConsumerCoordinator.

Reviewers: Lianet Magrans <lianetmr@gmail.com>, David Jacot <djacot@confluent.io>",2024-08-20 06:13:25,Sean Quah,Mixed
e23172a48a3529c4c8db33bfef824f8ed9b4c64c,"MINOR: Move OffsetCheckpointFile to storage module (#16917)


Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-20 16:29:24,Mickael Maison,Mixed
a537e716eb4c168373c0c9d361e68382a63ee637,"KAFKA-17137 Ensure Admin APIs are properly tested (#16658)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-21 03:34:10,Xuan-Zhang Gong,Not TDD
7b6d4fbc57207fd45a5ab6bc56d566ccf11b4a6b,"KAFKA-17333; ResignedState should not notify of leader change (#16900)

When a voter fails as leader (LeaderState) the quorum-state still states that it is the leader of
the epoch. When the voter starts it never starts as leader and instead starts as resigned
(ResignedState) if it was previously a leader. This causes the KRaft client to immediately notify
the state machine (e.g QuorumController) that it is leader or active. This is incorrect for two
reasons.

One, the controller cannot be notified of leadership until it has reached the LEO. If the
controller is notified before that it will generate and append records that are not based on the
latest state.

Two, it is not practical to notify of local leadership when it is resigned since any write
operation (prepareAppend and schedulePreparedAppend) will fail with NotLeaderException while KRaft
is in the resigned state.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, David Arthur <mumrah@gmail.com>",2024-08-20 16:24:13,José Armando García Sancio,Mixed
944c1353a925858ea9bd9024a713cd7301f55133,"KAFKA-16736 Remove `offsets.commit.required.acks` in 4.0 (#16938)

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-08-21 11:14:04,David Jacot,Mixed
0eaaff88cf68bc2c24d4874ff9bc1cc2b493c24b,"KAFKA-17151 Remove waitForCondition when detecting thread leak (#16661)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-21 17:09:31,PoAn Yang,Mixed
0bb2aee8385c98d38b306f77a8c71875f5d48c1a,"KAFKA-17305; Check broker registrations for missing features (#16848)

When a broker tries to register with the controller quorum, its registration should be rejected if it doesn't support a feature that is currently enabled. (A feature is enabled if it is set to a non-zero feature level.) This is important for the newly added kraft.version feature flag.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, José Armando García Sancio <jsancio@apache.org>",2024-08-21 11:14:56,Alyssa Huang,Mixed
e4cc5d18f45d2965e4e1e571adc34bfb80cba642,"MINOR: remove get prefix for internal Kafka Streams methods (#16722)

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-08-21 14:27:14,Matthias J. Sax,Mixed
28cd7136fb1b5702af82c3736d246c7a1e709140,"KAFKA-16324 Move BrokerApiVersionsCommand to tools (#16850)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-22 09:22:20,PoAn Yang,Mixed
6cad2c0d6785a93d571e64df340dcd86e901ead9,"KAFKA-17370 Move LeaderAndIsr to metadata module (#16943)

 isrWithBrokerEpoch = addBrokerEpochToIsr(isrToSend.toL",2024-08-22 15:47:09,Dmitry Werner,Mixed
246b165456df8e54fbacc68420876fb33727cfeb,"KAFKA-17359 Add tests and enhance the docs of `Admin#describeConfigs` for the case of nonexistent resource  (#16947)

- The different behavior of nonexistent resource. For example: nonexistent broker will cause timeout; nonexistent topic will produce UnknownTopicOrPartitionException; nonexistent group will return static/default configs; client_metrics will return empty configs
- The resources (topic and broker resource types are currently supported) this description is out-of-date
- Add some junit test

Reviewers: Andrew Schofield <aschofield@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-08-23 03:23:34,xijiu,Not TDD
a3aa6372ea1cf9a1eb02e79239d0b54ed5f44ad1,"KAFKA-17336 Add IT to make sure the production MV does not use unstable version of LIST_OFFSET  (#16893)

- due to the server config UNSTABLE_API_VERSIONS_ENABLE_CONFIG is true, so we can't test the scenario of ListOffsetsRequest is unstable version. We want to test this case in this PR
- get the MV from metadataCache.metadataVersion() instead of config.interBrokerProtocolVersion since MV can be set dynamically.

Reviewers: Jun Rao <junrao@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-08-23 03:47:55,Ken Huang,Mixed
79f979cd525a168ea51148974e0d105acb0cd2b9,"KAFKA-17372 Move `ThrottledChannelExpirationTest#testThrottledChannelDelay` and `ThrottledChannel` to server module (#16935)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-23 05:09:57,TengYao Chi,Mixed
eafb92bdce17dbf56afe7f23b8bbc995870f4699,"KAFKA-17193: Pin all external GitHub Actions to the specific git hash (#16960)


Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-23 12:37:12,Mickael Maison,Not TDD
ffc865c4324a2c77a9dbbb90c75202ffd3a0982a,"KAFKA-17291: Add integration test for share group list and describe (#16920)

Add an integration test for share group list and describe admin operations.

Reviewers: Omnia Ibrahim <o.g.h.ibrahim@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-08-23 16:31:04,Andrew Schofield,Not TDD
ced34e3176463759991d1ba322f1c793a243d068,"KAFKA-16379; Coordinator event queue, processing, flush, purgatory time histograms (#16949)

This patch introduces a wrapper around [HdrHistogram](https://github.com/HdrHistogram/HdrHistogram) to use for group coordinator histograms, event queue time, event processing time, flush time, and purgatory time.

Reviewers: David Jacot <djacot@confluent.io>",2024-08-23 04:53:22,Jeff Kim,Mixed
e750f44cf8c72103932435552c69101391b14558,"KAFKA-17409 Remove deprecated constructor of org.apache.kafka.clients.producer.RecordMetadata (#16979)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-25 06:02:42,xijiu,Mixed
4a485ddb71c844acc8bf241feda1fcbffc5ce9be,"KAFKA-17315 Fix the behavior of delegation tokens that expire immediately upon creation in KRaft mode (#16858)

In kraft mode, expiring delegation token (`expiryTimePeriodMs` < 0) has following different behavior to zk mode.

1. `ExpiryTimestampMs` is set to ""expiryTimePeriodMs"" [0] rather than ""now"" [1]
2. it throws exception directly if the token is expired already [2]. By contrast, zk mode does not. [3]

[0] https://github.com/apache/kafka/blob/49fc14f6116a697550339a8804177bd9290d15db/metadata/src/main/java/org/apache/kafka/controller/DelegationTokenControlManager.java#L316
[1] https://github.com/apache/kafka/blob/49fc14f6116a697550339a8804177bd9290d15db/core/src/main/scala/kafka/server/DelegationTokenManagerZk.scala#L292
[2] https://github.com/apache/kafka/blob/49fc14f6116a697550339a8804177bd9290d15db/metadata/src/main/java/org/apache/kafka/controller/DelegationTokenControlManager.java#L305
[3] https://github.com/apache/kafka/blob/49fc14f6116a697550339a8804177bd9290d15db/core/src/main/scala/kafka/server/DelegationTokenManagerZk.scala#L293

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-25 07:29:58,TengYao Chi,Not TDD
d67c18b4aec66fec5d145c9ee737c7a469b8635c,"KAFKA-17331 Set correct version for EarliestLocalSpec and LatestTieredSpec (#16876)

Add the version check to client side when building ListOffsetRequest for the specific timestamp:
1) the version must be >=8 if timestamp=-4L (EARLIEST_LOCAL_TIMESTAMP)
2) the version must be >=9 if timestamp=-5L (LATEST_TIERED_TIMESTAMP)

Reviewers: PoAn Yang <payang@apache.org>, Chia-Ping Tsai <chia7712@gmail.com>",2024-08-25 17:39:28,TengYao Chi,Mixed
11966a209a8bb5bbf867b5bb5ca1d60b80e26650,"KAFKA-17360 local log retention ms/bytes ""-2"" is not treated correctly (#16932)

1) When the local.retention.ms/bytes is set to -2, we didn't replace it with the server-side retention.ms/bytes config, so the -2 local retention won't take effect.
2) When setting retention.ms/bytes to -2, we can notice this log message:

```
Deleting segment LogSegment(baseOffset=10045, size=1037087, lastModifiedTime=1724040653922, largestRecordTimestamp=1724040653835) due to local log retention size -2 breach. Local log size after deletion will be 13435280. (kafka.log.UnifiedLog) [kafka-scheduler-6]
```
This is not helpful for users. We should replace -2 with real retention value when logging.

Reviewers: Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-08-25 19:46:15,Kuan-Po Tseng,Mixed
4ae0ab38dd3a82cf2c36032014ee74af63251859,"MINOR: remove get prefix for internal IQ methods (#16954)

Reviewers: Bill Bejeck <bill@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-08-26 07:02:49,Matthias J. Sax,Mixed
aaf887d3d942d463239369a37e1c97dfa711a775,"KAFKA-14048; [2/2] Use the new group coordinator by default in 4.0 (#16945)

This patch makes the new group coordinator, introduced as part of KIP-848, the default. This means that any KRaft cluster created from trunk defaults to using the new group coordinator. This includes all the integration tests which do not specify it. This patch also changes the default in system tests.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-08-26 01:14:26,David Jacot,Mixed
cb19a557e9526c9764c165f88c4a750413f18f0b,"KAFKA-17373 Add print.epoch to kafka-console-share-consumer.sh/kafka-console-consumer.sh (#16987)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-26 17:30:57,xijiu,Mixed
4886414aa0edcca67ae69399a34cd2bc9c225239,"KAFKA-17324: Set config group.protocol to classic in Streams (#16878)

Streams is not compatible with the new consumer rebalance protocol proposed in KIP-848. Thus, Streams should set/override config group.protocol to classic at startup to ensure that the classic protocol is used.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-08-26 14:01:56,TengYao Chi,Mixed
1621f88f06560394dd2a8415471e8c714b3323c3,"KAFKA-17367: Share coordinator infra classes [1/N] (#16921)

Introduce ShareCoordinator interface and related classes.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Apoorv Mittal <apoorvmittal10@gmail.com>, David Arthur <mumrah@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-08-26 10:09:47,Sushant Mahajan,Mixed
e8b27b6a33ffe9e0790dd5f47465e071b4e8a089,"KAFKA-16335: Remove deprecated method of StreamPartitioner (#15482)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2024-08-26 13:16:43,Caio Guedes,Mixed
ccd24f2cf6ce76146720913d6c22535177ca03a4,"KAFKA-17341 Refactor consumer heartbeat request managers (#16963)

Refactor the heartbeat request managers for consumer groups and share groups. Almost all of the code can be shared which is definitely good.

Reviewers: Lianet Magrans <lianetmr@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-08-27 16:37:37,Andrew Schofield,Mixed
5557720246dea28caa14855e0997bb93a9fcb920,"KAFKA-17038 KIP-919 supports for `alterPartitionReassignments` and `listPartitionReassignments` (#16644)

This is a follow-up after KIP-919, extending support for BOOTSTRAP_CONTROLLERS_CONFIG to both Admin#alterPartitionReassignments and Admin#listPartitionReassignments.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-27 17:12:16,Kuan-Po Tseng,Not TDD
006af8b939017cb0aed3bf8ce5f3f26e137faf77,"KAFKA-17327; Add support of group in kafka-configs.sh (#16887)

The patch adds support of alter/describe configs for group in kafka-configs.sh.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>",2024-08-27 02:16:46,DL1231,Mixed
b9fe9f532fe11c658d07b11543e874526cb837b8,"KAFKA-16972: Move BrokerTopicStats to storage module (#17003)


Reviewers: Luke Chen <showuon@gmail.com>",2024-08-27 11:39:37,Mickael Maison,Mixed
62dc982ce9ce76b299a628d50648e3529fd88e63,"KAFKA-17396: Fix releasing session on final epoch (#16955)

The topic partitions were not being released as the final epoch removes the share session for the client at the start.

The PR streamlines the release process by invoking an explicit releaseSession API which removes the session and releases acquired records. Also newContext and acknowledgeSession method previously used to evict the share session but streamlined methods to just do the needful without altering the share session eviction.

Reviewers:  Andrew Schofield <aschofield@confluent.io>,  Manikumar Reddy <manikumar.reddy@gmail.com>, Chirag Wadhwa <122860692+chirag-wadhwa5@users.noreply.github.com>",2024-08-27 16:14:57,Apoorv Mittal,Mixed
f5439864c6a3cf8275c951a5a09a0d500789d869,"KAFKA-15406: Add the ForwardingManager metrics from KIP-938 (#16904)

Implement the remaining ForwardingManager metrics from KIP-938: Add more metrics for measuring KRaft performance:

kafka.server:type=ForwardingManager,name=QueueTimeMs.p99
kafka.server:type=ForwardingManager,name=QueueTimeMs.p999
kafka.server:type=ForwardingManager,name=QueueLength
kafka.server:type=ForwardingManager,name=RemoteTimeMs.p99
kafka.server:type=ForwardingManager,name=RemoteTimeMs.p999

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2024-08-27 16:39:31,kevin-wu24,Mixed
f9e30289d96b6c096c2bad44d714200e4c34cc04,"KAFKA-17403 Generate HB to leave on pollOnClose if needed (#16974)

Fix to ensure that the HB request to leave the group is generated when closing the HBRequestManager if the state is LEAVING. This is needed because we could end up closing the network thread without giving a chance to the HBManager to generate the request. This flow on consumer.close with short timeout:

1. app thread triggers releaseAssignmentAndLeaveGroup
2. background thread transitions to LEAVING
    2.1 the next run of the background thread should poll the HB manager and generate a request
3. app thread releaseAssignmentAndLeaveGroup times out and moves on to close the network thread (stops polling managers. Calls pollOnClose to gather the final requests and send them along with the unsent)

If 3 happens in the app thread before 2.1 happens in the background, the HB manager won't have a chance to generate the request to leave. This PR implements the pollOnClose to generate the final request if needed.


Reviewers: Kirk True <kirk@kirktrue.pro>, TaiJuWu <tjwu1217@gmail.com>, TengYao Chi <kitingiao@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-08-28 09:04:25,Lianet Magrans,Mixed
fb19b3f7e73acf1d2e98685e1df0ee5b11d216c3,"KAFKA-14262 Deletion of MirrorMaker v1 deprecated classes & tests (#16879)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-28 09:49:56,abhi-ksolves,Mixed
dd7d7c3145d41103525cd212e718a8bdf5dd484b,"KAFKA-17335 Lack of default for URL encoding configuration for OAuth causes NPE (#16990)

AccessTokenRetrieverFactory uses the value of sasl.oauthbearer.header.urlencode provided by the user, or null if no value was provided for that configuration. When the HttpAccessTokenRetriever is created the JVM attempts to unbox the value into a boolean, a NullPointerException is thrown.

The fix is to explicitly check the Boolean, and if it's null, use Boolean.FALSE.

Reviewers: bachmanity1 <81428651+bachmanity1@users.noreply.github.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-08-28 23:11:41,Kirk True,Mixed
f61719f96262d1dd36c99d49861c75ed39c964cb,"MINOR: remove get prefix for internal PAPI methods (#17025)

Reviewers: Bill Bejeck <bill@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-08-28 09:41:32,Matthias J. Sax,Mixed
25819cecdb230ff592197bdd1b454fd695a8c244,"KAFKA-17426; Check node directory id for KRaft (#17017)

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2024-08-28 11:31:58,José Armando García Sancio,Mixed
ca0cc355f6457286f4d986aec0a2ee2eb368813e,"KAFKA-12670: Support configuring unclean leader election in KRaft (#16866)

Previously in KRaft mode, we could request an unclean leader election for a specific topic using
the electLeaders API. This PR adds an additional way to trigger unclean leader election when in
KRaft mode via the static controller configuration and various dynamic configurations.

In order to support all possible configuration methods, we have to do a multi-step configuration
lookup process:

1. check the dynamic topic configuration for the topic.
2. check the dynamic node configuration.
3. check the dynamic cluster configuration.
4. check the controller's static configuration.

Fortunately, we already have the logic to do this multi-step lookup in KafkaConfigSchema.java.
This PR reuses that logic. It also makes setting a configuration schema in
ConfigurationControlManager mandatory. Previously, it was optional for unit tests.

Of course, the dynamic configuration can change over time, or the active controller can change
to a different one with a different configuration. These changes can make unclean leader
elections possible for partitions that they were not previously possible for. In order to address
this, I added a periodic background task which scans leaderless partitions to check if they are
eligible for an unclean leader election.

Finally, this PR adds the UncleanLeaderElectionsPerSec metric.

Co-authored-by: Luke Chen showuon@gmail.com

Reviewers: Igor Soarez <soarez@apple.com>, Luke Chen <showuon@gmail.com>",2024-08-28 14:13:20,Colin Patrick McCabe,Mixed
291523e3e40567f961b4d94068e6946d751d18e4,"KAFKA-12829: Remove the deprecated method `init(ProcessorContext, StateStore)` from the `StateStore` interface (#16906)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Matthias J. Sax <matthias@confluent.io>",2024-08-28 17:49:16,xijiu,Mixed
ad4405c8dd2f94fcce66ccf157866bf2e21b9eb8,"KAFKA-17062: handle dangling ""copy_segment_start"" state when deleting remote logs (#16959)

The COPY_SEGMENT_STARTED state segments are counted when calculating remote retention size. This causes unexpected retention size breached segment deletion. This PR fixes it by
  1. only counting COPY_SEGMENT_FINISHED and DELETE_SEGMENT_STARTED state segments when calculating remote log size.
  2. During copy Segment, if we encounter errors, we will delete the segment immediately.
  3. Tests added.

Co-authored-by: Guillaume Mallet <>

Reviewers: Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Satish Duggana <satishd@apache.org>, Guillaume Mallet <>",2024-08-29 14:09:55,Luke Chen,Mixed
c977bfdd3cda4f7f4d3313d02e151df756872800,"KAFKA-17413; Re-introduce `group.version` feature flag (#17013)

This patch re-introduces the `group.version` feature flag and gates the new consumer rebalance protocol with it. The `group.version` feature flag is attached to the metadata version `4.0-IV0` and it is marked as production ready. This allows system tests to pick it up directly by default without requiring to set `unstable.feature.versions.enable` in all of them. This is fine because we don't plan to do any incompatible changes before 4.0.

Reviewers: Justine Olshan <jolshan@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-08-29 01:22:54,David Jacot,Mixed
8db80d1f07020807bc82707f2d8642ec4fe7eb21,"KAFKA-17064: New consumer assign should update assignment in background thread (#16673)

Reviewers: Kirk True <ktrue@confluent.io>, Lianet Magrans <lianetmr@gmail.com>",2024-08-29 23:01:36,PoAn Yang,Mixed
b154f58ce8b6b0dfb8122d346213521600a18ce5,"KAFKA-12829: Remove deprecated Topology#addGlobalStore of old Processor API (#16791)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2024-08-29 16:52:52,JohnHuang,Not TDD
2b495945a2e15f4bd77cbd36c26a65eef95d74ee,"KAFKA-17377: Consider using defaultApiTimeoutMs in AsyncKafkaConsumer#unsubscribe (#17030)

Reviewers: Kirk True <ktrue@confluent.io>, Lianet Magrans <lianetmr@gmail.com>",2024-08-29 20:24:25,PoAn Yang,Mixed
4a3ab89f95aba294bb536af55548522d946d1ee3,"KAFKA-17386 Remove broker-list, threads and num-fetch-threads in ConsumerPerformance (#16983)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-30 22:09:37,PoAn Yang,Mixed
70dd577286de31ef20dc4f198e95f9b9e4479b47,"KAFKA-15909 Throw error when consumer configured with empty/whitespace-only group.id for LegacyKafkaConsumer (#16933)

Per KIP-289, the use of an empty value for group.id configuration was deprecated back in 2.2.0.

In 3.7, the AsyncKafkaConsumer implementation will throw an error (see KAFKA-14438).

This task is to update the LegacyKafkaConsumer implementation to throw an error in 4.0.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-30 23:24:36,PoAn Yang,Mixed
7005a1fa4b6f94cd9ddb0708bfedeafd27266f52,"KAFKA-17433 Add a deflake Github action (#17019)

This patch adds a ""deflake"" github action which can be used to run a single JUnit test or suites. It works by parameterizing the --tests Gradle option. If the test extends ClusterTest, the ""deflake"" workflow can repeat number of times by setting the kafka.cluster.test.repeat system property.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-31 11:26:33,David Arthur,Not TDD
a6062d08682b5459a904d0abd044be1c51b4f981,"KAFKA-17137 Feat admin client it acl configs (#16648)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-31 12:29:39,Eric Chang,Not TDD
1841c07d4af1daa55f5f332e7c844738c12e7f7c,"KAFKA-17449 Move Quota classes to server-common module (#17060)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-31 12:41:34,Mickael Maison,Mixed
8f4d856977370997be70d6c5b4dccba054e6daaf,"MINOR: add helper function `createTopic` to ClusterInstance (#16852)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-31 19:49:59,TaiJuWu,Not TDD
fc720d33a03e5b40a31b82c4baddb8a23b6e8f9d,"MINOR: remove get prefix for internal state methods (#17053)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-08-31 20:02:06,Matthias J. Sax,Mixed
d44627da9949d84f9369ceae0c742f789661c1c1,"MINOR: remove get prefix for internal KeyValueStoreWrapper (#17065)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-01 10:35:08,Chia Chuan Yu,Mixed
1f5aea2a864e873dd4c0207d8039fe3fd24c66a5,"MINOR: remove get prefix for internal DSL methods (#17050)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-01 17:14:51,Matthias J. Sax,Mixed
0fde28049aab195c19796c28e2e86a3d19884813,"KAFKA-17331 Throw unsupported version exception if the server does NOT support EarliestLocalSpec and LatestTieredSpec (#16873)

Add the version check to server side for the specific timestamp:
- the version must be >=8 if timestamp=-4L
- the version must be >=9 if timestamp=-5L

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-01 21:13:40,PoAn Yang,Mixed
6a2789cf70665bc564bfa582fec17f42b93f3616,"KAFKA-17293: New consumer HeartbeatRequestManager should rediscover disconnected coordinator (#16844)

Reviewers: Lianet Magrans <lianetmr@gmail.com>, TaiJuWu <tjwu1217@gmail.com>",2024-09-01 09:59:21,TengYao Chi,Mixed
b527691e0a7d9aaef6793aaac57ba0e2b909e9d5,MINOR: add missing @Override annotations,2024-09-01 11:37:59,Matthias J. Sax,Not TDD
89418b66aeb3e004e6ef16cd42f2f929d48a6718,"KAFKA-17442: Handled persister errors with write async calls (KIP-932) (#16956)

The PR makes the persister write RPC async. Also handles the errors from persister as per the review comment here:
Addressing review comment for PR: #16397 (comment)

Reviewers: Andrew Schofield <aschofield@confluent.io>, Abhinav Dixit <adixit@confluent.io>, Jun Rao <junrao@gmail.com>",2024-09-01 16:36:26,Apoorv Mittal,Mixed
c30615e6d7732b0214d59985ee5961bc9266b364,"KAFKA-17430: Move RequestChannel.Metrics/RequestMetrics to server module (#17015)


Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-03 10:11:47,Mickael Maison,Mixed
f59d829381a7021971b0b2835fbbacb4abd996a5,"KAFKA-15853 Move TransactionLogConfig and TransactionStateManagerConfig getters out of KafkaConfig (#16665)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-03 18:24:12,Omnia Ibrahim,Mixed
2f9b23625917fed841a176a73bbbc02bfa330a2d,"KAFKA-17294 Handle retriable errors when fetching offsets in new consumer (#16833)

The original behavior was implemented to maintain the behavior of the Classic consumer, where the ConsumerCoordinator would do the same when handling the OffsetFetchResponse. This behavior is being updated for the legacy coordinator as part of KAFKA-17279, to retry on all retriable errors.

We should review and update the CommitRequestManager to align with this, and retry on all retriable errors, which seems sensible when fetching offsets.

The corresponding PR for classic consumer is #16826

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-03 19:05:29,TengYao Chi,Mixed
88b9ff30adf19ba43072a8b26ede07aa4bfa727d,"KAFKA-15859 Introduce remote.list.offsets.request.timeout.ms dynamic config (#17045)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-03 23:06:01,Kamal Chandraprakash,Mixed
839431e59170f162fb0da665f145919edfb16ea7,"KAFKA-17468 Move kafka/log/remote/quota classes to storage module (#17074)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-04 02:18:47,Mickael Maison,Mixed
b0d0956b20735575b7d4d870c2838912f4006940,"KAFKA-17425: Improve coexistence of consumer and share groups (#17039)

This PR ensures that using the various group RPCs work properly when issued against the wrong type of group, such as DescribeConsumerGroups for a share group, or ConsumerGroupHeartbeat for a share group. There are no changes to the RPC error codes required.

The significant code changes are:

Making sure that the group coordinator does not assume that only classic and consumer groups exist. This was the cause of a ClassCastException when ConsumerGroupHeartbeat was being used against a share group.
Making sure that committing offsets to a share group fails with GroupIdNotFoundException rather than java.lang.UnsupportedOperation. This was the cause of a name collision between a share group and a consumer group when using kafka-consumer-groups.sh --reset-offsets which inadvertently created a consumer group of the same name.

 Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2024-09-04 00:16:15,Andrew Schofield,Mixed
edac19ba503762aece76ee2e97068177d27336c5,"KAFKA-17277: [1/2] Add version mapping command to the storage tool and feature command tool (#16973)

As a part of KIP-1022 the following has been implemented in this patch:

A version-mapping command to to look up the corresponding features for a given metadata version. Using the command with no --release-version argument will return the mapping for the latest stable metadata version.
This command has been added to the FeatureCommand Tool and the Storage Tool.
The storage tools parsing method has been made more modular similar to the feature command tool

Reviewers: Justine Olshan <jolshan@confluent.io>",2024-09-03 15:48:36,Ritika Reddy,Mixed
5fd7ce2ace1e0418df033dd32a470d4306a211ea,"KAFKA-17414 Move RequestLocal to server-common module (#16986)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-04 16:12:20,Dmitry Werner,Mixed
9abb8d3b3cbc2bc862d894726cb0aca0b11fe518,"MINOR: Set `group.coordinator.rebalance.protocols` to `classic,consumer` by default (#17057)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-05 13:50:20,David Jacot,Mixed
235a5b6cf910265b65a25228f4d479cfb732b671,"MINOR: `ClusterInstance#waitForTopic` gets hanging when the broker is shutdown (#17085)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-05 14:07:41,TaiJuWu,Not TDD
af0604e6ef683a4ec400ed9d6c65eda4b5b8e08c,"KAFKA-16188: Delete kafka.common.MessageReader (#17090)


Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-05 09:41:59,Mickael Maison,Mixed
b4f47aeff506a45c66d60c40d4f63ca219f68bdc,"KAFKA-16448: Add timestamp to error handler context (#17054)

Part of KIP-1033.

Co-authored-by: Dabz <d.gasparina@gmail.com>
Co-authored-by: loicgreffier <loic.greffier@michelin.com>

Reviewers: Matthias J. Sax <matthias@confluent.io>",2024-09-05 08:42:52,Sebastien Viale,Mixed
eec9eccacb5362eb682e3d6007755b2eb524dda9,"KAFKA-17483: Complete pending share fetch requests on broker close (#17096)

The PR adds capability to complete pending fetch requests on broker shutdown.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-09-06 14:03:51,Apoorv Mittal,Mixed
a9a4a52c9d832e616b3e7608a38dde2ff4f43a9a,"KAFKA-16963: Ducktape test for KIP-853 (#17081)

Add a ducktape system test for KIP-853 quorum reconfiguration, including adding and removing voters.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2024-09-06 13:44:09,Alyssa Huang,Not TDD
e4d108d4df3762843deb568498d5b29c93488e17,"KAFKA-15793 Fix ZkMigrationIntegrationTest#testMigrateTopicDeletions (#17004)


Reviewers: Igor Soarez <soarez@apple.com>, Ajit Singh <>",2024-09-06 21:57:13,David Arthur,Not TDD
be3ab8bdd5e3fdf507fa279f949d9428401c9da9,"KAFKA-14460: Skip removed entries from in-memory KeyValueIterator (#16505)

As described in KAFKA-14460, one of the functional requirements of KeyValueStore is that ""The returned iterator must not return null values"" on methods which return iterator.

This is not completely the case today for InMemoryKeyValueStore. To iterate over the store, we copy the keySet in order not to block access for other threads. However, entries that are removed from the store after initializing the iterator will be returned with null values by the iterator.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2024-09-07 17:06:55,Ayoub Omari,Mixed
72e16cb9e171498b0b9b440b8aefaa0445176fcd,"KAFKA-16863 : Deprecate default exception handlers  (#17005)

Implements KIP-1056:
 - deprecates default.deserialization.exception.handler in favor of deserialization.exception.handler
 - deprecates default.production.exception.handler in favor of production.exception.handler

Reviewers: Matthias J. Sax <matthias@confluent.io>",2024-09-07 20:14:46,Murali Basani,Mixed
4ac1dd4fc7b033e5703d7c469c0d52e7d96788a7,"KAFKA-17482: Make share partition initialization async (KIP-932) (#17097)

The PR introduces states for share partition which are used to make share partition initilzation async.

Reviewers:  Andrew Schofield <aschofield@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-09-09 19:15:08,Apoorv Mittal,Mixed
92672d1df81cd608f9c360260e022c07e41d2ceb,"KAFKA-17470: CommitRequestManager should record failed request only once even if multiple errors in response (#17109)

Reviewers: Lianet Magrans <lmagrans@confluent.io>",2024-09-09 21:52:32,TengYao Chi,Mixed
821c10157d1719f2cc9cb279242805e69158a086,"KAFKA-17367: Introduce share coordinator  [2/N] (#17011)

Introduces the share coordinator. This coordinator is built on the new coordinator runtime framework. It 
is responsible for persistence of share-group state in a new internal topic named ""__share_group_state"".
The responsibility for being a share coordinator is distributed across the brokers in a cluster. 

Reviewers: David Arthur <mumrah@gmail.com>, Andrew Schofield <aschofield@confluent.io>, Apoorv Mittal <apoorvmittal10@gmail.com>",2024-09-09 20:01:24,Sushant Mahajan,Mixed
089cbefac9cb7b6c153c5377ee877ca290b3ee9e,"KAFKA-16830 Remove the scala version formatters support (#17127)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-10 16:04:58,Kuan-Po Tseng,Mixed
af8d058d8e43ed90b02885ae723c9801b8ed71ab,"KAFKA-17491: Move BrokerServerMetrics to server module (#17114)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2024-09-10 11:14:43,Dmitry Werner,Mixed
cd7670d884fdc6ec3dc5817e9fb05b2e54f9805f,"KAFKA-17478 Fix NPE with bad metric.reporters config (#17086)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-10 22:22:06,Frederik Rouleau,Mixed
31f79055cebcc88d866dcd8eb331fd8b85557be9,"KAFKA-17306; Soften the validation when replaying tombstones (#16898)

This patch fixes a few buts in the replay logic of the consumer group records:
* The first issue is that the logic assumed that the group or the member exists when tombstones are replayed. Obviously, this is incorrect after a restart. The group or the member may not me there anymore if the __consumer_offsets partitions only contains tombstones for the group or the member. The patch fixes this by considering tombstones as no-ops if the entity does not exist.
* The second issue is that the logic assumed that consumer group records are always in a specific order in the log so the logic was only accepting to create a consumer group when `ConsumerGroupMemberMetadata` record is replayed. This is obviously incorrect too. During the life time of a consumer group, the records may be in different order. The patch fixes this by allowing the creating of a consumer group by any record.
* The third issue is that it is possible to replay offset commit records for a specific consumer group before the consumer group is actually created while replying its records. By default the OffsetMetadataManager creates a simple classic group to hold those offset commits. When the consumer offset records are finally replayed, the logic will fail because a classic group already exists. The patch fixes this by converting a simple classic group when records for a consumer group are replayed.

All those combinations are hard to test with unit tests. This patch adds an integration tests which reproduces some of those interleaving of records. I used them to reproduce the issues describe above.

Reviewers: TengYao Chi <kitingiao@gmail.com>, Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-09-10 07:28:36,David Jacot,Mixed
e311716bebc88c8c357323236fca671bee81daca,"KAFKA-17492 skip features with minVersion of 0 instead of replacing 0 with 1 when BrokerRegistrationRequest < 4 (#17128)

The 3.8 controller assumes the unknown features have min version = 0, but KAFKA-17011 replace the min=0 by min=1 when BrokerRegistrationRequest < 4. Hence, to support upgrading from 3.8.0 to 3.9, this PR changes the implementation of ApiVersionsResponse (<4) and BrokerRegistrationRequest (<4) to skip features with supported minVersion of 0 instead of replacing 0 with 1

Reviewers: Jun Rao <junrao@gmail.com>, Colin P. McCabe <cmccabe@apache.org>, Chia-Ping Tsai <chia7712@gmail.com>",2024-09-11 01:16:59,Ken Huang,Mixed
6fd973b4a5987c6f829b1285d4f38b029798f186,"KAFKA-16331: Remove EOSv1 from Kafka Streams system tests (#17108)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Bill Bejeck <bill@confluent.io>",2024-09-10 17:55:03,Matthias J. Sax,Not TDD
9242723e4cdfdbdcbd76a66b9965c25c2fbf6abf,"KAFKA-17435 remove use.incremental.alter.configs (#17027)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-11 14:34:05,Xuan-Zhang Gong,Mixed
e380b7f5d1a095c5ca60da3637b93e62e611ba13,"KAFKA-17290: Added Integration tests for ShareFetch and ShareAcknowledge APIs (#16916)

This PR contains Integration Tests for Share Fetch and Share Acknowledge APIs

Reviewers:  Apoorv Mittal <apoorvmittal10@gmail.com>,  Manikumar Reddy <manikumar.reddy@gmail.com>",2024-09-11 14:26:45,Chirag Wadhwa,Not TDD
b4e1deb43a75ca84262d877c5f47bbf2b0dbc6c4,"MINOR: Few cleanups

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2024-09-11 15:12:53,Vikas Singh,Mixed
d04f53489256cf19e7faeacfe325f7527f796cf0,"KAFKA-17109: implement exponential backoff for state directory lock (#17116)

This PR implements exponential backoff for state directory lock to increase the time between two consecutive attempts of acquiring the lock.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-09-11 13:26:19,Alieh Saeedi,Mixed
0e30209f01728d176906df23fad3cf8b36abbf38,"KAFKA-17506 KRaftMigrationDriver initialization race (#17147)

There is a race condition between KRaftMigrationDriver running its first poll() and being notified by Raft about a leader change. If onControllerChange is called before RecoverMigrationStateFromZKEvent is run, we will end up getting stuck in the INACTIVE state.

This patch fixes the race by enqueuing a RecoverMigrationStateFromZKEvent from onControllerChange if the driver has not yet initialized. If another RecoverMigrationStateFromZKEvent was already enqueued, the second one to run will just be ignored.

Reviewers: Luke Chen <showuon@gmail.com>",2024-09-11 10:41:49,David Arthur,Mixed
7b865f2b228a44feacd17d869d60fde7c2c1d73d,"KAFKA-17347 Add missing client-metrics option to kafka-configs.sh (#17046)

When KIP-714 was developed, the entity type of client-metrics was added to the kafka-configs.sh tool. The idea was to have two forms of specifying the name and type of a client metrics config resource, either --entity-type client-metrics --entity-name NAME or --client-metrics NAME. This style of alias is used for all of the entity types. Unfortunately, the --client-metrics form was not implemented. This PR corrects that and adds more tests.

Reviewers: Apoorv Mittal <apoorvmittal10@gmail.com>, DL1231 <53332773+DL1231@users.noreply.github.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-09-12 01:01:03,Andrew Schofield,Mixed
60707a5fe97ba57d4fc809712a6735fb35707dfb,"KAFKA-17392 Remove whitelist option in ConsoleConsumerOptions (#17138)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-12 01:46:16,"Chung, Ming-Yen",Mixed
0c4ffc682ca0d54e702b61e1c9bc71d6eeea3409,"KAFKA-17231 Add missing node latency metrics (#17137)

This is the equivalent of #16755 for the share group consumer.

The node request-latency-max and request-latency-avg were not being recorded and thus reported as NaN for the share group consumer.

Reviewers: Apoorv Mittal <apoorvmittal10@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-09-12 01:56:41,Andrew Schofield,Mixed
3f4c25fe1d800abafa9df81ccaa42b1b3921c824,"KAFKA-17448: New consumer seek should update positions in background thread (#17075)

Reviewers: Lianet Magrans <lmagrans@confluent.io>, Kirk True <ktrue@confluent.io>",2024-09-11 20:08:33,PoAn Yang,Mixed
f466e86bb5600b3b969df4b5f8fa4f5512bd1835,"KAFKA-17400: Added share fetch purgatory for delaying share fetch requests (#16969)

Introduced a share fetch purgatory on the broker which delays share fetch requests that cannot be completed instantaneously. Introduced 2 new classes -

DelayedShareFetch - Contains logic to instantaneously complete or force complete a share fetch request on timeout.
DelayedShareFetchKey - Contains the key which can be used to watch the entries within the share fetch purgatory.
ShareFetchUtils - This utility class contains functionalities required for post-processing once the replica manager fetch is completed.
There are many scenarios which can cause a share fetch request to be delayed and multiple scenarios when a delayed share fetch can be attempted to be completed. In this PR, we are only targeting the case when record lock partition limit is reached, the ShareFetch should wait for up to MaxWaitMs for records to be released.

Reviewers: David Arthur <mumrah@gmail.com>, Andrew Schofield <aschofield@confluent.io>, Apoorv Mittal <apoorvmittal10@gmail.com>, Jun Rao <junrao@gmail.com>",2024-09-11 11:47:33,Abhinav Dixit,Mixed
e0ee73e98ba21b4740f4ca7066c460c7649db655,"KAFKA-16332 Remove Deprecated builder methods for Time/Session/Join/SlidingWindows (#17126)

Removed deprecated methods:
 - TimeWindows#of
 - TimeWindows#grace
 - SessionWindows#with
 - SessionWindows#grace
 - SlidingWindows#withTimeDifferencAndGrace

Reviewers: Matthias J. Sax <matthias@confluent.io>",2024-09-11 14:12:56,Kuan-Po Tseng,Mixed
c62c3899aaa1787b72ec8236e5a2ab290e2989ac,"KAFKA-12829: Remove deprecated StreamsBuilder#addGlobalStore of old Processor API (#17059)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Matthias J. Sax <matthias@confluent.io>",2024-09-11 14:22:08,JohnHuang,Not TDD
a1f28570afb9499fb0cdb9b2928afb50a8a489ff,"MINOR Move scripts into committer-tools (#17162)

Moving reviewers.py and kafka-merge-pr.py into committer-tools. Also include a new find-unfinished-test.py 
script which can be used for finding hanging tests on Jenkins or Github Actions.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-11 18:22:35,David Arthur,Not TDD
300e825be748e6aa55f86f6a6fa588398f1fcc73,"MINOR Refactored share module classes (#17178)

Reviewers: Andrew Schofield <aschofield@confluent.io>, David Arthur <mumrah@gmail.com>",2024-09-12 13:32:15,Apoorv Mittal,Mixed
0035ac06d33fbd427605cd107e3a1da1ff2061ce,"KAFKA-17489: Do not handle failed tasks as tasks to assign (#17115)

Failed tasks discovered when removed from the state updater during assignment or revocation are added to the task registry. From there they are retrieved and handled as normal tasks. This leads to a couple of IllegalStateExceptions because it breaks some invariants that ensure that only good tasks are assigned and processed.

This commit solves this bug by distinguish failed from non-failed tasks in the task registry.

Reviewer: Lucas Brutschy <lbrutschy@confluent.io>",2024-09-13 10:41:45,Bruno Cadonna,Mixed
02e3f7cc284d062adad5324d9493f39559346ae7,"KAFKA-12601 Remove deprecated `delegation.token.master.key` (#17082)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-13 17:21:46,Xuan-Zhang Gong,Mixed
3a79fabacfeb7bb7a182ca676be36fc2da81d26d,"KAFKA-17502: Modified commitSync() and close() handling in clients (#17136)

Currently the code in ShareConsumeRequestManager works on the basis that there can only be one commitSync()/close() at a time. But there is a chance these calls timeout on the application thread, but are still sent later on the background thread. This will mean the incoming commitSync()/close() will not be processed, resulting in possible loss of acknowledgements.

To cover this case, we will now have a list of AcknowledgeRequestStates to store the commitSyncs() and a separate requestState to store the close(). This queue will be processed one by one until its empty. For close(), we are still assuming there can only be one active close() at a time.

eviewers:  Andrew Schofield <aschofield@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-09-13 16:54:05,ShivsundarR,Mixed
d95e384146e67e475b2e0638f70d6f4a708a01dc,"KAFKA-17508: Adding some guard for fallback deletion logic (#17154)

In KAFKA-16424, we added a fallback logic to delete the logs, but the file has no parent. It'd be better we have some guard from it.

Signed-off-by: PoAn Yang <payang@apache.org>

Reviewers: Luke Chen <showuon@gmail.com>",2024-09-13 19:45:30,PoAn Yang,Mixed
d3936365bf0fc7df86c2632a576081474d923e08,"KAFKA-16468: verify that migrating brokers provide their inter.broker.listener (#17159)

When brokers undergoing ZK migration register with the controller, it should verify that they have
provided a way to contact them via their inter.broker.listener. Otherwise the migration will fail
later on with a more confusing error message.

Reviewers: David Arthur <mumrah@gmail.com>",2024-09-13 09:18:24,Colin Patrick McCabe,Mixed
4692aeb67130da9ac3c3410f4ee5c82e4ce10390,"KAFKA-17036 KIP-919 supports for createAcls, deleteAcls, describeAcls (#16493)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-14 03:40:32,PoAn Yang,Mixed
98252cae14bbcad5bc342c41c8eb5101a94e7329,"KAFKA-16681 Rewrite MiniKDC by Java (#16213)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-14 04:13:40,PoAn Yang,Mixed
6610a4d46fa1efb02d905d1dccfd3b58e79f9c1f,"KAFKA-17527: Fix NPE for null RecordContext (#17169)

Reviewers: Bruno Cadonna <bruno@confluent.io>",2024-09-13 16:34:15,Matthias J. Sax,Mixed
d7a456ed5d531465d33cb83f4fafe7f79327d6b8,"KAFKA-17543: Enforce that broker.id.generation.enable is not used when migrating to KRaft (#17192)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Arthur <mumrah@gmail.com>",2024-09-13 17:24:48,Colin Patrick McCabe,Mixed
7a321f29a2495d519165206e50b10595a0ceae9c,"KAFKA-17513 Move LogSegmentsTest to storage module (#17173)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-15 00:26:07,xijiu,Mixed
c95865437b80ad37cc2bf3007fc744b40f712aa8,"KAFKA-16027: Refactor testUpdatePartitionLeadership (#17083)

Reviewers: David Arthur <mumrah@gmail.com>",2024-09-15 09:38:26,TengYao Chi,Mixed
6744a718c2c177c7d462b231ea5e476d98f6eb38,"KAFKA-17066 new consumer updateFetchPositions all in background thread (#16885)

Fix for the known issue that the logic for updating fetch positions in the new consumer was being performed partly in the app thread, party in the background thread, potentially leading to race conditions on the subscription state.

This PR moves the logic for updateFetchPositions to the background thread as a single event (instead of triggering separate events to validate, fetchOffsets, listOffsets). A new UpdateFetchPositionsEvent is triggered from the app thread and processed in the background, where it performs those same operations and updates the subscription state accordingly, without blocking the background thread.

This PR maintains the existing logic for keeping a pendingOffsetFetchRequest that does not complete within the lifetime of the updateFetchPositions attempt, and may be used on the next call to updateFetchPositions.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-09-16 01:43:45,Lianet Magrans,Mixed
344d8a60af8ba7e4ae646501494b17b6987a95d3,"KAFKA-15859 Make RemoteListOffsets call an async operation (#16602)

This is the part-2 of the KIP-1075

To find the offset for a given timestamp, ListOffsets API is used by the client. When the topic is enabled with remote storage, then we have to fetch the remote indexes such as offset-index and time-index to serve the query. Also, the ListOffsets request can contain the query for multiple topics/partitions.

The time taken to read the indexes from remote storage is non-deterministic and the query is handled by the request-handler threads. If there are multiple LIST_OFFSETS queries and most of the request-handler threads are busy in reading the data from remote storage, then the other high-priority requests such as FETCH and PRODUCE might starve and be queued. This can lead to higher latency in producing/consuming messages.

In this patch, we have introduced a delayed operation for remote list-offsets call. If the timestamp need to be searched in the remote-storage, then the request-handler threads will pass-on the request to the remote-log-reader threads. And, the request gets handled in asynchronous fashion.

Covered the patch with unit and integration tests.

Reviewers: Satish Duggana <satishd@apache.org>, Luke Chen <showuon@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-09-16 07:25:06,Kamal Chandraprakash,Mixed
f1c011a8b5c3eb94a9c3f84ea6497b36445bcb5c,"KAFKA-14482 Move LogLoader to storage module (#17042)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-17 00:37:49,Mickael Maison,Mixed
aaf3fc05f8e7cb6b8c79f8471f68faa3a994e1e5,"MINOR: fix rawtype warning in StandbyTask (#17203)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-16 11:49:19,Matthias J. Sax,Mixed
09e3c12057b1e15ad2a9fb85af452fd3c3dc87e1,"KAFKA-17543: Improve and clarify the error message about generated broker IDs in migration (#17210)

This PR tries to improve the error message when broker.id is set to -1 and ZK migration is enabled. It is not
needed to disable the broker.id.generation.enable option. It is sufficient to just not use it (by not setting
the broker.id to -1).

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Luke Chen <showuon@gmail.com>",2024-09-18 11:45:25,Jakub Scholz,Mixed
31d395163e55487c6f2025a2ed08cfe3ad1c9cdb,"KAFKA-17553 Fix shutdown race condition in StreamThreadTest (#17191)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-19 15:17:25,David Arthur,Mixed
14c45bed5a1046b65179935188e6205dcfdf6f98,"KAFKA-17579: Dynamic LogCleaner configurations are picked up on restart

Reviewers: Christo Lolov <lolovc@amazon.com>",2024-09-19 15:52:58,Jason Taylor,Not TDD
8569cf102b93f23e2536a6c8659125f6e8b86a8d,"KAFKA-17356 add integration test for KAFKA-17310 (#17211)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-20 01:14:58,Kuan-Po Tseng,Mixed
79753594ca184170fc9b0ebbec53d204d0092a2d,"KAFKA-16813 Add global timeout (60s) for `@ClusterTemplate`, `@ClusterTest` and `@ClusterTests` (#16957)

Reviewers: TaiJuWu <tjwu1217@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-09-21 02:36:13,Ken Huang,Mixed
2489cf586f81d4ddef25dc409c03dfc3c4ccad24,"KAFKA-16331: remove EOSv1 config from StreamsConfig (#17170)

Reviewers: Bill Bejeck <bill@confluent.io>",2024-09-20 15:55:03,Matthias J. Sax,Mixed
bf450ebe5a4c24492d5dc39cb47da6e7bc0c633f,"MINOR: fix generics in streams-test-utils package (#17206)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-21 22:48:38,Matthias J. Sax,Not TDD
9685aa75470ea85b9d263bf530012446be639eda,"KAFKA-16331 remove EOSv1 from StreamsProducer (#17212)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-23 11:34:39,Matthias J. Sax,Mixed
d06344382574eec3da917e00e4537e40449f16e2,"MINOR: fixing JavaDocs and other cleanup (#17207)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-23 11:46:40,Matthias J. Sax,Mixed
2e8bae8c7ec643234396b81f0862a6a0c9e0a526,"MINOR: Fix SubscriptionResponseWrapperSerializer (#17205)

The existing check is not correct, because `byte` range is from -128...127.
This PR fixes the check to use `< 0`.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-23 19:32:30,Matthias J. Sax,Mixed
67f966f34827c8133d16de7740675fc1f9cded5e,"KAFKA-17469: Moved share external interfaces to share module. (#17262)

Reviewers: Apoorv Mittal <apoorvmittal10@gmail.com>, David Arthur <mumrah@gmail.com>",2024-09-24 12:08:01,Sushant Mahajan,Mixed
db56553fd3b1f265788e3a97ce6f537af00fdb75,"KAFKA-17530 Remove blacklist/whitelist from ReplaceField (#17237)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-25 01:02:28,TaiJuWu,Mixed
a577d30d3828b360915f8982f7c85fc1c378c8c9,"KAFKA-17076: retain last batch in each round of cleaning (#17193)

In each round of cleaning, retain the last batch even if it's empty, so that logEndOffset info will not get lost after compaction.

Reviewers: Jun Rao <junrao@gmail.com>",2024-09-24 21:20:19,Vincent Jiang,Mixed
bb97d63d418fe047cf5a59b16c7004e5011402da,"KAFKA-17578: Remove partitionRacks from TopicMetadata (#17233)

The ModernGroup#subscribedTopicMetadata takes too much memory due to partitionRacks. This is not being used at the moment as the consumer protocol does not support rack aware assignments.

A heap dump from a group with 500 members, 2K subscribed topic partitions shows 654,400 bytes used for partitionRacks. The rest of the ConsumerGroup object holds 822,860 bytes.

Reviewers: David Jacot <djacot@confluent.io>",2024-09-25 00:48:48,PoAn Yang,Mixed
ab0df20489a8d6079cc576f4d9f7326db4b333c9,"KAFKA-17592; Support for SubscribedTopicsRegex in ConsumerGroupHeartbeat RPC (#17257)

This patch includes:
- Bump ConsumerGroupHeartbeatRequest version to include subscribedTopicRegex field
- Introduce new error code for InvalidRegularExpression 
- Bump ConsumerGroupHeartbeatResponse version to support new regex error
- Wire the new field into the GroupMetadataManager when processing HB

Reviewers: David Jacot <djacot@confluent.io>",2024-09-25 00:52:05,Lianet Magrans,Mixed
84fee3399edee0e2940d20315f7e45acda747f48,"KAFKA-17087 Deprecate `delete-config` of TopicCommand (#17222)

Reviewers: Apoorv Mittal <apoorvmittal10@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-09-26 03:37:10,TengYao Chi,Mixed
2637d12e2f4cbd8d46c1ed108a9a3b4e12c0c924,"KAFKA-16908 Refactor `QuorumConfig` with `AbstractConfig` (#17231)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-26 04:06:42,xijiu,Mixed
e512b634d406112ddb11d431088266d25dc1bab0,"KAFKA-14563: add feature version supports in the producers and ApiVersions (#17265)

Add the client side feature version handling.

Reviewers: Artem Livshits <alivshits@confluent.io>, Justine Olshan <jolshan@confluent.io>",2024-09-25 17:50:14,Calvin Liu,Mixed
6b9ea76456646b8f1cfcbb43936c31b846840444,"KAFKA-17057: Add RETRY option to ProductionExceptionHanlder (#17163)

Implements KIP-1065

Reviewers: Alieh Saeedi <asaeedi@confluent.io>, Bill Bejeck <bill@confluent.io>",2024-09-25 20:06:16,Matthias J. Sax,Mixed
560076ba9e8948b91b7af6ae9faa8306ac184059,"KAFKA-15859: Add timeout field to the ListOffsets request (#17112)

This is part-3 of the KIP-1075.

Added a `timeoutMs` field to the ListOffsets request. This timeout is applicable only for the topic/partitions that are enabled with remote storage. 

When the timeout is defined in the request, then we use it to define the delay timeout for `DelayedRemoteListOffsets` request. When the timeout is not defined (requests from older client), then we take the dynamic `remote.list.offsets.request.timeout.ms` server config as the timeout.

Consumer and Admin client behavior are different. Consumer retries the LIST_OFFSETS request in-case of an error but not the AdminClient. And, consumer timeouts the request, if the response exceeds `request.timeout.ms`, whereas, AdminClient timeouts the request when it exceeds the `default.api.timeout.ms`. 

To retain the same behavior, we are passing the `requestTimeoutMs` as timeout from the consumer and defaultApiTimeout / overwritten ListOffsetsOption timeout from the admin.

Reviewers: Satish Duggana <satishd@apache.org>, Luke Chen <showuon@gmail.com>",2024-09-26 11:03:17,Kamal Chandraprakash,Mixed
3d23029d1c91764852faf68fdbd21418259c2b03,"KAFKA-17584: Fix incorrect synonym handling for dynamic log configurations (#17258)

Several Kafka log configurations in have synonyms. For example, log retention can be configured
either by log.retention.ms, or by log.retention.minutes, or by log.retention.hours. There is also
a faculty in Kafka to dynamically change broker configurations without restarting the broker. These
dynamically set configurations are stored in the metadata log and override what is in the broker
properties file.

Unfortunately, these two features interacted poorly; there was a bug where the dynamic log
configuration update code ignored synonyms. For example, if you set log.retention.minutes and then
reconfigured something unrelated that triggered the LogConfig update path, the retention value that
you had configured was overwritten.

The reason for this was incorrect handling of synonyms. The code tried to treat the Kafka broker
configuration as a bag of key/value entities rather than extracting the correct retention time (or
other setting with overrides) from the KafkaConfig object.

Reviewers: Luke Chen <showuon@gmail.com>, Jun Rao <junrao@gmail.com>, Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Christo Lolov <lolovc@amazon.com>, Federico Valeri <fedevaleri@gmail.com>, Rajini Sivaram <rajinisivaram@googlemail.com>, amangandhi94 <>",2024-09-26 14:16:19,Colin Patrick McCabe,Mixed
6abbd548b86c61e8675bef8a4858144af21f4732,"MINOR Refactoring share fetch code (KIP-932) (#17269)

Reviewers: Andrew Schofield <aschofield@confluent.io>, David Arthur <mumrah@gmail.com>",2024-09-26 08:09:31,Apoorv Mittal,Mixed
7c429f3514dd50e98f42c74595c35b5f0b32b7d7,"KAFKA-17612 Remove some tests that only apply to ZK mode or migration (#17276)

Reviewers: David Arthur <mumrah@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-09-26 20:41:29,Colin Patrick McCabe,Mixed
ede0c94aaae3bbc9f3e0ac6bb0b0e6c8b9df39d7,"KAFKA-14562 [1/2]: Implement epoch bump after every transaction (#16719)

Implement server side changes for epoch bump but keep EndTxn as an unstable API until the client side changes are implemented. EndTxnResponse will return the producer ID and epoch for the transaction. Introduces new tagged fields to the TransactionLogValue to persist the clientTransactionVersion, previousProducerId, and nextProducerId to the log so that the state can be reloaded. See KIP-890 for more details.

Small updates to naming of lastProducerId -> PreviousProducerId. Also cleans up the many TransactionMetadata constructors.

Reviewers: Artem Livshits <alivshits@confluent.io>, David Jacot <djacot@confluent.io>",2024-09-26 09:37:11,Justine Olshan,Mixed
68b97705062826f0cef935f4769b1af17f460919,"KAFKA-17608, KAFKA-17604, KAFKA-16963; KRaft controller crashes when active controller is removed (#17146)

This change fixes a few issues.

KAFKA-17608; KRaft controller crashes when active controller is removed
When a control batch is committed, the quorum controller currently increases the last stable offset but fails to create a snapshot for that offset. This causes an issue if the quorum controller renounces and needs to revert to that offset (which has no snapshot present). Since the control batches are no-ops for the quorum controller, it does not need to update its offsets for control records. We skip handle commit logic for control batches.

KAFKA-17604; Describe quorum output missing added voters endpoints
Describe quorum output will miss endpoints of voters which were added via AddRaftVoter. This is due to a bug in LeaderState's updateVoterAndObserverStates which will pull replica state from observer states map (which does not include endpoints). The fix is to populate endpoints from the lastVoterSet passed into the method.

Reviewers: José Armando García Sancio <jsancio@apache.org>, Colin P. McCabe <cmccabe@apache.org>, Chia-Ping Tsai <chia7712@apache.org>",2024-09-26 13:56:19,Alyssa Huang,Not TDD
18340c973378610cd5930974201088b6aca8a8ad,"KAFKA-17563 Move `RequestConvertToJson` to server module (#17223)

Reviewers: Chia-Ping Tsai <chia7712@apache.org>",2024-09-27 02:19:47,xijiu,Mixed
4e52a126ee3b3d6e07b16a705b45ee1cf4849fe8,"KAFKA-17154: New consumer subscribe may join group without a call to consumer.poll (#17165)

Reviewers: Lianet Magrans <lmagrans@confluent.io>, TaiJuWu <tjwu1217@gmail.com>",2024-09-26 20:55:21,PoAn Yang,Mixed
b4eb7cf390e77584c8a0c08955f496552e6725a8,"KAFKA-16683 Extract security-related helpers from scala.TestUtils to java class (#16912)

Reviewers: Chia-Ping Tsai <chia7712@apache.org>",2024-09-27 03:02:11,PoAn Yang,Not TDD
6cb70a831cfb01ee1f66d0baea8ed51c812d094f,"KAFKA-17277: [2/2] Add feature dependency command to the storage and the feature command tool (#17093)

This patch belongs to the ongoing efforts of implementing KIP-1022.

Added feature-dependencies command to look up dependencies for a given feature version supplied by --feature flag. If the feature is not known or the version not yet defined, we throw an error.

Examples :
bin/kafka-feature feature-dependencies --feature transaction.version=2
transaction.version=2 requires:
metadata.version=4 (3.3-IV0) (listing any other version dependencies)

bin/kafka-feature feature-dependencies --feature metadata.version=17
metadata.version=17 (3.7-IV2) has no dependencies

Reviewers: Justine Olshan <jolshan@confluent.io>, Artem Livshits <alivshits@confluent.io>",2024-09-26 15:44:08,Ritika Reddy,Mixed
27a3c752161d97db096dc0e8d905c7224b4aee2b,"KAFKA-17488: Cleanup (test) code for Kafka Streams ""metric version"" (#17182)

This PR simply StreamsMetricsImpl to avoid passing in the unused ""metric version"" parameter.

Reviewers: Matthias J. Sax <matthias@confluent.io>",2024-09-26 17:04:01,Joao Pedro Fonseca Dantas,Mixed
ce5491b7bf80b39f402d8914e19646663180ef40,"KAFKA-16331: remove KafkaClientSupplier from StreamsProducer (#17259)

With EOSv1 removed, we don't need to create a producer per task, and thus can simplify the code by removing KafkaClientSupplier from the deeply nested StreamsProducer, to simplify the code.

Reviewers: Bill Bejeck <bill@confluent.io>",2024-09-26 17:07:00,Matthias J. Sax,Mixed
05366d2fa7c4bf06b32657f654c678bc9bfd7ee1,"KAFKA-17626: Move common fetch related classes from storage to server-common (#17289)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Arthur <mumrah@gmail.com>",2024-09-26 20:31:28,Apoorv Mittal,Mixed
bc47ce1a53e693709e0005517c82f33c6880afe2,MINOR: Fix a race and add JMH bench for HdrHistogram (#17221),2024-09-27 23:49:10,Dimitar Dimitrov,Mixed
05d05e1b5e382e76209b0a9536bbe5eb27ffc292,"KAFKA-17581: AsyncKafkaConsumer can't unsubscribe invalid topics (#17244)

Reviewers: Kirk True <ktrue@confluent.io>, Lianet Magrans <lmagrans@confluent.io>",2024-09-27 16:56:22,PoAn Yang,Mixed
10c789416c254f48104b7f9a44c82375eff8fb00,"KAFKA-17619: Remove zk type and instance from ClusterTest (#17284)

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Chia-Ping Tsai <chia7712@gmail.com>, David Arthur <mumrah@gmail.com>",2024-09-27 11:38:15,PoAn Yang,Not TDD
1854d4b8a11461b53b59fa109b95f2a4f5003997,"KAFKA-14572: Migrate EmbeddedKafkaCluster used by Streams integration tests from EmbeddedZookeeper to KRaft (#17016)

Migrate the EmbeddedKafkaCluster from the EmbeddedZookeeper to KRaft

Reviewers Bill Bejeck <bbejeck@apache.org>",2024-09-27 15:49:12,Omnia Ibrahim,Not TDD
16cac978735eb2e73421247e74f7e09fec6d0410,"KAFKA-17636 Fix missing SCRAM bootstrap records (#17305)

Fixes a regression introduced by #16669 which inadvertently stopped processing SCRAM arguments from kafka-storage.sh

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Federico Valeri <fedevaleri@gmail.com>",2024-09-28 09:57:25,David Arthur,Mixed
05696037d330e5e355d62cb1b977bac9df78db82,"KAFKA-12823 Remove Deprecated method KStream#through (#16761)

Implements KIP-1087

Reviewers: Matthias J. Sax <matthias@confluent.io>, Lucas Brutschy <lbrutschy@confluent.io>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2024-09-28 15:21:26,Arnav Dadarya,Mixed
40360819bb97d6b05dfef6451888b4d908fc3bf4,"KAFKA-17498: Reduce the number of remote calls when serving LIST_OFFSETS request (#17132)

While serving  LIST_OFFSETS request, avoid fetching the remote indexes if they can be served from the local indexes. 

Reviewers: Satish Duggana <satishd@apache.org>, Luke Chen <showuon@gmail.com>, Christo Lolov <lolovc@amazon.com>",2024-09-30 12:14:46,Kamal Chandraprakash,Mixed
bb112570ae0599702aa3f3e38fae1b4f252bdacb,"KAFKA-17109: Move lock backoff retry to streams TaskManager  (#17209)

This PR implements exponential backoff for failed initializations of tasks due to lock exceptions. It increases the time between two consecutive attempts of initializing the tasks.

Reviewer: Bruno Cadonna <cadonna@apache.org>",2024-09-30 13:30:54,Alieh Saeedi,Mixed
800de133bf6f6ea3157deaa3e3092e780cd82a10,"KAFKA-17634 Tweak wakeup logic to match WakeupTrigger changes (#17304)

WakeupTrigger was refactored as a result of changes in AsyncKafkaConsumer. This PR makes the equivalent changes in ShareConsumerImpl.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-09-30 21:50:44,Andrew Schofield,Mixed
818ee8a581b92ccd0434310ea3b108e76daea565,"KAFKA-17078: Add SecurityManagerCompatibility shim (#16522)

Signed-off-by: Greg Harris <greg.harris@aiven.io>
Reviewers: José Armando García Sancio <jsancio@apache.org>, Omnia Ibrahim <o.g.h.ibrahim@gmail.com>, Chris Egerton <fearthecellos@gmail.com>, Luke Chen <showuon@gmail.com>, David Arthur <mumrah@gmail.com>",2024-09-30 08:06:14,Greg Harris,Mixed
7fb25a2b0683bd4e7238eb705f03c955210bea1f,"KAFKA-16769 Remove add.source.alias.to.metrics configuration (#17323)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-02 02:03:02,Mickael Maison,Mixed
4312ce6d250a60b15ee5ae0aac3aaab2c1f2bcc9,"MINOR: improve RecordCollectorImpl (#17185)

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-10-01 12:33:42,Matthias J. Sax,Mixed
49d7ea6c6a2afe4620d089625b3473f913a3f11e,"KAFKA-16308 [3/N]: Introduce feature dependency validation to UpdateFeatures command (#16443)

This change includes:

1. Dependency checking when updating the feature (all request versions)
2. Returning top level error and no feature level errors if any feature failed to update and using this error for all the features in the response. (all request versions)
3. Returning only top level none error for v2 and beyond

Reviewers: Jun Rao <jun@confluent.io>",2024-10-01 14:21:38,Justine Olshan,Mixed
7b7eb6243f020d9ad54fd40cc290f41e52abc6ca,"KAFKA-17367: Share coordinator persistent batch merging algorithm. [3/N] (#17149)

This patch introduces a merging algorithm for persistent state batches in the share coordinator. 

The algorithm removes any expired batches (lastOffset before startOffset) and then places the rest in a sorted map. It then identifies batch pairs which overlap and combine them while preserving the relative priorities of any intersecting sub-ranges. The resultant batches are placed back into the map. The algorithm ends when no more overlapping pairs can be found.

Reviewers: Andrew Schofield <aschofield@confluent.io>, David Arthur <mumrah@gmail.com>, Apoorv Mittal <apoorvmittal10@gmail.com>, Jun Rao <junrao@gmail.com>",2024-10-02 11:30:51,Sushant Mahajan,Mixed
540fb91103efc17b01a6fcdc649a3ee43d0ab9f1,"KAFKA-17258 Migrate AdminFenceProducersIntegrationTest to ClusterTestExtensions framework (#17311)

Reviewers: Ken Huang <s7133700@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-10-03 00:47:29,"Chung, Ming-Yen",Not TDD
ae6e53fab2adfb5024e9687fd6a21cd61ee8fa84,"MINOR: Fix MockAdminClient to match the server side update features handling. (#17343)

49d7ea6 updated the behavior of the UpdateFeaturesRequest/Response, but the MockAdminClient did not reflect those changes.

Now if any feature fails, all the features fail and the correct message is written in the result. Also only update the features if all features are successful and the command is not validate only.

Reviewers: Jun Rao <jun@confluent.io>",2024-10-02 13:20:44,Justine Olshan,Not TDD
979740b49d32db4ca7dfb212f913d0842001ea92,"KAFKA-17589 Move JUnit extensions to test-common module (#17318)

This patch completely removes the compile-time dependency on core for both test and main sources by introducing two new modules.

1) `test-common` include all the common test implementation code (including dependency on :core for BrokerServer, ControllerServer, etc)
2) `test-common:api` new sub-module that just includes interfaces including our junit extension

Reviewers: David Arthur <mumrah@gmail.com>",2024-10-03 10:28:37,Chia-Ping Tsai,Mixed
d0ad84df5d52fdc55b590356cd0bba62c2de6a8e,"MINOR: producer perf improvements (#17348)

Adding some missing input checks and fixing a formatting issue.

Signed-off-by: Federico Valeri <fedevaleri@gmail.com>

Reviewers: Luke Chen <showuon@gmail.com>",2024-10-03 10:29:19,Federico Valeri,Mixed
8be808ea4a0d31f87bacd327faf3274460d3ccb3,"KAFKA-17285 Consider using `Utils.closeQuietly` to replace `CoreUtils.swallow` when handling Closeable objects (#16843)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-03 10:45:01,bboyleonp666,Not TDD
e3e3f25cc4527f4a8144d6dd641d8c9306679d1a,"KAFKA-17500: Metadata redirection for NOT_LEADER_OR_FOLLOWER (#17279)

This PR implements the metadata redirection feature of the ShareFetch and ShareAcknowledge responses where an error code of NOT_LEADER_OR_FOLLOWER or FENCED_LEADER_EPOCH along with current leader information in the response is used to optimise handling of leadership changes in the client. This is applying the logic of KIP-951 to share group consumers.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2024-10-03 10:51:34,Andrew Schofield,Mixed
99e1d8fbb30c8c132cd9baec016efb833b6036ec,"MINOR: Cache topic resolution in TopicIds set (#17285)

Looking up topics in a TopicsImage is relatively slow. Cache the results
in TopicIds to improve assignor performance. In benchmarks, we see a
noticeable improvement in performance in the heterogeneous case.

Before
```
Benchmark                                       (assignmentType)  (assignorType)  (isRackAware)  (memberCount)  (partitionsToMemberRatio)  (subscriptionType)  (topicCount)  Mode  Cnt    Score   Error  Units
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false          10000                         10         HOMOGENEOUS          1000  avgt    5   36.400 ± 3.004  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false          10000                         10       HETEROGENEOUS          1000  avgt    5  158.340 ± 0.825  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL         UNIFORM          false          10000                         10         HOMOGENEOUS          1000  avgt    5    1.329 ± 0.041  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL         UNIFORM          false          10000                         10       HETEROGENEOUS          1000  avgt    5  382.901 ± 6.203  ms/op
```

After
```
Benchmark                                       (assignmentType)  (assignorType)  (isRackAware)  (memberCount)  (partitionsToMemberRatio)  (subscriptionType)  (topicCount)  Mode  Cnt    Score   Error  Units
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false          10000                         10         HOMOGENEOUS          1000  avgt    5   36.465 ± 1.954  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL           RANGE          false          10000                         10       HETEROGENEOUS          1000  avgt    5  114.043 ± 1.424  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL         UNIFORM          false          10000                         10         HOMOGENEOUS          1000  avgt    5    1.454 ± 0.019  ms/op
ServerSideAssignorBenchmark.doAssignment             INCREMENTAL         UNIFORM          false          10000                         10       HETEROGENEOUS          1000  avgt    5  342.840 ± 2.744  ms/op
```

---

Based heavily on https://github.com/apache/kafka/pull/16527.

Reviewers: David Arthur <mumrah@gmail.com>, David Jacot <djacot@confluent.io>",2024-10-03 00:40:25,Sean Quah,Mixed
1962917436f463541f9bb63791b7ed55c23ce8c1,"KAFKA-17674: Fix bug on update positions of newly added partitions (#17342)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-03 13:10:54,Lianet Magrans,Mixed
d173842d36413e011252220c01f0da294f179d63,"KAFKA-17469: Move persister related classes to persister pkg. (#17349)

Reviewers: Andrew Schofield <aschofield@confluent.io>, David Arthur <mumrah@gmail.com>",2024-10-03 11:00:22,Sushant Mahajan,Mixed
0edf5dbd204df9eb62bfea1b56993e95737df5a3,"KAFKA-16649: Remove lock from DynamicBrokerConfig.removeReconfigurable (#15838)

Do not acquire the DynamicBrokerConfig lock in DynamicBrokerConfig.removeReconfigurable. It's not
necessary, because the list that these functions are modifying is a thread-safe
CopyOnWriteArrayList.  In DynamicBrokerConfig.reloadUpdatedFilesWithoutConfigChange, I changed the
code to use a simple Java forEach rather than a Scala conversion, in order to feel more confident
that concurrent modifications to the List would not have any bad effects here. (forEach is always
safe on CopyOnWriteArrayList.)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>, David Arthur <mumrah@gmail.com>",2024-10-03 09:25:17,Colin Patrick McCabe,Not TDD
85bfdf4127e135eb85f01be6285dca4094e8ac79,"KAFKA-17613: Remove ZK migration code (#17293)

Remove the controller machinery for doing ZK migration in Kafka 4.0.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Arthur <mumrah@gmail.com>",2024-10-03 12:01:14,Colin Patrick McCabe,Mixed
dbd50ff84725c01785472087dd1f357e9ed860ae,"KAFKA-16469: Metadata schema checker (#15995)

Create a schema checker that can validate that later versions of a KRPC schema are compatible with earlier ones.

Reviewers: David Arthur <mumrah@gmail.com>",2024-10-03 12:13:38,Colin Patrick McCabe,Mixed
894c4a96914695ae72859adf2d26afca26ba531b,"KAFKA-17525 Convert the UnknownServerException to InvalidRequestException when altering client-metrics config at runtime (#17168)

Reviewers: Apoorv Mittal <apoorvmittal10@gmail.com>, TengYao Chi <kitingiao@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-10-04 10:19:54,TaiJuWu,Not TDD
c8cfb4c7f1ff906cc3ac0d22ba9b99c0c8a14e9c,"KAFKA-17428: Add retry mechanism for cleaning up dangling remote segments (#17335)

This change introduces a retry mechanism for cleaninig up remote segments that failed the copy to remote storage.
It also makes sure that we always update the remote segment state whenever we attempt a deletion.

When a segment copy fails, we immediately try to delete the segment, but this can also fail.
The RLMExpirationTask is now also responsible for retring dangling segments cleanup.

This is how a segment state is updated in the above case:

1. COPY_SEGMENT_STARTED (copy task fails)
2. DELETE_SEGMENT_STARTED (copy task cleanup also fails)
3. DELETE_SEGMENT_STARTED (expiration task retries; self state transition)
4. DELETE_SEGMENT_FINISHED (expiration task completes)
5. COPY_SEGMENT_STARTED (copy task retries)
6. COPY_SEGMENT_FINISHED (copy task completes)

Signed-off-by: Federico Valeri <fedevaleri@gmail.com>

Reviewers: Kamal Chandraprakash<kamal.chandraprakash@gmail.com>, Luke Chen <showuon@gmail.com>",2024-10-04 11:20:07,Federico Valeri,Mixed
cbc02e006d0f1805ff14c843b9c80ce9d601c23b,"KAFKA-16106; Schedule timeout task to refresh classic group size metric (#17325)

In the existing implementation, If an operation modifying the classic group state fails, the group reverts but the group size counter does not. This creates an inconsistency between the group size metric and the actual group size.

Considering that It will be complicated to rely on the appendFuture to revert the metrics upon the operation failure, this PR introduces a new implementation. A timeout task will periodically refresh the metrics based on the current groups soft state. The refreshing interval is hardcoded to 60 seconds.

Reviewers: David Jacot <djacot@confluent.io>",2024-10-04 00:31:06,Dongnuo Lyu,Mixed
16186eabcddc2cc17a39949a68c9eb13ac8bc5c3,"KAFKA-16927; Handle expanding leader endpoints (#17363)

When a replica restarts in the follower state it is possible for the set of leader endpoints to not match the latest set of leader endpoints. Voters will discover the latest set of leader endpoints through the BEGIN_QUORUM_EPOCH request. This means that KRaft needs to allow for the replica to transition from Follower to Follower when only the set of leader endpoints has changed.

Reviewers: Colin P. McCabe <cmccabe@apache.org>, Alyssa Huang <ahuang@confluent.io>",2024-10-04 10:51:43,José Armando García Sancio,Mixed
455c79c339a5135e393864fd0e3ce19be35f465e,"KAFKA-17509: Introduce a delayed action queue to complete purgatory actions outside purgatory. (#17177)

Add purgatory actions to DelayedActionQueue when partition locks are released after fetch in forceComplete. 

Reviewers: David Arthur <mumrah@gmail.com>, Apoorv Mittal <apoorvmittal10@gmail.com>, Jun Rao <junrao@gmail.com>",2024-10-04 09:32:24,Abhinav Dixit,Mixed
c11a38f9df698f84cfd8b2be98a15fc73a0b8925,"KAFKA-17248: KIP-1076 add admin client test helper [1/N] (#17375)

No functional changes, this PR contains a test-helper class for working with AdminClient

Reviewers Matthias Sax <mjsax@apache.org>",2024-10-04 13:58:16,Bill Bejeck,Not TDD
c3f13b5c5709547e42399f10cf33636af3924b4c,"KAFKA-16308 [4/4]: Add release-version flag to upgrade and downgrade commands (#17362)

I've added the release-version flag to the upgrade and downgrade commands. I've also added tests.

While working on this, I realized that we reveal non-production features to be returned in the version-mapping and dependencies commands. I have changed this to only return production features (except in tests) and added tests for this.

Reviewers: Jun Rao <jun@confluent.io>",2024-10-04 13:03:54,Justine Olshan,Mixed
930f165546a83bd3a67567b95249dd485df375fe,"KAFKA-17248: Add reporter for adding thread metrics to telemetry pipeline and a test [2/N] (#17376)

This PR adds a Reporter instance that will add streams thread metrics to the telemetry pipeline.
For testing, the PR adds a unit test.

Reviewers: Matthias Sax <mjsax@apache.org>",2024-10-05 18:28:31,Bill Bejeck,Mixed
f1d65496799d5eb99179c345385a0ecba4e64b89,"KAFKA-17706 Allow all imports for test-common and test-common-api (#17378)

Reviewers: David Arthur <mumrah@gmail.com>",2024-10-06 14:02:10,Chia-Ping Tsai,Not TDD
d38a90df2b68daf7b96f1300e2fca308dc5498cc,"KAFKA-17672 Run quarantined tests separately (#17329)

Introduce new quarantinedTest that excludes tests tagged with ""flaky"". Also introduce two new build parameters ""maxQuarantineTestRetries"" and ""maxQuarantineTestRetryFailures"".

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-06 14:09:24,David Arthur,Not TDD
0e4eebe9c000e9eefad6461fb502f59615d7318b,"KAFKA-12895 Drop support for Scala 2.12 in Kafka 4.0 (#17313)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-07 01:34:38,TengYao Chi,Mixed
924c1081dc78f27947d7ed7f6bbb9d438c5fb5c1,"KAFKA-17415 Avoid overflow of expired timestamp (#17026)

Both ZK and KRaft modes do not handle overflow, so setting a large max lifetime results in a negative expired timestamp and negative max timestamp, which is unexpected behavior.

In this PR, we are only fixing the KRaft code since ZK will be removed soon.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-07 01:43:43,TengYao Chi,Not TDD
9e809be4ce99578a7de1596335061b71eda11d9d,"KAFKA-17529 Remove blacklist from MM2 (#17202)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-07 13:21:31,Chia-Chuan Yu,Mixed
2beadc8bd0cf6383c5159f5701e7f93254f6ef2d,"KAFKA-17695 cleanup org.apache.kafka.common.test.TestUtils (#17364)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-07 13:37:34,Ken Huang,Not TDD
7c34cf6e2cb0359103fa3de5cf3fe49547ce7ce3,"KAFKA-17664: Added check before sending background event after ShareAcknowledge (#17332)

What
Currently, we prepare a ShareAcknowledgeCommitCallback event for every ShareAcknowledgeResponse and send it over to the application thread.
In cases where the acknowledgement commit callback handler is not configured by the user, this event is not used in the application thread. So we can generate this event based on whether the callback was configured.

In this PR, we have a new event which the application thread sends whenever the user enables or disables the commit callback handler, thereby letting the ShareConsumeRequestManager know if it has to send the background event or not.

Test
We also have a unit test verifying if the ShareConsumeRequestManager sends back the event based on the boolean configured.

 Reviewers:  Andrew Schofield <aschofield@confluent.io>,  Manikumar Reddy <manikumar.reddy@gmail.com>",2024-10-07 11:26:55,ShivsundarR,Mixed
10a0905628c65c1fa8df2d0c1c7d1a808074cf08,"KAFKA-17564 Move BrokerFeatures to server module (#17228)

Reviewers: TengYao Chi <kitingiao@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-10-07 15:16:48,Ken Huang,Mixed
18a584c90e8130ce8f37edbb6dda08af9321be1d,"KAFKA-17618; group consumer heartbeat interval should be less than session timeout (#17281)

This patch ensures that the heartbeat interval is smaller than the session timeout.

Reviewers: David Jacot <djacot@confluent.io>",2024-10-07 01:53:26,PoAn Yang,Mixed
366aa1014c01b4c14195d9930e423746f9edd999,"KAFKA-17317; Validate and maybe trigger downgrade after static member replacement (#17306)

This implementation doesn't change the existing downgrade path.

In `classicGroupJoinToConsumerGroup`, if the group should be downgraded, it will be converted to a classic group at the end of the method. The returned records will be the records from GroupJoin plus the records from conversion. No rebalance will be triggered in the newly converted group.

Reviewers: David Jacot <djacot@confluent.io>",2024-10-07 02:11:16,Dongnuo Lyu,Mixed
672c6172334f5c1c25702abaa174eb25858af286,"KAFKA-14577: Move ConsoleProducer to tools module (#17157)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Federico Valeri <fedevaleri@gmail.com>",2024-10-07 11:19:59,Dmitry Werner,Mixed
8dbbf5ea7684d942d41f66a96f5e66399cd50b85,"KAFKA-14705: Move topic filters to tools module (#17387)

After MirrorMaker 1 removal, there are no other modules dependencies for these classes, so we can safely move them to tools module.

Signed-off-by: Federico Valeri <fedevaleri@gmail.com>
Reviewers: Mickael Maison <mickael.maison@gmail.com>",2024-10-07 16:54:36,Federico Valeri,Mixed
dbc0e9af702c109752d6f19eedb1f001ee80ec3f,"KAFKA-17248: Add reporter for getting client metrics into telemetry pipeline and test [3/N] (#17377)

This PR adds a Reporter instance that will add streams client metrics to the telemetry pipeline.
For testing, the PR adds a unit test.

Reviewers: Matthias Sax <mjsax@apache.org>",2024-10-07 16:21:36,Bill Bejeck,Mixed
2733268409e9245bdb18879bbde84ba5a64e0e5a,"KAFKA-17624 Remove the E2E uses of accessing ACLs from zk (#17338)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-08 07:10:14,TengYao Chi,Not TDD
8db86c60a6aefc03ad1082d9c681c9776db14bef,"KAFKA-17385 Remove authorizer, authorizer-properties, zk-tls-config-file in AclCommand (#17224)

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-10-08 08:48:43,PoAn Yang,Mixed
5624bc7c7e43339eb64e18491ac5039324e50678,"MINOR: Remove hamcrest from connect:runtime, raft and server-common (#17394)


Reviewers: David Arthur <mumrah@gmail.com>",2024-10-08 14:22:45,Mickael Maison,Not TDD
3815339e057a57a98416c7ffc14fc5517d8e835b,"KAFKA-14158: Remove auto.include.jmx.reporter configuration (#17360)


Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-08 16:17:07,Mickael Maison,Mixed
374663c64bf4db9f11f3ec199263a144f3a3c2a0,"KAFKA-17287: Added integration tests for ShareConsumer (#17009)

Reviewers: Andrew Schofield <aschofield@confluent.io>, David Arthur <mumrah@gmail.com>",2024-10-08 10:37:16,ShivsundarR,Not TDD
284a3db28aa5f76844f1b1e696d36d88b161c090,"KAFKA-15908: Remove deprecated Consumer.poll(long timeout) (#17368)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, David Jacot <djacot@confluent.io>, Lianet Magrans <lmagrans@confluent.io>",2024-10-08 10:49:10,Andrew Schofield,Mixed
435e9851d2b10ca193f4ded1ccde362203931dad,"KAFKA-17505: New consumer seekToBeginning/End should run in background thread (#17230)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, PoAn Yang <payang@apache.org>, Kirk True <ktrue@confluent.io>, Lianet Magrans <lmagrans@confluent.io>",2024-10-08 20:39:41,TaiJuWu,Mixed
8d186bfb4fbffcc804476a170ad58361ec3b6d28,"KAFKA-16331: Remove task producers from Kafka Streams (#17344)

With EOSv1 removal, we don't have producer-per-task any longer,
and thus can remove the corresponding code which handles task producers.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Bill Bejeck <bill@confluent.io>",2024-10-08 15:36:05,Matthias J. Sax,Mixed
a6bce450ddd5b974ad9484e2fb4d1851c6446754,"KAFKA-17720 Remove zookeeper_migration_test.py and migration-related functions in kafka.py (#17410)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-09 09:45:33,"Chung, Ming-Yen",Not TDD
2836f7aaaed372fc7d6cd3d1db1eab99c494930b,"KAFKA-14705 Remove deprecated classes and options in tools (#17420)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-09 10:33:34,Mickael Maison,Mixed
bb6ebd83f9a0f9b2a37704f1f37b78a48cf480e1,"MINOR: Fix typo and refactor new group coordinator tests (#17072)

This patch fixes a few things:
* Typos.
* Merge the tests for fetchOffsets and fetchAllOffsets together into parameterized tests since they share the same structure.
* Use Topic.GROUP_METADATA_TOPIC_NAME instead of __consumer_offsets in new group coordinator tests.

Reviewers: Ken Huang <s7133700@gmail.com>, David Jacot <djacot@confluent.io>",2024-10-09 07:37:23,Sean Quah,Mixed
8125c3da5bb6ebb35a0cb3494624d33fad4e3187,"KAFKA-17703: Moved DelayedActionsQueue outside DelayedShareFetch (#17380)

Move ActionQueue outside DelayedShareFetch class to SharePartitionManager where SharePartitionManager has the ability to add a delayed action to the ActionQueue.

Add TopicPartition as a key for delayed share fetch along with SharePartition (that is already present right now). This will be utilized later when we add the code to know if new data has been added to the topic partition.

Reviewers: Apoorv Mittal <apoorvmittal10@gmail.com>, Jun Rao <junrao@gmail.com>",2024-10-09 10:53:36,Abhinav Dixit,Mixed
34ebccc79f25681e9a4488c1a153cfd03d695169,"KAFKA-17751; fix pollTimeout calculation in pollFollowerAsVoter (#17434)

KAFKA-16534 introduced a change to send UpdateVoterRequest every ""3 * fetchTimeoutMs"" if the voter's configure endpoints are different from the endpoints persisted in the KRaft log. It also introduced a regression where if the voter nodes do not need an update then updateVoterTimer wasn't reset. This resulted in a busy-loop in KafkaRaftClient#poll method resulting in high CPU usage.

This PR modifies the conditions in pollFollowerAsVoter to reset updateVoterTimer appropriately.

Reviewers: José Armando García Sancio <jsancio@apache.org>",2024-10-09 17:43:01,Gaurav Narula,Not TDD
f1aa3a555ea78c76a44bb6a834f4a9adeeb3f320,"KAFKA-17532-2: Moved ShareGroupConfig and added share.record.lock.duration.ms to dynamic configs (#17331)

This PR is the first series in the attempt to add share.record.lock.duration.ms to dynamic group configs. As part of this PR, the ShareGroupConfig has been moved to org.apache.kafka.coordinator.group.modern.share

Reviewers:  Andrew Schofield <aschofield@confluent.io>,  Apoorv Mittal <apoorvmittal10@gmail.com>, Abhinav Dixit <adixit@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-10-10 11:27:59,Chirag Wadhwa,Mixed
9b62c861fa4650e58a393384ed16dcec9df32fc5,"KAFKA-17739 Clean up build.gradle to adopt the minimum Java version as 11 (#17426)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-10 14:22:38,TengYao Chi,Mixed
a8ab55af7425af6e17d2db1758c8712ef2dc09d5,"KAFKA-17731: Removed timed waiting signal for client telemetry close (#17431)

Reviewers: Andrew Schofield <aschofield@confluent.io>, Kirk True <ktrue@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Lianet Magrans <lmagrans@confluent.io>",2024-10-10 13:19:05,Apoorv Mittal,Mixed
6d650ff9e5c88b707fdf0107beb9a0f1da1a2f8e,"KAFKA-17534: Add configuration to disable the heartbeats topic replication (#17413)

Introducing heartbeats.replication.enabled to explicitly disable the default heartbeats topic replication.
This change implements KIP-1089.

Reviewers: Viktor Somogyi-Vass <viktorsomogyi@gmail.com>",2024-10-10 14:21:36,Dániel Urbán,Mixed
b98aee328bc5f60607ffbab9af8b11b8182fe006,"KAFKA-17620: Simplifying share partition acquire API (kip-932) (#17283)

Simplified Share Partition Acquire API to not include CompletableFuture. The records do not need a future handling rather can be just acquired while updating internal data structure hence now need to of CompletableFuture.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Jun Rao <junrao@gmail.com>",2024-10-10 09:15:22,Apoorv Mittal,Mixed
167e2f71f051fe7672265d1b5ae008622d3ea526,"KAFKA-17713: Don't generate snapshot when published metadata is not batch aligned (#17398)

When MetadataBatchLoader handles a BeginTransactionRecord, it will publish the metadata that has seen so far and not publish again until the transaction is ended or aborted. This means a partial record batch can be published. If a snapshot is generated during this time, the currently published metadata may not align with the end of a record batch. This causes problems with Raft replication which expects a snapshot's offset to exactly precede a record batch boundary.

This patch enhances SnapshotGenerator to refuse to generate a snapshot if the metadata is not batch aligned.

Reviewers: David Arthur <mumrah@gmail.com>",2024-10-10 13:23:14,kevin-wu24,Mixed
b03fe66cfe3b0457c856b12772ac4a95c6eedbbb,"KAFKA-17759 Remove Utils.mkSet (#17460)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-11 21:20:43,Gaurav Narula,Mixed
b3b86d52f4255ef7f6efad83209e3abbc19421e7,"KAFKA-17717 Remove ConfigUtils#translateDeprecatedConfigs and tests (#17458)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-11 21:57:22,mingdaoy,Mixed
d66d808172b8898fa43dcf7635a09cffd1adb587,"MINOR: fix some GHA run syntax (#17471)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-12 08:52:55,David Arthur,Not TDD
d74f1f847a42ffb3013eba68a275da03b970f175,"KAFKA-17199 Add UT for TransactionLogConfig and TransactionStateManagerConfig (#17442)

Reviewers: Ken Huang <s7133700@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-10-12 09:42:54,"Chung, Ming-Yen",Mixed
d55b4e640ca83e2c9b8dc2bd8b9ef981cccca80f,"KAFKA-17763 Remove Utils.covariantCast and use var for type inference (#17468)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-14 15:22:43,Logan Zhu,Not TDD
76a1af984b39d9890fe26954aff36bb1a321af77,"KAFKA-17746 Replace JavaConverters with CollectionConverters (#17451)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-14 17:13:20,Linsiyuan9,Mixed
203f3237ec4e2fbacb34ec6d3b6d1b7c6b45f712,"KAFKA-17374 add bootstrap.controller to kafka-reassign-partitions.sh (#16964)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-14 21:17:00,Ken Huang,Mixed
582bb48e8863523818b9d3a48031a3fc705e8914,"KAFKA-17748 Remove scala-java8-compat (#17497)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-15 13:34:21,TengYao Chi,Mixed
5545d717c350f378af8919445222bf4ebfb15685,"KAFKA-17633: Add share group record formatter and parser. (#17467)

As part of KIP-932, a new internal topic __share_group_state was introduced. There are 2 types of records which are currently being added in this topic - ShareSnapshotKey/Value and ShareUpdateKey/Value
In light of this, we must make the existing tooling like kafka-console-consumer and kafka-dump-log aware of these records for debugging and introspection purposes.
This PR introduces ShareGroupStateMessageFormatter to be used used with kafka-console-consumer and adds an internal class ShareGroupStateMessageParser in DumpLogSegments.scala.
Unit tests have been added to DumpLogSegmentsTest.scala


Reviewers:  Andrew Schofield <aschofield@confluent.io>,  Manikumar Reddy <manikumar.reddy@gmail.com>",2024-10-15 11:44:15,Sushant Mahajan,Mixed
d8b15ecd405ab23636be3133adf4ef7c0d0ed3d0,"KAFKA-17756: Added dynamic share group configs share.heartbeat.interval.ms and share.session.timeout.ms (#17450)

This PR adds the 2 configs share.heartbeat.interval.ms and share.session.timeout.ms in GroupConfig. These can be dynamically set for a share group without restarting the server

Reviewers: Andrew Schofield <aschofield@confluent.io>,  Apoorv Mittal <apoorvmittal10@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-10-15 13:36:12,Chirag Wadhwa,Mixed
604564cce3e195eece6927dc83d150e0150022fc,"KAFKA-15859: Complete delayed RemoteListOffsets requests when replica moves away from broker (#17487)

Removed the ListOffsetsMetadata wrapper class. Complete the response when replica is not a leader.

Reviewers: Jun Rao <junrao@gmail.com>",2024-10-15 17:04:33,Kamal Chandraprakash,Mixed
8e54a0472348e199df3afd3e16ad4f7997bb8cb0,"KAFKA-17536; Ensure clear error message when new consumer used with incompatible cluster (#17411)

In Kafka 4.0, by default the consumer uses the updated consumer group protocol defined in KIP-848. When the consumer is used with a cluster that does not support (or is not configured to use) the new protocol, the consumer will get an unfriendly error about unavailable APIs. Since this error could be the user's first impression when attempting to upgrade to 4.0, we need to make sure that the error is very clear about the remediation steps (set the group.protocol to CLASSIC on the client or upgrade and enable the new protocol on the cluster).

Reviewers: Kirk True <ktrue@confluent.io>, David Jacot <djacot@confluent.io>",2024-10-16 01:30:57,PoAn Yang,Not TDD
5fe59f83e06a850458a0d4ca602a45a6ee306620,"KAFKA-17741 Cleanup code base for JDK 11 (#17441)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-16 23:05:39,TengYao Chi,Mixed
493e4c1cc958afefe60ff63db56f14100c3d2988,"KAFKA-17248: Override admin client to push metrics true, test for case where streams metrics [4/N] (#17422)

This PR disables metrics push for the AdminClient as the default. KafkaStreams enables metrics push for its internal AdminClient.

Tests are included that assert an error if a user disables either the main consumer or admin client metrics push but Kafka Streams metrics push config is enabled.

Reviewers: Matthias Sax <mjsax@apache.org>",2024-10-16 15:01:50,Bill Bejeck,Mixed
1de4f27ec091fdac4f05add43bf38f8c18d90d8a,"KAFKA-17805: Deprecate named topologies in Kafka Streams (#17513)

Deprecate for 4.0. This feature will be phased out, with new functionality generally not supporting named topologies, so users are encouraged to migrate off of named topologies as soon as possible.

Though who are using this experimental feature are encouraged to reach out by filing a jira ticket so we can better understand your use case and how to support it going forward.

Reviewers: Matthias Sax <mjsax@apache.org>",2024-10-16 14:24:30,A. Sophie Blee-Goldman,Mixed
8adfdbbde0cf91c2b596e82fd18aaa985a2e9eed,"KAFKA-17256 KRAFT should honor the listener name and security protocol from ClusterConfig (#16824)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-17 10:34:15,Kuan-Po Tseng,Mixed
5791397d03ab63093bd846549879196999cf03f3,"KAFKA-17776 Capability for connection disconnect listeners in socket server (#17473)

As of now, there isn't any way that resources can be cleaned in Kafka when client disconnects the connections. Generally time bound clean up happens which keep the resources occupied.

This PR provides capability to attach listeners in Socket Server which can react to client connection disconnections.

Reviewers: Jun Rao <junrao@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-10-17 12:28:46,Apoorv Mittal,Mixed
337e80e78a0108c084a48bd3b9da95ea08d074b4,"MINOR: Correctly catch console messages (#17407)

Some tests didn't catch output messages correctly, for example, the output of a test should be ""Completed updating config for user admin."" but we didn't got it. Copied a method from `ToolsTestUtils.java` which can be removed after we move ConfigCommand to tools module.
 Change the output stream from `scala.Console.println` to `System.out.println` to make test easier.",2024-10-17 13:12:28,dengziming,Not TDD
863b728c403238738ca8f25d42b2a2577ebe0b6a,"KAFKA-17677 Remove atomicGetOrUpdate (#17484)

Since we are removing support for Scala 2.12, CoreUtils#atomicGetOrUpdate should also be removed, as it is a workaround for the different behavior between ConcurrentMap.getOrElse and JConcurrentMapWrapper.

JMH results show no significant performance regression when using `getOrElseUpdate`:

Benchmark                                                            (mapSize)  (writePercentage)  Mode  Cnt  Score   Error  Units
ConcurrentMapBenchmark.testConcurrentHashMapComputeIfAbsentReadOnly        100                0.1  avgt    5  4.182 ± 0.006  ns/op
ConcurrentMapBenchmark.testConcurrentHashMapGetReadOnly                    100                0.1  avgt    5  3.372 ± 0.024  ns/op
JMH benchmarks done

Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-10-17 14:16:44,TengYao Chi,Mixed
017da210999c72789ce3b720af04c1a834b80a5c,"KAFKA-17710; Rework uniform heterogeneous assignor to improve perf (#17385)

Rework the uniform heterogeneous assignor to improve performance, while
preserving the high level ideas and structure from the existing
implementation:
 * The assignor works in 3 stages: importing the previous assignment for
   stickiness, assigning unassigned partitions and iteratively
   reassigning partitions to improve balance.
 * Unassigned partitions are assigned to the subscribers with the least
   number of partitions. This maximizes balance within a single topic.
 * During the iterative rebalancing phase, partitions are reassigned to
   their previous owner if it improves balance (stickiness restoration).
 * During the iterative rebalancing phase, partitions are reassigned to
   the subscriber with the least number of partitions to improve
   balance.

A non-exhaustive list of changes is:
 * The assignment of unassigned partitions and iterative reassignment
   stages now works through partitions topic by topic. Previously
   partitions from topics with the same number of partitions per
   subscriber would be interleaved. Since we iterate topic by topic, we
   can reuse data about topic subscribers.
 * Instead of maintaining TreeSets to find the least loaded subscribers,
   we sort an ArrayList of subscribers once per topic and start filling
   up subscribers, least loaded first. In testing, this approach was
   found to be faster than maintaining PriorityQueues.
 * Implement stickiness restoration by creating a mapping of partitions
   to previous owner and checking against that mapping, instead of
   tracking partition movements during iterative reassignment.
 * Track member partition counts using a plain int array, to avoid
   overhead from boxing and HashMap lookups. Member partition counts are
   accessed very frequently and this needs to be fast. As a consequence,
   we have to number members 0 to M - 1.
 * Bound the iterative reassignment stage to a fixed number of
   iterations. Under some uncommon subscription patterns, the iterative
   reassignment stage converges slowly. In these cases, the iterative
   reassignment stage terminates without producing an optimally balanced
   assignment anyway (see javadoc for balanceTopics).
 * Re-use Maps from the previous assignment where possible,
   ie. introduce a copy-on-write mechanism while computing the new
   assignment.

Reviewers: David Jacot <djacot@confluent.io>",2024-10-17 01:43:29,Sean Quah,Mixed
66aa9cd282e882e5238263d8bcc6c86a8cf6c861,"KAFKA-17724 Move SubscriptionState changes to background thread (#17418)

Reviewers: Jason Gustafson <jason@responsive.dev>, Chia-Ping Tsai <chia7712@gmail.com>",2024-10-17 18:29:19,Andrew Schofield,Mixed
5da3b9410dc5e19de438337f7e4e28de5ad399bf,"KAFKA-17778: Add listener to remove client instances on connection disconnect (#17474)

The ClientsMetricManager keeps the client instance cache at a limit of 16384. The active connections can be low, but connections can be created and destroyed in short span. Which hits the cache limit and results in cache miss for new connections.

The client instance cache keeps the instances for 3 * push interval ms. Hence when the cache gets full it creates new instances for every request while evicting others from cache. This gives some bumps to the GC for the broker and eventually CPU. Though with evicting early it will still be garbage collected but the long running active connections will not be removed from the cache.

This PR adds capability to evict client instances from cache when the connection from client is dropped.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Andrew Schofield <aschofield@confluent.io>, Jun Rao <junrao@gmail.com>",2024-10-17 10:10:13,Apoorv Mittal,Mixed
cb3b03377d530cb4815d2fbfd5bf3d9436822ece,"KAFKA-17742: Move DelayedShareFetchPurgatory declaration to ReplicaManager (#17437)

Declare the delayed share fetch purgatory inside ReplicaManager along with the existing purgatories. 

Check the share fetch purgatory when a replica becomes the follower or a replica is deleted from a broker through ReplicaManager.

Perform a checkAndComplete for share fetch when HWM is updated.

Reviewers:  Andrew Schofield <aschofield@confluent.io>,  Apoorv Mittal <apoorvmittal10@gmail.com>, Jun Rao <junrao@gmail.com>",2024-10-17 13:58:10,Abhinav Dixit,Mixed
715606e7035afe456a97804c3a832cf9d2ad4dcb,"MINOR: Use Endpoint instead of EndPoint in RemoteLogManager (#17514)


Reviewers: Luke Chen <showuon@gmail.com>",2024-10-18 09:35:00,Mickael Maison,Mixed
d6b59435708da4ba5d96c160d74aabd41c43284b,"KAFKA-17099: Print the origin processor node in logs when a processing exception occurs (#17475)

This PR leverages the updates brought by KIP-1033 to get the name of the processor node which raised a processing exception and display it in the stacktrace instead of the source node.

Reviewer: Bruno Cadonna <cadonna@apache.org>",2024-10-18 11:31:09,Loïc GREFFIER,Mixed
8107bda69574b85cab1b811597770aa5136d8703,"KAFKA-17654 Fix flaky ProducerIdManagerTest#testUnrecoverableErrors (#17361)

Reviewers: 陳昱霖(Yu-Lin Chen) <chenyulin0719@apache.org>, Chia-Ping Tsai <chia7712@gmail.com>",2024-10-18 21:21:29,Ken Huang,Mixed
b917b85e62373ca66ef249c86b102b5ef8ee7195,"KAFKA-17817 Remove cache from FetchRequest#fetchData (#17535)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-18 21:53:24,xijiu,Mixed
eb897c6ad5e05b6c801482587d5191dfb56a4d27,"MINOR: Fix potential NPE (#17541)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-19 01:05:45,Dmitry Werner,Not TDD
6b28e81ba140975bd4a651d8bbb2f0652ac32746,"KAKFA-17173 move quota config params from KafkaConfig to QuotaConfig (#17505)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-19 18:01:06,Eric Chang,Mixed
b54f0c129fb4da82e8508290abdb9315e7fc4460,"KAFKA-17476 Delete kafka.common.OffsetAndMetadata (#17553)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-20 02:15:24,Mickael Maison,Mixed
76a9df47ca6088361fe707a2946827f7558d9f71,"KAFKA-17639 Add Java 23 to CI build matrix (#17409)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-20 23:55:19,Ken Huang,Not TDD
7efbed4e497bf4943746a2d976336f56f00da07a,"KAFKA-17545: Removing process fetch queue (#17534)

The PR removed the process fetch queue as we have moved to share fetch purgatory.

Reviewers: Abhinav Dixit <adixit@confluent.io>, Jun Rao <junrao@gmail.com>",2024-10-21 09:27:09,Apoorv Mittal,Mixed
e3751a838c1a58ba5fe2570b266a9ca1bca8fdae,"KAFKA-17794: Add some formatting safeguards for KIP-853 (#17504)

KIP-853 adds support for dynamic KRaft quorums. This means that the quorum topology is
no longer statically determined by the controller.quorum.voters configuration. Instead, it
is contained in the storage directories of each controller and broker.

Users of dynamic quorums must format at least one controller storage directory with either
the --initial-controllers or --standalone flags.  If they fail to do this, no quorum can be
established. This PR changes the storage tool to warn about the case where a KIP-853 flag has
not been supplied to format a KIP-853 controller. (Note that broker storage directories
can continue to be formatted without a KIP-853 flag.)

There are cases where we don't want to specify initial voters when formatting a controller. One
example is where we format a single controller with --standalone, and then dynamically add 4
more controllers with no initial topology. In this case, we want the 4 later controllers to grab
the quorum topology from the initial one. To support this case, this PR adds the
--no-initial-controllers flag.

Reviewers: José Armando García Sancio <jsancio@apache.org>, Federico Valeri <fvaleri@redhat.com>",2024-10-21 10:06:41,Colin Patrick McCabe,Mixed
84ab3b9a5c4930f5ae047df088e38c456c7cde54,"KAFKA-17031: Make RLM thread pool configurations public and fix default handling (#17499)

According to KIP-950, remote.log.manager.thread.pool.size should be marked as deprecated and replaced by two new configurations: remote.log.manager.copier.thread.pool.size and remote.log.manager.expiration.thread.pool.size. Fix default handling so that -1 works as expected.

Reviewers: Luke Chen <showuon@gmail.com>, Gaurav Narula <gaurav_narula2@apple.com>, Satish Duggana <satishd@apache.org>, Colin P. McCabe <cmccabe@apache.org>",2024-10-21 10:39:11,Federico Valeri,Mixed
f30f2d03e9064cb9a167fe35b0c5d63470405ce6,"KAFKa-16331: remove EOSv1 support for getting clientInstanceIds (#17521)

With EOSv1 removed, we don't need to collect producer's clientInstanceIds per task any longer. While we never completed this feature, we can remove the corresponding scaffolding code.

Reviewers: Bill Bejeck <bill@confluent.io>",2024-10-21 18:24:46,Matthias J. Sax,Mixed
243e8e28302e40580342bc48d18e353894bf2aa5,"KAFKA-17272 [2/2]: System tests for protocol migration (#17503)

This patch adds `consumer_protocol_migration_test.py` that tests the upgrade/downgrade paths between the old and new group protocol in KIP-848.

A successful test result can be found [here](https://confluent-open-source-kafka-branch-builder-system-test-results.s3-us-west-2.amazonaws.com/dlyu-test-sem-versions/2024-10-21--001/report.html)

Reviewers: David Jacot <djacot@confluent.io>",2024-10-22 07:40:13,Dongnuo Lyu,Not TDD
cfa2edc7a7cac94e7c008e49a4494a50c52d4788,"KAFKA-17844: Complete share fetch request on exception  (#17566)

The PR adds test cases and minor fix to complete share fetch requests on exception from Share Partition Manager.",2024-10-22 20:17:50,Apoorv Mittal,Mixed
d36eb9ed3f0ba3d9b58671f7bd74f82b7bbf6b9e,"KAFKA-17686 AsyncKafkaConsumer.offsetsForTimes() fails with NullPointerException (#17353)

The code to convert the Map was initially expressed using the Streams API with collect(Collectors.toMap()). Unfortunately, the implementation of Collector returned by Collectors.toMap() does not support null entries. The KafkaConsumer.offsetsForTimes() API explicitly states that nulls can be present in the returned Map, hence this change.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-23 02:42:10,Kirk True,Not TDD
25a3590dc23f9f75dcaf6d380b9932f6a0c0411e,"KAFKA-17813: Moving broker endpoint class and common server connection id (#17519)


Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Kuan-Po Tseng <brandboat@gmail.com>, Jun Rao <junrao@gmail.com>",2024-10-22 11:58:28,Apoorv Mittal,Mixed
14a098b289b9b25edddd483e1b088c4c6b7848ad,"KAFKA-17600: Add nextOffsets to the ConsumerRecords (#17414)

This PR implements KIP-1094.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Kirk True <ktrue@confluent.io>, Lucas Brutschy <lbrutschy@confluent.io>",2024-10-23 16:25:50,Alieh Saeedi,Mixed
2d896d9130f121e75ccba2d913bdffa358cf3867,"KAFKA-17614: Remove AclAuthorizer (#17424)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2024-10-23 17:07:48,PoAn Yang,Mixed
2ff13976ab5d75d4d1a518394529dc56a7cb8bd7,"KAFKA-17568 Rewrite TestPurgatoryPerformance by Java (#17246)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-24 02:44:37,Ken Huang,Not TDD
0d44415bac1c33aea637ee98d220626e05e63350,"KAFKA-17774: Adding capability to handle max fetch records in Share Fetch (KIP-932) (#17322)

The PR adds capability to restrict the messages in Share Fetch. The max fetch records will be an additional way to limit the number of records sent from broker to client.

In Share Fetch, with min and mx bytes, there exists 3 problems:

1. The max.poll.records client config sends the max number of records defined to application but might have fetched extra becuase of higher max bytes. But the timeout for the sent records has started on the broker.
2. As the application processes records as per max.poll.records, hence those number of records are sent in every acknowledgement. This causes the cache data to be tracked per offset as the batch is broken.
3. The client has to sent the partial acknoledgment batch and cannot piggyback on fetch requests.

To handle the above scenario max fetch records has been added. Once this PR is merged and we define the right methodolgy then KIP will be updated to have max fetch records in share fetch RPC rather as broker config.

Reviewers: Abhinav Dixit <adixit@confluent.io>, Andrew Schofield <aschofield@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Jun Rao <junrao@gmail.com>",2024-10-23 13:21:32,Apoorv Mittal,Mixed
8faeb9390dd5b866bcb38e23ac3f2453b77d5185,"MINOR: Code cleanup Kafka Streams (#16050)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2024-10-23 16:54:06,Sanskar Jhajharia,Not TDD
3856644cd69edcd0aa4c0a4edeb391ed3a66fd21,"KAFKA-17233: MirrorCheckpointConnector should use batched listConsumerGroupOffsets (#17038)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Greg Harris <gharris1727@gmail.com>",2024-10-24 09:38:44,Joao Pedro Fonseca Dantas,Mixed
553e6b4c6d912b3b619b5a1a5263b616b6d3f62e,"KAFKA-17860 Remove log4j-appender module (#17588)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-24 18:13:30,TengYao Chi,Mixed
140d35c5459f4c7a91b23a238467cb5aa01b59fb,"KAFKA-8779 Fix flaky tests introduced by dynamic log levels (#17382)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-24 21:39:35,Kuan-Po Tseng,Not TDD
98b7e4deaf19b33e52e15eb2c32c4c264dc7ff03,"KAFKA-17574 Allow overriding TestKitNodes baseDirectory (#17225)

This allows shutting down a KafkaClusterTestKit from a JVM shutdown hook without risking error logs because the base directory has already been deleted by the shutdown hook TestUtils.tempDirectory sets up.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-25 01:48:25,Stig Døssing,Not TDD
5311839bd567e565376a86352010f9593285ca5f,"KAFKA-17847 Avoid the extra bytes copy when compressing telemetry payload (#17578)

Reviewers: Apoorv Mittal <apoorvmittal10@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-10-25 03:05:48,ClarkChen,Mixed
1eb7644349cb07139d6a3c1ad1986979647cac99,"KAFKA-16845 Migrate ReplicationQuotasTestRig to new test infra (#17089)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-25 03:33:01,Dmitry Werner,Not TDD
33147d1089397ea20ba46bd0afb83174b45b506c,"KAFKA-17863: share consumer max poll records soft limit (#17592)

Make max.poll.records a soft limit so that record batch boundaries can be respected in records returned by ShareConsumer.poll. This gives a significant performance gain because the broker is much more efficient at handling batches which have not been split.

Reviewers: Apoorv Mittal <apoorvmittal10@gmail.com>,  Manikumar Reddy <manikumar.reddy@gmail.com>",2024-10-25 16:37:14,Andrew Schofield,Mixed
09d76f917c3bdd6a53444b79909b99217421e69b,"KAFKA-16564 Apply `Xlint` to java code in core module (#16965)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-26 01:07:56,Ken Huang,Not TDD
d7ac865fb0d2f739392623a379d056a7bf3c19f4,"KAFKA-17868: Do not ignore --feature flag in kafka-storage.sh (#17597)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Justine Olshan <jolshan@confluent.io>",2024-10-25 12:33:22,Colin Patrick McCabe,Mixed
397ae598e63a430e93e986519356ea517b9ce266,"KAFKA-17848: Fixing share purgatory request and locks handling (#17583)

For delayed fetch, tryComplete can be called again after onComplete. As the requests are processed with parallel threads hence this scenario can occur. We attain locks in tryComplete which keeps pending as onComplete is never called when request is already completed.

Reviewers: Abhinav Dixit <adixit@confluent.io>, Andrew Schofield <aschofield@confluent.io>, Jun Rao <junrao@gmail.com>",2024-10-26 08:00:33,Apoorv Mittal,Mixed
12a60b8cd9989a3f128b26c854a547f0c4dd155b,"KAFKA-17878 Move ActionQueue to server module (#17602)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-28 20:35:23,Dmitry Werner,Not TDD
6e88c10ed5628ff31c0aa3096d16a1c78ef3127f,"KAFKA-14483 Move LocalLog to storage module (#17587)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-28 20:41:46,Mickael Maison,Mixed
14a9130f6fa31c10cb65cc500c101148d0410306,"KAFKA-17793: Improve kcontroller robustness against long delays (#17502)

As described in KIP-500, the Kafka controller monitors the liveness of each broker in the cluster. It gathers this information from heartbeats sent from the brokers themselves.

In some rare cases, the main controller thread may get blocked for several seconds at a time. In the current code, this will result in the controller being unable to update the last contact times for the brokers during this time.

This PR changes the controller heartbeat handling to be partially lockless. Specifically, the last contact time for each broker will be updated locklessly prior to the rest of the heartbeat handling. This will ensure that heartbeats always get through.

Additionally, this PR adds a PeriodicTaskControlManager to better manage periodic tasks. This should help handle the very common pattern where we want to schedule a background task at some frequency. We also want the background task to be immediately rescheduled if there is too much work to be done in one event.

Reviewers: Liu Zeyu <zeyu.luke@gmail.com>, David Arthur <mumrah@gmail.com>",2024-10-28 08:36:07,Colin Patrick McCabe,Mixed
5f92f60bfff8852ec75ce1988316dcb44bfdc918,"KAFKA-17329: DefaultStatePersister implementation (#17270)

Adds the DefaultStatePersister and other supporting classes for managing share state.

* Added DefaultStatePersister implementation. This is the entry point for callers who wish to invoke the share state RPC API.
* Added PersisterStateManager which is used by DefaultStatePersister to manage and send the RPCs over the network.
* Added code to BrokerServer and BrokerMetadataPublisher to instantiate the appropriate persister based on the config value for group.share.persister.class.name. If this is not specified, the DefaultStatePersister will be used. To force use of NoOpStatePersister, set the config to empty. This is an internal config, not to be exposed to the end user. This will be used to factory plug the appropriate persister.
* Using this persister, the internal __share_group_state topic will come to life and will be used for persistence of share group info.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Jun Rao <junrao@gmail.com>, David Arthur <mumrah@gmail.com>",2024-10-28 14:11:04,Sushant Mahajan,Mixed
9e424755d4d236442847b13863580f44f27e22a6,"KAFKA-17439: Make polling for new records an explicit action/event in the new consumer (#17035)

Reviewers: Andrew Schofield <aschofield@confluent.io>, Lianet Magrans <lmagrans@confluent.io>",2024-10-28 15:46:37,Kirk True,Mixed
4817eb9227bc54225f9d24dcdc496f545538a67e,"KAFKA-15344: Streams task should cache consumer nextOffsets (#17091)

This PR augments Streams messages with leader epoch. In case of empty buffer queues, the last offset and leader epoch are retrieved from the streams task 's cache of nextOffsets.

Co-authored-by: Lucas Brutschy <lbrutschy@confluent.io>
Reviewers: Lucas Brutschy <lbrutschy@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2024-10-29 09:30:11,Alieh Saeedi,Mixed
571f50817c0c3e81a8f767396e485bc23a0731ba,"KAFKA-17411: Create local state Standbys on start (#16922)

Instead of waiting until Tasks are assigned to us, we pre-emptively
create a StandbyTask for each non-empty Task directory found on-disk.

We do this before starting any StreamThreads, and on our first
assignment (after joining the consumer group), we recycle any of these
StandbyTasks that were assigned to us, either as an Active or a
Standby.

We can't just use these ""initial Standbys"" as-is, because they were
constructed outside the context of a StreamThread, so we first have to
update them with the context (log context, ChangelogReader, and source
topics) of the thread that it has been assigned to.

The motivation for this is to (in a later commit) read StateStore
offsets for unowned Tasks from the StateStore itself, rather than the
.checkpoint file, which we plan to deprecate and remove.

There are a few additional benefits:

Initializing these Tasks on start-up, instead of on-assignment, will
reduce the time between a member joining the consumer group and beginning
processing. This is especially important when active tasks are being moved
over, for example, as part of a rolling restart.

If a Task has corrupt data on-disk, it will be discovered on startup and
wiped under EOS. This is preferable to wiping the state after being
assigned the Task, because another instance may have non-corrupt data and
would not need to restore (as much).

There is a potential performance impact: we open all on-disk Task
StateStores, and keep them all open until we have our first assignment.
This could require large amounts of memory, in particular when there are
a large number of local state stores on-disk.

However, since old local state for Tasks we don't own is automatically
cleaned up after a period of time, in practice, we will almost always
only be dealing with the state that was last assigned to the local
instance.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>, Bruno Cadonna <cadonna@apache.org>, Matthias Sax <mjsax@apache.org>",2024-10-29 12:59:25,Nick Telford,Mixed
f0a3960e3e114228bd4d8b220812fc142f832b2b,"KAFKA-17867 Consider using zero-copy for PushTelemetryRequest (#17622)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-30 20:49:56,Kuan-Po Tseng,Mixed
7fb6e9ec1c059289740f72c0e27babad24d9beec,"KAFKA-17840 Move ReplicationQuotaManager, ClientRequestQuotaManager and QuotaFactory to server module (#17609)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-30 21:18:28,PoAn Yang,Mixed
30b1bdfc7420f362bf22bfe8d7776f988aa3318b,"KAFKA-17835 Move ProducerIdManager and RPCProducerIdManager to transaction-coordinator module (#17562)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-10-31 02:40:47,Ken Huang,Mixed
d7135b2a5b232df4635e023d2edcccae8fcd7c48,"MINOR: Various cleanups in metadata (#17633)

Reviewers: David Arthur <mumrah@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-10-31 02:48:33,Mickael Maison,Mixed
29881782c842b3d8ecbd2215a12956f3536d4e31,"KAFKA-17609 Migrate broker compatibility test from ZK to KRaft (#17603)

Reviewers: Matthias J. Sax <matthias@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-10-31 04:51:06,Bill Bejeck,Not TDD
fb65dfeb116f86386b1932fb26f188deae67c089,"KAFKA-17726: New consumer subscribe/subscribeFromPattern in background thread (#17569)

Reviewers: Andrew Schofield <aschofield@confluent.io>, Lianet Magrans <lmagrans@confluent.io>",2024-10-30 22:15:13,PoAn Yang,Mixed
ff116df0152381425c98daf32ce78db3fa828063,"KAFKA-17002: Integrated partition leader epoch for Persister APIs (KIP-932) (#16842)

The PR integrates leader epoch for partition while invoking Persister APIs. The write RPC is retried once on leader epoch failure.

Reviewers: Abhinav Dixit <adixit@confluent.io>, Andrew Schofield <aschofield@confluent.io>, Jun Rao <junrao@gmail.com>, David Arthur <mumrah@gmail.com>",2024-10-30 14:41:39,Apoorv Mittal,Mixed
609488231511022146c18be0b3bbd26ad8bb50a9,"KAFKA-17905 Remove the specified type of using lambda for BaseFunction (#17648)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-01 02:33:16,Yung,Not TDD
6f040cabc7c688106eca6b26e64b39948c0b154d,"KAFKA-17116 New consumer may not send effective leave group if member ID received after close (#17549)

KIP-1082 (https://cwiki.apache.org/confluence/display/KAFKA/KIP-1082%3A+Require+Client-Generated+IDs+over+the+ConsumerGroupHeartbeat+RPC)

Reviewers: Andrew Schofield <aschofield@confluent.io>, David Jacot <djacot@confluent.io>, Lianet Magrans <lianetmr@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-11-01 03:03:17,TengYao Chi,Mixed
18b8b992f9baa91d9785d491f7cce2867ecb6ba9,"[KAFKA-17870] Fail CreateTopicsRequest if total number of partitions exceeds 10k (#17604)

We fail the entire CreateTopicsRequest action if there are more than 10k total
partitions being created in this topic for this specific request. The usual pattern for
this API to try and succeed with some topics. Since the 10k limit applies to all topics
then no topic should be created if they all exceede it.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2024-10-31 13:54:03,Jonah Hooper,Mixed
346fdbafc539bc48bb66eedae89a15e240007fd9,"KAFKA-17912 Align string representations of SharePartitionKey (#17656)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-01 15:43:32,Andrew Schofield,Mixed
5a3b544d6172d9811b28eacd9e4a1c55c5dd5e8d,"KAFKA-17880 Move integration test from streams module to streams/integration-tests module (#17615)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-01 18:21:06,PoAn Yang,Mixed
2696a6d7a196374897dcf0968b3fcce8d1668143,"KAFKA-17767 Load test catalog data [3/n] (#17654)

Add a new ""load-catalog"" job to the workflow. This job will checkout the test-catalog branch at 7 days prior and generate a text file of all the tests that were known at that time. This file is then passed down to the two parallel ""test"" jobs to be used as a source of data for the quarantined test behavior.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-01 10:38:47,David Arthur,Not TDD
e14a81b4b288dfd85c340fb77a6f9ba9f6de1ce4,"KAFKA-14562 [2/3]: Implement epoch bump after every transaction (KIP-890) (#17402)

This patch includes changes to the clients end transaction response handling when transaction version 2 is enabled.
Version 5+ of the End Txn Response includes the producer Id and the producer epoch fields.

Upon receiving the request, the client updates its producer Id and epoch according to the response.

On receiving an EndTxnRequest the server would've either:

Bumped the epoch for the given producer ID.
On epoch overflow, sent a new producer Id with epoch 0.
This patch also includes changes to the endTxnRequest to send the right request version based on whether txnV2 is enabled.

There was a test failure in the integration tests that allowed us to catch a bug in the PrepareComplete method where we update the transit metadata incorrectly. Added the bug fix in this patch where the lastProducerEpoch is updated correctly.

Reviewers: Artem Livshits <alivshits@confluent.io>, Justine Olshan <jolshan@confluent.io>",2024-11-01 08:12:00,Ritika Reddy,Mixed
568b9e8a6ce9d7982ed4d3da35eaf26dd590f006,"KAFKA-17803: LogSegment#read should return the base offset of the batch that contains startOffset rather than startOffset (#17528)

Reviewers: Jose Sancio <jsancio@gmail.com>, Jun Rao <junrao@gmail.com>",2024-11-01 09:32:00,kevin-wu24,Mixed
3d9f88daf3de7afec2c825f6def0ac12c8a546c7,"KAFKA-17546 Admin.listGroups and kafka-groups.sh (#17626)

This implements the kafka-groups.sh tool and Admin.listGroups method defined in KIP-1043.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-02 05:37:04,Andrew Schofield,Mixed
908dfa30d77b3368d2a228d0f1bc3803189e7ec1,"MINOR: Update clientInstanceIds from EOS_V2 refactor (#17664)

Updates KafkaStreams.clientInstanceIds method to correctly populate the client-id -> clientInstanceId map that was altered in a previous refactoring.

Added a test that confirms ClientInstanceIds is correctly storing consumer and producer instance ids

Reviewers: Matthias Sax <mjsax@apache.org>",2024-11-02 10:37:46,Bill Bejeck,Mixed
af53758746485daa06c4d4366036c04f7f9f0e63,"KAFKA-17814 Use `final` declaration to replace the suppression `this-escape` (#17613)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-03 15:00:02,Linsiyuan9,Mixed
7b41eedc1a6ea2f4526cbd66748698eaf5469384,"KAFKA-17909 Remove zkBroker from ConsumerGroupHeartbeatRequest and ConsumerGroupDescribeRequest (#17665)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-04 04:35:22,TengYao Chi,Not TDD
a0292bae39941ee5ca89380744129bea1db2aa6c,"KAFKA-17463 add retry in Persister for NOT_COORDINATOR error (#17645)

Reviewers: Andrew Schofield <aschofield@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-11-04 21:06:39,Apoorv Mittal,Mixed
64f3ee4c336339ee17163cc742442fef0db7b62c,"KAFKA-17593; [2/N] Update request validation & validate regex (#17651)

This patch does two things:
1) Change the validation of the ConsumerGroupHeartbeat request to accept subscribed topic names and/or subscribed topic regex. At least of them must be set in the first request with epoch 0.
2) Validate the provided regular expression by compiling it.

Co-authored-by: Lianet Magrans <lmagrans@confluent.io>

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Lianet Magrans <lmagrans@confluent.io>",2024-11-04 06:38:09,David Jacot,Mixed
5cf91e4cbec8d33bd8e938164ca4b3fe172fda55,"KAFKA-17593; [3/N] Track the number of subscribed members per regular expression in ConsumerGroup (#17653)

This patch adds a data structure to ConsumerGroup to track the number of members subscribed to each regular expressions in the group. This will be useful to know whether a regex is new in the group or whether a regex must be removed from the group.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Lianet Magrans <lmagrans@confluent.io>",2024-11-04 06:39:09,David Jacot,Mixed
c5a31cd6fbf258100b10e92d731d36d9f97130f9,"KAFKA-17625: Removing explicit ZK test parameterizations (#17638)

This PR removes ZK test parameterizations from ducktape by:

- Removing zk from quorum.all_non_upgrade
- Removing quorum.zk from @matrix and @parametrize annotations
- Changing usages of quorum.all to quorum.all_kraft
- Deleting message_format_change_test.py

The default metadata_quorum value still needs to be changed to KRaft rather than ZK, but this will be done in a follow-up PR.

Reviewers: Kirk True <kirk@kirktrue.pro>, Colin P. McCabe <cmccabe@apache.org>",2024-11-04 09:38:04,kevin-wu24,Not TDD
ebb3202e01d9481d7e711cd25e4e564863b91e1e,"KAFKA-16964 Integration tests for adding and removing voters (#17582)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-05 03:09:37,kevin-wu24,Mixed
e3f953483cb480631bf041698770b47ddb82796f,"KAFKA-17857 Move AbstractResetIntegrationTest and subclasses to tools (#17594)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-05 04:16:19,Kuan-Po Tseng,Not TDD
fd4d58899bcc5c4ac69c5d3c309bc05ed7bf4e20,"KAFKA-17819 : Handle piggyback acknowledgements when subscription changes in ShareConsumeRequestManager. (#17537)

Currently in ShareConsumeRequestManager, after we receive a ShareFetchResponse, if the subscription changes before we acknowledge(via ShareFetch), then we do not acknowledge the records which are not part of the updated subscription. Instead we must acknowledge all the records that we had received irrespective of the current subscription.
This bug is only when we are acknowledging via ShareFetch where we use SubscriptionState::fetchablePartitions to obtain the partitions to fetch. In ShareAcknowledge, as we are getting the partitions from the active share sessions, even if the subscription changed, the session would remain active.


Reviewers:  Andrew Schofield <aschofield@confluent.io>,  Manikumar Reddy <manikumar.reddy@gmail.com>",2024-11-05 13:06:11,ShivsundarR,Mixed
c91243a4b71fb7430b0987f0a2ddf37f3a922927,"KAFKA-17877; Only call once maybeSendResponseCallback for each marker (#17619)

We should only call once `maybeSendResponseCallback` for each marker during the WriteTxnMarkersRequest handling.

Consider the following 2 cases:

First
We have 2 markers to append, one for producer-0, one for producer-1
When we first process producer-0, it appends a marker to the __consumer_offset.
The __consumer_offset append finishes very fast because the group coordinator is no longer the leader. So the coordinator directly returns NOT_LEADER_OR_FOLLOWER. In its callback, it calls the maybeComplete() for the first time, and because there is only one partition to append, it is able to go further to call maybeSendResponseCallback() and decrement numAppends.
Then it calls the replica manager append for nothing, in the callback, it calls the maybeComplete() for the second time. This time, it also decrements numAppends.

Second
We have 2 markers to append, one for producer-0, one for producer-1
When we first process producer-0, it appends a marker to the __consumer_offset and a data topic foo.
The 2 appends will be handled by group coordinator and replica manager asynchronously.
It can be a race that, both appends finishes together, then they can fill the `markerResults` at the same time, then call the  `maybeComplete`. Because the `partitionsWithCompatibleMessageFormat.size == markerResults.size` condition is satisfied, both `maybeComplete` calls can go through to decrement the `numAppends` and cause a premature response.

Note: the problem only happens with KIP-848 coordinator enabled.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Justine Olshan <jolshan@confluent.io>, David Jacot <djacot@confluent.io>",2024-11-05 02:06:32,Calvin Liu,Mixed
ee3cea05aac766c60cc858c33c7cd489ddcbdf9f,"KAFKA-16816: Remove unneeded FencedInstanceId support on commit path for new consumer (#17559)

Reviewers: Lianet Magrans <lmagrans@confluent.io>",2024-11-05 14:33:23,TaiJuWu,Mixed
36c131ef4a22c9e917c43c4661005614c4c6f4b7,"KAFKA-17609:[1/4] Changes needed to convert system tests to use KRaft and remove ZK  (#17275)

This is part one of a multi-pr effort to convert Kafka Streams system tests to KRaft. I decided to break down the changes into multiple PRs to reduce the review load

Reviewers: Matthias Sax <mjsax@apache.org>",2024-11-05 11:23:33,Bill Bejeck,Not TDD
4ed0a958e54ee6c3b80e4eb5fbc986e5b6be49e5,"KAFKA-17248 - KIP 1076 implementation (#17021)

Implementation of KIP-1076 to allow for adding client application metrics to the KIP-714 framework

Reviewers: Apoorv Mittal <amittal@confluent.io>, Andrew Schofield <aschofield@confluent.io>, Matthias Sax <mjsax@apache.org>",2024-11-05 11:29:54,Bill Bejeck,Mixed
08c876c1fe5b32d8301b2cc4cabc53f2d3088312,"Fix TransactionStateManager handling of empty batch when loading transaction metadata (#17688)

When loading transaction metadata from a transaction log partition, if the partition contains a segment ending with an empty batch, ""currOffset"" update logic at will be skipped for the last batch. Since ""currOffset"" is not advanced to next offset of last batch properly, TransactionStateManager.loadTransactionMetadata method will be stuck in the ""while"" loop.

This change fixes the issue by updating ""currOffset"" after processing each batch, whether the batch is empty or not.

Reviewers: Justine Olshan <jolshan@confluent.io>, Jun Rao <junrao@gmail.com>",2024-11-05 14:22:20,Vincent Jiang,Mixed
069667b6b264447ea980911aa6568a7a389d8679,"KAFKA-16339: [1/4 KStream#transform] Remove Deprecated ""transformer"" methods and classes (#17198)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2024-11-05 22:04:41,Joao Pedro Fonseca Dantas,Mixed
c903bdf496761713d0ed8bed1cd087e6fa562dc2,"KAFKA-12827 Remove Deprecated method KafkaStreams#setUncaughtExceptionHandler (#16988)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2024-11-05 22:08:32,Abhishek Giri,Not TDD
b7e69ebf5c29917b73663eeb8144d36a1b853ce1,"KAFKA-17924: Remove `bufferpool-wait-time-total`, `io-waittime-total`, and `iotime-total` (#17697)

These metrics were deprecated in KIP-773 and are being removed in Kafka 4.0.

Reviewers:  Chia-Ping Tsai <chia7712@gmail.com>, Divij Vaidya <diviv@amazon.com>",2024-11-06 08:46:28,Yung,Mixed
c40cb07984cebe268ee47a9c3ba8adb25cbca711,"KAFKA-17911: Fix handling of env variables in KafkaDockerWrapper (#17655)


Reviewers: Luke Chen <showuon@gmail.com>",2024-11-06 10:47:51,Mickael Maison,Mixed
8cbd2edfe782997380683cbfa7451a4f2de893f0,"KAFKA-17896: Admin.describeClassicGroups (#17680)

The implementation of Admin.describeClassicGroups from KIP-1043.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2024-11-06 17:14:10,Andrew Schofield,Mixed
d170b52362bf9b4699eb3d3b8c9e8e659d47d830,"KAFKA-17635: Ensure only committed offsets are returned for purging (#17686)

Kafka Streams actively purges records from repartition topics. Prior to this PR, Kafka Streams would retrieve the offset from the consumedOffsets map, but here are a couple of edge cases where the consumedOffsets can get ahead of the commitedOffsets map. In these cases, this means Kafka Streams will potentially purge a repartition record before it's committed.

Updated the current StreamTask test to cover this case

Reviewers: Matthias Sax <mjsax@apache.org>",2024-11-06 17:45:27,Bill Bejeck,Mixed
f2b19baee04edb02ece7b2b7e4c6b50b1301ac9c,"KIP-16331: Remove EOS-v1 from StreamsConfigUtils (#17691)

Reviewers: Bill Bejeck <bill@confluent.io>",2024-11-06 18:18:49,Matthias J. Sax,Mixed
b213c64f97fa6b4ab3b79b828e37095603841d6f,"KAFKA-17480: New consumer commit all consumed should retrieve offsets in background thread (#17150)

Reviewers: Lianet Magrans <lmagrans@confluent.io>, Kirk True <ktrue@confluent.io>, TengYao Chi <kitingiao@gmail.com>",2024-11-07 15:45:44,PoAn Yang,Mixed
a0d4cbec402c6c09e601c76a7332747e80e518ca,"KAFKA-17743: Add minBytes implementation to DelayedShareFetch (#17539)

Reviewers:  Apoorv Mittal <apoorvmittal10@gmail.com>, Jun Rao <junrao@gmail.com>",2024-11-07 07:57:00,Abhinav Dixit,Mixed
c69a6b0e804171f0b64eca8f3abdef260cca38d2,"KAFKA-17248 - KIP 1076 Add process-id to get carried to telemetry results (#17630)

This PR adds the processId to Kafka Streams client instance metrics

Reviewers: Matthias Sax <mjsax@apache.org>",2024-11-07 12:12:42,Bill Bejeck,Mixed
95650431dfd2072cfd79efd5536d9eff7b50f3d9,"KAFKA-16339: [2/4 KStream#flatTransform] Remove Deprecated ""transformer"" methods and classes (#17245)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2024-11-07 17:35:17,Joao Pedro Fonseca Dantas,Mixed
1792b19a057662263b01a7e6c6546de48934389a,"KAFKA-17593; [4/N] Introduce ConsumerGroupRegularExpression record & related bookkeeping in ConsumerGroup (#17694)

This patch introduces the ConsumerGroupRegularExpression record (key + value) and updates the `GroupMatadataManager` and the `ConsumerGroup` to bookkeep it appropriately. Note that with this change, regular expressions are counted as subscribers in the `subscribedTopicNames` data structure. This is important because the topic metadata of the group is computed based on it.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Lianet Magrans <lmagrans@confluent.io>",2024-11-07 23:16:51,David Jacot,Mixed
0049b967e5597280ed60fccb00bd637613e7c58a,"KAFKA-17890: Move DelayedOperationPurgatory to server-common (#17636)


Reviewers: Jun Rao <jun@confluent.io>, Apoorv Mittal <amittal@confluent.io>",2024-11-08 09:55:09,Mickael Maison,Mixed
b9976437e11dee877f32376d18140641ef4ccbc7,"KAFKA-16780: Txn consumer exerts pressure on remote storage when collecting aborted txns (#17659)

- KIP-1058 (https://cwiki.apache.org/confluence/display/KAFKA/KIP-1058:+Txn+consumer+exerts+pressure+on+remote+storage+when+collecting+aborted+transactions)
- Unit and Integration tests added.

Reviewers: Divij Vaidya <diviv@amazon.com>",2024-11-08 14:49:09,Kamal Chandraprakash,Mixed
2e2b0a58eda3e677763af974a44a6aaa3c280214,"KAFKA-17914: Update string ref with SharePartitionKey. (#17660)

Currently, we are using the String repr of the shareCoordinator/sharePartition key (groupId:topicId:parition) as defined in kip-932 in a few methods like ShareCoordinator.partitionFor and ShareCoordinatorMetadataCacheHelper.getShareCoordinator.
This has the potential to introduce subtle bugs when incorrect strings are used to invoke these methods. What is perturbing is that the failures might be intermittent.
This PR aims to remedy the situation by changing the type to the concrete SharePartitionKey. This way callers need not be worried about a specific encoding or format of the coordinator key as long as the SharePartitionKey has the correct fields set.
There is one issue - the FIND_COORDINATOR RPC does require the coordinator key to be set as a String in the request body. We can't get around this and have to set the value as String. However, on the KafkaApis handler side we parse this key into a SharePartitionKey again and gain compile time safety. One downside is that we need to split and format the incoming coordinator key in the request but that can be encapsulated at a single location in SharePartitionKey.
Added tests for partitionFor.

Reviewers: Andrew Schofield <aschofield@confluent.io>,  Apoorv Mittal <apoorvmittal10@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-11-08 15:05:39,Sushant Mahajan,Mixed
32d9dec9e15c6e411f78ff5f4b60a14537f90d4c,"rebase to fix merge conflict (#17702)

Fixes an issue with the TTD in the specific case where users don't specify an initial time for the driver and also don't specify a start timestamp for the TestInputTopic, then pipe input records without timestamps. This combination results in a slight mismatch in the expected timestamps for the piped records, which can be noticeable when writing tests with very small time deltas.

The problem is that, while both the TTD and the TestInputTopic will be initialized to the ""current time"" when not otherwise specified, it's possible for some milliseconds to have passed between the creation of the TTD and the creation of the TestInputTopic. This can result in a TestInputTopic getting a start timestamp that's several ms larger than the driver's time, and ultimately causing the piped input records to have timestamps slightly in the future relative to the driver.

In practice even those who hit this issue might not notice it if they aren't manipulating time in their tests, or are advancing time by enough to negate the several-milliseconds of difference. However we noticed a test fail due to this because we were testing a ttl-based processor and had advanced the driver time by only 1 millisecond past the ttl. The piped record should have been expired, but because it's timestamp was a few milliseconds longer than the driver's start time, this test ended up failing.

Reviewers: Matthias Sax <mjsax@apache.org>, Bruno Cadonna <cadonna@apache.org>, Lucas Brutschy < lbrutschy@confluent.io>",2024-11-08 19:04:07,A. Sophie Blee-Goldman,Not TDD
324a74d4fd179614df648009fc294dfbf225c775,"KAFKA-17801: RemoteLogManager may compute inaccurate upperBoundOffset for aborted txns (#17676)

Reviewers: Jun Rao <junrao@gmail.com>",2024-11-09 08:52:17,Kamal Chandraprakash,Mixed
4966aed40d484eb0f07dd0b70f85cff4068f0862,"KAFKA-17970 Moving some share purgatory classes from core to share module (#17722)

As part of PR: https://github.com/apache/kafka/pull/17636 where purgatory has been moved from core to server-common hence move some existing classes used in Share Fetch to Share module.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-10 01:04:17,Apoorv Mittal,Mixed
393455eb1ada86eaea84f9485efe7f133de2583c,"KAFKA-17837 Rewrite DeleteTopicTest (#17579)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-10 03:06:52,TengYao Chi,Not TDD
5d2074e8f26a0573fd7d66cc4dfa68a9dae58dc4,"MINOR: Move StopPartition to server-common (#17704)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-10 03:13:12,Mickael Maison,Mixed
0bc91be14591c742e19e3572871080386b904849,"KAFKA-17872: Update consumed offsets on records with invalid timestamp (#17710)

TimestampExtractor allows to drop records by returning a timestamp of -1. For this case, we still need to update consumed offsets to allows us to commit progress.

Reviewers: Bill Bejeck <bill@confluent.io>",2024-11-09 17:21:16,Matthias J. Sax,Mixed
440e0b8801bca5a648a2cc2a7e98f25c44b0810d,"KAFKA-17923 Remove old kafka version from e2e (#17673)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-11 06:22:06,PoAn Yang,Mixed
9db5ed00a8369d5c696e836661230110ea2ea44d,"KAFKA-16726: Added share.auto.offset.reset dynamic config for share groups (#17573)

This PR adds another dynamic config share.auto.offset.reset fir share groups.


Reviewers:  Andrew Schofield <aschofield@confluent.io>, Apoorv Mittal <apoorvmittal10@gmail.com>,  Abhinav Dixit <adixit@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-11-11 14:36:11,Chirag Wadhwa,Mixed
c92f16a727ebb44b0c44038fbfa254d425dffcae,"KAFKA-17787: Removed --zookeeper option and logic from ConfigCommand (#17507)


Reviewers: Mickael Maison <mickael.maison@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>
Co-authored-by: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-11 18:50:49,Chengyan,Mixed
8be958d66148e49e404fe3d1a96139bf0040f84c,"MINOR: Cleanup GroupMetadataManagerTest (#17751)

This patch does a few cleanups in GroupMetadataManagerTest:
* Uses `Map.of` where possible.
* Uses `List.of` instead of `Arrays.asList`.
* Fix inconsistent indentation in a few places.

Reviewers: Lianet Magrans <lmagrans@confluent.io>",2024-11-11 22:53:07,David Jacot,Not TDD
207b35901c2fdc3959304f8e8c242c5128c2cd7d,"KAFKA-17314 Fix the typo: `maxlifeTimeMs` (#17749)

Reviewers: TengYao Chi <kitingiao@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-11-12 16:26:29,Ken Huang,Not TDD
939831fdab16d5f4c58ed56134122b2292203ddb,"MINOR: Convert AlterReplicaLogDirsRequestTest to KRaft (#17764)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2024-11-12 12:38:52,Colin Patrick McCabe,Not TDD
5a5239770ff3565233e5cbecf11446e76339f8fe,"MINOR: Refactor GroupCoordinator's Assertions (#17755)

This patch cleans up the `Assertions` class in the `group-coordinator` module.

Reviewers: Lianet Magrans <lmagrans@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-11-12 05:30:58,David Jacot,Not TDD
8563955e3950a85f8af61b184f2d05bf6cfe4c1f,"KAFKA-17632: Fix RoundRobinPartitioner for even partition counts (#17620)

RoundRobinPartitioner does not handle the fact that on new batch creation, the partition method is called twice.

Reviewers: Viktor Somogyi-Vass <viktorsomogyi@gmail.com>, Mickael Maison <mickael.maison@gmail.com>",2024-11-12 15:44:36,Dániel Urbán,Mixed
5914013219a3769df8e28408d5e99bf3e500b9c4,"KAFKA-17980: Introduce `isReady` API in RemoteLogMetadataManager (#17737)

- The isReady API in RemoteLogMetadataManager (RLMM) is used to denote whether the partition metadata is ready for remote storage operations. The plugin implementors can use this API to denote the partition status while bootstrapping the RLMM.
- Using this API, we are gracefully starting the remote log components. The segment copy, delete, and other operations that hits remote storage will be invoked once the metadata is ready for a given partition.
- See KIP-1105 (https://cwiki.apache.org/confluence/display/KAFKA/KIP-1105%3A+Make+remote+log+manager+thread-pool+configs+dynamic) for more details.

Reviewers: Federico Valeri <fvaleri@redhat.com>, Satish Duggana <satishd@apache.org>",2024-11-12 22:47:48,Kamal Chandraprakash,Mixed
adf4b6eb390249e6adf5976a491e5d117f0c87d2,"KAFKA-17991: Added timed calls for future.get in persister. (#17772)

Reviewers: Andrew Schofield <aschofield@confluent.io>, Apoorv Mittal <apoorvmittal10@gmail.com>, David Arthur <mumrah@gmail.com>",2024-11-12 19:15:39,Sushant Mahajan,Mixed
edab667a9a80ddbbc267e247fac554bb44f480bc,"MINOR Quarantine some flaky tests (#17779)

Reviewers: Colin Patrick McCabe <cmccabe@apache.org>",2024-11-12 19:34:44,David Arthur,Not TDD
6bc7be70d733c060d07ab8300317c82d9e1c2927,"KAFKA-17922 add helper to ClusterInstance to create client component  (#17666)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-13 09:39:15,Ken Huang,Not TDD
52d2fa5c8b3d5f737fe97645c65e73df872e2a67,"KAFKA-17885: Enable clients to rebootstrap based on timeout or error code (KIP-1102) (#17720)

Implementation of https://cwiki.apache.org/confluence/display/KAFKA/KIP-1102%3A+Enable+clients+to+rebootstrap+based+on+timeout+or+error+code
- Introduces rebootstrap trigger interval config metadata.recovery.rebootstrap.trigger.ms, set to 5 minutes by default
- Makes rebootstrap the default for metadata.recovery.strategy
- Adds new error code REBOOTSTRAP_REQUIRED, introduces top-level error code in metadata response. On this error, clients rebootstrap.
- Configs apply to producers, consumers, share consumers, admin clients, Connect and KStreams clients.

Reviewers: Apoorv Mittal <apoorvmittal10@gmail.com>,  Manikumar Reddy <manikumar.reddy@gmail.com>",2024-11-13 13:01:08,Rajini Sivaram,Mixed
a802865aaddf1035661be2d9682e0e244b3d9442,"KAFKA-17593; [5/N] Include resolved regular expressions into target assignment computation (#17750)

This patch does a few things:
* Refactors the `TargetAssignmentBuilder` to use inheritance to differentiate Consumer and Share groups.
* Introduces `UnionSet` to lazily aggregate the subscriptions for a given member. 
* Wires the resolved regular expressions in the `GroupMetadataManager`. At the moment, they are only used when the target assignment is computed.

Reviewers: Sean Quah <squah@confluent.io>, Jeff Kim <jeff.kim@confluent.io>, Lianet Magrans <lmagrans@confluent.io>",2024-11-13 06:59:52,David Jacot,Mixed
6fc6e87382de6f1a7f6ddc383a178d34dbe3e2b8,"KAFKA-17593; [6/N] Add new record to GroupCoordinatorRecordSerde (#17791)

This patch extends `GroupCoordinatorRecordSerde` to support the `ConsumerGroupRegularExpression` record.

Reviewers: Jeff Kim <jeff.kim@confluent.io>",2024-11-13 09:08:09,David Jacot,Mixed
b6b2c9ebc45bd60572c24355886620dbdc406ce9,"KAFKA-16985: Ensure consumer attempts to send leave request on close even if interrupted (#16686)

Reviewers: Andrew Schofield <aschofield@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Lianet Magrans <lmagrans@confluent.io>, Philip Nee <pnee@confluent.io>",2024-11-13 20:26:40,Kirk True,Mixed
e4b8644400e4442303947aecb34f4f8d416bd766,"KAFKA-17992 Remove getUnderlying and isKRaftTest from ClusterInstance (#17802)

Reviewers: TengYao Chi <kitingiao@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-11-14 17:11:19,Yung,Not TDD
18199028a672fd973ac37bf26316994babc2a6da,"KAFKA-17995: Fix errors in remote segment cleanup when retention.ms is large (#17794)

If a user has configured value of `retention.ms` to a value greater than current unix timestamp epoch, then we fail cleanup of a remote log segment with an error. This change fixes the bug by handling this case of large `retention.ms` correctly.

Reviewers: Divij Vaidya <diviv@amazon.com>",2024-11-14 11:24:45,PoAn Yang,Mixed
1834030107b93fe2c08fcb48451f14b0d764051d,"KAFKA-17510: Exception handling and purgatory completion on initialization delay (#17709)

Reviewers: Jun Rao <junrao@gmail.com>",2024-11-14 07:44:42,Apoorv Mittal,Mixed
e9cd9c9811dba121131809f92bc5ac83bf3e3053,"KAFKA-18006 Add 3.9.0 to end-to-end test (core, client) (#17797)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-15 00:24:24,TengYao Chi,Not TDD
ed9cb08dfe9178d7427f354fb0b87a964233cd22,"KAFKA-17977 Remove new_consumer from E2E (#17798)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-15 16:26:26,PoAn Yang,Not TDD
84fe66827dca926ae94af0d755996f30ed576b67,"KAFKA-18006: Add 3.9.0 to end-to-end test (streams) (#17800)

This commit adds AK 3.9 to the system tests on trunk.
Follow-up of #17797

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>, Bruno Cadonna <cadonna@apache.org>",2024-11-15 14:58:24,TengYao Chi,Not TDD
cc20e7847450d7a3bd5af85f821697e17761cc60,"KAFKA-17648: AsyncKafkaConsumer#unsubscribe and #close swallow TopicAuthorizationException and GroupAuthorizationException (#17516)

Reviewers: Lianet Magrans <lmagrans@confluent.io>, Kirk True <ktrue@confluent.io>",2024-11-15 15:15:26,PoAn Yang,Mixed
77cc8ffbab40c81e7df62e77fcbd46dbad96aac9,"KAFKA-17948: Potential issue during tryComplete and onComplete simultaneous calls to access global variables (#17739)

Reviewers: Andrew Schofield <aschofield@confluent.io>, Apoorv Mittal <apoorvmittal10@gmail.com>, Jun Rao <junrao@gmail.com>",2024-11-15 10:26:54,Abhinav Dixit,Mixed
5725a51453859163c01735052b0c15ee6a513b8e,"KAFKA-16460: New consumer times out consuming records in multiple consumer_test.py system tests (#17777)

Reviewers: Lianet Magrans <lmagrans@confluent.io>",2024-11-15 19:41:39,PoAn Yang,Not TDD
a8f84cab958761434bcafca2c0fd90f53b52aacf,"KAFKA-18001: Support UpdateRaftVoterRequest in KafkaNetworkChannel (#17773)

Adds support for UpdateRaftVoterRequest in KafkaNetworkChannel. This addresses the following scenario:

* Bootstrap a KRaft Controller quorum in dynamic mode
* Start additional controllers (as observers)
* Update kraft.version feature from 0 to 1
* Use kafka-metadata-quorum add-controller to promote an observer controller to a follower

Reviewers: Colin Patrick McCabe <cmccabe@apache.org>, Alyssa Huang <ahuang@confluent.io>",2024-11-15 15:55:01,Justin Lee,Mixed
dfa5aa5484a12e18cc763e064a70391103524165,"KAFKA-18022: fetchOffsetMetadata handling for minBytes estimation in both common/uncommon cases of share fetch (#17825)

Reviewers: Jun Rao <junrao@gmail.com>",2024-11-16 07:26:30,Abhinav Dixit,Mixed
5cf9872e8f37c5f48e1200259c1d7f784273e5a6,"KAFKA-18017: Fix call order for HB error and group manager (#17805)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-17 19:12:25,Lianet Magrans,Not TDD
e4c00346793f93bf358acbf85da4bc18c916eb2a,"KAFKA-18019: Make INVALID_PRODUCER_ID_MAPPING a fatal error (#17822)

This patch contains changes to the handling of the INVALID_PRODUCER_ID_MAPPING error.
Quoted from KIP-890
Since we bump epoch on abort, we no longer need to call InitProducerId to fence requests. InitProducerId will only be called when the producer starts up to fence a previous instance.

With this change, some other calls to InitProducerId were inspected including the call after receiving an InvalidPidMappingException. This exception was changed to abortable as part of KIP-360: Improve reliability of idempotent/transactional producer. However, this change means that we can violate EOS guarantees. As an example:

Consider an application that is copying data from one partition to another

Application instance A processes to offset 4
Application instance B comes up and fences application instance A
Application instance B processes to offset 5
Application instances A and B are idle for transaction.id.expiration.ms, transaction id expires on server
Application instance A attempts to process offset 5 (since in its view, that is next) -- if we recover from invalid pid mapping, we can duplicate this processing
Thus, INVALID_PID_MAPPING should be fatal to the producer.

This is consistent with KIP-1050: Consistent error handling for Transactions where errors that are fatal to the producer are in the ""application recoverable"" category. This is a grouping that indicates to the client that the producer needs to restart and recovery on the application side is necessary. KIP-1050 is approved so we are consistent with that decision.

This PR also fixes the flakiness of TransactionsExpirationTest.

Reviewers:  Artem Livshits <alivshits@confluent.io>, Justine Olshan <jolshan@confluent.io>, Calvin Liu <caliu@confluent.io>",2024-11-17 18:43:04,Ritika Reddy,Mixed
e1dcd383bccc7d16a87a34583722145053cae8a3,"KAFKA-17927 Disallow users to configure `max.in.flight.requests.per.connection` bigger than 5 (#17717)

Reviewers: PoAn Yang <payang@apache.org>, Chia-Ping Tsai <chia7712@gmail.com>",2024-11-18 14:01:16,TengYao Chi,Mixed
a592912ec94b021a2bd7485abb9ebda02dc01766,"KAFKA-17663 Add metadata caching in PartitionLeaderStrategy (#17367)

Admin API operations have two phases: lookup and fulfilment. The lookup phase involves a METADATA request whose details depend upon the operation being performed.

For some operations, the METADATA request can be quite expensive to serve. For example, if the user calls Admin.listOffsets for 1000 topics, the METADATA request will include all 1000 topics and the response will contain the leader information for all of these topics. And then the actual fulfilment phase does the real work of the operation.

In cases where a long-running application is performing repeated admin operations which need the same metadata information about partition leadership, it is not necessary to send the METADATA request for every single admin operation.

This PR adds a cache of the mapping from topic-partition to leader id to the admin client. The cache doesn't need to be very sophisticated because the admin client will retry if the information becomes stale, and the cache can be updated as a result of the retry.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-18 14:45:06,Andrew Schofield,Not TDD
53d8316b5da7d8355331aa2d50193748c8261706,"KAFKA-14934 KafkaClusterTestKit makes FaultHandler accessible (#17774)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-18 18:23:54,TengYao Chi,Not TDD
eafa78d99d3353af9079145cdc5d4fe9251baf1d,"KAFKA-18016: Modified handling of piggyback acknowledgements in ShareConsumeRequestManager. (#17824)

What
There was a bug in handling piggyback acknowledgements in ShareConsumeRequestManager, where the fetchAcknowledgementsMap could be updated when the request was in flight and when the ShareFetch response is received, we were removing any acknowledgements(without actually sending them) which came when the request was in flight.

Fix
Now we are maintaining 2 separate maps(one which has the acknowledgements to send and one which keeps track of the acknowledgements in flight).

 Reviewers: Andrew Schofield <aschofield@confluent.io>, Apoorv Mittal <apoorvmittal10@gmail.com>,  Manikumar Reddy <manikumar.reddy@gmail.com>",2024-11-18 17:15:42,ShivsundarR,Mixed
50c15b94c94fbe8f964703c057963b38100b0bd6,"KAFKA-17561: KIP-1091 add operator metrics (#17820)

Implementation of KIP-1091 adding operator metrics to Kafka Streams
Updated existing tests to validate added metrics
Reviewers: Bruno Cadonna <cadonna@apache.org>, Matthias Sax <mjsax@apache.org>",2024-11-18 10:30:09,Bill Bejeck,Mixed
130bf1054b037d3fbc941dbf9e6d1276a8edfbad,"MINOR: some minor cleanups in the quorum controller. (#17819)

BrokerHeartbeatManager.java: fix an outdated comment.

Move an inefficient test method that is O(num_brokers) from ClusterControlManager.java into ReplicationControlManagerTest.java, so that it doesn't accidentally get used in production code.

Remove QuorumController.ImbalanceSchedule, etc. since it is no longer used.

Move the initialization of OffsetControlManager later in the QuorumController constructor and add a comment explaining why it should come last. This doesn't fix any bugs currently, but it's a good practice for the future.

Reviewers: Mickael Maison <mickael.maison@gmail.com>",2024-11-18 11:15:38,Colin Patrick McCabe,Not TDD
5f4cbd4aa4239d887ad9f5d381181621bdb58e7c,"KAFKA-17767 Automatically quarantine new tests [5/n] (#17725)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-19 09:56:36,David Arthur,Mixed
624cd4f7d0bd17218b2c70c87ba89dc4312ad900,"MINOR: Various cleanups in connect:runtime tests (#17827)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-19 15:55:54,Mickael Maison,Not TDD
389f96aabd6239015dfa9d4180524dcfc5121e5c,"MINOR: Various cleanups in coordinator modules (#17828)


Reviewers: David Jacot <djacot@confluent.io>, Ken Huang <s7133700@gmail.com>",2024-11-19 10:01:05,Mickael Maison,Mixed
615c8c0e11678c39904d8bdde991a0c1a4b67625,"KAFKA-17850: fix leaking internal exception in state manager (#17711)

Following the KIP-1033 a FailedProcessingException is passed to the Streams-specific uncaught exception handler.

The goal of the PR is to unwrap a FailedProcessingException into a StreamsException when an exception occurs during the flushing or closing of a store

Reviewer: Bruno Cadonna <cadonna@apache.org>",2024-11-19 10:51:07,Sebastien Viale,Mixed
a211ee99b57daba3ca3e2c0989e241c990aa6f6c,"KAFKA-17593; [7/N] Introduce CoordinatorExecutor (#17823)

This patch introduces the `CoordinatorExecutor` construct into the `CoordinatorRuntime`. It allows scheduling asynchronous tasks from within a `CoordinatorShard` while respecting the runtime semantic. It will be used to asynchronously resolve regular expressions.

The `GroupCoordinatorService` uses a default `ExecutorService` with a single thread to back it at the moment. It seems that it should be sufficient. In the future, we could consider making the number of threads configurable.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, Lianet Magrans <lmagrans@confluent.io>",2024-11-19 07:19:22,David Jacot,Mixed
32c887b05e088f175f49d871506312caf34db256,"KAFKA-17949: Introduce GroupState and replace ShareGroupState (#17763)

This PR introduces the unified GroupState enum for all group types from KIP-1043. This PR also removes ShareGroupState and begins the work to replace Admin.listShareGroups with Admin.listGroups. That will complete in a future PR.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2024-11-19 21:17:12,Andrew Schofield,Mixed
8ccb26de2eab4f3695bcdd029c82e4a7c872c314,"KAFKA-17733: Protocol upgrade should allow empty member assignment in group conversion (#17853)

During conversion from classic to consumer group, if a member has empty assignment (e.g., the member just joined and has never synced), the conversion will fail because of the buffer underflow error when deserializing the member assignment. This patch allows empty assignment while deserializing the member assignment.

Reviewers: Jeff Kim <jeff.kim@confluent.io>, David Jacot <djacot@confluent.io>",2024-11-19 10:46:07,Dongnuo Lyu,Not TDD
c6294aacef5d07b023a688b24bae35eeb3d4fdcb,"KAFKA-17721 Enable to configure listener name and protocol for controller (#17525)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-20 23:06:29,Kuan-Po Tseng,Mixed
fd9de50de120ec400220e6b960d11f302cd88486,"KAFKA-18041: Update key for storing global consumer instance id for consistency (#17869)

This PR updates the key for storing the KIP-714 client instance id for the global consumer to follow a more consistent pattern of the other embedded Kafka Streams consumer clients.

Reviewers: Matthias Sax <mjsax@apache.org>",2024-11-20 16:14:03,Bill Bejeck,Not TDD
4f1688742e75a147741fbdc307c5e85d2addb811,"KAFKA-15387: Remove Connect's deprecated task configurations endpoint (#17412)

Reviewers: Mickael Maison <mickael.maison@gmail.com>",2024-11-21 19:43:54,Yash Mayya,Mixed
c0a092f56262fcc32534396f5d89a6bfa32064e5,"MINOR: Cleanups in raft module (#17877)


Reviewers: Yash Mayya <yash.mayya@gmail.com>",2024-11-21 15:19:07,Mickael Maison,Not TDD
1c998f8ef3620ed6bf782a01696f61811da2dea2,"KAFKA-17869: Adding tests to ensure KIP-1076 doesn't interfere with consumer metrics[1/3] (#17781)

Adding tests to ensure the KIP-1076 methods don't interfere with existing metrics in clients

Reviewers: Apoorv Mittal <amittal@confluent.io>, Matthias Sax <mjsax@apache.org>",2024-11-21 13:41:29,Bill Bejeck,Mixed
240efbb99d9ee489251db0a8110936ad9eb0eb48,"MINOR: improve JavaDocs for Kafka Streams exceptions and error handlers (#17856)

Reviewers: Bill Bejeck <bill@confluent.io>",2024-11-21 11:46:23,Matthias J. Sax,Not TDD
5fba067aaa73e44a3832859e4742f7c1aa6959fe,"KAFKA-18063: SnapshotRegistry should not leak memory (#17898)

SnapshotRegistry needs to have a reference to all snapshot data structures. However, this should
not be a strong reference, but a weak reference, so that these data structures can be garbage
collected as needed. This PR also adds a scrub mechanism so that we can eventually reclaim the
slots used by GC'ed Revertable objects in the SnapshotRegistry.revertables array.

Reviewers: David Jacot <david.jacot@gmail.com>",2024-11-21 13:27:53,Colin Patrick McCabe,Mixed
38aca3a045474a9e52ae25bde28d8a013b04f92b,"KAFKA-17917: Convert Kafka core system tests to use KRaft (#17847)

- Remove some unused Zookeeper code

- Migrate group mode transactions, security rolling upgrade, and throttling tests to using KRaft

- Add KRaft downgrade tests to kraft_upgrade_test.py

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2024-11-21 13:40:49,kevin-wu24,Not TDD
7db4d53f1890ba7349c6f2bd26c449173886fed9,"KAFKA-12690 Remove deprecated Producer#sendOffsetsToTransaction (#17865)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-22 18:07:10,Nick Guo,Mixed
0d7c7659811d5edafa9d33bcce8984b08f1ecb91,"KAFKA-15561 [1/N]: Introduce new subscribe api for RE2J regex (#17897)

Reviewers: David Jacot <djacot@confluent.io>",2024-11-22 11:58:20,Lianet Magrans,Mixed
d5e270482cf6601e1b635d69d311957e84d6bb59,"MINOR: Various cleanups in clients (#17895)


Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-22 20:38:31,Mickael Maison,Mixed
be4ea8092b5cc817f82a3b685dc53419d474eff2,"MINOR: Add git support for schema compatibility checker (#17684)

Add git support for schema compatibility checker. Pulls in valid schema from remote git trunk branch to check with edited schema in local branch. Adds new option for command line verify-evolution-git which takes in a required file name.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2024-11-22 14:02:31,mannoopj,Mixed
866f0cc30808c7150f82d7a08d1f37611ed28ef9,"KAFKA-16339: [3/4 KStream#transformValues] Remove Deprecated ""transformer"" methods and classes (#17266)

Reviewers: Matthias J. Sax <matthias@confluent.io>",2024-11-22 15:07:03,Joao Pedro Fonseca Dantas,Mixed
cd36d6453562dd5b6c7cb0df8e50d9401e0bfb98,"KAFKA-18051: Disallow creating ACLs with principals that do not contain a colon (#17883)

Kafka Principals must contain a colon. We should enforce this in createAcls.

Reviewers: David Arthur <mumrah@gmail.com>",2024-11-22 16:50:33,Colin Patrick McCabe,Mixed
87b902d35da595f9f1f0b01d57aec263e34ac25c,"KAFKA-18026: KIP-1112, ProcessorWrapper API with PAPI and partial DSL implementation (#17892)

This PR includes the API for KIP-1112 and a partial implementation, which wraps any processors added through the PAPI and the DSL processors that are written to the topology through the ProcessorParameters#addProcessorTo method.

Further PRs will complete the implementation by converting the remaining DSL operators to using the #addProcessorTo method, and future-proof the processor writing mechanism to prevent new DSL operators from being implemented incorrectly/without the wrapper

Reviewers: Almog Gavra <almog@responsive.dev>, Guozhang Wang <guozhang.wang.us@gmail.com>",2024-11-23 21:19:19,A. Sophie Blee-Goldman,Mixed
5ad532f4ad040e94346d1c76e0729c717423b9ad,"KAFKA-18075 Prevent ClusterInstance default producer and consumer initialization with empty configs (#17926)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-24 15:07:56,Kuan-Po Tseng,Not TDD
70babd57167f09ec85d25cb92b93794f2bc33e9e,"KAFKA-18079 consumer-config does not work with console-share-consumer (#17925)

Reviewers: Andrew Schofield <aschofield@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-11-24 20:13:14,PoAn Yang,Mixed
654ebe10f4a5c31e449b2a2ef6c284254ed7dceb,"KAFKA-18071: Avoid event to refresh regex if no pattern subscription (#17917)

Reviewers: David Jacot <djacot@confluent.io>, Andrew Schofield <aschofield@confluent.io>",2024-11-24 21:39:11,Lianet Magrans,Mixed
d1952e854202c574c1c19a48b17cc00e9d2eccd5,"KAFKA-18045 Add 0.11, 1.0, 1.1, and 2.0 back to streams_upgrade_test.py (#17876)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-25 21:34:36,PoAn Yang,Not TDD
3268435fd666e7dbfd3d50ad56008d177ec650bf,"KAFKA-18013: Add AutoOffsetResetStrategy internal class (#17858)

- Deprecates OffsetResetStrategy enum
- Adds new internal class AutoOffsetResetStrategy
- Replaces all OffsetResetStrategy enum usages with AutoOffsetResetStrategy
- Deprecate old/Add new constructors to MockConsumer

 Reviewers: Andrew Schofield <aschofield@confluent.io>, Matthias J. Sax <matthias@confluent.io>",2024-11-25 19:11:12,Manikumar Reddy,Mixed
54843e6e1ed196ba0f89ced990fb561aab77d265,"KAFKA-18077 Remove deprecated JmxReporter(String) (#17923)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-25 21:54:50,ClarkChen,Mixed
d17a149205428bd9e8b9e5d9f7c1a7cbe8d1e479,"KAFKA-17956 Remove Admin.listShareGroups (#17912)

KIP-1043 introduced Admin.listGroups as the way to list all types of groups. As a result, Admin.listShareGroups has been removed. This PR is the final step of the removal.

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-25 22:05:35,Andrew Schofield,Mixed
0f33b16fdf7ddb76b7f13480ded05374af6c2195,"KAFKA-18085: Abort inflight requests on existing connections while rebootstrapping (#17939)

When disconnecting channels before rebootstrapping due to the rebootstrap conditions introduced in KIP-1102, we should ensure that inflight requests are aborted similar to other disconnections like request timeout in clients. With the earlier rebootstrapping from KIP-899, we only rebootstrapped when there were no connections, so no disconnections are required.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2024-11-25 17:58:11,Rajini Sivaram,Mixed
95947d2f581cce85c25ef9eb3501dc13d09ae05a,"KAFKA-17299: add unit tests for previous fix (#17919)

https://github.com/apache/kafka/pull/17899 fixed the issue, but did not
add any unit tests.

Reviewers: Bill Bejeck <bill@confluent.io>",2024-11-25 12:03:57,Matthias J. Sax,Mixed
7f8a592ad19dd13b13353649a559a4bebdc0f450,"KAFKA-17869: Adding tests to ensure KIP-1076 doesn't interfere producer metrics[2/3] (#17783)

Adding producer tests to ensure the KIP-1076 methods don't interfere with existing metrics
Reviewers: Matthias Sax <mjsax@apache.org>",2024-11-25 16:24:16,Bill Bejeck,Mixed
4fc9e442c308364acc43046bdaefd87571ab20a5,"KAFKA-17898: Refine Epoch Bumping Logic (#17849)

With KAFKA-14562, we implemented epoch bump on both the client and the server. Mentioned below are the different epoch bump scenarios we have on hand after enabled tv2

Non-Transactional Producers
• Epoch bumping is always allowed.
• Different code paths are used to handle epoch bumping.

Transactional Producers

No Epoch Bump Allowed
• coordinatorSupportsBumpingEpoch = false when initPIDVersion < 3 or initPIDVersion = null.

Client-Triggered Epoch Bump Allowed
• coordinatorSupportsBumpingEpoch = true when initPIDVersion >= 3.
• TransactionVersion2Enabled = false when endTxnVersion < 5.

Only Server-Triggered Epoch Bump Allowed
• TransactionVersion2Enabled = true and endTxnVersion >= 5.

We want to refine the code and make it more structured to correctly handle epoch bumping in the above mentioned cases.

The changes made in this patch are:

Rename epochBumpRequired to epochBumpTriggerRequired to symbolize a manual epoch bump request from the client
Modify canEpochBump method according to the above mentioned scenarios

Reviewers: Artem Livshits <alivshits@confluent.io>, Calvin Liu <caliu@confluent.io>, Justine Olshan <jolshan@confluent.io>",2024-11-25 14:29:15,Ritika Reddy,Mixed
cebec91470c440a1735e50210ae3fc0f62ee40a7,"KAFKA-18080 Replace DelayedItem by Long type (#17927)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-26 17:00:27,Yung,Not TDD
0b081fc3100243a886f21a7bdf26b395d876bf59,"KAFKA-15561 [2/N]: Background event and subscription state changes for RE2J pattern (#17918)

Reviewers: David Jacot <djacot@confluent.io>",2024-11-26 14:49:13,Lianet Magrans,Mixed
866d66229da658a5eb1fcb9da28624dd8d2f3e2a,"KAFKA-18056: Fixed bug in handling commitAsync responses (#17909)

There was a bug in handling the ShareAcknowledgeResponse for commitAsync(). Currently after we receive a response, we send out a background event to the application thread to update the acknowledgement commit callbacks for EVERY TopicIdPartition.
The map that was sent was not cleared after sending the event. This meant we ended up sending responses for partitions that were already sent in the previous event. So there will be duplicate calls to the callback.

The PR fixes the bug and adds a unit test for the same.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-11-26 20:15:19,ShivsundarR,Mixed
056a76e2b911ff56287da1b798703c882fb4cb3e,"KAFKA-17811 Separate modules to use different JDKs (#17522)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-26 23:30:41,TengYao Chi,Not TDD
0e4d8b3e8688d8c4babcf5f5718d946c636a5390,"KAFKA-17569 Rewrite TestLinearWriteSpeed by Java (#17736)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-26 23:43:01,TengYao Chi,Not TDD
24dd11d693687ce89eb5d1e0f746bca4107797a8,"KAFKA-17593; [8/N] Resolve regular expressions (#17864)

This patch introduces the asynchronous resolution of regular expressions. Let me unpack a few details about the implementations:
1) I have decided to finally update all the regular expressions within a consumer group together. My assumption is that the number of regular expressions in a group will be generally small but the number of topics in a cluster is large. Hence grouping has two benefits. Firstly, it allows to go through the list of topics once for all the regular expressions. Secondly, it reduces the number of potential rebalances because all the regular expressions are updated at the same time.
2) An update is triggered when the group is subscribed to at least one regular expressions.
3) An update is triggered when there is no ongoing update.
4) An update is triggered only of the previous one is older than 10s.
5) An update is triggered when the group has unresolved regular expressions.
6) An update is triggered when the metadata image has new topics.

Reviewers: Jeff Kim <jeff.kim@confluent.io>",2024-11-26 08:56:25,David Jacot,Mixed
b42efc7dc269129f6ea3d2e860d9bbaef4efa283,"KAFKA-18049: Upgrade the caffeine version to 3.1.1 (#17879)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2024-11-26 18:00:50,Ken Huang,Not TDD
98d47f47ef21394779ef2ff2675c6ee54d5a5dc2,"KAFKA-18028 the effective kraft version of --no-initial-controllers should be 1 rather than 0 (#17836)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-27 01:45:11,PoAn Yang,Mixed
2b2b3cd355c2bb226a869988a6b1a59a7f2db055,"KAFKA-18062: use feature version to enable ELR (#17867)

Replace the ELR static config with feature version.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2024-11-26 14:40:23,Calvin Liu,Mixed
37b4d9b01d5790f307d9c5877b7252306780da37,"KAFKA-15561 [3/N]: Client support for SubscriptionPattern in HB (#17951)

Reviewers: David Jacot <djacot@confluent.io>",2024-11-27 12:01:12,Lianet Magrans,Mixed
aae42ef656a1097acf54375a542b7ff78f0364a0,"KAFKA-17593; [9/N] Mark ConsumerGroupHeartbeat API v1 as stable (#17961)

Reviewers: Lianet Magrans <lmagrans@confluent.io>",2024-11-27 13:03:46,David Jacot,Mixed
486f65e8c60d1126b1b62180b6b66352e2783907,"KAFKA-18100 `Using` block suppresses all errors (#17954)

https://github.com/apache/kafka/pull/15881 changed our tests to utilize `using` blocks. But these blocks don't throw any errors, so if there is a failed assertion within the block, the test will still pass. 

We should either check the failure using a corresponding `match` block with Success(_) and Failure(e), use `using.resource`, or use try/finally blocks to clean up resources.

See https://www.scala-lang.org/api/3.0.2/scala/util/Using$.html

Co-authored-by: frankvicky <kitingiao@gmail.com>

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-28 03:25:19,TaiJuWu,Not TDD
a39c984d2162a8010f09798141cb38c9ade7d3fa,"KAFKA-15561 [4/N]: MockConsumer support for SubscriptionPattern (#17962)

Reviewers: David Jacot <djacot@confluent.io>",2024-11-27 14:33:28,Lianet Magrans,Mixed
c446e799be38eaa15be7650df4fc404d6abb6eed,"KAFKA-17010 Remove `DescribeLogDirsResponse#LogDirInfo`, `DescribeLogDirsResponse#ReplicaInfo`, and `DescribeLogDirsResult#all` (#17953)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-11-28 04:42:34,Chia-Chuan Yu,Not TDD
5243fb9a7d717521e64fa57bcdf895825df37e85,"KAFKA-18026: migrate KTableSource to use ProcesserSupplier#stores (#17903)

This PR is part of the implementation for KIP-1112 (KAFKA-18026). In order to have DSL operators be properly wrapped by the interface suggestion in 1112, we need to make sure they all use the ConnectedStoreProvider#stores method to connect stores instead of manually calling addStateStore.

This is a refactor only, there is no new behaviors.

Reviewers: Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2024-11-27 14:04:27,Almog Gavra,Mixed
700bdd5feeb5902c703f7d68e0aa45394a090120,"KAFKA-17997 Remove deprecated config log.message.timestamp.difference.max.ms (#17928)

Reviewers: Divij Vaidya <diviv@amazon.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-11-29 03:15:46,"HYUNSANG HAN (한현상, Travis)",Mixed
e7bbcdb2514804ea9e010d170dc576183cfb6637,"KAFKA-18090: Add ShareMemberDescription and Assignment (#17975)

Introduce ShareMemberDescription and ShareMemberAssignment as distinct classes for share groups. Although the correspondence with consumer groups is fairly close, the concepts are likely to diverge over time and separating these concepts now makes sense.

Reviewers: Manikumar Reddy <manikumar.reddy@gmail.com>",2024-11-29 10:20:01,Andrew Schofield,Mixed
9d23f89e05782875f5f37f1e9687c621b0e3edb8,"KAFKA-17338 ConsumerConfig should prevent using partition assignors with CONSUMER group protocol (#16899)

Reviewers: Kirk True <ktrue@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Lianet Magrans <lmagrans@confluent.io>",2024-11-29 09:36:29,Ken Huang,Mixed
6237325fb14047fc96ed7ed048540483baa61b0c,"KAFKA-15561 [5/N]: Integration tests for new subscribe API with Re2J pattern (#17964)

- integration tests for new subscribe api with RE2J pattern
- fix to ensure all topics are included in metadata requests when consumer is subscribed to RE2J pattern

Reviewers: David Jacot <djacot@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-11-30 01:02:39,Lianet Magrans,Not TDD
ae3c5dec99b6f20d860c945101d792c436301dc7,"KAFKA-18013: Add support for duration based offset reset strategy to Kafka Consumer (#17972)

Update AutoOffsetResetStrategy.java to support duration based reset strategy
Update OffsetFetcher related classes and unit tests

Reviewers: Andrew Schofield <aschofield@confluent.io>, Lianet Magrans <lmagrans@confluent.io>",2024-11-29 22:38:57,Manikumar Reddy,Mixed
615f1a0bf999cd0b5ccf38c09e6afaba89538e9f,"KAFKA-16181: Use incrementalAlterConfigs when updating broker configs by kafka-configs.sh (#15304)

This PR implement KIP-1011, kafka-configs.sh now uses incrementalAlterConfigs API to alter broker configurations instead of the deprecated alterConfigs API, and it will fall directly if the broker doesn't support incrementalAlterConfigs.

Reviewers: David Jacot <djacot@confluent.io>, OmniaGM <o.g.h.ibrahim@gmail.com>.",2024-12-01 18:32:02,dengziming,Mixed
44cb90222c680b076f563004f8c0e7d8655d77af,"MINOR: Refactor configs in GroupMetadataManager (#17982)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-12-02 02:26:28,David Jacot,Mixed
c3d22180d45dba3caeb25ffaea36142140662900,"KAFKA-18128 Fix failed test MetadataSchemaCheckerToolTest.testVerifyEvolutionGit in PR (#17996)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-12-02 16:19:18,TengYao Chi,Mixed
6fd951a9c0aa773060cd6bbf8a8b8c47ee9d2965,"KAFKA-17610 Drop alterConfigs (#18002)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-12-02 23:26:06,TengYao Chi,Not TDD
184b64fb41651f95e038f402fa24f58761f4c185,"KAFKA-18026: migrate KStream and KTable aggregates to use ProcesserSupplier#stores (#17929)

As part of KIP-1112, to maximize the utility of the new ProcessorWrapper, we need to migrate the DSL operators to the new method of attaching state stores by implementing ProcessorSupplier#stores, which makes these stores available for inspection by the user's wrapper.

This PR covers the aggregate operator for both KStream and KTable.


Reviewers: Guozhang Wang <guozhang.wang.us@gmail.com>, Rohan Desai <rohan@responsive.dev>",2024-12-03 02:09:43,A. Sophie Blee-Goldman,Mixed
275b995bf2c8a26977ea72fa2b4831b930276654,"KAFKA-18095; Allow a  member to join without subscription under new consumer protocol (#18003)

This patch relaxes requiring non-empty subscribed names and regex in the full heartbeat request. Without this, a consumer using client side regexes may not be able to join the group when the regex does not match any topics yet and this is inconsistent with the old protocol. Relaxing the subscribed regex is not strictly required but it seems better to keep it consistent.

Reviewers: Lianet Magrans <lmagrans@confluent.io>",2024-12-03 02:11:36,David Jacot,Mixed
a8cdbaf4b30a119c66a9a85f6cab32610cd17fa9,"KAFKA-18138: The controller must add all extant brokers to BrokerHeartbeatTracker when activating (#18009)

The controller must add all extant brokers to BrokerHeartbeatTracker when activating. Otherwise, we
could end up in a situation where a broker fails exactly as a controller failover occurs, and we
never fence it.

Also, fix a bug where the slf4j logger object in PeriodicTaskControlManager was initialized as
though it belonged to OffsetControlManager.

Reviewers: David Mao <dmao@confluent.io>, David Arthur <mumrah@gmail.com>",2024-12-03 10:33:52,Colin Patrick McCabe,Mixed
c76fb5cb9b284e5b5f8b642c7b740ed004f32bb0,"KAFKA-17893: Support record keys in the foreignKeyExtractor argument of KTable foreign join (#17756)

Currently, KTable foreign key joins only allow extracting the foreign key from the value of the source record. This forces users to duplicate data that might already exist in the key into the value when the foreign key needs to be derived from both the key and value. This leads to:

- Data duplication
- Additional storage overhead
- Potential data inconsistency if the duplicated data gets out of sync
- Less intuitive API when the foreign key is naturally derived from both key and value

This change allows user to extract the foreign key from the key and value of the source record.

Reviewers: Lucas Brutschy <lbrutschy@confluent.io>",2024-12-03 17:34:13,Peter Lee,Mixed
180112a4a95d754f38d004a910b1a31151311605,"KAFKA-18084 Added write locks in SharePartition where locks were async calls were being made (#17957)

Reviewers: Andrew Schofield <aschofield@confluent.io>, poorv Mittal <apoorvmittal10@gmail.com>, Sushant Mahajan <sushant.mahajan88@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-12-04 01:46:29,Abhinav Dixit,Mixed
ac8b3dfbf002e75b7868bca642673163e694e926,"KAFKA-18060 new coordinator does not handle TxnOffsetCommitRequest with empty member id when using CONSUMER group (#17914)

There are two issues in KAFKA-18060:

1) New coordinator can't handle the TxnOffsetCommitRequest with empty member id, and TxnOffsetCommitRequest v0-v2 do definitely has an empty member ID, causing ConsumerGroup#validateOffsetCommit to throw an UnknownMemberIdException. This prevents the old producer from calling sendOffsetsToTransaction. Note that TxnOffsetCommitRequest versions v0-v2 are included in KIP-896, so it seems the new coordinator should support that operations

2) The deprecated API Producer#sendOffsetsToTransaction does not use v0-v2 to send TxnOffsetCommitRequest with an empty member ID. Unfortunately, it has been released for a while. Therefore, the new coordinator needs to handle TxnOffsetCommitRequest with an empty member ID for all versions.

Taken from the two issues above, we need to handle empty member id in all API versions when new coordinator are dealing with TxnOffsetCommitRequest.

Reviewers: David Jacot <djacot@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-12-04 02:55:19,Kuan-Po Tseng,Mixed
fe88232b07cd1954793cc64eea0ec735257fb622,"KAFKA-17750 Extend kafka-consumer-groups command line tool to support new consumer group (part 1) (#17958)

1) Bump validVersions of ConsumerGroupDescribeRequest.json and ConsumerGroupDescribeResponse.json to ""0-1"".

2) Add MemberType field to ConsumerGroupDescribeResponse.json. Default value is -1 (unknown). 0 is for classic member and 1 is for consumer member.

3) When ConsumerGroupMember#useClassicProtocol is true, return MemberType field as 0. Otherwise, return 1.

Reviewers: David Jacot <djacot@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-12-04 06:08:39,PoAn Yang,Mixed
dbae448a052bd3d5f3c1293294a33497de213bff,"KAFKA-18137: Unloading transaction state incorrectly removes loading partitions (#18011)

When there is a become follower transition on a transaction coordinator state partition, we intend to unload the state partition. However, we pass the new epoch to the method that does the unloading. In that method, we create a `TransactionPartitionAndLeaderEpoch` object comprising of the topic partition and the epoch that we use as a key to remove the partition from loading. However, we wouldn't ever expect to see this epoch in that map since we only load on the leader. See the code snippet: https://github.com/apache/kafka/blob/d00f0ecf1a1a082c97564f4b807e7a342472b57a/core/src/main/scala/kafka/coordinator/transaction/TransactionStateManager.scala#L602

We could have a partition load after the unloading occurs, and that partition will be stuck storing stale state on the broker until it restarts. While this may not immediately cause a correctness issue, we should try to properly clean up state.

Check that the epoch is less than the new epoch when removing the partition from loadingPartitions.

Added a test that failed before this change was made.

Reviewers: Artem Livshits <alivshits@confluent.io>, Jeff Kim <jeff.kim@confluent.io>",2024-12-03 14:51:07,Justine Olshan,Mixed
31d97bc3c99f543d7a3ca148361e5f346c50fde3,"KAFKA-18026: KIP-1112, skip re-registering aggregate stores in StatefulProcessorNode (#18015)

Minor followup to #17929 based on this discussion

Also includes some very minor refactoring/renaming on the side. The only real change is in the KGroupedStreamImpl class

Reviewers: Guozhang Wang <guozhang.wang.us@gmail.com>",2024-12-03 22:18:55,A. Sophie Blee-Goldman,Mixed
f60382bf21601b1c6708d094fadb13de59a77278,"KAFKA-18127 Validate SubscriptionPattern used on v0 HB (#17989)

Reviewers: David Jacot <djacot@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",2024-12-04 19:55:12,Lianet Magrans,Not TDD
bd0ea70912574a931beb0ee344d9d3c1fc8875e0,"KAFKA-18096: Allow join with regex if no matching topics  (#18024)

Reviewers: David Jacot <djacot@confluent.io>",2024-12-04 11:35:42,Lianet Magrans,Mixed
2d39d5be64d4f5b6446f4b9ec3f32b039707d9d1,"KAFKA-17783: Adding listeners to remove share partition on partition changes (#17796)

Reviewers: Andrew Schofield <aschofield@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Jun Rao <junrao@gmail.com>",2024-12-04 15:43:37,Apoorv Mittal,Mixed
2b43c49f51d8f8bdac5125ea20d41967d1f830cf,"KAFKA-18050 Upgrade the checkstyle version to 10.20.2 (#17999)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-12-05 10:59:18,Ken Huang,Mixed
8fde6dedea839709d8c83a4a0c32403c917ceab8,"KAFKA-18155 : Fix bug in response handler for ShareAcknowledge (#18029)

In the response handler for ShareAcknowledge, we are passing the clientResponse.receivedTimeMs() to the handler methods. But when there is a disconnect or when the response received is null, we should be passing the current time instead.

This bug was causing consumer to hang as it did not call the handler methods on disconnect, and further requests were blocked waiting for its completion.

Reviewers: Andrew Schofield <aschofield@confluent.io>,  Apoorv Mittal <apoorvmittal10@gmail.com>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-12-05 12:59:13,ShivsundarR,Mixed
c3506834e97dedadca7d48b7192000e4cee526c2,"KAFKA-17598; Command line validation tool for RE2J regex (#18031)

This patch introduces the `--validate-regex` argument to the `kafka-consumer-group` command line tool as defined in KIP-848. The new argument allows the verification of RE2 regular expressions.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Lianet Magrans <lmagrans@confluent.io>",2024-12-04 23:40:32,David Jacot,Mixed
e99561e1f30a30f9b151669a78d340f286a3ead6,"KAFKA-17593; [10/N] Remove resolved regular expressions when unsubscribed (#17976)

This patch does a few things:
1) It cleans up resolved regular expressions when they are unsubscribed from. It covers the regular leave/fenced paths for the new protocol and it also covers the LeaveGroup API as new members could be removed via the admin API.
2) It ensures that tombstones for  resolved regular expressions are generated on the conversion patch from consumer to classic group.
3) It fixes [KAFKA-18116](https://issues.apache.org/jira/browse/KAFKA-18116) because I faced the same issue while working on the LeaveGroup API. It adds an integration test for this case too.

Reviewers: Dongnuo Lyu <dlyu@confluent.io>, Jeff Kim <jeff.kim@confluent.io>",2024-12-04 23:41:37,David Jacot,Mixed
50b6953661a46d7d57a8aca5c875e91a19166253,"KAFKA-18122 : Added support for ShareConsumeBenchWorker (#17984)

Added ShareConsumeBenchSpec and ShareConsumeBenchWorker similar to ConsumeBenchSpec/ConsumeBenchWorker. This will help us run trogdor workloads for share consumers as well.
Added a sample json workload running 5 share consumers.

Reviewers: Andrew Schofield <aschofield@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-12-05 18:46:32,ShivsundarR,Mixed
fa54065298d1f3f62aa1e3563722fb58ac6f491d,"KAFKA-18086: Enable propagation of the error message when writing state (#17980)

* KAFKA-18086: Enable propagation of the error message when writing state

* Propagate the error message in the writing state when calling SharePartitionManager.acknowledge and SharePartitionManager.releaseSession, and add corresponding tests to verify that the expected error message is propagated.

* Reviewers: Andrew Schofield <aschofield@confluent.io>, Apoorv Mittal <apoorvmittal10@gmail.com>",2024-12-05 17:48:26,Yung,Mixed
09e8fa2dbe0517fcb08d756f67dfd4061f275a71,"KAFKA-18026: KIP-1112, migrate stream-table joins to use ProcesserSupplier#stores (#18047)

Covers wrapping of processors and state stores for KStream-KTable joins

Reviewers: Almog Gavra <almog@responsive.dev>, Guozhang Wang <guozhang.wang.us@gmail.com>",2024-12-05 10:06:11,A. Sophie Blee-Goldman,Not TDD
e30edb3eff0d2794854fa270ee1a4514dd983d6c,"KAFKA-18052: Decouple the dependency of feature stable version to the metadata version (#17886)

Currently the validation of feature upgrade relies on the supported version range generated during registration. For a given feature, its max supported feature version in production is set to be the default version value (the latest feature version with bootstrap metadata value smaller or equal to the latest production metadata value).

This patch introduces a LATEST_PRODUCTION value independent from the metadata version to each feature so that the highest supported feature version can be customized by the feature owner.

The change only applies to dynamic feature upgrade. During formatting, we still use the default value associated the metadata version.

Reviewers: Justine Olshan <jolshan@confluent.io>, Jun Rao <junrao@gmail.com>",2024-12-05 11:07:47,Dongnuo Lyu,Mixed
970d8930ac7b0cff8d042d96f8bedb2a0b55f9a9,"KAFKA-18159 Remove onPartitionsRevoked and onPartitionsAssigned from SinkTask (#18049)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-12-06 04:28:34,Nick Guo,Not TDD
0ff55c316aab9b54adcb1cfc4d3d3dbedc279270,"KAFKA-18106: Generate LeaderAndIsrUpdates on unclean shutdown (#18045)

Generate LeaderAndISR change records when a broker re-registers and the quorum controller detects an unclean shutdown.

This is necessary to ensure that we perform the expected partition state transitions, eg: bumping leader epochs and so on.

Reviewers: Colin P. McCabe <cmccabe@apache.org>",2024-12-05 16:19:05,David Mao,Mixed
36b48536f62698a5cc6be3c24bb68da6e2602b57,"MINOR: Fix broken test (#18062)

Reviewers: David Jacot <djacot@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, TaiJuWu <tjwu1217@gmail.com>",2024-12-05 21:31:52,Lianet Magrans,Not TDD
8864cba0e85ed076d21d1632847a40269f6aacf3,"MINOR: Update full request condition in ConsumerGroupHeartbeat request handling (#18061)

With the addition of the SubscribedTopicRegex field to the ConsumerGroupHeartbeat request, we need to update the definition of a full request. This patch does so.

Reviewers: Lianet Magrans <lmagrans@confluent.io>",2024-12-05 23:05:22,David Jacot,Mixed
e7d986e48c2e939e834ecb44e61f41153a52eead,"KAFKA-17550: DescribeGroups v6 exploitation (#17706)

This PR introduces the DescribeGroups v6 API as part of KIP-1043. This adds an error message for the described groups so that it is possible to get some context on the error. It also changes the behaviour for when the group ID cannot be found but returning error code GROUP_ID_NOT_FOUND rather than NONE.

Reviewers: David Jacot <djacot@confluent.io>",2024-12-05 23:12:24,Andrew Schofield,Mixed
ccca9f146e34cf344583900671259caf63df2f0b,"KAFKA-17945, KAFKA-17944: Handling leader epoch error for offset reset APIs (#17979)

The PR sends known leader epoch while fetch offset information. If API throws exception then PR adds way to handle the exceptions and surface same to make decision for handling share partition itself.

Reviewers: Abhinav Dixit <adixit@confluent.io>, Andrew Schofield <aschofield@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>, Jun Rao <junrao@gmail.com>",2024-12-06 09:55:38,Apoorv Mittal,Mixed
0bbed823e818a920fbaa2d54b50f4fcd81a8a759,"KAFKA-17200: Allow the replication of user internal topics (#17815)

Reviewers: Viktor Somogyi-Vass <viktorsomogyi@gmail.com>",2024-12-06 15:23:58,Patrik Marton,Mixed
b7294d92e11b2cc7b4766663b46aa0f2a718bee9,"KAFKA-17593; [11/11] Update subscription type (#18020)

This is the last patch in the series which introduces regular expressions in the new consumer group protocol. The patch ensures that the subscription type of the group takes into account the regular expressions. Please refer to the code to see how they are included.

Reviewers: Sean Quah <squah@confluent.io>, Jeff Kim <jeff.kim@confluent.io>",2024-12-06 06:57:27,David Jacot,Mixed
755adf8a566e07c26a8d8e32fbe7e0db5a5e1361,"KAFKA-14563: RemoveClient-Side AddPartitionsToTxn Requests (#17698)

Removes the client side AddPartitionsToTxn/AddOffsetsToTxn calls so that the partition is implicitly added as part of KIP-890 part 2. 

This change also requires updating the valid state transitions. The client side can not know for certain if a partition has been added server side when the request times out (partial completion). Thus for TV2, the transition to PrepareAbort is now valid for Empty, CompleteCommit, and CompleteAbort. 

For readability, the V1 and V2 endTransaction methods have been separated. 

Reviewers: Artem Livshits <alivshits@confluent.io>, Justine Olshan <jolshan@confluent.io>, Ritika Reddy <rreddy@confluent.io>",2024-12-06 09:00:04,Calvin Liu,Mixed
15206d5083b18d7ff8afd360304dc17e90f7a35b,"KAFKA-18084 Added usage for rollback state while SharePartition acquires records (#17965)

Reviewers: Andrew Schofield <aschofield@confluent.io>, Apoorv Mittal <apoorvmittal10@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-12-07 01:32:08,Abhinav Dixit,Mixed
24385a89cf991ddd79e1dcb000cb680c0a2e137e,"MINOR: Replace assertUnorderedListEquals by assertUnorderedRecordsEquals in group-coordinator module (#18076)

Reviewers: Lianet Magrans <lianetmr@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-12-07 11:43:25,David Jacot,Not TDD
42f74a1c3afd693a16c3980ee022e82872e4bfa2,"KAFKA-17796: Persist higher leaderEpoch in read state call. (#17580)

This PR adds code into the ShareCoordinatorService.readState method to issue a runtime.scheduleWriteOperation call if the incoming read state request holds a valid leaderEpoch value (not -1).

Co-authored-by: TaiJu Wu <tjwu1217@gmail.com>

Reviewers: Andrew Schofield <aschofield@confluent.io>, David Jacot <djacot@confluent.io>",2024-12-07 09:02:03,Sushant Mahajan,Mixed
4630628701a5f2b153aa9d87bbbae26a18743200,"KAFKA-18144 Move the storage exceptions out of the core module (#18021)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-12-07 22:43:00,Mickael Maison,Mixed
af0054b50204c17be0cc84b8a3ef4575324bcb79,"KAFKA-18182: KIP-891 Add VersionRange to Plugins and DelegatingClassLoader APIs (#16984)

Reviewers: Greg Harris <greg.harris@aiven.io>",2024-12-07 09:20:02,snehashisp,Not TDD
d5c202943473f152a77c9c7096317d13f89ece0a,"KAFKA-16339: [4/4 KStream#flatTransformValues] Remove Deprecated ""transformer"" methods and classes (#17882)

Reviewer: Matthias J. Sax <matthias@confluent.io>",2024-12-08 20:10:11,Joao Pedro Fonseca Dantas,Mixed
9ae1b0f01784d314d21100e7d021467626b20137,"KAFKA-18134; Disallow group upgrades when custom assignors are used (#18046)

Disallow upgrades from classic groups to consumer groups when any member's assignment has non-empty userData.

Reviewers: David Jacot <djacot@confluent.io>",2024-12-09 00:39:22,Sean Quah,Mixed
d76238a18fb6a86b4b08bc04918ea1a0ee626517,"KAFKA-17696 New consumer background operations unaware of metadata errors (#17440)

Reviewers: Kirk True <ktrue@confluent.io>, Lianet Magrans <lmagrans@confluent.io>",2024-12-09 09:31:14,Ken Huang,Mixed
3a9777a667620c5f926176452744c751df4dac17,"KAFKA-14619; KRaft validate snapshot id are at batch boundaries (#17500)

When KafkaRaftClient receives a request to create a snapshot with end offset that is not aligned to a batch boundary, do not create a misaligned snapshot and instead log at info level and throw an IllegalArgumentException.

Checking that the end offset is at a batch boundary is performed by reading the log at snapshotId.offset() and checking whether the offset in question is the base offset of the returned batch.

Reviewers: José Armando García Sancio <jsancio@apache.org>",2024-12-09 11:38:00,kevin-wu24,Mixed
77ac31b36ade61ed7413d6dcbb472381d02316e9,"KAFKA-18164: Clear existing acknowledgements on share session epoch reset. (#18063)

Reviewers: Andrew Schofield <aschofield@confluent.io>",2024-12-09 21:03:49,ShivsundarR,Mixed
05fd36a3b766d898c46e4f212490de3525b1e4d5,KAFKA-18174: Subsequent write event completions should be a noop (#18083),2024-12-09 17:17:29,Jeff Kim,Mixed
e8837465a5fc478f1c79d1ad475b43e00a39a5d7,"KAFKA-18067: Kafka Streams can leak Producer client under EOS (#17931)

To avoid leaking producers, we should add a 'closedflag toStreamProducer` indicating whether we should reset prouder.

Reviewers: Guozhang Wang <guozhang.wang.us@gmail.com>, Anna Sophie Blee-Goldman <ableegoldman@apache.org>",2024-12-09 16:12:05,TengYao Chi,Mixed
4603f7495e981cf22c7aa5168c05b0d7a43473a3,"KAFKA-18030 Remove old upgrade-system-tests modules (#17843)

Reviewers: Chia-Ping Tsai <chia7712@gmail.com>",2024-12-10 11:19:14,mingdaoy,Not TDD
c8380ae77950bbd2161cf14cbdeb007562655f2f,"KAFKA-17750: Extend kafka-consumer-groups command line tool to support new consumer group (part 2) (#18034)

* Add fields `groupEpoch` and `targetAssignmentEpoch` to `ConsumerGroupDescription.java`.
* Add fields `memberEpoch` and `upgraded` to `MemberDescription.java`.
* Add assertion to `PlaintextAdminIntegrationTest#testDescribeClassicGroups` to make sure member in classic group returns `upgraded` as `Optional.empty`.
* Add new case `testConsumerGroupWithMemberMigration` to `PlaintextAdminIntegrationTest` to make sure migration member has correct `upgraded` value. Add assertion for `groupEpoch`, `targetAssignmentEpoch`, `memberEpoch` as well.

Reviewers: David Jacot <djacot@confluent.io>

Signed-off-by: PoAn Yang <payang@apache.org>",2024-12-10 05:02:20,PoAn Yang,Mixed
45835a0e459b3d1a7203d73c94e7b393bdc89dca,"MINOR: Cleanup connect runtime module (#18074)


Reviewers: Mickael Maison <mickael.maison@gmail.com>",2024-12-10 18:25:38,Dmitry Werner,Mixed
3cf8745243026b83d97fbc80f2b1fe03f1455701,"MINOR: Add clientTransactionVersion to AddPartitionsToTxn requests and persist the value across transitions (#18086)

We can better keep track of which transactions use TV_2 by storing this information in the clientTransactionVersion field and persisting it across state transitions. Also updated some logging and equality code to include this information.

Added a test to ensure version persists. There aren't many TV2 transitions that don't specify TV, but I did test the InitProducerId + epoch overflow case.

Reviewers: Artem Livshits <alivshits@confluent.io>, Jeff Kim <jeff.kim@confluent.io>",2024-12-10 12:59:01,Justine Olshan,Mixed
57737a357fad495964c1aefc593b67d107098d38,"KAFKA-18188; Admin LeaveGroup should allow removing member using consumer protocol by member id (#18116)

The LeaveGroup API is used by the admin client to remove static members or remove all members from the group. The latter does not work because the API does not allow removing a member using the CONSUMER protocol by member id. Moreover, the response should only include the member id if the member id was included in the request. This patch fixes both issues.

Reviewers: Dongnuo Lyu <dlyu@confluent.io>, Christo Lolov <lolovc@amazon.com>, Jeff Kim <jeff.kim@confluent.io>",2024-12-10 23:17:32,David Jacot,Mixed
7591868aead54fff7d5e8a44c5e06746ed34866b,"KAFKA-18179: Move AsyncOffsetReadFutureHolder to storage module (#18095)

Reviewers: Christo Lolov <lolovc@amazon.com>",2024-12-11 09:56:47,Mickael Maison,Not TDD
d2ad418cfd05278e7fbff9a6db7088c68050e1f9,"KAFKA-18156 VerifiableConsumer should ignore ""--session-timeout"" when using CONSUMER protocol (#18036)

Reviewers: TaiJuWu <tjwu1217@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-12-11 21:12:46,Kuan-Po Tseng,Mixed
bd6d0fbf3d6a2eee4703a4cfcaaa3d6c775c5681,"KAFKA-16437 Upgrade to Jakarta and Jetty 12 (KIP-1032) (#16754)

This commit implements the changes for KIP-1032. This updates Kafka to Jakarta specs, JavaEE 10 and Jetty 12. The changes here primarily effect Kafka Connect and MM2.

Todo/Notes:

1) I bumped the connect modules to JDK 17 but I also had to bump a couple other things that had a dependency on conect. The tools project depends on connect so that had to be bumped, and streams depends on tools so that needed to be bumped. This means we may need to separate some things if we don't want to enforce JDK 17 on streams.

2) There is an issue with a test in DedicatedMirrorIntegrationTest that I had to change for now that involves escaping characters and not quite sure what to do about it yet. The cause is the Servlet 6 spec changing what is allowed in the path. See: Jetty 12: 400: Ambiguous URI path encoding for path <%=FOO%>~1 (encoded: %3C%25%3DFOO%25%3E%7E1) jetty/jetty.project#11890

3) I had to configure the idle timeout in Jetty requests to match our request timeout so tests didn't fail. This was needed to fix the ConnectWorkerIntegrationTest#testPollTimeoutExpiry() test

Testing is being done by just using the existing tests for Connect and MM2 which should be sufficient.

Reviewers: Greg Harris <greg.harris@aiven.io>, David Arthur <mumrah@gmail.com>, Chia-Ping Tsai <chia7712@gmail.com>",2024-12-11 23:24:14,Christopher L. Shannon,Mixed
d09e2228461791d257db825b7862c11d7b46aba9,"KAFKA-18189: CoordinatorRequestManager log message can include incorrect coordinator disconnect time (#18109)

Fixed logic in markCoordinatorUnknown to ensure the warning log contains the correct number of milliseconds the client has been disconnected.

Reviewers: Christo Lolov <lolovc@amazon.com>",2024-12-11 16:22:51,Kirk True,Mixed
e979fce94eb401c0c6e36e9a7cbf917cc33b1c49,"KAFKA-17030; Unattached voters will fetch from bootstrap servers (#17352)

Because the set of voters are dynamic (KIP-953), it is possible for a replica to believe they are a voter while the current leader doesn't have that replica in the voter set. In this replicated state, the leader will not sent BeginQuorumEpoch requests to such a replica. This means that such replicas will not be able to discover the leader.

This change will help Unattached rediscover the leader by sending Fetch requests to the the bootstrap servers.
Followers have a similar issue - if they are unable to communicate with the leader they should try contacting the bootstrap servers.

Reviewers: José Armando García Sancio <jsancio@apache.org>",2024-12-11 11:38:14,Alyssa Huang,Mixed
d83f09d014ff574784212cfdc317b5004c90c687,"KAFKA-18015: Add support for duration based offset reset strategy to Kafka Streams (#17973)

Part of KIP-1106.

Adds the public APIs to Kafka Streams, to support the the newly added ""by_duration"" reset policy,
plus adds the missing ""none"" reset policy. Deprecates the enum `Topology.AutoOffsetReset` and
all related methods, and replaced them with new overload using the new `AutoOffsetReset` class.

Co-authored-by: Matthias J. Sax <matthias@confluent.io>

Reviewers: Matthias J. Sax <matthias@confluent.io>, Bill Bejeck <bill@confluent.io>, Manikumar Reddy <manikumar.reddy@gmail.com>",2024-12-11 10:47:25,KApolinario1120,Mixed
